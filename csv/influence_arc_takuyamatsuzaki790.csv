2009.iwslt-evaluation.15,P08-1023,0,0.0260161,"a2 are word alignments between a source language phrase f1m and a target language phrase en1 ; p(·) and l(·) are phrasal translation probabilities and lexical weights, respectively; wp stands for the word penalty. In order to be used in CKY-style decoding [10], a rule in the form of (1) can be easily transformed into an end-to-end Hiero-style [10] translation rule: (2) And the corresponding synchronous PCFG production takes the form of: X →∑i wi ∗log(pi ) f1m , en1 . (3) It has been proved that the end-to-end phrase table significantly influence the translation result of syntax-based systems [11, 12]. Note that the phrase table mentioned here 2 http://www.statmt.org/moses/ is not constrained to be linguistic phrases, i.e., a phrase inside the table is not necessarily covered by a subtree. This makes the phrase table more flexible to be used than in the tree/forest-to-string systems [11, 12] where additional approaches have to be employed in order to make use of nonlinguistic phrases [13, 14]. Return back to Figure 1, HPSG trees attached with PASs are generated by parsing the target language sentences using Enju. Then, we extract HPSG and PAS based translation rules from the word-aligned a"
2009.iwslt-evaluation.15,P07-1089,0,0.0155645,"hronous PCFG production takes the form of: X →∑i wi ∗log(pi ) f1m , en1 . (3) It has been proved that the end-to-end phrase table significantly influence the translation result of syntax-based systems [11, 12]. Note that the phrase table mentioned here 2 http://www.statmt.org/moses/ is not constrained to be linguistic phrases, i.e., a phrase inside the table is not necessarily covered by a subtree. This makes the phrase table more flexible to be used than in the tree/forest-to-string systems [11, 12] where additional approaches have to be employed in order to make use of nonlinguistic phrases [13, 14]. Return back to Figure 1, HPSG trees attached with PASs are generated by parsing the target language sentences using Enju. Then, we extract HPSG and PAS based translation rules from the word-aligned and target-language-parsed parallel corpora. The HPSG-based xRs (tree-to-string, [15]) translation rules (binarized inversely [16]) are extracted using the GHKM minimal-rule extraction algorithm of [1]. In order to trace the lexical level translation information (similar to PASbased rules (Section 3 and Figure 2)), we remember the endto-end alignments in an HPSG-based translation rule. The ideas a"
2009.iwslt-evaluation.15,N04-1035,0,0.47118,"by Head-driven Phrase Structure Grammar and Predicate-Argument Structures. We report the results of our system on both the development and test sets. 1. Introduction How can we integrate deep syntactic information into current statistical machine translation (SMT) systems to further improve the accuracy and fluency? How to deal with global reordering problem for a language pair that do not share isomorphic syntactic structures? These remain to be essential issues faced by current SMT research community. In this paper, we manage to answer these questions in terms of string-to-tree translation [1, 2, 3]. English, the target language in our case study, is the most popularly researched language with plenty resources and syntactic parsers. In contrast to commit to Probabilistic Context-Free Grammar (PCFG) which only generates shallow trees of English [1, 2, 3], we propose the use of deep parse trees and semantic dependencies described respectively by Head-driven Phrase Structure Grammar (HPSG) [4, 5] and PredicateArgument Structures (PASs). We illustrate two major characteristics that an HPSG tree (used by us) differs from a PCFG tree. First, a node in an HPSG tree is represented by a typed fea"
2009.iwslt-evaluation.15,P06-1121,0,0.0665645,"by Head-driven Phrase Structure Grammar and Predicate-Argument Structures. We report the results of our system on both the development and test sets. 1. Introduction How can we integrate deep syntactic information into current statistical machine translation (SMT) systems to further improve the accuracy and fluency? How to deal with global reordering problem for a language pair that do not share isomorphic syntactic structures? These remain to be essential issues faced by current SMT research community. In this paper, we manage to answer these questions in terms of string-to-tree translation [1, 2, 3]. English, the target language in our case study, is the most popularly researched language with plenty resources and syntactic parsers. In contrast to commit to Probabilistic Context-Free Grammar (PCFG) which only generates shallow trees of English [1, 2, 3], we propose the use of deep parse trees and semantic dependencies described respectively by Head-driven Phrase Structure Grammar (HPSG) [4, 5] and PredicateArgument Structures (PASs). We illustrate two major characteristics that an HPSG tree (used by us) differs from a PCFG tree. First, a node in an HPSG tree is represented by a typed fea"
2009.iwslt-evaluation.15,N09-1025,0,0.211268,"by Head-driven Phrase Structure Grammar and Predicate-Argument Structures. We report the results of our system on both the development and test sets. 1. Introduction How can we integrate deep syntactic information into current statistical machine translation (SMT) systems to further improve the accuracy and fluency? How to deal with global reordering problem for a language pair that do not share isomorphic syntactic structures? These remain to be essential issues faced by current SMT research community. In this paper, we manage to answer these questions in terms of string-to-tree translation [1, 2, 3]. English, the target language in our case study, is the most popularly researched language with plenty resources and syntactic parsers. In contrast to commit to Probabilistic Context-Free Grammar (PCFG) which only generates shallow trees of English [1, 2, 3], we propose the use of deep parse trees and semantic dependencies described respectively by Head-driven Phrase Structure Grammar (HPSG) [4, 5] and PredicateArgument Structures (PASs). We illustrate two major characteristics that an HPSG tree (used by us) differs from a PCFG tree. First, a node in an HPSG tree is represented by a typed fea"
2009.iwslt-evaluation.15,J08-1002,1,0.797575,"e pointer to semantic arguments Table 1: Examples of syntactic/semantic features extracted from HPSG signs that are included in the output of Enju (top and bottom stands for features of phrasal and lexical nodes, respectively). ing translation. The idea proposed in this paper can be considered as a natural integration of syntactic information and semantic dependency information for assisting string-to-tree translation. We call the integration natural here, because the HPSG tree and PAS of an English sentence are generated synchronously by using a state-of-the-art HPSG parser on English, Enju1 [6]. Note that the information available in the output of Enju is a fairly crude approximation of the TFS used in the full HPSG grammar [4, 5] due to practicable considerations [6]. Although the information taken from Enju’s output is much more than the commonly used PCFG parser, the HPSG-based translation rule is still extracted from an approximation of the full HPSG grammar. 2. System Outline 2.1. Parameter Estimation The diagram of parameter estimation in our system is shown in Figure 1, which is similar to most syntax-based SMT sys1 http://www-tsujii.is.s.u-tokyo.ac.jp/enju/index.html Proceed"
2009.iwslt-evaluation.15,J03-1002,0,0.00225715,"ction and estimation, GHKM [1] Phrase-training (Moses [9]) PAS-based translation rules Phrase translation table HPSG-based translation rules Binarizing (Section 4) To Hiero-style (Section 2.1) α1 SRILM [17] 5-gram LM α2 α3 Binarizing (Section 4) α4 Minimum Error Rate Training on the development sets (Z-mert [18]) Figure 1: The parameter estimation and rule combination diagram of our system. tems [1, 7]. Given bilingual parallel corpora, we first tokenize the source and target sentences (e.g., word segmentation of Chinese; punctuation segmentation and lowercase of English). Then, we use GIZA++ [8] and grow-diag-finaland balancing strategy (dealing with unaligned source/target words) [9] on the tokenized parallel corpora to obtain a phrase-aligned parallel corpora. A phrase translation table (PTT) is estimated from the phrase-aligned parallel corpora. We implement the step of phrase table extraction employing the Moses toolkit2 [9]. Recall that the Moses-style phrase translation rule takes the following form: Here, a1 and a2 are word alignments between a source language phrase f1m and a target language phrase en1 ; p(·) and l(·) are phrasal translation probabilities and lexical weights,"
2009.iwslt-evaluation.15,P07-2045,0,0.00823132,"The diagram of parameter estimation in our system is shown in Figure 1, which is similar to most syntax-based SMT sys1 http://www-tsujii.is.s.u-tokyo.ac.jp/enju/index.html Proceedings of IWSLT 2009, Tokyo - Japan Original parallel corpora Target language parsing (Enju [6]) Lexical analyzing Phrase-aligned and target-language-parsed parallel corpora Tokenized parallel corpora Predicate-Argument Structure based translation rule extraction and estimation (Section 3) GIZA++ & balancing Phrase-aligned parallel corpora HPSG translation rule extraction and estimation, GHKM [1] Phrase-training (Moses [9]) PAS-based translation rules Phrase translation table HPSG-based translation rules Binarizing (Section 4) To Hiero-style (Section 2.1) α1 SRILM [17] 5-gram LM α2 α3 Binarizing (Section 4) α4 Minimum Error Rate Training on the development sets (Z-mert [18]) Figure 1: The parameter estimation and rule combination diagram of our system. tems [1, 7]. Given bilingual parallel corpora, we first tokenize the source and target sentences (e.g., word segmentation of Chinese; punctuation segmentation and lowercase of English). Then, we use GIZA++ [8] and grow-diag-finaland balancing strategy (dealing wi"
2009.iwslt-evaluation.15,J07-2003,0,0.634756,"9] on the tokenized parallel corpora to obtain a phrase-aligned parallel corpora. A phrase translation table (PTT) is estimated from the phrase-aligned parallel corpora. We implement the step of phrase table extraction employing the Moses toolkit2 [9]. Recall that the Moses-style phrase translation rule takes the following form: Here, a1 and a2 are word alignments between a source language phrase f1m and a target language phrase en1 ; p(·) and l(·) are phrasal translation probabilities and lexical weights, respectively; wp stands for the word penalty. In order to be used in CKY-style decoding [10], a rule in the form of (1) can be easily transformed into an end-to-end Hiero-style [10] translation rule: (2) And the corresponding synchronous PCFG production takes the form of: X →∑i wi ∗log(pi ) f1m , en1 . (3) It has been proved that the end-to-end phrase table significantly influence the translation result of syntax-based systems [11, 12]. Note that the phrase table mentioned here 2 http://www.statmt.org/moses/ is not constrained to be linguistic phrases, i.e., a phrase inside the table is not necessarily covered by a subtree. This makes the phrase table more flexible to be used than in"
2009.iwslt-evaluation.15,P09-1020,0,0.0220831,"hronous PCFG production takes the form of: X →∑i wi ∗log(pi ) f1m , en1 . (3) It has been proved that the end-to-end phrase table significantly influence the translation result of syntax-based systems [11, 12]. Note that the phrase table mentioned here 2 http://www.statmt.org/moses/ is not constrained to be linguistic phrases, i.e., a phrase inside the table is not necessarily covered by a subtree. This makes the phrase table more flexible to be used than in the tree/forest-to-string systems [11, 12] where additional approaches have to be employed in order to make use of nonlinguistic phrases [13, 14]. Return back to Figure 1, HPSG trees attached with PASs are generated by parsing the target language sentences using Enju. Then, we extract HPSG and PAS based translation rules from the word-aligned and target-language-parsed parallel corpora. The HPSG-based xRs (tree-to-string, [15]) translation rules (binarized inversely [16]) are extracted using the GHKM minimal-rule extraction algorithm of [1]. In order to trace the lexical level translation information (similar to PASbased rules (Section 3 and Figure 2)), we remember the endto-end alignments in an HPSG-based translation rule. The ideas a"
2009.iwslt-evaluation.15,N04-1014,0,0.0309107,"t constrained to be linguistic phrases, i.e., a phrase inside the table is not necessarily covered by a subtree. This makes the phrase table more flexible to be used than in the tree/forest-to-string systems [11, 12] where additional approaches have to be employed in order to make use of nonlinguistic phrases [13, 14]. Return back to Figure 1, HPSG trees attached with PASs are generated by parsing the target language sentences using Enju. Then, we extract HPSG and PAS based translation rules from the word-aligned and target-language-parsed parallel corpora. The HPSG-based xRs (tree-to-string, [15]) translation rules (binarized inversely [16]) are extracted using the GHKM minimal-rule extraction algorithm of [1]. In order to trace the lexical level translation information (similar to PASbased rules (Section 3 and Figure 2)), we remember the endto-end alignments in an HPSG-based translation rule. The ideas are described in [1, 11] in detail. In order to use the dependency structure, we describe a linear-time algorithm based on minimum covering trees to extract PAS-based translation rules (Section 3). SRI Language Modeling (SRILM) toolkit3 [17] is employed to train a 5-gram language model"
2009.iwslt-evaluation.15,N06-1033,0,0.449598,"a phrase inside the table is not necessarily covered by a subtree. This makes the phrase table more flexible to be used than in the tree/forest-to-string systems [11, 12] where additional approaches have to be employed in order to make use of nonlinguistic phrases [13, 14]. Return back to Figure 1, HPSG trees attached with PASs are generated by parsing the target language sentences using Enju. Then, we extract HPSG and PAS based translation rules from the word-aligned and target-language-parsed parallel corpora. The HPSG-based xRs (tree-to-string, [15]) translation rules (binarized inversely [16]) are extracted using the GHKM minimal-rule extraction algorithm of [1]. In order to trace the lexical level translation information (similar to PASbased rules (Section 3 and Figure 2)), we remember the endto-end alignments in an HPSG-based translation rule. The ideas are described in [1, 11] in detail. In order to use the dependency structure, we describe a linear-time algorithm based on minimum covering trees to extract PAS-based translation rules (Section 3). SRI Language Modeling (SRILM) toolkit3 [17] is employed to train a 5-gram language model (LM) on the tokenized target language side w"
2009.iwslt-evaluation.15,P03-1021,0,0.00667254,"lexical level translation information (similar to PASbased rules (Section 3 and Figure 2)), we remember the endto-end alignments in an HPSG-based translation rule. The ideas are described in [1, 11] in detail. In order to use the dependency structure, we describe a linear-time algorithm based on minimum covering trees to extract PAS-based translation rules (Section 3). SRI Language Modeling (SRILM) toolkit3 [17] is employed to train a 5-gram language model (LM) on the tokenized target language side with Kneser-Ney smoothing. Toolkit Z-mert4 [18] is used for Minimum-Error Rate Training (MERT) [19]. 3 http://www.speech.sri.com/projects/srilm/ 4 http://www.cs.jhu.edu/ - 100 - ozaidan/zmert/ Proceedings of IWSLT 2009, Tokyo - Japan 2.2. Rule Combination Since the PTT, the HPSG-based rules, and the PAS-based rules are independently extracted and estimated, the distribution overlapping among them is inevitable. As shown in Figure 1, we use Z-mert to tune their weights on the development sets. The optimal derivation is computed by:   3 ∑  ∑ αi wj 4 d∗ = arg max log pji i (d) + log pα . LM (d)  d∈D  i=1 ji Here, pj1 , pj2 , and pj3 represent the feature subsets from PPT, binarized PAS-b"
2009.iwslt-evaluation.15,W05-1506,0,0.0324405,"3], we define a PASR to be an xRs rule and binarize it in an inverse way [16]. 3.2.1. Definition of PASR 2.3. Decoding We use a CKY-style algorithm with beam-pruning and cubepruning [10] to decode Chinese sentences. For efficient decoding with integrated N-gram LMs, we binarize all translation rules into rules that contain at most two variables and can be incrementally scored by LM [16]. For each source language sentence f , the output of the chart-parsing algorithm is expressed as a hyper-graph representing a set of derivations. Given a hyper-graph for f , we use the Algorithm 3 described in [20] to extract its k-best derivations. Since different derivations may lead to the same target language string e, we further adopt Algorithm 3’s modification (i.e., keep a hash-table to maintain the unique target sentences [21]) to efficiently generate the unique k-best translations. 3. PAS-based Translation Rule Extraction In this section, we first express an example of an HPSG tree attached with PASs, and then describe the data structure and an extraction algorithm of PAS-based translation rules (short as PASR, hereafter). A PASR is a 4-tuple ⟨S, T, A, n⟩, which describes the alignment A betwee"
2009.iwslt-evaluation.15,2006.amta-papers.8,0,0.0203907,"e included in the three subsets. In addition, number of phrases and words are contained in pj1 , and number of rules are included in pj2 and pj3 . three elements in the source and target language sides. In particular, we observe that the “head” of this rule is ignored whose arguments can be generalized into variables. Note that PASs are not only attached to verbs in a sentence, but also to all other words in the sentence. The corresponding PASRs are illustrated in Figure 2 as well. Even apparently similar in data structure, we argue our PASRs are still different from the traditional xRs rules [1, 11, 21], since the knowledge of semantic dependencies are further explicitly employed. We give the formal definitions and a lineartime rule extraction algorithm in the following subsections. 3.2. Definitions Using a strategy similar to most string-to-tree systems [3], we define a PASR to be an xRs rule and binarize it in an inverse way [16]. 3.2.1. Definition of PASR 2.3. Decoding We use a CKY-style algorithm with beam-pruning and cubepruning [10] to decode Chinese sentences. For efficient decoding with integrated N-gram LMs, we binarize all translation rules into rules that contain at most two varia"
2009.iwslt-evaluation.15,P02-1040,0,0.0763328,"Missing"
C08-1069,P05-1022,0,0.0138055,"ncludes a minimum number of back-off rules. 4 Experiments 4.1 Experiment Setting We compared the performance of an HPSG parser with several CFG parsers. The HPSG parser is the Enju parser (Ninomiya et al., 2007), which has been developed for parsing with the Enju HPSG grammar. A disambiguation module based on a discriminative maximum-entropy model is used in the Enju parser. We compared the Enju parser with four CFG parsers: Stanford’s lexicalized parser (Klein and Manning, 2003), Collins’ parser (Collins, 1999), Charniak’s parser (Charniak, 2000), and Charniak and Johnson’s reranking parser (Charniak and Johnson, 2005). The first three parsers are based on treebank PCFGs derived from PTB. The last parser is a combination of Charniak’s parser and a reranking module based on a maximum-entropy model. The Enju parser and Collins’ parser require POS-tagged sentences as the input. A POS tagger distributed with the Enju parser was used for the POS-tagging. We used a standard split of PTB for the training/development/test data: sections 02-21 for the extraction of the synchronous grammar, section 22 for the development, and section 23 for the evaluation of the parsers. Some of the trees in PTB are missing in the HP"
C08-1069,A00-2018,0,0.0606592,"be sufficiently small so that the highest-scored derivation includes a minimum number of back-off rules. 4 Experiments 4.1 Experiment Setting We compared the performance of an HPSG parser with several CFG parsers. The HPSG parser is the Enju parser (Ninomiya et al., 2007), which has been developed for parsing with the Enju HPSG grammar. A disambiguation module based on a discriminative maximum-entropy model is used in the Enju parser. We compared the Enju parser with four CFG parsers: Stanford’s lexicalized parser (Klein and Manning, 2003), Collins’ parser (Collins, 1999), Charniak’s parser (Charniak, 2000), and Charniak and Johnson’s reranking parser (Charniak and Johnson, 2005). The first three parsers are based on treebank PCFGs derived from PTB. The last parser is a combination of Charniak’s parser and a reranking module based on a maximum-entropy model. The Enju parser and Collins’ parser require POS-tagged sentences as the input. A POS tagger distributed with the Enju parser was used for the POS-tagging. We used a standard split of PTB for the training/development/test data: sections 02-21 for the extraction of the synchronous grammar, section 22 for the development, and section 23 for the"
C08-1069,J07-2003,0,0.0118602,"∈ T2 , i = 1, . . . k}, which is a set of pairs of non-terminal nodes that dominate the same span of s, and then !   ()  (  2. split (T1 , T2 ) at each (Ni1 , Ni2 ) for i = 1, . . . , k. *+ *1 *+ *12 ++3 *1 ++ 4564     ()  ( -/./0  78 . 7 -/.#0 ++3 *1 *9+2 ++ *12 78 . 7 *9+!2 4/564 Figure 3: An example of synchronous TSG: synchronous productions (top) and a synchronous derivation (bottom). Stochastic synchronous grammars have been used in several machine-translation systems to serve as a model of tree-to-tree translation (e.g., (Eisner, 2003; Chiang, 2007)). Our objective of automatic conversion between syntactic analyses is similar to the tree-to-tree machine translation. An important difference is that, for our purpose, the generated tree pair should have the same yields since they are two analyses of the same sentence. We also want the synchronous grammar to be able to generate a pair of trees wherein some constituents in one tree cross with the constituents in the other tree; for example, such a treetransformation is necessary to change the articleattachment levels. We show below that, by means of a simple algorithm, we can obtain a synchro"
C08-1069,C04-1041,0,0.0663942,"Missing"
C08-1069,P07-1032,0,0.0747532,"Missing"
C08-1069,P03-2041,0,0.142299,"vel of the articles: HPSG analysis (left) and PTB-CFG analysis (right).                     Figure 2: An example of synchronous CFG 2.3 Stochastic Synchronous Tree-Substitution Grammar for Tree Conversion For the purpose of the inverted transformation of simplified HPSG trees to PTB-CFG trees, we use a statistical approach based on the stochastic synchronous grammars. Stochastic synchronous grammars are a family of probabilistic models that generate a pair of trees by recursively applying synchronous productions, starting with a pair of initial symbols. See e.g., Eisner (2003) for a more formal definition. Figure 2 shows an example of synchronous CFG, which generates the pairs of strings of the form (abm c, cbm a). Each nonterminal symbol on the yields of the synchronous production is linked to a non-terminal symbol on the other rule’s yield. In the figure, the links are represented by subscripts. A linked pair of the nonterminal symbols is simultaneously expanded by another synchronous production. The probability of a derivation D of a tree pair hS, T i is defined as the product of the probability of the pair of initial symbols (i.e., the root nodes of S and T ),"
C08-1069,J07-3004,0,0.0617922,"Missing"
C08-1069,N03-1016,0,0.0191937,"ous productions, and the scores of the backoff rules. We set the value of  to be sufficiently small so that the highest-scored derivation includes a minimum number of back-off rules. 4 Experiments 4.1 Experiment Setting We compared the performance of an HPSG parser with several CFG parsers. The HPSG parser is the Enju parser (Ninomiya et al., 2007), which has been developed for parsing with the Enju HPSG grammar. A disambiguation module based on a discriminative maximum-entropy model is used in the Enju parser. We compared the Enju parser with four CFG parsers: Stanford’s lexicalized parser (Klein and Manning, 2003), Collins’ parser (Collins, 1999), Charniak’s parser (Charniak, 2000), and Charniak and Johnson’s reranking parser (Charniak and Johnson, 2005). The first three parsers are based on treebank PCFGs derived from PTB. The last parser is a combination of Charniak’s parser and a reranking module based on a maximum-entropy model. The Enju parser and Collins’ parser require POS-tagged sentences as the input. A POS tagger distributed with the Enju parser was used for the POS-tagging. We used a standard split of PTB for the training/development/test data: sections 02-21 for the extraction of the synchr"
C08-1069,W05-1511,1,0.893231,"Missing"
C08-1069,W07-2208,1,0.872039,"sed on synchronous grammars. The use of such a shallow representation as a common format has the advantage of reduced noise introduced by the conversion in comparison with the noise produced by the conversion to deeper representations. We compared an HPSG parser with several CFG parsers in our experiment and found that meaningful differences among the parsers’ performance can still be observed by such a shallow representation. 1 Introduction Recently, there have been advancement made in the parsing techniques for large-scale lexicalized grammars (Clark and Curran, 2004; Ninomiya et al., 2005; Ninomiya et al., 2007), and it have presumably been accelerated by the development of the semi-automatic acquisition techniques of large-scale lexicalized grammars from parsed corpora (Hockenmaier and Steedman, 2007; Miyao c 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. et al., 2005). In many of the studies on lexicalized grammar parsing, the accuracy of the parsing results is evaluated in terms of the accuracy of the semantic representations output by the parsers. Since the formalisms f"
C08-1069,J93-2004,0,\N,Missing
C08-1069,J03-4003,0,\N,Missing
C10-1144,W03-3006,0,0.0295547,"hm to train a CCG parser. Different from their work, we focused on improving the performance of the deep parser by refining the training method for supertagging. Ninomiya et al. (2007) used the supertagging probabilities as a reference distribution for the log-linear model for HPSG, which aimed to consistently integrate supertagging into probabilistic HPSG parsing. Prins et al. (2001) trained a POStagger on an automatic parser-generated lexical entry corpus as a filter for Dutch HPSG parsing to improve the parsing speed and accuracy. 1287 Related Work The existing work most similar to ours is Boullier (2003). He presented a non-statistical parsing-based supertagger for LTAG. Similar to his method, we used a CFG to approximate the original lexicalized grammar. The main difference between these two methods is that we consider the grammar constraints in the training phase of the supertagger, not only in the supertagging test phase and our main objective is to improve the performance of the final parser. 6 Conclusions and Future Work In this paper, based on the observation that supertaggers are commonly trained separately from lexicalized parsers without global grammar constraints, we proposed a fore"
C10-1144,W03-1006,0,0.0595728,"Missing"
C10-1144,C04-1041,0,0.0370791,"Missing"
C10-1144,W07-1202,0,0.0337935,"Missing"
C10-1144,W02-2203,0,0.0712976,"Missing"
C10-1144,W02-1001,0,0.0540738,"ansitive verbs in non-3rd person present form, which indicates that the head syntactic category of “like” is verb and it has an NP subject and an NP complement. With such fine-grained grammatical type distinctions, the number of supertags is very large. Compared to the 45 part-of-speech (POS) tags defined in the PennTreebank, the HPSG grammar we used contains 2,308 supertags. The large number and the complexity of the supertags makes supertagging harder than the POS tagging task. Supertagging can be formulated as a sequence labeling task. Here, we follow the definition of Collins’ perceptron (Collins, 2002). The training objective of supertagging is to learn the mapping from a POS-tagged word sentence w = (w1 /p1 , ..., wn /pn ) to a sequence of supertags s = (s1 , ..., sn ). We use function GEN (w) to indicate all candidates of supertag sequences given input w. Feature function Φ maps a sample (w, s) to a point in the feature space Rd . θ is the vector of feature weights. Given an input w, the most plausible supertag sequence is found by the prediction function defined as follows: F (w) = argmax θ · Φ(w, s) (1) s∈GEN(w) 2.3 CFG-filtering CFG-filtering (Kiefer and Krieger, 2000) is a technique t"
C10-1144,P07-1037,0,0.049781,"Missing"
C10-1144,2000.iwpt-1.15,0,0.0491666,"ion of Collins’ perceptron (Collins, 2002). The training objective of supertagging is to learn the mapping from a POS-tagged word sentence w = (w1 /p1 , ..., wn /pn ) to a sequence of supertags s = (s1 , ..., sn ). We use function GEN (w) to indicate all candidates of supertag sequences given input w. Feature function Φ maps a sample (w, s) to a point in the feature space Rd . θ is the vector of feature weights. Given an input w, the most plausible supertag sequence is found by the prediction function defined as follows: F (w) = argmax θ · Φ(w, s) (1) s∈GEN(w) 2.3 CFG-filtering CFG-filtering (Kiefer and Krieger, 2000) is a technique to find a superset of (packed) HPSG parse trees that satisfy the constraints in a grammar. A CFG that approximates the original HPSG grammar is used for efficiently finding such trees without doing full-fledged HPSG parsing that is computationally demanding because the schema application involves unification operations among large feature structures (signs). The number of possible signs is infinite in general and hence 1282 Figure 1: HPSG parsing for the sentence “They like coffee.” some features (e.g., the number agreement feature) are ignored in the approximating CFG so that"
C10-1144,J99-2004,0,0.161949,"Missing"
C10-1144,P05-1011,1,0.841523,"g methods was also investigated. 4.1 Corpus Description The HPSG grammar used in the experiments is Enju version 2.32 . It is semi-automatically converted from the WSJ portion of PennTreebank (Miyao, 2006). The grammar consists of 2,308 supertags in total. Sections 02-21 were used to train different supertagging models and the HPSG parser. Section 22 and section 23 were used as the development set and the test set respectively. We evaluated the HPSG parser performance by labeled precision (LP) and labeled recall (LR) of predicate-argument relations of the parser’s output as in previous works (Miyao, 2005). All experiments were conducted on an AMD Opteron 2.4GHz server. Template Type Word POS Word-POS Template wi ,wi−1 ,wi+1 , wi−1 &wi , wi &wi+1 pi , pi−1 , pi−2 , pi+1 , pi+2 , pi−1 &pi , pi−2 &pi−1 , pi−1 &pi+1 , pi &pi+1 , pi+1 &pi+2 pi−1 &wi , pi &wi , pi+1 &wi Table 1: Feature templates used for supertagging models. 1 “UNK” supertags are ignored in evaluation as in previous works. 2 http://www-tsujii.is.s.u-tokyo.ac.jp/enju/index.html 1284 4.2 Baseline Models and Settings We used a point-wise averaged perceptron (PW) to train a baseline supertagger. Point-wise classifiers have been reporte"
C10-1144,W07-0702,0,0.0405674,"Missing"
C10-1144,W06-1619,1,0.908214,"Missing"
C10-1144,W07-2208,1,0.900258,"Missing"
C10-1144,W01-1815,0,0.0835441,"Missing"
C10-1144,W09-3832,1,0.612735,"Missing"
C10-2162,P00-1058,0,0.0298208,"d particular attention to a different grammar framework, i.e. HPSG, with the analysis of more Chinese constructions, such as the serial verb construction. In addition, in our on-going deep parsing work, we use the developed Chinese HPSG grammar, i.e. the lexical entries, to train a full-fledged HPSG parser directly. Additionally, there are some works that induce lexicalized grammar from corpora for other languages. For example, by using the Penn Treebank, Miyao et al. (2005) automatically extracted a large HPSG lexicon, Xia (1999), Chen and Shanker (2000), Hockenmaier and Steedman (2002), and Chiang (2000) invented LTAG/CCG specific procedures for lexical entry extraction. From the German Tiger corpus, Cramer and Zhang (2009) constructed a German HPSG grammar; Hockenmaier (2006) created a German CCGbank; and Rehbei and Genabith (2009) acquired LFG resources. In addition, Schluter and Genabith (2009) automatically obtained widecoverage LFG resources from a French Treebank. Our work implements a similar idea to these works, but we apply different grammar design and annotation rules, which are specific to Chinese. Furthermore, we obtained a comparative result to state-of-the-art works for English."
C10-2162,P04-1014,0,0.103169,"Missing"
C10-2162,W09-2605,0,0.0464518,"ons, such as the serial verb construction. In addition, in our on-going deep parsing work, we use the developed Chinese HPSG grammar, i.e. the lexical entries, to train a full-fledged HPSG parser directly. Additionally, there are some works that induce lexicalized grammar from corpora for other languages. For example, by using the Penn Treebank, Miyao et al. (2005) automatically extracted a large HPSG lexicon, Xia (1999), Chen and Shanker (2000), Hockenmaier and Steedman (2002), and Chiang (2000) invented LTAG/CCG specific procedures for lexical entry extraction. From the German Tiger corpus, Cramer and Zhang (2009) constructed a German HPSG grammar; Hockenmaier (2006) created a German CCGbank; and Rehbei and Genabith (2009) acquired LFG resources. In addition, Schluter and Genabith (2009) automatically obtained widecoverage LFG resources from a French Treebank. Our work implements a similar idea to these works, but we apply different grammar design and annotation rules, which are specific to Chinese. Furthermore, we obtained a comparative result to state-of-the-art works for English. There are some researchers who worked on Chinese HPSG grammar development manually. Zhang (2004) implemented a Chinese HP"
C10-2162,hockenmaier-steedman-2002-acquiring,0,0.475048,"cted adjuncts. But in our grammar, we only deal with extracted arguments, and the gap in a relative clause (as indicated in the dash-boxed part in Figure 12). When the extracted phrase is an adjunct of the relative clause, we simply view the clause as a modifier of the extracted phrase. shown in Figure 13, we obtain a lexical entry for the word ‘写/write’ as shown in Figure 14. 3.1.2 Rules for Correcting Inconsistency There are some inconsistencies in the annotation of the CTB, which presents difficulties for performing the derivation tree annotation. Therefore, we define 49 rules, as done in (Hockenmaier and Steedman, 2002) for English, to mitigate inconsistencies before annotation (refer to Table 3). 3.1.3 Rules for Assisting Annotation We also define 48 rules (refer to Table 2), which are similar to the rules used in (Miyao, 2006) for English, to help the derivation tree annotation. For example, 12 pattern rules are defined to assign the schemas to corresponding constituents. Figure 13. HPSG derivation tree for Figure 8. Rule Type Rules for correcting inconsistent annotation Rule Description Rule # Fix tree annotation 37 Fix phrase tag annotation 5 Fix functional tag annotation 5 Fix POS tag annotation 2 Slash"
C10-2162,J08-1002,1,0.92028,"Missing"
C10-2162,schluter-van-genabith-2008-treebank,0,0.0354136,"Missing"
C10-2162,Y09-2048,1,0.594404,"Missing"
C10-2162,C02-1145,0,0.0248821,"work, we paid particular attention to a different grammar framework, i.e. HPSG, with the analysis of more Chinese constructions, such as the serial verb construction. In addition, in our on-going deep parsing work, we use the developed Chinese HPSG grammar, i.e. the lexical entries, to train a full-fledged HPSG parser directly. Additionally, there are some works that induce lexicalized grammar from corpora for other languages. For example, by using the Penn Treebank, Miyao et al. (2005) automatically extracted a large HPSG lexicon, Xia (1999), Chen and Shanker (2000), Hockenmaier and Steedman (2002), and Chiang (2000) invented LTAG/CCG specific procedures for lexical entry extraction. From the German Tiger corpus, Cramer and Zhang (2009) constructed a German HPSG grammar; Hockenmaier (2006) created a German CCGbank; and Rehbei and Genabith (2009) acquired LFG resources. In addition, Schluter and Genabith (2009) automatically obtained widecoverage LFG resources from a French Treebank. Our work implements a similar idea to these works, but we apply different grammar design and annotation rules, which are specific to Chinese. Furthermore, we obtained a comparative result to state-of-the-art"
C10-2162,N04-1013,0,\N,Missing
C10-2162,W02-1502,0,\N,Missing
C10-2162,P06-1064,0,\N,Missing
C10-2162,W08-1700,0,\N,Missing
E09-1069,J97-4005,0,0.0599797,"(i) deterministic shift-reduce parsing for unification-based grammars, and (ii) best-first shift-reduce parsing with beam thresholding for unification-based grammars. Deterministic parsing cannot simply be applied to unification-based grammar parsing, which often fails because of its hard constraints. Therefore, it is developed by using default unification, which almost always succeeds in unification by overwriting inconsistent constraints in grammars. 1 Introduction Over the last few decades, probabilistic unification-based grammar parsing has been investigated intensively. Previous studies (Abney, 1997; Johnson et al., 1999; Kaplan et al., 2004; Malouf and van Noord, 2004; Miyao and Tsujii, 2005; Riezler et al., 2000) defined a probabilistic model of unification-based grammars, including head-driven phrase structure grammar (HPSG), lexical functional grammar (LFG) and combinatory categorial grammar (CCG), as a maximum entropy model (Berger et al., 1996). Geman and Johnson (Geman and Johnson, 2002) and Miyao and Tsujii (Miyao and Tsujii, 2002) proposed a feature forest, which is a dynamic programming algorithm for estimating the probabilities of all possible parse candidates. A feature fores"
E09-1069,J96-1002,0,0.0115771,"ification, which almost always succeeds in unification by overwriting inconsistent constraints in grammars. 1 Introduction Over the last few decades, probabilistic unification-based grammar parsing has been investigated intensively. Previous studies (Abney, 1997; Johnson et al., 1999; Kaplan et al., 2004; Malouf and van Noord, 2004; Miyao and Tsujii, 2005; Riezler et al., 2000) defined a probabilistic model of unification-based grammars, including head-driven phrase structure grammar (HPSG), lexical functional grammar (LFG) and combinatory categorial grammar (CCG), as a maximum entropy model (Berger et al., 1996). Geman and Johnson (Geman and Johnson, 2002) and Miyao and Tsujii (Miyao and Tsujii, 2002) proposed a feature forest, which is a dynamic programming algorithm for estimating the probabilities of all possible parse candidates. A feature forest can estimate the model parameters without unpacking the parse forest, i.e., the chart and its edges. Feature forests have been used successfully for probabilistic HPSG and CCG (Clark and Curran, 2004b; Miyao and Tsujii, 2005), and its parsing is empirically known to be fast and accurate, especially with supertagging (Clark and Curran, 2004a; Ninomiya et"
E09-1069,J93-1002,0,0.164709,"e feature structure nodes are not unified but merged as a set of types. Then, all types marked as “strict” are unified into one type for each node. If this fails, the default unification also returns unification failure as its result. Finally, each node is assigned a single type, which is the result of type unification for all types marked as both “default” and “strict” if it succeeds or all types marked only as “strict” otherwise. 4 Shift-reduce parsing for unificationbased grammars Non-deterministic shift-reduce parsing for unification-based grammars has been studied by Briscoe and Carroll (Briscoe and Carroll, 1993). Their algorithm works non-deterministically with the mechanism of the packed parse forest, and hence it has the problem of locality in the packed parse forest. This section explains our shiftreduce parsing algorithms, which are based on deterministic shift-reduce CFG parsing (Sagae and Lavie, 2005) and best-first shift-reduce CFG parsing (Sagae and Lavie, 2006). Sagae’s parser selects the most probable shift/reduce actions and non-terminal symbols without assuming explicit CFG rules. Therefore, his parser can proceed deterministically without failure. However, in Binary Reduce Features [Sw(0"
E09-1069,P05-1022,0,0.0606157,"–611, c Athens, Greece, 30 March – 3 April 2009. 2009 Association for Computational Linguistics 603 segmented constituents are instantiated. This is because values in parse trees can propagate anywhere throughout the parse tree by unification. For example, values may propagate from the root node to terminal nodes, and the final form of the terminal nodes is unknown until the parser finishes constructing the whole parse tree. Consequently, the design of grammars, semantic structures, and feature functions becomes complex. To solve the problem of locality, several approaches, such as reranking (Charniak and Johnson, 2005), shift-reduce parsing (Yamada and Matsumoto, 2003), search optimization learning (Daumé and Marcu, 2005) and sampling methods (Malouf and van Noord, 2004; Nakagawa, 2007), were studied. In this paper, we investigate shift-reduce parsing approach for unification-based grammars without the mechanisms of the packed parse forest. Shift-reduce parsing for CFG and dependency parsing have recently been studied (Nivre and Scholz, 2004; Ratnaparkhi, 1997; Sagae and Lavie, 2005, 2006; Yamada and Matsumoto, 2003), through approaches based essentially on deterministic parsing. These techniques, however,"
E09-1069,C04-1041,0,0.0267427,"including head-driven phrase structure grammar (HPSG), lexical functional grammar (LFG) and combinatory categorial grammar (CCG), as a maximum entropy model (Berger et al., 1996). Geman and Johnson (Geman and Johnson, 2002) and Miyao and Tsujii (Miyao and Tsujii, 2002) proposed a feature forest, which is a dynamic programming algorithm for estimating the probabilities of all possible parse candidates. A feature forest can estimate the model parameters without unpacking the parse forest, i.e., the chart and its edges. Feature forests have been used successfully for probabilistic HPSG and CCG (Clark and Curran, 2004b; Miyao and Tsujii, 2005), and its parsing is empirically known to be fast and accurate, especially with supertagging (Clark and Curran, 2004a; Ninomiya et al., 2007; Ninomiya et al., 2006). Both estimation and parsing with the packed parse forest, however, have several inherent problems deriving from the restriction of locality. First, feature functions can be defined only for local structures, which limit the parser’s performance. This is because parsers segment parse trees into constituents and factor equivalent constituents into a single constituent (edge) in a chart to avoid the same cal"
E09-1069,P04-1014,0,0.0235272,"including head-driven phrase structure grammar (HPSG), lexical functional grammar (LFG) and combinatory categorial grammar (CCG), as a maximum entropy model (Berger et al., 1996). Geman and Johnson (Geman and Johnson, 2002) and Miyao and Tsujii (Miyao and Tsujii, 2002) proposed a feature forest, which is a dynamic programming algorithm for estimating the probabilities of all possible parse candidates. A feature forest can estimate the model parameters without unpacking the parse forest, i.e., the chart and its edges. Feature forests have been used successfully for probabilistic HPSG and CCG (Clark and Curran, 2004b; Miyao and Tsujii, 2005), and its parsing is empirically known to be fast and accurate, especially with supertagging (Clark and Curran, 2004a; Ninomiya et al., 2007; Ninomiya et al., 2006). Both estimation and parsing with the packed parse forest, however, have several inherent problems deriving from the restriction of locality. First, feature functions can be defined only for local structures, which limit the parser’s performance. This is because parsers segment parse trees into constituents and factor equivalent constituents into a single constituent (edge) in a chart to avoid the same cal"
E09-1069,P02-1036,0,0.0201586,"n unification by overwriting inconsistent constraints in grammars. 1 Introduction Over the last few decades, probabilistic unification-based grammar parsing has been investigated intensively. Previous studies (Abney, 1997; Johnson et al., 1999; Kaplan et al., 2004; Malouf and van Noord, 2004; Miyao and Tsujii, 2005; Riezler et al., 2000) defined a probabilistic model of unification-based grammars, including head-driven phrase structure grammar (HPSG), lexical functional grammar (LFG) and combinatory categorial grammar (CCG), as a maximum entropy model (Berger et al., 1996). Geman and Johnson (Geman and Johnson, 2002) and Miyao and Tsujii (Miyao and Tsujii, 2002) proposed a feature forest, which is a dynamic programming algorithm for estimating the probabilities of all possible parse candidates. A feature forest can estimate the model parameters without unpacking the parse forest, i.e., the chart and its edges. Feature forests have been used successfully for probabilistic HPSG and CCG (Clark and Curran, 2004b; Miyao and Tsujii, 2005), and its parsing is empirically known to be fast and accurate, especially with supertagging (Clark and Curran, 2004a; Ninomiya et al., 2007; Ninomiya et al., 2006). Both estim"
E09-1069,P03-1046,0,0.0772058,"Missing"
E09-1069,P99-1069,0,0.0417252,"stic shift-reduce parsing for unification-based grammars, and (ii) best-first shift-reduce parsing with beam thresholding for unification-based grammars. Deterministic parsing cannot simply be applied to unification-based grammar parsing, which often fails because of its hard constraints. Therefore, it is developed by using default unification, which almost always succeeds in unification by overwriting inconsistent constraints in grammars. 1 Introduction Over the last few decades, probabilistic unification-based grammar parsing has been investigated intensively. Previous studies (Abney, 1997; Johnson et al., 1999; Kaplan et al., 2004; Malouf and van Noord, 2004; Miyao and Tsujii, 2005; Riezler et al., 2000) defined a probabilistic model of unification-based grammars, including head-driven phrase structure grammar (HPSG), lexical functional grammar (LFG) and combinatory categorial grammar (CCG), as a maximum entropy model (Berger et al., 1996). Geman and Johnson (Geman and Johnson, 2002) and Miyao and Tsujii (Miyao and Tsujii, 2002) proposed a feature forest, which is a dynamic programming algorithm for estimating the probabilities of all possible parse candidates. A feature forest can estimate the mod"
E09-1069,N04-1013,0,0.0459961,"ing for unification-based grammars, and (ii) best-first shift-reduce parsing with beam thresholding for unification-based grammars. Deterministic parsing cannot simply be applied to unification-based grammar parsing, which often fails because of its hard constraints. Therefore, it is developed by using default unification, which almost always succeeds in unification by overwriting inconsistent constraints in grammars. 1 Introduction Over the last few decades, probabilistic unification-based grammar parsing has been investigated intensively. Previous studies (Abney, 1997; Johnson et al., 1999; Kaplan et al., 2004; Malouf and van Noord, 2004; Miyao and Tsujii, 2005; Riezler et al., 2000) defined a probabilistic model of unification-based grammars, including head-driven phrase structure grammar (HPSG), lexical functional grammar (LFG) and combinatory categorial grammar (CCG), as a maximum entropy model (Berger et al., 1996). Geman and Johnson (Geman and Johnson, 2002) and Miyao and Tsujii (Miyao and Tsujii, 2002) proposed a feature forest, which is a dynamic programming algorithm for estimating the probabilities of all possible parse candidates. A feature forest can estimate the model parameters without"
E09-1069,P05-1011,0,0.788301,"-first shift-reduce parsing with beam thresholding for unification-based grammars. Deterministic parsing cannot simply be applied to unification-based grammar parsing, which often fails because of its hard constraints. Therefore, it is developed by using default unification, which almost always succeeds in unification by overwriting inconsistent constraints in grammars. 1 Introduction Over the last few decades, probabilistic unification-based grammar parsing has been investigated intensively. Previous studies (Abney, 1997; Johnson et al., 1999; Kaplan et al., 2004; Malouf and van Noord, 2004; Miyao and Tsujii, 2005; Riezler et al., 2000) defined a probabilistic model of unification-based grammars, including head-driven phrase structure grammar (HPSG), lexical functional grammar (LFG) and combinatory categorial grammar (CCG), as a maximum entropy model (Berger et al., 1996). Geman and Johnson (Geman and Johnson, 2002) and Miyao and Tsujii (Miyao and Tsujii, 2002) proposed a feature forest, which is a dynamic programming algorithm for estimating the probabilities of all possible parse candidates. A feature forest can estimate the model parameters without unpacking the parse forest, i.e., the chart and its"
E09-1069,D07-1100,0,0.0167214,"propagate anywhere throughout the parse tree by unification. For example, values may propagate from the root node to terminal nodes, and the final form of the terminal nodes is unknown until the parser finishes constructing the whole parse tree. Consequently, the design of grammars, semantic structures, and feature functions becomes complex. To solve the problem of locality, several approaches, such as reranking (Charniak and Johnson, 2005), shift-reduce parsing (Yamada and Matsumoto, 2003), search optimization learning (Daumé and Marcu, 2005) and sampling methods (Malouf and van Noord, 2004; Nakagawa, 2007), were studied. In this paper, we investigate shift-reduce parsing approach for unification-based grammars without the mechanisms of the packed parse forest. Shift-reduce parsing for CFG and dependency parsing have recently been studied (Nivre and Scholz, 2004; Ratnaparkhi, 1997; Sagae and Lavie, 2005, 2006; Yamada and Matsumoto, 2003), through approaches based essentially on deterministic parsing. These techniques, however, cannot simply be applied to unification-based grammar parsing because it can fail as a result of its hard constraints in the grammar. Therefore, in this study, we propose"
E09-1069,W07-2208,1,0.834096,"t al., 1996). Geman and Johnson (Geman and Johnson, 2002) and Miyao and Tsujii (Miyao and Tsujii, 2002) proposed a feature forest, which is a dynamic programming algorithm for estimating the probabilities of all possible parse candidates. A feature forest can estimate the model parameters without unpacking the parse forest, i.e., the chart and its edges. Feature forests have been used successfully for probabilistic HPSG and CCG (Clark and Curran, 2004b; Miyao and Tsujii, 2005), and its parsing is empirically known to be fast and accurate, especially with supertagging (Clark and Curran, 2004a; Ninomiya et al., 2007; Ninomiya et al., 2006). Both estimation and parsing with the packed parse forest, however, have several inherent problems deriving from the restriction of locality. First, feature functions can be defined only for local structures, which limit the parser’s performance. This is because parsers segment parse trees into constituents and factor equivalent constituents into a single constituent (edge) in a chart to avoid the same calculation. This also means that the semantic structures must be segmented. This is a crucial problem when we think of designing semantic structures other than predicat"
E09-1069,W06-1619,1,0.806997,"Missing"
E09-1069,C02-1100,1,0.829183,"the phrasestructure rules and the lexical entries are represented by feature structures (Carpenter, 1992), and constraints in the grammar are forced by unification. Among the phrase-structure rules, a binary rule is a partial function: ℱ × ℱ → ℱ, 3 Default unification Default unification was originally investigated in a series of studies of lexical semantics, in order to deal with default inheritance in a lexicon. It is also desirable, however, for robust processing, because (i) it almost always succeeds and (ii) a feature structure is relaxed such that the amount of information is maximized (Ninomiya et al., 2002). In our experiments, we tested a simplified version of Copestake’s default unification. Before explaining it, we first explain Carpenter’s 604 two definitions of default unification (Carpenter, 1993). procedure forced_unification(p, q) queue := {〈p, q〉}; while( queue is not empty ) 〈p, q〉 := shift(queue); p := deref(p); q := deref(q); if p ≠ q θ(p) ≔ θ(p) ∪ θ(q); θ(q) ≔ ptr(p); forall f ∈ feat(p)⋃ feat(q) if f ∈ feat(p) ∧ f ∈ feat(q) queue := queue ∪ 〈δ(f, p), δ(f, q)〉; if f ∉ feat(p) ∧ f ∈ feat(q) δ(f, p) ≔ δ(f, q); procedure mark(p, m) p := deref(p); if p has not been visited θ(p) := {〈θ(p)"
E09-1069,C04-1010,0,0.290997,"ently, the design of grammars, semantic structures, and feature functions becomes complex. To solve the problem of locality, several approaches, such as reranking (Charniak and Johnson, 2005), shift-reduce parsing (Yamada and Matsumoto, 2003), search optimization learning (Daumé and Marcu, 2005) and sampling methods (Malouf and van Noord, 2004; Nakagawa, 2007), were studied. In this paper, we investigate shift-reduce parsing approach for unification-based grammars without the mechanisms of the packed parse forest. Shift-reduce parsing for CFG and dependency parsing have recently been studied (Nivre and Scholz, 2004; Ratnaparkhi, 1997; Sagae and Lavie, 2005, 2006; Yamada and Matsumoto, 2003), through approaches based essentially on deterministic parsing. These techniques, however, cannot simply be applied to unification-based grammar parsing because it can fail as a result of its hard constraints in the grammar. Therefore, in this study, we propose deterministic parsing for unification-based grammars by using default unification, which almost always succeeds in unification by overwriting inconsistent constraints in the grammars. We further pursue best-first shift-reduce parsing for unificationbased gramm"
E09-1069,W97-0301,0,0.0427544,"mmars, semantic structures, and feature functions becomes complex. To solve the problem of locality, several approaches, such as reranking (Charniak and Johnson, 2005), shift-reduce parsing (Yamada and Matsumoto, 2003), search optimization learning (Daumé and Marcu, 2005) and sampling methods (Malouf and van Noord, 2004; Nakagawa, 2007), were studied. In this paper, we investigate shift-reduce parsing approach for unification-based grammars without the mechanisms of the packed parse forest. Shift-reduce parsing for CFG and dependency parsing have recently been studied (Nivre and Scholz, 2004; Ratnaparkhi, 1997; Sagae and Lavie, 2005, 2006; Yamada and Matsumoto, 2003), through approaches based essentially on deterministic parsing. These techniques, however, cannot simply be applied to unification-based grammar parsing because it can fail as a result of its hard constraints in the grammar. Therefore, in this study, we propose deterministic parsing for unification-based grammars by using default unification, which almost always succeeds in unification by overwriting inconsistent constraints in the grammars. We further pursue best-first shift-reduce parsing for unificationbased grammars. Sections 2 and"
E09-1069,P00-1061,0,0.217224,"ing with beam thresholding for unification-based grammars. Deterministic parsing cannot simply be applied to unification-based grammar parsing, which often fails because of its hard constraints. Therefore, it is developed by using default unification, which almost always succeeds in unification by overwriting inconsistent constraints in grammars. 1 Introduction Over the last few decades, probabilistic unification-based grammar parsing has been investigated intensively. Previous studies (Abney, 1997; Johnson et al., 1999; Kaplan et al., 2004; Malouf and van Noord, 2004; Miyao and Tsujii, 2005; Riezler et al., 2000) defined a probabilistic model of unification-based grammars, including head-driven phrase structure grammar (HPSG), lexical functional grammar (LFG) and combinatory categorial grammar (CCG), as a maximum entropy model (Berger et al., 1996). Geman and Johnson (Geman and Johnson, 2002) and Miyao and Tsujii (Miyao and Tsujii, 2002) proposed a feature forest, which is a dynamic programming algorithm for estimating the probabilities of all possible parse candidates. A feature forest can estimate the model parameters without unpacking the parse forest, i.e., the chart and its edges. Feature forests"
E09-1069,W05-1513,0,0.758564,"uctures, and feature functions becomes complex. To solve the problem of locality, several approaches, such as reranking (Charniak and Johnson, 2005), shift-reduce parsing (Yamada and Matsumoto, 2003), search optimization learning (Daumé and Marcu, 2005) and sampling methods (Malouf and van Noord, 2004; Nakagawa, 2007), were studied. In this paper, we investigate shift-reduce parsing approach for unification-based grammars without the mechanisms of the packed parse forest. Shift-reduce parsing for CFG and dependency parsing have recently been studied (Nivre and Scholz, 2004; Ratnaparkhi, 1997; Sagae and Lavie, 2005, 2006; Yamada and Matsumoto, 2003), through approaches based essentially on deterministic parsing. These techniques, however, cannot simply be applied to unification-based grammar parsing because it can fail as a result of its hard constraints in the grammar. Therefore, in this study, we propose deterministic parsing for unification-based grammars by using default unification, which almost always succeeds in unification by overwriting inconsistent constraints in the grammars. We further pursue best-first shift-reduce parsing for unificationbased grammars. Sections 2 and 3 explain unification-"
E09-1069,P06-2089,0,0.0575817,"ct” if it succeeds or all types marked only as “strict” otherwise. 4 Shift-reduce parsing for unificationbased grammars Non-deterministic shift-reduce parsing for unification-based grammars has been studied by Briscoe and Carroll (Briscoe and Carroll, 1993). Their algorithm works non-deterministically with the mechanism of the packed parse forest, and hence it has the problem of locality in the packed parse forest. This section explains our shiftreduce parsing algorithms, which are based on deterministic shift-reduce CFG parsing (Sagae and Lavie, 2005) and best-first shift-reduce CFG parsing (Sagae and Lavie, 2006). Sagae’s parser selects the most probable shift/reduce actions and non-terminal symbols without assuming explicit CFG rules. Therefore, his parser can proceed deterministically without failure. However, in Binary Reduce Features [Sw(0)] [Sw(1)] [Sw(2)] [Sw(3)] [Sp(0)] [Sp(1)] [Sp(2)] [Sp(3)] [Shw(0)] [Shw(1)] [Shp(0)] [Shp(1)] [Snw(0)] [Snw(1)] [Snp(0)] [Snp(1)] [Ssy(0)] [Ssy(1)] [Shsy(0)] [Shsy(1)] [Snsy(0)] [Snsy(1)] [d] [wi-1] [wi] [wi+1] [pi-2] [pi-1] [pi] [pi+1] [pi+2] [pi+3] [d,c,hw,hp,hl] [d,c,hw,hp] [d, c, hw, hl] [d, c, sy, hw] [c, sp, hw, hp, hl] [c, sp, hw, hp] [c, sp, hw,hl] [c, s"
E09-1069,P07-1079,0,0.0302476,"Missing"
E09-1069,W03-3023,0,0.213876,"09 Association for Computational Linguistics 603 segmented constituents are instantiated. This is because values in parse trees can propagate anywhere throughout the parse tree by unification. For example, values may propagate from the root node to terminal nodes, and the final form of the terminal nodes is unknown until the parser finishes constructing the whole parse tree. Consequently, the design of grammars, semantic structures, and feature functions becomes complex. To solve the problem of locality, several approaches, such as reranking (Charniak and Johnson, 2005), shift-reduce parsing (Yamada and Matsumoto, 2003), search optimization learning (Daumé and Marcu, 2005) and sampling methods (Malouf and van Noord, 2004; Nakagawa, 2007), were studied. In this paper, we investigate shift-reduce parsing approach for unification-based grammars without the mechanisms of the packed parse forest. Shift-reduce parsing for CFG and dependency parsing have recently been studied (Nivre and Scholz, 2004; Ratnaparkhi, 1997; Sagae and Lavie, 2005, 2006; Yamada and Matsumoto, 2003), through approaches based essentially on deterministic parsing. These techniques, however, cannot simply be applied to unification-based gramm"
E12-1044,P09-1109,0,0.377853,"ation disambiguation with an existing parsing model, our approach resembles the approach by Hogan (2007). She detected noun phrase coordinations by finding symmetry in conjunct structure and the dependency between the lexical heads of the conjuncts. They are used to rerank the n-best outputs of the Bikel parser (2004), whereas two models interact with each other in our method. Shimbo and Hara (2007) proposed an alignment-based method for detecting and disambiguating non-nested coordination structures. They disambiguated coordination structures based on the edit distance between two conjuncts. Hara et al. (2009) extended the method, dealing with nested coordinations as well. We used their method as one of the two sub-models. 3 Background 3.1 Coordination structure analysis with alignment-based local features Coordination structure analysis with alignmentbased local features (Hara et al., 2009) is a hybrid approach to coordination disambiguation that combines a simple grammar to ensure consistent global structure of coordinations in a sentence, and features based on sequence alignment to capture local symmetry of conjuncts. In this section, we describe the method briefly. A sentence is denoted by x ="
E12-1044,P07-1086,0,0.435112,"s paper is as follows. First, we describe three basic methods required in the technique we propose: 1) coordination structure analysis with alignment-based local features, 2) HPSG parsing, and 3) dual decomposition. Finally, we show experimental results that demonstrate the effectiveness of our approach. We compare three methods: coordination structure analysis with alignment-based local features, HPSG parsing, and the dual-decomposition-based approach that combines both. 2 Related Work Many previous studies for coordination disambiguation have focused on a particular type of NP coordination (Hogan, 2007). Resnik (1999) disambiguated coordination structures by using semantic similarity of the conjuncts in a taxonomy. He dealt with two kinds of patterns, [n0 n1 and n2 n3 ] and [n1 and n2 n3 ], where ni are all nouns. He detected coordination structures based on similarity of form, meaning and conceptual association between n1 and n2 and between n1 and n3 . Nakov and Hearst (2005) used the Web as a training set and applied it to a task that is similar to Resnik’s. In terms of integrating coordination disambiguation with an existing parsing model, our approach resembles the approach by Hogan (200"
E12-1044,J93-2004,0,0.0429474,"Missing"
E12-1044,C04-1204,1,0.84166,"disambiguation remains a difficult sub-problem in parsing, even for state-of-the-art parsers. One approach to solve this problem is a grammatical approach. This approach, however, often fails in noun and adjective coordinations because there are many possible structures in these coordinations that are grammatically correct. For example, a noun sequence of the form “n0 n1 and n2 n3 ” has as many as five possible structures (Resnik, 1999). Therefore, a grammatical approach is not sufficient to disambiguate coordination structures. In fact, the Stanford parser (Klein and Manning, 2003) and Enju (Miyao and Tsujii, 2004) fail to disambiguate a sentence I am a freshman advertising and marketing major. Table 1 shows the output from them and the correct coordination structure. The coordination structure above is obvious to humans because there is a symmetry of conjuncts (-ing) in the sentence. Coordination structures often have such structural and semantic symmetry of conjuncts. One approach is to capture local symmetry of conjuncts. However, this approach fails in VP and sentential coordinations, which can easily be detected by a grammatical approach. This is because conjuncts in these coordinations do not nece"
E12-1044,J08-1002,1,0.887845,"Missing"
E12-1044,H05-1105,0,0.0244554,"lignment-based local features, HPSG parsing, and the dual-decomposition-based approach that combines both. 2 Related Work Many previous studies for coordination disambiguation have focused on a particular type of NP coordination (Hogan, 2007). Resnik (1999) disambiguated coordination structures by using semantic similarity of the conjuncts in a taxonomy. He dealt with two kinds of patterns, [n0 n1 and n2 n3 ] and [n1 and n2 n3 ], where ni are all nouns. He detected coordination structures based on similarity of form, meaning and conceptual association between n1 and n2 and between n1 and n3 . Nakov and Hearst (2005) used the Web as a training set and applied it to a task that is similar to Resnik’s. In terms of integrating coordination disambiguation with an existing parsing model, our approach resembles the approach by Hogan (2007). She detected noun phrase coordinations by finding symmetry in conjunct structure and the dependency between the lexical heads of the conjuncts. They are used to rerank the n-best outputs of the Bikel parser (2004), whereas two models interact with each other in our method. Shimbo and Hara (2007) proposed an alignment-based method for detecting and disambiguating non-nested c"
E12-1044,D10-1001,0,0.14598,"pty SUBJ feature. When the corpus is annoThe sign of the tated with least these offeatures, the lexical Figure 3: at Construction coordination in Enjuenpeatedly applytries required to explain the sentence are uniquely ns. Finally, the determined. In this study, we define partiallyinto efficiently solvable sub-problems. is output on the composed specified derivation trees as tree structures annoIttated is becoming popular in the NLP community with schema names and HPSG signs includand been shown to effectively inghas the specifications of work the above features.on seve Penn eral We NLP tasks (Rush et al., 2010). describe the process of grammar developWe consider an optimization problem ment in terms of the four phases: specification, externalization, extraction, and verification. rammar develarg max(f (x) + g(x)) (2) o be annotated x 3.1 Specification ons, and ii) adwhich is difficult to solve (e.g. NP-hard), while General grammatical constraints are defined in grammar rules arg maxx f (x) and arg maxx g(x) are effectively this phase, and in HPSG, they are represented history of rule In dual decomposition, solve Figthrough the design of the sign andwe schemata. tree annotated solvable. uremin 1 show"
E12-1044,D07-1064,0,0.382384,"m, meaning and conceptual association between n1 and n2 and between n1 and n3 . Nakov and Hearst (2005) used the Web as a training set and applied it to a task that is similar to Resnik’s. In terms of integrating coordination disambiguation with an existing parsing model, our approach resembles the approach by Hogan (2007). She detected noun phrase coordinations by finding symmetry in conjunct structure and the dependency between the lexical heads of the conjuncts. They are used to rerank the n-best outputs of the Bikel parser (2004), whereas two models interact with each other in our method. Shimbo and Hara (2007) proposed an alignment-based method for detecting and disambiguating non-nested coordination structures. They disambiguated coordination structures based on the edit distance between two conjuncts. Hara et al. (2009) extended the method, dealing with nested coordinations as well. We used their method as one of the two sub-models. 3 Background 3.1 Coordination structure analysis with alignment-based local features Coordination structure analysis with alignmentbased local features (Hara et al., 2009) is a hybrid approach to coordination disambiguation that combines a simple grammar to ensure con"
I11-1084,W06-1615,0,0.0623828,"me parsing system can be applied to a novel domain. However, there are some cases where we cannot achieve such high parsing accuracy as parsing 2 Related work Since domain adaptation is an extensive research area in parsing research (Nivre et al., 2007), many ideas have been proposed, including un- or 749 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 749–757, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP and imperatives. In the experiments, we also used QuestionBank for comparison. semi-supervised approaches (Roark and Bacchiani, 2003; Blitzer et al., 2006; Steedman et al., 2003; McClosky et al., 2006; Clegg and Shepherd, 2005; McClosky et al., 2010) and supervised approaches (Titov and Henderson, 2006; Hara et al., 2007). The main focus of these works is on adapting parsing models trained with a specific genre of text (in most cases the Penn Treebank WSJ) to other genres of text, such as biomedical research papers and broadcast news. The major problem tackled in such tasks is the handling of unknown words and domain-specific manners of expression. However, parsing imperatives and questions involves a significantly different problem; even when"
I11-1084,W07-2208,1,0.7578,"et al., 2006)3 , respectively. Although the publicly available implementation of each parser also has the option to restrict the output to a projective dependency tree, we used the non-projective versions because the dependency structures converted from the question sentences in the Brown Corpus included many non-projective dependencies. We used the pennconverter (Johansson and Nugues, 2007) 4 to convert a PTB-style treebank into dependency trees 5 . To evaluate the output from each of the parsers, we used the labeled attachment accuracy excluding punctuation. 3.2 HPSG parser The Enju parser (Ninomiya et al., 2007)6 is a deep parser based on the HPSG (Head Driven Phrase Structure Grammar) formalism. It produces an analysis of a sentence including the syntactic structure (i.e., parse tree) and the semantic structure represented as a set of predicateargument dependencies. We used the toolkit distributed with the Enju parser to train the parser with a PTB-style treebank. The toolkit initially converts a PTB-style treebank into an HPSG treebank and then trains the parser on this. The HPSG treebank converted from the test section was used as the gold-standard in the evaluation. As evaluation metrics for the"
I11-1084,J07-4004,0,0.025712,"accuracy of state-of-the-art parsers on questions, and proposed a supervised parser adaptation by manually creating a treebank of questions.1 The question sentences are annotated with phrase structure trees in the Penn Treebank scheme, although function tags and empty categories are omitted. QuestionBank was used for the supervised training of an LFG parser, resulting in a significant improvement in parsing accuracy. Rimell and Clark (2008) also worked on the problem of question parsing in the context of domain adaptation, and proposed a supervised method for the adaptation of the C&C parser (Clark and Curran, 2007). In this work, question sentences were collected from TREC 9-12 competitions and annotated with POS and CCG lexical categories. The authors reported a significant improvement in CCG parsing without phrase structure annotations. Our work further extends Judge et al. (2006) and Rimell and Clark (2008), while covering a wider range of sentence constructions. Although QuestionBank and the resource of Rimell and Clark (2008) claim to be corpora of questions, they are biased because the sentences come from QA queries. For example, such queries rarely include yes/no questions or tag questions. For o"
I11-1084,P81-1022,0,0.773475,"Missing"
I11-1084,W05-1102,0,0.0323997,"re some cases where we cannot achieve such high parsing accuracy as parsing 2 Related work Since domain adaptation is an extensive research area in parsing research (Nivre et al., 2007), many ideas have been proposed, including un- or 749 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 749–757, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP and imperatives. In the experiments, we also used QuestionBank for comparison. semi-supervised approaches (Roark and Bacchiani, 2003; Blitzer et al., 2006; Steedman et al., 2003; McClosky et al., 2006; Clegg and Shepherd, 2005; McClosky et al., 2010) and supervised approaches (Titov and Henderson, 2006; Hara et al., 2007). The main focus of these works is on adapting parsing models trained with a specific genre of text (in most cases the Penn Treebank WSJ) to other genres of text, such as biomedical research papers and broadcast news. The major problem tackled in such tasks is the handling of unknown words and domain-specific manners of expression. However, parsing imperatives and questions involves a significantly different problem; even when all words in a sentence are known, the sentence has a very different str"
I11-1084,W07-2202,1,0.899758,"adaptation is an extensive research area in parsing research (Nivre et al., 2007), many ideas have been proposed, including un- or 749 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 749–757, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP and imperatives. In the experiments, we also used QuestionBank for comparison. semi-supervised approaches (Roark and Bacchiani, 2003; Blitzer et al., 2006; Steedman et al., 2003; McClosky et al., 2006; Clegg and Shepherd, 2005; McClosky et al., 2010) and supervised approaches (Titov and Henderson, 2006; Hara et al., 2007). The main focus of these works is on adapting parsing models trained with a specific genre of text (in most cases the Penn Treebank WSJ) to other genres of text, such as biomedical research papers and broadcast news. The major problem tackled in such tasks is the handling of unknown words and domain-specific manners of expression. However, parsing imperatives and questions involves a significantly different problem; even when all words in a sentence are known, the sentence has a very different structure from declarative sentences. Compared to domain adaptation, structural types of sentences h"
I11-1084,D08-1050,0,0.0186762,"ptation, structural types of sentences have received little attention to date. A notable exception is the work on QuestionBank (Judge et al., 2006). This work highlighted the low accuracy of state-of-the-art parsers on questions, and proposed a supervised parser adaptation by manually creating a treebank of questions.1 The question sentences are annotated with phrase structure trees in the Penn Treebank scheme, although function tags and empty categories are omitted. QuestionBank was used for the supervised training of an LFG parser, resulting in a significant improvement in parsing accuracy. Rimell and Clark (2008) also worked on the problem of question parsing in the context of domain adaptation, and proposed a supervised method for the adaptation of the C&C parser (Clark and Curran, 2007). In this work, question sentences were collected from TREC 9-12 competitions and annotated with POS and CCG lexical categories. The authors reported a significant improvement in CCG parsing without phrase structure annotations. Our work further extends Judge et al. (2006) and Rimell and Clark (2008), while covering a wider range of sentence constructions. Although QuestionBank and the resource of Rimell and Clark (20"
I11-1084,N03-1027,0,0.0233071,"stems, and therefore the same parsing system can be applied to a novel domain. However, there are some cases where we cannot achieve such high parsing accuracy as parsing 2 Related work Since domain adaptation is an extensive research area in parsing research (Nivre et al., 2007), many ideas have been proposed, including un- or 749 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 749–757, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP and imperatives. In the experiments, we also used QuestionBank for comparison. semi-supervised approaches (Roark and Bacchiani, 2003; Blitzer et al., 2006; Steedman et al., 2003; McClosky et al., 2006; Clegg and Shepherd, 2005; McClosky et al., 2010) and supervised approaches (Titov and Henderson, 2006; Hara et al., 2007). The main focus of these works is on adapting parsing models trained with a specific genre of text (in most cases the Penn Treebank WSJ) to other genres of text, such as biomedical research papers and broadcast news. The major problem tackled in such tasks is the handling of unknown words and domain-specific manners of expression. However, parsing imperatives and questions involves a significantly differe"
I11-1084,W07-2416,0,0.0948282,"and Malt parsers The MST and Malt parsers are dependency parsers that produce non-projective dependency trees, using the spanning tree algorithm (McDonald et al., 2005a; McDonald et al., 2005b)2 and transitionbased algorithm (Nivre et al., 2006)3 , respectively. Although the publicly available implementation of each parser also has the option to restrict the output to a projective dependency tree, we used the non-projective versions because the dependency structures converted from the question sentences in the Brown Corpus included many non-projective dependencies. We used the pennconverter (Johansson and Nugues, 2007) 4 to convert a PTB-style treebank into dependency trees 5 . To evaluate the output from each of the parsers, we used the labeled attachment accuracy excluding punctuation. 3.2 HPSG parser The Enju parser (Ninomiya et al., 2007)6 is a deep parser based on the HPSG (Head Driven Phrase Structure Grammar) formalism. It produces an analysis of a sentence including the syntactic structure (i.e., parse tree) and the semantic structure represented as a set of predicateargument dependencies. We used the toolkit distributed with the Enju parser to train the parser with a PTB-style treebank. The toolkit"
I11-1084,P06-1063,0,0.244348,"Missing"
I11-1084,E03-1008,0,0.085386,"be applied to a novel domain. However, there are some cases where we cannot achieve such high parsing accuracy as parsing 2 Related work Since domain adaptation is an extensive research area in parsing research (Nivre et al., 2007), many ideas have been proposed, including un- or 749 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 749–757, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP and imperatives. In the experiments, we also used QuestionBank for comparison. semi-supervised approaches (Roark and Bacchiani, 2003; Blitzer et al., 2006; Steedman et al., 2003; McClosky et al., 2006; Clegg and Shepherd, 2005; McClosky et al., 2010) and supervised approaches (Titov and Henderson, 2006; Hara et al., 2007). The main focus of these works is on adapting parsing models trained with a specific genre of text (in most cases the Penn Treebank WSJ) to other genres of text, such as biomedical research papers and broadcast news. The major problem tackled in such tasks is the handling of unknown words and domain-specific manners of expression. However, parsing imperatives and questions involves a significantly different problem; even when all words in a sentence"
I11-1084,P06-1043,0,0.0275101,"omain. However, there are some cases where we cannot achieve such high parsing accuracy as parsing 2 Related work Since domain adaptation is an extensive research area in parsing research (Nivre et al., 2007), many ideas have been proposed, including un- or 749 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 749–757, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP and imperatives. In the experiments, we also used QuestionBank for comparison. semi-supervised approaches (Roark and Bacchiani, 2003; Blitzer et al., 2006; Steedman et al., 2003; McClosky et al., 2006; Clegg and Shepherd, 2005; McClosky et al., 2010) and supervised approaches (Titov and Henderson, 2006; Hara et al., 2007). The main focus of these works is on adapting parsing models trained with a specific genre of text (in most cases the Penn Treebank WSJ) to other genres of text, such as biomedical research papers and broadcast news. The major problem tackled in such tasks is the handling of unknown words and domain-specific manners of expression. However, parsing imperatives and questions involves a significantly different problem; even when all words in a sentence are known, the sentenc"
I11-1084,W06-2902,0,0.0245006,"2 Related work Since domain adaptation is an extensive research area in parsing research (Nivre et al., 2007), many ideas have been proposed, including un- or 749 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 749–757, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP and imperatives. In the experiments, we also used QuestionBank for comparison. semi-supervised approaches (Roark and Bacchiani, 2003; Blitzer et al., 2006; Steedman et al., 2003; McClosky et al., 2006; Clegg and Shepherd, 2005; McClosky et al., 2010) and supervised approaches (Titov and Henderson, 2006; Hara et al., 2007). The main focus of these works is on adapting parsing models trained with a specific genre of text (in most cases the Penn Treebank WSJ) to other genres of text, such as biomedical research papers and broadcast news. The major problem tackled in such tasks is the handling of unknown words and domain-specific manners of expression. However, parsing imperatives and questions involves a significantly different problem; even when all words in a sentence are known, the sentence has a very different structure from declarative sentences. Compared to domain adaptation, structural"
I11-1084,N10-1004,0,0.0265445,"not achieve such high parsing accuracy as parsing 2 Related work Since domain adaptation is an extensive research area in parsing research (Nivre et al., 2007), many ideas have been proposed, including un- or 749 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 749–757, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP and imperatives. In the experiments, we also used QuestionBank for comparison. semi-supervised approaches (Roark and Bacchiani, 2003; Blitzer et al., 2006; Steedman et al., 2003; McClosky et al., 2006; Clegg and Shepherd, 2005; McClosky et al., 2010) and supervised approaches (Titov and Henderson, 2006; Hara et al., 2007). The main focus of these works is on adapting parsing models trained with a specific genre of text (in most cases the Penn Treebank WSJ) to other genres of text, such as biomedical research papers and broadcast news. The major problem tackled in such tasks is the handling of unknown words and domain-specific manners of expression. However, parsing imperatives and questions involves a significantly different problem; even when all words in a sentence are known, the sentence has a very different structure from declarative"
I11-1084,P05-1012,0,0.0476,"come from QA queries. For example, such queries rarely include yes/no questions or tag questions. For our study, sentences were collected from the Brown Corpus, which includes a wider range of types of questions 3 Target Parsers and POS tagger We examined the performance of two dependency parsers and a deep parser on the target text sets. All parsers assumed that the input was already POS-tagged. We used the tagger in Tsuruoka et al. (2005). 3.1 MST and Malt parsers The MST and Malt parsers are dependency parsers that produce non-projective dependency trees, using the spanning tree algorithm (McDonald et al., 2005a; McDonald et al., 2005b)2 and transitionbased algorithm (Nivre et al., 2006)3 , respectively. Although the publicly available implementation of each parser also has the option to restrict the output to a projective dependency tree, we used the non-projective versions because the dependency structures converted from the question sentences in the Brown Corpus included many non-projective dependencies. We used the pennconverter (Johansson and Nugues, 2007) 4 to convert a PTB-style treebank into dependency trees 5 . To evaluate the output from each of the parsers, we used the labeled attachment"
I11-1084,H05-1066,0,0.0651665,"Missing"
I11-1084,P05-1011,1,0.816729,"iate. As a result, we extracted 750 imperative sentences and 1,241 question sentences from 24,243 sentences. Examples of extracted sentences are shown in Figure 1. Table 1 gives the statistics of the extracted sentences, which show that each genre contains top-level / embedded imperative and question sentences to some extent.7 As described below, we also used QuestionBank in the experiments. The advantage, however, of using the Brown treebank is that it includes annotations of function tags and empty categories, and therefore, we can apply the Penn Treebank-to-HPSG conversion program of Enju (Miyao and Tsujii, 2005), which relies on function tags and empty categories. Hence, we show experimental results for Enju only with the Brown data. It should also be noted that, a constituencyto-dependency converter, pennconverter (Johansson and Nugues, 2007), provides a more accurate conversion when function tags and empty categories are available (see footnote 4). Imperatives - Let &apos;s face it ! ! - Let this generation have theirs . - Believe me . - Make up your mind to pool your resources and get the most out of your remaining years of life . - Believe me ! ! - Find out what you like to do most and really give it"
I11-1084,nivre-etal-2006-maltparser,0,\N,Missing
I11-1084,D07-1096,0,\N,Missing
I11-1136,P04-1015,0,0.226468,".t ◦ s0 .t (b) s0 .w ◦ d s0 .t ◦ d s0 .w ◦ s0 .vl s1 .w ◦ s1 .vr s1 .w ◦ s1 .vl s0 .lc.w s0 .lc.t s1 .lc.w s1 .lc.t s1 .rc2 .w s1 .rc2 .t s0 .t ◦ s0 .lc.t ◦ s0 .lc2 .t s1 .t ◦ s1 .lc.t ◦ s1 .lc2 .t (c) j s2 .t s1 .w s1 .t s0 .w s0 .t (d) d s0 .vl s0 .lc.w s1 .rc.w s0 .lc2 .w s1 .rc2 .w s0 .lc2 .t s1 .rc2 .t To deal with conflicts between more than one of these actions, each action is associated with a score, and the score of a parser state is the total score of the actions that have been applied. To train the model, we adopt the averaged perceptron algorithm (Collins, 2002) with early update (Collins and Roark, 2004), following Huang and Sagae (2010). With the early update, whenever the gold action sequence falls off from the beam, the parameters are immediately updated with the rest of the sentence neglected. 2.2.2 Merging equivalent states Dynamic programming is enabled by merging equivalent states: if two states produce the same feature vector, they are merged into one state. Formally, a parser state (or configuration) ψ is described by h`, i, j, Si, where ` is the current step, [i . . . j] is the span of the top tree s0 in the stack S = (sd−1 , . . . , s0 ), where d is the depth of the stack. The equi"
I11-1136,W02-1001,0,0.181731,"plicable to any languages for which a projective shift-reduce parser works well. 2 Baseline Models First of all, we describe our baseline POS tagger and dependency parsers. These models will later be combined into pipelined models, which are then used as the baseline models in Section 4. 2.1 Baseline POS Tagger We build a baseline POS tagger, which uses the same POS-tagging features as those used in the state-of-the-art joint word segmentation and POS tagging model for Chinese (Zhang and Clark, 2008a). The list of features are shown in Table 1. We train the model with the averaged perceptron (Collins, 2002), and the decoding is performed using the Viterbi algorithm with beam search. Following Zhang and Clark (2008a), we use a tag dictionary and closed-set tags, which lead to improvement in both speed and accuracy. During training, the model stores all word–tag pairs into a tag dictionary, and for each word occurring more 2.2 Baseline Parsers For the baseline parsers for experiments, we build two dependency parsers: a reimplementation of the parser by Huang and Sagae (2010) (hereinafter Parser-HS), which is a shift-reduce dependency parser enhanced with dynamic programming (DP) using graph-struct"
I11-1136,D07-1098,0,0.0991258,"first-/secondwhere Φ order delayed features generated by action a be4 Experiment ing applied to ψ. When a S HIFT (t) action is performed, the model fills in the argument in the de4.1 Experimental Settings layed features with the newly-assigned tag t, as well as adding new delayed features it generates: We evaluate the performance of our joint parsers ~ 1 (ψ, SH (t)) + T (t, d~2 ), Φ ~ 2 (ψ, SH (t))i, and baseline models on the Chinese Penn Treehd~1 , d~2 i ← hΦ bank (CTB) 5 dataset. We use the standard split where T (t, d~2 ) is the resulting feature vector afof CTB-5 described in Duan et al. (2007) and the ter tag t is filled in to the first argument of the head-finding rules in Zhang and Clark (2008b). features in d~2 . Note that action SH (t) also adds We iteratively train each of the models and d~0 = T (t, d~1 ) to its (non-delayed) feature vector. choose the best model, in terms of the tagging acNote that the above formulation with the decuracy (for tagger) or word-level dependency aclayed features is equivalent to the model with full curacy (for parsers and joint parsers) on the devellook-ahead features if the exact decoding is peropment set, to use in the final evaluation. When fo"
I11-1136,P10-1110,0,0.220606,"ith underspecified POS tags of look-ahead words, we overcome this issue by introducing so-called delayed features. Our joint approach achieved substantial improvements over the pipeline and baseline systems in both POS tagging and dependency parsing task, achieving the new state-of-the-art performance on this joint task. 1    Introduction The tasks of part-of-speech (POS) tagging and dependency parsing have been widely investigated since the early stages of NLP research. Among mainstream approaches to dependency parsing, an incremental parsing framework is commonly used (e.g. Nivre (2008); Huang and Sagae (2010)), mainly because it achieves state-of-the-art accuracy while retaining linear-time computational complexity, and is also considered to reflect how humans process natural language sentences (Frazier and Rayner, 1982). However, although some of the Chinese POS tags require long-range syntactic information in order to be disambiguated, to the extent of our knowledge, none of the previous approaches have addressed the joint modeling of these two tasks in an incremental framework. Also, since POS tagging is a preliminary step for dependency parsing, the traditional pipeline approach may suffer fro"
I11-1136,P08-1102,0,0.0699744,"Missing"
I11-1136,C08-1049,0,0.0608786,"Missing"
I11-1136,P03-1054,0,0.00400021,"years, joint segmentation and tagging have been widely investigated (e.g. Zhang and Clark (2010); Kruengkrai et al. (2009); Zhang and Clark (2008a); Jiang et al. (2008a); Jiang et al. (2008b)). Particularly, our framework of using a single perceptron to solve the joint problem is motivated by Zhang and Clark (2008a). Also, our joint parsing framework is an extension of Huang and Sagae (2010)’s framework, which is described in detail in Section 2.2. In constituency parsing, the parsing naturally involves the POS tagging since the non-terminal symbols are commonly associated with POS tags (e.g. Klein and Manning (2003)). Rush et al. (2010) proposed to use dual composition to combine a constituency parser and a trigram POS tagger, showing the effectiveness of taking advantage of these two systems. In dependency parsing, Lee et al. (2011) recently proposed a discriminative graphical model that solves morphological disambiguation and dependency parsing jointly. However, their main focus was to capture interaction between morphology and syntax in morphologically-rich, highlyinflected languages (such as Latin and Ancient Greek), which are unlike Chinese. More recently, Li et al. (2011) proposed the first joint m"
I11-1136,P09-1058,0,0.14012,"Missing"
I11-1136,P11-1089,0,0.0529511,"g a single perceptron to solve the joint problem is motivated by Zhang and Clark (2008a). Also, our joint parsing framework is an extension of Huang and Sagae (2010)’s framework, which is described in detail in Section 2.2. In constituency parsing, the parsing naturally involves the POS tagging since the non-terminal symbols are commonly associated with POS tags (e.g. Klein and Manning (2003)). Rush et al. (2010) proposed to use dual composition to combine a constituency parser and a trigram POS tagger, showing the effectiveness of taking advantage of these two systems. In dependency parsing, Lee et al. (2011) recently proposed a discriminative graphical model that solves morphological disambiguation and dependency parsing jointly. However, their main focus was to capture interaction between morphology and syntax in morphologically-rich, highlyinflected languages (such as Latin and Ancient Greek), which are unlike Chinese. More recently, Li et al. (2011) proposed the first joint model for Chinese POS tagging and dependency parsing in a graph-based parsing framework, which is one of our baseline systems. On the other hand, our work is the first incremental approach to this joint task. 6 Conclusion I"
I11-1136,D11-1109,0,0.41298,"ith POS tags (e.g. Klein and Manning (2003)). Rush et al. (2010) proposed to use dual composition to combine a constituency parser and a trigram POS tagger, showing the effectiveness of taking advantage of these two systems. In dependency parsing, Lee et al. (2011) recently proposed a discriminative graphical model that solves morphological disambiguation and dependency parsing jointly. However, their main focus was to capture interaction between morphology and syntax in morphologically-rich, highlyinflected languages (such as Latin and Ancient Greek), which are unlike Chinese. More recently, Li et al. (2011) proposed the first joint model for Chinese POS tagging and dependency parsing in a graph-based parsing framework, which is one of our baseline systems. On the other hand, our work is the first incremental approach to this joint task. 6 Conclusion In this paper, we have presented the first joint approach that successfully solves POS tagging and dependency parsing on an incremental framework. The proposed joint models outperform the pipeline models in terms of both tagging and dependency parsing accuracies, and our best model achieved the new state-of-the-art performance on this joint task, whi"
I11-1136,J08-4003,0,0.136623,"difficulties with underspecified POS tags of look-ahead words, we overcome this issue by introducing so-called delayed features. Our joint approach achieved substantial improvements over the pipeline and baseline systems in both POS tagging and dependency parsing task, achieving the new state-of-the-art performance on this joint task. 1    Introduction The tasks of part-of-speech (POS) tagging and dependency parsing have been widely investigated since the early stages of NLP research. Among mainstream approaches to dependency parsing, an incremental parsing framework is commonly used (e.g. Nivre (2008); Huang and Sagae (2010)), mainly because it achieves state-of-the-art accuracy while retaining linear-time computational complexity, and is also considered to reflect how humans process natural language sentences (Frazier and Rayner, 1982). However, although some of the Chinese POS tags require long-range syntactic information in order to be disambiguated, to the extent of our knowledge, none of the previous approaches have addressed the joint modeling of these two tasks in an incremental framework. Also, since POS tagging is a preliminary step for dependency parsing, the traditional pipeline"
I11-1136,D10-1001,0,0.0463127,"nd tagging have been widely investigated (e.g. Zhang and Clark (2010); Kruengkrai et al. (2009); Zhang and Clark (2008a); Jiang et al. (2008a); Jiang et al. (2008b)). Particularly, our framework of using a single perceptron to solve the joint problem is motivated by Zhang and Clark (2008a). Also, our joint parsing framework is an extension of Huang and Sagae (2010)’s framework, which is described in detail in Section 2.2. In constituency parsing, the parsing naturally involves the POS tagging since the non-terminal symbols are commonly associated with POS tags (e.g. Klein and Manning (2003)). Rush et al. (2010) proposed to use dual composition to combine a constituency parser and a trigram POS tagger, showing the effectiveness of taking advantage of these two systems. In dependency parsing, Lee et al. (2011) recently proposed a discriminative graphical model that solves morphological disambiguation and dependency parsing jointly. However, their main focus was to capture interaction between morphology and syntax in morphologically-rich, highlyinflected languages (such as Latin and Ancient Greek), which are unlike Chinese. More recently, Li et al. (2011) proposed the first joint model for Chinese POS"
I11-1136,J95-2002,0,0.0248697,"ociated with dependency labels and head information of stack elements, are not included since our framework is based on unlabeled dependencies and the arc-standard strategy. The additional features for Parser-ZN− require the features in Table 2 (d) to be added into the set of kernel features. 2.2.4 Beam search with DP In the shift-reduce parsing with dynamic programming, we cannot simply apply beam search as in a non-DP shift-reduce parsing, because each state does not have a unique score any more. To decide the ordering of states within the beam, the concept of prefix score and inside score (Stolcke, 1995) is adopted. The prefix score ξ is the total score of the best action sequence from the initial state to the current state, while the inside score η 1218 (a) q0 .t q0 .w ◦ q0 .t s0 .t ◦ q0 .t ◦ q1 .t s0 .w ◦ q0 .t ◦ q1 .t (b) t ◦ s0 .w t ◦ s0 .w ◦ q0 .w t ◦ B(s0 .w) ◦ q0 .w t ◦ s0 .t ◦ s0 .rc.t t ◦ s0 .w ◦ s0 .t ◦ s0 .rc.t (c) j s2 .t q0 .w s1 .w s1 .t s0 .w s0 .t is the score of the tree on the top of the stack. With these scores and a set of predictor states Π(ψ) of state ψ, the full description of state ψ takes the form ψ : h`, i, j, S; ξ, η, Πi. The calculation of the prefix and inside sco"
I11-1136,P11-1139,0,0.048531,"Missing"
I11-1136,P08-1101,0,0.443622,"sion on the results and error analysis. Although we specifically focus on Chinese in this work, our joint model is applicable to any languages for which a projective shift-reduce parser works well. 2 Baseline Models First of all, we describe our baseline POS tagger and dependency parsers. These models will later be combined into pipelined models, which are then used as the baseline models in Section 4. 2.1 Baseline POS Tagger We build a baseline POS tagger, which uses the same POS-tagging features as those used in the state-of-the-art joint word segmentation and POS tagging model for Chinese (Zhang and Clark, 2008a). The list of features are shown in Table 1. We train the model with the averaged perceptron (Collins, 2002), and the decoding is performed using the Viterbi algorithm with beam search. Following Zhang and Clark (2008a), we use a tag dictionary and closed-set tags, which lead to improvement in both speed and accuracy. During training, the model stores all word–tag pairs into a tag dictionary, and for each word occurring more 2.2 Baseline Parsers For the baseline parsers for experiments, we build two dependency parsers: a reimplementation of the parser by Huang and Sagae (2010) (hereinafter P"
I11-1136,D08-1059,0,0.701122,"sion on the results and error analysis. Although we specifically focus on Chinese in this work, our joint model is applicable to any languages for which a projective shift-reduce parser works well. 2 Baseline Models First of all, we describe our baseline POS tagger and dependency parsers. These models will later be combined into pipelined models, which are then used as the baseline models in Section 4. 2.1 Baseline POS Tagger We build a baseline POS tagger, which uses the same POS-tagging features as those used in the state-of-the-art joint word segmentation and POS tagging model for Chinese (Zhang and Clark, 2008a). The list of features are shown in Table 1. We train the model with the averaged perceptron (Collins, 2002), and the decoding is performed using the Viterbi algorithm with beam search. Following Zhang and Clark (2008a), we use a tag dictionary and closed-set tags, which lead to improvement in both speed and accuracy. During training, the model stores all word–tag pairs into a tag dictionary, and for each word occurring more 2.2 Baseline Parsers For the baseline parsers for experiments, we build two dependency parsers: a reimplementation of the parser by Huang and Sagae (2010) (hereinafter P"
I11-1136,D10-1082,0,0.130141,"Missing"
I11-1136,P11-2033,0,0.280377,"se a tag dictionary and closed-set tags, which lead to improvement in both speed and accuracy. During training, the model stores all word–tag pairs into a tag dictionary, and for each word occurring more 2.2 Baseline Parsers For the baseline parsers for experiments, we build two dependency parsers: a reimplementation of the parser by Huang and Sagae (2010) (hereinafter Parser-HS), which is a shift-reduce dependency parser enhanced with dynamic programming (DP) using graph-structured stack (GSS; Tomita (1991)), and our extension of Parser-HS by incorporating a richer set of features taken from Zhang and Nivre (2011) (hereinafter Parser-ZN), which is originally a non-DP arc-eager dependency parser and achieves the current state-of-theart performance for Chinese dependency parsing. In this section, we briefly describe these models since the features and DP formalism serve as a basis for the joint models described in Section 3. 2.2.1 Shift-reduce parsing Shift-reduce dependency parsing algorithms incrementally process an input sentence from left to right. In the framework known as “arc-standard” (Nivre, 2008), the parser performs one of the following three actions at each step: • S HIFT (SH): move the first"
I11-1136,P08-1000,0,\N,Missing
I13-1009,P12-1081,0,0.0291301,"Missing"
I13-1009,W06-1673,0,0.0387656,"Missing"
I13-1009,P08-1068,0,0.0952147,"Missing"
I17-1097,P89-1010,0,0.802831,"ts to detect the changed word in an incorrect statement (Fig. 2). The solver hides each NE w in a statement S in order and makes a VQA query S−w , which is the set of words in S excluding w. If the statement is correct, the hidden word is expected to be found in the search results of the query S−w at high probability. For a hidden NE w, we first calculate the ratio vqa(w) of the probabilities of finding w in the search results D(S−w ) of the query S−w and in a randomly chosen document in the collection Dm : 4.2.1 Pointwise Mutual Information (PMI) Feature The first statistical feature is PMI (Church and Hanks, 1989), which is defined for a pair of words as, pmi(w1 , w2 ) ≡ log hidden NE: w = “Avars” Test statement: p(w1 , w2 |Ds ) , p(w1 |Ds )p(w2 |Ds ) where p(wi |Ds ) denotes the probability of observing the word wi in a sentence that is randomly chosen from Ds and p(w1 , w2 |Ds ) denotes the probability of observing both w1 and w2 in a randomly chosen sentence. A low PMI score indicates the independence of the two words. The solver expects that a low PMI score indicates that two NEs are not related to each other and suggests that the statement is incorrect. The solver calculates PMI for the pairs of a"
I17-1097,P02-1006,0,0.335717,"Missing"
I17-1097,C16-1278,0,0.0169001,"lected to support these hypotheses. • According to the observed evidences, five features that range over text search, statistics, and logical entailment were designed. They were combined as the features of a classifier and yielded state-of-the-art results on the task. 2 Related Work Fact-checking can be framed as a questionanswering (QA) task in a broad sense. However, it has not been studied as intensively as other In a series of recent papers, elementary science 968 Knowledge resource Textbook Wikipedia Textbook + Wikipedia questions are used as a benchmark of AI systems (Khot et al., 2015; Jansen et al., 2016; Clark et al., 2016; Khashabi et al., 2016). The questions, all in the form of multiple-choice questions, were collected from 4th grade science tests. In the majority of the questions, the choices are nouns rather than sentences as in the following example taken from (Khashabi et al., 2016): Table 1: Ratio of correct statements that can be evidenced by a single paragraph in the knowledge resource NE change Time change NE or Time change Q. In New York State, the longest period of daylight occurs during which month? (A) December (B) June (C) March (D) September Count (ratio) 163 / 275 (0.59) 47"
I17-1097,C12-1084,0,0.0398114,"Missing"
I17-1097,W14-2508,0,0.223818,"Missing"
I17-1097,J90-1003,0,\N,Missing
I17-1097,W07-1401,0,\N,Missing
I17-1097,D15-1080,0,\N,Missing
I17-2063,P17-1195,1,0.826784,"tted” argument to “a solution” in this sentence to derive a correct semantic representation, e.g., ∃x(x2 = 1 ∧ x &gt; 0). No previous work, including Iida et al’s, has dealt with such “syntactically determined” zero arguments as far as we are aware of. It is partly because most previous work has focused on the resolution of zero arguments of a predicate and there is no Japanese predicate that syntactically determines the antecedent of its zero argument. There is a growing interest in the natural language processing of mathematical problem text (e.g., Mitra and Baral, 2016; Upadhyay et al., 2016; Matsuzaki et al., 2017) because it serves as a prototypical example of a natural language interface for intelligent systems. In this paper, we describe a coreference resolution system for math problem text. In order to solve a math problem, all the anaphoric expressions including those referring to a proposition, as well as those referring to an entity, must be correctly analyzed. Although much research has been done on coreference resolution for texts such as newspaper, few researches have been done on math problems text. Previous studies mainly focused on the relation between pronouns or definite noun phrases and"
I17-2063,P16-1202,0,0.0141186,"ke sense. That is, we must not supply the “omitted” argument to “a solution” in this sentence to derive a correct semantic representation, e.g., ∃x(x2 = 1 ∧ x &gt; 0). No previous work, including Iida et al’s, has dealt with such “syntactically determined” zero arguments as far as we are aware of. It is partly because most previous work has focused on the resolution of zero arguments of a predicate and there is no Japanese predicate that syntactically determines the antecedent of its zero argument. There is a growing interest in the natural language processing of mathematical problem text (e.g., Mitra and Baral, 2016; Upadhyay et al., 2016; Matsuzaki et al., 2017) because it serves as a prototypical example of a natural language interface for intelligent systems. In this paper, we describe a coreference resolution system for math problem text. In order to solve a math problem, all the anaphoric expressions including those referring to a proposition, as well as those referring to an entity, must be correctly analyzed. Although much research has been done on coreference resolution for texts such as newspaper, few researches have been done on math problems text. Previous studies mainly focused on the relatio"
I17-2063,D09-1151,0,0.0823763,"Missing"
I17-2063,D16-1029,0,0.0274589,"ust not supply the “omitted” argument to “a solution” in this sentence to derive a correct semantic representation, e.g., ∃x(x2 = 1 ∧ x &gt; 0). No previous work, including Iida et al’s, has dealt with such “syntactically determined” zero arguments as far as we are aware of. It is partly because most previous work has focused on the resolution of zero arguments of a predicate and there is no Japanese predicate that syntactically determines the antecedent of its zero argument. There is a growing interest in the natural language processing of mathematical problem text (e.g., Mitra and Baral, 2016; Upadhyay et al., 2016; Matsuzaki et al., 2017) because it serves as a prototypical example of a natural language interface for intelligent systems. In this paper, we describe a coreference resolution system for math problem text. In order to solve a math problem, all the anaphoric expressions including those referring to a proposition, as well as those referring to an entity, must be correctly analyzed. Although much research has been done on coreference resolution for texts such as newspaper, few researches have been done on math problems text. Previous studies mainly focused on the relation between pronouns or d"
I17-2063,J14-2004,0,\N,Missing
I17-2063,P10-1160,0,\N,Missing
I17-2063,D16-1132,0,\N,Missing
L16-1440,P15-2024,1,0.904798,", even fragmentary information will be helpful. However, if it is used as an automatic interpreter on smartphones, it is a totally different type of matter. It is expected to convey correct information between two people who do not understand each other’s language, sometimes in critical situations. In other words the measurement of the quality of MT systems should include not only the intrinsic metrics such as accuracy and fluency but also how often a user can complete his/her purpose in using it. In our previous paper, we proposed a light weight, humanin-the-loop extrinsic evaluation scheme (Matsuzaki et al., 2015), where MT systems are evaluated by human subjects’ scores on the second language ability tests translated to the subjects’ native language by MT. Specifically, we used dialogue completion questions (Figure 1) as the test material. Dialogues often involve linguistic phenomena that are not frequent in written text, such as interrogatory sentences, imperative sentences, and ellipsis. It turned out that our evaluation captured a different dimension of translation quality than that captured by manual and automatic intrinsic evaluation. In this paper, we report on another experiment involving 795 h"
L16-1440,P02-1040,0,0.114219,"alogues often involve linguistic phenomena that are not frequent in written text, such as interrogatory sentences, imperative sentences, and ellipsis. It turned out that our evaluation captured a different dimension of translation quality than that captured by manual and automatic intrinsic evaluation. In this paper, we report on another experiment involving 795 human participants, and scrutinize what kinds of errors hinder the users’ comprehension of the dialogues more often than others. Although MT-mediated conversation is already in the scope of development, automatic metrics such as BLEU (Papineni et al., 2002) and NIST (Doddington, 2002) do not tell us which errors are more harmful than others. The translation errors in the test materials were manually classified according to an error taxonomy. Then, the subjects’ responses on the translated questions were analyzed on the basis of the type and frequency of the translation errors. Through the analysis, we identified several types of errors that deteriorated most the subjects’ performance, their confidence on the answers, and the overall evaluation of the translation quality. INSTRUCTION Choose the most suitable utterance for the blank in the followi"
L16-1440,vilar-etal-2006-error,0,0.08079,"Missing"
N09-1007,W06-1655,0,0.354127,"entation Bakeoff (the second SIGHAN CWS bakeoff) (Emerson, 2005), two of the highest scoring systems in the closed track competition were based on a CRF model (Tseng et al., 2005; Asahara et al., 2005). While the CRF model is quite effective compared with other models designed for CWS, it may be limited by its restrictive independence assumptions on non-adjacent labels. Although the window can in principle be widened by increasing the Markov order, this may not be a practical solution, because the complexity of training and decoding a linearchain CRF grows exponentially with the Markov order (Andrew, 2006). To address this difﬁculty, a choice is to relax the Markov assumption by using the semi-Markov conditional random ﬁeld model (semi-CRF) (Sarawagi and Cohen, 2004). Despite the theoretical advantage of semi-CRFs over CRFs, however, some previous studies (Andrew, 2006; Liang, 2005) exploring the use of a semi-CRF for Chinese word segmentation did not ﬁnd signiﬁcant gains over the CRF ones. As discussed in Andrew (2006), the reason may be that despite the greater representational power of the semi-CRF, there are some valuable features that could be more naturally expressed in a character-based"
N09-1007,I05-3018,0,0.0345224,"s beling task (Xue, 2003). Labels are assigned to each character in the sentence, indicating whether the character xi is the start (Labeli = B), middle or end of a multi-character word (Labeli = C). A popular discriminative model that have been used for this task is the conditional random ﬁelds (CRFs) (Lafferty et al., 2001), starting with the model of Peng et al. (2004). In the Second International Chinese Word Segmentation Bakeoff (the second SIGHAN CWS bakeoff) (Emerson, 2005), two of the highest scoring systems in the closed track competition were based on a CRF model (Tseng et al., 2005; Asahara et al., 2005). While the CRF model is quite effective compared with other models designed for CWS, it may be limited by its restrictive independence assumptions on non-adjacent labels. Although the window can in principle be widened by increasing the Markov order, this may not be a practical solution, because the complexity of training and decoding a linearchain CRF grows exponentially with the Markov order (Andrew, 2006). To address this difﬁculty, a choice is to relax the Markov assumption by using the semi-Markov conditional random ﬁeld model (semi-CRF) (Sarawagi and Cohen, 2004). Despite the theoretica"
N09-1007,I05-3019,0,0.342649,"Missing"
N09-1007,I05-3017,0,0.737646,"the North American Chapter of the ACL, pages 56–64, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics beling task (Xue, 2003). Labels are assigned to each character in the sentence, indicating whether the character xi is the start (Labeli = B), middle or end of a multi-character word (Labeli = C). A popular discriminative model that have been used for this task is the conditional random ﬁelds (CRFs) (Lafferty et al., 2001), starting with the model of Peng et al. (2004). In the Second International Chinese Word Segmentation Bakeoff (the second SIGHAN CWS bakeoff) (Emerson, 2005), two of the highest scoring systems in the closed track competition were based on a CRF model (Tseng et al., 2005; Asahara et al., 2005). While the CRF model is quite effective compared with other models designed for CWS, it may be limited by its restrictive independence assumptions on non-adjacent labels. Although the window can in principle be widened by increasing the Markov order, this may not be a practical solution, because the complexity of training and decoding a linearchain CRF grows exponentially with the Markov order (Andrew, 2006). To address this difﬁculty, a choice is to relax t"
N09-1007,P07-1104,0,0.0508784,"nt Variable Segmenter 2.1 Discriminative Probabilistic Latent Variable Model Given data with latent structures, the task is to learn a mapping between a sequence of observations x = x1 , x2 , . . . , xm and a sequence of labels y = y1 , y2 , . . . , ym . Each yj is a class label for the j’th character of an input sequence, and is a member of a set Y of possible class labels. For each sequence, the model also assumes a sequence of latent variables h = h1 , h2 , . . . , hm , which is unobservable in training examples. The DPLVM is deﬁned as follows (Morency et al., 2 The system was also used in Gao et al. (2007), with an improved performance in CWS. 3 In practice, one may add a few extra labels based on linguistic intuitions (Xue, 2003). 2007): P (y|x, Θ) =  P (y|h, x, Θ)P (h|x, Θ), (1) h where Θ are the parameters of the model. DPLVMs can be seen as a natural extension of CRF models, and CRF models can be seen as a special case of DPLVMs that have only one latent variable for each label. To make the training and inference efﬁcient, the model is restricted to have disjoint sets of latent variables associated with each class label. Each hj is a member in a set Hyj of possible latent variables for the"
N09-1007,C04-1081,0,0.541571,"Missing"
N09-1007,E09-1088,1,0.796261,"onal loglikelihood of the training data. The second term is a regularizer that is used for reducing overﬁtting in parameter estimation. For decoding in the test stage, given a test sequence x, we want to ﬁnd the most probable label sequence, y∗ : y∗ = argmaxy P (y|x, Θ∗ ). (5) For latent conditional models like DPLVMs, the best label path y∗ cannot directly be produced by the 4 It means that Eq. 2 is from Eq. 1 with additional deﬁnition. 58 Viterbi algorithm because of the incorporation of hidden states. In this paper, we use a technique based on A∗ search and dynamic programming described in Sun and Tsujii (2009), for producing the most probable label sequence y∗ on DPLVM. In detail, an A∗ search algorithm5 (Hart et al., 1968) with a Viterbi heuristic function is adopted to produce top-n latent paths, h1 , h2 , . . . hn . In addition, a forward-backward-style algorithm is used to compute the exact probabilities of their corresponding label paths, y1 , y2 , . . . yn . The model then tries to determine the optimal label path based on the top-n statistics, without enumerating the remaining low-probability paths, which could be exponentially enormous. The optimal label path y∗ is ready when the following"
N09-1007,I05-3027,0,0.634414,"utational Linguistics beling task (Xue, 2003). Labels are assigned to each character in the sentence, indicating whether the character xi is the start (Labeli = B), middle or end of a multi-character word (Labeli = C). A popular discriminative model that have been used for this task is the conditional random ﬁelds (CRFs) (Lafferty et al., 2001), starting with the model of Peng et al. (2004). In the Second International Chinese Word Segmentation Bakeoff (the second SIGHAN CWS bakeoff) (Emerson, 2005), two of the highest scoring systems in the closed track competition were based on a CRF model (Tseng et al., 2005; Asahara et al., 2005). While the CRF model is quite effective compared with other models designed for CWS, it may be limited by its restrictive independence assumptions on non-adjacent labels. Although the window can in principle be widened by increasing the Markov order, this may not be a practical solution, because the complexity of training and decoding a linearchain CRF grows exponentially with the Markov order (Andrew, 2006). To address this difﬁculty, a choice is to relax the Markov assumption by using the semi-Markov conditional random ﬁeld model (semi-CRF) (Sarawagi and Cohen, 2004)."
N09-1007,W06-0121,0,0.114226,"Missing"
N09-1007,O03-4002,0,0.816245,"purposes, e.g., full-text indexing. However, as is illustrated, recognizing long words (without sacriﬁcing the performance on short words) is challenging. Conventional approaches to Chinese word segmentation treat the problem as a character-based la1 Following previous work, in this paper, words can also refer to multi-word expressions, including proper names, long named entities, idioms, etc. Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 56–64, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics beling task (Xue, 2003). Labels are assigned to each character in the sentence, indicating whether the character xi is the start (Labeli = B), middle or end of a multi-character word (Labeli = C). A popular discriminative model that have been used for this task is the conditional random ﬁelds (CRFs) (Lafferty et al., 2001), starting with the model of Peng et al. (2004). In the Second International Chinese Word Segmentation Bakeoff (the second SIGHAN CWS bakeoff) (Emerson, 2005), two of the highest scoring systems in the closed track competition were based on a CRF model (Tseng et al., 2005; Asahara et al., 2005). Wh"
N09-1007,P07-1106,0,0.496064,"h row represents a CWS model. For each group, the rows marked by ∗ represent our models with hybrid word/character information. Best05 represents the best system of the Second International Chinese Word Segmentation Bakeoff on the corresponding data; A06 represents the semi-CRF model in Andrew (2006)10 , which was also used in Gao et al. (2007) (denoted as G07) with an improved performance; Z06-a and Z06-b represents the pure subword CRF model and the conﬁdence-based combination of CRF and rule-based models, respectively (Zhang et al., 2006); ZC07 represents the word-based perceptron model in Zhang and Clark (2007); T05 represents the CRF model in Tseng et al. (2005); C05 represents the system in Chen et al. 10 It is a hybrid Markov/semi-Markov CRF model which outperforms conventional semi-CRF models (Andrew, 2006). However, in general, as discussed in Andrew (2006), it is essentially still a semi-CRF model. 61 (2005). The best F-score and recall of OOV words of each group is shown in bold. As is shown in the table, we achieved the best F-score in two out of the three corpora. We also achieved the best recall rate of OOV words on those two corpora. Both of the MSR and PKU Corpus use simpliﬁed Chinese, w"
N09-1007,N06-2049,0,0.152838,"ts are grouped into three sub-tables according to different corpora. Each row represents a CWS model. For each group, the rows marked by ∗ represent our models with hybrid word/character information. Best05 represents the best system of the Second International Chinese Word Segmentation Bakeoff on the corresponding data; A06 represents the semi-CRF model in Andrew (2006)10 , which was also used in Gao et al. (2007) (denoted as G07) with an improved performance; Z06-a and Z06-b represents the pure subword CRF model and the conﬁdence-based combination of CRF and rule-based models, respectively (Zhang et al., 2006); ZC07 represents the word-based perceptron model in Zhang and Clark (2007); T05 represents the CRF model in Tseng et al. (2005); C05 represents the system in Chen et al. 10 It is a hybrid Markov/semi-Markov CRF model which outperforms conventional semi-CRF models (Andrew, 2006). However, in general, as discussed in Andrew (2006), it is essentially still a semi-CRF model. 61 (2005). The best F-score and recall of OOV words of each group is shown in bold. As is shown in the table, we achieved the best F-score in two out of the three corpora. We also achieved the best recall rate of OOV words on"
N10-1090,J99-2004,0,0.799406,"Missing"
N10-1090,W03-1006,0,0.0618424,"Missing"
N10-1090,W02-2203,0,0.237479,"Missing"
N10-1090,P07-1037,0,0.0586619,"Missing"
N10-1090,P05-1012,0,0.0520652,"do. However, current widely used sequence labeling models have the limited ability to catch these longdistance syntactic relations. In supertagging stage, tree structures are still not constructed. Dependency formalism is an alternative way to describe these two syntactic properties. Based on this observation, we think dependency information could assist supertag prediction. To model the dependency, we follow mainstream dependency parsing formalism. Two representative methods for dependency parsing are transitionbased model like MaltParser (Nivre, 2003) and graph-based model like MSTParser1 (McDonald et al., 2005). Previous research (Nivre and McDonald, 2008) showed that MSTParser is more accurate than MaltParser for long dependencies. Since our motivation is to capture long-distance dependency as a complement for local supertagging models, we use the projective MSTParser formalism to model dependencies. MOD-IN MOD-OUT Table 1: Non-local feature templates used for supertagging. Here, p, w and s represent POS, word and schema respectively. Direction (Left/Right) from MODIN/MODOUT word to the current word is also considered in the feature templates. 3.2 Figure 1: Model structure of incorporating dependen"
N10-1090,W06-1619,1,0.927482,"Missing"
N10-1090,P08-1108,0,0.0151596,"labeling models have the limited ability to catch these longdistance syntactic relations. In supertagging stage, tree structures are still not constructed. Dependency formalism is an alternative way to describe these two syntactic properties. Based on this observation, we think dependency information could assist supertag prediction. To model the dependency, we follow mainstream dependency parsing formalism. Two representative methods for dependency parsing are transitionbased model like MaltParser (Nivre, 2003) and graph-based model like MSTParser1 (McDonald et al., 2005). Previous research (Nivre and McDonald, 2008) showed that MSTParser is more accurate than MaltParser for long dependencies. Since our motivation is to capture long-distance dependency as a complement for local supertagging models, we use the projective MSTParser formalism to model dependencies. MOD-IN MOD-OUT Table 1: Non-local feature templates used for supertagging. Here, p, w and s represent POS, word and schema respectively. Direction (Left/Right) from MODIN/MODOUT word to the current word is also considered in the feature templates. 3.2 Figure 1: Model structure of incorporating dependency information into the supertagging stage. Do"
N10-1090,W03-3017,0,0.0457851,"he word well, supertagging would be an easier job to do. However, current widely used sequence labeling models have the limited ability to catch these longdistance syntactic relations. In supertagging stage, tree structures are still not constructed. Dependency formalism is an alternative way to describe these two syntactic properties. Based on this observation, we think dependency information could assist supertag prediction. To model the dependency, we follow mainstream dependency parsing formalism. Two representative methods for dependency parsing are transitionbased model like MaltParser (Nivre, 2003) and graph-based model like MSTParser1 (McDonald et al., 2005). Previous research (Nivre and McDonald, 2008) showed that MSTParser is more accurate than MaltParser for long dependencies. Since our motivation is to capture long-distance dependency as a complement for local supertagging models, we use the projective MSTParser formalism to model dependencies. MOD-IN MOD-OUT Table 1: Non-local feature templates used for supertagging. Here, p, w and s represent POS, word and schema respectively. Direction (Left/Right) from MODIN/MODOUT word to the current word is also considered in the feature temp"
N10-1090,P07-1079,1,0.916812,"Missing"
N10-1090,P03-1064,0,0.0637293,"Missing"
N10-1090,W09-3832,1,0.802062,"es encode possible syntactic behavior of a word. Although the number of supertags is far larger than the 45 POS tags defined in Penn Treebank, sequence labeling techniques are still effective for supertagging. Previous research (Clark, 2002) showed that a POS sequence is very informative for supertagging, and some extent of local syntactic information can be captured by the context of surrounding words and POS tags. However, since the context window length is limited for the computational cost reasons, there are still long-range dependencies which are not easily captured in sequential models (Zhang et al., 2009). In practice, the multi-tagging technique proposed by Clark (2002) assigned more than one supertag to each word and let the ambiguous supertags be selected by the parser. As for other NLP applications which use supertags, resolving more supertag ambiguities in supertagging stage is preferred. With this consideration, we focus on supertagging and aim to make it as accurate as possible. In this paper, we incorporated long-distance information into supertagging. First, we used dependency parser formalism to model long-distance relationships between the input words, which is hard to model in sequ"
N10-1090,W07-0702,0,\N,Missing
N10-1090,P08-1000,0,\N,Missing
P05-1010,A00-2018,0,\N,Missing
P05-1010,J98-4004,0,\N,Missing
P05-1010,W96-0214,0,\N,Missing
P05-1010,C02-1126,0,\N,Missing
P05-1010,J03-4003,0,\N,Missing
P05-1010,P03-1054,0,\N,Missing
P05-1010,N03-1014,0,\N,Missing
P05-1010,P04-1014,0,\N,Missing
P05-1010,W03-3021,0,\N,Missing
P05-1010,W04-3327,0,\N,Missing
P05-1010,P96-1024,0,\N,Missing
P08-1006,P06-2006,0,0.0284334,"on, our system cannot be compared directly to the results reported by Erkan et al. (2007) and Katrenko and Adriaans (2006), while Sætre et al. (2007) presented better results than theirs in the same evaluation criterion. 5 Related Work Though the evaluation of syntactic parsers has been a major concern in the parsing community, and a couple of works have recently presented the comparison of parsers based on different frameworks, their methods were based on the comparison of the parsing accuracy in terms of a certain intermediate parse representation (Ringger et al., 2004; Kaplan et al., 2004; Briscoe and Carroll, 2006; Clark and Curran, 2007; Miyao et al., 2007; Clegg and Shepherd, 2007; Pyysalo et al., 2007b; Pyysalo et al., 2007a; Sagae et al., 2008). Such evaluation requires gold standard data in an intermediate representation. However, it has been argued that the conversion of parsing results into an intermediate representation is difficult and far from perfect. The relationship between parsing accuracy and task accuracy has been obscure for many years. Quirk and Corston-Oliver (2006) investigated the impact of parsing accuracy on statistical MT. However, this work was only concerned with a single depe"
P08-1006,P04-1056,0,0.02889,"gher dependency accuracy when trained only with GENIA. We therefore only input GENIA as the training data for the retraining of dependency parsers. For the other parsers, we input the concatenation of WSJ and GENIA for the retraining, while the reranker of RERANK was not retrained due to its cost. Since the parsers other than NO-RERANK and RERANK require an external POS tagger, a WSJ-trained POS tagger is used with WSJtrained parsers, and geniatagger (Tsuruoka et al., 2005) is used with GENIA-retrained parsers. 4 Experiments 4.1 Experiment settings In the following experiments, we used AImed (Bunescu and Mooney, 2004), which is a popular corpus for the evaluation of PPI extraction systems. The corpus consists of 225 biomedical paper abstracts (1970 sentences), which are sentence-split, tokenized, and annotated with proteins and PPIs. We use gold protein annotations given in the corpus. Multi-word protein names are concatenated and treated as single words. The accuracy is measured by abstract-wise 10-fold cross validation and the one-answer-per-occurrence criterion (Giuliano et al., 2006). A threshold for SVMs is moved to adjust the balance of precision and recall, and the maximum f-scores are reported for"
P08-1006,P05-1022,0,0.0663263,"parsing) using five different parse representations. We run a PPI system with several combinations of parser and parse representation, and examine their impact on PPI identification accuracy. Our experiments show that the levels of accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data. 1 Introduction Parsing technologies have improved considerably in the past few years, and high-performance syntactic parsers are no longer limited to PCFG-based frameworks (Charniak, 2000; Klein and Manning, 2003; Charniak and Johnson, 2005; Petrov and Klein, 2007), but also include dependency parsers (McDonald and Pereira, 2006; Nivre and Nilsson, 2005; Sagae and Tsujii, 2007) and deep parsers (Kaplan et al., 2004; Clark and Curran, 2004; Miyao and Tsujii, 2008). However, efforts to perform extensive comparisons of syntactic parsers based on different frameworks have been limited. The most popular method for parser comparison involves the direct measurement of the parser output accuracy in terms of metrics such as bracketing precision and recall, or dependency accuracy. This assumes the existence of a gold-standard test corpus,"
P08-1006,P04-1014,0,0.498927,"s show that the levels of accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data. 1 Introduction Parsing technologies have improved considerably in the past few years, and high-performance syntactic parsers are no longer limited to PCFG-based frameworks (Charniak, 2000; Klein and Manning, 2003; Charniak and Johnson, 2005; Petrov and Klein, 2007), but also include dependency parsers (McDonald and Pereira, 2006; Nivre and Nilsson, 2005; Sagae and Tsujii, 2007) and deep parsers (Kaplan et al., 2004; Clark and Curran, 2004; Miyao and Tsujii, 2008). However, efforts to perform extensive comparisons of syntactic parsers based on different frameworks have been limited. The most popular method for parser comparison involves the direct measurement of the parser output accuracy in terms of metrics such as bracketing precision and recall, or dependency accuracy. This assumes the existence of a gold-standard test corpus, such as the Penn Treebank (Marcus et al., 1994). It is difficult to apply this method to compare parsers based on different frameworks, because parse representations are often framework-specific and di"
P08-1006,P07-1032,0,0.0427625,"mpared directly to the results reported by Erkan et al. (2007) and Katrenko and Adriaans (2006), while Sætre et al. (2007) presented better results than theirs in the same evaluation criterion. 5 Related Work Though the evaluation of syntactic parsers has been a major concern in the parsing community, and a couple of works have recently presented the comparison of parsers based on different frameworks, their methods were based on the comparison of the parsing accuracy in terms of a certain intermediate parse representation (Ringger et al., 2004; Kaplan et al., 2004; Briscoe and Carroll, 2006; Clark and Curran, 2007; Miyao et al., 2007; Clegg and Shepherd, 2007; Pyysalo et al., 2007b; Pyysalo et al., 2007a; Sagae et al., 2008). Such evaluation requires gold standard data in an intermediate representation. However, it has been argued that the conversion of parsing results into an intermediate representation is difficult and far from perfect. The relationship between parsing accuracy and task accuracy has been obscure for many years. Quirk and Corston-Oliver (2006) investigated the impact of parsing accuracy on statistical MT. However, this work was only concerned with a single dependency parser, and did n"
P08-1006,P02-1034,0,0.0398489,"ng classifiers (Katrenko and Adriaans, 2006; Erkan et al., 2007; Sætre et al., 2007). For the protein pair IL-8 and CXCR1 in Figure 4, a dependency parser outputs a dependency tree shown in Figure 1. From this dependency tree, we can extract a dependency path shown in Figure 5, which appears to be a strong clue in knowing that these proteins are mentioned as interacting. (dep_path (SBJ (ENTITY1 recognizes)) (rOBJ (recognizes ENTITY2))) Figure 6: Tree representation of a dependency path We follow the PPI extraction method of Sætre et al. (2007), which is based on SVMs with SubSet Tree Kernels (Collins and Duffy, 2002; Moschitti, 2006), while using different parsers and parse representations. Two types of features are incorporated in the classifier. The first is bag-of-words features, which are regarded as a strong baseline for IE systems. Lemmas of words before, between and after the pair of target proteins are included, and the linear kernel is used for these features. These features are commonly included in all of the models. Filtering by a stop-word list is not applied because this setting made the scores higher than Sætre et al. (2007)’s setting. The other type of feature is syntactic features. For de"
P08-1006,P97-1003,0,0.0850946,"ank. Penn Treebank-style phrase structure trees without function tags and empty nodes. This is the default output format for phrase structure parsers. We also create this representation by converting ENJU’s output by tree structure matching, although this conversion is not perfect because forms of PTB and ENJU’s output are not necessarily compatible. PTB Dependency trees of syntactic heads (Figure 8). This representation is obtained by converting PTB trees. We first determine lexical heads of nonterminal nodes by using Bikel’s implementation of Collins’ head detection algorithm9 (Bikel, 2004; Collins, 1997). We then convert lexicalized trees into dependencies between lexical heads. HD The Stanford dependency format (Figure 9). This format was originally proposed for extracting dependency relations useful for practical applications (de Marneffe et al., 2006). A program to convert PTB is attached to the Stanford parser. Although the concept looks similar to CoNLL, this representaSD 8 http://nlp.cs.lth.se/pennconverter/ http://www.cis.upenn.edu/˜dbikel/software. html 9 Figure 9: Stanford dependencies tion does not necessarily form a tree structure, and is designed to express more fine-grained relat"
P08-1006,de-marneffe-etal-2006-generating,0,0.148922,"Missing"
P08-1006,C96-1058,0,0.0205152,"for the sentence “IL-8 recognizes and activates CXCR1.” An advantage of dependency parsing is that dependency trees are a reasonable approximation of the semantics of sentences, and are readily usable in NLP applications. Furthermore, the efficiency of popular approaches to dependency parsing compare favorable with those of phrase structure parsing or deep parsing. While a number of approaches have been proposed for dependency parsing, this paper focuses on two typical methods. McDonald and Pereira (2006)’s dependency 1 parser, based on the Eisner algorithm for projective dependency parsing (Eisner, 1996) with the secondorder factorization. MST 1 http://sourceforge.net/projects/mstparser 47 Figure 2: Penn Treebank-style phrase structure tree Sagae and Tsujii (2007)’s dependency parser,2 based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005). KSDEP 2.2 Phrase structure parsing Owing largely to the Penn Treebank, the mainstream of data-driven parsing research has been dedicated to the phrase structure parsing. These parsers output Penn Treebank-style phrase structure trees, although function tags and empty categories are stri"
P08-1006,D07-1024,0,0.532677,"e for NLP researchers in choosing an appropriate parser for their purposes. In this paper, we present a comparative evaluation of syntactic parsers and their output representations based on different frameworks: dependency parsing, phrase structure parsing, and deep parsing. Our approach to parser evaluation is to measure accuracy improvement in the task of identifying protein-protein interaction (PPI) information in biomedical papers, by incorporating the output of different parsers as statistical features in a machine learning classifier (Yakushiji et al., 2005; Katrenko and Adriaans, 2006; Erkan et al., 2007; Sætre et al., 2007). PPI identification is a reasonable task for parser evaluation, because it is a typical information extraction (IE) application, and because recent studies have shown the effectiveness of syntactic parsing in this task. Since our evaluation method is applicable to any parser output, and is grounded in a real application, it allows for a fair comparison of syntactic parsers based on different frameworks. Parser evaluation in PPI extraction also illuminates domain portability. Most state-of-the-art parsers for English were trained with the Wall Street Journal (WSJ) portion"
P08-1006,W01-0521,0,0.0556271,"parsing in this task. Since our evaluation method is applicable to any parser output, and is grounded in a real application, it allows for a fair comparison of syntactic parsers based on different frameworks. Parser evaluation in PPI extraction also illuminates domain portability. Most state-of-the-art parsers for English were trained with the Wall Street Journal (WSJ) portion of the Penn Treebank, and high accuracy has been reported for WSJ text; however, these parsers rely on lexical information to attain high accuracy, and it has been criticized that these parsers may overfit to WSJ text (Gildea, 2001; 46 Proceedings of ACL-08: HLT, pages 46–54, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics Klein and Manning, 2003). Another issue for discussion is the portability of training methods. When training data in the target domain is available, as is the case with the GENIA Treebank (Kim et al., 2003) for biomedical papers, a parser can be retrained to adapt to the target domain, and larger accuracy improvements are expected, if the training method is sufficiently general. We will examine these two aspects of domain portability by comparing the original parsers w"
P08-1006,E06-1051,0,0.19788,"used with GENIA-retrained parsers. 4 Experiments 4.1 Experiment settings In the following experiments, we used AImed (Bunescu and Mooney, 2004), which is a popular corpus for the evaluation of PPI extraction systems. The corpus consists of 225 biomedical paper abstracts (1970 sentences), which are sentence-split, tokenized, and annotated with proteins and PPIs. We use gold protein annotations given in the corpus. Multi-word protein names are concatenated and treated as single words. The accuracy is measured by abstract-wise 10-fold cross validation and the one-answer-per-occurrence criterion (Giuliano et al., 2006). A threshold for SVMs is moved to adjust the balance of precision and recall, and the maximum f-scores are reported for each setting. 4.2 Comparison of accuracy improvements Tables 1 and 2 show the accuracy obtained by using the output of each parser in each parse representation. The row “baseline” indicates the accuracy obtained with bag-of-words features. Table 3 shows the time for parsing the entire AImed corpus, and Table 4 shows the time required for 10-fold cross validation with GENIA-retrained parsers. When using the original WSJ-trained parsers (Table 1), all parsers achieved almost t"
P08-1006,W07-2202,1,0.375843,"en used in parser evaluation and applications. PAS is a graph structure that represents syntactic/semantic relations among words (Figure 3). The concept is therefore similar to CoNLL dependencies, though PAS expresses deeper relations, and may include reentrant structures. In this work, we chose the two versions of the Enju parser (Miyao and Tsujii, 2008). The HPSG parser that consists of an HPSG grammar extracted from the Penn Treebank, and a maximum entropy model trained with an HPSG treebank derived from the Penn Treebank.7 ENJU The HPSG parser adapted to biomedical texts, by the method of Hara et al. (2007). Because this parser is trained with both WSJ and GENIA, we compare it parsers that are retrained with GENIA (see section 3.3). ENJU-GENIA 3 Evaluation Methodology In our approach to parser evaluation, we measure the accuracy of a PPI extraction system, in which 6 http://nlp.stanford.edu/software/lex-parser. shtml 7 http://www-tsujii.is.s.u-tokyo.ac.jp/enju/ 48 the parser output is embedded as statistical features of a machine learning classifier. We run a classifier with features of every possible combination of a parser and a parse representation, by applying conversions between representat"
P08-1006,W07-2416,0,0.333541,"ntences, and are readily usable in NLP applications. Furthermore, the efficiency of popular approaches to dependency parsing compare favorable with those of phrase structure parsing or deep parsing. While a number of approaches have been proposed for dependency parsing, this paper focuses on two typical methods. McDonald and Pereira (2006)’s dependency 1 parser, based on the Eisner algorithm for projective dependency parsing (Eisner, 1996) with the secondorder factorization. MST 1 http://sourceforge.net/projects/mstparser 47 Figure 2: Penn Treebank-style phrase structure tree Sagae and Tsujii (2007)’s dependency parser,2 based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005). KSDEP 2.2 Phrase structure parsing Owing largely to the Penn Treebank, the mainstream of data-driven parsing research has been dedicated to the phrase structure parsing. These parsers output Penn Treebank-style phrase structure trees, although function tags and empty categories are stripped off (Figure 2). While most of the state-of-the-art parsers are based on probabilistic CFGs, the parameterization of the probabilistic model of each parser var"
P08-1006,N04-1013,0,0.601287,"uracy. Our experiments show that the levels of accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data. 1 Introduction Parsing technologies have improved considerably in the past few years, and high-performance syntactic parsers are no longer limited to PCFG-based frameworks (Charniak, 2000; Klein and Manning, 2003; Charniak and Johnson, 2005; Petrov and Klein, 2007), but also include dependency parsers (McDonald and Pereira, 2006; Nivre and Nilsson, 2005; Sagae and Tsujii, 2007) and deep parsers (Kaplan et al., 2004; Clark and Curran, 2004; Miyao and Tsujii, 2008). However, efforts to perform extensive comparisons of syntactic parsers based on different frameworks have been limited. The most popular method for parser comparison involves the direct measurement of the parser output accuracy in terms of metrics such as bracketing precision and recall, or dependency accuracy. This assumes the existence of a gold-standard test corpus, such as the Penn Treebank (Marcus et al., 1994). It is difficult to apply this method to compare parsers based on different frameworks, because parse representations are often f"
P08-1006,P03-1054,0,0.166071,"ructure parsing, or deep parsing) using five different parse representations. We run a PPI system with several combinations of parser and parse representation, and examine their impact on PPI identification accuracy. Our experiments show that the levels of accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data. 1 Introduction Parsing technologies have improved considerably in the past few years, and high-performance syntactic parsers are no longer limited to PCFG-based frameworks (Charniak, 2000; Klein and Manning, 2003; Charniak and Johnson, 2005; Petrov and Klein, 2007), but also include dependency parsers (McDonald and Pereira, 2006; Nivre and Nilsson, 2005; Sagae and Tsujii, 2007) and deep parsers (Kaplan et al., 2004; Clark and Curran, 2004; Miyao and Tsujii, 2008). However, efforts to perform extensive comparisons of syntactic parsers based on different frameworks have been limited. The most popular method for parser comparison involves the direct measurement of the parser output accuracy in terms of metrics such as bracketing precision and recall, or dependency accuracy. This assumes the existence of"
P08-1006,P05-1010,1,0.242557,"parser/ http://bllip.cs.brown.edu/resources.shtml 4 We set n = 50 in this paper. 5 http://nlp.cs.berkeley.edu/Main.html#Parsing This study demonstrates that IL-8 recognizes and activates CXCR1, CXCR2, and the Duffy antigen by distinct mechanisms. The molar ratio of serum retinol-binding protein (RBP) to transthyretin (TTR) is not useful to assess vitamin A status during infection in hospitalised children. Figure 3: Predicate argument structure timized automatically by assigning latent variables to each nonterminal node and estimating the parameters of the latent variables by the EM algorithm (Matsuzaki et al., 2005). Stanford’s unlexicalized parser (Klein and Manning, 2003).6 Unlike NO-RERANK, probabilities are not parameterized on lexical heads. Figure 4: Sentences including protein names SBJ OBJ ENTITY1(IL-8) −→ recognizes ←− ENTITY2(CXCR1) Figure 5: Dependency path STANFORD 2.3 Deep parsing Recent research developments have allowed for efficient and robust deep parsing of real-world texts (Kaplan et al., 2004; Clark and Curran, 2004; Miyao and Tsujii, 2008). While deep parsers compute theory-specific syntactic/semantic structures, predicate argument structures (PAS) are often used in parser evaluation"
P08-1006,E06-1011,0,0.0491874,"inations of parser and parse representation, and examine their impact on PPI identification accuracy. Our experiments show that the levels of accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data. 1 Introduction Parsing technologies have improved considerably in the past few years, and high-performance syntactic parsers are no longer limited to PCFG-based frameworks (Charniak, 2000; Klein and Manning, 2003; Charniak and Johnson, 2005; Petrov and Klein, 2007), but also include dependency parsers (McDonald and Pereira, 2006; Nivre and Nilsson, 2005; Sagae and Tsujii, 2007) and deep parsers (Kaplan et al., 2004; Clark and Curran, 2004; Miyao and Tsujii, 2008). However, efforts to perform extensive comparisons of syntactic parsers based on different frameworks have been limited. The most popular method for parser comparison involves the direct measurement of the parser output accuracy in terms of metrics such as bracketing precision and recall, or dependency accuracy. This assumes the existence of a gold-standard test corpus, such as the Penn Treebank (Marcus et al., 1994). It is difficult to apply this method to"
P08-1006,J08-1002,1,0.858485,"f accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data. 1 Introduction Parsing technologies have improved considerably in the past few years, and high-performance syntactic parsers are no longer limited to PCFG-based frameworks (Charniak, 2000; Klein and Manning, 2003; Charniak and Johnson, 2005; Petrov and Klein, 2007), but also include dependency parsers (McDonald and Pereira, 2006; Nivre and Nilsson, 2005; Sagae and Tsujii, 2007) and deep parsers (Kaplan et al., 2004; Clark and Curran, 2004; Miyao and Tsujii, 2008). However, efforts to perform extensive comparisons of syntactic parsers based on different frameworks have been limited. The most popular method for parser comparison involves the direct measurement of the parser output accuracy in terms of metrics such as bracketing precision and recall, or dependency accuracy. This assumes the existence of a gold-standard test corpus, such as the Penn Treebank (Marcus et al., 1994). It is difficult to apply this method to compare parsers based on different frameworks, because parse representations are often framework-specific and differ from parser to parse"
P08-1006,E06-1015,0,0.0153065,"and Adriaans, 2006; Erkan et al., 2007; Sætre et al., 2007). For the protein pair IL-8 and CXCR1 in Figure 4, a dependency parser outputs a dependency tree shown in Figure 1. From this dependency tree, we can extract a dependency path shown in Figure 5, which appears to be a strong clue in knowing that these proteins are mentioned as interacting. (dep_path (SBJ (ENTITY1 recognizes)) (rOBJ (recognizes ENTITY2))) Figure 6: Tree representation of a dependency path We follow the PPI extraction method of Sætre et al. (2007), which is based on SVMs with SubSet Tree Kernels (Collins and Duffy, 2002; Moschitti, 2006), while using different parsers and parse representations. Two types of features are incorporated in the classifier. The first is bag-of-words features, which are regarded as a strong baseline for IE systems. Lemmas of words before, between and after the pair of target proteins are included, and the linear kernel is used for these features. These features are commonly included in all of the models. Filtering by a stop-word list is not applied because this setting made the scores higher than Sætre et al. (2007)’s setting. The other type of feature is syntactic features. For dependency-based par"
P08-1006,P05-1013,0,0.273658,"representation, and examine their impact on PPI identification accuracy. Our experiments show that the levels of accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data. 1 Introduction Parsing technologies have improved considerably in the past few years, and high-performance syntactic parsers are no longer limited to PCFG-based frameworks (Charniak, 2000; Klein and Manning, 2003; Charniak and Johnson, 2005; Petrov and Klein, 2007), but also include dependency parsers (McDonald and Pereira, 2006; Nivre and Nilsson, 2005; Sagae and Tsujii, 2007) and deep parsers (Kaplan et al., 2004; Clark and Curran, 2004; Miyao and Tsujii, 2008). However, efforts to perform extensive comparisons of syntactic parsers based on different frameworks have been limited. The most popular method for parser comparison involves the direct measurement of the parser output accuracy in terms of metrics such as bracketing precision and recall, or dependency accuracy. This assumes the existence of a gold-standard test corpus, such as the Penn Treebank (Marcus et al., 1994). It is difficult to apply this method to compare parsers based on"
P08-1006,N07-1051,0,0.0565978,"t parse representations. We run a PPI system with several combinations of parser and parse representation, and examine their impact on PPI identification accuracy. Our experiments show that the levels of accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data. 1 Introduction Parsing technologies have improved considerably in the past few years, and high-performance syntactic parsers are no longer limited to PCFG-based frameworks (Charniak, 2000; Klein and Manning, 2003; Charniak and Johnson, 2005; Petrov and Klein, 2007), but also include dependency parsers (McDonald and Pereira, 2006; Nivre and Nilsson, 2005; Sagae and Tsujii, 2007) and deep parsers (Kaplan et al., 2004; Clark and Curran, 2004; Miyao and Tsujii, 2008). However, efforts to perform extensive comparisons of syntactic parsers based on different frameworks have been limited. The most popular method for parser comparison involves the direct measurement of the parser output accuracy in terms of metrics such as bracketing precision and recall, or dependency accuracy. This assumes the existence of a gold-standard test corpus, such as the Penn Treeban"
P08-1006,W07-1004,0,0.29972,"). This format was originally proposed for extracting dependency relations useful for practical applications (de Marneffe et al., 2006). A program to convert PTB is attached to the Stanford parser. Although the concept looks similar to CoNLL, this representaSD 8 http://nlp.cs.lth.se/pennconverter/ http://www.cis.upenn.edu/˜dbikel/software. html 9 Figure 9: Stanford dependencies tion does not necessarily form a tree structure, and is designed to express more fine-grained relations such as apposition. Research groups for biomedical NLP recently adopted this representation for corpus annotation (Pyysalo et al., 2007a) and parser evaluation (Clegg and Shepherd, 2007; Pyysalo et al., 2007b). Predicate-argument structures. This is the default output format for ENJU and ENJU-GENIA. PAS Although only CoNLL is available for dependency parsers, we can create four representations for the phrase structure parsers, and five for the deep parsers. Dotted arrows in Figure 7 indicate imperfect conversion, in which the conversion inherently introduces errors, and may decrease the accuracy. We should therefore take caution when comparing the results obtained by imperfect conversion. We also measure the accuracy obtained"
P08-1006,W06-1608,0,0.0654162,"n of the parsing accuracy in terms of a certain intermediate parse representation (Ringger et al., 2004; Kaplan et al., 2004; Briscoe and Carroll, 2006; Clark and Curran, 2007; Miyao et al., 2007; Clegg and Shepherd, 2007; Pyysalo et al., 2007b; Pyysalo et al., 2007a; Sagae et al., 2008). Such evaluation requires gold standard data in an intermediate representation. However, it has been argued that the conversion of parsing results into an intermediate representation is difficult and far from perfect. The relationship between parsing accuracy and task accuracy has been obscure for many years. Quirk and Corston-Oliver (2006) investigated the impact of parsing accuracy on statistical MT. However, this work was only concerned with a single dependency parser, and did not focus on parsers based on different frameworks. 6 Conclusion and Future Work We have presented our attempts to evaluate syntactic parsers and their representations that are based on different frameworks; dependency parsing, phrase structure parsing, or deep parsing. The basic idea is to measure the accuracy improvements of the PPI extraction task by incorporating the parser output as statistical features of a machine learning classifier. Experiments"
P08-1006,ringger-etal-2004-using,0,0.102376,"owever, efforts to perform extensive comparisons of syntactic parsers based on different frameworks have been limited. The most popular method for parser comparison involves the direct measurement of the parser output accuracy in terms of metrics such as bracketing precision and recall, or dependency accuracy. This assumes the existence of a gold-standard test corpus, such as the Penn Treebank (Marcus et al., 1994). It is difficult to apply this method to compare parsers based on different frameworks, because parse representations are often framework-specific and differ from parser to parser (Ringger et al., 2004). The lack of such comparisons is a serious obstacle for NLP researchers in choosing an appropriate parser for their purposes. In this paper, we present a comparative evaluation of syntactic parsers and their output representations based on different frameworks: dependency parsing, phrase structure parsing, and deep parsing. Our approach to parser evaluation is to measure accuracy improvement in the task of identifying protein-protein interaction (PPI) information in biomedical papers, by incorporating the output of different parsers as statistical features in a machine learning classifier (Ya"
P08-1006,D07-1111,1,0.727784,"ine their impact on PPI identification accuracy. Our experiments show that the levels of accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data. 1 Introduction Parsing technologies have improved considerably in the past few years, and high-performance syntactic parsers are no longer limited to PCFG-based frameworks (Charniak, 2000; Klein and Manning, 2003; Charniak and Johnson, 2005; Petrov and Klein, 2007), but also include dependency parsers (McDonald and Pereira, 2006; Nivre and Nilsson, 2005; Sagae and Tsujii, 2007) and deep parsers (Kaplan et al., 2004; Clark and Curran, 2004; Miyao and Tsujii, 2008). However, efforts to perform extensive comparisons of syntactic parsers based on different frameworks have been limited. The most popular method for parser comparison involves the direct measurement of the parser output accuracy in terms of metrics such as bracketing precision and recall, or dependency accuracy. This assumes the existence of a gold-standard test corpus, such as the Penn Treebank (Marcus et al., 1994). It is difficult to apply this method to compare parsers based on different frameworks, bec"
P08-1006,1993.iwpt-1.22,0,0.0459583,"e on par with each other, while parsing speed differs significantly. We also found that accuracy improvements vary when parsers are retrained with domainspecific data, indicating the importance of domain adaptation and the differences in the portability of parser training methods. Although we restricted ourselves to parsers trainable with Penn Treebank-style treebanks, our methodology can be applied to any English parsers. Candidates include RASP (Briscoe and Carroll, 53 2006), the C&C parser (Clark and Curran, 2004), the XLE parser (Kaplan et al., 2004), MINIPAR (Lin, 1998), and Link Parser (Sleator and Temperley, 1993; Pyysalo et al., 2006), but the domain adaptation of these parsers is not straightforward. It is also possible to evaluate unsupervised parsers, which is attractive since evaluation of such parsers with goldstandard data is extremely problematic. A major drawback of our methodology is that the evaluation is indirect and the results depend on a selected task and its settings. This indicates that different results might be obtained with other tasks. Hence, we cannot conclude the superiority of parsers/representations only with our results. In order to obtain general ideas on parser performance,"
P08-1006,A00-2018,0,\N,Missing
P08-1006,J93-2004,0,\N,Missing
P08-1006,J04-4004,0,\N,Missing
P10-1034,W07-0702,0,0.101471,"orner of Figure 2. In order to include richer context information and account for multiple interpretations of unaligned words of foreign language, minimal rules which share adjacent tree fragments are connected together to form composed rules (Galley et al., Considering the parse error problem in the 1-best or k-best parse trees, Mi and Huang (2008) extracted tree-to-string translation rules from aligned packed forest-string pairs. A forest compactly encodes exponentially many trees 327 fine-grained tree-to-string rule extraction, rather than string-to-string translation (Hassan et al., 2007; Birch et al., 2007). The Logon project2 (Oepen et al., 2007) for Norwegian-English translation integrates in-depth grammatical analysis of Norwegian (using lexical functional grammar, similar to (Riezler and Maxwell, 2006)) with semantic representations in the minimal recursion semantics framework, and fully grammar-based generation for English using HPSG. A hybrid (of rule-based and data-driven) architecture with a semantic transfer backbone is taken as the vantage point of this project. In contrast, the fine-grained tree-to-string translation rule extraction approaches in this paper are totally data-driven, an"
P10-1034,N09-1025,0,0.0888322,"e set that is more appropriate to reflect the real translation situations. This motivates our proposal of using deep syntactic information to obtain a fine-grained translation rule set. We name the information such as the voice of a verb in a tree fragment as deep syntactic information. We use a head-driven phrase structure grammar (HPSG) parser to obtain the Introduction Tree-to-string translation rules are generic and applicable to numerous linguistically syntax-based Statistical Machine Translation (SMT) systems, such as string-to-tree translation (Galley et al., 2004; Galley et al., 2006; Chiang et al., 2009), tree-to-string translation (Liu et al., 2006; Huang et al., 2006), and forest-to-string translation (Mi et al., 2008; Mi and Huang, 2008). The algorithms proposed by Galley et al. (2004; 2006) are frequently used for extracting minimal and composed rules from aligned 1-best tree-string pairs. Dealing with the parse error problem and rule sparseness problem, Mi and Huang (2008) replaced the 1-best parse tree with a packed forest which compactly encodes exponentially many parses for treeto-string rule extraction. However, current tree-to-string rules only make use of Probabilistic Context-Free"
P10-1034,P05-1033,0,0.680418,"a binarized rule set. These glue rules can be seen as an extension from X to {Xm }of the two glue rules described in (Chiang, 2007). 331 # of sentences # of Jp words # of En words Train 994K 28.2M 24.7M Dev. 2K 57.4K 50.3K Test 2K 57.1K 49.9K tree nodes # rules # tree types extract time Table 3: Statistics of the JST corpus. PRS TFS 0.9 0.4 3.5 C3S POS 62.1 23.5 - C3 TFS 83.9 34.7 98.6 FS POS 92.5 40.6 - F TFS 103.7 45.2 121.2 Table 4: Statistics of several kinds of tree-to-string rules. Here, the number is in million level and the time is in hour. use the Algorithm 3 described in (Huang and Chiang, 2005) to extract its k-best (k = 500 in our experiments) derivations. Since different derivations may lead to the same target language string, we further adopt Algorithm 3’s modification, i.e., keep a hash-table to maintain the unique target sentences (Huang et al., 2006), to efficiently generate the unique k-best translations. 200 for English-to-Japanese translation and 500 for Japanese-to-English translation. We used four dual core Xeon machines (4×3.0GHz×2CPU, 4×64GB memory) to run all the experiments. 4.4 Results 4.3 Setups Table 4 illustrates the statistics of several translation rule sets, wh"
P10-1034,J07-2003,0,0.549376,"rsal of the terminal nodes in Et . At each terminal node, we seek its minimum covering tree, retrieve PRS, and update the hash-table. For example, suppose we are decoding an HPSG tree (with gray nodes) shown in Figure 2. At t1 , we can extract its minimum covering tree with the root node to be c0 , then take this tree fragment as the key to retrieve PRS, and consequently put c0 and the available rules in the hash-table. When decoding at c0 , we can directly access the hash-table looking for available PASbased rules. In contrast, we use a CKY-style algorithm with beam-pruning and cube-pruning (Chiang, 2007) to decode Japanese sentences. For each Japanese sentence F , the output of the chart-parsing algorithm is expressed as a hypergraph representing a set of derivations. Given such a hypergraph, we r∈d This equation reflects that the translation rules in one d come from three sets. Inspired by (Liu et al., 2009b), it is appealing to combine these rule sets together in one decoder because PTT provides excellent rule coverages while TRS and PRS offer linguistically motivated phrase selections and nonlocal reorderings. Each f (r) is in turn a product of five features: f (r) = p(s|t)λ3 · p(t|s)λ4 ·"
P10-1034,N04-1035,0,0.791221,"ormation to “killed”, we are gaining a rule set that is more appropriate to reflect the real translation situations. This motivates our proposal of using deep syntactic information to obtain a fine-grained translation rule set. We name the information such as the voice of a verb in a tree fragment as deep syntactic information. We use a head-driven phrase structure grammar (HPSG) parser to obtain the Introduction Tree-to-string translation rules are generic and applicable to numerous linguistically syntax-based Statistical Machine Translation (SMT) systems, such as string-to-tree translation (Galley et al., 2004; Galley et al., 2006; Chiang et al., 2009), tree-to-string translation (Liu et al., 2006; Huang et al., 2006), and forest-to-string translation (Mi et al., 2008; Mi and Huang, 2008). The algorithms proposed by Galley et al. (2004; 2006) are frequently used for extracting minimal and composed rules from aligned 1-best tree-string pairs. Dealing with the parse error problem and rule sparseness problem, Mi and Huang (2008) replaced the 1-best parse tree with a packed forest which compactly encodes exponentially many parses for treeto-string rule extraction. However, current tree-to-string rules"
P10-1034,P06-1121,0,0.0797987,"we are gaining a rule set that is more appropriate to reflect the real translation situations. This motivates our proposal of using deep syntactic information to obtain a fine-grained translation rule set. We name the information such as the voice of a verb in a tree fragment as deep syntactic information. We use a head-driven phrase structure grammar (HPSG) parser to obtain the Introduction Tree-to-string translation rules are generic and applicable to numerous linguistically syntax-based Statistical Machine Translation (SMT) systems, such as string-to-tree translation (Galley et al., 2004; Galley et al., 2006; Chiang et al., 2009), tree-to-string translation (Liu et al., 2006; Huang et al., 2006), and forest-to-string translation (Mi et al., 2008; Mi and Huang, 2008). The algorithms proposed by Galley et al. (2004; 2006) are frequently used for extracting minimal and composed rules from aligned 1-best tree-string pairs. Dealing with the parse error problem and rule sparseness problem, Mi and Huang (2008) replaced the 1-best parse tree with a packed forest which compactly encodes exponentially many parses for treeto-string rule extraction. However, current tree-to-string rules only make use of Prob"
P10-1034,J03-1002,0,0.00648777,"Missing"
P10-1034,P03-1021,0,0.0143227,"shown in the bottom-right corner of Figure 2. The definition supplies us a linear-time algorithm to directly find the tree fragment that covers a PAS during both rule extracting and rule matching when decoding an HPSG tree. 4 Experiments 4.1 Translation models We use a tree-to-string model and a string-to-tree model for bidirectional Japanese-English translations. Both models use a phrase translation table (PTT), an HPSG tree-based rule set (TRS), and a PAS-based rule set (PRS). Since the three rule sets are independently extracted and estimated, we 330 use Minimum Error Rate Training (MERT) (Och, 2003) to tune the weights of the features from the three rule sets on the development set. Given a 1-best (localized) HPSG tree Et , the tree-to-string decoder searches for the optimal derivation d∗ that transforms Et into a Japanese string among the set of all possible derivations D: The string-to-tree decoder searches for the optimal derivation d∗ that parses a Japanese string F into a packed forest of the set of all possible derivations D: d∗ = arg max{λ1 log pLM (τ (d)) + λ2 |τ (d)| d∈D + λ3 g(d) + log s(d|F )}. d∗ = arg max{λ1 log pLM (τ (d)) + λ2 |τ (d)| This formula differs from Equation 2 b"
P10-1034,P07-1037,0,0.0377843,"Missing"
P10-1034,2007.tmi-papers.18,0,0.0670195,"Missing"
P10-1034,W05-1506,0,0.0605444,"pearing in a binarized rule set. These glue rules can be seen as an extension from X to {Xm }of the two glue rules described in (Chiang, 2007). 331 # of sentences # of Jp words # of En words Train 994K 28.2M 24.7M Dev. 2K 57.4K 50.3K Test 2K 57.1K 49.9K tree nodes # rules # tree types extract time Table 3: Statistics of the JST corpus. PRS TFS 0.9 0.4 3.5 C3S POS 62.1 23.5 - C3 TFS 83.9 34.7 98.6 FS POS 92.5 40.6 - F TFS 103.7 45.2 121.2 Table 4: Statistics of several kinds of tree-to-string rules. Here, the number is in million level and the time is in hour. use the Algorithm 3 described in (Huang and Chiang, 2005) to extract its k-best (k = 500 in our experiments) derivations. Since different derivations may lead to the same target language string, we further adopt Algorithm 3’s modification, i.e., keep a hash-table to maintain the unique target sentences (Huang et al., 2006), to efficiently generate the unique k-best translations. 200 for English-to-Japanese translation and 500 for Japanese-to-English translation. We used four dual core Xeon machines (4×3.0GHz×2CPU, 4×64GB memory) to run all the experiments. 4.4 Results 4.3 Setups Table 4 illustrates the statistics of several translation rule sets, wh"
P10-1034,2006.amta-papers.8,0,0.715916,"tions. This motivates our proposal of using deep syntactic information to obtain a fine-grained translation rule set. We name the information such as the voice of a verb in a tree fragment as deep syntactic information. We use a head-driven phrase structure grammar (HPSG) parser to obtain the Introduction Tree-to-string translation rules are generic and applicable to numerous linguistically syntax-based Statistical Machine Translation (SMT) systems, such as string-to-tree translation (Galley et al., 2004; Galley et al., 2006; Chiang et al., 2009), tree-to-string translation (Liu et al., 2006; Huang et al., 2006), and forest-to-string translation (Mi et al., 2008; Mi and Huang, 2008). The algorithms proposed by Galley et al. (2004; 2006) are frequently used for extracting minimal and composed rules from aligned 1-best tree-string pairs. Dealing with the parse error problem and rule sparseness problem, Mi and Huang (2008) replaced the 1-best parse tree with a packed forest which compactly encodes exponentially many parses for treeto-string rule extraction. However, current tree-to-string rules only make use of Probabilistic Context-Free Grammar tree fragments, in which part-of-speech (POS) or 1 For exa"
P10-1034,P07-2045,0,0.00800156,"t can be segmented properly into a set of tree fragments, each of which can be used to generate a tree-to-string translation rule. 2.3 Rich syntactic information for SMT Before describing our approaches of applying deep syntactic information yielded by an HPSG parser for fine-grained rule extraction, we would like to briefly review what kinds of deep syntactic information have been employed for SMT. Two kinds of supertags, from Lexicalized TreeAdjoining Grammar and Combinatory Categorial Grammar (CCG), have been used as lexical syntactic descriptions (Hassan et al., 2007) for phrasebased SMT (Koehn et al., 2007). By introducing supertags into the target language side, i.e., the target language model and the target side of the phrase table, significant improvement was achieved for Arabic-to-English translation. Birch et al. (2007) also reported a significant improvement for Dutch-English translation by applying CCG supertags at a word level to a factorized SMT system (Koehn et al., 2007). In this paper, we also make use of supertags on the English language side. In an HPSG parse tree, these lexical syntactic descriptions are included in the LEXENTRY feature (refer to Table 2) of a lexical node (Matsuz"
P10-1034,P02-1040,0,0.0839341,"Missing"
P10-1034,P09-4007,0,0.278936,"Missing"
P10-1034,N06-1032,0,0.0194013,"are connected together to form composed rules (Galley et al., Considering the parse error problem in the 1-best or k-best parse trees, Mi and Huang (2008) extracted tree-to-string translation rules from aligned packed forest-string pairs. A forest compactly encodes exponentially many trees 327 fine-grained tree-to-string rule extraction, rather than string-to-string translation (Hassan et al., 2007; Birch et al., 2007). The Logon project2 (Oepen et al., 2007) for Norwegian-English translation integrates in-depth grammatical analysis of Norwegian (using lexical functional grammar, similar to (Riezler and Maxwell, 2006)) with semantic representations in the minimal recursion semantics framework, and fully grammar-based generation for English using HPSG. A hybrid (of rule-based and data-driven) architecture with a semantic transfer backbone is taken as the vantage point of this project. In contrast, the fine-grained tree-to-string translation rule extraction approaches in this paper are totally data-driven, and easily applicable to numerous language pairs by taking English as the source or target language. rather than the 1-best tree used by Galley et al. (2004; 2006). Two problems were managed to be tackled"
P10-1034,2007.mtsummit-papers.63,0,0.168113,"Missing"
P10-1034,P09-1063,0,0.106393,"Missing"
P10-1034,P09-1065,0,0.154289,") and f (r) are identical with those used in Equation 2. d∈D + log s(d|Et )}. (3) (2) Here, the first item is the language model (LM) probability where τ (d) is the target string of derivation d; the second item is the translation length penalty; and the third item is the translation score, which is decomposed into a product of feature values of rules: ∏ s(d|Et ) = f (r∈P T T )f (r∈T RS )f (r∈P RS ). 4.2 Decoding algorithms In our translation models, we have made use of three kinds of translation rule sets which are trained separately. We perform derivation-level combination as described in (Liu et al., 2009b) for mixing different types of translation rules within one derivation. For tree-to-string translation, we use a bottomup beam search algorithm (Liu et al., 2006) for decoding an HPSG tree Et . We keep at most 10 best derivations with distinct τ (d)s at each node. Recall the definition of minimum covering tree, which supports a faster way to retrieve available rules from PRS without generating all the subtrees. That is, when node n fortunately to be the root of some minimum covering tree(s), we use the tree(s) to seek available PAS-based rules in PRS. We keep a hash-table with the key to be"
P10-1034,N06-1033,0,0.0309826,"e rule sets together in one decoder because PTT provides excellent rule coverages while TRS and PRS offer linguistically motivated phrase selections and nonlocal reorderings. Each f (r) is in turn a product of five features: f (r) = p(s|t)λ3 · p(t|s)λ4 · l(s|t)λ5 · l(t|s)λ6 · eλ7 . Here, s/t represent the source/target part of a rule in PTT, TRS, or PRS; p(·|·) and l(·|·) are translation probabilities and lexical weights of rules from PTT, TRS, and PRS. The derivation length penalty is controlled by λ7 . In our string-to-tree model, for efficient decoding with integrated n-gram LM, we follow (Zhang et al., 2006) and inversely binarize all translation rules into Chomsky Normal Forms that contain at most two variables and can be incrementally scored by LM. In order to make use of the binarized rules in the CKY decoding, we add two kinds of glues rules: S → Xm (1) , Xm (1) ; S → S (1) Xm (2) , S (1) Xm (2) . Here Xm ranges over the nonterminals appearing in a binarized rule set. These glue rules can be seen as an extension from X to {Xm }of the two glue rules described in (Chiang, 2007). 331 # of sentences # of Jp words # of En words Train 994K 28.2M 24.7M Dev. 2K 57.4K 50.3K Test 2K 57.1K 49.9K tree no"
P10-1034,D08-1022,0,0.449701,"o obtain a fine-grained translation rule set. We name the information such as the voice of a verb in a tree fragment as deep syntactic information. We use a head-driven phrase structure grammar (HPSG) parser to obtain the Introduction Tree-to-string translation rules are generic and applicable to numerous linguistically syntax-based Statistical Machine Translation (SMT) systems, such as string-to-tree translation (Galley et al., 2004; Galley et al., 2006; Chiang et al., 2009), tree-to-string translation (Liu et al., 2006; Huang et al., 2006), and forest-to-string translation (Mi et al., 2008; Mi and Huang, 2008). The algorithms proposed by Galley et al. (2004; 2006) are frequently used for extracting minimal and composed rules from aligned 1-best tree-string pairs. Dealing with the parse error problem and rule sparseness problem, Mi and Huang (2008) replaced the 1-best parse tree with a packed forest which compactly encodes exponentially many parses for treeto-string rule extraction. However, current tree-to-string rules only make use of Probabilistic Context-Free Grammar tree fragments, in which part-of-speech (POS) or 1 For example, “John has killed Mary.” versus “John was killed by Mary.” 325 Proc"
P10-1034,P08-1023,0,0.115331,"tic information to obtain a fine-grained translation rule set. We name the information such as the voice of a verb in a tree fragment as deep syntactic information. We use a head-driven phrase structure grammar (HPSG) parser to obtain the Introduction Tree-to-string translation rules are generic and applicable to numerous linguistically syntax-based Statistical Machine Translation (SMT) systems, such as string-to-tree translation (Galley et al., 2004; Galley et al., 2006; Chiang et al., 2009), tree-to-string translation (Liu et al., 2006; Huang et al., 2006), and forest-to-string translation (Mi et al., 2008; Mi and Huang, 2008). The algorithms proposed by Galley et al. (2004; 2006) are frequently used for extracting minimal and composed rules from aligned 1-best tree-string pairs. Dealing with the parse error problem and rule sparseness problem, Mi and Huang (2008) replaced the 1-best parse tree with a packed forest which compactly encodes exponentially many parses for treeto-string rule extraction. However, current tree-to-string rules only make use of Probabilistic Context-Free Grammar tree fragments, in which part-of-speech (POS) or 1 For example, “John has killed Mary.” versus “John was kill"
P10-1034,P06-1077,0,\N,Missing
P11-1003,P05-1033,0,0.60377,"y generate target function words during decoding. Extensive experiments involving large-scale English-toJapanese translation revealed a significant improvement of 1.8 points in BLEU score, as compared with a strong forest-to-string baseline system. 1 Introduction Rule generalization remains a key challenge for current syntax-based statistical machine translation (SMT) systems. On the one hand, there is a tendency to integrate richer syntactic information into a translation rule in order to better express the translation phenomena. Thus, flat phrases (Koehn et al., 2003), hierarchical phrases (Chiang, 2005), and syntactic tree fragments (Galley et al., 2006; Mi and Huang, 2008; Wu et al., 2010) are gradually used in SMT. On the other hand, the use of syntactic phrases continues due to the requirement for phrase coverage in most syntax-based systems. For example, 22 Mi et al. (2008) achieved a 3.1-point improvement in BLEU score (Papineni et al., 2002) by including bilingual syntactic phrases in their forest-based system. Compared with flat phrases, syntactic rules are good at capturing global reordering, which has been reported to be essential for translating between languages with substantial s"
P11-1003,P10-1146,0,0.0878591,"sh and Japanese, which is a subject-objectverb language (Xu et al., 2009). Forest-based translation frameworks, which make use of packed parse forests on the source and/or target language side(s), are an increasingly promising approach to syntax-based SMT, being both algorithmically appealing (Mi et al., 2008) and empirically successful (Mi and Huang, 2008; Liu et al., 2009). However, forest-based translation systems, and, in general, most linguistically syntax-based SMT systems (Galley et al., 2004; Galley et al., 2006; Liu et al., 2006; Zhang et al., 2007; Mi et al., 2008; Liu et al., 2009; Chiang, 2010), are built upon word aligned parallel sentences and thus share a critical dependence on word alignments. For example, even a single spurious word alignment can invalidate a large number of otherwise extractable rules, and unaligned words can result in an exponentially large set of extractable rules for the interpretation of these unaligned words (Galley et al., 2006). What makes word alignment so fragile? In order to investigate this problem, we manually analyzed the alignments of the first 100 parallel sentences in our English-Japanese training data (to be shown in Table 2). The alignments w"
P11-1003,N04-1035,0,0.767859,"n reported to be essential for translating between languages with substantial structural differences, such as English and Japanese, which is a subject-objectverb language (Xu et al., 2009). Forest-based translation frameworks, which make use of packed parse forests on the source and/or target language side(s), are an increasingly promising approach to syntax-based SMT, being both algorithmically appealing (Mi et al., 2008) and empirically successful (Mi and Huang, 2008; Liu et al., 2009). However, forest-based translation systems, and, in general, most linguistically syntax-based SMT systems (Galley et al., 2004; Galley et al., 2006; Liu et al., 2006; Zhang et al., 2007; Mi et al., 2008; Liu et al., 2009; Chiang, 2010), are built upon word aligned parallel sentences and thus share a critical dependence on word alignments. For example, even a single spurious word alignment can invalidate a large number of otherwise extractable rules, and unaligned words can result in an exponentially large set of extractable rules for the interpretation of these unaligned words (Galley et al., 2006). What makes word alignment so fragile? In order to investigate this problem, we manually analyzed the alignments of the"
P11-1003,P06-1121,0,0.104629,"ing. Extensive experiments involving large-scale English-toJapanese translation revealed a significant improvement of 1.8 points in BLEU score, as compared with a strong forest-to-string baseline system. 1 Introduction Rule generalization remains a key challenge for current syntax-based statistical machine translation (SMT) systems. On the one hand, there is a tendency to integrate richer syntactic information into a translation rule in order to better express the translation phenomena. Thus, flat phrases (Koehn et al., 2003), hierarchical phrases (Chiang, 2005), and syntactic tree fragments (Galley et al., 2006; Mi and Huang, 2008; Wu et al., 2010) are gradually used in SMT. On the other hand, the use of syntactic phrases continues due to the requirement for phrase coverage in most syntax-based systems. For example, 22 Mi et al. (2008) achieved a 3.1-point improvement in BLEU score (Papineni et al., 2002) by including bilingual syntactic phrases in their forest-based system. Compared with flat phrases, syntactic rules are good at capturing global reordering, which has been reported to be essential for translating between languages with substantial structural differences, such as English and Japanese"
P11-1003,W05-1506,0,0.0758848,"Missing"
P11-1003,N03-1017,0,0.02613,"xponential number of parse trees to properly generate target function words during decoding. Extensive experiments involving large-scale English-toJapanese translation revealed a significant improvement of 1.8 points in BLEU score, as compared with a strong forest-to-string baseline system. 1 Introduction Rule generalization remains a key challenge for current syntax-based statistical machine translation (SMT) systems. On the one hand, there is a tendency to integrate richer syntactic information into a translation rule in order to better express the translation phenomena. Thus, flat phrases (Koehn et al., 2003), hierarchical phrases (Chiang, 2005), and syntactic tree fragments (Galley et al., 2006; Mi and Huang, 2008; Wu et al., 2010) are gradually used in SMT. On the other hand, the use of syntactic phrases continues due to the requirement for phrase coverage in most syntax-based systems. For example, 22 Mi et al. (2008) achieved a 3.1-point improvement in BLEU score (Papineni et al., 2002) by including bilingual syntactic phrases in their forest-based system. Compared with flat phrases, syntactic rules are good at capturing global reordering, which has been reported to be essential for translating"
P11-1003,P07-2045,0,0.00850188,"orest 96.52 91.36 93.55 42.1 52.2 1.22 1.23 15.7 27.07 Min-F Y A′ forest 144.91 92.98 72.98 26.3 58.6 11.2 1.37 1.37 22.4 27.93 C3-F Y A′ forest 228.59 162.71 120.08 18.6 130.7 29.0 2.18 2.15 35.4 28.89 Table 3: Statistics and translation results for four types of tree-to-string rules. With the exception of ‘# nodes/tree’, the numbers in the table are in millions and the time is in hours. Here, fw denotes function word, and DT denotes the decoding time, and the BLEU scores were computed on the test set. We performed GIZA++ (Och and Ney, 2003) and the grow-diag-final-and symmetrizing strategy (Koehn et al., 2007) on the training set to obtain alignments. The SRI Language Modeling Toolkit (Stolcke, 2002) was employed to train a five-gram Japanese LM on the training set. We evaluated the translation quality using the BLEU-4 metric (Papineni et al., 2002). Joshua v1.3 (Li et al., 2009), which is a freely available decoder for hierarchical phrasebased SMT (Chiang, 2005), is used as an external baseline system for comparison. We extracted 4.5M translation rules from the training set for the 4K English sentences in the development and test sets. We used the default configuration of Joshua, with the exceptio"
P11-1003,W02-2016,0,0.0394124,"nstead of a 1best tree, as in the case of (Galley et al., 2006). Multiple interpretations of unaligned function words for an aligned tree-string pair result in a derivation forest. Now, we have a packed parse forest in which each tree corresponds to a derivation forest. Thus, pruning free attachments of function words is practically important in order to extract composed rules from this “(derivation) forest of (parse) forest”. In the English-to-Japanese translation test case of the present study, the target chunk set is yielded by a state-of-the-art Japanese dependency parser, Cabocha v0.535 (Kudo and Matsumoto, 2002). The output of Cabocha is a list of chunks. A chunk contains roughly one content word (usually the head) and affixed function words, such as case markers (e.g., ga) and verbal morphemes (e.g., sa re ta, which indicate past tense and passive voice). For example, the Japanese sentence in Figure 1 is separated into four chunks, and the dependencies among these chunks are identified by arrows. These arrows point out the head chunk that the current chunk modifies. Moreover, we also hope to gain a fine-grained alignment among these syntactic chunks and source tree fragments. Thereby, during decodin"
P11-1003,P09-4007,0,0.0147167,"g rules. With the exception of ‘# nodes/tree’, the numbers in the table are in millions and the time is in hours. Here, fw denotes function word, and DT denotes the decoding time, and the BLEU scores were computed on the test set. We performed GIZA++ (Och and Ney, 2003) and the grow-diag-final-and symmetrizing strategy (Koehn et al., 2007) on the training set to obtain alignments. The SRI Language Modeling Toolkit (Stolcke, 2002) was employed to train a five-gram Japanese LM on the training set. We evaluated the translation quality using the BLEU-4 metric (Papineni et al., 2002). Joshua v1.3 (Li et al., 2009), which is a freely available decoder for hierarchical phrasebased SMT (Chiang, 2005), is used as an external baseline system for comparison. We extracted 4.5M translation rules from the training set for the 4K English sentences in the development and test sets. We used the default configuration of Joshua, with the exception of the maximum number of items/rules, and the value of k (of the k-best outputs) is set to be 200. 4.2 Results Table 3 lists the statistics of the following translation rule sets: • C3-T: a composed rule set extracted from the derivation forests of 1-best HPSG trees that w"
P11-1003,P09-1063,0,0.0938612,"Missing"
P11-1003,D07-1038,0,0.123961,"nd ‘the’, which may appear anywhere in an English sentence. Following these problematic alignments, we are forced to make use of relatively large English tree fragments to construct translation rules that tend to be ill-formed and less generalized. This is the motivation of the present approach of re-aligning the target function words to source tree fragments, so that the influence of incorrect alignments is reduced and the function words can be generated by tree fragments on the fly. However, the current dominant research only uses 1-best trees for syntactic realignment (Galley et al., 2006; May and Knight, 2007; Wang et al., 2010), which adversely affects the rule set quality due to parsing errors. Therefore, we realign target function words to a packed forest that compactly encodes exponentially many parses. Given aligned forest-string pairs, we extract composed tree-to-string translation rules that account for multiple interpretations of both aligned and unaligned target function words. In order to constrain the exhaustive attachments of function words, we further limit the function words to bind to their surrounding chunks yielded by a dependency parser. Using the composed rules of the present st"
P11-1003,D08-1022,0,0.21945,"ments involving large-scale English-toJapanese translation revealed a significant improvement of 1.8 points in BLEU score, as compared with a strong forest-to-string baseline system. 1 Introduction Rule generalization remains a key challenge for current syntax-based statistical machine translation (SMT) systems. On the one hand, there is a tendency to integrate richer syntactic information into a translation rule in order to better express the translation phenomena. Thus, flat phrases (Koehn et al., 2003), hierarchical phrases (Chiang, 2005), and syntactic tree fragments (Galley et al., 2006; Mi and Huang, 2008; Wu et al., 2010) are gradually used in SMT. On the other hand, the use of syntactic phrases continues due to the requirement for phrase coverage in most syntax-based systems. For example, 22 Mi et al. (2008) achieved a 3.1-point improvement in BLEU score (Papineni et al., 2002) by including bilingual syntactic phrases in their forest-based system. Compared with flat phrases, syntactic rules are good at capturing global reordering, which has been reported to be essential for translating between languages with substantial structural differences, such as English and Japanese, which is a subject"
P11-1003,P10-1145,0,0.259825,"Missing"
P11-1003,P08-1023,0,0.418907,"zation remains a key challenge for current syntax-based statistical machine translation (SMT) systems. On the one hand, there is a tendency to integrate richer syntactic information into a translation rule in order to better express the translation phenomena. Thus, flat phrases (Koehn et al., 2003), hierarchical phrases (Chiang, 2005), and syntactic tree fragments (Galley et al., 2006; Mi and Huang, 2008; Wu et al., 2010) are gradually used in SMT. On the other hand, the use of syntactic phrases continues due to the requirement for phrase coverage in most syntax-based systems. For example, 22 Mi et al. (2008) achieved a 3.1-point improvement in BLEU score (Papineni et al., 2002) by including bilingual syntactic phrases in their forest-based system. Compared with flat phrases, syntactic rules are good at capturing global reordering, which has been reported to be essential for translating between languages with substantial structural differences, such as English and Japanese, which is a subject-objectverb language (Xu et al., 2009). Forest-based translation frameworks, which make use of packed parse forests on the source and/or target language side(s), are an increasingly promising approach to synta"
P11-1003,J08-1002,1,0.822257,"binding particles, conjunctive particles, and phrasal particles. Japanese grammar also uses auxiliary verbs to give further semantic or syntactic information about the preceding main or full verb. Alike English, the extra meaning provided by a Japanese auxiliary verb alters the basic meaning of the main verb so that the main verb has one or more of the following functions: passive voice, progressive aspect, perfect aspect, modality, dummy, or emphasis. 2.2 HPSG forests Following our precious work (Wu et al., 2010), we use head-drive phrase structure grammar (HPSG) forests generated by Enju2 (Miyao and Tsujii, 2008), which is a state-of-the-art HPSG parser for English. HPSG (Pollard and Sag, 1994; Sag et al., 2003) is a lexicalist grammar framework. In HPSG, linguistic entities such as words and phrases are represented by a data structure called a sign. A sign gives a factored representation of the syntactic features of a word/phrase, as well as a representation of their semantic content. Phrases and words represented by signs are collected into larger phrases by the applications of schemata. The semantic representation of the new phrase is calculated at the same time. As such, an HPSG parse forest can b"
P11-1003,J03-1002,0,0.00515132,"ge of 82.3 trees in a parse forest. 6 http://www.jst.go.jp M&H-F N A forest 96.52 91.36 93.55 42.1 52.2 1.22 1.23 15.7 27.07 Min-F Y A′ forest 144.91 92.98 72.98 26.3 58.6 11.2 1.37 1.37 22.4 27.93 C3-F Y A′ forest 228.59 162.71 120.08 18.6 130.7 29.0 2.18 2.15 35.4 28.89 Table 3: Statistics and translation results for four types of tree-to-string rules. With the exception of ‘# nodes/tree’, the numbers in the table are in millions and the time is in hours. Here, fw denotes function word, and DT denotes the decoding time, and the BLEU scores were computed on the test set. We performed GIZA++ (Och and Ney, 2003) and the grow-diag-final-and symmetrizing strategy (Koehn et al., 2007) on the training set to obtain alignments. The SRI Language Modeling Toolkit (Stolcke, 2002) was employed to train a five-gram Japanese LM on the training set. We evaluated the translation quality using the BLEU-4 metric (Papineni et al., 2002). Joshua v1.3 (Li et al., 2009), which is a freely available decoder for hierarchical phrasebased SMT (Chiang, 2005), is used as an external baseline system for comparison. We extracted 4.5M translation rules from the training set for the 4K English sentences in the development and te"
P11-1003,P02-1040,0,0.0817636,"al machine translation (SMT) systems. On the one hand, there is a tendency to integrate richer syntactic information into a translation rule in order to better express the translation phenomena. Thus, flat phrases (Koehn et al., 2003), hierarchical phrases (Chiang, 2005), and syntactic tree fragments (Galley et al., 2006; Mi and Huang, 2008; Wu et al., 2010) are gradually used in SMT. On the other hand, the use of syntactic phrases continues due to the requirement for phrase coverage in most syntax-based systems. For example, 22 Mi et al. (2008) achieved a 3.1-point improvement in BLEU score (Papineni et al., 2002) by including bilingual syntactic phrases in their forest-based system. Compared with flat phrases, syntactic rules are good at capturing global reordering, which has been reported to be essential for translating between languages with substantial structural differences, such as English and Japanese, which is a subject-objectverb language (Xu et al., 2009). Forest-based translation frameworks, which make use of packed parse forests on the source and/or target language side(s), are an increasingly promising approach to syntax-based SMT, being both algorithmically appealing (Mi et al., 2008) and"
P11-1003,2007.mtsummit-papers.63,0,0.299106,"Missing"
P11-1003,J10-2004,0,0.249488,"pear anywhere in an English sentence. Following these problematic alignments, we are forced to make use of relatively large English tree fragments to construct translation rules that tend to be ill-formed and less generalized. This is the motivation of the present approach of re-aligning the target function words to source tree fragments, so that the influence of incorrect alignments is reduced and the function words can be generated by tree fragments on the fly. However, the current dominant research only uses 1-best trees for syntactic realignment (Galley et al., 2006; May and Knight, 2007; Wang et al., 2010), which adversely affects the rule set quality due to parsing errors. Therefore, we realign target function words to a packed forest that compactly encodes exponentially many parses. Given aligned forest-string pairs, we extract composed tree-to-string translation rules that account for multiple interpretations of both aligned and unaligned target function words. In order to constrain the exhaustive attachments of function words, we further limit the function words to bind to their surrounding chunks yielded by a dependency parser. Using the composed rules of the present study in a baseline fo"
P11-1003,P10-1034,1,0.916471,"e-scale English-toJapanese translation revealed a significant improvement of 1.8 points in BLEU score, as compared with a strong forest-to-string baseline system. 1 Introduction Rule generalization remains a key challenge for current syntax-based statistical machine translation (SMT) systems. On the one hand, there is a tendency to integrate richer syntactic information into a translation rule in order to better express the translation phenomena. Thus, flat phrases (Koehn et al., 2003), hierarchical phrases (Chiang, 2005), and syntactic tree fragments (Galley et al., 2006; Mi and Huang, 2008; Wu et al., 2010) are gradually used in SMT. On the other hand, the use of syntactic phrases continues due to the requirement for phrase coverage in most syntax-based systems. For example, 22 Mi et al. (2008) achieved a 3.1-point improvement in BLEU score (Papineni et al., 2002) by including bilingual syntactic phrases in their forest-based system. Compared with flat phrases, syntactic rules are good at capturing global reordering, which has been reported to be essential for translating between languages with substantial structural differences, such as English and Japanese, which is a subject-objectverb langua"
P11-1003,N09-1028,0,0.0420268,"gradually used in SMT. On the other hand, the use of syntactic phrases continues due to the requirement for phrase coverage in most syntax-based systems. For example, 22 Mi et al. (2008) achieved a 3.1-point improvement in BLEU score (Papineni et al., 2002) by including bilingual syntactic phrases in their forest-based system. Compared with flat phrases, syntactic rules are good at capturing global reordering, which has been reported to be essential for translating between languages with substantial structural differences, such as English and Japanese, which is a subject-objectverb language (Xu et al., 2009). Forest-based translation frameworks, which make use of packed parse forests on the source and/or target language side(s), are an increasingly promising approach to syntax-based SMT, being both algorithmically appealing (Mi et al., 2008) and empirically successful (Mi and Huang, 2008; Liu et al., 2009). However, forest-based translation systems, and, in general, most linguistically syntax-based SMT systems (Galley et al., 2004; Galley et al., 2006; Liu et al., 2006; Zhang et al., 2007; Mi et al., 2008; Liu et al., 2009; Chiang, 2010), are built upon word aligned parallel sentences and thus sh"
P11-1003,2007.mtsummit-papers.71,0,0.0466022,"with substantial structural differences, such as English and Japanese, which is a subject-objectverb language (Xu et al., 2009). Forest-based translation frameworks, which make use of packed parse forests on the source and/or target language side(s), are an increasingly promising approach to syntax-based SMT, being both algorithmically appealing (Mi et al., 2008) and empirically successful (Mi and Huang, 2008; Liu et al., 2009). However, forest-based translation systems, and, in general, most linguistically syntax-based SMT systems (Galley et al., 2004; Galley et al., 2006; Liu et al., 2006; Zhang et al., 2007; Mi et al., 2008; Liu et al., 2009; Chiang, 2010), are built upon word aligned parallel sentences and thus share a critical dependence on word alignments. For example, even a single spurious word alignment can invalidate a large number of otherwise extractable rules, and unaligned words can result in an exponentially large set of extractable rules for the interpretation of these unaligned words (Galley et al., 2006). What makes word alignment so fragile? In order to investigate this problem, we manually analyzed the alignments of the first 100 parallel sentences in our English-Japanese traini"
P11-1003,P06-1077,0,\N,Missing
P12-1110,D07-1022,0,0.0208608,"Missing"
P12-1110,P04-1015,0,0.256701,"ark (2010), the POS tag is assigned to the word when its first character is shifted, and the word–tag pairs observed in the training data and the closed-set tags (Xia, 2000) are used to prune (1) All subtrees spanning M consecutive characters unlikely derivations. Because 33 tags are defined in have the same index 2M − 1. the CTB tag set (Xia, 2000), our model exploits a (2) All terminal states have the same step index 2N total of 36 actions. (including the root arc), where N is the number To train the model, we use the averaged percepof characters in the sentence. tron with the early update (Collins and Roark, 2004). (3) Every action increases the index. In our joint model, the early update is invoked by Note that the number of shifted characters is also mistakes in any of word segmentation, POS tagging, necessary to meet condition (3). Otherwise, it allows or dependency parsing. an unlimited number of SH(t) actions without incrementing the step index. Figure 1 portrays how the 3.2 Alignment of States states are aligned using the proposed scheme, where When dependency parsing is integrated into the task a subtree is denoted as a rectangle with its partial of joint word segmentation and POS tagging, it is"
P12-1110,D07-1098,0,0.0272609,"st setting we found is σp = 0.5: this result suggests that we probably should resolve remaining errors by preferentially using the local n-gram based features at the early stage of training. Otherwise, the premature incorporation of the non-local syntactic dependencies might engender overfitting to the training data. 4 4.1 Experiment Experimental Settings We use the Chinese Penn Treebank ver. 5.1, 6.0, and 7.0 (hereinafter CTB-5, CTB-6, and CTB-7) for evaluation. These corpora are split into training, development, and test sets, according to previous works. For CTB-5, we refer to the split by Duan et al. (2007) as CTB-5d, and to the split by Jiang et al. (2008) as CTB-5j. We also prepare a dataset for cross validation: the dataset CTB-5c consists of sentences from CTB-5 excluding the development and test sets of CTB-5d and CTB-5j. We split CTB5c into five sets (CTB-5c-n), and alternatively use four of these as the training set and the rest as the test set. CTB-6 is split according to the official split described in the documentation, and CTB-7 is split according to Wang et al. (2011). The statistics of these splits are shown in Table 2. As external dictionaries, we use the HowNet Word List3 , consis"
P12-1110,P08-1043,0,0.0320765,"Missing"
P12-1110,I11-1136,1,0.801089,"their model is practically ten times as fast as their original model. To incorporate the word-level features into the character-based decoder, the features are decomposed into substring-level features, which are effective for incomplete words to have comparable scores to complete words in the beam. Because we found that even an incremental approach with beam search is intractable if we perform the wordbased decoding, we take a character-based approach to produce our joint model. The incremental framework of our model is based on the joint POS tagging and dependency parsing model for Chinese (Hatori et al., 2011), which is an extension of the shift-reduce dependency parser with dynamic programming (Huang and Sagae, 2010). They specifically modified the shift action so that it assigns the POS tag when a word is shifted onto the stack. However, because they regarded word segmentation as given, their model did not consider the interaction between segmentation and POS tagging. 3 Model 3.1 Incremental Joint Segmentation, POS Tagging, and Dependency Parsing Based on the joint POS tagging and dependency parsing model by Hatori et al. (2011), we build our joint model to solve word segmentation, POS tagging, a"
P12-1110,P10-1110,0,0.192797,"ese characters causes numerous oversegmentation errors for OOV words. Based on these observations, we aim at building a joint model that simultaneously processes word segmentation, POS tagging, and dependency parsing, trying to capture global interaction among 1045 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1045–1053, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics these three tasks. To handle the increased computational complexity, we adopt the incremental parsing framework with dynamic programming (Huang and Sagae, 2010), and propose an efficient method of character-based decoding over candidate structures. Two major challenges exist in formalizing the joint segmentation and dependency parsing task in the character-based incremental framework. First, we must address the problem of how to align comparable states effectively in the beam. Because the number of dependency arcs varies depending on how words are segmented, we devise a step alignment scheme using the number of character-based arcs, which enables effective joint decoding for the three tasks. Second, although the feature set is fundamentally a combina"
P12-1110,P08-1102,0,0.0101226,"sts that we probably should resolve remaining errors by preferentially using the local n-gram based features at the early stage of training. Otherwise, the premature incorporation of the non-local syntactic dependencies might engender overfitting to the training data. 4 4.1 Experiment Experimental Settings We use the Chinese Penn Treebank ver. 5.1, 6.0, and 7.0 (hereinafter CTB-5, CTB-6, and CTB-7) for evaluation. These corpora are split into training, development, and test sets, according to previous works. For CTB-5, we refer to the split by Duan et al. (2007) as CTB-5d, and to the split by Jiang et al. (2008) as CTB-5j. We also prepare a dataset for cross validation: the dataset CTB-5c consists of sentences from CTB-5 excluding the development and test sets of CTB-5d and CTB-5j. We split CTB5c into five sets (CTB-5c-n), and alternatively use four of these as the training set and the rest as the test set. CTB-6 is split according to the official split described in the documentation, and CTB-7 is split according to Wang et al. (2011). The statistics of these splits are shown in Table 2. As external dictionaries, we use the HowNet Word List3 , consisting of 91,015 words, and page names from the Chine"
P12-1110,P09-1058,0,0.0291533,"to peace-operation-related groups. 1 Introduction In processing natural languages that do not include delimiters (e.g. spaces) between words, word segmentation is the crucial first step that is necessary to perform virtually all NLP tasks. Furthermore, the word-level information is often augmented with the POS tags, which, along with segmentation, form the basic foundation of statistical NLP. Because the tasks of word segmentation and POS tagging have strong interactions, many studies have been devoted to the task of joint word segmentation and POS tagging for languages such as Chinese (e.g. Kruengkrai et al. (2009)). This is because some of the segmentation ambiguities cannot be resolved without considering the surrounding grammatical constructions encoded in a sequence of POS tags. The joint approach to word segmentation and POS tagging has been reported to improve word segmentation and POS tagging accuracies by more than âS the only difference is the existence of the last word ; however, whether or not this word exists changes the whole syntactic structure and segmentation of the sentence. This is an example in which word segmentation cannot be handled properly without considering long-range syntactic"
P12-1110,D11-1109,0,0.170218,"Missing"
P12-1110,W03-1025,0,0.220404,"Missing"
P12-1110,P94-1010,0,0.471525,"Missing"
P12-1110,P11-1139,0,0.0620577,"Missing"
P12-1110,I11-1035,0,0.116556,"are split into training, development, and test sets, according to previous works. For CTB-5, we refer to the split by Duan et al. (2007) as CTB-5d, and to the split by Jiang et al. (2008) as CTB-5j. We also prepare a dataset for cross validation: the dataset CTB-5c consists of sentences from CTB-5 excluding the development and test sets of CTB-5d and CTB-5j. We split CTB5c into five sets (CTB-5c-n), and alternatively use four of these as the training set and the rest as the test set. CTB-6 is split according to the official split described in the documentation, and CTB-7 is split according to Wang et al. (2011). The statistics of these splits are shown in Table 2. As external dictionaries, we use the HowNet Word List3 , consisting of 91,015 words, and page names from the Chinese Wikipedia4 as of Oct 26, 2011, consisting of 709,352 words. These dictionaries only consist of word forms with no frequency or POS information. We use standard measures of word-level precision, recall, and F1 score, for evaluating each task. The output of dependencies cannot be correct unless the syntactic head and dependent of the dependency relation are both segmented correctly. Following the standard setting in dependency"
P12-1110,P08-1101,0,0.0702245,"an existing morphological analyzer. In addition, the lattice does not include word segmentation ambiguities crossing boundaries of space-delimited tokens. In contrast, because the Chinese language does not have spaces between words, we fundamentally need to consider the lattice structure of the whole sentence. Therefore, we place no restriction on the segmentation possibilities to consider, and we assess the full potential of the joint segmentation and dependency parsing model. Among the many recent works on joint segmentation and POS tagging for Chinese, the linear-time incremental models by Zhang and Clark (2008) and Zhang and Clark (2010) largely inspired our model. Zhang and Clark (2008) proposed an incremental joint segmentation and POS tagging model, with an effective feature set for Chinese. However, it requires to computationally expensive multiple beams to compare words of different lengths using beam search. More recently, Zhang and Clark (2010) proposed an efficient character-based decoder for their word-based model. In their new model, a single beam suffices for decoding; hence, they reported that their model is practically ten times as fast as their original model. To incorporate the word-l"
P12-1110,D10-1082,0,0.120486,"haracter-based decoding over candidate structures. Two major challenges exist in formalizing the joint segmentation and dependency parsing task in the character-based incremental framework. First, we must address the problem of how to align comparable states effectively in the beam. Because the number of dependency arcs varies depending on how words are segmented, we devise a step alignment scheme using the number of character-based arcs, which enables effective joint decoding for the three tasks. Second, although the feature set is fundamentally a combination of those used in previous works (Zhang and Clark, 2010; Huang and Sagae, 2010), to integrate them in a single incremental framework is not straightforward. Because we must perform decisions of three kinds (segmentation, tagging, and parsing) in an incremental framework, we must adjust which features are to be activated when, and how they are combined with which action labels. We have also found that we must balance the learning rate between features for segmentation and tagging decisions, and those for dependency parsing. We perform experiments using the Chinese Treebank (CTB) corpora, demonstrating that the accuracies of the three tasks can be i"
P12-1110,P11-2033,0,0.0886955,"Missing"
P12-1110,J96-3004,0,\N,Missing
P12-3022,J07-2003,0,0.0770155,"uracies of Akamon and the baseline systems on the NTCIR-9 English-to-Japanese translation task (Wu et al., 2011b). * stands for only using 2 million parallel sentences of the total 3 million data. Here, HPSG forests were used in Akamon. SRILM • language models: Akamon can make use of one or many n-gram language models trained by using SRILM5 (Stolcke, 2002) or the Berkeley language model toolkit, berkeleylm-1.0b36 (Pauls and Klein, 2011). The weights of multiple language models are tuned under minimum error rate training (MERT) (Och, 2003). • pruning: traditional beam-pruning and cubepruning (Chiang, 2007) techniques are incorporated in Akamon to make decoding feasible for large-scale rule sets. Before decoding, we also perform the marginal probability-based inside-outside algorithm based pruning (Mi et al., 2008) on the original parsing forest to control the decoding time. • MERT: Akamon has its own MERT module which optimizes weights of the features so as to maximize some automatic evaluation metric, such as BLEU (Papineni et al., 2002), on a development set. 5 6 http://www.speech.sri.com/projects/srilm/ http://code.google.com/p/berkeleylm/ 129 dev f.seg.lw clean dev.e tokenize e.clean f.clea"
P12-3022,P05-1067,0,0.201691,"g PCFG trees (Galley et al., 2004) and HPSG trees/forests (Wu et al., 2010). 1 Introduction Syntax-based statistical machine translation (SMT) systems have achieved promising improvements in recent years. Depending on the type of input, the systems are divided into two categories: stringbased systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006; Shen et al., 2008), and tree/forest-based systems whose input is already a parse tree or a packed forest to be directly converted into a target tree or string (Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009; Wu et al., 2010; Wu et al., 2011a). ∗ Work done when all the authors were in The University of Tokyo. Depending on whether or not parsers are explicitly used for obtaining linguistically annotated data during training, the systems are also divided into two categories: formally syntax-based systems that do not use additional parsers (Wu, 1997; Chiang, 2005; Xiong et al., 2006), and linguistically syntax-based systems that use PCFG parsers (Liu et al., 2006; Huang et al., 2006; Ga"
P12-3022,I11-1153,1,0.853242,"penal2 3 izes word order mistakes. In this table, Akamon-Forest differs from Akamon-Comb by using different configurations: Akamon-Forest used only 2/3 of the total training data (limited by the experiment environments and time). Akamon-Comb represents the system combination result by combining Akamon-Forest and other phrase-based SMT systems, which made use of pre-ordering methods of head finalization as described in (Isozaki et al., 2010b) and used the total 3 million training data. The detail of the pre-ordering approach and the combination method can be found in (Sudoh et al., 2011) and (Duh et al., 2011). Also, Moses (hierarchical) stands for the hierarchical phrase-based SMT system and Moses (phrase) stands for the flat phrase-based SMT system. For intuitive comparison (note that the result achieved by Google is only for reference and not a comparison, since it uses a different and unknown training data) and following (Goto et al., 2011), the scores achieved by using the Google online translation system4 are also listed in this table. Here is a brief description of Akamon’s main features: Code available at https://sites.google.com/site/xianchaowu2012 Code available at http://www.kecl.ntt.co."
P12-3022,N04-1035,0,0.544876,"ft.com Abstract We describe Akamon, an open source toolkit for tree and forest-based statistical machine translation (Liu et al., 2006; Mi et al., 2008; Mi and Huang, 2008). Akamon implements all of the algorithms required for tree/forestto-string decoding using tree-to-string translation rules: multiple-thread forest-based decoding, n-gram language model integration, beam- and cube-pruning, k-best hypotheses extraction, and minimum error rate training. In terms of tree-to-string translation rule extraction, the toolkit implements the traditional maximum likelihood algorithm using PCFG trees (Galley et al., 2004) and HPSG trees/forests (Wu et al., 2010). 1 Introduction Syntax-based statistical machine translation (SMT) systems have achieved promising improvements in recent years. Depending on the type of input, the systems are divided into two categories: stringbased systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006; Shen et al., 2008), and tree/forest-based systems whose input is already a parse tree or a packed forest to be directly converted into a target tree or string (Ding and Palmer, 2005; Quirk et al"
P12-3022,P06-1121,0,0.42834,"otheses extraction, and minimum error rate training. In terms of tree-to-string translation rule extraction, the toolkit implements the traditional maximum likelihood algorithm using PCFG trees (Galley et al., 2004) and HPSG trees/forests (Wu et al., 2010). 1 Introduction Syntax-based statistical machine translation (SMT) systems have achieved promising improvements in recent years. Depending on the type of input, the systems are divided into two categories: stringbased systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006; Shen et al., 2008), and tree/forest-based systems whose input is already a parse tree or a packed forest to be directly converted into a target tree or string (Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009; Wu et al., 2010; Wu et al., 2011a). ∗ Work done when all the authors were in The University of Tokyo. Depending on whether or not parsers are explicitly used for obtaining linguistically annotated data during training, the systems are also divided into two categories: formally syntax-based systems t"
P12-3022,W05-1506,0,0.0386043,"ch optimizes weights of the features so as to maximize some automatic evaluation metric, such as BLEU (Papineni et al., 2002), on a development set. 5 6 http://www.speech.sri.com/projects/srilm/ http://code.google.com/p/berkeleylm/ 129 dev f.seg.lw clean dev.e tokenize e.clean f.clean dev.f word segmentation e.tok Enju i.e., first construct a translation forest by applying the tree-to-string translation rules to the original parsing forest of the source sentence, and then collect k-best hypotheses for the root node(s) of the translation forest using Algorithm 2 or Algorithm 3 as described in (Huang and Chiang, 2005). Later, the k-best hypotheses are used both for parameter tuning on additional development set(s) and for final optimal translation result extracting. pre-processing word segment tokenize GIZA++ e.forests alignment f.seg lowercase e.tok.lw lowercase f.seg.lw Enju rule extraction e.forests N-gram LM Rule set Akamon Decoder (MERT) Figure 1: Training and tuning process of the Akamon system. Here, e = source English language, f = target foreign language. • translation rule extraction: as former mentioned, we extract tree-to-string translation rules for Akamon. In particular, we implemented the GH"
P12-3022,2006.amta-papers.8,0,0.0880683,"et al., 2010). 1 Introduction Syntax-based statistical machine translation (SMT) systems have achieved promising improvements in recent years. Depending on the type of input, the systems are divided into two categories: stringbased systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006; Shen et al., 2008), and tree/forest-based systems whose input is already a parse tree or a packed forest to be directly converted into a target tree or string (Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009; Wu et al., 2010; Wu et al., 2011a). ∗ Work done when all the authors were in The University of Tokyo. Depending on whether or not parsers are explicitly used for obtaining linguistically annotated data during training, the systems are also divided into two categories: formally syntax-based systems that do not use additional parsers (Wu, 1997; Chiang, 2005; Xiong et al., 2006), and linguistically syntax-based systems that use PCFG parsers (Liu et al., 2006; Huang et al., 2006; Galley et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zh"
P12-3022,D10-1092,0,0.106682,"Missing"
P12-3022,W10-1736,0,0.0606869,"forest-based translations in the past several years without re-implementing the systems or general algorithms from scratch. 2 Akamon Toolkit Features Limited by the successful parsing rate and coverage of linguistic phrases, Akamon currently achieves comparable translation accuracies compared with the most frequently used SMT baseline system, Moses (Koehn et al., 2007). Table 2 shows the automatic translation accuracies (case-sensitive) of Akamon and Moses. Besides BLEU and NIST score, we further list RIBES score3 , , i.e., the software implementation of Normalized Kendall’s τ as proposed by (Isozaki et al., 2010a) to automatically evaluate the translation between distant language pairs based on rank correlation coefficients and significantly penal2 3 izes word order mistakes. In this table, Akamon-Forest differs from Akamon-Comb by using different configurations: Akamon-Forest used only 2/3 of the total training data (limited by the experiment environments and time). Akamon-Comb represents the system combination result by combining Akamon-Forest and other phrase-based SMT systems, which made use of pre-ordering methods of head finalization as described in (Isozaki et al., 2010b) and used the total 3"
P12-3022,P07-2045,0,0.0219959,"extraction (Galley et al., 2004; Mi and Huang, 2008; Wu et al., 2010; Wu et al., 2011a) and tree/forest-based decoding (Liu et al., 2006; Mi et al., 2008). We hope this system will help related researchers to catch up with the achievements of tree/forest-based translations in the past several years without re-implementing the systems or general algorithms from scratch. 2 Akamon Toolkit Features Limited by the successful parsing rate and coverage of linguistic phrases, Akamon currently achieves comparable translation accuracies compared with the most frequently used SMT baseline system, Moses (Koehn et al., 2007). Table 2 shows the automatic translation accuracies (case-sensitive) of Akamon and Moses. Besides BLEU and NIST score, we further list RIBES score3 , , i.e., the software implementation of Normalized Kendall’s τ as proposed by (Isozaki et al., 2010a) to automatically evaluate the translation between distant language pairs based on rank correlation coefficients and significantly penal2 3 izes word order mistakes. In this table, Akamon-Forest differs from Akamon-Comb by using different configurations: Akamon-Forest used only 2/3 of the total training data (limited by the experiment environments"
P12-3022,P09-1063,0,0.0771927,"Missing"
P12-3022,P09-1065,0,0.0305507,"Missing"
P12-3022,D08-1022,0,0.676027,"-based statistical machine translation (SMT) systems have achieved promising improvements in recent years. Depending on the type of input, the systems are divided into two categories: stringbased systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006; Shen et al., 2008), and tree/forest-based systems whose input is already a parse tree or a packed forest to be directly converted into a target tree or string (Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009; Wu et al., 2010; Wu et al., 2011a). ∗ Work done when all the authors were in The University of Tokyo. Depending on whether or not parsers are explicitly used for obtaining linguistically annotated data during training, the systems are also divided into two categories: formally syntax-based systems that do not use additional parsers (Wu, 1997; Chiang, 2005; Xiong et al., 2006), and linguistically syntax-based systems that use PCFG parsers (Liu et al., 2006; Huang et al., 2006; Galley et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009), HPSG parsers (Wu e"
P12-3022,P10-1145,0,0.0900326,"Missing"
P12-3022,P08-1023,0,0.455039,"troduction Syntax-based statistical machine translation (SMT) systems have achieved promising improvements in recent years. Depending on the type of input, the systems are divided into two categories: stringbased systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006; Shen et al., 2008), and tree/forest-based systems whose input is already a parse tree or a packed forest to be directly converted into a target tree or string (Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009; Wu et al., 2010; Wu et al., 2011a). ∗ Work done when all the authors were in The University of Tokyo. Depending on whether or not parsers are explicitly used for obtaining linguistically annotated data during training, the systems are also divided into two categories: formally syntax-based systems that do not use additional parsers (Wu, 1997; Chiang, 2005; Xiong et al., 2006), and linguistically syntax-based systems that use PCFG parsers (Liu et al., 2006; Huang et al., 2006; Galley et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009)"
P12-3022,J03-1002,0,0.00652201,"g and Decoding Frameworks Figure 1 shows the training and tuning progress of the Akamon system. Given original bilingual parallel corpora, we first tokenize and lowercase the source and target sentences (e.g., word segmentation of Chinese and Japanese, punctuation segmentation of English). The pre-processed monolingual sentences will be used by SRILM (Stolcke, 2002) or BerkeleyLM (Pauls and Klein, 2011) to train a n-gram language model. In addition, we filter out too long sentences here, i.e., only relatively short sentence pairs will be used to train word alignments. Then, we can use GIZA++ (Och and Ney, 2003) and symmetric strategies, such as grow-diag-final (Koehn et al., 2007), on the tokenized parallel corpus to obtain a wordaligned parallel corpus. The source sentence and its packed forest, the target sentence, and the word alignment are used for tree-to-string translation rule extraction. Since a 1best tree is a special case of a packed forest, we will focus on using the term ‘forest’ in the continuing discussion. Then, taking the target language model, the rule set, and the preprocessed development set as inputs, we perform MERT on the decoder to tune the weights of the features. The Akamon"
P12-3022,P03-1021,0,0.036344,"e.tok f.seg lowercase lowercase e.tok.lw Table 2: Translation accuracies of Akamon and the baseline systems on the NTCIR-9 English-to-Japanese translation task (Wu et al., 2011b). * stands for only using 2 million parallel sentences of the total 3 million data. Here, HPSG forests were used in Akamon. SRILM • language models: Akamon can make use of one or many n-gram language models trained by using SRILM5 (Stolcke, 2002) or the Berkeley language model toolkit, berkeleylm-1.0b36 (Pauls and Klein, 2011). The weights of multiple language models are tuned under minimum error rate training (MERT) (Och, 2003). • pruning: traditional beam-pruning and cubepruning (Chiang, 2007) techniques are incorporated in Akamon to make decoding feasible for large-scale rule sets. Before decoding, we also perform the marginal probability-based inside-outside algorithm based pruning (Mi et al., 2008) on the original parsing forest to control the decoding time. • MERT: Akamon has its own MERT module which optimizes weights of the features so as to maximize some automatic evaluation metric, such as BLEU (Papineni et al., 2002), on a development set. 5 6 http://www.speech.sri.com/projects/srilm/ http://code.google.co"
P12-3022,P02-1040,0,0.0860203,"in, 2011). The weights of multiple language models are tuned under minimum error rate training (MERT) (Och, 2003). • pruning: traditional beam-pruning and cubepruning (Chiang, 2007) techniques are incorporated in Akamon to make decoding feasible for large-scale rule sets. Before decoding, we also perform the marginal probability-based inside-outside algorithm based pruning (Mi et al., 2008) on the original parsing forest to control the decoding time. • MERT: Akamon has its own MERT module which optimizes weights of the features so as to maximize some automatic evaluation metric, such as BLEU (Papineni et al., 2002), on a development set. 5 6 http://www.speech.sri.com/projects/srilm/ http://code.google.com/p/berkeleylm/ 129 dev f.seg.lw clean dev.e tokenize e.clean f.clean dev.f word segmentation e.tok Enju i.e., first construct a translation forest by applying the tree-to-string translation rules to the original parsing forest of the source sentence, and then collect k-best hypotheses for the root node(s) of the translation forest using Algorithm 2 or Algorithm 3 as described in (Huang and Chiang, 2005). Later, the k-best hypotheses are used both for parameter tuning on additional development set(s) and"
P12-3022,P11-1027,0,0.0837387,".2773 0.2799 0.3948 NIST 6.830 7.795 7.881 6.905 7.258 8.713 RIBES 0.6991 0.7200 0.7068 0.6619 0.6861 0.7813 corpus e.tok f.seg lowercase lowercase e.tok.lw Table 2: Translation accuracies of Akamon and the baseline systems on the NTCIR-9 English-to-Japanese translation task (Wu et al., 2011b). * stands for only using 2 million parallel sentences of the total 3 million data. Here, HPSG forests were used in Akamon. SRILM • language models: Akamon can make use of one or many n-gram language models trained by using SRILM5 (Stolcke, 2002) or the Berkeley language model toolkit, berkeleylm-1.0b36 (Pauls and Klein, 2011). The weights of multiple language models are tuned under minimum error rate training (MERT) (Och, 2003). • pruning: traditional beam-pruning and cubepruning (Chiang, 2007) techniques are incorporated in Akamon to make decoding feasible for large-scale rule sets. Before decoding, we also perform the marginal probability-based inside-outside algorithm based pruning (Mi et al., 2008) on the original parsing forest to control the decoding time. • MERT: Akamon has its own MERT module which optimizes weights of the features so as to maximize some automatic evaluation metric, such as BLEU (Papineni"
P12-3022,P05-1034,0,0.271418,"al., 2004) and HPSG trees/forests (Wu et al., 2010). 1 Introduction Syntax-based statistical machine translation (SMT) systems have achieved promising improvements in recent years. Depending on the type of input, the systems are divided into two categories: stringbased systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006; Shen et al., 2008), and tree/forest-based systems whose input is already a parse tree or a packed forest to be directly converted into a target tree or string (Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009; Wu et al., 2010; Wu et al., 2011a). ∗ Work done when all the authors were in The University of Tokyo. Depending on whether or not parsers are explicitly used for obtaining linguistically annotated data during training, the systems are also divided into two categories: formally syntax-based systems that do not use additional parsers (Wu, 1997; Chiang, 2005; Xiong et al., 2006), and linguistically syntax-based systems that use PCFG parsers (Liu et al., 2006; Huang et al., 2006; Galley et al., 2006; M"
P12-3022,P08-1066,0,0.103141,"nd minimum error rate training. In terms of tree-to-string translation rule extraction, the toolkit implements the traditional maximum likelihood algorithm using PCFG trees (Galley et al., 2004) and HPSG trees/forests (Wu et al., 2010). 1 Introduction Syntax-based statistical machine translation (SMT) systems have achieved promising improvements in recent years. Depending on the type of input, the systems are divided into two categories: stringbased systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006; Shen et al., 2008), and tree/forest-based systems whose input is already a parse tree or a packed forest to be directly converted into a target tree or string (Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009; Wu et al., 2010; Wu et al., 2011a). ∗ Work done when all the authors were in The University of Tokyo. Depending on whether or not parsers are explicitly used for obtaining linguistically annotated data during training, the systems are also divided into two categories: formally syntax-based systems that do not use addit"
P12-3022,2011.eamt-1.3,0,0.0197478,"icients and significantly penal2 3 izes word order mistakes. In this table, Akamon-Forest differs from Akamon-Comb by using different configurations: Akamon-Forest used only 2/3 of the total training data (limited by the experiment environments and time). Akamon-Comb represents the system combination result by combining Akamon-Forest and other phrase-based SMT systems, which made use of pre-ordering methods of head finalization as described in (Isozaki et al., 2010b) and used the total 3 million training data. The detail of the pre-ordering approach and the combination method can be found in (Sudoh et al., 2011) and (Duh et al., 2011). Also, Moses (hierarchical) stands for the hierarchical phrase-based SMT system and Moses (phrase) stands for the flat phrase-based SMT system. For intuitive comparison (note that the result achieved by Google is only for reference and not a comparison, since it uses a different and unknown training data) and following (Goto et al., 2011), the scores achieved by using the Google online translation system4 are also listed in this table. Here is a brief description of Akamon’s main features: Code available at https://sites.google.com/site/xianchaowu2012 Code available at"
P12-3022,P10-1034,1,0.357096,"ource toolkit for tree and forest-based statistical machine translation (Liu et al., 2006; Mi et al., 2008; Mi and Huang, 2008). Akamon implements all of the algorithms required for tree/forestto-string decoding using tree-to-string translation rules: multiple-thread forest-based decoding, n-gram language model integration, beam- and cube-pruning, k-best hypotheses extraction, and minimum error rate training. In terms of tree-to-string translation rule extraction, the toolkit implements the traditional maximum likelihood algorithm using PCFG trees (Galley et al., 2004) and HPSG trees/forests (Wu et al., 2010). 1 Introduction Syntax-based statistical machine translation (SMT) systems have achieved promising improvements in recent years. Depending on the type of input, the systems are divided into two categories: stringbased systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006; Shen et al., 2008), and tree/forest-based systems whose input is already a parse tree or a packed forest to be directly converted into a target tree or string (Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al.,"
P12-3022,P11-1003,1,0.433477,"achieved promising improvements in recent years. Depending on the type of input, the systems are divided into two categories: stringbased systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006; Shen et al., 2008), and tree/forest-based systems whose input is already a parse tree or a packed forest to be directly converted into a target tree or string (Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009; Wu et al., 2010; Wu et al., 2011a). ∗ Work done when all the authors were in The University of Tokyo. Depending on whether or not parsers are explicitly used for obtaining linguistically annotated data during training, the systems are also divided into two categories: formally syntax-based systems that do not use additional parsers (Wu, 1997; Chiang, 2005; Xiong et al., 2006), and linguistically syntax-based systems that use PCFG parsers (Liu et al., 2006; Huang et al., 2006; Galley et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009), HPSG parsers (Wu et al., 2010; Wu et al., 2011a), or dependency parsers"
P12-3022,J97-3002,0,0.0325341,"cube-pruning, k-best hypotheses extraction, and minimum error rate training. In terms of tree-to-string translation rule extraction, the toolkit implements the traditional maximum likelihood algorithm using PCFG trees (Galley et al., 2004) and HPSG trees/forests (Wu et al., 2010). 1 Introduction Syntax-based statistical machine translation (SMT) systems have achieved promising improvements in recent years. Depending on the type of input, the systems are divided into two categories: stringbased systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006; Shen et al., 2008), and tree/forest-based systems whose input is already a parse tree or a packed forest to be directly converted into a target tree or string (Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009; Wu et al., 2010; Wu et al., 2011a). ∗ Work done when all the authors were in The University of Tokyo. Depending on whether or not parsers are explicitly used for obtaining linguistically annotated data during training, the systems are also divided into two categori"
P12-3022,P06-1066,0,0.128388,"nput is already a parse tree or a packed forest to be directly converted into a target tree or string (Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009; Wu et al., 2010; Wu et al., 2011a). ∗ Work done when all the authors were in The University of Tokyo. Depending on whether or not parsers are explicitly used for obtaining linguistically annotated data during training, the systems are also divided into two categories: formally syntax-based systems that do not use additional parsers (Wu, 1997; Chiang, 2005; Xiong et al., 2006), and linguistically syntax-based systems that use PCFG parsers (Liu et al., 2006; Huang et al., 2006; Galley et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009), HPSG parsers (Wu et al., 2010; Wu et al., 2011a), or dependency parsers (Ding and Palmer, 2005; Quirk et al., 2005; Shen et al., 2008). A classification1 of syntax-based SMT systems is shown in Table 1. Translation rules can be extracted from aligned string-string (Chiang, 2005), tree-tree (Ding and Palmer, 2005) and tree/forest-string (Galley et al., 2004; Mi and Huang, 2008; Wu et al., 2011a) data structures. Lev"
P12-3022,P09-1020,0,0.0219495,"achine translation (SMT) systems have achieved promising improvements in recent years. Depending on the type of input, the systems are divided into two categories: stringbased systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006; Shen et al., 2008), and tree/forest-based systems whose input is already a parse tree or a packed forest to be directly converted into a target tree or string (Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009; Wu et al., 2010; Wu et al., 2011a). ∗ Work done when all the authors were in The University of Tokyo. Depending on whether or not parsers are explicitly used for obtaining linguistically annotated data during training, the systems are also divided into two categories: formally syntax-based systems that do not use additional parsers (Wu, 1997; Chiang, 2005; Xiong et al., 2006), and linguistically syntax-based systems that use PCFG parsers (Liu et al., 2006; Huang et al., 2006; Galley et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zhang et al., 2009), HPSG parsers (Wu et al., 2010; Wu et a"
P12-3022,P06-1077,0,\N,Missing
P12-3022,P05-1033,0,\N,Missing
P13-1103,C04-1180,0,0.155143,"dependency parsing is applied and then semantic role labeling is performed on the dependencies (Sasano and Kurohashi, 2011; Kawahara and Kurohashi, 2011; Kudo and Matsumoto, 2002; Iida and Poesio, 2011; Hayashibe et al., 2011). This dominance is mainly because chunkbased dependency analysis looks most appropriate for Japanese syntax due to its morphosyntactic typology, which includes agglutination and scrambling (Bekki, 2010). However, it is also true that this type of analysis has prevented us from deeper syntactic analysis such as deep parsing (Clark and Curran, 2007) and logical inference (Bos et al., 2004; Bos, 2007), both of which have been surpassing shallow parsing-based approaches in languages like English. In this paper, we present our work on inducing wide-coverage Japanese resources based on combinatory categorial grammar (CCG) (Steedman, 2001). Our work is basically an extension of a seminal work on CCGbank (Hockenmaier and Steedman, 2007), in which the phrase structure trees of the Penn Treebank (PTB) (Marcus et al., 1993) are converted into CCG derivations and a wide-coverage CCG lexicon is then extracted from these derivations. As CCGbank has enabled a variety of outstanding works o"
P13-1103,P05-2013,0,0.658358,"Missing"
P13-1103,J07-4004,0,0.109849,"dependency-based pipeline in which chunk-based dependency parsing is applied and then semantic role labeling is performed on the dependencies (Sasano and Kurohashi, 2011; Kawahara and Kurohashi, 2011; Kudo and Matsumoto, 2002; Iida and Poesio, 2011; Hayashibe et al., 2011). This dominance is mainly because chunkbased dependency analysis looks most appropriate for Japanese syntax due to its morphosyntactic typology, which includes agglutination and scrambling (Bekki, 2010). However, it is also true that this type of analysis has prevented us from deeper syntactic analysis such as deep parsing (Clark and Curran, 2007) and logical inference (Bos et al., 2004; Bos, 2007), both of which have been surpassing shallow parsing-based approaches in languages like English. In this paper, we present our work on inducing wide-coverage Japanese resources based on combinatory categorial grammar (CCG) (Steedman, 2001). Our work is basically an extension of a seminal work on CCGbank (Hockenmaier and Steedman, 2007), in which the phrase structure trees of the Penn Treebank (PTB) (Marcus et al., 1993) are converted into CCG derivations and a wide-coverage CCG lexicon is then extracted from these derivations. As CCGbank has"
P13-1103,hanaoka-etal-2010-japanese,1,0.904346,"Missing"
P13-1103,I11-1023,0,0.0377645,"ces are dependency-based. Our method first integrates multiple dependency-based corpora into phrase structure trees and then converts the trees into CCG derivations. The method is empirically evaluated in terms of the coverage of the obtained lexicon and the accuracy of parsing. 1 Introduction Syntactic parsing for Japanese has been dominated by a dependency-based pipeline in which chunk-based dependency parsing is applied and then semantic role labeling is performed on the dependencies (Sasano and Kurohashi, 2011; Kawahara and Kurohashi, 2011; Kudo and Matsumoto, 2002; Iida and Poesio, 2011; Hayashibe et al., 2011). This dominance is mainly because chunkbased dependency analysis looks most appropriate for Japanese syntax due to its morphosyntactic typology, which includes agglutination and scrambling (Bekki, 2010). However, it is also true that this type of analysis has prevented us from deeper syntactic analysis such as deep parsing (Clark and Curran, 2007) and logical inference (Bos et al., 2004; Bos, 2007), both of which have been surpassing shallow parsing-based approaches in languages like English. In this paper, we present our work on inducing wide-coverage Japanese resources based on combinatory"
P13-1103,J07-3004,0,0.654,"due to its morphosyntactic typology, which includes agglutination and scrambling (Bekki, 2010). However, it is also true that this type of analysis has prevented us from deeper syntactic analysis such as deep parsing (Clark and Curran, 2007) and logical inference (Bos et al., 2004; Bos, 2007), both of which have been surpassing shallow parsing-based approaches in languages like English. In this paper, we present our work on inducing wide-coverage Japanese resources based on combinatory categorial grammar (CCG) (Steedman, 2001). Our work is basically an extension of a seminal work on CCGbank (Hockenmaier and Steedman, 2007), in which the phrase structure trees of the Penn Treebank (PTB) (Marcus et al., 1993) are converted into CCG derivations and a wide-coverage CCG lexicon is then extracted from these derivations. As CCGbank has enabled a variety of outstanding works on wide-coverage deep parsing for English, our resources are expected to significantly contribute to Japanese deep parsing. The application of the CCGbank method to Japanese is not trivial, as resources like PTB are not available in Japanese. The widely used resources for parsing research are the Kyoto corpus (Kawahara et al., 2002) and the NAIST t"
P13-1103,P06-1064,0,0.109969,"treebank of Japanese. We largely extended their work by exploiting the standard chunk-based Japanese corpora and demonstrated the first results for Japanese deep parsing with grammar induced from large corpora. Corpus-based acquisition of wide-coverage CCG resources has enjoyed great success for English (Hockenmaier and Steedman, 2007). In that method, PTB was converted into CCG-based derivations from which a wide-coverage CCG lexicon was extracted. CCGbank has been used for the development of wide-coverage CCG parsers (Clark and Curran, 2007). The same methodology has been applied to German (Hockenmaier, 2006), Italian (Bos et al., 2009), and Turkish (C¸akıcı, 2005). Their treebanks are annotated with dependencies of words, the conversion of which into phrase structures is not a big concern. A notable contribution of the present work is a method for inducing CCG grammars from chunk-based dependency structures, which is not obvious, as we discuss later in this paper. CCG parsing provides not only predicate argument relations but also CCG derivations, which can be used for various semantic processing tasks (Bos et al., 2004; Bos, 2007). Our work constitutes a starting point for such deep linguistic p"
P13-1103,P11-1081,0,0.0302296,"panese syntactic resources are dependency-based. Our method first integrates multiple dependency-based corpora into phrase structure trees and then converts the trees into CCG derivations. The method is empirically evaluated in terms of the coverage of the obtained lexicon and the accuracy of parsing. 1 Introduction Syntactic parsing for Japanese has been dominated by a dependency-based pipeline in which chunk-based dependency parsing is applied and then semantic role labeling is performed on the dependencies (Sasano and Kurohashi, 2011; Kawahara and Kurohashi, 2011; Kudo and Matsumoto, 2002; Iida and Poesio, 2011; Hayashibe et al., 2011). This dominance is mainly because chunkbased dependency analysis looks most appropriate for Japanese syntax due to its morphosyntactic typology, which includes agglutination and scrambling (Bekki, 2010). However, it is also true that this type of analysis has prevented us from deeper syntactic analysis such as deep parsing (Clark and Curran, 2007) and logical inference (Bos et al., 2004; Bos, 2007), both of which have been surpassing shallow parsing-based approaches in languages like English. In this paper, we present our work on inducing wide-coverage Japanese resour"
P13-1103,W07-1522,0,0.0261019,"he phrase structure trees of the Penn Treebank (PTB) (Marcus et al., 1993) are converted into CCG derivations and a wide-coverage CCG lexicon is then extracted from these derivations. As CCGbank has enabled a variety of outstanding works on wide-coverage deep parsing for English, our resources are expected to significantly contribute to Japanese deep parsing. The application of the CCGbank method to Japanese is not trivial, as resources like PTB are not available in Japanese. The widely used resources for parsing research are the Kyoto corpus (Kawahara et al., 2002) and the NAIST text corpus (Iida et al., 2007), both of which are based on the dependency structures of chunks. Moreover, the relation between chunk-based dependency structures and CCG derivations is not obvious. In this work, we propose a method to integrate multiple dependency-based corpora into phrase structure trees augmented with predicate argument relations. We can then convert the phrase structure trees into CCG derivations. In the following, we describe the details of the integration method as well as Japanese-specific issues in the conversion into CCG derivations. The method is empirically evaluated in terms of the quality of the"
P13-1103,I11-1051,0,0.0253575,"ese have not been widely studied, mainly because most Japanese syntactic resources are dependency-based. Our method first integrates multiple dependency-based corpora into phrase structure trees and then converts the trees into CCG derivations. The method is empirically evaluated in terms of the coverage of the obtained lexicon and the accuracy of parsing. 1 Introduction Syntactic parsing for Japanese has been dominated by a dependency-based pipeline in which chunk-based dependency parsing is applied and then semantic role labeling is performed on the dependencies (Sasano and Kurohashi, 2011; Kawahara and Kurohashi, 2011; Kudo and Matsumoto, 2002; Iida and Poesio, 2011; Hayashibe et al., 2011). This dominance is mainly because chunkbased dependency analysis looks most appropriate for Japanese syntax due to its morphosyntactic typology, which includes agglutination and scrambling (Bekki, 2010). However, it is also true that this type of analysis has prevented us from deeper syntactic analysis such as deep parsing (Clark and Curran, 2007) and logical inference (Bos et al., 2004; Bos, 2007), both of which have been surpassing shallow parsing-based approaches in languages like English. In this paper, we present o"
P13-1103,kawahara-etal-2002-construction,0,0.0285141,"Gbank (Hockenmaier and Steedman, 2007), in which the phrase structure trees of the Penn Treebank (PTB) (Marcus et al., 1993) are converted into CCG derivations and a wide-coverage CCG lexicon is then extracted from these derivations. As CCGbank has enabled a variety of outstanding works on wide-coverage deep parsing for English, our resources are expected to significantly contribute to Japanese deep parsing. The application of the CCGbank method to Japanese is not trivial, as resources like PTB are not available in Japanese. The widely used resources for parsing research are the Kyoto corpus (Kawahara et al., 2002) and the NAIST text corpus (Iida et al., 2007), both of which are based on the dependency structures of chunks. Moreover, the relation between chunk-based dependency structures and CCG derivations is not obvious. In this work, we propose a method to integrate multiple dependency-based corpora into phrase structure trees augmented with predicate argument relations. We can then convert the phrase structure trees into CCG derivations. In the following, we describe the details of the integration method as well as Japanese-specific issues in the conversion into CCG derivations. The method is empiri"
P13-1103,W02-2016,0,0.789644,"ed, mainly because most Japanese syntactic resources are dependency-based. Our method first integrates multiple dependency-based corpora into phrase structure trees and then converts the trees into CCG derivations. The method is empirically evaluated in terms of the coverage of the obtained lexicon and the accuracy of parsing. 1 Introduction Syntactic parsing for Japanese has been dominated by a dependency-based pipeline in which chunk-based dependency parsing is applied and then semantic role labeling is performed on the dependencies (Sasano and Kurohashi, 2011; Kawahara and Kurohashi, 2011; Kudo and Matsumoto, 2002; Iida and Poesio, 2011; Hayashibe et al., 2011). This dominance is mainly because chunkbased dependency analysis looks most appropriate for Japanese syntax due to its morphosyntactic typology, which includes agglutination and scrambling (Bekki, 2010). However, it is also true that this type of analysis has prevented us from deeper syntactic analysis such as deep parsing (Clark and Curran, 2007) and logical inference (Bos et al., 2004; Bos, 2007), both of which have been surpassing shallow parsing-based approaches in languages like English. In this paper, we present our work on inducing wide-c"
P13-1103,J93-2004,0,0.0433915,"However, it is also true that this type of analysis has prevented us from deeper syntactic analysis such as deep parsing (Clark and Curran, 2007) and logical inference (Bos et al., 2004; Bos, 2007), both of which have been surpassing shallow parsing-based approaches in languages like English. In this paper, we present our work on inducing wide-coverage Japanese resources based on combinatory categorial grammar (CCG) (Steedman, 2001). Our work is basically an extension of a seminal work on CCGbank (Hockenmaier and Steedman, 2007), in which the phrase structure trees of the Penn Treebank (PTB) (Marcus et al., 1993) are converted into CCG derivations and a wide-coverage CCG lexicon is then extracted from these derivations. As CCGbank has enabled a variety of outstanding works on wide-coverage deep parsing for English, our resources are expected to significantly contribute to Japanese deep parsing. The application of the CCGbank method to Japanese is not trivial, as resources like PTB are not available in Japanese. The widely used resources for parsing research are the Kyoto corpus (Kawahara et al., 2002) and the NAIST text corpus (Iida et al., 2007), both of which are based on the dependency structures o"
P13-1103,J08-1002,1,0.869855,"Missing"
P13-1103,J05-1004,0,0.0607126,"3 Step 2-2, 2-3 NPni せ CAUSE ＜ に DAT た PAST ＜ T1 交渉 negotiation VP T/T S NPni PP Aux Noun Step 2-1 S ＜ Scont＼NPni Svo_s＼NPni に DAT Svo_s＼NPni 参加 participation Sbase＼Scont Scont＼Svo_s た PAST Svo_s＼Svo_s せ CAUSE さ do Figure 9: A phrase structure into a CCG derivation. In the figure, the annotation given in the two corpora is shown inside the dotted box at the bottom. We converted the predicate-argument annotations given as labeled word-to-word dependencies into the relations between the predicate words and their argument phrases. The results are thus similar to the annotation style of PropBank (Palmer et al., 2005). In the NAIST corpus, each pred-arg relation is labeled with the argument-type (ga/o/ni) and a flag indicating that the relation is mediated by either a syntactic dependency or a zero anaphora. For a relation of a predicate wp and its argument wa in the NAIST corpus, the boundary of the argument phrase is determined as follows: 1. If wa precedes wp and the relation is mediated by a syntactic dep., select the maximum PP that is formed by attaching one or more postpositions to the NP headed by wa . 2. If wp precedes wa or the relation is mediated by a zero anaphora, select the maximum NP headed"
P13-1103,I11-1085,0,0.0137283,"e languages, those for Japanese have not been widely studied, mainly because most Japanese syntactic resources are dependency-based. Our method first integrates multiple dependency-based corpora into phrase structure trees and then converts the trees into CCG derivations. The method is empirically evaluated in terms of the coverage of the obtained lexicon and the accuracy of parsing. 1 Introduction Syntactic parsing for Japanese has been dominated by a dependency-based pipeline in which chunk-based dependency parsing is applied and then semantic role labeling is performed on the dependencies (Sasano and Kurohashi, 2011; Kawahara and Kurohashi, 2011; Kudo and Matsumoto, 2002; Iida and Poesio, 2011; Hayashibe et al., 2011). This dominance is mainly because chunkbased dependency analysis looks most appropriate for Japanese syntax due to its morphosyntactic typology, which includes agglutination and scrambling (Bekki, 2010). However, it is also true that this type of analysis has prevented us from deeper syntactic analysis such as deep parsing (Clark and Curran, 2007) and logical inference (Bos et al., 2004; Bos, 2007), both of which have been surpassing shallow parsing-based approaches in languages like Englis"
P13-1103,P09-2013,0,0.033705,"Missing"
P13-1103,W02-1210,0,0.191891,"Missing"
P13-1103,P07-1031,0,0.0702006,"se corpora―namely, the Kyoto corpus, the NAIST text corpus, and the JP corpus ―into a phrase structure treebank, which is similar in spirit to PTB. Our approach is to convert the dependency structures of the Kyoto corpus into phrase structures and then augment them with syntactic/semantic roles from the other two corpora. The conversion involves two steps: 1) recognizing the chunk-internal structures, and (2) converting inter-chunk dependencies into phrase structures. For 1), we don’t have any explicit information in the Kyoto corpus although, in principle, each chunk has internal structures (Vadas and Curran, 2007; Yamada et al., 2010). The lack of a chunk-internal structure makes the dependencyto-constituency conversion more complex than a similar procedure by Bos et al. (2009) that converts an Italian dependency treebank into constituency trees since their dependency trees are annotated down to the level of each word. For the current implementation, we abandon the idea of identifying exact structures and instead basically rely on the following generic rules (Fig. 6): Nominal chunks Compound nouns are first formed as a right-branching phrase and post-positions are then attached to it. Verbal chunks Ve"
P13-1103,P05-2024,0,0.0296169,"ng is fairly limited. Formal theories of Japanese syntax were presented by Gunji (1987) based on Head-driven Phrase Structure Grammar (HPSG) (Sag et al., 2003) and by Komagata (1999) based on CCG, although their implementations in real-world parsing have not been very successful. JACY (Siegel 1 In fact, the NAIST text corpus includes additional texts, but in this work we only use the news text section. 1044 and Bender, 2002) is a large-scale Japanese grammar based on HPSG, but its semantics is tightly embedded in the grammar and it is not as easy to systematically switch them as it is in CCG. Yoshida (2005) proposed methods for extracting a wide-coverage lexicon based on HPSG from a phrase structure treebank of Japanese. We largely extended their work by exploiting the standard chunk-based Japanese corpora and demonstrated the first results for Japanese deep parsing with grammar induced from large corpora. Corpus-based acquisition of wide-coverage CCG resources has enjoyed great success for English (Hockenmaier and Steedman, 2007). In that method, PTB was converted into CCG-based derivations from which a wide-coverage CCG lexicon was extracted. CCGbank has been used for the development of wide-c"
P14-1008,E09-1025,0,0.0537802,"Missing"
P14-1008,W09-0208,0,0.0205201,"Missing"
P14-1008,D12-1058,0,0.0257949,"Missing"
P14-1008,S13-1002,0,0.025353,"Selection operators are implemented as markers assigned to abstract denotations, with specially designed axioms. For example superlatives satisfy the following property: A ⊂ B & shighest (B) ⊂ A ⇒ shighest (B) = shighest (A). New rules can be added if necessary. T/H Abstract denotations DCS trees Language resources Inference On-the-fly knowledge Yes/No Axioms Figure 4: RTE system tic expressions, and apply distributional similarity to judge their validity. In this way, our framework combines distributional and logical semantics, which is also the main subject of Lewis and Steedman (2013) and Beltagy et al. (2013). As follows, our full system (Figure 4) additionally invokes linguistic knowledge on-the-fly: Coreference We use Stanford CoreNLP to resolve coreferences (Raghunathan et al., 2010), whereas coreference is implemented as a special type of selection. If a node σ in a DCS tree T belongs to a mention cluster m, we take the abstract denotation [[Tσ ]] and make a selection sm ([[Tσ ]]), which is regarded as the abstract denotation of that mention. Then all selections of the same mention cluster are declared to be equal. 3 Parsing Coreference 4. If H is not proven, compare DCS trees of T and H, and"
P14-1008,H05-1049,0,0.10417,"Missing"
P14-1008,D13-1160,0,0.0654843,"Missing"
P14-1008,N10-1145,0,0.0314724,"Missing"
P14-1008,H05-1079,0,0.0660109,"s blamed for deaths. H: A storm has caused loss of life. The germ OBJ(blame) and germ ARG(death) in DCS tree of T are joined by the underscored path. Two paths are aligned if the joined germs are aligned, and we impose constraints on aligned germs to inhibit meaningless alignments, as described below. However, this method does not work for realworld datasets such as PASCAL RTE (Dagan et al., 2006), because of the knowledge bottleneck: it is often the case that the lack of sufficient linguistic knowledge causes failure of inference, thus the system outputs “no entailment” for almost all pairs (Bos and Markert, 2005). The transparent syntax-to-semantics interface of DCS enables us to back off to NLP techniques during inference for catching up the lack of knowledge. We extract fragments of DCS trees as paraphrase candidates, translate them back to linguis3.2 Aligning germs by logical clues Two germs are aligned if they are both at leaf nodes (e.g. ARG(death) in T and ARG(life) in H, Figure 5), or they already have part of their meanings in common, by some logical clues. 83 T : OBJ ARG Debby ARG ARG storm ARG MOD blame IOBJ ARG death H : storm, Debby, [[ Whatandis tropical is blamed for death ]] cause ARG S"
P14-1008,D13-1161,0,0.0450047,"Missing"
P14-1008,P13-1042,0,0.0158794,"Missing"
P14-1008,Q13-1015,0,0.132113,"here sf is a selection marker. Selection operators are implemented as markers assigned to abstract denotations, with specially designed axioms. For example superlatives satisfy the following property: A ⊂ B & shighest (B) ⊂ A ⇒ shighest (B) = shighest (A). New rules can be added if necessary. T/H Abstract denotations DCS trees Language resources Inference On-the-fly knowledge Yes/No Axioms Figure 4: RTE system tic expressions, and apply distributional similarity to judge their validity. In this way, our framework combines distributional and logical semantics, which is also the main subject of Lewis and Steedman (2013) and Beltagy et al. (2013). As follows, our full system (Figure 4) additionally invokes linguistic knowledge on-the-fly: Coreference We use Stanford CoreNLP to resolve coreferences (Raghunathan et al., 2010), whereas coreference is implemented as a special type of selection. If a node σ in a DCS tree T belongs to a mention cluster m, we take the abstract denotation [[Tσ ]] and make a selection sm ([[Tσ ]]), which is regarded as the abstract denotation of that mention. Then all selections of the same mention cluster are declared to be equal. 3 Parsing Coreference 4. If H is not proven, compare"
P14-1008,P11-1060,0,0.132622,"efined as: n  [[T ]] = w(σ) ∩ ( ιri (πri0 ([[Tτi ]])) × WRσ i ), Non-emptiness A 6= ∅: the set A is not empty. Subsumption A ⊂ B: set A is subsumed by B.3 i=1 Roughly speaking, the relations correspond to the logical concepts satisfiability and entailment. 4 Negation and disjointness (“k”) are explained in §2.5. http://nlp.stanford.edu/software/ corenlp.shtml 6 In (Liang et al., 2011) DCS trees are learned from QA pairs and database entries. We obtain DCS trees from dependency trees, to bypass the need of a concrete database. 7 The definition differs slightly from the original Liang et al. (2011), mainly for the sake of simplicity and clarity. 5 2 If A and B has the same dimension, q⊂ (A, B) is either ∅ or {∗} (0-dimension point set), depending on if A ⊂ B. 3 Using division operator, subsumption can be represented by non-emptiness, since for sets A, B of the same dimension, q⊂ (A, B) 6= ∅ ⇔ A ⊂ B. 81 πOBJ (F6 ) = dog ∩ F7 T F6 6= ∅ T dog ⊂ πOBJ (F2 ) Axiom 4 dog ⊂ animal Axiom 8 dog ⊂ F3 dog ∩ F7 6= ∅ dog ∩ F7 ⊂ F3 ∩ F7 πOBJ (F4 ) = F3 ∩ F7 F3 ∩ F7 6= ∅ Axiom 6 Axiom 4 F4 6= ∅ Figure 3: An example of proof using abstract denotations 1. 2. 3. 4. W 6= ∅ A∩B ⊂A r Br × q⊂ (A, B) ⊂ A πR (A"
P14-1008,W07-1431,0,0.250248,"), we output “yes” if H is proven, or try to prove the negation of H if H is not proven. To negate H, we use the root negation as described in §2.5. If the negation of H is proven, we output “no”, otherwise we output “unknown”. The result is shown in Table 4. Since our system uses an off-the-shelf dependency parser, and semantic representations are obtained from simple rule-based conversion from dependency trees, there will be only one (right or wrong) interpretation in face of ambiguous sentences. Still, our system outperforms Lewis and Steedman (2013)’s probabilistic CCG-parser. Compared to MacCartney and Manning (2007) and MacCartney and Manning (2008), our system does not need a pretrained alignment model, and it improves by making multi-sentence inferences. To sum up, the result shows that DCS is good at handling universal quantifiers and negations. Most errors are due to wrongly generated DCS trees (e.g. wrongly assigned semantic roles) or unimplemented quantifier triggers (e.g. “neither”) or generalized quantifiers (e.g. “at least a few”). These could be addressed by future work. Experiments In this section, we evaluate our system on FraCaS (§4.2) and PASCAL RTE datasets (§4.3). 4.1 Language Resources T"
P14-1008,C08-1066,0,0.42732,"gation of H if H is not proven. To negate H, we use the root negation as described in §2.5. If the negation of H is proven, we output “no”, otherwise we output “unknown”. The result is shown in Table 4. Since our system uses an off-the-shelf dependency parser, and semantic representations are obtained from simple rule-based conversion from dependency trees, there will be only one (right or wrong) interpretation in face of ambiguous sentences. Still, our system outperforms Lewis and Steedman (2013)’s probabilistic CCG-parser. Compared to MacCartney and Manning (2007) and MacCartney and Manning (2008), our system does not need a pretrained alignment model, and it improves by making multi-sentence inferences. To sum up, the result shows that DCS is good at handling universal quantifiers and negations. Most errors are due to wrongly generated DCS trees (e.g. wrongly assigned semantic roles) or unimplemented quantifier triggers (e.g. “neither”) or generalized quantifiers (e.g. “at least a few”). These could be addressed by future work. Experiments In this section, we evaluate our system on FraCaS (§4.2) and PASCAL RTE datasets (§4.3). 4.1 Language Resources The lexical knowledge we use are sy"
P14-1008,P13-1131,0,0.0199019,"Missing"
P14-1008,W04-3206,0,0.0533051,"Missing"
P14-1008,N13-1090,0,0.0608526,"Missing"
P14-1008,P07-1058,0,0.0264103,"is proven, or try to prove the negation of H if H is not proven. To negate H, we use the root negation as described in §2.5. If the negation of H is proven, we output “no”, otherwise we output “unknown”. The result is shown in Table 4. Since our system uses an off-the-shelf dependency parser, and semantic representations are obtained from simple rule-based conversion from dependency trees, there will be only one (right or wrong) interpretation in face of ambiguous sentences. Still, our system outperforms Lewis and Steedman (2013)’s probabilistic CCG-parser. Compared to MacCartney and Manning (2007) and MacCartney and Manning (2008), our system does not need a pretrained alignment model, and it improves by making multi-sentence inferences. To sum up, the result shows that DCS is good at handling universal quantifiers and negations. Most errors are due to wrongly generated DCS trees (e.g. wrongly assigned semantic roles) or unimplemented quantifier triggers (e.g. “neither”) or generalized quantifiers (e.g. “at least a few”). These could be addressed by future work. Experiments In this section, we evaluate our system on FraCaS (§4.2) and PASCAL RTE datasets (§4.3). 4.1 Language Resources T"
P14-1008,H05-1047,0,0.0901183,"Missing"
P14-1008,N07-1071,0,0.0267031,"Missing"
P14-1008,P06-2105,0,0.0401589,"Missing"
P14-1008,P13-1092,0,0.0114834,"Missing"
P14-1008,P10-1040,0,0.00435916,"Missing"
P14-1008,D10-1048,0,0.00528686,"& shighest (B) ⊂ A ⇒ shighest (B) = shighest (A). New rules can be added if necessary. T/H Abstract denotations DCS trees Language resources Inference On-the-fly knowledge Yes/No Axioms Figure 4: RTE system tic expressions, and apply distributional similarity to judge their validity. In this way, our framework combines distributional and logical semantics, which is also the main subject of Lewis and Steedman (2013) and Beltagy et al. (2013). As follows, our full system (Figure 4) additionally invokes linguistic knowledge on-the-fly: Coreference We use Stanford CoreNLP to resolve coreferences (Raghunathan et al., 2010), whereas coreference is implemented as a special type of selection. If a node σ in a DCS tree T belongs to a mention cluster m, we take the abstract denotation [[Tσ ]] and make a selection sm ([[Tσ ]]), which is regarded as the abstract denotation of that mention. Then all selections of the same mention cluster are declared to be equal. 3 Parsing Coreference 4. If H is not proven, compare DCS trees of T and H, and generate path alignments. 5. Aligned paths are evaluated by a similarity score to estimate their likelihood of being paraphrases. Path alignments with scores higher than a threshold"
P14-1008,C10-1131,0,0.050771,"Missing"
P14-1008,D12-1018,0,0.00909485,"Missing"
P14-1008,N06-1005,0,0.0594277,"Missing"
P14-1008,P13-1045,0,0.00800173,"n ⊂ πSUBJ (die) dog ⊂ animal all criminals commit criminal ⊂ πSUBJ (commit∩ a crime (WSUBJ × crimeOBJ )) rise k fall no dogs are hurt dog k πOBJ (hurt) Abstract denotations and statements are convenient for representing semantics of various types of expressions and linguistic knowledge. Some examples are shown in Table 2.4 2.4 Based on abstract denotations, we briefly describe our process to apply DCS to textual inference. Table 2: Abstract denotations and statements 2.4.1 Natural language to DCS trees To obtain DCS trees from natural language, we use Stanford CoreNLP5 for dependency parsing (Socher et al., 2013), and convert Stanford dependencies to DCS trees by pattern matching on POS tags and dependency labels.6 Currently we use the following semantic roles: ARG, SUBJ, OBJ, IOBJ, TIME and MOD. The semantic role MOD is used for any restrictive modifiers. Determiners such as “all”, “every” and “each” trigger quantifiers, as shown in Figure 2. • Content words: a content word (e.g. read) defines a set representing the word (e.g. read = {(x, y) |read(x, y)}). In addition we introduce following functions: • ×: the Cartesian product of two sets. • ∩: the intersection of two sets. • πr : projection onto do"
P14-1008,R11-1063,0,0.0483574,"Missing"
P14-1008,P12-1030,0,0.0343029,"Missing"
P14-1008,P03-1029,0,0.0284226,"Missing"
P14-1008,N13-1007,0,\N,Missing
P15-2024,D10-1092,0,0.12896,"Missing"
P15-2024,laoudi-etal-2006-task,0,0.055194,"Missing"
P15-2024,C04-1072,0,0.379528,"Missing"
P15-2024,P02-1040,0,0.103529,"ed to the subjects’ native language. A largescale experiment involving 320 subjects revealed that the context-unawareness of the current MT systems severely damages human performance when solving the test problems, while one of the evaluated MT systems performed as good as a human translation produced in a context-unaware condition. An analysis of the experimental results showed that the extrinsic evaluation captured a different dimension of translation quality than that captured by manual and automatic intrinsic evaluation. 1 Introduction Automatic evaluation metrics, such as the BLEU score (Papineni et al., 2002), were crucial ingredients for the advances of machine translation technology in the last decade. Meanwhile, the shortcomings of BLEU and similar n-gram proximitybased metrics have been pointed out by many authors including Callison-Burch et al. (2006). The main criticisms include: 1) unreliability in evaluating short translations, 2) non-interpretability of the scores beyond numerical comparison, and 3) bias towards statistical MT systems. Manual evaluation of translation quality is more reliable in many regards, but it is costly. Furthermore, it is not necessarily easy to analyze the charact"
P15-2024,2010.iwslt-papers.16,0,0.0499505,"Missing"
P15-2024,2006.amta-papers.25,0,0.059344,"of problems were different among the subjects, they were designed such that the number of subjects who solve each translated problem was roughly the same. Each subject was given 12 sheets of paper, each of which showed a problem and its answer choices, and was given one minute to complete each problem. # of subjects that correctly answered M(p) 0.4 Correct Answer Rate 2.5 Procedure CARM (p) = 0.2 1 ∑ CARM (p). |P | p∈P 2.7 Intrinsic Evaluations Automatic Evaluation Metrics We also evaluated the translation quality using BLEU, BLEU+1 (Lin and Och, 2004), RIBES (Isozaki et al., 2010), and TER (Snover et al., 2006). We prepared two sorts of reference translations: RefS and RefO . RefS consisted of two manual translations of the 40 problems produced by method HS . RefO consisted of three manual translations produced in the normal way, i.e., by HO . 3.2 System-level Evaluation We first present the system-level evaluation results for the four translation methods. Figure 2 shows the min/max and the quartiles of the correct answer rates (CARs) for the 40 problems translated by each system. The averages of the correct answer rates are 0.524, 0.696, 0.693, and 0.875 for each translation system G, Y , HS , and"
P15-2024,E06-1032,0,0.0470481,"ystems performed as good as a human translation produced in a context-unaware condition. An analysis of the experimental results showed that the extrinsic evaluation captured a different dimension of translation quality than that captured by manual and automatic intrinsic evaluation. 1 Introduction Automatic evaluation metrics, such as the BLEU score (Papineni et al., 2002), were crucial ingredients for the advances of machine translation technology in the last decade. Meanwhile, the shortcomings of BLEU and similar n-gram proximitybased metrics have been pointed out by many authors including Callison-Burch et al. (2006). The main criticisms include: 1) unreliability in evaluating short translations, 2) non-interpretability of the scores beyond numerical comparison, and 3) bias towards statistical MT systems. Manual evaluation of translation quality is more reliable in many regards, but it is costly. Furthermore, it is not necessarily easy to analyze the characteristics of MT systems based solely on the evaluation results such as a 5-point scale evaluation of adequacy/fluency and a ranking of the outputs of different systems. 145 Proceedings of the 53rd Annual Meeting of the Association for Computational Ling"
P15-2024,2006.eamt-1.25,0,0.105198,"Missing"
P15-2024,W10-1703,0,0.0340523,"icipants’ grade levels and scholastic abilities (including English ability) did not affect the test results. . The extrinsic evaluation score of translation method M is the average of CAR over P : Avg-CARM = 0.8 Human Evaluation Five native Japanese speakers ranked the translations by the four systems for each of the 40 problems. They were shown the translations of a problem by the four methods with its source problem in English and asked to give a relative ranking among them, such as “G &lt; Y &lt; HS = HO .” This method was adapted from the manual evaluation conducted in the recent WMT workshops (Callison-Burch et al., 2010). The relative ranking was broken down into six (= 4 C2 ) binary relations. For each relation “A &gt; B” found in the broken-down relations, one point was added to system A. The final ranking among the systems for a problem was determined by the total points. 2.6 Extrinsic Evaluation Metric # of subjects who solved M(p) 0.6 Figure 2: Boxplots of Correct Answer Rates for 40 Problems Each subject was given 12 different problems that consisted of an equal number (3) of translated problems produced by the four translation methods. Although the sets of problems were different among the subjects, they"
P15-2024,N07-2020,0,\N,Missing
P17-1195,D14-1058,0,0.154454,"ogant and attractive idea of seeing a natural language as a formal language. The automation of end-to-end math problem solving thus has an outstanding status in the research themes in natural language processing. The conceptual basis has been laid down, which connects text to the truth (= answer) through reasoning. However, we have not seen a fully automated system that instantiates it end-to-end. We wish to add a piece to the big picture by materializing it. Past studies have mainly targeted at primary school level arithmetic word problems (Bobrow, 1964; Charniak, 1969; Kushman et al., 2014; Hosseini et al., 2014; Shi et al., 2015; Roy and Roth, 2015; Zhou et al., 2015; Koncel-Kedziorski et al., 2015; Mitra and Baral, 2016; Upadhyay et al., 2016). In their nature, arithmetic questions are quantifier-free. Moreover they tend to include only ∧ (and) as the logical connective. The main challenge in these works was to extract simple numerical relations (most typically equations) from a real-world scenario described in a text. Seo et al. (2015) took SAT geometry questions as their benchmark. However, the nature of SAT geometry questions restricts the resulting formula’s complexity. In §3, we will show that"
P17-1195,D10-1119,0,0.0412134,"Missing"
P17-1195,D11-1140,0,0.0126532,"? ?? ???? ?? ? ?? ∖ ?? ???? ?? ? ∖ ?? ∖ ?? ? ∖ ?? ? ?? ?∖? ? Figure 4: Bunsetsu dependency structure (top) and CCG derivation tree (bottom) 7 Math Expression Analysis n&gt;0 Naomi ga Two-step Semantic Parsing Two central issues in parsing are the cost of the search and the accuracy of disambiguation. Supervised learning is commonly used to solve both. It is however very costly to create the training data by manually annotating a large number of sentences with CCG trees. Past studies have tried to bypass it by so-called weak supervision, where a parser is trained only with the logical form (e.g., Kwiatkowski et al. 2011) or even only with the answers to the queries (e.g., Liang et al. 2011). Although the adaptation of such methods to the pre-university math data is an interesting future direction, we developed yet another approach based on a hybrid of shallow dependency parsing and the detailed CCG grammar. The syntactic structure of Japanese sentences has traditionally been analyzed based on the relations among word chunks called bunsetsus. A bunsetsu consists of one or more content words followed by zero or more function words. The dependencies among bunsetsus mostly correspond to the predicate-argument and"
P17-1195,P11-1060,0,0.14829,"Missing"
P17-1195,P16-1202,0,0.396109,"roblem solving thus has an outstanding status in the research themes in natural language processing. The conceptual basis has been laid down, which connects text to the truth (= answer) through reasoning. However, we have not seen a fully automated system that instantiates it end-to-end. We wish to add a piece to the big picture by materializing it. Past studies have mainly targeted at primary school level arithmetic word problems (Bobrow, 1964; Charniak, 1969; Kushman et al., 2014; Hosseini et al., 2014; Shi et al., 2015; Roy and Roth, 2015; Zhou et al., 2015; Koncel-Kedziorski et al., 2015; Mitra and Baral, 2016; Upadhyay et al., 2016). In their nature, arithmetic questions are quantifier-free. Moreover they tend to include only ∧ (and) as the logical connective. The main challenge in these works was to extract simple numerical relations (most typically equations) from a real-world scenario described in a text. Seo et al. (2015) took SAT geometry questions as their benchmark. However, the nature of SAT geometry questions restricts the resulting formula’s complexity. In §3, we will show that none of them includes ∀ (for all), ∨ (or) or → (implies). It suggests that this type of questions require littl"
P17-1195,W02-2016,0,0.160382,"constraint of a dependency tree, it is impractical to do exhaustive search. We use beam search based on a simple score function on the chart items that combines several features such as the number of atomic categories in the item. We also use N -best dependency trees to circumvent the dependency errors. The restricted CKY parsing is repeated on the N -best dependency trees until a CCG tree is obtained. Our hope is to reject a dependency error as violation of the syntactic and semantic constraints encoded in the CCG lexicon. In the experiment, we used a Japanese dependency parser developed by Kudo and Matsumoto (2002). We modified it to produce N -best outputs and used up to 20-best trees per sentence. 8 Global Type Coherency The well-typedness of the logical form is usually guaranteed by the combinatory rules. However, they do not always guarantee the type coherency among the interpretations of the math expressions. For instance, consider the following derivation: if x + y ∈ U, then x + z ∈ V. S/S : λP.(addR (x, y) ∈ U → P ) S : addV (x, y) ∈ V &gt; S : addR (x, y) ∈ U → addV (x, z) ∈ V The + symbol is interpreted as the addition of real numbers (addR ) in the first clause but that of vectors (addV ) in the"
P17-1195,D15-1135,0,0.0867175,"ea of seeing a natural language as a formal language. The automation of end-to-end math problem solving thus has an outstanding status in the research themes in natural language processing. The conceptual basis has been laid down, which connects text to the truth (= answer) through reasoning. However, we have not seen a fully automated system that instantiates it end-to-end. We wish to add a piece to the big picture by materializing it. Past studies have mainly targeted at primary school level arithmetic word problems (Bobrow, 1964; Charniak, 1969; Kushman et al., 2014; Hosseini et al., 2014; Shi et al., 2015; Roy and Roth, 2015; Zhou et al., 2015; Koncel-Kedziorski et al., 2015; Mitra and Baral, 2016; Upadhyay et al., 2016). In their nature, arithmetic questions are quantifier-free. Moreover they tend to include only ∧ (and) as the logical connective. The main challenge in these works was to extract simple numerical relations (most typically equations) from a real-world scenario described in a text. Seo et al. (2015) took SAT geometry questions as their benchmark. However, the nature of SAT geometry questions restricts the resulting formula’s complexity. In §3, we will show that none of them incl"
P17-1195,D16-1029,0,0.249363,"an outstanding status in the research themes in natural language processing. The conceptual basis has been laid down, which connects text to the truth (= answer) through reasoning. However, we have not seen a fully automated system that instantiates it end-to-end. We wish to add a piece to the big picture by materializing it. Past studies have mainly targeted at primary school level arithmetic word problems (Bobrow, 1964; Charniak, 1969; Kushman et al., 2014; Hosseini et al., 2014; Shi et al., 2015; Roy and Roth, 2015; Zhou et al., 2015; Koncel-Kedziorski et al., 2015; Mitra and Baral, 2016; Upadhyay et al., 2016). In their nature, arithmetic questions are quantifier-free. Moreover they tend to include only ∧ (and) as the logical connective. The main challenge in these works was to extract simple numerical relations (most typically equations) from a real-world scenario described in a text. Seo et al. (2015) took SAT geometry questions as their benchmark. However, the nature of SAT geometry questions restricts the resulting formula’s complexity. In §3, we will show that none of them includes ∀ (for all), ∨ (or) or → (implies). It suggests that this type of questions require little need to analyze the lo"
P17-1195,D07-1071,0,0.0202649,"Missing"
P17-1195,D15-1096,0,0.265704,"ormal language. The automation of end-to-end math problem solving thus has an outstanding status in the research themes in natural language processing. The conceptual basis has been laid down, which connects text to the truth (= answer) through reasoning. However, we have not seen a fully automated system that instantiates it end-to-end. We wish to add a piece to the big picture by materializing it. Past studies have mainly targeted at primary school level arithmetic word problems (Bobrow, 1964; Charniak, 1969; Kushman et al., 2014; Hosseini et al., 2014; Shi et al., 2015; Roy and Roth, 2015; Zhou et al., 2015; Koncel-Kedziorski et al., 2015; Mitra and Baral, 2016; Upadhyay et al., 2016). In their nature, arithmetic questions are quantifier-free. Moreover they tend to include only ∧ (and) as the logical connective. The main challenge in these works was to extract simple numerical relations (most typically equations) from a real-world scenario described in a text. Seo et al. (2015) took SAT geometry questions as their benchmark. However, the nature of SAT geometry questions restricts the resulting formula’s complexity. In §3, we will show that none of them includes ∀ (for all), ∨ (or) or → (implies)"
P17-1195,D15-1171,0,\N,Missing
P17-1195,D15-1202,0,\N,Missing
W03-0416,C02-1114,0,\N,Missing
W03-0416,J92-4003,0,\N,Missing
W03-0416,J98-1004,0,\N,Missing
W03-0416,P98-2124,0,\N,Missing
W03-0416,C98-2119,0,\N,Missing
W06-1619,J97-4005,0,0.142664,"verb SUBJ &lt; 1 &gt; COMPS &lt; &gt; come Spring/NN HEAD verb 2 SUBJ &lt; 1 &gt; COMPS &lt;&gt; has/VBZ come/VBN flex= &lt;spring, NN, Figure 1: HPSG parsing. Ã X T0 exp &gt; (2005) also introduced a preliminary probabilistic model p0 (T |w) whose estimation does not require the parsing of a treebank. This model is introduced as a reference distribution of the probabilistic HPSG model; i.e., the computation of parse trees given low probabilities by the model is omitted in the estimation stage. We have ! X 1 exp λu fu (T ) phpsg (T |w) = Zw u Ã X HEAD noun SUBJ &lt;&gt; COMPS &lt;&gt; Figure 2: Example of features. Previous studies (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005) defined a probabilistic model of unification-based grammars including HPSG as a log-linear model or maximum entropy model (Berger et al., 1996). The probability that a parse result T is assigned to a given sentence w = hw1 , . . . , wn i is Zw = HEAD verb SUBJ &lt;NP&gt; COMPS &lt;&gt; (Previous probabilistic HPSG) Ã ! X 1 exp λu fu (T ) phpsg0 (T |w) = p0 (T |w) Zw u ! λu fu (T 0 ) , u where λu is a model parameter, fu is a feature function that represents a characteristic of parse tree"
W06-1619,J99-2004,0,0.501786,"studies vary in the design of the probabilistic models, the fundamental conception of probabilistic modeling is intended to capture characteristics of phrase structures or grammar rules. Although lexical information, such as head words, is known to significantly improve the parsing accuracy, it was also used to augment information on phrase structures. Another interesting approach to this problem was using supertagging (Clark and Curran, 2004b; Clark and Curran, 2004a; Wang and Harper, 2004; Nasr and Rambow, 2004), which was originally developed for lexicalized tree adjoining grammars (LTAG) (Bangalore and Joshi, 1999). Supertagging is a process where words in an input sentence are tagged with ‘supertags,’ which are lexical entries in lexicalized grammars, e.g., elementary trees in LTAG, lexical categories in CCG, and lexical entries in HPSG. Supertagging was, in the first place, a technique to reduce the cost of parsing with lexicalized grammars; ambiguity in assigning lexical entries to words is reduced by the light-weight process of supertagging before the heavy process of parsing. Bangalore and Joshi (1999) claimed that if words can be assigned correct supertags, syntactic parsing is almost trivial. Wha"
W06-1619,J96-1002,0,0.016666,"arsing of a treebank. This model is introduced as a reference distribution of the probabilistic HPSG model; i.e., the computation of parse trees given low probabilities by the model is omitted in the estimation stage. We have ! X 1 exp λu fu (T ) phpsg (T |w) = Zw u Ã X HEAD noun SUBJ &lt;&gt; COMPS &lt;&gt; Figure 2: Example of features. Previous studies (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005) defined a probabilistic model of unification-based grammars including HPSG as a log-linear model or maximum entropy model (Berger et al., 1996). The probability that a parse result T is assigned to a given sentence w = hw1 , . . . , wn i is Zw = HEAD verb SUBJ &lt;NP&gt; COMPS &lt;&gt; (Previous probabilistic HPSG) Ã ! X 1 exp λu fu (T ) phpsg0 (T |w) = p0 (T |w) Zw u ! λu fu (T 0 ) , u where λu is a model parameter, fu is a feature function that represents a characteristic of parse tree T , and Zw is the sum over the set of all possible parse trees for the sentence. Intuitively, the probability is defined as the normalized product of the weights exp(λu ) when a characteristic corresponding to fu appears in parse result T . The model parameters,"
W06-1619,P05-1022,0,0.134381,"Missing"
W06-1619,C04-1041,0,0.527929,"ment of Computer Science University of Tokyo Yoshimasa Tsuruoka School of Informatics University of Manchester Yusuke Miyao Department of Computer Science University of Tokyo Jun’ichi Tsujii Department of Computer Science, University of Tokyo School of Informatics, University of Manchester SORST, Japan Science and Technology Agency Hongo 7-3-1, Bunkyo-ku, Tokyo, 113-0033, Japan {ninomi, matuzaki, tsuruoka, yusuke, tsujii}@is.s.u-tokyo.ac.jp Abstract niak and Johnson, 2005) or over complex phrase structures of head-driven phrase structure grammar (HPSG) or combinatory categorial grammar (CCG) (Clark and Curran, 2004b; Malouf and van Noord, 2004; Miyao and Tsujii, 2005). Although these studies vary in the design of the probabilistic models, the fundamental conception of probabilistic modeling is intended to capture characteristics of phrase structures or grammar rules. Although lexical information, such as head words, is known to significantly improve the parsing accuracy, it was also used to augment information on phrase structures. Another interesting approach to this problem was using supertagging (Clark and Curran, 2004b; Clark and Curran, 2004a; Wang and Harper, 2004; Nasr and Rambow, 2004), which wa"
W06-1619,P05-1011,1,0.474032,"a Tsuruoka School of Informatics University of Manchester Yusuke Miyao Department of Computer Science University of Tokyo Jun’ichi Tsujii Department of Computer Science, University of Tokyo School of Informatics, University of Manchester SORST, Japan Science and Technology Agency Hongo 7-3-1, Bunkyo-ku, Tokyo, 113-0033, Japan {ninomi, matuzaki, tsuruoka, yusuke, tsujii}@is.s.u-tokyo.ac.jp Abstract niak and Johnson, 2005) or over complex phrase structures of head-driven phrase structure grammar (HPSG) or combinatory categorial grammar (CCG) (Clark and Curran, 2004b; Malouf and van Noord, 2004; Miyao and Tsujii, 2005). Although these studies vary in the design of the probabilistic models, the fundamental conception of probabilistic modeling is intended to capture characteristics of phrase structures or grammar rules. Although lexical information, such as head words, is known to significantly improve the parsing accuracy, it was also used to augment information on phrase structures. Another interesting approach to this problem was using supertagging (Clark and Curran, 2004b; Clark and Curran, 2004a; Wang and Harper, 2004; Nasr and Rambow, 2004), which was originally developed for lexicalized tree adjoining"
W06-1619,P04-1014,0,0.410288,"ment of Computer Science University of Tokyo Yoshimasa Tsuruoka School of Informatics University of Manchester Yusuke Miyao Department of Computer Science University of Tokyo Jun’ichi Tsujii Department of Computer Science, University of Tokyo School of Informatics, University of Manchester SORST, Japan Science and Technology Agency Hongo 7-3-1, Bunkyo-ku, Tokyo, 113-0033, Japan {ninomi, matuzaki, tsuruoka, yusuke, tsujii}@is.s.u-tokyo.ac.jp Abstract niak and Johnson, 2005) or over complex phrase structures of head-driven phrase structure grammar (HPSG) or combinatory categorial grammar (CCG) (Clark and Curran, 2004b; Malouf and van Noord, 2004; Miyao and Tsujii, 2005). Although these studies vary in the design of the probabilistic models, the fundamental conception of probabilistic modeling is intended to capture characteristics of phrase structures or grammar rules. Although lexical information, such as head words, is known to significantly improve the parsing accuracy, it was also used to augment information on phrase structures. Another interesting approach to this problem was using supertagging (Clark and Curran, 2004b; Clark and Curran, 2004a; Wang and Harper, 2004; Nasr and Rambow, 2004), which wa"
W06-1619,E03-1071,0,0.0114331,"k and Curran, 2004b). The CCG supertagger uses a maximum entropy classifier and is similar to our model. We evaluated the performance of our probabilistic model as a supertagger. The accuracy of the resulting supertagger on our development set (Section 22) is given in Table 5 and Table 6. The test sentences were automatically POS-tagged. Results of other supertaggers for automatically exWhen compared with other supertag sets of automatically extracted lexicalized grammars, the (effective) size of our supertag set, 1,361 lexical entries, is between the CCG supertag set (398 categories) used by Curran and Clark (2003) and the LTAG supertag set (2920 elementary trees) used by Shen and Joshi (2003). The relative order based on the sizes of the tag sets exactly matches the order based on the accuracies of corresponding supertaggers. 161 ambiguation of phrase structures. We have not yet investigated whether our results can be reproduced with other lexicalized grammars. Our results might hold only for HPSG because HPSG has strict feature constraints and has lexical entries with rich syntactic information such as wh-movement. 5.2 Efficacy of extremely lexicalized models The implemented parsers of models 1 and 2"
W06-1619,W04-3308,0,0.07953,"ar (CCG) (Clark and Curran, 2004b; Malouf and van Noord, 2004; Miyao and Tsujii, 2005). Although these studies vary in the design of the probabilistic models, the fundamental conception of probabilistic modeling is intended to capture characteristics of phrase structures or grammar rules. Although lexical information, such as head words, is known to significantly improve the parsing accuracy, it was also used to augment information on phrase structures. Another interesting approach to this problem was using supertagging (Clark and Curran, 2004b; Clark and Curran, 2004a; Wang and Harper, 2004; Nasr and Rambow, 2004), which was originally developed for lexicalized tree adjoining grammars (LTAG) (Bangalore and Joshi, 1999). Supertagging is a process where words in an input sentence are tagged with ‘supertags,’ which are lexical entries in lexicalized grammars, e.g., elementary trees in LTAG, lexical categories in CCG, and lexical entries in HPSG. Supertagging was, in the first place, a technique to reduce the cost of parsing with lexicalized grammars; ambiguity in assigning lexical entries to words is reduced by the light-weight process of supertagging before the heavy process of parsing. Bangalore and Jos"
W06-1619,P02-1036,0,0.0599348,"he weights exp(λu ) when a characteristic corresponding to fu appears in parse result T . The model parameters, λu , are estimated using numerical optimization methods (Malouf, 2002) to maximize the log-likelihood of the training data. However, the above model cannot be easily estimated because the estimation requires the computation of p(T |w) for all parse candidates assigned to sentence w. Because the number of parse candidates is exponentially related to the length of the sentence, the estimation is intractable for long sentences. To make the model estimation tractable, Geman and Johnson (Geman and Johnson, 2002) and Miyao and Tsujii (Miyao and Tsujii, 2002) proposed a dynamic programming algorithm for estimating p(T |w). Miyao and Tsujii Zw = X Ã 0 p0 (T |w) exp ! 0 λu fu (T ) u T0 p0 (T |w) = X n Y p(li |wi ), i=1 where li is a lexical entry assigned to word wi in T and p(li |wi ) is the probability of selecting lexical entry li for wi . In the experiments, we compared our model with the probabilistic HPSG model of Miyao and Tsujii (2005). The features used in their model are combinations of the feature templates listed in Table 1. The feature templates fbinary and funary are defined for constituent"
W06-1619,W05-1511,1,0.805598,"← α + ∆α; β ← β + ∆β; κ ← κ + ∆κ; δ ← δ + ∆δ; θ ← θ + ∆θ; 4.2 We evaluated the speed and accuracy of parsing with extremely lexicalized models by using Enju 2.1, the HPSG grammar for English (Miyao et al., 2005; Miyao and Tsujii, 2005). The lexicon of the grammar was extracted from Sections 02-21 of the Penn Treebank (Marcus et al., 1994) (39,832 sentences). The grammar consisted of 3,797 lexical entries for 10,536 words1 . The probabilistic models were trained using the same portion of the treebank. We used beam thresholding, global thresholding (Goodman, 1997), preserved iterative parsing (Ninomiya et al., 2005) and other techFigure 3: Pseudo-code of iterative parsing for HPSG. Zw = X exp Ã X l0 ! 0 λu fu (l , w, i) , u where Zw is the sum over all possible lexical entries for the word wi . The feature templates used in our model are listed in Table 2 and are word trigrams and POS 5-grams. 4 Evaluation Experiments 1 An HPSG treebank is automatically generated from the Penn Treebank. Those lexical entries were generated by applying lexical rules to observed lexical entries in the HPSG treebank (Nakanishi et al., 2004). The lexicon, however, included many lexical entries that do not appear in the HPSG"
W06-1619,W97-0302,0,0.1716,", i). The FOM of a newly created partial parse, F , is computed by summing the values of ρ of the daughters and an additional FOM of F if the model is the previous model or model 3. The FOM for models 1 and 2 is computed by only summing the values of ρ of the daughters; i.e., weights exp(λu ) in the figure are assigned zero. The terms κ and δ are the thresholds of the number of phrasal signs in the chart cell and the beam width for signs in the chart cell. The terms α and β are the thresholds of the number and the beam width of lexical entries, and θ is the beam width for global thresholding (Goodman, 1997). Table 2: Features for the probabilities of lexical entry selection. procedure Parsing(hw1 , . . . , wn i, hL, Ri, α, β, κ, δ, θ) for i = 1 to n foreachP F 0 ∈ {F |hwi , F i ∈ L} p= λu fu (F 0 ) u π[i − 1, i] ← π[i − 1, i] ∪ {F 0 } if (p &gt; ρ[i − 1, i, F 0 ]) then ρ[i − 1, i, F 0 ] ← p LocalThresholding(i − 1, i,α, β) for d = 1 to n for i = 0 to n − d j =i+d for k = i + 1 to j − 1 foreach Fs ∈ φ[i, k], Ft ∈ φ[k, j], r ∈ R if F = r(Fs , Ft ) has succeeded P λu fu (F ) p = ρ[i, k, Fs ] + ρ[k, j, Ft ] + u π[i, j] ← π[i, j] ∪ {F } if (p &gt; ρ[i, j, F ]) then ρ[i, j, F ] ← p LocalThresholding(i, j,κ,"
W06-1619,P03-1046,0,0.045596,"f the parser. A predicate-argument relation is defined as a tuple hσ, wh , a, wa i, where σ is the predicate type (e.g., adjective, intransitive verb), wh is the head word of the predicate, a is the argument label (MODARG, ARG1, ..., ARG4), and wa is the head word of the argument. Labeled precision (LP)/labeled recall (LR) is the ratio of tuples correctly identified by the parser3 . Unlabeled precision (UP)/unlabeled recall (UR) is the ratio of tuples without the predicate type and the argument label. This evaluation scheme was the same as used in previous evaluations of lexicalized grammars (Hockenmaier, 2003; Clark and Curran, 2004b; Miyao and Tsujii, 2005). The experiments were conducted on an AMD Opteron server with a 2.4-GHz CPU. Section 22 of the Treebank was used as the development set, and the performance was evaluated using sentences of ≤ 40 and 100 words in Section 23. The performance of each parsing technique was analyzed using the sentences in Section 24 of ≤ 100 words. Table 3 details the numbers and average lengths of the tested sentences of ≤ 40 and 100 words in Sections 23 and 24, and the total numbers of sentences in Sections 23 and 24. The parsing performance for Section 23 is sho"
W06-1619,P99-1069,0,0.0141744,"1 &gt; COMPS &lt; &gt; come Spring/NN HEAD verb 2 SUBJ &lt; 1 &gt; COMPS &lt;&gt; has/VBZ come/VBN flex= &lt;spring, NN, Figure 1: HPSG parsing. Ã X T0 exp &gt; (2005) also introduced a preliminary probabilistic model p0 (T |w) whose estimation does not require the parsing of a treebank. This model is introduced as a reference distribution of the probabilistic HPSG model; i.e., the computation of parse trees given low probabilities by the model is omitted in the estimation stage. We have ! X 1 exp λu fu (T ) phpsg (T |w) = Zw u Ã X HEAD noun SUBJ &lt;&gt; COMPS &lt;&gt; Figure 2: Example of features. Previous studies (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005) defined a probabilistic model of unification-based grammars including HPSG as a log-linear model or maximum entropy model (Berger et al., 1996). The probability that a parse result T is assigned to a given sentence w = hw1 , . . . , wn i is Zw = HEAD verb SUBJ &lt;NP&gt; COMPS &lt;&gt; (Previous probabilistic HPSG) Ã ! X 1 exp λu fu (T ) phpsg0 (T |w) = p0 (T |w) Zw u ! λu fu (T 0 ) , u where λu is a model parameter, fu is a feature function that represents a characteristic of parse tree T , and Zw is the sum"
W06-1619,P00-1061,0,0.0728146,"ing/NN HEAD verb 2 SUBJ &lt; 1 &gt; COMPS &lt;&gt; has/VBZ come/VBN flex= &lt;spring, NN, Figure 1: HPSG parsing. Ã X T0 exp &gt; (2005) also introduced a preliminary probabilistic model p0 (T |w) whose estimation does not require the parsing of a treebank. This model is introduced as a reference distribution of the probabilistic HPSG model; i.e., the computation of parse trees given low probabilities by the model is omitted in the estimation stage. We have ! X 1 exp λu fu (T ) phpsg (T |w) = Zw u Ã X HEAD noun SUBJ &lt;&gt; COMPS &lt;&gt; Figure 2: Example of features. Previous studies (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005) defined a probabilistic model of unification-based grammars including HPSG as a log-linear model or maximum entropy model (Berger et al., 1996). The probability that a parse result T is assigned to a given sentence w = hw1 , . . . , wn i is Zw = HEAD verb SUBJ &lt;NP&gt; COMPS &lt;&gt; (Previous probabilistic HPSG) Ã ! X 1 exp λu fu (T ) phpsg0 (T |w) = p0 (T |w) Zw u ! λu fu (T 0 ) , u where λu is a model parameter, fu is a feature function that represents a characteristic of parse tree T , and Zw is the sum over the set of all po"
W06-1619,N04-1013,0,0.0264089,"e/VBN flex= &lt;spring, NN, Figure 1: HPSG parsing. Ã X T0 exp &gt; (2005) also introduced a preliminary probabilistic model p0 (T |w) whose estimation does not require the parsing of a treebank. This model is introduced as a reference distribution of the probabilistic HPSG model; i.e., the computation of parse trees given low probabilities by the model is omitted in the estimation stage. We have ! X 1 exp λu fu (T ) phpsg (T |w) = Zw u Ã X HEAD noun SUBJ &lt;&gt; COMPS &lt;&gt; Figure 2: Example of features. Previous studies (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005) defined a probabilistic model of unification-based grammars including HPSG as a log-linear model or maximum entropy model (Berger et al., 1996). The probability that a parse result T is assigned to a given sentence w = hw1 , . . . , wn i is Zw = HEAD verb SUBJ &lt;NP&gt; COMPS &lt;&gt; (Previous probabilistic HPSG) Ã ! X 1 exp λu fu (T ) phpsg0 (T |w) = p0 (T |w) Zw u ! λu fu (T 0 ) , u where λu is a model parameter, fu is a feature function that represents a characteristic of parse tree T , and Zw is the sum over the set of all possible parse trees for the sentence. Intuitively,"
W06-1619,P03-1064,0,0.184888,"similar to our model. We evaluated the performance of our probabilistic model as a supertagger. The accuracy of the resulting supertagger on our development set (Section 22) is given in Table 5 and Table 6. The test sentences were automatically POS-tagged. Results of other supertaggers for automatically exWhen compared with other supertag sets of automatically extracted lexicalized grammars, the (effective) size of our supertag set, 1,361 lexical entries, is between the CCG supertag set (398 categories) used by Curran and Clark (2003) and the LTAG supertag set (2920 elementary trees) used by Shen and Joshi (2003). The relative order based on the sizes of the tag sets exactly matches the order based on the accuracies of corresponding supertaggers. 161 ambiguation of phrase structures. We have not yet investigated whether our results can be reproduced with other lexicalized grammars. Our results might hold only for HPSG because HPSG has strict feature constraints and has lexical entries with rich syntactic information such as wh-movement. 5.2 Efficacy of extremely lexicalized models The implemented parsers of models 1 and 2 were around four times faster than the previous model without a loss of accuracy"
W06-1619,P03-1054,0,0.0219404,"hrasestructure-based model. The hybrid model is not only significantly faster but also significantly more accurate by two points of precision and recall compared to the previous model. 1 Introduction For the last decade, accurate and wide-coverage parsing for real-world text has been intensively and extensively pursued. In most of state-of-theart parsers, probabilistic events are defined over phrase structures because phrase structures are supposed to dominate syntactic configurations of sentences. For example, probabilities were defined over grammar rules in probabilistic CFG (Collins, 1999; Klein and Manning, 2003; Char155 Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 155–163, c Sydney, July 2006. 2006 Association for Computational Linguistics probabilistic model is defined as the probability of unigram supertagging. So, the hybrid model can be regarded as an extension of supertagging from unigram to n-gram. The hybrid model can also be regarded as a variant of the statistical CDG parser (Wang, 2003; Wang and Harper, 2004), in which the parse tree probabilities are defined as the product of the supertagging probabilities and the dependency pr"
W06-1619,H05-1059,1,0.811846,"nd the performance was evaluated using sentences of ≤ 40 and 100 words in Section 23. The performance of each parsing technique was analyzed using the sentences in Section 24 of ≤ 100 words. Table 3 details the numbers and average lengths of the tested sentences of ≤ 40 and 100 words in Sections 23 and 24, and the total numbers of sentences in Sections 23 and 24. The parsing performance for Section 23 is shown in Table 4. The upper half of the table shows the performance using the correct POSs in the Penn Treebank, and the lower half shows the performance using the POSs given by a POS tagger (Tsuruoka and Tsujii, 2005). The left and right sides of the table show the performances for the sentences of ≤ 40 and ≤ 100 words. Our models significantly increased not only the parsing speed but also the parsing accuracy. Model 3 was around three to four times faster and had around two points higher precision and recall than the previous model. Surprisingly, model 1, which used only lexical information, was very fast and as accurate as the previous model. Model 2 also improved the accuracy slightly without information of phrase structures. When the automatic POS tagger was introduced, both precision and recall droppe"
W06-1619,W04-0307,0,0.294366,"natory categorial grammar (CCG) (Clark and Curran, 2004b; Malouf and van Noord, 2004; Miyao and Tsujii, 2005). Although these studies vary in the design of the probabilistic models, the fundamental conception of probabilistic modeling is intended to capture characteristics of phrase structures or grammar rules. Although lexical information, such as head words, is known to significantly improve the parsing accuracy, it was also used to augment information on phrase structures. Another interesting approach to this problem was using supertagging (Clark and Curran, 2004b; Clark and Curran, 2004a; Wang and Harper, 2004; Nasr and Rambow, 2004), which was originally developed for lexicalized tree adjoining grammars (LTAG) (Bangalore and Joshi, 1999). Supertagging is a process where words in an input sentence are tagged with ‘supertags,’ which are lexical entries in lexicalized grammars, e.g., elementary trees in LTAG, lexical categories in CCG, and lexical entries in HPSG. Supertagging was, in the first place, a technique to reduce the cost of parsing with lexicalized grammars; ambiguity in assigning lexical entries to words is reduced by the light-weight process of supertagging before the heavy process of pa"
W06-1619,W02-2018,0,0.00906575,"iven sentence w = hw1 , . . . , wn i is Zw = HEAD verb SUBJ &lt;NP&gt; COMPS &lt;&gt; (Previous probabilistic HPSG) Ã ! X 1 exp λu fu (T ) phpsg0 (T |w) = p0 (T |w) Zw u ! λu fu (T 0 ) , u where λu is a model parameter, fu is a feature function that represents a characteristic of parse tree T , and Zw is the sum over the set of all possible parse trees for the sentence. Intuitively, the probability is defined as the normalized product of the weights exp(λu ) when a characteristic corresponding to fu appears in parse result T . The model parameters, λu , are estimated using numerical optimization methods (Malouf, 2002) to maximize the log-likelihood of the training data. However, the above model cannot be easily estimated because the estimation requires the computation of p(T |w) for all parse candidates assigned to sentence w. Because the number of parse candidates is exponentially related to the length of the sentence, the estimation is intractable for long sentences. To make the model estimation tractable, Geman and Johnson (Geman and Johnson, 2002) and Miyao and Tsujii (Miyao and Tsujii, 2002) proposed a dynamic programming algorithm for estimating p(T |w). Miyao and Tsujii Zw = X Ã 0 p0 (T |w) exp ! 0"
W06-1619,J93-2004,0,\N,Missing
W06-1619,J03-4003,0,\N,Missing
W07-2208,P06-1041,0,0.0124517,"ciency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics ran, 2004b; Clark and Curran, 2004a; Wang, 2003; Wang and Harper, 2004; Nasr and Rambow, 2004; Ninomiya et al., 2006; Foth et al., 2006; Foth and Menzel, 2006), which was originally developed for lexicalized tree adjoining grammars (LTAG) (Bangalore and Joshi, 1999). Supertagging is a process where words in an input sentence are tagged with ‘supertags,’ which are lexical entries in lexicalized grammars, e.g., elementary trees in LTAG, lexical categories in CCG, and lexical entries in HPSG. The concept of supertagging is simple and interesting, and the effects of this were recently demonstrated in the case of a CCG parser (Clark and Curran, 2004a) with the result of a drastic improvement in the parsing speed. Wang and Harper (2004) also demonstrated"
W07-2208,J97-4005,0,0.510494,"ar (LFG) (Bresnan, 1982). They are preferred because they give precise and in-depth analyses for explaining linguistic phenomena, such as passivization, control verbs and relative clauses. The main difficulty of developing parsers in these formalisms was how to model a well-defined probabilistic model for graph structures such as feature structures. This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model (Berger et al., 1996) with many features for parse trees (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005). Following this discriminative approach, techniques for efficiency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007"
W07-2208,J99-2004,0,0.0748299,"n Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics ran, 2004b; Clark and Curran, 2004a; Wang, 2003; Wang and Harper, 2004; Nasr and Rambow, 2004; Ninomiya et al., 2006; Foth et al., 2006; Foth and Menzel, 2006), which was originally developed for lexicalized tree adjoining grammars (LTAG) (Bangalore and Joshi, 1999). Supertagging is a process where words in an input sentence are tagged with ‘supertags,’ which are lexical entries in lexicalized grammars, e.g., elementary trees in LTAG, lexical categories in CCG, and lexical entries in HPSG. The concept of supertagging is simple and interesting, and the effects of this were recently demonstrated in the case of a CCG parser (Clark and Curran, 2004a) with the result of a drastic improvement in the parsing speed. Wang and Harper (2004) also demonstrated the effects of supertagging with a statistical constraint dependency grammar (CDG) parser by showing accura"
W07-2208,J96-1002,0,0.0413835,"grammar (CCG) (Steedman, 2000) and lexical function grammar (LFG) (Bresnan, 1982). They are preferred because they give precise and in-depth analyses for explaining linguistic phenomena, such as passivization, control verbs and relative clauses. The main difficulty of developing parsers in these formalisms was how to model a well-defined probabilistic model for graph structures such as feature structures. This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model (Berger et al., 1996) with many features for parse trees (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005). Following this discriminative approach, techniques for efficiency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 6"
W07-2208,C04-1041,0,0.456892,"es such as feature structures. This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model (Berger et al., 1996) with many features for parse trees (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005). Following this discriminative approach, techniques for efficiency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics ran, 2004b; Clark and Curran, 2004a; Wang, 2003; Wang and Harper, 2004; Nasr and Rambow, 2004; Ninomiya et al., 2006; Foth et al., 2006; Foth and Menzel, 2006), which was originally developed for lexicalized tree adjoining grammars (LTAG) (Bangalore and Joshi, 1999). Supertagging is a proc"
W07-2208,P04-1014,0,0.211016,"es such as feature structures. This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model (Berger et al., 1996) with many features for parse trees (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005). Following this discriminative approach, techniques for efficiency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics ran, 2004b; Clark and Curran, 2004a; Wang, 2003; Wang and Harper, 2004; Nasr and Rambow, 2004; Ninomiya et al., 2006; Foth et al., 2006; Foth and Menzel, 2006), which was originally developed for lexicalized tree adjoining grammars (LTAG) (Bangalore and Joshi, 1999). Supertagging is a proc"
W07-2208,P06-1037,0,0.0803821,"are tagged with ‘supertags,’ which are lexical entries in lexicalized grammars, e.g., elementary trees in LTAG, lexical categories in CCG, and lexical entries in HPSG. The concept of supertagging is simple and interesting, and the effects of this were recently demonstrated in the case of a CCG parser (Clark and Curran, 2004a) with the result of a drastic improvement in the parsing speed. Wang and Harper (2004) also demonstrated the effects of supertagging with a statistical constraint dependency grammar (CDG) parser by showing accuracy as high as the state-of-the-art parsers, and Foth et al. (2006) and Foth and Menzel (2006) reported that accuracy was significantly improved by incorporating the supertagging probabilities into manually tuned Weighted CDG. Ninomiya et al. (2006) showed the parsing model using only supertagging probabilities could achieve accuracy as high as the probabilistic model for phrase structures. This means that syntactic structures are almost determined by supertags as is claimed by Bangalore and Joshi (1999). However, supertaggers themselves were heuristically used as an external tagger. They filter out unlikely lexical entries just to help parsing (Clark and Cur"
W07-2208,P02-1036,0,0.316566,"in these formalisms was how to model a well-defined probabilistic model for graph structures such as feature structures. This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model (Berger et al., 1996) with many features for parse trees (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005). Following this discriminative approach, techniques for efficiency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics ran, 2004b; Clark and Curran, 2004a; Wang, 2003; Wang and Harper, 2004; Nasr and Rambow, 2004; Ninomiya et al., 2006; Foth et al., 2006; Foth and Menzel, 2006), which was originally developed for lexic"
W07-2208,W97-0302,0,0.0999642,"and Tsujii (2005)’s model, but ‘our model 1’ achieved 0.56 points higher F-score, and ‘our model 2’ achieved 0.8 points higher F-score. When the automatic POS tagger was introduced, Fscore dropped by around 2.4 points for all models. We also compared our model with Matsuzaki et al. (2007)’s model. Matsuzaki et al. (2007) proThe terms κ and δ are the thresholds of the number of phrasal signs in the chart cell and the beam width for signs in the chart cell. The terms α and β are the thresholds of the number and the beam width of lexical entries, and θ is the beam width for global thresholding (Goodman, 1997). The terms with suffixes 0 are the initial values. The parser iterates parsing until it succeeds to generate a parse tree. The parameters increase for each iteration by the terms prefixed by ∆, and parsing finishes when the parameters reach the terms with suffixes last. Details of the parameters are written in (Ninomiya et al., 2005). The beam thresholding parameters for ‘our model 2’ are α0 = 18, ∆α = 6, αlast = 42, β0 = 9.0, ∆β = 3.0, βlast = 21.0, δ0 = 18, ∆δ = 6, δlast = 42, κ0 = 9.0, ∆κ = 3.0, κlast = 21.0. In ‘our model 2’, the global thresholding was not used. 66 posed a technique for"
W07-2208,P03-1046,0,0.0277048,"f the parser. A predicate-argument relation is defined as a tuple hσ, wh , a, wa i, where σ is the predicate type (e.g., adjective, intransitive verb), wh is the head word of the predicate, a is the argument label (MODARG, ARG1, ..., ARG4), and wa is the head word of the argument. Labeled precision (LP)/labeled recall (LR) is the ratio of tuples correctly identified by the parser2 . Unlabeled precision (UP)/unlabeled recall (UR) is the ratio of tuples without the predicate type and the argument label. This evaluation scheme was the same as used in previous evaluations of lexicalized grammars (Hockenmaier, 2003; Clark The HPSG treebank is used for training the probabilistic model for lexical entry selection, and hence, those lexical entries that do not appear in the treebank are rarely selected by the probabilistic model. The ‘effective’ tag set size, therefore, is around 1,361, the number of lexical entries without those never-seen lexical entries. 2 When parsing fails, precision and recall are evaluated, although nothing is output by the parser; i.e., recall decreases greatly. 65 and Curran, 2004b; Miyao and Tsujii, 2005). The experiments were conducted on an AMD Opteron server with a 2.4-GHz CPU."
W07-2208,A00-2021,0,0.0236621,"ence w = hw1 , . . . , wn i is to sentence w. Because the number of parse candidates is exponentially related to the length of the sentence, the estimation is intractable for long sentences. To make the model estimation tractable, Geman and Johnson (Geman and Johnson, 2002) and Miyao and Tsujii (Miyao and Tsujii, 2002) proposed a dynamic programming algorithm for estimating p(T |w). Miyao and Tsujii (2005) also introduced a preliminary probabilistic model p0 (T |w) whose estimation does not require the parsing of a treebank. This model is introduced as a reference distribution (Jelinek, 1998; Johnson and Riezler, 2000) of the probabilistic HPSG model; i.e., the computation of parse trees given low probabilities by the model is omitted in the estimation stage (Miyao and Tsujii, 2005), or a probabilistic model can be augmented by several distributions estimated from the larger and simpler corpus (Johnson and Riezler, 2000). In (Miyao and Tsujii, 2005), p0 (T |w) is defined as the product of probabilities of selecting lexical entries with word and POS unigram features: (Miyao and Tsujii (2005)’s model) 1 puniref (T |w) = p0 (T |w) exp Zw Zw = (Probabilistic HPSG) Zw = T0 Ã 0 p0 (T |w) exp T0 phpsg (T |w) = X X"
W07-2208,P99-1069,0,0.311858,"snan, 1982). They are preferred because they give precise and in-depth analyses for explaining linguistic phenomena, such as passivization, control verbs and relative clauses. The main difficulty of developing parsers in these formalisms was how to model a well-defined probabilistic model for graph structures such as feature structures. This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model (Berger et al., 1996) with many features for parse trees (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005). Following this discriminative approach, techniques for efficiency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007 Association for Comput"
W07-2208,N04-1013,0,0.253832,"nalyses for explaining linguistic phenomena, such as passivization, control verbs and relative clauses. The main difficulty of developing parsers in these formalisms was how to model a well-defined probabilistic model for graph structures such as feature structures. This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model (Berger et al., 1996) with many features for parse trees (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005). Following this discriminative approach, techniques for efficiency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics ran, 2004b; Clark and Curran, 2004a; Wang, 2003; Wa"
W07-2208,W05-1511,1,0.920749,"y a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model (Berger et al., 1996) with many features for parse trees (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005). Following this discriminative approach, techniques for efficiency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics ran, 2004b; Clark and Curran, 2004a; Wang, 2003; Wang and Harper, 2004; Nasr and Rambow, 2004; Ninomiya et al., 2006; Foth et al., 2006; Foth and Menzel, 2006), which was originally developed for lexicalized tree adjoining grammars (LTAG) (Bangalore and Joshi, 1999). Supertagging is a process where words in an input sentence are tagged wi"
W07-2208,W06-1619,1,0.158093,"scriminative approach, techniques for efficiency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics ran, 2004b; Clark and Curran, 2004a; Wang, 2003; Wang and Harper, 2004; Nasr and Rambow, 2004; Ninomiya et al., 2006; Foth et al., 2006; Foth and Menzel, 2006), which was originally developed for lexicalized tree adjoining grammars (LTAG) (Bangalore and Joshi, 1999). Supertagging is a process where words in an input sentence are tagged with ‘supertags,’ which are lexical entries in lexicalized grammars, e.g., elementary trees in LTAG, lexical categories in CCG, and lexical entries in HPSG. The concept of supertagging is simple and interesting, and the effects of this were recently demonstrated in the case of a CCG parser (Clark and Curran, 2004a) with the result of a drastic improvement in the parsing speed"
W07-2208,P00-1061,0,0.388867,"preferred because they give precise and in-depth analyses for explaining linguistic phenomena, such as passivization, control verbs and relative clauses. The main difficulty of developing parsers in these formalisms was how to model a well-defined probabilistic model for graph structures such as feature structures. This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model (Berger et al., 1996) with many features for parse trees (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005). Following this discriminative approach, techniques for efficiency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics ra"
W07-2208,W02-2018,0,0.014737,"SG) Zw = T0 Ã 0 p0 (T |w) exp T0 phpsg (T |w) = X X 1 exp Zw Ã exp Ã X X ! p0 (T |w) = λu fu (T ) X Ã X u ! λu fu (T ) ! 0 λu fu (T ) u n Y p(li |wi ), i=1 u ! 0 λu fu (T ) , u where λu is a model parameter, fu is a feature function that represents a characteristic of parse tree T , and Zw is the sum over the set of all possible parse trees for the sentence. Intuitively, the probability is defined as the normalized product of the weights exp(λu ) when a characteristic corresponding to fu appears in parse result T . The model parameters, λu , are estimated using numerical optimization methods (Malouf, 2002) to maximize the log-likelihood of the training data. However, the above model cannot be easily estimated because the estimation requires the computation of p(T |w) for all parse candidates assigned 62 where li is a lexical entry assigned to word wi in T and p(li |wi ) is the probability of selecting lexical entry li for wi . In the experiments, we compared our model with other two types of probabilistic models using a supertagger (Ninomiya et al., 2006). The first one is the simplest probabilistic model, which is defined with only the probabilities of lexical entry selection. It is defined si"
W07-2208,H05-1059,1,0.820103,"Missing"
W07-2208,W04-0307,0,0.13942,"04; Miyao and Tsujii, 2005). Following this discriminative approach, techniques for efficiency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics ran, 2004b; Clark and Curran, 2004a; Wang, 2003; Wang and Harper, 2004; Nasr and Rambow, 2004; Ninomiya et al., 2006; Foth et al., 2006; Foth and Menzel, 2006), which was originally developed for lexicalized tree adjoining grammars (LTAG) (Bangalore and Joshi, 1999). Supertagging is a process where words in an input sentence are tagged with ‘supertags,’ which are lexical entries in lexicalized grammars, e.g., elementary trees in LTAG, lexical categories in CCG, and lexical entries in HPSG. The concept of supertagging is simple and interesting, and the effects of this were recently demonstrated in the case of a CCG parser (Clark and Curran, 2004a) with the result"
W07-2208,P05-1011,1,0.268471,"g linguistic phenomena, such as passivization, control verbs and relative clauses. The main difficulty of developing parsers in these formalisms was how to model a well-defined probabilistic model for graph structures such as feature structures. This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model (Berger et al., 1996) with many features for parse trees (Abney, 1997; Johnson et al., 1999; Riezler et al., 2000; Malouf and van Noord, 2004; Kaplan et al., 2004; Miyao and Tsujii, 2005). Following this discriminative approach, techniques for efficiency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics ran, 2004b; Clark and Curran, 2004a; Wang, 2003; Wang and Harper, 2004; Nasr"
W07-2208,W04-3308,0,0.0211161,"005). Following this discriminative approach, techniques for efficiency were investigated for estimation (Geman and Johnson, 2002; Miyao and Tsujii, 2002; Malouf and van Noord, 2004) and parsing (Clark and Curran, 2004b; Clark and Curran, 2004a; Ninomiya et al., 2005). An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur60 Proceedings of the 10th Conference on Parsing Technologies, pages 60–68, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics ran, 2004b; Clark and Curran, 2004a; Wang, 2003; Wang and Harper, 2004; Nasr and Rambow, 2004; Ninomiya et al., 2006; Foth et al., 2006; Foth and Menzel, 2006), which was originally developed for lexicalized tree adjoining grammars (LTAG) (Bangalore and Joshi, 1999). Supertagging is a process where words in an input sentence are tagged with ‘supertags,’ which are lexical entries in lexicalized grammars, e.g., elementary trees in LTAG, lexical categories in CCG, and lexical entries in HPSG. The concept of supertagging is simple and interesting, and the effects of this were recently demonstrated in the case of a CCG parser (Clark and Curran, 2004a) with the result of a drastic improveme"
W07-2208,J93-2004,0,\N,Missing
W09-3832,W02-2203,0,0.628695,"Missing"
W09-3832,C04-1041,0,0.207871,"Missing"
W09-3832,W02-1001,0,0.099489,",308 supertags. Because of this, it is often very hard or even impossible to apply computationary demanding methods to HPSG supertagging. 3 POS Word-POS Supertag† Substructure Table 1: Feature templates for point-wise model and sequential model. Templates with † are only used by sequential model. ssi,j represents j-th substructure of supertag at i. For briefness, si is omitted for each template. “×” means set-product. e.g., {a,b}×{A,B}={a&A,a&B,b&A,b&B} Perceptron and Bayes Point Machine Perceptron is an efficient online discriminative training method. We used perceptron with weightaveraging (Collins, 2002) as the basis of our supertagging model. We also use perceptron-based Bayes point machine (BPM) (Herbrich et al., 2001) in some of the experiments. In short, a BPM is an average of a number of averaged perceptrons’ weights. We use average of 10 averaged perceptrons, each of which is trained on a different random permutation of the training data. 3.1 3.2 Here we follow the definition of Collins’ perceptron to learn a mapping from the input space (w, p) ∈ W × P to the supertag space s ∈ S. We use function GEN(w,p) to indicate all candidates given input (w, p). Feature function f maps a training"
W09-3832,P07-1037,0,0.405152,"Missing"
W09-3832,2000.iwpt-1.15,0,0.471397,"Missing"
W09-3832,W06-1619,1,0.909984,"Missing"
W09-3832,J99-2004,0,\N,Missing
W09-3832,W03-1006,0,\N,Missing
W09-3832,P03-1064,0,\N,Missing
W10-1816,A00-2031,0,0.0367762,"sentences. The annotation of more sentences in the science domain is ongoing. The current annotation of the NICT Chinese Treebank is informative for some language analysis tasks, such as syntactic parsing and word segmentation. However, the deep information, which includes both the grammatical functional tags and the traces, are omitted in the annotation. Without grammatical functions, the simple bracketing structure is not informative enough to represent the semantics for Chinese. Furthermore, the traces are critical elements in detecting long-distance dependencies. Gabbard et al. (2006) and Blaheta and Charniak (2000) applied machine learning models to automatically assign the empty categories and functional tags to an English treebank. However, considering about the different domains that the Penn Chinese Treebank and the NICT Chinese Treebank belong to, the machine learning model trained on the Penn Chinese Treebank may not work successfully on the NICT Chinese Treebank. In order to guarantee the high annotation quality, in our work, we manually re-annotate both the grammatical functional tags and the traces to the NICT Chinese Treebank. With the deep re-annotation, the NICT Chinese Treebank could be use"
W10-1816,N06-1024,0,0.017187,"00 Chinese sentences. The annotation of more sentences in the science domain is ongoing. The current annotation of the NICT Chinese Treebank is informative for some language analysis tasks, such as syntactic parsing and word segmentation. However, the deep information, which includes both the grammatical functional tags and the traces, are omitted in the annotation. Without grammatical functions, the simple bracketing structure is not informative enough to represent the semantics for Chinese. Furthermore, the traces are critical elements in detecting long-distance dependencies. Gabbard et al. (2006) and Blaheta and Charniak (2000) applied machine learning models to automatically assign the empty categories and functional tags to an English treebank. However, considering about the different domains that the Penn Chinese Treebank and the NICT Chinese Treebank belong to, the machine learning model trained on the Penn Chinese Treebank may not work successfully on the NICT Chinese Treebank. In order to guarantee the high annotation quality, in our work, we manually re-annotate both the grammatical functional tags and the traces to the NICT Chinese Treebank. With the deep re-annotation, the NI"
W10-1816,hockenmaier-steedman-2002-acquiring,0,0.0151834,"k and the NICT Chinese Treebank belong to, the machine learning model trained on the Penn Chinese Treebank may not work successfully on the NICT Chinese Treebank. In order to guarantee the high annotation quality, in our work, we manually re-annotate both the grammatical functional tags and the traces to the NICT Chinese Treebank. With the deep re-annotation, the NICT Chinese Treebank could be used not only for the shallow natural language processing tasks, but also as a resource for deep applications, such as the lexicalized grammar development from treebanks (Miyao 2006; Guo 2009; Xia 1999; Hockenmaier and Steedman 2002). Considering that the translation quality of the sentences in the NICT Chinese Treebank may affect the quality of re-annotation, in the current phase, we only selected 2,363 sentences that are of good translation quality, for re-annotation. In the future, with the expansion of the NICT Chinese Treebank, we will continue this reannotation work on large-scale sentences. 2 Content of Re-annotation Because the NICT Chinese Treebank follows the annotation guideline of the Penn Chinese Treebank, our re-annotation uses similar annotation criteria in the Penn Chinese Treebank. Figure 1 exemplifies ou"
W10-1816,C02-1145,0,0.0993283,"Missing"
W11-0407,W97-1502,0,0.0760306,"parser that converts the human annotations automatically into a richly annotated HPSG treebank. In order to check the proposed scheme’s effectiveness, we performed automatic pseudo-annotations that emulate the system’s idealized behavior and measured the performance of the parser trained on those annotations. In addition, we implemented a prototype system and conducted manual annotation experiments on a small test set. There has been a number of research projects to efficiently develop richly annotated corpora with the help of parsers, one of which is called a discriminant-based treebanking (Carter, 1997). In discriminant-based treebanking, the annotation process consists of two steps: a parser first generates the parse trees, which are annotation candidates, and then a human annotator selects the most plausible one. One of the most important characteristics of this methodology is to use easily-understandable questions called discriminants for picking up the final annotation results. Human annotators can perform annotations simply by answering those questions without closely examining the whole tree. Although this approach has been successful in breaking down the difficult annotations into a s"
W11-0407,W07-2202,1,0.843251,"tic dependency. In both of S-full and SL-full, the improvement from the baseline is significant. Especially, SL-full for “in-chart” data has almost complete agreement with the gold-standard HPSG annotations. The detailed figures are shown in Table 4. Therefore, we can therefore conclude that high quality CFG annotations lead to high quality HPSG annotations when the are combined with a good statistical HPSG parser. 4.2 Domain Adaptation We evaluated the parser accuracy adapted with the automatically created treebank on the Brown Corpus. In this experiment, we used the adaptation algorithm by (Hara et al., 2007), with the same hyperparameters used there. Table 5 shows the result of the adapted parser. Each line of this table stands for the parser adapted with different data. “Gold” is the result adapted on the gold-standard annotations, and “Gold (only covered)” is that adapted on the gold data which is covered by the original Enju HPSG grammar that was extracted from the WSJ portion of the Penn Treebank. “SL-full” is the result adapted on our automatically created data. “Baseline” is the result by the original Enju parser, which is trained only on the WSJ-PTB and whose grammar was extracted from the"
W11-0407,P10-2013,0,0.0218851,"or an unavailable link due to the death of the source edge. tion is that the stochastic model of the HPSG parser properly resolves the remaining ambiguities in the HPSG annotation within the constraints given by a part of the CFG trees. In order to check the validity of this expectation and to measure to what extent the CFG-based annotations can achieve correct HPSG annotations, we performed a pseudo-annotation experiment. In this experiment, we used bracketed sentences in the Brown Corpus (Kuˇcera and Francis, 1967), and a court transcript portion of the Manually Annotated Sub-Corpus (MASC) (Ide et al., 2010). We automatically created HPSG annotations that mimic the annotation results by an ideal annotator in the following four steps. First, HPSG treebanks for these sentences are created by the treebank conversion program distributed with the Enju parser. This program converts a syntactic tree annotated by Penn Treebank style into an HPSG tree. Since this program cannot convert the sentences that are not covered by the basic design of the grammar, we used only those that are successfully converted by the program throughout the experiments and considered this converted treebank as the gold-standard"
W11-0407,H94-1020,0,0.066519,"ottleneck to reduce the cost of annotator training and can restrict the size of annotations. Introduction On the basis of the success of the research on the corpus-based development in NLP, the demand for a variety of corpora has increased, for use as both a training resource and an evaluation data-set. However, the development of a richly annotated corpus such as an HPSG treebank is not an easy task, since the traditional two-step annotation, in which a parser first generates the candidates and then an annotator checks each candidate, needs intensive efforts even for well-trained annotators (Marcus et al., 1994; Kurohashi and Nagao, 1998). Among many NLP problems, adapting a parser for out-domain texts, which is usually referred to as domain adaptation problem, is one of the most remarkable problems. The main cause of this problem is the lack of corpora in that domain. Because it is difficult to prepare a sufficient corpus for each domain without Interactive predictive parsing (S´anchez-S´aez et al., 2009; S´anchez-S´aez et al., 2010) is another approach of annotations, which focuses on CFG trees. In this system, an annotator revises the currently proposed CFG tree until he or she gets the correct t"
W11-0407,W07-2208,1,0.841369,"to each word, and then, the lexical signs for “Dogs” and “run” are combined by SubjectHead schema. In this way, lexical signs and phrasal signs are combined until the whole sentence becomes one sign. Compared to Context Free Grammar (CFG), since each sign of HPSG has rich information about the phrase, such as subcategorization frame or predicate-argument structure, a corpus annotated in an HPSG manner is more difficult to build than CFG corpus. In our system, we aim at building HPSG treebanks with low-cost in which even nonexperts can perform annotations. 2.2 HPSG Deep Parser The Enju parser (Ninomiya et al., 2007) is a statistical deep parser based on the HPSG formalism. It produces an analysis of a sentence that includes the 57 2 3 HEAD noun 6 7 &lt;> 5 4SUBJ COMPS &lt;> Dogs 2 3 HEAD verb 6 7 &lt; noun >5 4SUBJ COMPS &lt;> Drung ⇓ 2 3 HEAD verb 6 7 &lt;> 5 4SUBJ COMPS &lt;> 2 Subject 3 HEAD noun 6 7 &lt;> 5 1 4SUBJ COMPS &lt;> Headj 3 HEAD verb 6 7 6SUBJ &lt; 1 >7 4 5 COMPS &lt;> 2 Figure 1: Example of HPSG parsing for “Dogs run.” syntactic structure (i.e., parse tree) and the semantic structure represented as a set of predicate-argument dependencies. The grammar design is based on the standard HPSG analysis of English (Pollard a"
W11-0407,W09-3835,0,0.0520196,"Missing"
W11-0407,N10-2010,0,0.046945,"Missing"
W11-0407,C10-2166,0,0.0201854,"3, and annotated 200 sentences in total on the system. Half of the sentences were taken from the Brown corpus and the other half were taken from a court-debate section of the MASC corpus. All of the sentences were annotated twice by two annotators. Both of the annotators has background in computer science and linguistics. Table 6 shows the statistics of the annotation procedures. This table indicates that human annotators strongly prefer “S” operation to others, and that the manual annotation on the prototype system is at least comparable to the recent discriminant-based annotation system by (Zhang and Kordoni, 2010), although the comparison is not strict because of the difference of the text. Table 7 shows the automatic evaluation results. We can see that the interactive annotation gave slight improvements in all accuracy metrics. The improvements were however not as much as we desired. By classifying the remaining errors in the annotation results, we identified several classes of major errors: 1. Truly ambiguous structures, which require the context or world-knowledge to correctly resolve them. Brown (train.) MASC in 10,576 / 10,394 864 / 857 out 7,190 / 6,464 489 / 449 in+out 17,766 / 16,858 1,353 / 1,"
W11-1203,C10-1003,1,0.841841,"Missing"
W11-1203,W09-1117,0,0.502059,"sujii‡ † Department of Computer Science, University of Tokyo {daniel.andrade, matuzaki}@is.s.u-tokyo.ac.jp ‡ Microsoft Research Asia, Beijing jtsujii@microsoft.com Abstract ular (Laroche and Langlais, 2010; Andrade et al., 2010; Ismail and Manandhar, 2010; Laws et al., 2010; Garera et al., 2009). The general idea is based on the assumption that similar words have similar contexts across languages. The context of a word can be described by the sentence in which it occurs (Laroche and Langlais, 2010) or a surrounding word-window (Rapp, 1999; Haghighi et al., 2008). A few previous studies, like (Garera et al., 2009), suggested to use the predecessor and successors from the dependency-parse tree, instead of a word window. In (Andrade et al., 2011), we showed that including dependency-parse tree context positions together with a sentence bag-of-words context can improve word translation accuracy. However previous works do not make an attempt to find an optimal combination of these different context positions. Using comparable corpora to find new word translations is a promising approach for extending bilingual dictionaries (semi-) automatically. The basic idea is based on the assumption that similar words"
W11-1203,P08-1088,0,0.0416332,"rpora Daniel Andrade† , Takuya Matsuzaki† , Jun’ichi Tsujii‡ † Department of Computer Science, University of Tokyo {daniel.andrade, matuzaki}@is.s.u-tokyo.ac.jp ‡ Microsoft Research Asia, Beijing jtsujii@microsoft.com Abstract ular (Laroche and Langlais, 2010; Andrade et al., 2010; Ismail and Manandhar, 2010; Laws et al., 2010; Garera et al., 2009). The general idea is based on the assumption that similar words have similar contexts across languages. The context of a word can be described by the sentence in which it occurs (Laroche and Langlais, 2010) or a surrounding word-window (Rapp, 1999; Haghighi et al., 2008). A few previous studies, like (Garera et al., 2009), suggested to use the predecessor and successors from the dependency-parse tree, instead of a word window. In (Andrade et al., 2011), we showed that including dependency-parse tree context positions together with a sentence bag-of-words context can improve word translation accuracy. However previous works do not make an attempt to find an optimal combination of these different context positions. Using comparable corpora to find new word translations is a promising approach for extending bilingual dictionaries (semi-) automatically. The basic"
W11-1203,C10-2055,0,0.373772,"Missing"
W11-1203,C10-1070,0,0.412999,"ndency-parsing Information for Finding Translations with Comparable Corpora Daniel Andrade† , Takuya Matsuzaki† , Jun’ichi Tsujii‡ † Department of Computer Science, University of Tokyo {daniel.andrade, matuzaki}@is.s.u-tokyo.ac.jp ‡ Microsoft Research Asia, Beijing jtsujii@microsoft.com Abstract ular (Laroche and Langlais, 2010; Andrade et al., 2010; Ismail and Manandhar, 2010; Laws et al., 2010; Garera et al., 2009). The general idea is based on the assumption that similar words have similar contexts across languages. The context of a word can be described by the sentence in which it occurs (Laroche and Langlais, 2010) or a surrounding word-window (Rapp, 1999; Haghighi et al., 2008). A few previous studies, like (Garera et al., 2009), suggested to use the predecessor and successors from the dependency-parse tree, instead of a word window. In (Andrade et al., 2011), we showed that including dependency-parse tree context positions together with a sentence bag-of-words context can improve word translation accuracy. However previous works do not make an attempt to find an optimal combination of these different context positions. Using comparable corpora to find new word translations is a promising approach for"
W11-1203,C10-2070,0,0.296323,"Missing"
W11-1203,P05-1012,0,0.038244,"ection of complaints concerning automobiles compiled by the USA National Highway Traffic Safety Administration (NHTSA)3 . Both corpora are publicly available. The corpora are non-parallel, but are comparable in terms of content. The part of MLIT and NHTSA which we used for our experiments, contains 24090 and 47613 sentences, respectively. The Japanese MLIT corpus was morphologically analyzed and dependency parsed using Juman and KNP4 . The English corpus NHTSA was POS-tagged and stemmed with Stepp Tagger (Tsuruoka et al., 2005; Okazaki et al., 2008) and dependency parsed using the MST parser (McDonald et al., 2005). Using the Japanese-English dictionary JMDic5 , we found 1796 content words in Japanese which have a translation which is in the English corpus. These content words and their translations cor. respond to our pivot words in Japanese and English, respectively.6 2 http://www.mlit.go.jp/jidosha/carinf/rcl/defects.html http://www-odi.nhtsa.dot.gov/downloads/index.cfm 4 http://www-lab25.kuee.kyoto-u.ac.jp/nlresource/juman.html and http://www-lab25.kuee.kyotou.ac.jp/nl-resource/knp.html 5 http://www.csse.monash.edu.au/ jwb/edict doc.html 6 Recall that we assume a one-to-one correspondence between a"
W11-1203,D08-1047,1,0.799856,"nd, Infrastructure, Transport and Tourism (MLIT)2 and another collection of complaints concerning automobiles compiled by the USA National Highway Traffic Safety Administration (NHTSA)3 . Both corpora are publicly available. The corpora are non-parallel, but are comparable in terms of content. The part of MLIT and NHTSA which we used for our experiments, contains 24090 and 47613 sentences, respectively. The Japanese MLIT corpus was morphologically analyzed and dependency parsed using Juman and KNP4 . The English corpus NHTSA was POS-tagged and stemmed with Stepp Tagger (Tsuruoka et al., 2005; Okazaki et al., 2008) and dependency parsed using the MST parser (McDonald et al., 2005). Using the Japanese-English dictionary JMDic5 , we found 1796 content words in Japanese which have a translation which is in the English corpus. These content words and their translations cor. respond to our pivot words in Japanese and English, respectively.6 2 http://www.mlit.go.jp/jidosha/carinf/rcl/defects.html http://www-odi.nhtsa.dot.gov/downloads/index.cfm 4 http://www-lab25.kuee.kyoto-u.ac.jp/nlresource/juman.html and http://www-lab25.kuee.kyotou.ac.jp/nl-resource/knp.html 5 http://www.csse.monash.edu.au/ jwb/edict doc."
W11-1203,P99-1067,0,0.757235,"omparable Corpora Daniel Andrade† , Takuya Matsuzaki† , Jun’ichi Tsujii‡ † Department of Computer Science, University of Tokyo {daniel.andrade, matuzaki}@is.s.u-tokyo.ac.jp ‡ Microsoft Research Asia, Beijing jtsujii@microsoft.com Abstract ular (Laroche and Langlais, 2010; Andrade et al., 2010; Ismail and Manandhar, 2010; Laws et al., 2010; Garera et al., 2009). The general idea is based on the assumption that similar words have similar contexts across languages. The context of a word can be described by the sentence in which it occurs (Laroche and Langlais, 2010) or a surrounding word-window (Rapp, 1999; Haghighi et al., 2008). A few previous studies, like (Garera et al., 2009), suggested to use the predecessor and successors from the dependency-parse tree, instead of a word window. In (Andrade et al., 2011), we showed that including dependency-parse tree context positions together with a sentence bag-of-words context can improve word translation accuracy. However previous works do not make an attempt to find an optimal combination of these different context positions. Using comparable corpora to find new word translations is a promising approach for extending bilingual dictionaries (semi-)"
W11-1203,E03-1023,0,0.0132709,"asic idea for finding a translation for a word q (query), is to measure the context of q and then to compare the context with each possible translation candidate, using an existing dictionary. We will call words for which we have a translation in the given dictionary, pivot words. First, using the source corpus, they calculate the degree of association of a query word q with all pivot words. The degree of association is a measure which is based on the cooccurrence frequency of q and the pivot word in a certain context position. A context (position) can be a word-window (Rapp, 1999), sentence (Utsuro et al., 2003), or a certain position in the dependencyparse tree (Garera et al., 2009; Andrade et al., 2011). In this way, they get a context vector for q, which contains the degree of association to the pivot words in different context positions. Using the target corpus, they then calculate a context vector for each 11 possible translation candidate x, in the same way. Finally, they compare the context vector of q with the context vector of each candidate x, and retrieve a ranked list of possible translation candidates. In the next section, we explain the baseline which is based on that previous research."
W11-2907,W09-1201,0,0.0278561,"Missing"
W11-2907,N04-1013,0,0.190045,"Missing"
W11-2907,W09-1206,0,0.0202207,"nglish. Instead of training a parser based on the obtained LFG resources, Guo used an external PCFG parser to create cstructure trees, and then mapped the c-structure trees into f-structures using their annotation rules (Guo, 2009). Besides of Guo’s work, some researchers worked on joint dependency parsing and semantic role labeling to fulfill Chinese deep parsing (Li et al., 2010; Morante et al., 2009; Gesmundo et al., 2009; Dai et al., 2009; Lluis et al., 2009); other researchers focused on performing semantic role labeling after syntactic parsing (Fung et al., 2007; Sun and Jurafsky, 2004; Bjorkelund et al., 2009; Meza-Ruiz and Riedel, 2009; Zhao et al., 2009). There were also some previous works that focused on building the language resources with lexicalized grammars, but not parsing with these resources. With the hand-crafted conversion rules, Yu et al. (2010) built a Chinese HPSG Treebank semi-automatically from the Penn Chinese Treebank. Guo (2009) also used rules to convert the Penn Chinese Treebank into LFG resources. Moreover, Tse and Curran (2010) built a Chinese CCGbank, which was also automatically induced from the Penn Chinese Treebank. (the person who wrote the book) Figure 12: The syntac"
W11-2907,J94-4001,0,0.317999,"Missing"
W11-2907,P04-1014,0,0.027432,"Missing"
W11-2907,P03-1056,0,0.547035,"arser can be explained in the following way: Given a segmented and pos-tagged input sentence, (1) the supertagger offers all the maybeparsable supertag (i.e. lexical template) sequences with scores to the parser; (2) the feature forest model applies beam threshold on the scored supertag sequences, and then obtains a well-formed HPSG parse tree. 吃/eat 过 了 。 ((Somebody) has eaten (something).) (b) A Chinese sentence with both subject and object pro-drop Figure 1: Examples of pro-drop in Chinese The other significant linguistic property in Chinese is the frequent pro-drop phenomena. For example, Levy and Manning (2003) showed that unlike English, the subject pro-drop (the null realization of uncontrolled pronominal subjects) is widespread in Chinese; this is exemplified in Figure 1 (a). Huang (1989) further provided a detailed analysis to show that subjects as well as objects may drop from finite Chinese sentences (as shown in Figure 1 (b)). 3 3.1 Figure 2 shows a supertag sequence provided by the supertagger for a Chinese sentence, in which the supertag of the word ‘写(wrote)’ indicates a lexical template for the transitive verb with an extracted object. Figure 3 illustrates the HPSG parse tree output from"
W11-2907,W09-1202,0,0.0187412,"ese Treebank. This is the only previous work that had been conducted on Chinese deep parsing based on lexicalized grammars, although many related works had been done on English. Instead of training a parser based on the obtained LFG resources, Guo used an external PCFG parser to create cstructure trees, and then mapped the c-structure trees into f-structures using their annotation rules (Guo, 2009). Besides of Guo’s work, some researchers worked on joint dependency parsing and semantic role labeling to fulfill Chinese deep parsing (Li et al., 2010; Morante et al., 2009; Gesmundo et al., 2009; Dai et al., 2009; Lluis et al., 2009); other researchers focused on performing semantic role labeling after syntactic parsing (Fung et al., 2007; Sun and Jurafsky, 2004; Bjorkelund et al., 2009; Meza-Ruiz and Riedel, 2009; Zhao et al., 2009). There were also some previous works that focused on building the language resources with lexicalized grammars, but not parsing with these resources. With the hand-crafted conversion rules, Yu et al. (2010) built a Chinese HPSG Treebank semi-automatically from the Penn Chinese Treebank. Guo (2009) also used rules to convert the Penn Chinese Treebank into LFG resources. Mo"
W11-2907,W09-1212,0,0.0170433,"is the only previous work that had been conducted on Chinese deep parsing based on lexicalized grammars, although many related works had been done on English. Instead of training a parser based on the obtained LFG resources, Guo used an external PCFG parser to create cstructure trees, and then mapped the c-structure trees into f-structures using their annotation rules (Guo, 2009). Besides of Guo’s work, some researchers worked on joint dependency parsing and semantic role labeling to fulfill Chinese deep parsing (Li et al., 2010; Morante et al., 2009; Gesmundo et al., 2009; Dai et al., 2009; Lluis et al., 2009); other researchers focused on performing semantic role labeling after syntactic parsing (Fung et al., 2007; Sun and Jurafsky, 2004; Bjorkelund et al., 2009; Meza-Ruiz and Riedel, 2009; Zhao et al., 2009). There were also some previous works that focused on building the language resources with lexicalized grammars, but not parsing with these resources. With the hand-crafted conversion rules, Yu et al. (2010) built a Chinese HPSG Treebank semi-automatically from the Penn Chinese Treebank. Guo (2009) also used rules to convert the Penn Chinese Treebank into LFG resources. Moreover, Tse and Curra"
W11-2907,2007.tmi-papers.10,0,0.0165638,"hough many related works had been done on English. Instead of training a parser based on the obtained LFG resources, Guo used an external PCFG parser to create cstructure trees, and then mapped the c-structure trees into f-structures using their annotation rules (Guo, 2009). Besides of Guo’s work, some researchers worked on joint dependency parsing and semantic role labeling to fulfill Chinese deep parsing (Li et al., 2010; Morante et al., 2009; Gesmundo et al., 2009; Dai et al., 2009; Lluis et al., 2009); other researchers focused on performing semantic role labeling after syntactic parsing (Fung et al., 2007; Sun and Jurafsky, 2004; Bjorkelund et al., 2009; Meza-Ruiz and Riedel, 2009; Zhao et al., 2009). There were also some previous works that focused on building the language resources with lexicalized grammars, but not parsing with these resources. With the hand-crafted conversion rules, Yu et al. (2010) built a Chinese HPSG Treebank semi-automatically from the Penn Chinese Treebank. Guo (2009) also used rules to convert the Penn Chinese Treebank into LFG resources. Moreover, Tse and Curran (2010) built a Chinese CCGbank, which was also automatically induced from the Penn Chinese Treebank. (the"
W11-2907,W06-2932,0,0.08923,"Missing"
W11-2907,W09-1213,0,0.0213047,"ng a parser based on the obtained LFG resources, Guo used an external PCFG parser to create cstructure trees, and then mapped the c-structure trees into f-structures using their annotation rules (Guo, 2009). Besides of Guo’s work, some researchers worked on joint dependency parsing and semantic role labeling to fulfill Chinese deep parsing (Li et al., 2010; Morante et al., 2009; Gesmundo et al., 2009; Dai et al., 2009; Lluis et al., 2009); other researchers focused on performing semantic role labeling after syntactic parsing (Fung et al., 2007; Sun and Jurafsky, 2004; Bjorkelund et al., 2009; Meza-Ruiz and Riedel, 2009; Zhao et al., 2009). There were also some previous works that focused on building the language resources with lexicalized grammars, but not parsing with these resources. With the hand-crafted conversion rules, Yu et al. (2010) built a Chinese HPSG Treebank semi-automatically from the Penn Chinese Treebank. Guo (2009) also used rules to convert the Penn Chinese Treebank into LFG resources. Moreover, Tse and Curran (2010) built a Chinese CCGbank, which was also automatically induced from the Penn Chinese Treebank. (the person who wrote the book) Figure 12: The syntactic dependency tree correspo"
W11-2907,N04-1032,0,0.0174061,"works had been done on English. Instead of training a parser based on the obtained LFG resources, Guo used an external PCFG parser to create cstructure trees, and then mapped the c-structure trees into f-structures using their annotation rules (Guo, 2009). Besides of Guo’s work, some researchers worked on joint dependency parsing and semantic role labeling to fulfill Chinese deep parsing (Li et al., 2010; Morante et al., 2009; Gesmundo et al., 2009; Dai et al., 2009; Lluis et al., 2009); other researchers focused on performing semantic role labeling after syntactic parsing (Fung et al., 2007; Sun and Jurafsky, 2004; Bjorkelund et al., 2009; Meza-Ruiz and Riedel, 2009; Zhao et al., 2009). There were also some previous works that focused on building the language resources with lexicalized grammars, but not parsing with these resources. With the hand-crafted conversion rules, Yu et al. (2010) built a Chinese HPSG Treebank semi-automatically from the Penn Chinese Treebank. Guo (2009) also used rules to convert the Penn Chinese Treebank into LFG resources. Moreover, Tse and Curran (2010) built a Chinese CCGbank, which was also automatically induced from the Penn Chinese Treebank. (the person who wrote the bo"
W11-2907,C10-1122,0,0.16879,"et al., 2009); other researchers focused on performing semantic role labeling after syntactic parsing (Fung et al., 2007; Sun and Jurafsky, 2004; Bjorkelund et al., 2009; Meza-Ruiz and Riedel, 2009; Zhao et al., 2009). There were also some previous works that focused on building the language resources with lexicalized grammars, but not parsing with these resources. With the hand-crafted conversion rules, Yu et al. (2010) built a Chinese HPSG Treebank semi-automatically from the Penn Chinese Treebank. Guo (2009) also used rules to convert the Penn Chinese Treebank into LFG resources. Moreover, Tse and Curran (2010) built a Chinese CCGbank, which was also automatically induced from the Penn Chinese Treebank. (the person who wrote the book) Figure 12: The syntactic dependency tree corresponding to Figure 10 (the reason that someone wrote the book) Figure 13: The syntactic dependency tree corresponding to Figure 11 However, since the syntactic analysis does not consider predicate-argument dependencies, such an ambiguity in semantic parsing does not exist in syntactic parsing. For instance, for both the two semantic analyses listed in Figure 10 and Figure 11, the syntactic dependencies are similar, as shown"
W11-2907,J08-1002,1,0.878911,"sentences (as shown in Figure 1 (b)). 3 3.1 Figure 2 shows a supertag sequence provided by the supertagger for a Chinese sentence, in which the supertag of the word ‘写(wrote)’ indicates a lexical template for the transitive verb with an extracted object. Figure 3 illustrates the HPSG parse tree output from the parser with this supertag sequence. Chinese Deep Parsing based on HPSG Parsing Model In this paper, we used an HPSG parser - Enju1, which was successfully applied in English deep parsing, to obtain the deep analysis of Chinese. This HPSG parser uses the feature forest model proposed by Miyao and Tsujii (2008), which is a maximum entropy model that is defined over feature forests, as a parsing disambiguation model. The feature forest model provides a solution to the problem of probabilistic modeling of complex data structures. Moreover, in order to reduce the search space and further increase the parsing efficiency, in this parser, a supertagger (Matsuzaki et al. 2007) is applied before parsing. This supertager provides the maybe-parsable supertag (i.e. lexical template) sequences to the parser. In short, in the HPSG parser, the probability, p(t|w), of producing a parse tree t for a given sentence"
W11-2907,W09-1219,0,0.0532946,"Missing"
W11-2907,W09-1205,0,0.0193571,"uced from the Penn Chinese Treebank. This is the only previous work that had been conducted on Chinese deep parsing based on lexicalized grammars, although many related works had been done on English. Instead of training a parser based on the obtained LFG resources, Guo used an external PCFG parser to create cstructure trees, and then mapped the c-structure trees into f-structures using their annotation rules (Guo, 2009). Besides of Guo’s work, some researchers worked on joint dependency parsing and semantic role labeling to fulfill Chinese deep parsing (Li et al., 2010; Morante et al., 2009; Gesmundo et al., 2009; Dai et al., 2009; Lluis et al., 2009); other researchers focused on performing semantic role labeling after syntactic parsing (Fung et al., 2007; Sun and Jurafsky, 2004; Bjorkelund et al., 2009; Meza-Ruiz and Riedel, 2009; Zhao et al., 2009). There were also some previous works that focused on building the language resources with lexicalized grammars, but not parsing with these resources. With the hand-crafted conversion rules, Yu et al. (2010) built a Chinese HPSG Treebank semi-automatically from the Penn Chinese Treebank. Guo (2009) also used rules to convert the Penn Chinese Treebank into"
W11-2907,C10-2162,1,0.789144,"esearchers worked on joint dependency parsing and semantic role labeling to fulfill Chinese deep parsing (Li et al., 2010; Morante et al., 2009; Gesmundo et al., 2009; Dai et al., 2009; Lluis et al., 2009); other researchers focused on performing semantic role labeling after syntactic parsing (Fung et al., 2007; Sun and Jurafsky, 2004; Bjorkelund et al., 2009; Meza-Ruiz and Riedel, 2009; Zhao et al., 2009). There were also some previous works that focused on building the language resources with lexicalized grammars, but not parsing with these resources. With the hand-crafted conversion rules, Yu et al. (2010) built a Chinese HPSG Treebank semi-automatically from the Penn Chinese Treebank. Guo (2009) also used rules to convert the Penn Chinese Treebank into LFG resources. Moreover, Tse and Curran (2010) built a Chinese CCGbank, which was also automatically induced from the Penn Chinese Treebank. (the person who wrote the book) Figure 12: The syntactic dependency tree corresponding to Figure 10 (the reason that someone wrote the book) Figure 13: The syntactic dependency tree corresponding to Figure 11 However, since the syntactic analysis does not consider predicate-argument dependencies, such an am"
W11-2907,W09-1208,0,0.0161437,"ained LFG resources, Guo used an external PCFG parser to create cstructure trees, and then mapped the c-structure trees into f-structures using their annotation rules (Guo, 2009). Besides of Guo’s work, some researchers worked on joint dependency parsing and semantic role labeling to fulfill Chinese deep parsing (Li et al., 2010; Morante et al., 2009; Gesmundo et al., 2009; Dai et al., 2009; Lluis et al., 2009); other researchers focused on performing semantic role labeling after syntactic parsing (Fung et al., 2007; Sun and Jurafsky, 2004; Bjorkelund et al., 2009; Meza-Ruiz and Riedel, 2009; Zhao et al., 2009). There were also some previous works that focused on building the language resources with lexicalized grammars, but not parsing with these resources. With the hand-crafted conversion rules, Yu et al. (2010) built a Chinese HPSG Treebank semi-automatically from the Penn Chinese Treebank. Guo (2009) also used rules to convert the Penn Chinese Treebank into LFG resources. Moreover, Tse and Curran (2010) built a Chinese CCGbank, which was also automatically induced from the Penn Chinese Treebank. (the person who wrote the book) Figure 12: The syntactic dependency tree corresponding to Figure 10 ("
W11-2907,J93-2004,0,\N,Missing
W11-2907,J08-2001,0,\N,Missing
W11-2907,J05-3003,0,\N,Missing
W11-2907,P10-1113,0,\N,Missing
W11-2907,D07-1096,0,\N,Missing
W13-4403,C02-1126,0,0.0866221,"Missing"
W13-4403,A00-2018,0,0.0149568,"Missing"
W13-4403,D09-1127,0,0.077969,"Missing"
W13-4403,J93-2004,0,0.0424905,"Missing"
W13-4403,P03-1056,0,0.085125,"Missing"
W13-4403,W12-6332,1,0.808052,"Missing"
W13-4403,W09-3825,0,0.0151052,"tion Penn Treebank (PTB) was built based on the idea of context-free PSG (Marcus et al., 1993). It is now a common practice to develop data-driven English parsers using PTB annotation and encouraging performances have been reported (Collins, 2000; Charniak, 2000). Following the success of PTB, Xue et al. 2000 built Penn Chinese Treebank (CTB). CTB is also based on context-free PSG. Since CTB provides training data for Chinese parsing, researchers attempted to train Chinese parsing with CTB (Bikel and Chiang, 2000; Chiang and Bikel, 2002; Levy and Manning, 2003; Bikel, 2004; Wang et al., 2006; Zhang and Clark, 2009; 1a. Students process data 1b. Data processing system 1c. Data was processed 2a. 学生 处理 数据 Student process data Students process data 2b. 数据 处理 系统 Data process system Data processing system 11 Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing (SIGHAN-7), pages 11–19, Nagoya, Japan, 14 October 2013. 2c. 数据 处理 了 Data process le Data was processed 4a. 鸟儿 飞 向 南方 Bird fly towards south Birds fly towards the south 4b. *鸟儿 吃 向 南方 Bird eat towards south Birds eat towards the south 4c. *鸟儿 喜欢 向 南方 Bird like towards south Birds like towards the south 5a. Agent Direction V 5b. Age"
W13-4403,W00-1201,0,\N,Missing
W13-4403,P06-1054,0,\N,Missing
W14-2414,W07-1422,0,0.0787364,"Missing"
W14-2414,P11-1060,0,0.0852828,"Missing"
W14-2414,P14-1008,1,0.780015,"logically sound transformations, but tree transformations can be seen as an approximation of logical inference. For (ii), abstract denotation is more efficient than FOL formula, because abstract denotation eliminates quantifiers and meanings of natural language texts can be represented by atomic sentences. To elaborate the above discussion and to provide more topics to the literature, in this paper we discuss the following four questions: (§2) How well can tree transformation approximate logical inference? (§3) With rigorous inference on DCS trees, where does logic contribute in the system of Tian et al. (2014)? (§4) Does logical inference have further potentials in Recognizing Textual Entailment (RTE) task? and (§5) How efficient is abstract denotation compared to FOL formula? We provide examples or experimental results to the above questions. Dependency-based Compositional Semantics (DCS) provides a precise and expressive way to model semantics of natural language queries on relational databases, by simple dependency-like trees. Recently abstract denotation is proposed to enable generic logical inference on DCS. In this paper, we discuss some other possibilities to equip DCS with logical inference"
W14-2414,N13-1090,0,\N,Missing
Y09-2048,W02-1502,0,0.136567,"; these two structures involve dislocation of phrases from their basic positions which these six schemas require. These structures are covered by our Chinese HPSG framework, and we will introduce the details in the next section. 3 The Design of Chinese HPSG Framework The formalized framework HPSG uses a small number of rule schemas and a large number of lexical entries to describe language. Our basic policy of Chinese HPSG is to exploit rule schemas defined for English with minimum changes. Although a possible solution would be to create an initial grammar with the help of the Grammar Matrix (Bender et al., 2002), we refer to the rule schemas used in an existing HPSG parser (Miyao, 2006), because we intend to apply the technology of this parser to our Chinese parser. This does not only reduce the cost of development of Chinese grammar but also confirm the assumption that, despite surface diversity, human languages share the same organization principles. For example, we do not introduce new rule schemas specific to Chinese unless they are absolutely necessary. We generalize Chinese syntactic structures into five structures based on the Chinese syntactic structure system that we proposed in the previous"
Y09-2048,P05-1022,0,0.0135203,"PSG framework. As the first step of our work, we design a Chinese HPSG framework, which can be used as the basis for a practical parser. In this paper, 1) we present a Chinese syntactic structure system and 2) we design a primary Chinese HPSG framework. Keywords: HPSG, data-driven parsing, Chinese HPSG framework, coverage, consistency. 1 Introduction Data-driven parsing has been proven to be the most effective approach to development of a practical parser. It can deliver a parser with broad-coverage and high-accuracy. Some English data-driven syntactic parsers have been developed in the past (Charniak and Johnson, 2005; McDonald and Pereira, 2006; Miyao and Tsujii, 2005). Following the success of the research on English data-driven parsing, the same methodology has been applied to Chinese parsing (Levy and Manning, 2003; Wang et al., 2005; Guo et al., 2007). The goal of our research is to develop a data-driven Chinese parser that is based on Head-driven Phrase Structure Grammar (HPSG) (Sag et al., 2003). Since an English data-driven parser based on the HPSG framework has been developed by our group (Miyao and Tsujii, 2005), we follow the same methodology for developing a Chinese parser. We first convert an"
Y09-2048,P03-1056,0,0.0293544,"we design a primary Chinese HPSG framework. Keywords: HPSG, data-driven parsing, Chinese HPSG framework, coverage, consistency. 1 Introduction Data-driven parsing has been proven to be the most effective approach to development of a practical parser. It can deliver a parser with broad-coverage and high-accuracy. Some English data-driven syntactic parsers have been developed in the past (Charniak and Johnson, 2005; McDonald and Pereira, 2006; Miyao and Tsujii, 2005). Following the success of the research on English data-driven parsing, the same methodology has been applied to Chinese parsing (Levy and Manning, 2003; Wang et al., 2005; Guo et al., 2007). The goal of our research is to develop a data-driven Chinese parser that is based on Head-driven Phrase Structure Grammar (HPSG) (Sag et al., 2003). Since an English data-driven parser based on the HPSG framework has been developed by our group (Miyao and Tsujii, 2005), we follow the same methodology for developing a Chinese parser. We first convert an existing Chinese treebank into an HPSG treebank, based on which we can obtain a large lexicon and a statistical model for choosing the most plausible interpretation. Since the HPSG framework for English ha"
Y09-2048,E06-1011,0,0.0317725,"step of our work, we design a Chinese HPSG framework, which can be used as the basis for a practical parser. In this paper, 1) we present a Chinese syntactic structure system and 2) we design a primary Chinese HPSG framework. Keywords: HPSG, data-driven parsing, Chinese HPSG framework, coverage, consistency. 1 Introduction Data-driven parsing has been proven to be the most effective approach to development of a practical parser. It can deliver a parser with broad-coverage and high-accuracy. Some English data-driven syntactic parsers have been developed in the past (Charniak and Johnson, 2005; McDonald and Pereira, 2006; Miyao and Tsujii, 2005). Following the success of the research on English data-driven parsing, the same methodology has been applied to Chinese parsing (Levy and Manning, 2003; Wang et al., 2005; Guo et al., 2007). The goal of our research is to develop a data-driven Chinese parser that is based on Head-driven Phrase Structure Grammar (HPSG) (Sag et al., 2003). Since an English data-driven parser based on the HPSG framework has been developed by our group (Miyao and Tsujii, 2005), we follow the same methodology for developing a Chinese parser. We first convert an existing Chinese treebank in"
Y09-2048,P05-1011,1,0.743126,"a Chinese HPSG framework, which can be used as the basis for a practical parser. In this paper, 1) we present a Chinese syntactic structure system and 2) we design a primary Chinese HPSG framework. Keywords: HPSG, data-driven parsing, Chinese HPSG framework, coverage, consistency. 1 Introduction Data-driven parsing has been proven to be the most effective approach to development of a practical parser. It can deliver a parser with broad-coverage and high-accuracy. Some English data-driven syntactic parsers have been developed in the past (Charniak and Johnson, 2005; McDonald and Pereira, 2006; Miyao and Tsujii, 2005). Following the success of the research on English data-driven parsing, the same methodology has been applied to Chinese parsing (Levy and Manning, 2003; Wang et al., 2005; Guo et al., 2007). The goal of our research is to develop a data-driven Chinese parser that is based on Head-driven Phrase Structure Grammar (HPSG) (Sag et al., 2003). Since an English data-driven parser based on the HPSG framework has been developed by our group (Miyao and Tsujii, 2005), we follow the same methodology for developing a Chinese parser. We first convert an existing Chinese treebank into an HPSG treebank, base"
Y09-2048,W05-1516,0,0.0188136,"nese HPSG framework. Keywords: HPSG, data-driven parsing, Chinese HPSG framework, coverage, consistency. 1 Introduction Data-driven parsing has been proven to be the most effective approach to development of a practical parser. It can deliver a parser with broad-coverage and high-accuracy. Some English data-driven syntactic parsers have been developed in the past (Charniak and Johnson, 2005; McDonald and Pereira, 2006; Miyao and Tsujii, 2005). Following the success of the research on English data-driven parsing, the same methodology has been applied to Chinese parsing (Levy and Manning, 2003; Wang et al., 2005; Guo et al., 2007). The goal of our research is to develop a data-driven Chinese parser that is based on Head-driven Phrase Structure Grammar (HPSG) (Sag et al., 2003). Since an English data-driven parser based on the HPSG framework has been developed by our group (Miyao and Tsujii, 2005), we follow the same methodology for developing a Chinese parser. We first convert an existing Chinese treebank into an HPSG treebank, based on which we can obtain a large lexicon and a statistical model for choosing the most plausible interpretation. Since the HPSG framework for English has been studied comp"
