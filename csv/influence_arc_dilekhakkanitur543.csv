2020.deelio-1.9,2020.emnlp-main.54,0,0.184937,"Missing"
2020.deelio-1.9,2021.ccl-1.108,0,0.135312,"Missing"
2020.deelio-1.9,D18-2029,0,0.0270846,"Pretrained KG embeddings based on ConceptNet via TransE (Bordes et al., 2013; Zhou et al., 2018). Figure 2: Illustration of the proposed model incorporating external KGs for SocialIQA. • Pretrained word embeddings retrofitted by ConceptNet (Speer et al., 2017), where its training adjusts a word’s embeddings to be close to those of its neighbors in the graph. 4 Experiments and Results 4.1 Experimental Setup We use Hugging Face’s transformers toolkit2 and train our models on the 33k SocialIQA training • Encoded tuple-converted text with templates and pretrained universal sentence encoder (USE) (Cer et al., 2018), a Transformer-based 2 76 https://huggingface.co/transformers/ 4.3 instances, running hyper-parameters search over the learning rate in {5e − 6, 1e − 5, 2.5e − 5}, and the effective batch size (number of GPUs × batch size per GPU × gradient accumulation steps) in {8, 16, 32} for the proposed models and baselines respectively, and report their best performance on the dev set. We set the maximum returned tuples of each instance to k = 30. 4.2 To demonstrate the effective utilization of external KGs, we now investigate performance in the limited training data regime. We fine-tuned our model on 5"
2020.deelio-1.9,N19-1423,0,0.0289326,"ng-Yun Chang1 , Yang Liu2 , Karthik Gopalakrishnan2 , Behnam Hedayatnia2 , ¨ 2∗ Pei Zhou3 , Dilek Hakkani-Tur 1 Academia Sinica, Taiwan; 2 Alexa AI, Amazon, USA; 3 USC, USA r06922168@ntu.edu.tw, {yangliud,karthgop,behnam,hakkanit}@amazon.com Abstract achieved impressive performance by fine-tuning T5 (Raffel et al., 2019). Recently there is an increasing effort to utilize external knowledge bases to incorporate commonsense information underlying the text (Shwartz et al., 2020; Mitra et al., 2019; Ji et al., 2020a,b). While most prior work on SocialIQA utilized large pretrained language models (Devlin et al., 2019; Liu et al., 2019; Radford et al., 2018, 2019; Raffel et al., 2019), we argue that such a challenging task requires commonsense reasoning of social events, and simply fine-tuning the model to fit the task is insufficient. We believe it would be beneficial if the model can learn from knowledge-rich resources such as ConceptNet (Liu and Singh, 2004), and thus have a broader and deeper understanding of the information not present in the provided context and answer candidates. In this paper, we propose two approaches tailored to large pretrained language models to utilize existing knowledge graph"
2020.deelio-1.9,S12-1052,0,0.033482,"ly infuse such KGs into pretrained language models. We demonstrate our proposed methods perform well on SocialIQA, a social commonsense reasoning task, in both limited and full training data regimes. 1 Introduction Empowering machines with commonsense has become a hot topic recently. Past research efforts for this problem include the construction of various data sets and models. Several commonsense data sets have been commonly used in past work to develop machines’ commonsense capability (Talmor et al., 2019; Huang et al., 2019; Zellers et al., 2019; Sap et al., 2019b; Sakaguchi et al., 2019; Gordon et al., 2012; Rajani et al., 2019). In particular, SocialIQA (Sap et al., 2019b) is a multiple-choice QA data set for probing machine’s emotional and social intelligence in a variety of everyday situations, which is the data set used in this study. To improve the modeling approaches for the SocialIQA and other commonsense tasks, Shwartz et al. (2020) and Bosselut and Choi (2019) focused on zero-shot setting using pretrained language models. Khashabi et al. (2020) reformulated the multi-choice setup used in most data sets as a generation task and 2 Problem Formulation and Baseline In SocialIQA, given a con"
2020.deelio-1.9,P19-1487,0,0.019547,"to pretrained language models. We demonstrate our proposed methods perform well on SocialIQA, a social commonsense reasoning task, in both limited and full training data regimes. 1 Introduction Empowering machines with commonsense has become a hot topic recently. Past research efforts for this problem include the construction of various data sets and models. Several commonsense data sets have been commonly used in past work to develop machines’ commonsense capability (Talmor et al., 2019; Huang et al., 2019; Zellers et al., 2019; Sap et al., 2019b; Sakaguchi et al., 2019; Gordon et al., 2012; Rajani et al., 2019). In particular, SocialIQA (Sap et al., 2019b) is a multiple-choice QA data set for probing machine’s emotional and social intelligence in a variety of everyday situations, which is the data set used in this study. To improve the modeling approaches for the SocialIQA and other commonsense tasks, Shwartz et al. (2020) and Bosselut and Choi (2019) focused on zero-shot setting using pretrained language models. Khashabi et al. (2020) reformulated the multi-choice setup used in most data sets as a generation task and 2 Problem Formulation and Baseline In SocialIQA, given a context C of an event and"
2020.deelio-1.9,2020.acl-main.740,0,0.0394901,"Missing"
2020.deelio-1.9,D19-1243,0,0.0428778,"Missing"
2020.deelio-1.9,2020.aacl-main.28,0,0.253534,"Missing"
2020.deelio-1.9,D19-1454,0,0.0570248,"Missing"
2020.deelio-1.9,2020.emnlp-main.373,0,0.211563,"Missing"
2020.deelio-1.9,N19-1421,0,0.0267776,"ionships. Thus, towards general commonsense learning, we propose two approaches to implicitly and explicitly infuse such KGs into pretrained language models. We demonstrate our proposed methods perform well on SocialIQA, a social commonsense reasoning task, in both limited and full training data regimes. 1 Introduction Empowering machines with commonsense has become a hot topic recently. Past research efforts for this problem include the construction of various data sets and models. Several commonsense data sets have been commonly used in past work to develop machines’ commonsense capability (Talmor et al., 2019; Huang et al., 2019; Zellers et al., 2019; Sap et al., 2019b; Sakaguchi et al., 2019; Gordon et al., 2012; Rajani et al., 2019). In particular, SocialIQA (Sap et al., 2019b) is a multiple-choice QA data set for probing machine’s emotional and social intelligence in a variety of everyday situations, which is the data set used in this study. To improve the modeling approaches for the SocialIQA and other commonsense tasks, Shwartz et al. (2020) and Bosselut and Choi (2019) focused on zero-shot setting using pretrained language models. Khashabi et al. (2020) reformulated the multi-choice setup us"
2020.deelio-1.9,S18-1120,0,0.0281737,"assification and semantic similarity. In the second approach, we treat the retrieved tuples as items in a cached external knowledge base (KB), which dynamically changes based on every input instance. The model can then decide the importance of each item and leverage them accordingly. Then we transform these embeddings of the topk tuples using a linear transformation that is learned during training, and then concatenate all of them to form the knowledge representation HKG ∈ Rk×d . KG Attentive Representations Motivated by previous work on question answering (Seo et al., 2017; Zhu et al., 2018; Wang et al., 2018; Huang et al., 2019), which uses attention among different segments of the input, here we treat the knowledge tuples as a new segment. Specifically, we concatenate the top-k retrieved tuples and map them into the space of RoBERTa’s final hidden representations as an additional segment, and then attend to it using RoBERTa’s last hidden representation to generate a new KG-attentive sentence representation. Formally, let d be the hidden dimension, l be the sequence length of the input, HR ∈ Rl×d be RoBERTa’s final hidden representation for the SocialIQA input sequence for a given candidate, and"
2020.deelio-1.9,P19-1472,0,0.0232918,"se learning, we propose two approaches to implicitly and explicitly infuse such KGs into pretrained language models. We demonstrate our proposed methods perform well on SocialIQA, a social commonsense reasoning task, in both limited and full training data regimes. 1 Introduction Empowering machines with commonsense has become a hot topic recently. Past research efforts for this problem include the construction of various data sets and models. Several commonsense data sets have been commonly used in past work to develop machines’ commonsense capability (Talmor et al., 2019; Huang et al., 2019; Zellers et al., 2019; Sap et al., 2019b; Sakaguchi et al., 2019; Gordon et al., 2012; Rajani et al., 2019). In particular, SocialIQA (Sap et al., 2019b) is a multiple-choice QA data set for probing machine’s emotional and social intelligence in a variety of everyday situations, which is the data set used in this study. To improve the modeling approaches for the SocialIQA and other commonsense tasks, Shwartz et al. (2020) and Bosselut and Choi (2019) focused on zero-shot setting using pretrained language models. Khashabi et al. (2020) reformulated the multi-choice setup used in most data sets as a generation task"
2020.inlg-1.35,W00-1401,0,0.208654,"rresponding test references, we use BLEU (n-gram precision with brevity penalty) (Papineni et al., 2002) and METEOR (n-gram precision and recall, with synonyms) (Lavie and Agarwal, 2007). We compute corpus-level BLEU for the full set of outputs and matching references. For METEOR, we compute per-output metrics and average across all instances.8 We include these metrics in our evaluation primarily for completeness and supplement them with a human evaluation, since it is widely agreed that lexical overlap-based metrics are weak measures of quality (Novikova et al., 2017a; Belz and Reiter, 2006; Bangalore et al., 2000). Semantic accuracy. We compute the slot error rate (SER) for each model output as compared to the corresponding MR by finding the total number of deletions, repetitions, and hallucinations over the total number of slots for that instance (the lower the better).9 It is important to note that we only consider slots that have explicit values (e.g., MR: INFORM date=$date1) for our automatic SER computations. We are investigating methods to compute SER over implicit slots (e.g., MR: REQUEST party size=null) as future work, since it is non-trivial to compute due to the various ways an implicit slot"
2020.inlg-1.35,E06-1040,0,0.083477,"ur outputs match the corresponding test references, we use BLEU (n-gram precision with brevity penalty) (Papineni et al., 2002) and METEOR (n-gram precision and recall, with synonyms) (Lavie and Agarwal, 2007). We compute corpus-level BLEU for the full set of outputs and matching references. For METEOR, we compute per-output metrics and average across all instances.8 We include these metrics in our evaluation primarily for completeness and supplement them with a human evaluation, since it is widely agreed that lexical overlap-based metrics are weak measures of quality (Novikova et al., 2017a; Belz and Reiter, 2006; Bangalore et al., 2000). Semantic accuracy. We compute the slot error rate (SER) for each model output as compared to the corresponding MR by finding the total number of deletions, repetitions, and hallucinations over the total number of slots for that instance (the lower the better).9 It is important to note that we only consider slots that have explicit values (e.g., MR: INFORM date=$date1) for our automatic SER computations. We are investigating methods to compute SER over implicit slots (e.g., MR: REQUEST party size=null) as future work, since it is non-trivial to compute due to the vari"
2020.inlg-1.35,C18-1107,0,0.0564396,"Missing"
2020.inlg-1.35,W16-6626,0,0.0261931,"alize slots with values from the schema (although this may add noise), e.g., “The date is $date1” → “The date is [March 1st].” We use the same values for all templates for consistency. 16 We compute Fleiss Kappa scores for each dimension, finding near-perfect agreement for semantics (0.87), substantial agreement for grammar (0.76), and moderate agreement for naturalness (0.58) and overall (0.47). information that should be realized, without including contextual information to guide the generator as we do; although some work has described how this could be useful (Walker et al., 2018). WebNLG (Colin et al., 2016) includes structured triples from Wikipedia which may constitute slightly richer MRs, but are not contextualized. Oraby et al. (2019) generate rich MRs that contain syntactic and stylistic information for generating descriptive restaurant reviews, but do not add in any contextual information that does not need to be included in the output realization. Table-to-text generation using ROTOWIRE (NBA players and stats) also includes richer information, but it is also not contextualized (Wiseman et al., 2017; Gong et al., 2019). Other previous work has attempted to address domain transfer in NLG. De"
2020.inlg-1.35,P15-1044,0,0.0422431,"Missing"
2020.inlg-1.35,W16-3622,0,0.0489324,"Missing"
2020.inlg-1.35,W18-6539,0,0.0281326,"Missing"
2020.inlg-1.35,P17-1017,0,0.0510622,"a structured Meaning Representation (MR) (Moryossef et al., 2019; Wiseman et al., 2017; Gong et al., 2019; Duˇsek et al., 2018; Liu et al., 2017; Colin et al., 2016; Wen et al., 2016; Dusek and Jurc´ıcek, 2016; Duˇsek and Jurcicek, 2015; Wen et al., 2015). Popular datasets used for MR-to-text generation are confined to limited domains, e.g., restaurants or product information, and usually consist of simple tuples of slots and values describing the content to be realized, failing to offer any information about domains or slots that might be useful to generation models (Novikova et al., 2017b; Gardent et al., 2017; Wen et al., 2015). Table 1 shows examples of MRs from popular datasets. Neural network based approaches to data-totext natural language generation (NLG) have gained popularity in recent years, with the goal of generating a natural language prompt that accurately realizes an input meaning representation. To facilitate the training of neural network models, researchers created large datasets of paired utterances and their meaning representations. However, the creation of such datasets is an arduous task and they mostly consist of simple meaning representations composed of slot and value tokens"
2020.inlg-1.35,D19-1310,0,0.0258213,"k has described how this could be useful (Walker et al., 2018). WebNLG (Colin et al., 2016) includes structured triples from Wikipedia which may constitute slightly richer MRs, but are not contextualized. Oraby et al. (2019) generate rich MRs that contain syntactic and stylistic information for generating descriptive restaurant reviews, but do not add in any contextual information that does not need to be included in the output realization. Table-to-text generation using ROTOWIRE (NBA players and stats) also includes richer information, but it is also not contextualized (Wiseman et al., 2017; Gong et al., 2019). Other previous work has attempted to address domain transfer in NLG. Dethlefs et al. (2017) use an abstract meaning representation (AMR) as a way to share common semantic information across domains. Wen et al. (2016) use a “data counterfeiting” method to generate synthetic data from existing domains to train models on unseen domains, then fine-tune on a small set of in-domain utterances. Tran et al. (2018) also train models on a source domain dataset, then fine-tune on a small sample of target domain utterances for domain adaptation. Rather than fine-tuning models for new domains, our data-d"
2020.inlg-1.35,D17-1238,0,0.0301507,"Missing"
2020.inlg-1.35,W17-5525,0,0.0407138,"Missing"
2020.inlg-1.35,P19-1596,1,0.787242,"the same values for all templates for consistency. 16 We compute Fleiss Kappa scores for each dimension, finding near-perfect agreement for semantics (0.87), substantial agreement for grammar (0.76), and moderate agreement for naturalness (0.58) and overall (0.47). information that should be realized, without including contextual information to guide the generator as we do; although some work has described how this could be useful (Walker et al., 2018). WebNLG (Colin et al., 2016) includes structured triples from Wikipedia which may constitute slightly richer MRs, but are not contextualized. Oraby et al. (2019) generate rich MRs that contain syntactic and stylistic information for generating descriptive restaurant reviews, but do not add in any contextual information that does not need to be included in the output realization. Table-to-text generation using ROTOWIRE (NBA players and stats) also includes richer information, but it is also not contextualized (Wiseman et al., 2017; Gong et al., 2019). Other previous work has attempted to address domain transfer in NLG. Dethlefs et al. (2017) use an abstract meaning representation (AMR) as a way to share common semantic information across domains. Wen e"
2020.inlg-1.35,P02-1040,0,0.107219,"ut, we use our fine-tuned GPT-2 model with a language model head to generate an output sequence (until we hit an end-of-sequence token). We adopt top-k sampling at each decoding step. 4 Evaluation For each of our three models, we generate a single output for each test instance. Table 5 shows example model outputs. 4.1 Evaluation Metrics We focus on three distinct metric types: similarity to references, semantic accuracy, and diversity. Similarity to references. As a measure of how closely our outputs match the corresponding test references, we use BLEU (n-gram precision with brevity penalty) (Papineni et al., 2002) and METEOR (n-gram precision and recall, with synonyms) (Lavie and Agarwal, 2007). We compute corpus-level BLEU for the full set of outputs and matching references. For METEOR, we compute per-output metrics and average across all instances.8 We include these metrics in our evaluation primarily for completeness and supplement them with a human evaluation, since it is widely agreed that lexical overlap-based metrics are weak measures of quality (Novikova et al., 2017a; Belz and Reiter, 2006; Bangalore et al., 2000). Semantic accuracy. We compute the slot error rate (SER) for each model output a"
2020.inlg-1.35,P17-1099,0,0.0466217,"(2015): where s˜t is the decoder hidden state. For Seq2Seq/CVAE, we use constrained decoding to prune out candidate outputs with slot repetitions. We use a beam to keep track of slots that have already been generated and set the probability of a new candidate node to zero if slots are repeated. at = softmax(align(ht , st )) 3.4 where align is a function that computes the alignment score of the hidden state of the encoder ht and the decoder hidden state, st . The goal of this layer is to attend to the more salient input features. The copy mechanism we add is based on pointergenerator networks (See et al., 2017). At each decoding step t we compute a probability pgen : pgen = σ(whT h∗t + wsT st + wxT xt + bptr ) Pretrained Language Model: GPT-2 We also experiment with a pretrained language model, specifically GPT-2 (Radford et al., 2019).6 Since GPT-2 is trained on purely natural language strings, we first combine the symbolic and natural language features into flat natural language strings, similar to previous work by Budzianowski and Vuli´c (2019). We fine-tune the GPT-2 model using these natural language inputs with the target 6 where wh , ws , and wx are a learnable weights matrix; h∗t is a contex"
2020.inlg-1.35,C18-1103,0,0.0187529,"te eurus65], type[laptop], memory[4gb], driverRange[medium], isForBusiness[false] The satellite eurus 65 is a laptop designed for home use with 4 gb of memory and a medium sized hard drive Table 1: Sample MRs from popular NNLG datasets. Introduction ∗ Dataset Only having simple and limited information within these MRs has several shortcomings. Model outputs are either very generic or generators have to be trained for a narrow domain and cannot be used for new domains. Thus, some recent work has focused on different methods to improve naturalness (Zhu et al., 2019) and promote domain transfer (Tran and Nguyen, 2018; Wen et al., 2016). MRs are not unique to the problem of language generation: tasks such as dialog state tracking (Rastogi et al., 2019), policy learning (Chen et al., 2018), and task completion (Li et al., 2017) also 283 Proceedings of The 13th International Conference on Natural Language Generation, pages 283–295, c Dublin, Ireland, 15-18 December, 2020. 2020 Association for Computational Linguistics require the use of an MR to track context and state information relevant to the task. MRs from these more dialog-oriented tasks are often referred to as a “schemata.” While dialog state trackin"
2020.inlg-1.35,L18-1628,1,0.763635,"uitive, we automatically lexicalize slots with values from the schema (although this may add noise), e.g., “The date is $date1” → “The date is [March 1st].” We use the same values for all templates for consistency. 16 We compute Fleiss Kappa scores for each dimension, finding near-perfect agreement for semantics (0.87), substantial agreement for grammar (0.76), and moderate agreement for naturalness (0.58) and overall (0.47). information that should be realized, without including contextual information to guide the generator as we do; although some work has described how this could be useful (Walker et al., 2018). WebNLG (Colin et al., 2016) includes structured triples from Wikipedia which may constitute slightly richer MRs, but are not contextualized. Oraby et al. (2019) generate rich MRs that contain syntactic and stylistic information for generating descriptive restaurant reviews, but do not add in any contextual information that does not need to be included in the output realization. Table-to-text generation using ROTOWIRE (NBA players and stats) also includes richer information, but it is also not contextualized (Wiseman et al., 2017; Gong et al., 2019). Other previous work has attempted to addre"
2020.inlg-1.35,N16-1015,0,0.102634,"art models for neural natural language generation on this dataset and show that in many cases, including rich schema information allows our models to produce higher quality outputs both in terms of semantics and diversity. We also conduct experiments comparing model performance on seen versus unseen domains, and present a human evaluation demonstrating high ratings for overall output quality. 1 Much of the recent work on Neural Natural Language Generation (NNLG) focuses on generating a Authors contributed equally and are listed alphabetically. MR Reference E2E (Novikova et al., 2017b) Laptop (Wen et al., 2016) INFORM name[The Punter], food[Indian], priceRange[cheap] The Punter offers cheap Indian food. INFORM name[satellite eurus65], type[laptop], memory[4gb], driverRange[medium], isForBusiness[false] The satellite eurus 65 is a laptop designed for home use with 4 gb of memory and a medium sized hard drive Table 1: Sample MRs from popular NNLG datasets. Introduction ∗ Dataset Only having simple and limited information within these MRs has several shortcomings. Model outputs are either very generic or generators have to be trained for a narrow domain and cannot be used for new domains. Thus, some re"
2020.inlg-1.35,D15-1199,0,0.181786,"Representation (MR) (Moryossef et al., 2019; Wiseman et al., 2017; Gong et al., 2019; Duˇsek et al., 2018; Liu et al., 2017; Colin et al., 2016; Wen et al., 2016; Dusek and Jurc´ıcek, 2016; Duˇsek and Jurcicek, 2015; Wen et al., 2015). Popular datasets used for MR-to-text generation are confined to limited domains, e.g., restaurants or product information, and usually consist of simple tuples of slots and values describing the content to be realized, failing to offer any information about domains or slots that might be useful to generation models (Novikova et al., 2017b; Gardent et al., 2017; Wen et al., 2015). Table 1 shows examples of MRs from popular datasets. Neural network based approaches to data-totext natural language generation (NLG) have gained popularity in recent years, with the goal of generating a natural language prompt that accurately realizes an input meaning representation. To facilitate the training of neural network models, researchers created large datasets of paired utterances and their meaning representations. However, the creation of such datasets is an arduous task and they mostly consist of simple meaning representations composed of slot and value tokens to be realized. Th"
2020.inlg-1.35,D17-1239,0,0.0275041,"do; although some work has described how this could be useful (Walker et al., 2018). WebNLG (Colin et al., 2016) includes structured triples from Wikipedia which may constitute slightly richer MRs, but are not contextualized. Oraby et al. (2019) generate rich MRs that contain syntactic and stylistic information for generating descriptive restaurant reviews, but do not add in any contextual information that does not need to be included in the output realization. Table-to-text generation using ROTOWIRE (NBA players and stats) also includes richer information, but it is also not contextualized (Wiseman et al., 2017; Gong et al., 2019). Other previous work has attempted to address domain transfer in NLG. Dethlefs et al. (2017) use an abstract meaning representation (AMR) as a way to share common semantic information across domains. Wen et al. (2016) use a “data counterfeiting” method to generate synthetic data from existing domains to train models on unseen domains, then fine-tune on a small set of in-domain utterances. Tran et al. (2018) also train models on a source domain dataset, then fine-tune on a small sample of target domain utterances for domain adaptation. Rather than fine-tuning models for new"
2020.inlg-1.35,W07-0734,0,\N,Missing
2020.inlg-1.35,N19-1236,0,\N,Missing
2020.inlg-1.35,D19-1123,0,\N,Missing
2020.inlg-1.35,N16-1014,0,\N,Missing
2020.inlg-1.46,D18-1431,0,0.018451,"onal generation and weighted decoding. Conditional generation modifies the input to the model to condition on control parameters. Previous works proposed conditioning response generators on latent (Serban et al., 2016, 2017; Shen et al., 2017; Zhao et al., 2017) or discrete attributes, including dialog acts (Sankar and Ravi, 2019), sentiment (Sankar and Ravi, 2019), speaker identifiers (Li et al., 2016a), lexical features (See et al., 2019) or topics (Serban et al., 2017). Weighted decoding (See et al., 2019) instead uses token-level features that are controllable (Ghazvininejad et al., 2017; Baheti et al., 2018) and supplements the scores from the decoder model output with these features. Our work focuses on conditional generation methods with sentence-level control, as described in more detail in Section 4. There is also previous work on controlling attributes such as question asking at the dialog level. See et al. (2019) initialized the generation of turns of a dialog with a fixed distribution that specified what percentage of generated turns should include questions during the dialog. However this does not allow for flexible control where the number of questions may need to vary depending on the c"
2020.inlg-1.46,P17-4012,0,0.0314902,"ted is the same or different as compared to the knowledge sentence selected for the previous turn xj . Based on this information a certain subset of the transitions defined for dialog act planning are used to predict the dialog acts for the next response. 3.3.2 Knowledge-independent DA Planning The prediction of the dialog acts is done independently of the selected knowledge in four ways: 1. Simple DA planning: We define a set of transitions that determine the set of DAs for the next response based solely on the previous dialog act. 2. Seq2Seq Model for DA planning: Using the OpenNMT library (Klein et al., 2017), we train a sequence-to-sequence model based on bi-directional LSTMs with Luong attention (Luong et al., 2015) to estimate the DAs of the current turn given the dialog context Dj . During training, each dialog act label is a separate token in the vocabulary and has its own embedding vector. Both the dialog act and word embeddings are initialized randomly and learned during training. 3. PropQ DA planning: For comparison to previous work we use the method in (See et al., 2019) which initializes the distribution of questions to be asked at the beginning of the conversation. The work finds that t"
2020.inlg-1.46,P16-1094,0,0.0996359,"Missing"
2020.inlg-1.46,D16-1127,0,0.646489,"l., 2017). As seen in Figure 1, candidate A is a typical generic response given the dialog context. In order to deal with this problem, previous work proposed grounding generated responses on knowledge sentences related to the dialog context (Ghazvininejad et al., 2018; Yavuz et al., 2019; Zhou et al., 2018; Dinan et al., 2018; Gopalakrishnan et al., 2019). To improve the diversity of generated responses, others proposed conditioning response generation on latent (Serban et al., 2016, 2017; Shen et al., 2017; Zhao et al., 2017; Xing et al., 2016) or discrete attributes (Sankar and Ravi, 2019; Li et al., 2016a; See et al., 2019; Serban et al., 2017). These discrete attributes are typically presented to the decoder at the turn level, and are not associated with a specific segment of the output. Another issue with seq2seq approaches is that, due to the lack of explicit control mechanisms, the style of these responses does not always match with what would be suggested by user experience experts. For example, the generated response may not acknowledge what the user just said, or may 412 Proceedings of The 13th International Conference on Natural Language Generation, pages 412–421, c Dublin, Ireland, 1"
2020.inlg-1.46,W02-0109,0,0.236445,"ted to their turns in the conversation. However there is no fine-grained annotation of which knowledge sentence or sentences were used for a turn, hence we create ground-truth knowledge annotations as a corpus post-processing step. To obtain the knowledge annotation for each turn we use Equation 1 to compute similarity between xj+1 and km . To obtain the knowledge annotation for each sentence within a turn, we tokenize the turn into individual sentences. For each sentence we use the same equation to compute similarity between i snj+1 and km . For sentence-tokenization we use the NLTK library (Loper and Bird, 2002). We decide whether or not the turn or sentences within a turn should be linked to a knowledge sentence by manually setting a threshold value on the similarity score between the knowledge and turn or sentences within a turn. We use the same threshold, 0.2, as described in Section 3.2. 5.2.2 Annotating Dialog Acts We obtain the dialog acts for each sentence by running an off-the-shelf SVM dialog act tagger4 (Mezza et al., 2018) which takes in as input the current sentence to predict one of 11 dialog acts listed in Table 1. We also experimented with using 4 https://github.com/ColingPaper2018/dia"
2020.inlg-1.46,D15-1166,0,0.122866,"Missing"
2020.inlg-1.46,N18-5020,0,0.0275398,"nes the style of the response in the form of DAs to be realized. We have two forms of DA planning methods: Knowledge-dependent DA planning and Knowledge-independent DA planning. Figure 2 depicts the architecture of PD-NRG. Figure 2: Policy-driven neural response generation. There has been previous work on task-oriented systems that proposed explicit content and sentence planning (Walker et al., 2007) to further control the content and order of sentences within the generated response. Previous work for open-domain dialog systems also followed a similar method for content and sentence planning. Fang et al. (2018), Ahmadvand et al. (2018), Fulda et al. (2018), Pichl (2018), Cervone et al. (2017), Yu et al. (2019) and Bowden et al. (2019) extracted multiple features such as topic, intent, entities, and sentiment to send to a dialog policy model to plan the structure and content of the response. However, these previous works generated responses from a set of templates that are usually repetitive for open-domain conversations. Our work focuses on neural generative models for response generation in opendomain dialog systems. The closest work to ours in terms of learning a dialog policy for open-domain dial"
2020.inlg-1.46,P17-4008,0,0.0171471,"two main approaches, conditional generation and weighted decoding. Conditional generation modifies the input to the model to condition on control parameters. Previous works proposed conditioning response generators on latent (Serban et al., 2016, 2017; Shen et al., 2017; Zhao et al., 2017) or discrete attributes, including dialog acts (Sankar and Ravi, 2019), sentiment (Sankar and Ravi, 2019), speaker identifiers (Li et al., 2016a), lexical features (See et al., 2019) or topics (Serban et al., 2017). Weighted decoding (See et al., 2019) instead uses token-level features that are controllable (Ghazvininejad et al., 2017; Baheti et al., 2018) and supplements the scores from the decoder model output with these features. Our work focuses on conditional generation methods with sentence-level control, as described in more detail in Section 4. There is also previous work on controlling attributes such as question asking at the dialog level. See et al. (2019) initialized the generation of turns of a dialog with a fixed distribution that specified what percentage of generated turns should include questions during the dialog. However this does not allow for flexible control where the number of questions may need to v"
2020.inlg-1.46,W19-5901,0,0.21303,"ive responses (Wei et al., 2017). As seen in Figure 1, candidate A is a typical generic response given the dialog context. In order to deal with this problem, previous work proposed grounding generated responses on knowledge sentences related to the dialog context (Ghazvininejad et al., 2018; Yavuz et al., 2019; Zhou et al., 2018; Dinan et al., 2018; Gopalakrishnan et al., 2019). To improve the diversity of generated responses, others proposed conditioning response generation on latent (Serban et al., 2016, 2017; Shen et al., 2017; Zhao et al., 2017; Xing et al., 2016) or discrete attributes (Sankar and Ravi, 2019; Li et al., 2016a; See et al., 2019; Serban et al., 2017). These discrete attributes are typically presented to the decoder at the turn level, and are not associated with a specific segment of the output. Another issue with seq2seq approaches is that, due to the lack of explicit control mechanisms, the style of these responses does not always match with what would be suggested by user experience experts. For example, the generated response may not acknowledge what the user just said, or may 412 Proceedings of The 13th International Conference on Natural Language Generation, pages 412–421, c D"
2020.inlg-1.46,N19-1170,0,0.0820829,"in Figure 1, candidate A is a typical generic response given the dialog context. In order to deal with this problem, previous work proposed grounding generated responses on knowledge sentences related to the dialog context (Ghazvininejad et al., 2018; Yavuz et al., 2019; Zhou et al., 2018; Dinan et al., 2018; Gopalakrishnan et al., 2019). To improve the diversity of generated responses, others proposed conditioning response generation on latent (Serban et al., 2016, 2017; Shen et al., 2017; Zhao et al., 2017; Xing et al., 2016) or discrete attributes (Sankar and Ravi, 2019; Li et al., 2016a; See et al., 2019; Serban et al., 2017). These discrete attributes are typically presented to the decoder at the turn level, and are not associated with a specific segment of the output. Another issue with seq2seq approaches is that, due to the lack of explicit control mechanisms, the style of these responses does not always match with what would be suggested by user experience experts. For example, the generated response may not acknowledge what the user just said, or may 412 Proceedings of The 13th International Conference on Natural Language Generation, pages 412–421, c Dublin, Ireland, 15-18 December, 2020"
2020.inlg-1.46,W19-5917,1,0.901903,"og systems have typically been modeled using end-to-end approaches, more specifically encoder-decoder architectures (Sordoni et al., 2015; Serban et al., 2017, 2016; Vinyals and Le, 2015). These seq2seq models are commonly trained on a maximum likelihood objective, which leads to repetitive and uninformative responses (Wei et al., 2017). As seen in Figure 1, candidate A is a typical generic response given the dialog context. In order to deal with this problem, previous work proposed grounding generated responses on knowledge sentences related to the dialog context (Ghazvininejad et al., 2018; Yavuz et al., 2019; Zhou et al., 2018; Dinan et al., 2018; Gopalakrishnan et al., 2019). To improve the diversity of generated responses, others proposed conditioning response generation on latent (Serban et al., 2016, 2017; Shen et al., 2017; Zhao et al., 2017; Xing et al., 2016) or discrete attributes (Sankar and Ravi, 2019; Li et al., 2016a; See et al., 2019; Serban et al., 2017). These discrete attributes are typically presented to the decoder at the turn level, and are not associated with a specific segment of the output. Another issue with seq2seq approaches is that, due to the lack of explicit control me"
2020.inlg-1.46,2020.acl-main.183,0,0.0233133,"ntrol where the number of questions may need to vary depending on the course of the dialog. Therefore, we focus on learning a dialog policy model that automatically learns the style of the response based on the dialog context. Similar to previous work for response generation we ground our generated responses on knowledge. Ghazvininejad et al. (2018), Yavuz et al. (2019), and Zhou et al. (2018) used end-to-end memory networks, copy mechanisms and static graph attention mechanisms respectively to incorporate knowledge. Dinan et al. (2018), Gopalakrishnan et al. (2019), and (Roller et al., 2020; Smith et al., 2020) used memory networks based on transformer architectures (Vaswani et al., 2017) to encode knowledge sentences and dialog history to decode a response. 413 dialog policy has components that predict the individual elements of the action plan: knowledge selection and dialog act planning. Knowledge selection determines the knowledge to be integrated in the response by finding sentences from a knowledge document corpus that are relevant to the dialog context. Dialog act (DA) planning determines the style of the response in the form of DAs to be realized. We have two forms of DA planning methods: Kn"
2020.inlg-1.46,N15-1020,0,0.0857211,"Missing"
2020.inlg-1.46,D19-3014,0,0.0186653,"ds: Knowledge-dependent DA planning and Knowledge-independent DA planning. Figure 2 depicts the architecture of PD-NRG. Figure 2: Policy-driven neural response generation. There has been previous work on task-oriented systems that proposed explicit content and sentence planning (Walker et al., 2007) to further control the content and order of sentences within the generated response. Previous work for open-domain dialog systems also followed a similar method for content and sentence planning. Fang et al. (2018), Ahmadvand et al. (2018), Fulda et al. (2018), Pichl (2018), Cervone et al. (2017), Yu et al. (2019) and Bowden et al. (2019) extracted multiple features such as topic, intent, entities, and sentiment to send to a dialog policy model to plan the structure and content of the response. However, these previous works generated responses from a set of templates that are usually repetitive for open-domain conversations. Our work focuses on neural generative models for response generation in opendomain dialog systems. The closest work to ours in terms of learning a dialog policy for open-domain dialog is (Xu et al., 2018) who designed a policy network to predict dialog acts and fed those acts into"
2020.inlg-1.46,P17-1061,0,0.0764659,"likelihood objective, which leads to repetitive and uninformative responses (Wei et al., 2017). As seen in Figure 1, candidate A is a typical generic response given the dialog context. In order to deal with this problem, previous work proposed grounding generated responses on knowledge sentences related to the dialog context (Ghazvininejad et al., 2018; Yavuz et al., 2019; Zhou et al., 2018; Dinan et al., 2018; Gopalakrishnan et al., 2019). To improve the diversity of generated responses, others proposed conditioning response generation on latent (Serban et al., 2016, 2017; Shen et al., 2017; Zhao et al., 2017; Xing et al., 2016) or discrete attributes (Sankar and Ravi, 2019; Li et al., 2016a; See et al., 2019; Serban et al., 2017). These discrete attributes are typically presented to the decoder at the turn level, and are not associated with a specific segment of the output. Another issue with seq2seq approaches is that, due to the lack of explicit control mechanisms, the style of these responses does not always match with what would be suggested by user experience experts. For example, the generated response may not acknowledge what the user just said, or may 412 Proceedings of The 13th Internati"
2020.lrec-1.53,P19-3011,0,0.0284727,"ata allows for better model and performance comparisons on the task of multi-domain dialogue state tracking as well as other dialogue subproblems. 8. Bibliographical References Bapna, A., T¨ur, G., Hakkani-T¨ur, D. Z., and Heck, L. (2017). Towards zero-shot frame semantic parsing for domain scaling. ArXiv, abs/1707.02363. Budzianowski, P., Wen, T.-H., Tseng, B.-H., Casanueva, I., Ultes, S., Ramadan, O., and Gasic, M. (2018). Multiwoz - a large-scale multi-domain wizard-of-oz dataset for task-oriented dialogue modelling. In EMNLP. Gao, S., Sethi, A., Aggarwal, S., Chung, T., and HakkaniTur, D. (2019). Dialog state tracking: A neural reading comprehension approach. Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue (SIGDIAL). Goel, R., Paul, S., Chung, T., Lecomte, J., Mandal, A., and Hakkani-Tur, D. (2018). Flexible and scalable state tracking framework for goal-oriented dialogue systems. arXiv preprint arXiv:1811.12891. Goel, R., Paul, S., and Hakkani-Tur, D. (2019). Hyst: A hybrid approach for flexible and accurate dialogue state tracking. Interspeech, To Appear. Henderson, M., Thomson, B., and Williams, J. D. (2014). The second dialog state tracking challenge. In"
2020.nlp4convai-1.10,D19-5801,0,0.0744262,"RC (Devlin et al., 2019; Jin et al., 2019), we concatenate the slot question, the dialogue context and one of the answer choices into a long sequence. We then feed this sequence into a sentence encoder to obtain a logit vector. Given a question, we can get m logit vectors assuming there are m answer choices. We then transform these m logit vectors into a probability vector through a fully connected layer and a softmax layer, see Figure 2 for details. Reading Comprehension Datasets For spanbased RC dataset, we use the dataset from Machine Reading for Question Answering (MRQA) 2019 shared task (Fisch et al., 2019) that was focused on extractive question answering. MRQA contains six distinct datasets across different domains: SQuAD, NewsQA, TriviaQA, SearchQA, HotpotQA, and NaturalQuestions. In this dataset, any answer to a question is a segment of text or span in a given document. For multiple-choice RC dataset, we leverage the current largest multiplechoice QA dataset, RACE (Lai et al., 2017) as well as a dialogue-based multiple-choice QA dataset, DREAM (Sun et al., 2019). Both of these datasets are collected from English language exams that are carefully designed by educational experts to assess the"
2020.nlp4convai-1.10,P19-1546,0,0.167824,"Missing"
2020.nlp4convai-1.10,D18-1547,0,0.114707,"Missing"
2020.nlp4convai-1.10,2021.ccl-1.108,0,0.146693,"Missing"
2020.nlp4convai-1.10,N19-1423,0,0.168761,"sive) 3.3 Multiple-Choice Reading Comprehension to Categorical Dialogue State Tracking restaurant.semi.name: What is the name of the restaurant where the user wants to eat? Answer: [ 53-55 ] (Fitzbillies restaurant) Table 2: Sample dialogue from MultiWOZ dataset showing framing of extractive DST to span-based RC. The span text (or don’t care user utterance) is also shown in italics. have not been mentioned or accepted yet by the user. All these slots must be assigned a None value in the dialogue state. We can view such cases as no answer exists in reading comprehension formulation. Similar to Devlin et al. (2019) for SQuAD 2.0 task, we assign the answer span with start and Figure 2: Model architecture for categorical dialog state tracking. “Encoder”is a pre-trained sentence encoder such as BERT. “Classifier” is a top-level fully connected layer. The other type of slots in the dialogue state cannot be filled through exact match in the dialogue 82 Dialogue U: I am looking for a place to to stay that has cheap price range it should be in a type of hotel A: Okay , Do you have a specific area you want to stay in? U: No, I just need to make sure it’s cheap. Oh, and I need parking. 4 4.1 Experiments Datasets"
2020.nlp4convai-1.10,P18-2124,0,0.0789771,"Missing"
2020.nlp4convai-1.10,D16-1264,0,0.116149,"Missing"
2020.nlp4convai-1.10,Q19-1016,0,0.0508001,"Missing"
2020.nlp4convai-1.10,N18-3006,1,0.897625,"Missing"
2020.nlp4convai-1.10,Q19-1014,0,0.193139,"s “oh! and make sure it has parking” but the slot hotelparking only accepts values from {Yes, No, Don’t Care}. In this case, the state tracker needs to infer whether or not the user wants parking based on the user utterance and select the correct value from the list. These kind of slots may not have exact-match spans in the dialogue context but usually require a limited number of values to choose from. Tracking these type of slots is surprisingly similar to multiple-choice reading comprehension (MCRC) tasks. In comparison to span-based RC tasks, the answers of MCRC datasets (Lai et al., 2017; Sun et al., 2019) are often in the form of open, natural language sentences and are not restricted to spans in text. Following the traditional models of MCRC (Devlin et al., 2019; Jin et al., 2019), we concatenate the slot question, the dialogue context and one of the answer choices into a long sequence. We then feed this sequence into a sentence encoder to obtain a logit vector. Given a question, we can get m logit vectors assuming there are m answer choices. We then transform these m logit vectors into a probability vector through a fully connected layer and a softmax layer, see Figure 2 for details. Reading"
2020.nlp4convai-1.10,E17-1042,0,0.104744,"Missing"
2020.nlp4convai-1.10,P19-1078,0,0.0388503,"ty value) in MultiWOZ for fair comparison.) Table 3: Sample dialogue from MultiWOZ dataset showing MultiWOZ We use the largest available multidomain dialogue dataset with state annotation: MultiWOZ 2.0 (Budzianowski et al., 2018) and MultiWOZ 2.1 (Eric et al., 2019), an enhanced, less noisier version of MultiWOZ 2.0 dataset, which contains 7 distinct domains across 10K dialogues. We exclude hospital and police domain that have very few dialogues. This results in 5 remaining domains attraction, restaurant, taxi, train, hotel with a total of 30 (domain, slot) pairs in the dialog state following Wu et al. (2019); Zhang et al. (2019). framing of categorical DST to multiple-choice RC. context in a large number of cases. For example, a user might express intent for hotel parking as “oh! and make sure it has parking” but the slot hotelparking only accepts values from {Yes, No, Don’t Care}. In this case, the state tracker needs to infer whether or not the user wants parking based on the user utterance and select the correct value from the list. These kind of slots may not have exact-match spans in the dialogue context but usually require a limited number of values to choose from. Tracking these type of sl"
2020.nlp4convai-1.10,P18-1134,0,0.122515,"for all slots where the output space of a slot is constrained by the values in the ontology. However, such approaches cannot handle previously unseen values and do not scale well for slots such as restaurantname that can take potentially unbounded set of values. To alleviate these issues, Rastogi et al. (2017); Goel et al. (2018) generate and score slot-value candidates from the ontology, dialogue context ngrams, slot tagger outputs, or a combination of them. However, these approaches suffer if a reliable slot tagger is not available or if the slot value is longer than the candidate n-grams. Xu and Hu (2018) proposed attention-based pointing mechanism to find the start and end of the slot value to better tackle the issue of unseen slot values. Gao et al. (2019) proposed using a RC framework for state tracking. They track slot values by answering the question “what is the value of the slot?” through attention-based pointing to the dialogue context. Chao and Lane (2019); Rastogi et al. (2019) utilize BERT to encode the dialogue context and then point to slot-value span in the encoded context. Although these approaches are more practical and scalable, they suffer when the exact slot value does not a"
2020.nlp4convai-1.10,D17-1082,0,\N,Missing
2020.nlp4convai-1.10,W19-5932,1,\N,Missing
2020.sigdial-1.3,D18-1547,0,0.0128717,"e experiments presented here (Wen et al., 2016; Golovanov et al., 2019), but these methods do not produce NLG outputs that integrate attributes from two different sources into the same sentence. Our final results show that the ability of our self-training method to automatically construct new training instances results in high quality natural, coherent and grammatical outputs with high semantic accuracy. In future, we hope to generalize our novel selftraining method to build an NLG that can combine two distinct domains, e.g. hotels or movies combined with restaurants in multi-domain dialogue (Budzianowski et al., 2018; Gaˇsi´c et al., 2015; Hakkani-T¨ur et al., 2016; Cervone et al., 2019; Ultes et al., 2017). Ideally systems that cover multiple domains should be able to produce utterances that seamlessly integrate both domains, if data exists for each domain independently. However, there may be additional challenges in such combinations. Our results require the initial neural models to generate some combined outputs. It is not clear whether there are some aspects of our experimental setup that facilitate this, e.g. it may require some attributes to be shared across the two initial ontologies, or some share"
2020.sigdial-1.3,P17-4012,0,0.0181953,"were all RNN encoder-decoder systems. Here we also use a standard RNN Encoder–Decoder model (Sutskever et al., 2014) that maps a source sequence (the input MR) to a target sequence (the utterance text). We 3 The train and test data are available http://nlds.soe.ucsc.edu/source-blending-NLG http://nlds.soe.ucsc.edu/sentence-planning-NLG http://www.macs.hw.ac.uk/InteractionLab/E2E/ 23 at first implement a baseline model and then add three variations of model supervision that aim to improve semantic accuracy. All of the models are built with OpenNMT-py, a sequence-to-sequence modeling framework (Klein et al., 2017). Encoder. The MR is represented as a sequence of (attribute, value) pairs with separate vocabularies for attributes and values. Each attribute and each value are represented using 1-hot vectors. An (attribute, value) pair is represented by concatenating the two 1-hot vectors. The input sequence is processed using two single layer bidirectional-LSTM (Hochreiter and Schmidhuber, 1997) encoders. The first encoder operates at the pair level, producing a hidden state for each attribute-value pair of the input sequence. The second LSTM encoder is intended to produce utterance level context informat"
2020.sigdial-1.3,D16-1230,0,0.0233984,"Section 4.2. The retrofit MRs match the (errorful) NLG output: when these MR/NLG output pairs combine attributes from both sources, they provide novel corrected examples to add back into training. Text-to-Meaning Semantic Extractor Much previous work in NLG relies on a test set that provides gold reference outputs, and then applies automatic metrics such as BLEU that compare the gold reference to the model output (Papineni et al., 2002; Duˇsek et al., 2020), even though the limitations of BLEU for NLG are widely acknowledged (Belz and Reiter, 2006; Stent et al., 2005; Novikova et al., 2017b; Liu et al., 2016). To address these limitations, recent work has started to develop “referenceless” NLG evaluation metrics (Dusek et al., 2017; Kann et al., 2018; Tian et al., 2018; Mehri and Eskenazi, 2020). Since there are no reference outputs for the COM test set, we need a referenceless evaluation metric. We develop a rule-based text-to-MR semantic extractor (TTM) that allows us to compare the input MR to an MR automatically constructed from an NLG model textual output by the TTM, in order to calculate SER, the slot error rate. The TTM system is based on information extraction methods. We conduct a human e"
2020.sigdial-1.3,N18-3006,1,0.889013,"Missing"
2020.sigdial-1.3,D15-1166,0,0.00851762,"quence. The outputs of both encoders are combined via concatenation. That is, the final state of the second encoder is concatenated onto each hidden state output by the first encoder. The size of the pair level encoder is 46 units and the size of the MR encoder is 20 units. Model parameters are initialized using Glorot initialization (Glorot and Bengio, 2010) and optimized using Stochastic Gradient Descent with mini-batches of size 128. Decoder. The decoder is a uni-directional LSTM that uses global attention with input-feeding. Attention weights are calculated via the general scoring method (Luong et al., 2015). The decoder takes two inputs at each time step: the word embedding of the previous time step, and the attention weighted average of the encoder hidden states. The groundtruth previous word is used when training, and the predicted previous word when evaluating. Beam search with five beams is used during inference. Supervision. Figure 3 shows the baseline system architecture as well as three types of supervision, based on conditioning on source (E2E, NYC) information. The additional supervision is intended to help the model attend to the source domain information. We call the three types of su"
2020.sigdial-1.3,N19-1410,0,0.0132734,"we need a referenceless evaluation metric. We develop a rule-based text-to-MR semantic extractor (TTM) that allows us to compare the input MR to an MR automatically constructed from an NLG model textual output by the TTM, in order to calculate SER, the slot error rate. The TTM system is based on information extraction methods. We conduct a human evaluation of its accuracy below. A similar approach is used to calculate semantic accuracy in other work in NLG, including comparative system evaluation in the E2E Generation Challenge (Juraska et al., 2018; Duˇsek et al., 2020; Wiseman et al., 2017; Shen et al., 2019). The TTM relies on a rule-based automatic aligner that tags each output utterance with the attributes and values that it realizes. The aligner takes advantage of the fact that the RECOMMEND dialogue act, and the attributes and their values are typically realized from a domain-specific finite vocabulary. The output of the aligner is then used by the TTM extractor to construct an MR that matches the (potentially errorful) utterance that was generated by the NLG. We refer to this MR as the “retrofit MR”. The retrofit MR is then compared to the input MR in order to automatically calculate the slo"
2020.sigdial-1.3,2020.sigdial-1.28,0,0.164573,"into training. Text-to-Meaning Semantic Extractor Much previous work in NLG relies on a test set that provides gold reference outputs, and then applies automatic metrics such as BLEU that compare the gold reference to the model output (Papineni et al., 2002; Duˇsek et al., 2020), even though the limitations of BLEU for NLG are widely acknowledged (Belz and Reiter, 2006; Stent et al., 2005; Novikova et al., 2017b; Liu et al., 2016). To address these limitations, recent work has started to develop “referenceless” NLG evaluation metrics (Dusek et al., 2017; Kann et al., 2018; Tian et al., 2018; Mehri and Eskenazi, 2020). Since there are no reference outputs for the COM test set, we need a referenceless evaluation metric. We develop a rule-based text-to-MR semantic extractor (TTM) that allows us to compare the input MR to an MR automatically constructed from an NLG model textual output by the TTM, in order to calculate SER, the slot error rate. The TTM system is based on information extraction methods. We conduct a human evaluation of its accuracy below. A similar approach is used to calculate semantic accuracy in other work in NLG, including comparative system evaluation in the E2E Generation Challenge (Jura"
2020.sigdial-1.3,W17-5525,0,0.0314402,"Missing"
2020.sigdial-1.3,D17-1238,0,0.040736,"Missing"
2020.sigdial-1.3,W18-5019,1,0.887465,"Missing"
2020.sigdial-1.3,P02-1040,0,0.108015,"is .80 and the correlation with deletions, the most frequent error type, is .97. Retrofit MRs for Self-Training. The TTM is critical for our novel self-training method described in Section 4.2. The retrofit MRs match the (errorful) NLG output: when these MR/NLG output pairs combine attributes from both sources, they provide novel corrected examples to add back into training. Text-to-Meaning Semantic Extractor Much previous work in NLG relies on a test set that provides gold reference outputs, and then applies automatic metrics such as BLEU that compare the gold reference to the model output (Papineni et al., 2002; Duˇsek et al., 2020), even though the limitations of BLEU for NLG are widely acknowledged (Belz and Reiter, 2006; Stent et al., 2005; Novikova et al., 2017b; Liu et al., 2016). To address these limitations, recent work has started to develop “referenceless” NLG evaluation metrics (Dusek et al., 2017; Kann et al., 2018; Tian et al., 2018; Mehri and Eskenazi, 2020). Since there are no reference outputs for the COM test set, we need a referenceless evaluation metric. We develop a rule-based text-to-MR semantic extractor (TTM) that allows us to compare the input MR to an MR automatically constru"
2020.sigdial-1.3,W18-6512,0,0.0271224,"Missing"
2020.sigdial-1.3,W18-6535,1,0.853212,"ferent domain ontology in the restaurant domain, with novel attributes and dialogue acts not seen in the other dataset, e.g. only one has attributes representing family friendly and rating information, and only one has attributes for decor and service. Our aim is an NLG engine that can realize utterances for the extended combined ontology not seen in the training data, e.g. for MRs that specify values for family friendly, rating, decor and service. Figure 1 illustrates this task. Example E1 is from a training set referred to as NYC, from previous work on controllable sentence planning in NLG (Reed et al., 2018), while E2 is from the E2E NLG shared task (Novikova et al., 2017a). As we describe in detail in Section 2, E1 and E2 are based on two distinct ontologies. Example E3 illustrates the task addressed in this paper: we create a test set of novel MRs for the combined ontology, and train a model to generate high quality outputs where individual sentences realize attributes from both ontologies. To our knowledge, this is a completely novel task. While it is common practice in NLG to construct test sets of MRs that realize attribute combinations not seen in training, initial experiments Natural langu"
2020.sigdial-1.3,P17-4013,0,0.0323122,"Missing"
2020.sigdial-1.3,D19-1221,0,0.0173749,"existing within-domain training data. We show that we can combine two training datasets for the restaurant domain, that have different ontologies, and generate output that combines attributes from both sources, by applying a combination of neural supervision and a novel self-training method. While it is common practice to construct test sets with unseen attribute combinations, we know of no prior work based on constructing a new combined ontology. Our experiments show that the task is surprisingly adversarial, consistent with recent work suggesting that neural models often fail to generalize (Wallace et al., 2019; Feng et al., 2018; Ribeiro et al.; Goodfellow et al., 2014). Work on domain transfer shares similar goals to the experiments presented here (Wen et al., 2016; Golovanov et al., 2019), but these methods do not produce NLG outputs that integrate attributes from two different sources into the same sentence. Our final results show that the ability of our self-training method to automatically construct new training instances results in high quality natural, coherent and grammatical outputs with high semantic accuracy. In future, we hope to generalize our novel selftraining method to build an NLG"
2020.sigdial-1.3,N16-1015,0,0.0500517,"Missing"
2020.sigdial-1.3,D15-1199,0,0.0608914,"Missing"
2020.sigdial-1.3,D17-1239,0,0.0319969,"Missing"
2020.sigdial-1.3,W16-4620,0,0.024417,"Missing"
2020.sigdial-1.35,D18-1547,0,0.043355,"mation by knowledge access, but also maintain natural conversation. For example, the responses at t = {4, 8} paraphrase written sentences into a colloquial style, the responses at t = {4, 16} acknowledge before giving a statements, the responses at t = {8, 12} ask a follow-up question to the user. (a) Positions for augmentation (b) User utterances (c) System responses Figure 3: Crowdsourcing user interfaces for MultiWOZ data augmentation with knowledge access turns 4 Split Train Valid Test Total Data To address the proposed research problems, we collected an augmented version of MultiWOZ 2.1 (Budzianowski et al., 2018; Eric et al., 2019) with out-of-API-coverage turns grounded on external knowledge sources beyond the original database entries. This was incrementally done by the following three crowdsourcing tasks. First, crowd workers were given a dialogue sampled from the original MultiWOZ 2.1 conversations and asked to indicate an appropriate position to insert a new turn about a selected subject from external knowledge categories (Figure 3a). This task aims to collect user behaviors about when to ask a knowledge-seeking question for a given subject. It corresponds to the knowledge-seeking turn detection"
2020.sigdial-1.35,N19-1423,0,0.0509188,"nsupervised anomaly detection algorithm, Local Outlier Factor (LOF) (Breunig et al., 2000). The algorithm compares the local densities between a given input instance and its nearest neighbors. If the input has a significantly lower density than the neighbors, it is considered an anomaly. We built a knowledge-seeking turn detector with the LOF implementation in PyOD (Zhao et al., 2019) with its default configurations. The system includes all the user utterances in the original MultiWOZ 2.1 training set. Every utterance in both training and test sets was encoded by the uncased pre-trained BERT (Devlin et al., 2019) model. If training data is available for the knowledgeseeking turn detection, the most straightforward solution will be training a binary classifier in a supervised manner. In this experiment, we fine-tuned the uncased pre-trained BERT (Devlin et al., 2019) model on the training data in Section 4. The model takes each single user utterance ut as an input and generates the utterance representation as the final layer output for [CLS] which is a special token in the beginning of the input sequence. We added a single layer feedforward network on top of the utterance embeddings, which was trained"
2020.sigdial-1.35,P18-1138,0,0.0236476,"al language response to the user by natural language generation (Perera and Nand, 2017). On the other hand, social conversational systems typically follow an end-to-end approach, and aim to generate target responses based on the previous conversation context (Ritter et al., 2011; Vinyals and Le, 2015; Serban et al., 2017). Ghazvininejad et al. (2018) proposed an extension to these models that grounds the responses on unstructured, textual knowledge, by using end-to-end memory networks where an attention over the knowledge relevant to the conversation context is estimated. Along similar lines, Liu et al. (2018) used pattern matching, named entity recognition and linking to find facts relevant to the current dialogue and other related entities from a knowledge base. Zhou et al. (2018) proposed both static and dynamic graph attention mechanisms for knowledge selection and response generation, respectively, using knowledge graphs. More recently, Dinan et al. (2018) and Gopalakrishnan et al. (2019) both have publicly released large conversational data sets, where knowledge sentences related to each conversation turn are annotated. Our proposed task, data, and baseline models in this work differ from the"
2020.sigdial-1.35,D16-1264,0,0.0114454,"ased large conversational data sets, where knowledge sentences related to each conversation turn are annotated. Our proposed task, data, and baseline models in this work differ from these studies in the following aspects: we target task-oriented conversations with more clear goals and explicit dialogue states than social conversations; and we aim to incorporate task-specific domain knowledge instead of commonsense knowledge. 279 The other line of related work is machine reading comprehension which aims to answer questions given unstructured text (Richardson et al., 2013; Hermann et al., 2015; Rajpurkar et al., 2016) and has later been extended to conversational question answering (Choi et al., 2018; Reddy et al., 2019). In our work, the document required to generate a response needs to be identified according to the conversation context. The responses are also different in that, rather than plain answers to factual questions, we aim to form factually accurate responses that seamlessly blend into the conversation. 3 turns at t = {3, 7, 11, 15}, while f1 (Ut |K) = 0 for the other user turns at t = {1, 5, 9, 13}. 3.2 Once a given user turn at t is determined as a knowledge-seeking turn by f1 (Ut |K), it mov"
2020.sigdial-1.35,Q19-1016,0,0.0323172,"d. Our proposed task, data, and baseline models in this work differ from these studies in the following aspects: we target task-oriented conversations with more clear goals and explicit dialogue states than social conversations; and we aim to incorporate task-specific domain knowledge instead of commonsense knowledge. 279 The other line of related work is machine reading comprehension which aims to answer questions given unstructured text (Richardson et al., 2013; Hermann et al., 2015; Rajpurkar et al., 2016) and has later been extended to conversational question answering (Choi et al., 2018; Reddy et al., 2019). In our work, the document required to generate a response needs to be identified according to the conversation context. The responses are also different in that, rather than plain answers to factual questions, we aim to form factually accurate responses that seamlessly blend into the conversation. 3 turns at t = {3, 7, 11, 15}, while f1 (Ut |K) = 0 for the other user turns at t = {1, 5, 9, 13}. 3.2 Once a given user turn at t is determined as a knowledge-seeking turn by f1 (Ut |K), it moves forward with Knowledge Selection to sort out the relevant knowledge snippets. This task takes each pai"
2020.sigdial-1.35,D13-1020,0,0.0140398,"akrishnan et al. (2019) both have publicly released large conversational data sets, where knowledge sentences related to each conversation turn are annotated. Our proposed task, data, and baseline models in this work differ from these studies in the following aspects: we target task-oriented conversations with more clear goals and explicit dialogue states than social conversations; and we aim to incorporate task-specific domain knowledge instead of commonsense knowledge. 279 The other line of related work is machine reading comprehension which aims to answer questions given unstructured text (Richardson et al., 2013; Hermann et al., 2015; Rajpurkar et al., 2016) and has later been extended to conversational question answering (Choi et al., 2018; Reddy et al., 2019). In our work, the document required to generate a response needs to be identified according to the conversation context. The responses are also different in that, rather than plain answers to factual questions, we aim to form factually accurate responses that seamlessly blend into the conversation. 3 turns at t = {3, 7, 11, 15}, while f1 (Ut |K) = 0 for the other user turns at t = {1, 5, 9, 13}. 3.2 Once a given user turn at t is determined as"
2020.sigdial-1.35,D11-1054,0,0.330889,"ictionless task-oriented scenarios, where the flow of the conversation does not break when users have requests that are out of the coverage of APIs/DB but potentially are already available in external knowledge sources. Inspired by recent studies on knowledge-grounded conversational modeling (Zhou et al., 2018; Dinan et al., 2018; Galley et al., 2019; Gopalakrishnan et al., 2019), our proposed task aims to develop end-to-end dialogue systems to understand relevant domain knowledge, and generate system responses with the selected knowledge. Different from previous work on social conversations (Ritter et al., 2011; Vinyals and Le, 2015; Serban et al., 2017), this task addresses task-oriented conversations grounded on fine-grained domain-level or entity-level knowledge sources related to given dialogue contexts. Figure 1 shows an example conversation with unstructured knowledge access. The user utterances at turns t = {3, 7} and t = {11, 15} request the policy details about bringing pets and making payments, respectively, which are out of the coverage of the structured domain APIs. On the other hand, the relevant knowledge contents can be found from the external sources as in the rightmost column which"
2021.dialdoc-1.16,2020.lrec-1.53,1,0.654969,"ve the generalizability of our filtering mechanism for unseen domains, we merged the domains which require further entity-level analysis into an “Others” class and defined this task as a three-way classification: {“Train”, “Taxi”, and “Others”}. We implemented a domain classifier by finetuning the RoBERTa-Large model which takes the whole dialogue context and outputs a domain label. Considering that a new domain (i.e., “Attraction”) is introduced in the test set, we augmented the training data with 3,350 additional samples of the “Attraction” domain, which were obtained from the MultiWOZ 2.1 (Eric et al., 2020), the source of the DSTC9 Track 1 data (all augmented samples are labeled as “Others”). More specifically, we first find out those dialogues for “Attraction” in the train120 ing set of the MultiWOZ 2.1 dataset (this dataset contains seven domains including “Attraction”) by selecting dialogue turns that contain “Attraction” related slots. We then replace the original “Attraction” related slots with entities of the “Attraction” domain in the knowledge base K. Meanwhile we replace the last user utterances in the dialogues with the knowledge questions that belong to the replaced new entities. Tabl"
2021.dialdoc-1.16,W17-5506,0,0.102743,"formation extracted from dialogue context improves the knowledge selection and end-to-end performances. Through experiments, we achieve state-of-theart performance for both automatic and human evaluation metrics on the DSTC9 Track 1 benchmark dataset, validating the effectiveness of our contributions. 1 Introduction Driven by the fast progress of natural language processing techniques, we are now witnessing a variety of task-orientated dialogue systems being used in daily life. These agents traditionally rely on pre-defined APIs to complete the tasks that users request (Williams et al., 2017; Eric et al., 2017); however, some user requests are related to the task domain but beyond these APIs’ coverage (Kim et al., 2020a). For example, while task-oriented agents can help users book a hotel, they fall short of answering potential follow-up questions users may have, such as “whether they can bring their pets to the hotel”. These beyond-API-coverage user requests frequently refer to the task or entities that were discussed in the prior conversation and can be addressed by interpreting them in context and retrieving relevant domain knowledge from web pages, for example, from textual descriptions Dilek Ha"
2021.dialdoc-1.16,2020.sigdial-1.35,1,0.572793,"experiments, we achieve state-of-theart performance for both automatic and human evaluation metrics on the DSTC9 Track 1 benchmark dataset, validating the effectiveness of our contributions. 1 Introduction Driven by the fast progress of natural language processing techniques, we are now witnessing a variety of task-orientated dialogue systems being used in daily life. These agents traditionally rely on pre-defined APIs to complete the tasks that users request (Williams et al., 2017; Eric et al., 2017); however, some user requests are related to the task domain but beyond these APIs’ coverage (Kim et al., 2020a). For example, while task-oriented agents can help users book a hotel, they fall short of answering potential follow-up questions users may have, such as “whether they can bring their pets to the hotel”. These beyond-API-coverage user requests frequently refer to the task or entities that were discussed in the prior conversation and can be addressed by interpreting them in context and retrieving relevant domain knowledge from web pages, for example, from textual descriptions Dilek Hakkani-Tur Amazon Alexa AI hakkanit@amazon.com and frequently asked questions (FAQs). Most taskoriented dialogu"
2021.dialdoc-1.16,2020.acl-main.703,0,0.0211954,"uestions that belong to the replaced new entities. Table 1 gives one example for explanation. In this example, we replace the original entity of “funky fun house” with a new entity of “California Academy of Science” randomly selected from the “Attraction” domain of the knowledge base. Besides, we replace the original last user utterance with a knowledge question randomly selected from the FAQs of this new entity “California Academy of Science”. For response generation, we compared the following three pre-trained sequence-to-sequence (seq2seq) models: T5-Base (Raffel et al., 2020), BART-Large (Lewis et al., 2020), and PegasusLarge (Zhang et al., 2020). Each model inputs a concatenated sequence of the whole dialogue context and the knowledge answer and then outputs a response. The ground-truth knowledge answer is used in the training phase, while the top-1 candidate from the knowledge selection result is used in the test phase. 2.2.2 3 2.3 Entity Tracking Once the domain classifier predicts the ’Others’ label for a given turn, the entity tracking module is executed to detect the entities mentioned in the dialogue context and align them to the entity-level candidates in the knowledge base. We adopt an u"
2021.dialdoc-1.16,2021.ccl-1.108,0,0.0765936,"Missing"
2021.eacl-main.148,D18-1547,0,0.0570486,"Missing"
2021.eacl-main.148,2020.acl-main.12,0,0.0345178,"Missing"
2021.eacl-main.148,2020.acl-main.57,0,0.074658,"Missing"
2021.eacl-main.148,2020.sigdial-1.4,0,0.0220647,"Missing"
2021.eacl-main.148,P19-1546,0,0.0181847,"ser and system. These values are then used by Natural Language Generator (NLG) to generate system responses and fulfill the user goals. Many of the recent works (Wu et al., 2019; Zhang et al., 2019; Goel et al., 2019; Heck et al., 2020) have proposed various neural models that achieve good performance for the task but are data hungry in general. Therefore, adapting to a new unknown domain (target domain) requires large amounts of domain-specific annotations limiting their use. However, given a wide range of practical applications, there has been a recent interest in data-efficient approaches. Lee et al. (2019), Gao et al. (2020) used transformer (Vaswani et al., 2017) based models which significantly reduce data dependence. Further, Gao et al. (2020) model the problem as machine reading comprehension task and benefit from its readily available external datasets and methods. Wu et al. (2019) were first to propose transferring knowledge from one domain to another. Since, many domains like restaurant and hotel share a lot of common slots like name, area, rating, etc and hence such a transfer proved to be effective for a low-resource domain. More recently, Campagna et al. (2020) aimed at zero-shot DST"
2021.eacl-main.148,2021.ccl-1.108,0,0.0949522,"Missing"
2021.eacl-main.148,P19-1253,0,0.0186302,"he data tion θM from train tasks τ . This is achieved by minimizing the empirical loss as θ(k) = SGD(Dτtrain , Lτ , θ; k, α) (2) X (3) IN IT θM = arg min θ Lτ (Dτtrain ; θ(k) ) τ Note that the above optimization is complex and involve second-order derivatives. For computational benefits, Nichol et al. (2018) proposed REPTILE and showed that these terms can be ignored without effecting the performance of the meta-learning algorithm. We refer the reader to their work for more details. 3 Methodology In this work, we propose D-REPTILE, a metalearning algorithm specific to DST task. Following what Qian and Yu (2019) did for dialogue generation problem, we treat different domains as tasks for the meta-learning algorithm. Let D = {d1 , d2 , . . . dn } (eg. {restaurant, taxi, payment, . . .}) be the set of train domains for which we have annotated data available. Let pD (.) define a probability distribution over these domains. Let Dd1 , Dd2 . . . Ddn be the training data from each of these domains. Let M be any DST model with parameters θM . Let m be the task-batch size (number of domains in a batch in our case), α, β be the inner and outer learning rate respectively, k be the number of gradient steps. Let"
2021.eacl-main.148,D19-5801,0,0.0276431,"omplex dataset with mostly 5 different domains, 8438 dialogues while the latter is relatively simple synthetically generated dataset with 26 domains and 16142 dialogues. Both the datasets contains dialogues spanning multiple domains. Following the setting from Wu et al. (2019), for extracting data of a particular domain from the dataset, we consider all the dialogues in which that domain is present and ignore slots from other domains both in train and test set. Further, as shown by Gao et al. (2020), we use external datasets from Machine Reading for Question Answering (MRQA) 2019 shared task (Fisch et al., 2019), DREAM (Sun et al., 2019), RACE (Lai et al., 2017) to pre-train our transformer in our experiments and label it with suffix ’-RC’ to distinguish it from ’-base’ model. 4.2 Evaluation Metric Based on the objective in DST, there is a well established metric Joint Goal Accuracy (JGA). JGA is the fraction of total turns across all dialogues for which the predicted and ground truth dialogue state matches for all slots. Following Wu et al. (2019), for testing for a single target domain in a multidomain dialogue, we only consider slots from that domain in metric computation. Note that in some of our"
2021.eacl-main.148,2020.nlp4convai-1.10,1,0.864437,"Missing"
2021.eacl-main.148,D18-1398,0,0.0259,"roven to be very successful in efficient and fast adaptations to new tasks with very few labelled samples. These methods specifically aim at the setting where there are many similar tasks but very small amount of data for each task. Agnostic of the underlying model, these meta-learning algorithms spit out initialization for its parameters which when fine-tuned using low-resource target task achieves good performance. Following their widespread success in few-shot image classification, there has been a lot of recent work on their merit in natural language processing tasks. Huang et al. (2018); Gu et al. (2018); Sennrich and Zhang (2019); Bansal et al. (2019); Dou et al. (2019); Yan et al. (2020) 1730 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 1730–1739 April 19 - 23, 2021. ©2021 Association for Computational Linguistics attempt at using meta-learning for efficient transfer of knowledge from high-resource tasks to a low-resource task. Further, some of the more recent works (Dai et al., 2020; Qian and Yu, 2019) have shown meta-learners can be used for system response generation in TOD systems which is generally downstream task fo"
2021.eacl-main.148,P19-1021,0,0.0505992,"Missing"
2021.eacl-main.148,Q19-1014,0,0.0141959,"different domains, 8438 dialogues while the latter is relatively simple synthetically generated dataset with 26 domains and 16142 dialogues. Both the datasets contains dialogues spanning multiple domains. Following the setting from Wu et al. (2019), for extracting data of a particular domain from the dataset, we consider all the dialogues in which that domain is present and ignore slots from other domains both in train and test set. Further, as shown by Gao et al. (2020), we use external datasets from Machine Reading for Question Answering (MRQA) 2019 shared task (Fisch et al., 2019), DREAM (Sun et al., 2019), RACE (Lai et al., 2017) to pre-train our transformer in our experiments and label it with suffix ’-RC’ to distinguish it from ’-base’ model. 4.2 Evaluation Metric Based on the objective in DST, there is a well established metric Joint Goal Accuracy (JGA). JGA is the fraction of total turns across all dialogues for which the predicted and ground truth dialogue state matches for all slots. Following Wu et al. (2019), for testing for a single target domain in a multidomain dialogue, we only consider slots from that domain in metric computation. Note that in some of our experiments (where explic"
2021.eacl-main.148,P19-1078,0,0.358998,"ific goal (for example hotel reservation). Many businesses from wide-variety of domains (like hotel, restaurant, car-rental, payments etc) have adopted these systems to cut down their cost on customer support services. Almost all such systems have a Dialogue State Tracking (DST) module which keeps track of values for some predefined domain-specific slots (example hotel-name, restaurant-rating etc) after every turn of utterances from user and system. These values are then used by Natural Language Generator (NLG) to generate system responses and fulfill the user goals. Many of the recent works (Wu et al., 2019; Zhang et al., 2019; Goel et al., 2019; Heck et al., 2020) have proposed various neural models that achieve good performance for the task but are data hungry in general. Therefore, adapting to a new unknown domain (target domain) requires large amounts of domain-specific annotations limiting their use. However, given a wide range of practical applications, there has been a recent interest in data-efficient approaches. Lee et al. (2019), Gao et al. (2020) used transformer (Vaswani et al., 2017) based models which significantly reduce data dependence. Further, Gao et al. (2020) model the proble"
2021.eacl-main.148,2020.acl-main.654,0,0.0623726,"Missing"
2021.inlg-1.9,P84-1044,0,0.71927,"Missing"
2021.inlg-1.9,D18-1076,0,0.0267875,"dge sentences per dialogue turn, and demonstrates significantly more knowledge diversity. Using WOW++, we then benchmark a number of different knowledge ranking algorithms using both standard information retrieval automatic measures as well as extrinsic human evaluation on generated responses. Our results indicate that neural rerankers using WOW++ are able to outperform other algorithms such as traditional IR baselines and neural models trained using the original WOW data. 2 took a tremendous leap forward with the introduction of standard datasets of knowledge-grounded dialogues. The work of (Zhou et al., 2018; Dinan et al., 2019; Gopalakrishnan et al., 2019) produced such corpora with upwards of 10K dialogues and up to 10s of dialogue turns leveraging knowledge from diverse sources such as Wikipedia, and the Washington Post. While certainly a step forward, these datasets introduced some unreasonable data constraints that aren’t apt to the knowledge setting such as either no explicitly-annotated knowledge snippets or only a single one, making training of robust knowledge selection systems very difficult. Since the introduction of these corpora, numerous groups have tackled the knowledge selection p"
2021.inlg-1.9,2020.eval4nlp-1.1,0,0.0118077,"ational systems (Ram et al., 2018; Khatri et al., 2018; Gabriel et al., 2020). In one line of work, a number of industry research groups have demonstrated that large quantities of chat data coupled with the latest highcapacity Transformer-based models can produce particularly engaging and convincing conversational experiences (Adiwardana et al., 2020; Roller et al., 2020). While these models produce impressive outputs, they consciously shirk any explicit knowledge-selection mechanisms. Any knowledgeable appearance in their outputs tends to be a consequence of facts memorized in training data (Lux et al., 2020). In addition, the models have a tendency to generate facts that may be factually inaccurate, referred to as factual hallucination. Knowledge selection in open-domain systems 3 WOW++ The WOW++ dataset we describe below is an augmented dataset based on the Wizard of Wikipedia (WOW) corpus (Dinan et al., 2019). The WOW corpus consists of 22,311 dialogues containing 201,999 turns. The dialogues are comprised of two interlocutors who engage in chit chat on a given topic where one interlocutor is a knowledgeable expert in the topic. The expert, or wizard, is provided access to knowledge snippets fr"
2021.maiworkshop-1.11,P18-1238,0,0.0215,"raph. On the basis of the visually-grounded graph, we apply a contrastive loss and a masked language model loss that explicitly encourage image-text alignment. Furthermore, we propose a per-triplet (object, relation, subject) contrastive loss to align object and relation representations across the two modalities respectively. We adopt a set of datasets, including Microsoft COCO Captions dataset (Lin et al., 2014), Visual Genome (Krishna et al., 2016), VQA (Antol et al., 2015), GQA (Hudson and Manning, 2019), Flicker 30k (Young et al., 2014), SBU (Ordonez et al., 2011), and Conceptual Caption (Sharma et al., 2018) to pre-train our model and fine-tune it on visual compositional question answering (GQA) (Hudson and Manning, 2019). Our preliminary analyses show improved performance and demonstrate the potential of the proposed approach on broader visual-language applications. 2 ods in that we incorporate the visual scene graph extracted from the image to enhance the cross-modal representation learning. The structured, visuallygrounded graph encodes rich semantic information (e.g., objects, relationships), which, compared to isolated object tags (Li et al., 2020) and bare image text singular features (Chen"
2021.maiworkshop-1.11,Q14-1006,0,0.0378545,"n learn to align to the image regions already associated with the scene graph. On the basis of the visually-grounded graph, we apply a contrastive loss and a masked language model loss that explicitly encourage image-text alignment. Furthermore, we propose a per-triplet (object, relation, subject) contrastive loss to align object and relation representations across the two modalities respectively. We adopt a set of datasets, including Microsoft COCO Captions dataset (Lin et al., 2014), Visual Genome (Krishna et al., 2016), VQA (Antol et al., 2015), GQA (Hudson and Manning, 2019), Flicker 30k (Young et al., 2014), SBU (Ordonez et al., 2011), and Conceptual Caption (Sharma et al., 2018) to pre-train our model and fine-tune it on visual compositional question answering (GQA) (Hudson and Manning, 2019). Our preliminary analyses show improved performance and demonstrate the potential of the proposed approach on broader visual-language applications. 2 ods in that we incorporate the visual scene graph extracted from the image to enhance the cross-modal representation learning. The structured, visuallygrounded graph encodes rich semantic information (e.g., objects, relationships), which, compared to isolated"
2021.naacl-demos.15,P16-1101,0,0.119186,"Missing"
2021.naacl-demos.15,N18-1202,0,0.0349262,"Missing"
2021.naacl-demos.15,N07-2038,0,0.211771,"Missing"
2021.naacl-demos.15,E17-1042,0,0.0349138,"Missing"
2021.naacl-demos.15,P17-1062,0,0.0536708,"Missing"
2021.naacl-demos.15,N19-2011,0,0.0247189,"Missing"
2021.naacl-industry.4,C18-1139,0,0.151896,"e context information. • In an end2end evaluation, we demonstrate that incorporating ER information improves quality of neural response generation models in open domain conversations. 2 2.1 2.2 Neural Entity Linking NEL typically involves two tasks: recognizing named entities in a given text and then disamgibuating the entity mentions according to the knowledge base (KB). Researchers have shown great success in NER with the help of Convolutional Neural Networks (CNNs), Bidirectional Recurrent Neural Networks (Bi-RNNs), and attention mechanisms along with a CRF decoder (Chiu and Nichols, 2016; Akbik et al., 2018; Ghaddar and Langlais, 2018; Jiang et al., 2019; Baevski et al., 2019; Yamada et al., 2020). Deep neural networks (DNNs) are also dominant in entity resolution tasks. They are used to calculate the semantic similarity between the recognized entity mentions and the entities in the KB (Yamada et al., 2016; Ganea and Hofmann, 2017; Sil et al., 2018; Raiman and Raiman, 2018). However, previous NEL work has mainly focused on news or formal documents, which is different from open-domain dialogues in many aspects. Sentences in open-domain dialogues are more informal, making it more difficult to reco"
2021.naacl-industry.4,D19-1539,0,0.0448174,"Missing"
2021.naacl-industry.4,D19-1367,0,0.0213049,"n, we demonstrate that incorporating ER information improves quality of neural response generation models in open domain conversations. 2 2.1 2.2 Neural Entity Linking NEL typically involves two tasks: recognizing named entities in a given text and then disamgibuating the entity mentions according to the knowledge base (KB). Researchers have shown great success in NER with the help of Convolutional Neural Networks (CNNs), Bidirectional Recurrent Neural Networks (Bi-RNNs), and attention mechanisms along with a CRF decoder (Chiu and Nichols, 2016; Akbik et al., 2018; Ghaddar and Langlais, 2018; Jiang et al., 2019; Baevski et al., 2019; Yamada et al., 2020). Deep neural networks (DNNs) are also dominant in entity resolution tasks. They are used to calculate the semantic similarity between the recognized entity mentions and the entities in the KB (Yamada et al., 2016; Ganea and Hofmann, 2017; Sil et al., 2018; Raiman and Raiman, 2018). However, previous NEL work has mainly focused on news or formal documents, which is different from open-domain dialogues in many aspects. Sentences in open-domain dialogues are more informal, making it more difficult to recognize and disambiguate entities. In addition, si"
2021.naacl-industry.4,Q17-1010,0,0.0127932,"Missing"
2021.naacl-industry.4,D17-1230,0,0.223866,"i.e., NER and ER standalone performance, we conduct an extrinsic evaluation where NER and ER results are integrated in a knowledge grounded neural response generation model in an open domain conversation system and response quality is evaluated. Our major contributions can Introduction Building an informative open-domain conversational agent that can naturally interact with humans has been one of recent scientific research topics. Inspired by the development of neural networks, neural generation based conversation systems have made great progress (Sutskever et al., 2014; Vinyals and Le, 2015; Li et al., 2017; Wolf et al., 2019a; Zhou et al., 2020). However, one issue in such approaches is that the neural models often produce universal and less informative responses (Huang et al., 2020). To address this issue, previous work proposed to incorporate external information into the response generation models, such as topics (Xing et al., 2017) and emotions (Zhou et al., 2018a). One line of research investigates the use of external knowledge to enrich the information of the responses (Ghazvininejad et al., 2018; Young et al., 2018; Dinan et al., 2018; Gopalakrishnan et al., 2019; Meng et al., 2020). ∗ T"
2021.naacl-industry.4,Q16-1026,0,0.133604,"rt models that do not use context information. • In an end2end evaluation, we demonstrate that incorporating ER information improves quality of neural response generation models in open domain conversations. 2 2.1 2.2 Neural Entity Linking NEL typically involves two tasks: recognizing named entities in a given text and then disamgibuating the entity mentions according to the knowledge base (KB). Researchers have shown great success in NER with the help of Convolutional Neural Networks (CNNs), Bidirectional Recurrent Neural Networks (Bi-RNNs), and attention mechanisms along with a CRF decoder (Chiu and Nichols, 2016; Akbik et al., 2018; Ghaddar and Langlais, 2018; Jiang et al., 2019; Baevski et al., 2019; Yamada et al., 2020). Deep neural networks (DNNs) are also dominant in entity resolution tasks. They are used to calculate the semantic similarity between the recognized entity mentions and the entities in the KB (Yamada et al., 2016; Ganea and Hofmann, 2017; Sil et al., 2018; Raiman and Raiman, 2018). However, previous NEL work has mainly focused on news or formal documents, which is different from open-domain dialogues in many aspects. Sentences in open-domain dialogues are more informal, making it mo"
2021.naacl-industry.4,D17-1277,0,0.0589877,"Missing"
2021.naacl-industry.4,C18-1161,0,0.0244133,"n. • In an end2end evaluation, we demonstrate that incorporating ER information improves quality of neural response generation models in open domain conversations. 2 2.1 2.2 Neural Entity Linking NEL typically involves two tasks: recognizing named entities in a given text and then disamgibuating the entity mentions according to the knowledge base (KB). Researchers have shown great success in NER with the help of Convolutional Neural Networks (CNNs), Bidirectional Recurrent Neural Networks (Bi-RNNs), and attention mechanisms along with a CRF decoder (Chiu and Nichols, 2016; Akbik et al., 2018; Ghaddar and Langlais, 2018; Jiang et al., 2019; Baevski et al., 2019; Yamada et al., 2020). Deep neural networks (DNNs) are also dominant in entity resolution tasks. They are used to calculate the semantic similarity between the recognized entity mentions and the entities in the KB (Yamada et al., 2016; Ganea and Hofmann, 2017; Sil et al., 2018; Raiman and Raiman, 2018). However, previous NEL work has mainly focused on news or formal documents, which is different from open-domain dialogues in many aspects. Sentences in open-domain dialogues are more informal, making it more difficult to recognize and disambiguate entit"
2021.naacl-industry.4,P19-1001,0,0.0128277,"n, since conversations are multi-turn, the semantic information in the current utterance is ambiguous and context needs to be considered. In this paper, we investigate NEL in open-domain conversational data and propose context-aware NER and ER models. Related Work Open-domain Conversation System Inspired by the availability of conversational data and the prosperity of neural networks, building open-domain conversation systems by data-driven approaches has achieved great progress. Previous methods can be roughly divided into two categories, retrieval-based (Zhang et al., 2018; Wu et al., 2019; Tao et al., 2019) and generation-based (Vinyals and Le, 2015; Li et al., 2017; Asghar et al., 2018; Tao et al., 2018). Chen et al. (2017) point out that conventional sequence-to-sequence methods tend to generate trivial responses that lack information and diversity. To address this issue, a line of research proposes to incorporate external knowledge into the generation process. Most of the work in this line retrieves knowledge based on a search or retrieval step first, and followed by further reranking of retrieved relevant knowledge snippets (Ghazvininejad et al., 2018; Young et al., 2018; Zhou et al., 27 Sup"
2021.naacl-industry.4,2020.cl-1.2,0,0.026393,"Missing"
2021.naacl-industry.4,J19-1005,0,0.0208717,"ities. In addition, since conversations are multi-turn, the semantic information in the current utterance is ambiguous and context needs to be considered. In this paper, we investigate NEL in open-domain conversational data and propose context-aware NER and ER models. Related Work Open-domain Conversation System Inspired by the availability of conversational data and the prosperity of neural networks, building open-domain conversation systems by data-driven approaches has achieved great progress. Previous methods can be roughly divided into two categories, retrieval-based (Zhang et al., 2018; Wu et al., 2019; Tao et al., 2019) and generation-based (Vinyals and Le, 2015; Li et al., 2017; Asghar et al., 2018; Tao et al., 2018). Chen et al. (2017) point out that conventional sequence-to-sequence methods tend to generate trivial responses that lack information and diversity. To address this issue, a line of research proposes to incorporate external knowledge into the generation process. Most of the work in this line retrieves knowledge based on a search or retrieval step first, and followed by further reranking of retrieved relevant knowledge snippets (Ghazvininejad et al., 2018; Young et al., 2018;"
2021.naacl-industry.4,2020.emnlp-main.523,0,0.0271871,"formation improves quality of neural response generation models in open domain conversations. 2 2.1 2.2 Neural Entity Linking NEL typically involves two tasks: recognizing named entities in a given text and then disamgibuating the entity mentions according to the knowledge base (KB). Researchers have shown great success in NER with the help of Convolutional Neural Networks (CNNs), Bidirectional Recurrent Neural Networks (Bi-RNNs), and attention mechanisms along with a CRF decoder (Chiu and Nichols, 2016; Akbik et al., 2018; Ghaddar and Langlais, 2018; Jiang et al., 2019; Baevski et al., 2019; Yamada et al., 2020). Deep neural networks (DNNs) are also dominant in entity resolution tasks. They are used to calculate the semantic similarity between the recognized entity mentions and the entities in the KB (Yamada et al., 2016; Ganea and Hofmann, 2017; Sil et al., 2018; Raiman and Raiman, 2018). However, previous NEL work has mainly focused on news or formal documents, which is different from open-domain dialogues in many aspects. Sentences in open-domain dialogues are more informal, making it more difficult to recognize and disambiguate entities. In addition, since conversations are multi-turn, the semant"
2021.naacl-industry.4,K16-1025,0,0.0268942,"samgibuating the entity mentions according to the knowledge base (KB). Researchers have shown great success in NER with the help of Convolutional Neural Networks (CNNs), Bidirectional Recurrent Neural Networks (Bi-RNNs), and attention mechanisms along with a CRF decoder (Chiu and Nichols, 2016; Akbik et al., 2018; Ghaddar and Langlais, 2018; Jiang et al., 2019; Baevski et al., 2019; Yamada et al., 2020). Deep neural networks (DNNs) are also dominant in entity resolution tasks. They are used to calculate the semantic similarity between the recognized entity mentions and the entities in the KB (Yamada et al., 2016; Ganea and Hofmann, 2017; Sil et al., 2018; Raiman and Raiman, 2018). However, previous NEL work has mainly focused on news or formal documents, which is different from open-domain dialogues in many aspects. Sentences in open-domain dialogues are more informal, making it more difficult to recognize and disambiguate entities. In addition, since conversations are multi-turn, the semantic information in the current utterance is ambiguous and context needs to be considered. In this paper, we investigate NEL in open-domain conversational data and propose context-aware NER and ER models. Related Wo"
2021.naacl-industry.4,C18-1317,0,0.0260671,"and disambiguate entities. In addition, since conversations are multi-turn, the semantic information in the current utterance is ambiguous and context needs to be considered. In this paper, we investigate NEL in open-domain conversational data and propose context-aware NER and ER models. Related Work Open-domain Conversation System Inspired by the availability of conversational data and the prosperity of neural networks, building open-domain conversation systems by data-driven approaches has achieved great progress. Previous methods can be roughly divided into two categories, retrieval-based (Zhang et al., 2018; Wu et al., 2019; Tao et al., 2019) and generation-based (Vinyals and Le, 2015; Li et al., 2017; Asghar et al., 2018; Tao et al., 2018). Chen et al. (2017) point out that conventional sequence-to-sequence methods tend to generate trivial responses that lack information and diversity. To address this issue, a line of research proposes to incorporate external knowledge into the generation process. Most of the work in this line retrieves knowledge based on a search or retrieval step first, and followed by further reranking of retrieved relevant knowledge snippets (Ghazvininejad et al., 2018; You"
2021.naacl-industry.4,2020.emnlp-main.272,0,0.0426753,"1, 2021. ©2021 Association for Computational Linguistics Figure 1: An example dialog illustrating the pipeline of NER, ER, and response generation. The bold sentence in the utterances is the current utterance and the previous utterances are the context. The current utterance and its context are fed to the NER module to identify the entity mentions. Then the ER module takes the entity mentions and all the sentences as input to resolve the entity. The response generation module produces an output based on the knowledge entity information and the dialog input. 2018b; Gopalakrishnan et al., 2019; Zhao et al., 2020). In our work, we propose neural entity recognition and linking to identify and resolve entities more accurately in order to obtain more relevant knowledge for knowledge grounded response generation. be summarized as follows: • We propose neural network based contextaware models for NER and ER respectively in open domain conversations. • Experimental results on different conversation datasets show that our proposed context-aware NER and ER models outperform other stateof-the-art models that do not use context information. • In an end2end evaluation, we demonstrate that incorporating ER informa"
2021.nlp4convai-1.21,W18-2706,0,0.0179524,"ves in the template >2 Table 2: Lexical style parameters and possible values. P  T ot sentation: f (¯ ot ) = f t=1 T . The classifiers are used for annotating the semantic parameters of the SGD data and for the style control models described in Section 5. 5 Style Controlled Text Generation 5.1 Conditional Training (CT) Controllable generation entails modeling p(x|a), where a is a control variable and x is the generated sequence. However, a pre-trained language model such as GPT-2 is only trained to learn p(x). On the other hand, conditional training (Kikuchi et al., 2016; Peng et al., 2018; Fan et al., 2018; See et al., 2019) refers to directly learning the conditional generative model p(x|a). The results are of high quality because the model is trained to directly maximize p(x|a), but this comes at the expense of fixing the control variable upfront and of re-training the entire model for each new control variable. In this work, we require a controlled generation method that is able to simultaneously render the semantic content given the schemata while achieving the desired stylistic goals. We also require the method to be both stable (preserve the fluency To perform style control, we fine-tune"
2021.nlp4convai-1.21,W17-4912,0,0.0197705,"pending a increasing index (e.g., San Jose → $slot1) for better generalization; and (2) we use only domain, meaning representations (MRs), and slot description as input data. Domain provides the context of the conversation (e.g., Restaurants); an Controllable text generation is an emerging research field. Current methods for controlling styles in text generation involve learning a conditional generative model or designing an appropriate decoding strategy. There are many methods proposed for learning a good conditional generative model. These include conditional training (Kikuchi et al., 2016; Ficler and Goldberg, 2017; Keskar et al., 2019; See et al., 2019), fine-tuning language models with external attribute models or side models (Dathathri et al., 2020; Zhang et al., 2020), finetuning models with reinforcement learning and hu1 The Schema-guided Dialogue Dataset: https: man feedback (Ziegler et al., 2019), training gen- //github.com/google-research-datasets/ erative adversarial models (Yu et al., 2017), and dstc8-schema-guided-dialogue 229 MR contains a dialog act, a slot and a value (e.g., OFFER(city=$slot2)); and the slot description describes the meaning of the slot in natural language. Table 8 in Appe"
2021.nlp4convai-1.21,D19-5602,0,0.0621314,"Missing"
2021.nlp4convai-1.21,D18-1507,0,0.0490074,"Missing"
2021.nlp4convai-1.21,W16-6626,0,0.0680588,"Missing"
2021.nlp4convai-1.21,W18-6539,0,0.020351,"ing, stylistic control is also achievable for more semantically complex styles using discriminatorbased guided decoding methods. The results also suggest that methods that are more scalable (with less hyper-parameters tuning) and that disentangle content generation and stylistic variations are more effective at achieving semantic correctness and style accuracy. 1 Introduction Natural Language Generation (NLG) for taskoriented dialogue focuses on effectively generating responses based on inputs that are frequently in the form of a structured meaning representation (MR) (Moryossef et al., 2019; Dušek et al., 2018; Colin et al., 2016; Wen et al., 2015). Recent work has suggested a schema-guided paradigm for taskoriented dialogue by adding descriptions in natural language form (Lin et al., 2021; Du et al., 2020; ∗ Rastogi et al., 2019; Bapna et al., 2017). Compared to structured MRs, dialogue schemata contain much richer contextual information, leading to better generated outputs. Although the primary aim of task-oriented NLG is to effectively generate outputs that realize system dialogue actions and communicate their associated contents correctly, it is often desirable to control the stylistic variatio"
2021.nlp4convai-1.21,P17-4008,0,0.228572,"useful to stylistically vary responses, e.g., using shorter responses for spoken dialogue systems, longer responses if the system includes visual modality through a screen, or emotion-specific responses that appropriately address user sentiment. Previous work on controlled text generation aimed at achieving stylistic goals has not focused on a schema-guided paradigm where specific content must be communicated correctly; instead, most work focuses more on unconstrained text-to-text generation without explicit meaning representations (Liu et al., 2021; Krause et al., 2020; Keskar et al., 2019; Ghazvininejad et al., 2017). Meanwhile, work on schema-guided NLG has primarily focused on generating fluent outputs that achieve low semantic error rather than achieving stylistic goals (Kale and Rastogi, 2020; Peng et al., 2020; Du et al., 2020). In this paper, we hope to fill the gap on stylistic control and evaluation for schemaguided NLG. Our contributions in this paper are three-fold: Work done as an intern at Amazon Alexa AI. 1. We describe how we pre-process and annotate style parameters within the Schema-guided Dialogue (SGD) dataset (Rastogi et al., 2019). 228 Proceedings of the Third Workshop on Natural Langu"
2021.nlp4convai-1.21,P18-1152,0,0.0272573,"ded paradigm has stronger restrictions on the degree of freedom allowed for content generation. We show that methods that disentangle content generation and style variations, especially for more semantically complex styles, result in better overall performance on semantic and stylistic control. 2 Related Work training variational auto-encoders (Yu et al., 2017; Hu et al., 2017). Others have worked on designing a good decoding strategy to guide generation, where the decoding procedure is guided by a scoring function or discriminator. These include weighted decoding (Ghazvininejad et al., 2017; Holtzman et al., 2018; See et al., 2019) and guided generation (Krause et al., 2020). Other lines of work include curating training data with rich style markup to facilitate training models with explicit stylistic supervision Oraby et al. (2019, 2018). While this previous work does focus on controllable text generation, most work has been carried out in a text-to-text generation setting, without specific semantic constraints. Instead, we focus on the task-oriented dialogue framework where specific values must be communicated, and conduct a rigorous evaluation of different methods and their efficacy on different fo"
2021.nlp4convai-1.21,2020.emnlp-main.527,0,0.0412704,"cific responses that appropriately address user sentiment. Previous work on controlled text generation aimed at achieving stylistic goals has not focused on a schema-guided paradigm where specific content must be communicated correctly; instead, most work focuses more on unconstrained text-to-text generation without explicit meaning representations (Liu et al., 2021; Krause et al., 2020; Keskar et al., 2019; Ghazvininejad et al., 2017). Meanwhile, work on schema-guided NLG has primarily focused on generating fluent outputs that achieve low semantic error rather than achieving stylistic goals (Kale and Rastogi, 2020; Peng et al., 2020; Du et al., 2020). In this paper, we hope to fill the gap on stylistic control and evaluation for schemaguided NLG. Our contributions in this paper are three-fold: Work done as an intern at Amazon Alexa AI. 1. We describe how we pre-process and annotate style parameters within the Schema-guided Dialogue (SGD) dataset (Rastogi et al., 2019). 228 Proceedings of the Third Workshop on Natural Language Processing for Conversational AI, pages 228–242 November 10, 2021. ©2021 Association for Computational Linguistics 2. We experiment with controlling different styles with various"
2021.nlp4convai-1.21,D16-1140,0,0.128711,"ding a $ prefix and appending a increasing index (e.g., San Jose → $slot1) for better generalization; and (2) we use only domain, meaning representations (MRs), and slot description as input data. Domain provides the context of the conversation (e.g., Restaurants); an Controllable text generation is an emerging research field. Current methods for controlling styles in text generation involve learning a conditional generative model or designing an appropriate decoding strategy. There are many methods proposed for learning a good conditional generative model. These include conditional training (Kikuchi et al., 2016; Ficler and Goldberg, 2017; Keskar et al., 2019; See et al., 2019), fine-tuning language models with external attribute models or side models (Dathathri et al., 2020; Zhang et al., 2020), finetuning models with reinforcement learning and hu1 The Schema-guided Dialogue Dataset: https: man feedback (Ziegler et al., 2019), training gen- //github.com/google-research-datasets/ erative adversarial models (Yu et al., 2017), and dstc8-schema-guided-dialogue 229 MR contains a dialog act, a slot and a value (e.g., OFFER(city=$slot2)); and the slot description describes the meaning of the slot in natura"
2021.nlp4convai-1.21,2021.naacl-main.448,0,0.0349808,"able (with less hyper-parameters tuning) and that disentangle content generation and stylistic variations are more effective at achieving semantic correctness and style accuracy. 1 Introduction Natural Language Generation (NLG) for taskoriented dialogue focuses on effectively generating responses based on inputs that are frequently in the form of a structured meaning representation (MR) (Moryossef et al., 2019; Dušek et al., 2018; Colin et al., 2016; Wen et al., 2015). Recent work has suggested a schema-guided paradigm for taskoriented dialogue by adding descriptions in natural language form (Lin et al., 2021; Du et al., 2020; ∗ Rastogi et al., 2019; Bapna et al., 2017). Compared to structured MRs, dialogue schemata contain much richer contextual information, leading to better generated outputs. Although the primary aim of task-oriented NLG is to effectively generate outputs that realize system dialogue actions and communicate their associated contents correctly, it is often desirable to control the stylistic variations of an output. For example, recognizing and reacting to emotions has been shown to enhance task outcomes and user engagement in task-oriented conversations (Fraser et al., 2018). La"
2021.nlp4convai-1.21,D19-1012,0,0.0280905,"meters which consider explicit features such as vocabulary, semantic parameters of style are less lexically-defined. As a result, it is generally harder to annotate these parameters directly from the original data without auxiliary information. In this work, we consider the following semantic parameters: formality, negative sentiment, positive sentiment and empathy. Formality and sentiment are common stylistic parameters studied in the stylistic control NLG literature. We also include empathy as an interesting and complex style studied in recent work (Wang et al., 2021; Majumder et al., 2020; Lin et al., 2019; Zhou and Wang, 2018). We train a classifier for each of the four styles and annotate the utterances in SGD with these features. We include more details about the classifiers in Section 4 and show additional information about the dataset used to train each classifier in Table 9 of Appendix A. 4 Baseline Model Language model Given a sequence of tokens  x = x1 , · · · , xt , the goal of the language model is to model the joint probability of the sequence p(x) = p(x1 , · · · , xt ). The joint probability p(x) is often factorized in terms of the product of conditional probabilities QT using the"
2021.nlp4convai-1.21,2021.acl-long.522,0,0.0951383,"Missing"
2021.nlp4convai-1.21,D15-1166,0,0.0183779,"d style matches the desired style value. For instance, if the predicted sentiment for generated text with the “positive sentiment” control code does not match the “positive” label, then it is considered incorrect. Response fluency We use BLEU score (n-gram precision with brevity penalty) (Papineni et al., 2002) as a measurement of the response fluency. We acknowledge that lexical overlap metrics are poor measures of quality (Novikova et al., 2017); however, we include BLEU for completeness and further evaluate quality through human judgments. Semantic correctness We use slot error rate (SER) (Luong et al., 2015) to measure the semantic correctness of the generated response as compared to the given MR. SER measures the ratio of semantic errors that the model makes by finding the total number of slot mistakes (deletions, repetitions, and hallucinations) in the generated text (lower is better). SER here only considers slots that have explicit values that must be realized (e.g., $slotN). 6.2 this behavior is expected. Finally, we see that there is not much of a performance drop in semantic correctness with respect to SER. The experimental results show that for lexical styles with a clear syntactic patter"
2021.nlp4convai-1.21,2020.findings-emnlp.17,0,0.0285866,"ropriately address user sentiment. Previous work on controlled text generation aimed at achieving stylistic goals has not focused on a schema-guided paradigm where specific content must be communicated correctly; instead, most work focuses more on unconstrained text-to-text generation without explicit meaning representations (Liu et al., 2021; Krause et al., 2020; Keskar et al., 2019; Ghazvininejad et al., 2017). Meanwhile, work on schema-guided NLG has primarily focused on generating fluent outputs that achieve low semantic error rather than achieving stylistic goals (Kale and Rastogi, 2020; Peng et al., 2020; Du et al., 2020). In this paper, we hope to fill the gap on stylistic control and evaluation for schemaguided NLG. Our contributions in this paper are three-fold: Work done as an intern at Amazon Alexa AI. 1. We describe how we pre-process and annotate style parameters within the Schema-guided Dialogue (SGD) dataset (Rastogi et al., 2019). 228 Proceedings of the Third Workshop on Natural Language Processing for Conversational AI, pages 228–242 November 10, 2021. ©2021 Association for Computational Linguistics 2. We experiment with controlling different styles with various controlled text gen"
2021.nlp4convai-1.21,W18-1505,0,0.0161701,"e Number of adjectives in the template >2 Table 2: Lexical style parameters and possible values. P  T ot sentation: f (¯ ot ) = f t=1 T . The classifiers are used for annotating the semantic parameters of the SGD data and for the style control models described in Section 5. 5 Style Controlled Text Generation 5.1 Conditional Training (CT) Controllable generation entails modeling p(x|a), where a is a control variable and x is the generated sequence. However, a pre-trained language model such as GPT-2 is only trained to learn p(x). On the other hand, conditional training (Kikuchi et al., 2016; Peng et al., 2018; Fan et al., 2018; See et al., 2019) refers to directly learning the conditional generative model p(x|a). The results are of high quality because the model is trained to directly maximize p(x|a), but this comes at the expense of fixing the control variable upfront and of re-training the entire model for each new control variable. In this work, we require a controlled generation method that is able to simultaneously render the semantic content given the schemata while achieving the desired stylistic goals. We also require the method to be both stable (preserve the fluency To perform style cont"
2021.nlp4convai-1.21,N19-1170,0,0.202698,"er restrictions on the degree of freedom allowed for content generation. We show that methods that disentangle content generation and style variations, especially for more semantically complex styles, result in better overall performance on semantic and stylistic control. 2 Related Work training variational auto-encoders (Yu et al., 2017; Hu et al., 2017). Others have worked on designing a good decoding strategy to guide generation, where the decoding procedure is guided by a scoring function or discriminator. These include weighted decoding (Ghazvininejad et al., 2017; Holtzman et al., 2018; See et al., 2019) and guided generation (Krause et al., 2020). Other lines of work include curating training data with rich style markup to facilitate training models with explicit stylistic supervision Oraby et al. (2019, 2018). While this previous work does focus on controllable text generation, most work has been carried out in a text-to-text generation setting, without specific semantic constraints. Instead, we focus on the task-oriented dialogue framework where specific values must be communicated, and conduct a rigorous evaluation of different methods and their efficacy on different forms of style genera"
2021.nlp4convai-1.21,2021.naacl-main.124,0,0.026628,"up to facilitate training models with explicit stylistic supervision Oraby et al. (2019, 2018). While this previous work does focus on controllable text generation, most work has been carried out in a text-to-text generation setting, without specific semantic constraints. Instead, we focus on the task-oriented dialogue framework where specific values must be communicated, and conduct a rigorous evaluation of different methods and their efficacy on different forms of style generation. Other recent work has explored adding additional information such as chit-chat data to task-oriented dialogue (Sun et al., 2021; Madotto et al., 2020) and could potentially provide new opportunities for stylistic control. 3 3.1 Data Collection and Annotation Schema-to-Template pairs We use the Schema-guided Dialogue (SGD) dataset1 to create a rich corpus of schema-totemplate pairs. This dataset is one of the largest publicly available corpora of annotated multidomain, task-oriented dialogues (Rastogi et al., 2019). Each dialogue in the data is represented as a list of user and system utterances. We use only the system-side utterances and annotations since we are focused on system-side generation. Table 1 shows an exam"
2021.nlp4convai-1.23,2021.deelio-1.2,0,0.0385273,"plicit background knowledge I and then produce a response R given both U and I. Extending most neural RG models that treat this as a conditional language modeling problem, we aim to learn the conditional probability distribution P (I, R|U ) by training on human dialogues. 2.1 Data Preparation Knowledge Schema We consider ConceptNet (Speer et al., 2017) as our knowledge schema, which is a large-scale crowdsourced commonsense knowledge base consisting of triples such as “buy, RelatedTo, money”. We have explored several other sources such as LMs trained to generate knowledge (Hwang et al., 2021; Becker et al., 2021) but observe much noise while aligning knowledge to dialogue turns. Dialogues We use dialogue datasets from Zhou ∗ et al. (2021) as they propose “common senseWork done while Pei Zhou was an intern at Amazon Alexa AI focused dialogues” by filtering three existing di251 Proceedings of the Third Workshop on Natural Language Processing for Conversational AI, pages 251–253 November 10, 2021. ©2021 Association for Computational Linguistics alogue datasets DailyDialog (Li et al., 2017), EmpatheticDialogues (Rashkin et al., 2019), MuTual (Cui et al., 2020) using ConceptNet triples, and also crowdsourc"
2021.nlp4convai-1.23,2020.emnlp-main.373,0,0.0374913,"Missing"
2021.nlp4convai-1.23,2020.acl-main.130,0,0.0242908,"to generate knowledge (Hwang et al., 2021; Becker et al., 2021) but observe much noise while aligning knowledge to dialogue turns. Dialogues We use dialogue datasets from Zhou ∗ et al. (2021) as they propose “common senseWork done while Pei Zhou was an intern at Amazon Alexa AI focused dialogues” by filtering three existing di251 Proceedings of the Third Workshop on Natural Language Processing for Conversational AI, pages 251–253 November 10, 2021. ©2021 Association for Computational Linguistics alogue datasets DailyDialog (Li et al., 2017), EmpatheticDialogues (Rashkin et al., 2019), MuTual (Cui et al., 2020) using ConceptNet triples, and also crowdsourced SocialIQA-prompted dialogues (Zhou et al., 2021). We extract dialogues that each has at least one matched triple from ConceptNet in one of its consecutive turn pairs, resulting in around 31k dialogues and 159k turns we can use for training instances (excluding the first turn). The total number of turn pairs that have at least one matched triple is around 57k. 2.2 Training Setup Each of our training instance is a sequence of tokens with three components: a dialog history U , implicit knowledge (empty or non-empty) I, and a response R. We enclose"
2021.nlp4convai-1.23,2020.acl-main.703,0,0.0211956,"Think Before You Speak: Learning to Generate Implicit Knowledge for Response Generation by Self-Talk Pei Zhou1∗ Behnam Hedayatnia2 Karthik Gopalakrishnan2 Seokhwan Kim2 Jay Pujara1 Xiang Ren1 Yang Liu2 Dilek Hakkani-Tur2 1 Department of Computer Science, University of Southern California 2 Amazon Alexa AI {peiz,jpujara,xiangren}@usc.edu, {behnam,karthgop,seokhwk,yangliud,hakkanit}@amazon.com 1 Introduction End-to-end response generation (RG) models based on pre-trained transformer-based (Vaswani et al., 2017) language models (LM) have shown to produce human-like responses (Zhang et al., 2020; Lewis et al., 2020; Roller et al., 2020). Humans, however, not only “just utter the right sentence”, but also contribute to the common ground consisting of mutual beliefs and common knowledge “whose truth is taken for granted as part of the background of the conversation” (Stalnaker, 1978; Clark and Schaefer, 1989; Clark and Brennan, 1991). For example, consider the utterance “I need to buy some flowers for my wife”, a potential appropriate response is “Perhaps you’d be interested in red roses”. To produce this response, the participant needs to understand relevant background knowledge such as “rose is a type o"
2021.nlp4convai-1.23,2020.acl-demos.30,0,0.0959559,"Missing"
2021.nlp4convai-1.23,2021.sigdial-1.13,1,0.882617,"RG models that first generate implicit commonsense inferences before producing a response given previous utterances. Inspired by inquiry-based discovery learning (Bruner, 1961) and the self-talk procedure (Shwartz et al., 2020), we encourage the RG model to talk with itself to elicit implicit knowledge before making a response. Collecting training data is challenging for our purpose since commonsense knowledge is by definition often omitted in conversations. We use ConceptNet triples (Speer et al., 2017) as the knowledge schema to represent knowledge and align common sense-focused dialogues (Zhou et al., 2021) with knowledge to train RG models. We conduct extensive human evaluation on different variants of our training procedure and find that models that generate implicit background knowledge before responding produce more grammatical, coherent, and engaging responses compared to RG models that directly generate responses. Further analysis shows that models can sometimes even learn to distinguish when it is necessary to self-talk to generate implicit knowledge, i.e., be aware of potential knowledge gaps in dialogues. We hope our findings encourage more future studies on making RG models better emul"
2021.nlp4convai-1.23,I17-1099,0,0.0227344,"o, money”. We have explored several other sources such as LMs trained to generate knowledge (Hwang et al., 2021; Becker et al., 2021) but observe much noise while aligning knowledge to dialogue turns. Dialogues We use dialogue datasets from Zhou ∗ et al. (2021) as they propose “common senseWork done while Pei Zhou was an intern at Amazon Alexa AI focused dialogues” by filtering three existing di251 Proceedings of the Third Workshop on Natural Language Processing for Conversational AI, pages 251–253 November 10, 2021. ©2021 Association for Computational Linguistics alogue datasets DailyDialog (Li et al., 2017), EmpatheticDialogues (Rashkin et al., 2019), MuTual (Cui et al., 2020) using ConceptNet triples, and also crowdsourced SocialIQA-prompted dialogues (Zhou et al., 2021). We extract dialogues that each has at least one matched triple from ConceptNet in one of its consecutive turn pairs, resulting in around 31k dialogues and 159k turns we can use for training instances (excluding the first turn). The total number of turn pairs that have at least one matched triple is around 57k. 2.2 Training Setup Each of our training instance is a sequence of tokens with three components: a dialog history U , i"
2021.nlp4convai-1.23,P19-1534,0,0.0205292,"er sources such as LMs trained to generate knowledge (Hwang et al., 2021; Becker et al., 2021) but observe much noise while aligning knowledge to dialogue turns. Dialogues We use dialogue datasets from Zhou ∗ et al. (2021) as they propose “common senseWork done while Pei Zhou was an intern at Amazon Alexa AI focused dialogues” by filtering three existing di251 Proceedings of the Third Workshop on Natural Language Processing for Conversational AI, pages 251–253 November 10, 2021. ©2021 Association for Computational Linguistics alogue datasets DailyDialog (Li et al., 2017), EmpatheticDialogues (Rashkin et al., 2019), MuTual (Cui et al., 2020) using ConceptNet triples, and also crowdsourced SocialIQA-prompted dialogues (Zhou et al., 2021). We extract dialogues that each has at least one matched triple from ConceptNet in one of its consecutive turn pairs, resulting in around 31k dialogues and 159k turns we can use for training instances (excluding the first turn). The total number of turn pairs that have at least one matched triple is around 57k. 2.2 Training Setup Each of our training instance is a sequence of tokens with three components: a dialog history U , implicit knowledge (empty or non-empty) I, an"
2021.nlp4convai-1.27,N19-1423,0,0.0486235,"Missing"
2021.nlp4convai-1.27,W17-5506,0,0.0485847,"Missing"
2021.nlp4convai-1.27,2020.nlp4convai-1.10,1,0.894996,"Missing"
2021.nlp4convai-1.27,2021.emnlp-main.552,0,0.0698861,"Missing"
2021.nlp4convai-1.27,2020.acl-main.456,1,0.868985,"Missing"
2021.nlp4convai-1.27,2021.dialdoc-1.16,1,0.839459,"Missing"
2021.nlp4convai-1.27,D19-1410,0,0.0172199,"ng turn detection benchmark dataset. Pos: knowledge-seeking turns; Neg: non-knowledge-seeking turns. 4.2 Baselines and Settings The baselines are 1) the best performing model in the DSTC9 Track 1 competition (Kim et al., 2021), which is a fine-tuned RoBERTa-Large model (Liu et al., 2019) on the training set. 2) Fine-tuned RoBERTa-Large-NLI (obtained by finetuning RoBERTa-Large on SNLI and MultiNLI datasets) and DistilBERT-Base-NLI-STSB (obtained by fine-tuning DistilBERT-Base on SNLI, MultiNLI, and STS-B datasets) on the training set. The sentence encoder E we used is DistilBERTBase-NLI-STSB (Reimers and Gurevych, 2019).4 Domains Examples Attraction Attraction Is it necessary to buy tickets in advance? How long it could take to see it all ? 4 hours it would be enough? Hotel Is there a minimum check in age? Hotel How much do you charge for parking? Restaurant Would there be room for a stroller with a sleeping baby during dinner? Restaurant Can I order crab cakes take out for eight servings ? Table 3: Examples of newly collected user questions in the contrast set. These user queries collected from real users are much more diverse than those in the benchmark test set of DSTC9 Track 1 dataset. The threshold η is"
2021.nlp4convai-1.27,2020.coling-main.611,1,0.811966,"Missing"
2021.nlp4convai-1.27,P17-1062,0,0.042073,"Missing"
2021.nlp4convai-1.27,2020.sigdial-1.35,1,0.842901,"Missing"
2021.nlp4convai-1.27,2021.ccl-1.108,0,0.0773871,"Missing"
2021.nlp4convai-1.27,2020.acl-main.654,1,0.769199,"Missing"
2021.nlp4convai-1.27,P19-1336,1,0.842344,"Missing"
2021.sigdial-1.12,2020.acl-main.12,0,0.0190158,"N can also be applied to multi-turn, non-goal oriented conversations. 2 Related Work There have been plenty of prior works in fewshot learning for dialogue tasks including natural language understanding (Shah et al., 2019; Liu et al., 2020; Hou et al., 2020a), dialogue state tracking (Wu et al., 2019; Dingliwal et al., 2021) and response generation (Tran and Le Nguyen, 2018; Mi et al., 2019; Chen et al., 2020; Peng et al., 2020a), which aim to make each model transferable to a low-resource new domain. Another line of recent work proposes data augmentation techniques for conversational agents (Campagna et al., 2020; Kale and Rastogi, 2020; Lee et al., 2021). While these studies focus on one-time augmentation by heuristics or static neural models, our proposed approach keeps improving the data generation and hence models trained with that data, using RL. C2C-GenDA (cluster to cluster generation for data augmentation) (Hou et al., 2020b) is a generative data augmentation approach focused on slot filling. This method jointly encodes multiple realisations (i.e. a cluster) with the same semantic interpretation and generates multiple previously unseen realisations. A “duplication-aware attention” model guaran"
2021.sigdial-1.12,2020.acl-main.18,0,0.0428373,"onstrate that GCN can generalise from seed data in limited-resource settings (data and computation) and achieve competitive performance in two NLP tasks: intent detection and slot tagging • We show that GCN can also be applied to multi-turn, non-goal oriented conversations. 2 Related Work There have been plenty of prior works in fewshot learning for dialogue tasks including natural language understanding (Shah et al., 2019; Liu et al., 2020; Hou et al., 2020a), dialogue state tracking (Wu et al., 2019; Dingliwal et al., 2021) and response generation (Tran and Le Nguyen, 2018; Mi et al., 2019; Chen et al., 2020; Peng et al., 2020a), which aim to make each model transferable to a low-resource new domain. Another line of recent work proposes data augmentation techniques for conversational agents (Campagna et al., 2020; Kale and Rastogi, 2020; Lee et al., 2021). While these studies focus on one-time augmentation by heuristics or static neural models, our proposed approach keeps improving the data generation and hence models trained with that data, using RL. C2C-GenDA (cluster to cluster generation for data augmentation) (Hou et al., 2020b) is a generative data augmentation approach focused on slot fill"
2021.sigdial-1.12,2020.acl-main.11,0,0.0343652,"Missing"
2021.sigdial-1.12,H90-1021,0,0.565854,"Missing"
2021.sigdial-1.12,2020.acl-main.128,0,0.248349,"efer to any language-related task, from intent detection to full task-oriented conversations. Similar to Generative Adversarial Networks (GAN), GCN effectively trains two models, a data generator and a learner. Unlike GAN-based approaches, however, GCN do not require a discriminator, only a numerical reward that can be obtained by any means and reflects the performance of the learner. This frees the architecture from tight domain constraints and allows it to be more adaptive and creative; some analysis and examples are shown in the respective section. Moreover, contrary to earlier approaches (Hou et al., 2020b, e.g.), we do not generate delexicalised utterances therefore we are not limiting our models to the vocabulary that exists in the data nor do we require a vocabulary to be provided. This allows GCN to better generalise from seed data, and create annotated training examples that are task-focused but also 111 Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 111–120 July 29–31, 2021. ©2021 Association for Computational Linguistics Figure 1: Generative Conversational Networks Architecture. We use PPO as described in (Ziegler et al., 2019) to p"
2021.sigdial-1.12,2021.ccl-1.108,0,0.056486,"Missing"
2021.sigdial-1.12,2020.acl-main.3,0,0.0159984,"training or evaluation. Our main contributions can be summarized as follows: • We propose GCN, a meta-learning approach for training conversational agents using RL • We demonstrate that GCN can generalise from seed data in limited-resource settings (data and computation) and achieve competitive performance in two NLP tasks: intent detection and slot tagging • We show that GCN can also be applied to multi-turn, non-goal oriented conversations. 2 Related Work There have been plenty of prior works in fewshot learning for dialogue tasks including natural language understanding (Shah et al., 2019; Liu et al., 2020; Hou et al., 2020a), dialogue state tracking (Wu et al., 2019; Dingliwal et al., 2021) and response generation (Tran and Le Nguyen, 2018; Mi et al., 2019; Chen et al., 2020; Peng et al., 2020a), which aim to make each model transferable to a low-resource new domain. Another line of recent work proposes data augmentation techniques for conversational agents (Campagna et al., 2020; Kale and Rastogi, 2020; Lee et al., 2021). While these studies focus on one-time augmentation by heuristics or static neural models, our proposed approach keeps improving the data generation and hence models trained"
2021.sigdial-1.12,2020.findings-emnlp.17,0,0.0226319,"an generalise from seed data in limited-resource settings (data and computation) and achieve competitive performance in two NLP tasks: intent detection and slot tagging • We show that GCN can also be applied to multi-turn, non-goal oriented conversations. 2 Related Work There have been plenty of prior works in fewshot learning for dialogue tasks including natural language understanding (Shah et al., 2019; Liu et al., 2020; Hou et al., 2020a), dialogue state tracking (Wu et al., 2019; Dingliwal et al., 2021) and response generation (Tran and Le Nguyen, 2018; Mi et al., 2019; Chen et al., 2020; Peng et al., 2020a), which aim to make each model transferable to a low-resource new domain. Another line of recent work proposes data augmentation techniques for conversational agents (Campagna et al., 2020; Kale and Rastogi, 2020; Lee et al., 2021). While these studies focus on one-time augmentation by heuristics or static neural models, our proposed approach keeps improving the data generation and hence models trained with that data, using RL. C2C-GenDA (cluster to cluster generation for data augmentation) (Hou et al., 2020b) is a generative data augmentation approach focused on slot filling. This method jo"
2021.sigdial-1.12,2020.tacl-1.18,0,0.0173942,"terance, etc.: Intent Detection. For this task we use a RoBERTabase sentence classifier (Liu et al., 2019) as a learner. Upon receipt of a batch of data, the learner will parse it and create an input and a target tensor, containing the utterances and labels respectively. Slot Tagging. For this task we use a RoBERTabase slot tagger (Liu et al., 2019). Similarly to intent detection, the learner will parse the batch of data but using the utterance part to create the input tensor and the IOB tags to create the target tensor. Non-goal oriented interaction. For this task we use the Bert2Bert model (Rothe et al., 2020) where, similarly to intent detection, the learner will create the input and target tensors that represent one dialogue turn. 3.5 Generator Training Following (Ziegler et al., 2019), we use two generator models, π and ρ. π is the model that is being trained and ρ is a reference model (distilGPT2 in our case) that keeps π from diverging too much, via a Kullback-Leibler (KL) term in the reward function. PPO is then used to update π. In GCN, each datapoint created by the generator is saved as is the performance of the learner for that particular datapoint. When the generator is being trained, we"
2021.sigdial-1.12,N19-1380,0,0.0438506,"Missing"
2021.sigdial-1.12,P19-1547,1,0.835378,"at can be used for training or evaluation. Our main contributions can be summarized as follows: • We propose GCN, a meta-learning approach for training conversational agents using RL • We demonstrate that GCN can generalise from seed data in limited-resource settings (data and computation) and achieve competitive performance in two NLP tasks: intent detection and slot tagging • We show that GCN can also be applied to multi-turn, non-goal oriented conversations. 2 Related Work There have been plenty of prior works in fewshot learning for dialogue tasks including natural language understanding (Shah et al., 2019; Liu et al., 2020; Hou et al., 2020a), dialogue state tracking (Wu et al., 2019; Dingliwal et al., 2021) and response generation (Tran and Le Nguyen, 2018; Mi et al., 2019; Chen et al., 2020; Peng et al., 2020a), which aim to make each model transferable to a low-resource new domain. Another line of recent work proposes data augmentation techniques for conversational agents (Campagna et al., 2020; Kale and Rastogi, 2020; Lee et al., 2021). While these studies focus on one-time augmentation by heuristics or static neural models, our proposed approach keeps improving the data generation and hen"
2021.sigdial-1.12,W15-4655,0,0.0724882,"Missing"
2021.sigdial-1.12,C18-1103,0,0.0612026,"Missing"
2021.sigdial-1.12,P19-1078,0,0.0239581,"d as follows: • We propose GCN, a meta-learning approach for training conversational agents using RL • We demonstrate that GCN can generalise from seed data in limited-resource settings (data and computation) and achieve competitive performance in two NLP tasks: intent detection and slot tagging • We show that GCN can also be applied to multi-turn, non-goal oriented conversations. 2 Related Work There have been plenty of prior works in fewshot learning for dialogue tasks including natural language understanding (Shah et al., 2019; Liu et al., 2020; Hou et al., 2020a), dialogue state tracking (Wu et al., 2019; Dingliwal et al., 2021) and response generation (Tran and Le Nguyen, 2018; Mi et al., 2019; Chen et al., 2020; Peng et al., 2020a), which aim to make each model transferable to a low-resource new domain. Another line of recent work proposes data augmentation techniques for conversational agents (Campagna et al., 2020; Kale and Rastogi, 2020; Lee et al., 2021). While these studies focus on one-time augmentation by heuristics or static neural models, our proposed approach keeps improving the data generation and hence models trained with that data, using RL. C2C-GenDA (cluster to cluster genera"
2021.sigdial-1.13,I17-1099,0,0.126315,"Missing"
2021.sigdial-1.13,2020.findings-emnlp.165,1,0.852259,"he best of our knowledge, there is no study or largescale multi-turn data for analyzing whether modelgenerated responses present the ability to communicate with commonsense knowledge or reasoning. Lack of real-life interactive setting for Commonsense Reasoning Benchmarks Current commonsense reasoning (CSR) benchmarks mostly target models’ ability to choose a right answer from several candidates given a question. We argue that this is a highly artificial scenario as models do not get options to choose from in real-life, and often they need to generate utterances. Recent work such as CommonGen (Lin et al., 2020) has started to explore generative settings to examine commonsense in natural language processing (NLP) models. This line of work, however, is still far from real use cases as it does not consider a real-life interaction task setup such as conversations. Thus we argue that existing commonsense benchmarks in NLP are not enough to train a language agent that produces smooth interpersonal communications, nor evaluate whether models have such capabilities. 3 2 2.1 Task Introduction and Motivations Commonsense-Focused Dialogue Response Generation We study commonsense-focused response generation for"
2021.sigdial-1.13,D16-1230,0,0.0300229,"n collected with different focuses such as incorporating knowledge (Gopalakrishnan et al., 2019; Dinan et al., 2018), empathy (Rashkin et al., 2019), task completion (Budzianowski et al., 2018), consistency (Nie et al., 2020), personality (Zhang et al., 2018) and reasoning (Cui et al., 2020) within dialog systems. There has also been work on combining a variety of Dialog Response Evaluation Due to the diverse responses that a dialog system can output, referenced automatic metrics (such as BLEU, ROUGE, Perplexity) do not correlate well with human judgement of these systems (Deriu et al., 2020; Liu et al., 2016). As a result, human evaluation has become the de-facto standard to evaluate dialog systems. However human evaluation is costly. Recently model-based metrics have been proposed with good correlation with human annotations (Zhang et al., 2019; Sellam et al., 2020; Mehri and Eskenazi, 2020b,a; Tao et al., 2018; Lowe et al., 2017). Most metrics focus on evaluating the coherence or appropriatness of a response with respect to its dialog context. (Mehri and Eskenazi, 2020a) identified 18 different dialog qualities such as interesting and topic depth. However none of these metrics evaluate the commo"
2021.sigdial-1.13,2020.acl-main.130,0,0.168291,"ed language models, GPT2 (Radford et al., 2019), and further train it on our training data sets. Specifically, the model is trained in a multitask fashion that minimizes the LM loss as well as the multiple choice loss following Wolf et al. (2019), and generates responses for a given dialog history. We consider the follow three types of training data setups. • Existing data sets, including DailyDialog (Li et al., 2017) (DD), EmpatheticDialogues (Rashkin et al., 2019)(ED), and Topical-Chat (Gopalakrishnan et al., 2019), a knowledge-grounded open-domain dataset with around 11k dialogues. MuTual (Cui et al., 2020) is not included since it is designed for response selection. • As described in Section 3.1, we use ConceptNet to search for potential triples in response turns and filter three dialogue datasets, DD, ED, and MuTual. We combine the three filtered dialogues from these datasets to form our training data, named ‘filter existing’ (FE, total around 21K dialogues). • The third category includes our collected dialogues using SocialIQA contexts. This is used along with the FE data above: FE and all of the 25k collected dialogues (FE+new crowdsourced), and FE plus the 11K filtered dialogues of our coll"
2021.sigdial-1.13,P17-1103,0,0.0204431,"so been work on combining a variety of Dialog Response Evaluation Due to the diverse responses that a dialog system can output, referenced automatic metrics (such as BLEU, ROUGE, Perplexity) do not correlate well with human judgement of these systems (Deriu et al., 2020; Liu et al., 2016). As a result, human evaluation has become the de-facto standard to evaluate dialog systems. However human evaluation is costly. Recently model-based metrics have been proposed with good correlation with human annotations (Zhang et al., 2019; Sellam et al., 2020; Mehri and Eskenazi, 2020b,a; Tao et al., 2018; Lowe et al., 2017). Most metrics focus on evaluating the coherence or appropriatness of a response with respect to its dialog context. (Mehri and Eskenazi, 2020a) identified 18 different dialog qualities such as interesting and topic depth. However none of these metrics evaluate the commonsense of a response, which is the focus of this work. 7 Conclusion We present our empirical study on commonsense in dialogue response generation. To obtain data for commonsense-focused analysis in open domain response generation, we use two strategies: filtering existing dialogue data using a commonsense knowledge graph Concep"
2021.sigdial-1.13,2020.acl-main.704,0,0.0162514,"and reasoning (Cui et al., 2020) within dialog systems. There has also been work on combining a variety of Dialog Response Evaluation Due to the diverse responses that a dialog system can output, referenced automatic metrics (such as BLEU, ROUGE, Perplexity) do not correlate well with human judgement of these systems (Deriu et al., 2020; Liu et al., 2016). As a result, human evaluation has become the de-facto standard to evaluate dialog systems. However human evaluation is costly. Recently model-based metrics have been proposed with good correlation with human annotations (Zhang et al., 2019; Sellam et al., 2020; Mehri and Eskenazi, 2020b,a; Tao et al., 2018; Lowe et al., 2017). Most metrics focus on evaluating the coherence or appropriatness of a response with respect to its dialog context. (Mehri and Eskenazi, 2020a) identified 18 different dialog qualities such as interesting and topic depth. However none of these metrics evaluate the commonsense of a response, which is the focus of this work. 7 Conclusion We present our empirical study on commonsense in dialogue response generation. To obtain data for commonsense-focused analysis in open domain response generation, we use two strategies: filterin"
2021.sigdial-1.13,2020.acl-main.64,0,0.112351,"s that contain ConceptNet triples as discussed earlier. In addition, it shows that though overall increasing training data size benefits model performance, the quality of data plays a more important role. We Proposed Commonsense Automatic Evaluation Results We now examine the correlation of our proposed automatic metric (MLP regressor) with human scores on the testing portion of our annotations. We cross-validate on the collected dialogues with 0.8/0.1/0.1 proportions. For comparison, we consider three baselines: our MLP with only symbolic features, our MLP with only neural features, and FED (Mehri and Eskenazi, 2020a), which uses DialoGPT to score how likely the next turn after the response expresses confusion. It requires no training nor human references, and has been shown to correlate with humans judgements on different criteria (commonsense not included). Table 4 shows the Spearman’s correlation of the system computed scores and human annotation scores using all the annotated data in a cross-validation setup. We can see that our simple MLP-based regressor reaches the highest spearman’s correlation with human scores, outperforming other baselines significantly. However, such a correlation result still"
2021.sigdial-1.13,P19-1534,0,0.429257,"odels, and show reasonable correlation with human evaluation of responses’ commonsense quality. 1 1 Introduction Open-domain dialogue response generation (RG) models aim to provide human-like natural language responses given dialogue histories (Chen et al., 2017). To improve generated response quality, many studies have been conducted to develop knowledge-grounded RG (Ghazvininejad et al., ∗ Work done while Pei Zhou was an intern at Amazon Alexa AI 1 Data and code will be released soon. 2018; Gopalakrishnan et al., 2019), personalized dialogue agents (Zhang et al., 2018), empathetic response (Rashkin et al., 2019), etc. For all the above-mentioned directions for RG, large-scale dialogue data geared towards the specific goals is crucial, since most current state-of-the-art neural RG models require training on appropriate and large data. Therefore several datasets have been collected to support such research efforts such as knowledge-grounded dialogues (Ghazvininejad et al., 2018; Gopalakrishnan et al., 2019), PersonaChat (Zhang et al., 2018), and EmpatheticDialogues (Rashkin et al., 2019). Producing natural and logically-coherent responses given dialogue contexts involves making commonsense inferences d"
2021.sigdial-1.13,2020.tacl-1.37,0,0.380271,"; Bisk et al., 2020; Sap et al., 2019b) test a model’s ability to choose the correct option given a context and a question; pre-trained language models have reached high performance on these benchmarks after fine-tuning. There have been many benchmarks that focus on reasoning abilities in multiple tasks such as reading comprehension (Huang et al., 2019; Yu et al., 2020), dialogue systems (Cui et al., 2020), and natural language inference (Williams et al., 2018), which involve inferences on language. Recent work also aims to probe models in these tasks to see if reasoning is actually achieved (Richardson and Sabharwal, 2020; Richardson et al., 2020; Zhou et al., 2020). In this study we tackle the response generation problem in dialogues, with a focus on collecting commonsense rich dialog data and evaluating commonsense quality of model responses. 6.2 Open Domain Dialogue Response Generation Recently open domain dialog systems have been modeled using end-to-end approaches, more specifically encoder-decoder architectures (Sordoni et al., 2015; Serban et al., 2017, 2016; Vinyals and Le, 2015). Recent work focused on finetuning large pre-trained transformer models (Radford et al., 2019; Zhang et al., 2020) on dialog"
2021.sigdial-1.13,D19-1454,0,0.0742573,"Missing"
2021.sigdial-1.13,2020.acl-tutorials.7,0,0.340866,"not consider a real-life interaction task setup such as conversations. Thus we argue that existing commonsense benchmarks in NLP are not enough to train a language agent that produces smooth interpersonal communications, nor evaluate whether models have such capabilities. 3 2 2.1 Task Introduction and Motivations Commonsense-Focused Dialogue Response Generation We study commonsense-focused response generation for dialogues. Commonsense can be defined as “the basic level of practical knowledge and reasoning concerning everyday situations and events that are commonly shared among most people” (Sap et al., 2020). Dialogue response generation is the task of generating a response turn r in a conversational setting given previous history turns h. Thus by combining these two together, we want to examine models’ ability to produce responses that make sense or is plausible in terms of commonsense. Motivations Commonsense Focused Dialogue Collection To collect more commonsense focused dialogues for response generation model training and evaluation, our effort is along two directions: filtering existing data to collect dialogues with responses that consist of commonsense (Section 3.1), and curating new data"
2021.sigdial-1.13,N15-1020,0,0.164442,"Missing"
2021.sigdial-1.13,N19-1421,0,0.0459046,"tion drop when considering either symbolic or neural features alone in our model, indicating that they might each capture a different 127 aspect for evaluating commonsense. datasets to exhibit multiple attributes (Roller et al., 2020). Metrics Spearman’s Correlation p-Value FED Symbolic Ours Neural All features -0.00797 0.12336 0.06176 0.20789 0.80569 1.27E-08 0.00450 4.53E-22 6.3 Table 4: Spearman’s correlation and p-values for different automatic metrics with human scores. 6 6.1 Related Work Commonsense Reasoning The majority of recent commonsense reasoning benchmarks (Zellers et al., 2018; Talmor et al., 2019; Bisk et al., 2020; Sap et al., 2019b) test a model’s ability to choose the correct option given a context and a question; pre-trained language models have reached high performance on these benchmarks after fine-tuning. There have been many benchmarks that focus on reasoning abilities in multiple tasks such as reading comprehension (Huang et al., 2019; Yu et al., 2020), dialogue systems (Cui et al., 2020), and natural language inference (Williams et al., 2018), which involve inferences on language. Recent work also aims to probe models in these tasks to see if reasoning is actually achieved ("
2021.sigdial-1.13,N18-1101,0,0.0298111,"ith human scores. 6 6.1 Related Work Commonsense Reasoning The majority of recent commonsense reasoning benchmarks (Zellers et al., 2018; Talmor et al., 2019; Bisk et al., 2020; Sap et al., 2019b) test a model’s ability to choose the correct option given a context and a question; pre-trained language models have reached high performance on these benchmarks after fine-tuning. There have been many benchmarks that focus on reasoning abilities in multiple tasks such as reading comprehension (Huang et al., 2019; Yu et al., 2020), dialogue systems (Cui et al., 2020), and natural language inference (Williams et al., 2018), which involve inferences on language. Recent work also aims to probe models in these tasks to see if reasoning is actually achieved (Richardson and Sabharwal, 2020; Richardson et al., 2020; Zhou et al., 2020). In this study we tackle the response generation problem in dialogues, with a focus on collecting commonsense rich dialog data and evaluating commonsense quality of model responses. 6.2 Open Domain Dialogue Response Generation Recently open domain dialog systems have been modeled using end-to-end approaches, more specifically encoder-decoder architectures (Sordoni et al., 2015; Serban e"
2021.sigdial-1.13,D18-1009,0,0.0457767,"ere is a large correlation drop when considering either symbolic or neural features alone in our model, indicating that they might each capture a different 127 aspect for evaluating commonsense. datasets to exhibit multiple attributes (Roller et al., 2020). Metrics Spearman’s Correlation p-Value FED Symbolic Ours Neural All features -0.00797 0.12336 0.06176 0.20789 0.80569 1.27E-08 0.00450 4.53E-22 6.3 Table 4: Spearman’s correlation and p-values for different automatic metrics with human scores. 6 6.1 Related Work Commonsense Reasoning The majority of recent commonsense reasoning benchmarks (Zellers et al., 2018; Talmor et al., 2019; Bisk et al., 2020; Sap et al., 2019b) test a model’s ability to choose the correct option given a context and a question; pre-trained language models have reached high performance on these benchmarks after fine-tuning. There have been many benchmarks that focus on reasoning abilities in multiple tasks such as reading comprehension (Huang et al., 2019; Yu et al., 2020), dialogue systems (Cui et al., 2020), and natural language inference (Williams et al., 2018), which involve inferences on language. Recent work also aims to probe models in these tasks to see if reasoning i"
2021.sigdial-1.13,P18-1205,0,0.202871,"ptNet and pretrained language and dialog models, and show reasonable correlation with human evaluation of responses’ commonsense quality. 1 1 Introduction Open-domain dialogue response generation (RG) models aim to provide human-like natural language responses given dialogue histories (Chen et al., 2017). To improve generated response quality, many studies have been conducted to develop knowledge-grounded RG (Ghazvininejad et al., ∗ Work done while Pei Zhou was an intern at Amazon Alexa AI 1 Data and code will be released soon. 2018; Gopalakrishnan et al., 2019), personalized dialogue agents (Zhang et al., 2018), empathetic response (Rashkin et al., 2019), etc. For all the above-mentioned directions for RG, large-scale dialogue data geared towards the specific goals is crucial, since most current state-of-the-art neural RG models require training on appropriate and large data. Therefore several datasets have been collected to support such research efforts such as knowledge-grounded dialogues (Ghazvininejad et al., 2018; Gopalakrishnan et al., 2019), PersonaChat (Zhang et al., 2018), and EmpatheticDialogues (Rashkin et al., 2019). Producing natural and logically-coherent responses given dialogue conte"
2021.sigdial-1.13,2020.acl-demos.30,0,0.416946,"rom ConceptNet. The triple identifying process is the same as our filtering process described earlier (Section 3.1). That is, we first identify a set of concepts in the response turn and query ConceptNet for potential triples and match those with the other concepts appearing in the dialogue history. Two-hop triples are searched in a similar manner, with the only difference being that the number of potential triples will be much larger. We also include the length of the response as an additional feature. As for neural features, we use the scores from a dialogue-focused language model DialoGPT (Zhang et al., 2020) on both the response itself and the dialogue history concatenated with the response. The score from DialoGPT can be considered as the plausibility of the sentence. We train this MLP model using the human evaluation scores for different responses. 5 5.1 Results and Analysis Automatic Evaluation Results Table 2 shows results according to automatic metrics on our 4.6K testing dialogues. We find that perplexity scores for the GPT2 model trained on filtered existing dialogue data (FE), or plus new collected data (FE+Crowdsourced), are much lower than that just trained on existing datasets as is. T"
C00-1042,J95-4004,0,0.0114959,"dies in tagging and morphological disambiguation using various techniques. POS tagging systems have used either a statistical or a rule-based approach. In the statistical approach, a large corpus has been used to train a probabilistic model which then has been used to tag new text, assigning the most likely tag for a given word in a given context (e.g., Church (1988), Cutting et al. (1992)). In the rule-based approach, a large number of hand-crafted linguistic constraints are used to eliminate impossible tags or morphological parses for a given word in a given context (Karlsson et al., 1995). Brill (1995a) has presented a transformation-based learning approach, which induces disambiguation rules from tagged corpora. Morphological disambiguation in in ecting or agglutinative languages with complex morphology involves more than determining the major or minor parts-of-speech of the lexical items. Typically, morphology marks a number of in ectional or derivational features and this involves ambiguity. For instance, a given word may be chopped up in di erent ways into morphemes, a given morpheme may mark di erent features depending on the morphotactics, or lexicalized variants of derived words may"
C00-1042,W95-0101,0,0.0279339,"dies in tagging and morphological disambiguation using various techniques. POS tagging systems have used either a statistical or a rule-based approach. In the statistical approach, a large corpus has been used to train a probabilistic model which then has been used to tag new text, assigning the most likely tag for a given word in a given context (e.g., Church (1988), Cutting et al. (1992)). In the rule-based approach, a large number of hand-crafted linguistic constraints are used to eliminate impossible tags or morphological parses for a given word in a given context (Karlsson et al., 1995). Brill (1995a) has presented a transformation-based learning approach, which induces disambiguation rules from tagged corpora. Morphological disambiguation in in ecting or agglutinative languages with complex morphology involves more than determining the major or minor parts-of-speech of the lexical items. Typically, morphology marks a number of in ectional or derivational features and this involves ambiguity. For instance, a given word may be chopped up in di erent ways into morphemes, a given morpheme may mark di erent features depending on the morphotactics, or lexicalized variants of derived words may"
C00-1042,A88-1019,0,0.00939913,"summarize relevant aspects of Turkish and present details of various statistical models for morphological disambiguation for Turkish. We then present results and analyses from our experiments. 2 Related Work There has been a large number of studies in tagging and morphological disambiguation using various techniques. POS tagging systems have used either a statistical or a rule-based approach. In the statistical approach, a large corpus has been used to train a probabilistic model which then has been used to tag new text, assigning the most likely tag for a given word in a given context (e.g., Church (1988), Cutting et al. (1992)). In the rule-based approach, a large number of hand-crafted linguistic constraints are used to eliminate impossible tags or morphological parses for a given word in a given context (Karlsson et al., 1995). Brill (1995a) has presented a transformation-based learning approach, which induces disambiguation rules from tagged corpora. Morphological disambiguation in in ecting or agglutinative languages with complex morphology involves more than determining the major or minor parts-of-speech of the lexical items. Typically, morphology marks a number of in ectional or derivat"
C00-1042,A92-1018,0,0.0216773,"ant aspects of Turkish and present details of various statistical models for morphological disambiguation for Turkish. We then present results and analyses from our experiments. 2 Related Work There has been a large number of studies in tagging and morphological disambiguation using various techniques. POS tagging systems have used either a statistical or a rule-based approach. In the statistical approach, a large corpus has been used to train a probabilistic model which then has been used to tag new text, assigning the most likely tag for a given word in a given context (e.g., Church (1988), Cutting et al. (1992)). In the rule-based approach, a large number of hand-crafted linguistic constraints are used to eliminate impossible tags or morphological parses for a given word in a given context (Karlsson et al., 1995). Brill (1995a) has presented a transformation-based learning approach, which induces disambiguation rules from tagged corpora. Morphological disambiguation in in ecting or agglutinative languages with complex morphology involves more than determining the major or minor parts-of-speech of the lexical items. Typically, morphology marks a number of in ectional or derivational features and this"
C00-1042,P98-1062,0,0.0240296,"for the di erent kinds of morphological ambiguities in Turkish.) We assume that all syntactically relevant features of word forms have to be determined correctly for morphological disambiguation. In this context, there have been some interesting previous studies for di erent languages. Levinger et al. (1995) have reported on an approach that learns morpholexical probabilities from an untagged corpus and have used the resulting information in morphological disambiguation in Hebrew. Hajic and Hladka (1998) have used maximum entropy modeling approach for morphological disambiguation in Czech. Ezeiza et al. (1998) have combined stochastic and rule-based disambiguation methods for Basque. Megyesi (1999) has adapted Brill&apos;s POS tagger with extended lexical templates to Hungarian. Previous approaches to morphological disambiguation of Turkish text had employed a constraintbased approach (O azer and Kuruoz, 1994; Oflazer and Tur, 1996; O azer and Tur, 1997). Although results obtained earlier in these approaches were reasonable, the fact that the constraint rules were hand crafted posed a rather serious impediment to the generality and improvement of these systems. 3 Turkish Turkish is a free constituent"
C00-1042,P98-1080,0,0.1122,"Missing"
C00-1042,J95-3004,0,0.105323,"nal features and this involves ambiguity. For instance, a given word may be chopped up in di erent ways into morphemes, a given morpheme may mark di erent features depending on the morphotactics, or lexicalized variants of derived words may interact with productively derived versions (see O azer and Tur (1997) for the di erent kinds of morphological ambiguities in Turkish.) We assume that all syntactically relevant features of word forms have to be determined correctly for morphological disambiguation. In this context, there have been some interesting previous studies for di erent languages. Levinger et al. (1995) have reported on an approach that learns morpholexical probabilities from an untagged corpus and have used the resulting information in morphological disambiguation in Hebrew. Hajic and Hladka (1998) have used maximum entropy modeling approach for morphological disambiguation in Czech. Ezeiza et al. (1998) have combined stochastic and rule-based disambiguation methods for Basque. Megyesi (1999) has adapted Brill&apos;s POS tagger with extended lexical templates to Hungarian. Previous approaches to morphological disambiguation of Turkish text had employed a constraintbased approach (O azer and Ku"
C00-1042,W99-0633,0,0.0180002,"ly relevant features of word forms have to be determined correctly for morphological disambiguation. In this context, there have been some interesting previous studies for di erent languages. Levinger et al. (1995) have reported on an approach that learns morpholexical probabilities from an untagged corpus and have used the resulting information in morphological disambiguation in Hebrew. Hajic and Hladka (1998) have used maximum entropy modeling approach for morphological disambiguation in Czech. Ezeiza et al. (1998) have combined stochastic and rule-based disambiguation methods for Basque. Megyesi (1999) has adapted Brill&apos;s POS tagger with extended lexical templates to Hungarian. Previous approaches to morphological disambiguation of Turkish text had employed a constraintbased approach (O azer and Kuruoz, 1994; Oflazer and Tur, 1996; O azer and Tur, 1997). Although results obtained earlier in these approaches were reasonable, the fact that the constraint rules were hand crafted posed a rather serious impediment to the generality and improvement of these systems. 3 Turkish Turkish is a free constituent order language. The order of the constituents may change freely according to the discours"
C00-1042,A94-1024,1,0.89016,"Missing"
C00-1042,W96-0207,1,0.871567,"Missing"
C00-1042,P97-1029,1,0.865525,"Missing"
C00-1042,P99-1033,1,0.898211,"sever any relationships with an adverbial modi er modifying the root. Thus instead of a simple POS tag, we use the full morphological analyses of the words, represented as a combination of features (including any derivational markers) as their morphosyntactic tags. For instance in the example above, we would use everything including the root form as the morphosyntactic tag. In order to alleviate the data sparseness problem we break down the full tags. We represent each word as a sequence of in ectional groups (IGs hereafter), separated by ^DBs denoting derivation boundaries, as described by O azer (1999). Thus a morphological parse would be represented in the following general form: 1 The morphological features other than the POSs are: +Become: become verb, +Caus: causative verb, +Pos: Positive polarity, +Inf: marker that derives an in nitive form from a verb, +A3sg: 3sg number-person agreement, +Pnon: No possessive agreement, and +Nom: Nominative case. ^DB&apos;s mark derivational boundaries. Full Tags (No roots) In ectional Groups Possible Observed 1 9,129 10,531 2,194 Table 3: Numbers of Tags and IGs in our case P (wi jtn1 ) = P (wi jti ) = 1, we can write: ( P W jT 1. 2. 3. 4. Adj Verb+Become"
C00-1042,J95-2001,0,\N,Missing
C00-1042,W96-0102,0,\N,Missing
C00-1042,J88-1003,0,\N,Missing
C00-1042,W96-0213,0,\N,Missing
C00-1042,A00-2013,0,\N,Missing
C00-1042,W98-1303,0,\N,Missing
C00-1042,C98-1077,0,\N,Missing
C00-1042,A00-1031,0,\N,Missing
C00-1042,P98-1063,0,\N,Missing
C00-1042,C98-1060,0,\N,Missing
C18-3006,P17-1045,1,0.833186,"al., 2016) demonstrated that using neural dialogue models can overcome current obstacles of deploying dialogue systems in larger dialogue domains. Rastogi et al. (2017) also proposed a multi-domain dialogue state tracker to achieve effective and efficient domain adaptation. Dialogue Management – Dialogue Policy Optimization The dialogue policy can be learned in either a supervised or a reinforcement learning manner (Su et al., 2016). The reinforcement learning based dialogue agent has been recently developed in different tasks and shown applicable for interactive scenarios (Li et al., 2017b; Dhingra et al., 2017; Shah et al., 2016). In order to enable reinforcement learning, a simulated environment is required. Several approaches are proposed for building user simulators as the interactive environment (Li et al., 2016; El Asri et al., 2016; Crook and Marin, 2017), so that the dialogue policy can be trained in a reinforcement framework. Natural Language Generation The RNN-based models have been applied to language generation for both chit-chat and task-orientated dialogue systems (Vinyals and Le, 2015; Wen et al., 2015b). The RNN-based NLG can learn from unaligned data by jointly optimizing sentence p"
C18-3006,W16-3622,0,0.0392894,"Missing"
C18-3006,W13-4073,0,0.0289462,"a good mechanism for integrating longer term knowledge context and shorter term dialogue context into these models (Chen et al., 2016b; Chen et al., 2016c). In addition, the importance of the LU module is investigated in Li et al. (2017a), where different types of errors from LU may degrade the whole system performance in an reinforcement learning setting. Dialogue Management – Dialogue State Tracking The state-of-the-art dialogue managers focus on monitoring the dialogue progress by neural dialogue state trackers. Among the initial models are the RNN based dialogue state tracking approaches (Henderson et al., 2013) that has shown to outperform Bayesian networks (Thomson and Young, 2010). More recent work that provided conjoint representations between the utterances, slot-value pairs as well as knowledge graph representations (Wen et al., 2016; Mrkˇsi´c et al., 2016) demonstrated that using neural dialogue models can overcome current obstacles of deploying dialogue systems in larger dialogue domains. Rastogi et al. (2017) also proposed a multi-domain dialogue state tracker to achieve effective and efficient domain adaptation. Dialogue Management – Dialogue Policy Optimization The dialogue policy can be l"
C18-3006,C16-1038,0,0.0214715,"asks, which supported flexible question types, allowed user-initiated requests during conversation, and finally achieved better robustness. Human feedback is also effectively leveraged into the learning framework for on-line training in an end-to-end manner (Liu et al., 2018). Dialogue Breadth In order to extend the coverage of the systems, transfer learning has been applied to different extended systems in order to proceed to a multi-domain scenario. Chen et al. (2016a) transfered the dialogue acts across different domains so that the performance of the newly-developed domain can be boosted. Kim et al. (2016) proposed to learn a domain-specific and domain-independent information in order to transfer the shared knowledge more efficiently and effectively. In addition, Gaˇsi´c et al. (2015) presented the policy committee in order to boost the performance for policy training in a new domain. All above work extended the dialogue coverage using different directions. Dialogue Depth Most current systems focus on knowledge-based understanding, but there are hierarchical understanding according to the dialogue complexity. For example, an intent about party scheduling may include restaurant reserving and inv"
C18-3006,I17-1074,1,0.889711,"Missing"
C18-3006,N18-1187,1,0.878801,"Missing"
C18-3006,P16-1230,0,0.0236728,", 2010). More recent work that provided conjoint representations between the utterances, slot-value pairs as well as knowledge graph representations (Wen et al., 2016; Mrkˇsi´c et al., 2016) demonstrated that using neural dialogue models can overcome current obstacles of deploying dialogue systems in larger dialogue domains. Rastogi et al. (2017) also proposed a multi-domain dialogue state tracker to achieve effective and efficient domain adaptation. Dialogue Management – Dialogue Policy Optimization The dialogue policy can be learned in either a supervised or a reinforcement learning manner (Su et al., 2016). The reinforcement learning based dialogue agent has been recently developed in different tasks and shown applicable for interactive scenarios (Li et al., 2017b; Dhingra et al., 2017; Shah et al., 2016). In order to enable reinforcement learning, a simulated environment is required. Several approaches are proposed for building user simulators as the interactive environment (Li et al., 2016; El Asri et al., 2016; Crook and Marin, 2017), so that the dialogue policy can be trained in a reinforcement framework. Natural Language Generation The RNN-based models have been applied to language generat"
C18-3006,N18-2010,1,0.822287,"(Vinyals and Le, 2015; Wen et al., 2015b). The RNN-based NLG can learn from unaligned data by jointly optimizing sentence planning and surface realization, and language variation can be easily achieved by sampling from output candidates (Wen et al., 2015a). Moreover, Wen et al. (2015b) improved the prior work by adding a gating mechanism for controlling the dialogue act during generation in order to avoid semantics repetition, showing promising results. Several aspects of improvement have been achieved using contextual and structured information (Duˇsek and Jurcicek, 2016; Nayak et al., 2017; Su et al., 2018) 4 Recent Trends and Challenges on Learning Dialogues This part will focus on discussing the recent trends and current challenges on dialogue system technology. End-to-End Learning for Dialogue Systems With the power of neural networks, there are more and more attempts for learning dialogue systems in an end-to-end fashion. Different learning frameworks are applied, including supervised learning and reinforcement learning. This part will discuss the work about end-to-end learning for dialogues (Dhingra et al., 2016; Wen et al., 2016; Williams and Zweig, 2016; Zhao and Eskenazi, 2016; Li et al."
C18-3006,W15-4639,0,0.0722328,"Missing"
C18-3006,D15-1199,0,0.0234091,"fferent tasks and shown applicable for interactive scenarios (Li et al., 2017b; Dhingra et al., 2017; Shah et al., 2016). In order to enable reinforcement learning, a simulated environment is required. Several approaches are proposed for building user simulators as the interactive environment (Li et al., 2016; El Asri et al., 2016; Crook and Marin, 2017), so that the dialogue policy can be trained in a reinforcement framework. Natural Language Generation The RNN-based models have been applied to language generation for both chit-chat and task-orientated dialogue systems (Vinyals and Le, 2015; Wen et al., 2015b). The RNN-based NLG can learn from unaligned data by jointly optimizing sentence planning and surface realization, and language variation can be easily achieved by sampling from output candidates (Wen et al., 2015a). Moreover, Wen et al. (2015b) improved the prior work by adding a gating mechanism for controlling the dialogue act during generation in order to avoid semantics repetition, showing promising results. Several aspects of improvement have been achieved using contextual and structured information (Duˇsek and Jurcicek, 2016; Nayak et al., 2017; Su et al., 2018) 4 Recent Trends and Ch"
C18-3006,W16-3601,0,0.02409,"yak et al., 2017; Su et al., 2018) 4 Recent Trends and Challenges on Learning Dialogues This part will focus on discussing the recent trends and current challenges on dialogue system technology. End-to-End Learning for Dialogue Systems With the power of neural networks, there are more and more attempts for learning dialogue systems in an end-to-end fashion. Different learning frameworks are applied, including supervised learning and reinforcement learning. This part will discuss the work about end-to-end learning for dialogues (Dhingra et al., 2016; Wen et al., 2016; Williams and Zweig, 2016; Zhao and Eskenazi, 2016; Li et al., 2017b). Recent advance of deep learning has inspired many applications of neural models to dialogue systems. Wen et al. (2016) and Bordes and Weston (2016) introduced a network-based end-to-end trainable taskoriented dialogue system, which treated dialogue system learning as the problem of learning a mapping from dialogue histories to system responses, and applied an encoder-decoder model to train the whole system. However, the system is trained in a supervised fashion, thus requires a lot of training data, and may not be able to explore the unknown space that does not exist in th"
D14-1223,W12-3504,0,0.0231025,"e.g. the last book)1 . To achieve a natural and accurate human to machine conversation, it is crucial to accurately identify and resolve referring expressions in utterances. As important as interpreting referring expressions (REs) is for modern NUI designs, relatively few studies have investigated withing the SDSs. Those that do focus on the impact of the input from multimodal interfaces such as gesture for understanding (Bolt, 1980; Heck et al., 2013; Johnston et al., 2002), touch for ASR error correction (Huggins-Daines and Rudnicky, 2008), or cues from the screen (Balchandran et al., 2008; Anastasiou et al., 2012). Most of these systems are engineered for a specific 1 An item could be anything from a list, e.g. restaurants, games, contact list, organized in different lay-outs on the screen. 2094 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2094–2104, c October 25-29, 2014, Doha, Qatar. 2014 Association for Computational Linguistics task, making it harder to generalize for different domains or SDSs. In this paper, we investigate a rather generic contextual model for resolving natural language REs for on-screen item selection to improve conversatio"
D14-1223,W10-0701,0,0.0298155,"Missing"
D14-1223,W09-0609,0,0.0201843,"mber of multimodal systems have been built, among which there are systems that combine speech, pointing (Neal, 1991), and gaze (Koons et al., 1993), systems that engage users in an intelligent conversation (Gustafson et al., 2000). Earlier studies have shown that multimodal interfaces enable users to interact with computers naturally and effectively (Schober and Clark, 1989; Oviatt et al., 1997). Considered as part of the situated interactive frameworks, many work focus on the problem of predicting how the user has resolved REs that is generated by the system, e.g., (Clark and Wilkes-Gibbs, ; Dale and Viethen, 2009; Gieselmann, 2004; Janarthanam and Lemon, 2010; Golland et al., 2010). In this work, focusing on smart devices, we investigate how the system resolves the REs in user utterances to take the next correct action. In (Pfleger and J.Alexandersson, 2006) a reference resolution model is presented for a questionanswering system on a mobile, multi-modal interface. Their system has several features to parse the posed question and keep history of the dialog to resolve co-reference issues. Their questionanswering model uses gesture as features to resolve queries such as “what’s the name of that [pointin"
D14-1223,W12-1633,0,0.0149236,"resolves the REs in user utterances to take the next correct action. In (Pfleger and J.Alexandersson, 2006) a reference resolution model is presented for a questionanswering system on a mobile, multi-modal interface. Their system has several features to parse the posed question and keep history of the dialog to resolve co-reference issues. Their questionanswering model uses gesture as features to resolve queries such as “what’s the name of that [pointing gesture] player?”, but they do not resolve locational referrals such as “the middle one” or “the second harry potter movie”. Others such as (Funakoshi et al., 2012) resolve anaphoric (“it”) or exophoric (“this one”) types of expressions in user utterances to identify geometric objects. In this paper, we study several types of REs to build a natural and flexible interaction for the user. (Heck et al., 2013) present an intent prediction model enriched with gesture detector to help disambiguate between different user intents related to the interface. In (Misu et al., 2014) a situated incar dialog model is presented to answer drivers’ spoken queries about their surroundings (no display screen). They integrate multi-modal inputs of 2095 speech, geo-location a"
D14-1223,D10-1040,0,0.123759,"Missing"
D14-1223,P08-4005,0,0.0285568,"s shown in Table 1. Note that, there are multiple ways of referring to the same item, (e.g. the last book)1 . To achieve a natural and accurate human to machine conversation, it is crucial to accurately identify and resolve referring expressions in utterances. As important as interpreting referring expressions (REs) is for modern NUI designs, relatively few studies have investigated withing the SDSs. Those that do focus on the impact of the input from multimodal interfaces such as gesture for understanding (Bolt, 1980; Heck et al., 2013; Johnston et al., 2002), touch for ASR error correction (Huggins-Daines and Rudnicky, 2008), or cues from the screen (Balchandran et al., 2008; Anastasiou et al., 2012). Most of these systems are engineered for a specific 1 An item could be anything from a list, e.g. restaurants, games, contact list, organized in different lay-outs on the screen. 2094 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2094–2104, c October 25-29, 2014, Doha, Qatar. 2014 Association for Computational Linguistics task, making it harder to generalize for different domains or SDSs. In this paper, we investigate a rather generic contextual model for resol"
D14-1223,W10-4324,0,0.0183448,", among which there are systems that combine speech, pointing (Neal, 1991), and gaze (Koons et al., 1993), systems that engage users in an intelligent conversation (Gustafson et al., 2000). Earlier studies have shown that multimodal interfaces enable users to interact with computers naturally and effectively (Schober and Clark, 1989; Oviatt et al., 1997). Considered as part of the situated interactive frameworks, many work focus on the problem of predicting how the user has resolved REs that is generated by the system, e.g., (Clark and Wilkes-Gibbs, ; Dale and Viethen, 2009; Gieselmann, 2004; Janarthanam and Lemon, 2010; Golland et al., 2010). In this work, focusing on smart devices, we investigate how the system resolves the REs in user utterances to take the next correct action. In (Pfleger and J.Alexandersson, 2006) a reference resolution model is presented for a questionanswering system on a mobile, multi-modal interface. Their system has several features to parse the posed question and keep history of the dialog to resolve co-reference issues. Their questionanswering model uses gesture as features to resolve queries such as “what’s the name of that [pointing gesture] player?”, but they do not resolve lo"
D14-1223,P03-1054,0,0.00549152,"id display. Also in “third from the ::: last”, the “third” :::: is the column-position, and the “last” is the column-pivot, the pivotal reference of the column in a multi-column grid display. The fourth tag, row-position, is used when the specific row is explicitly referred, such as in “the Harry Potter movie in the ::: first row”. To train our CRF-based SLL model we use three types of features: the current word, window words e.g., previous-word, next-word, etc., using five-window around the current word, and syntactic features from the part-of-speech (POS) tagger using the Stanford’s parser (Klein and Manning, 2003). Row Indicator Feature: This feature sets the relationship between the n-gram in an utterance indicated by the row-position or row-pivot tag and the item’s row number on the screen. For instance, given SSL output row-pivot(’top’) and item’s location row=1, the value of the feature is set to ’1’. If no row tag is found by SLL, this feature is set to ’0’. We use regular expressions to parse the numerical indicators, e.g., ’top’=’1’. Column Indicator Feature: Similarly, this feature indicates if a phrase in utterance indicated by the column-position or column-pivot tag matches the item’s column"
D14-1223,W14-4304,0,0.0303549,"uch as “what’s the name of that [pointing gesture] player?”, but they do not resolve locational referrals such as “the middle one” or “the second harry potter movie”. Others such as (Funakoshi et al., 2012) resolve anaphoric (“it”) or exophoric (“this one”) types of expressions in user utterances to identify geometric objects. In this paper, we study several types of REs to build a natural and flexible interaction for the user. (Heck et al., 2013) present an intent prediction model enriched with gesture detector to help disambiguate between different user intents related to the interface. In (Misu et al., 2014) a situated incar dialog model is presented to answer drivers’ spoken queries about their surroundings (no display screen). They integrate multi-modal inputs of 2095 speech, geo-location and gaze. We investigate a variety of REs for visual interfaces, and analyze automatic resolution in a classification task introducing a wide range of syntactic, semantic and contextual features. We look at how REs change with screen layout comparing different devices. To the best of our knowledge, our work is first to analyze REs from these aspects. 3 Data Crowdsourcing services, such as Amazon Mechanical Tur"
D14-1223,W97-1401,0,0.0320853,"dal systems provide a natural and effective way for users to interact with computers through multiple modalities such as speech, gesture, and gaze. Since the first appearance of the Put-That-There system (Bolt, 1980), a number of multimodal systems have been built, among which there are systems that combine speech, pointing (Neal, 1991), and gaze (Koons et al., 1993), systems that engage users in an intelligent conversation (Gustafson et al., 2000). Earlier studies have shown that multimodal interfaces enable users to interact with computers naturally and effectively (Schober and Clark, 1989; Oviatt et al., 1997). Considered as part of the situated interactive frameworks, many work focus on the problem of predicting how the user has resolved REs that is generated by the system, e.g., (Clark and Wilkes-Gibbs, ; Dale and Viethen, 2009; Gieselmann, 2004; Janarthanam and Lemon, 2010; Golland et al., 2010). In this work, focusing on smart devices, we investigate how the system resolves the REs in user utterances to take the next correct action. In (Pfleger and J.Alexandersson, 2006) a reference resolution model is presented for a questionanswering system on a mobile, multi-modal interface. Their system has"
D14-1223,P02-1048,0,\N,Missing
L16-1117,S15-2048,0,0.0430218,"Missing"
L16-1117,P10-2057,0,0.0173616,"is that what thFigure 1: Actionable item examples in meeting corpus. meeting (for example, when a meeting participant commits to an action item during a meeting, s/he may be sent a note or reminder about that action item, later on). Our annotations on a subset of the ICSI meetings corpus (Janin et al., 2003) enable research on actionable item detection and associated argument extraction tasks, and the study of appropriate user interface designs for implementation of these actionable items is left as a future work. Previous work on meeting understanding investigated de739 tection of decisions (Bui and Peters, 2010; Fern´andez et al., 2008), action items (Yang et al., 2008), agreement and disagreements (Galley et al., 2004; Hillard et al., 2003), and summarization (Riedhammer et al., 2010; Xie et al., 2009; Chen and Metze, 2013). Our task is closest to detection of action items, actually, action items are considered as a subgroup of actionable items that can be actionable in the form of reminders or to do lists. 2. Human-Machine Genre create_calendar_entry schedule a meeting with &lt;contact_name&gt;John&lt;/contact_name&gt; &lt;start_time&gt;this afternoon&lt;/start_time&gt; Human-Human Genre create_calendar_entry how about t"
L16-1117,W08-0125,0,0.0496516,"Missing"
L16-1117,P04-1085,0,0.0496143,"cipant commits to an action item during a meeting, s/he may be sent a note or reminder about that action item, later on). Our annotations on a subset of the ICSI meetings corpus (Janin et al., 2003) enable research on actionable item detection and associated argument extraction tasks, and the study of appropriate user interface designs for implementation of these actionable items is left as a future work. Previous work on meeting understanding investigated de739 tection of decisions (Bui and Peters, 2010; Fern´andez et al., 2008), action items (Yang et al., 2008), agreement and disagreements (Galley et al., 2004; Hillard et al., 2003), and summarization (Riedhammer et al., 2010; Xie et al., 2009; Chen and Metze, 2013). Our task is closest to detection of action items, actually, action items are considered as a subgroup of actionable items that can be actionable in the form of reminders or to do lists. 2. Human-Machine Genre create_calendar_entry schedule a meeting with &lt;contact_name&gt;John&lt;/contact_name&gt; &lt;start_time&gt;this afternoon&lt;/start_time&gt; Human-Human Genre create_calendar_entry how about the &lt;contact_name&gt;three of us&lt;/contact_name&gt; discuss this later &lt;start_time&gt;this afternoon&lt;/start_time&gt;? AIMU D"
L16-1117,D14-1002,0,0.0770124,"Missing"
L16-1117,N03-2012,0,0.0772157,"action item during a meeting, s/he may be sent a note or reminder about that action item, later on). Our annotations on a subset of the ICSI meetings corpus (Janin et al., 2003) enable research on actionable item detection and associated argument extraction tasks, and the study of appropriate user interface designs for implementation of these actionable items is left as a future work. Previous work on meeting understanding investigated de739 tection of decisions (Bui and Peters, 2010; Fern´andez et al., 2008), action items (Yang et al., 2008), agreement and disagreements (Galley et al., 2004; Hillard et al., 2003), and summarization (Riedhammer et al., 2010; Xie et al., 2009; Chen and Metze, 2013). Our task is closest to detection of action items, actually, action items are considered as a subgroup of actionable items that can be actionable in the form of reminders or to do lists. 2. Human-Machine Genre create_calendar_entry schedule a meeting with &lt;contact_name&gt;John&lt;/contact_name&gt; &lt;start_time&gt;this afternoon&lt;/start_time&gt; Human-Human Genre create_calendar_entry how about the &lt;contact_name&gt;three of us&lt;/contact_name&gt; discuss this later &lt;start_time&gt;this afternoon&lt;/start_time&gt;? AIMU Data Set The actionable"
N09-2067,lamel-etal-2008-question,0,0.0603513,"Missing"
N09-2067,N06-4010,0,0.0664508,"Missing"
N18-1187,P17-1045,0,0.577602,"query-regression networks (Seo et al., 2016), gated memory networks (Liu and Perez, 2017), and copy-augmented networks (Eric and Manning, 2017) to learn the dialogue state. These systems directly select a final response from a list of response candidates conditioning on the dialogue history without doing slot filling or user goal tracking. Our model, on the other hand, explicitly tracks user’s goal for effective integration with knowledge bases (KBs). Robust dialogue state tracking has been shown (Jurˇc´ıcˇ ek et al., 2012) to 2061 be critical in improving dialogue success in task completion. Dhingra et al. (2017) proposed an end-to-end RL dialogue agent for information access. Their model focuses on bringing differentiability to the KB query operation by introducing a “soft” retrieval process in selecting the KB entries. Such soft-KB lookup is prone to entity updates and additions in the KB, which is common in real world information systems. In our model, we use symbolic queries and leave the selection of KB entities to external services (e.g. a recommender system), as entity ranking in real world systems can be made with much richer features (e.g. user profiles, location and time context, etc.). Qual"
N18-1187,E17-2075,0,0.1117,"nknown how well the model performance generalizes to unseen dialogue state during user interactions. Our system is trained by a combination of supervised and deep RL methods, as it is shown that RL may effectively improve dialogue success rate by exploring a large dialogue action space (Henderson et al., 2008; Li et al., 2017). Bordes and Weston (2017) proposed a taskoriented dialogue model using end-to-end memory networks. In the same line of research, people explored using query-regression networks (Seo et al., 2016), gated memory networks (Liu and Perez, 2017), and copy-augmented networks (Eric and Manning, 2017) to learn the dialogue state. These systems directly select a final response from a list of response candidates conditioning on the dialogue history without doing slot filling or user goal tracking. Our model, on the other hand, explicitly tracks user’s goal for effective integration with knowledge bases (KBs). Robust dialogue state tracking has been shown (Jurˇc´ıcˇ ek et al., 2012) to 2061 be critical in improving dialogue success in task completion. Dhingra et al. (2017) proposed an end-to-end RL dialogue agent for information access. Their model focuses on bringing differentiability to the"
N18-1187,J08-4002,0,0.737487,"This makes it especially important for a system to be able to learn from users in an interactive manner. Comparing to SL models, systems trained with RL by receiving feedback during users interactions showed improved model robustness against diverse dialogue scenarios (Williams and Zweig, 2016; Liu and Lane, 2017b). A critical step in learning RL based taskoriented dialogue models is dialogue policy learning. Training dialogue policy online from scratch typically requires a large number of interactive learning sessions before an agent can reach a satisfactory performance level. Recent works (Henderson et al., 2008; Williams et al., 2017; Liu et al., 2017) explored pre-training the dialogue model using human-human or human-machine dialogue 2060 Proceedings of NAACL-HLT 2018, pages 2060–2069 c New Orleans, Louisiana, June 1 - 6, 2018. 2018 Association for Computational Linguistics corpora before performing interactive learning with RL to address this concern. A potential drawback with such pre-training approach is that the model may suffer from the mismatch of dialogue state distributions between supervised training and interactive learning stages. While interacting with users, the agent’s response at ea"
N18-1187,W14-4337,0,0.647552,"y in successfully completing a task. 1 Introduction Task-oriented dialogue systems assist users to complete tasks in specific domains by understanding user’s request and aggregate useful information from external resources within several dialogue turns. Conventional task-oriented dialogue systems have a complex pipeline (Rudnicky et al., 1999; Raux et al., 2005; Young et al., 2013) consisting of independently developed and modularly connected components for natural language understanding (NLU) (Mesnil et al., 2015; Liu and Lane, 2016; Hakkani-T¨ur et al., 2016), dialogue state tracking (DST) (Henderson et al., 2014c; ∗ † Work done while the author was an intern at Google. Work done while at Google Research. Mrkˇsi´c et al., 2016), and dialogue policy learning (Gasic and Young, 2014; Shah et al., 2016; Su et al., 2016, 2017). These system components are usually trained independently, and their optimization targets may not fully align with the overall system evaluation criteria (e.g. task success rate and user satisfaction). Moreover, errors made in the upper stream modules of the pipeline propagate to downstream components and get amplified, making it hard to track the source of errors. To address these"
N18-1187,W14-4340,0,0.697106,"y in successfully completing a task. 1 Introduction Task-oriented dialogue systems assist users to complete tasks in specific domains by understanding user’s request and aggregate useful information from external resources within several dialogue turns. Conventional task-oriented dialogue systems have a complex pipeline (Rudnicky et al., 1999; Raux et al., 2005; Young et al., 2013) consisting of independently developed and modularly connected components for natural language understanding (NLU) (Mesnil et al., 2015; Liu and Lane, 2016; Hakkani-T¨ur et al., 2016), dialogue state tracking (DST) (Henderson et al., 2014c; ∗ † Work done while the author was an intern at Google. Work done while at Google Research. Mrkˇsi´c et al., 2016), and dialogue policy learning (Gasic and Young, 2014; Shah et al., 2016; Su et al., 2016, 2017). These system components are usually trained independently, and their optimization targets may not fully align with the overall system evaluation criteria (e.g. task success rate and user satisfaction). Moreover, errors made in the upper stream modules of the pipeline propagate to downstream components and get amplified, making it hard to track the source of errors. To address these"
N18-1187,P16-1094,0,0.0254807,"kov Decision Process (POMDP) (Young et al., 2013). RL can be applied in the POMDP framework to learn dialogue policy online by interacting with users (Gaˇsi´c et al., 2013). The dialogue state and system action space have to be carefully designed in order to make the policy learning tractable (Young et al., 2013), which limits the model’s usage to restricted domains. Recent efforts have been made in designing end-to-end solutions for task-oriented dialogues, inspired by the success of encoder-decoder based neural network models in non-task-oriented conversational systems (Serban et al., 2015; Li et al., 2016). Wen et al. (Wen et al., 2017) designed an end-to-end trainable neural dialogue model with modularly connected system components. This system is a supervised learning model which is evaluated on fixed dialogue corpora. It is unknown how well the model performance generalizes to unseen dialogue state during user interactions. Our system is trained by a combination of supervised and deep RL methods, as it is shown that RL may effectively improve dialogue success rate by exploring a large dialogue action space (Henderson et al., 2008; Li et al., 2017). Bordes and Weston (2017) proposed a taskori"
N18-1187,I17-1074,0,0.134283,"aluation criteria (e.g. task success rate and user satisfaction). Moreover, errors made in the upper stream modules of the pipeline propagate to downstream components and get amplified, making it hard to track the source of errors. To address these limitations with the conventional task-oriented dialogue systems, recent efforts have been made in designing endto-end learning solutions with neural network based methods. Both supervised learning (SL) based (Wen et al., 2017; Bordes and Weston, 2017; Liu and Lane, 2017a) and deep reinforcement learning (RL) based systems (Zhao and Eskenazi, 2016; Li et al., 2017; Peng et al., 2017) have been studied in the literature. Comparing to chit-chat dialogue models that are usually trained offline using single-turn context-response pairs, task-oriented dialogue model involves reasoning and planning over multiple dialogue turns. This makes it especially important for a system to be able to learn from users in an interactive manner. Comparing to SL models, systems trained with RL by receiving feedback during users interactions showed improved model robustness against diverse dialogue scenarios (Williams and Zweig, 2016; Liu and Lane, 2017b). A critical step in"
N18-1187,W16-3603,1,0.805663,"dback after the imitation learning stage further improves the agent’s capability in successfully completing a task. 1 Introduction Task-oriented dialogue systems assist users to complete tasks in specific domains by understanding user’s request and aggregate useful information from external resources within several dialogue turns. Conventional task-oriented dialogue systems have a complex pipeline (Rudnicky et al., 1999; Raux et al., 2005; Young et al., 2013) consisting of independently developed and modularly connected components for natural language understanding (NLU) (Mesnil et al., 2015; Liu and Lane, 2016; Hakkani-T¨ur et al., 2016), dialogue state tracking (DST) (Henderson et al., 2014c; ∗ † Work done while the author was an intern at Google. Work done while at Google Research. Mrkˇsi´c et al., 2016), and dialogue policy learning (Gasic and Young, 2014; Shah et al., 2016; Su et al., 2016, 2017). These system components are usually trained independently, and their optimization targets may not fully align with the overall system evaluation criteria (e.g. task success rate and user satisfaction). Moreover, errors made in the upper stream modules of the pipeline propagate to downstream components"
N18-1187,P17-1163,0,0.0701032,"Missing"
N18-1187,D17-1237,0,0.0724012,"(e.g. task success rate and user satisfaction). Moreover, errors made in the upper stream modules of the pipeline propagate to downstream components and get amplified, making it hard to track the source of errors. To address these limitations with the conventional task-oriented dialogue systems, recent efforts have been made in designing endto-end learning solutions with neural network based methods. Both supervised learning (SL) based (Wen et al., 2017; Bordes and Weston, 2017; Liu and Lane, 2017a) and deep reinforcement learning (RL) based systems (Zhao and Eskenazi, 2016; Li et al., 2017; Peng et al., 2017) have been studied in the literature. Comparing to chit-chat dialogue models that are usually trained offline using single-turn context-response pairs, task-oriented dialogue model involves reasoning and planning over multiple dialogue turns. This makes it especially important for a system to be able to learn from users in an interactive manner. Comparing to SL models, systems trained with RL by receiving feedback during users interactions showed improved model robustness against diverse dialogue scenarios (Williams and Zweig, 2016; Liu and Lane, 2017b). A critical step in learning RL based ta"
N18-1187,N07-2038,0,0.0944419,"is last expression above gives us an unbiased gradient estimator. 4 Experiments 4.1 Datasets We evaluate the proposed method on DSTC2 (Henderson et al., 2014a) dataset in restaurant search domain and an internally collected dialogue corpus1 in movie booking domain. The movie booking dialogue corpus has an average number of 8.4 turns per dialogue. Its training set has 100K dialogues, and the development set and test set each has 10K dialogues. The movie booking dialogue corpus is generated (Shah et al., 2018) using a finite state machine based dialogue agent and an agenda based user simulator (Schatzmann et al., 2007) with natural language utterances rewritten by real users. The user simulator can be configured with different personalities, showing various levels of randomness and cooperativeness. This user simulator is also used to interact with our end-to-end training agent during imitation and reinforcement learning stages. We randomly select a user profile 1 The dataset can be accessed via https: //github.com/google-research-datasets/ simulated-dialogue when conducting each dialogue simulation. During model evaluation, we use an extended set of natural language surface forms over the ones used during t"
N18-1187,N18-3006,1,0.888483,"Missing"
N18-1187,W17-5518,0,0.10187,"Missing"
N18-1187,P16-1230,0,0.0434902,"resources within several dialogue turns. Conventional task-oriented dialogue systems have a complex pipeline (Rudnicky et al., 1999; Raux et al., 2005; Young et al., 2013) consisting of independently developed and modularly connected components for natural language understanding (NLU) (Mesnil et al., 2015; Liu and Lane, 2016; Hakkani-T¨ur et al., 2016), dialogue state tracking (DST) (Henderson et al., 2014c; ∗ † Work done while the author was an intern at Google. Work done while at Google Research. Mrkˇsi´c et al., 2016), and dialogue policy learning (Gasic and Young, 2014; Shah et al., 2016; Su et al., 2016, 2017). These system components are usually trained independently, and their optimization targets may not fully align with the overall system evaluation criteria (e.g. task success rate and user satisfaction). Moreover, errors made in the upper stream modules of the pipeline propagate to downstream components and get amplified, making it hard to track the source of errors. To address these limitations with the conventional task-oriented dialogue systems, recent efforts have been made in designing endto-end learning solutions with neural network based methods. Both supervised learning (SL) bas"
N18-1187,E17-1042,0,0.0800566,"Missing"
N18-1187,P17-1062,0,0.508865,"y important for a system to be able to learn from users in an interactive manner. Comparing to SL models, systems trained with RL by receiving feedback during users interactions showed improved model robustness against diverse dialogue scenarios (Williams and Zweig, 2016; Liu and Lane, 2017b). A critical step in learning RL based taskoriented dialogue models is dialogue policy learning. Training dialogue policy online from scratch typically requires a large number of interactive learning sessions before an agent can reach a satisfactory performance level. Recent works (Henderson et al., 2008; Williams et al., 2017; Liu et al., 2017) explored pre-training the dialogue model using human-human or human-machine dialogue 2060 Proceedings of NAACL-HLT 2018, pages 2060–2069 c New Orleans, Louisiana, June 1 - 6, 2018. 2018 Association for Computational Linguistics corpora before performing interactive learning with RL to address this concern. A potential drawback with such pre-training approach is that the model may suffer from the mismatch of dialogue state distributions between supervised training and interactive learning stages. While interacting with users, the agent’s response at each turn has a direct in"
N18-1187,W16-3601,0,0.133842,"ith the overall system evaluation criteria (e.g. task success rate and user satisfaction). Moreover, errors made in the upper stream modules of the pipeline propagate to downstream components and get amplified, making it hard to track the source of errors. To address these limitations with the conventional task-oriented dialogue systems, recent efforts have been made in designing endto-end learning solutions with neural network based methods. Both supervised learning (SL) based (Wen et al., 2017; Bordes and Weston, 2017; Liu and Lane, 2017a) and deep reinforcement learning (RL) based systems (Zhao and Eskenazi, 2016; Li et al., 2017; Peng et al., 2017) have been studied in the literature. Comparing to chit-chat dialogue models that are usually trained offline using single-turn context-response pairs, task-oriented dialogue model involves reasoning and planning over multiple dialogue turns. This makes it especially important for a system to be able to learn from users in an interactive manner. Comparing to SL models, systems trained with RL by receiving feedback during users interactions showed improved model robustness against diverse dialogue scenarios (Williams and Zweig, 2016; Liu and Lane, 2017b). A"
N18-3006,D16-1127,0,0.06104,"that (i) the developer must anticipate all ways in which users might interact with the agent, and (ii) since the programmed dialogue flows are not “differentiable”, the agent’s dialogue policy cannot be improved automatically with experience and each improvement requires human intervention to add logic to support a new dialogue flow or revise an existing flow. Recently proposed neural conversational models (Vinyals and Le (2015)) are trained with supervision over a large corpus of dialogues (Serban et al. (2016, 2017); Lowe et al. (2017)) or with reinforcement to optimize a long term reward (Li et al. (2016a,b)). End-to-end neural conversational models for task-oriented dialogues (Wen et al. (2016); Liu and Lane (2017a)) leverage annotated dialogues collected with an expert to embed the expert’s dialogue policy for a given task in End-to-end neural models show great promise towards building conversational agents that are trained from data and on-line experience using supervised and reinforcement learning. However, these models require a large corpus of dialogues to learn effectively. For goal-oriented dialogues, such datasets are expensive to collect and annotate, since each task involves a sepa"
N18-3006,W17-5526,0,0.184781,"Missing"
N18-3006,W16-3613,0,0.138296,"Missing"
N18-3006,D17-2014,0,0.0369977,"be replaced by machine learned generative models if available. Task Completion Platform (TCP) (Crook et al. (2016)) introduced a task configuration language for building goal-oriented dialogue interactions. The state update and policy modules of TCP could be used to implement agents that generate outlines for more complex tasks. The crowd-sourcing step uses human intelligence to gather diverse natural language utterances. Comparisons with the DSTC2 dataset show that this approach can create high-quality fully annotated datasets for training conversational agents in arbitrary domains. ParlAI (Miller et al. (2017)), a dialogue research software platform, provides easy integration with crowd sourcing for data collection and evaluation. However, the crowd sourcing tasks are open-ended and may result in lower quality dialogues as described in Section 4. In M2M, crowd workers are asked to paraphrase given utterances instead of writing new ones, which is at a suitable difficulty level for crowd workers. Finally, training a neural conversational model over the M2M generated dataset encodes the programmed policy in a differentiable neural model which can be deployed to interact with users. This model is amena"
N18-3006,N07-2038,0,0.152328,"ions consist of dialogue frames that encode the semantics of the turn through a dialogue act and a slot-value map (Table 1). For example “inform(date=tomorrow, time=evening)” is a dialogue frame that informs the system of the user’s constraints for the date and time slots. We use the Cambridge dialogue act schema (Henderson et al. (2013)) as the list of possible dialogue 43 acts. The process continues until either the user’s goals are achieved and the user exits the dialogue with a “bye()” act, or a maximum number of turns are reached. In our experiments we use an agenda-based user simulator (Schatzmann et al. (2007)) parameterized by a user goal and a user profile. The programmed system agent is modeled as a handcrafted finite state machine (Hopcroft et al. (2006)) which encodes a set of taskindependent rules for constructing system turns, with each turn consisting of a response frame which responds to the user’s previous turn, and an initiate frame which drives the dialogue forward through a predetermined sequence of subdialogues. For database querying applications, these sub-dialogues are: gather user preferences, query a database via an API, offer matching entities to the user, allow user to modify pr"
N18-3006,W17-5518,0,0.0624267,"Missing"
N18-3006,P16-1230,0,0.0449031,"Missing"
N18-3006,P17-4013,0,0.0196211,"ents from a programmed system agent, we trained an end-to-end conversa4 https://github.com/google-research-datasets/simulateddialogue 46 6 Related work and discussion We presented an approach for rapidly bootstrapping goal-oriented conversational agents for arbitrary database querying tasks, by combining dialogue self-play, crowd-sourcing and on-line reinforcement learning. The dialogue self-play step uses a taskindependent user simulator and programmed system agent seeded with a task-specific schema, which provides the developer with full control over the generated dialogue outlines. PyDial (Ultes et al. (2017)) is an extensible open-source toolkit which provides domain-independent implementations of dialogue system modules, which could be extended by adding dialogue self-play functionality. We described an FSM system agent for handling any transactional or form-filling task. For more complex tasks, the developer can extend the user simulator and system agents by adding their own rules. These components could also be replaced by machine learned generative models if available. Task Completion Platform (TCP) (Crook et al. (2016)) introduced a task configuration language for building goal-oriented dial"
N18-3006,P15-1129,0,0.018062,"API state for each turn. These annotated dialogues are sufficient for training end-toend models using supervision (Wen et al. (2016)). Dialogue self-play ensures sufficient coverage of flows encoded in the programmed system agent in the crowd sourced dataset. Consequently, the trained agent reads natural language user utterances and emits system turns by encoding the FSM policy of system agent in a differentiable neural model. Template utterances. Once a full dialogue has been sampled, a template utterance generator maps each annotation to a template utterance using a domain-general grammar (Wang et al. (2015)) parameterized with the task schema. For example, “inform(date=tomorrow, time=evening)” would map to a template “($slot is $value) (and ($slot is $value))*”, which is grounded as “Date is tomorrow and time is evening.” The developer can also provide a list of templates to use for some or all of the dialogue frames if they want more control over the language used in the utterances. Template utterances are an important bridge between the annotation and the corresponding natural language utterance, as they present the semantic information of a turn annotation in a format understandable by crowd"
P09-1048,P98-1013,0,0.0125282,"Missing"
P09-1048,W05-0620,0,0.0201316,"Missing"
P09-1048,P01-1017,0,0.0402229,"Missing"
P09-1048,W03-1006,0,0.020803,"Missing"
P09-1048,erk-pado-2006-shalmaneser,0,0.021266,"Missing"
P09-1048,J02-3001,0,0.10105,"Missing"
P09-1048,P02-1031,0,0.0346015,"Missing"
P09-1048,P07-1098,0,0.019224,"Missing"
P09-1048,N07-1051,0,0.0240934,"Missing"
P09-1048,C04-1127,1,0.822126,"Missing"
P09-1048,N04-1032,0,0.0335295,"Missing"
P09-1048,W05-0623,0,0.0539303,"Missing"
P09-1048,W04-3212,0,0.049316,"Missing"
P09-1048,W01-1511,1,0.848003,"Missing"
P09-1048,D07-1077,0,0.0941353,"Missing"
P09-1048,N10-1005,1,\N,Missing
P09-1048,C98-1013,0,\N,Missing
P10-1084,P06-1039,0,0.411341,"rid model can produce coherent and non-redundant summaries. 2 Background and Motivation There are many studies on the principles governing multi-document summarization to produce coherent and semantically relevant summaries. Previous work (Nenkova and Vanderwende, 2005; Conroy et al., 2006), focused on the fact that frequency of words plays an important factor. While, earlier work on summarization depend on a word score function, which is used to measure sentence rank scores based on (semi-)supervised learning methods, recent trend of purely data-driven methods, (Barzilay and Lee, 2004; Daum´ eIII and Marcu, 2006; Tang et al., 2009; Haghighi and Vanderwende, 2009), have shown remarkable improvements. Our work builds on both methods by constructing a hybrid approach to summarization. Our objective is to discover from document clusters, the latent topics that are organized into hierarchies following (Haghighi and Vanderwende, 2009). A hierarchical model is particularly appealing to summarization than a ”flat” model, e.g. LDA (Blei et al., 2003b), in that one can discover ”abstract” and ”specific” topics. For instance, discovering that ”baseball” and ”football” are both contained in an abstract class ”sp"
P10-1084,N04-1015,0,0.0190875,"aluations confirm that our hybrid model can produce coherent and non-redundant summaries. 2 Background and Motivation There are many studies on the principles governing multi-document summarization to produce coherent and semantically relevant summaries. Previous work (Nenkova and Vanderwende, 2005; Conroy et al., 2006), focused on the fact that frequency of words plays an important factor. While, earlier work on summarization depend on a word score function, which is used to measure sentence rank scores based on (semi-)supervised learning methods, recent trend of purely data-driven methods, (Barzilay and Lee, 2004; Daum´ eIII and Marcu, 2006; Tang et al., 2009; Haghighi and Vanderwende, 2009), have shown remarkable improvements. Our work builds on both methods by constructing a hybrid approach to summarization. Our objective is to discover from document clusters, the latent topics that are organized into hierarchies following (Haghighi and Vanderwende, 2009). A hierarchical model is particularly appealing to summarization than a ”flat” model, e.g. LDA (Blei et al., 2003b), in that one can discover ”abstract” and ”specific” topics. For instance, discovering that ”baseball” and ”football” are both contai"
P10-1084,W04-1013,0,0.0674545,"d summary, we incrementally add onto the summary the highest ranked sentence om and check if om significantly repeats the information already included in the summary until the algorithm reaches word count limit. We use a word overlap measure between sentences normalized to sentence length. A om is discarded if its similarity to any of the previously selected sentences is greater than a threshold identified by a greedy search on the training dataset. 6 We applied feature extraction of § 5.1 to compile the training and testing datasets. ROUGE is used for performance measure (Lin and Hovy, 2003; Lin, 2004), which evaluates summaries based on the maxium number of overlapping units between generated summary text and a set of human summaries. We use R-1 (recall against unigrams), R-2 (recall against bigrams), and R-SU4 (recall against skip-4 bigrams). Experiment 1: sumHLDA Parameter Analysis: In sumHLDA we introduce a prior different than the standard nested CRP (nCRP). Here, we illustrate that this prior is practical in learning hierarchical topics for summarization task. We use sentences from the human generated summaries during the discovery of hierarchical topics of sentences in document clust"
P10-1084,N09-1041,0,\N,Missing
P10-1084,P06-2020,0,\N,Missing
P10-1084,N03-1020,0,\N,Missing
P10-1084,P08-1036,0,\N,Missing
P11-1050,N04-1015,0,0.0207722,"ch has demonstrated the usefulness of sentence extraction for summarization based on lexical, semantic, and discourse constraints. Such models often rely on different approaches including: identifying important keywords (Nenkova et al., 2006); topic signatures based on user queries (Lin and Hovy, 2002; Conroy et al., 2006; Harabagiu et al., 2007); high frequency content word feature based learning (Nenkova and Vanderwende, 2005a; Nenkova and Vanderwende, 2005b), to name a few. Recent research focusing on the extraction of latent concepts from document clusters are close in spirit to our work (Barzilay and Lee, 2004; Daum´ eIII and Marcu, 2006; Eisenstein and Barzilay, 2008; Tang et al., 2009; Wang et al., 2009). Some of these work (Haghighi and Vanderwende, 2009; Celikyilmaz and Hakkani-Tur, 2010) focus on the discovery of hierarchical concepts from documents (from abstract to specific) using extensions of hierarchal topic models (Blei et al., 2004) and reflect this hierarchy on the sentences. Hierarchical concept learning models help to discover, for instance, that ”baseball” and ”football” are both contained in a general class ”sports”, so that the summaries reference terms related to more abstract co"
P11-1050,P99-1071,0,0.0931687,"eir correlations to extract topically coherent sentences. Prior research has demonstrated the usefulness of sentence extraction for generating summary text 491 taking advantage of surface level features such as word repetition, position in text, cue phrases, etc, (Radev, 2004; Nenkova and Vanderwende, 2005a; Wan and Yang, 2006; Nenkova et al., 2006). Because documents have pre-defined structures (e.g., sections, paragraphs, sentences) for different levels of concepts in a hierarchy, most recent summarization work has focused on structured probabilistic models to represent the corpus concepts (Barzilay et al., 1999; Daum´ e-III and Marcu, 2006; Eisenstein and Barzilay, 2008; Tang et al., 2009; Chen et al., 2000; Wang et al., 2009). In particular (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010) build hierarchical topic models to identify salient sentences that contain abstract concepts rather than specific concepts. Nonetheless, all these systems crucially rely on extracting various levels of generality from documents, focusing little on redundancy and coherence issues in model building. A model than can focus on both issues is deemed to be more beneficial for a summarization task. Topi"
P11-1050,P10-1084,1,0.861572,"hes including: identifying important keywords (Nenkova et al., 2006); topic signatures based on user queries (Lin and Hovy, 2002; Conroy et al., 2006; Harabagiu et al., 2007); high frequency content word feature based learning (Nenkova and Vanderwende, 2005a; Nenkova and Vanderwende, 2005b), to name a few. Recent research focusing on the extraction of latent concepts from document clusters are close in spirit to our work (Barzilay and Lee, 2004; Daum´ eIII and Marcu, 2006; Eisenstein and Barzilay, 2008; Tang et al., 2009; Wang et al., 2009). Some of these work (Haghighi and Vanderwende, 2009; Celikyilmaz and Hakkani-Tur, 2010) focus on the discovery of hierarchical concepts from documents (from abstract to specific) using extensions of hierarchal topic models (Blei et al., 2004) and reflect this hierarchy on the sentences. Hierarchical concept learning models help to discover, for instance, that ”baseball” and ”football” are both contained in a general class ”sports”, so that the summaries reference terms related to more abstract concepts like ”sports”. Although successful, the issue with concept learning methods for summarization is that the extracted sentences usually contain correlated concepts. We need a model"
P11-1050,P06-2020,0,0.053385,"ries discussed in §6. Our models achieve comparable qualitative results on summarization of multiple newswire documents. Human evaluations of generated summaries confirm that our model can generate non-redundant and topically coherent summaries. 2 Multi-Document Summarization Models Prior research has demonstrated the usefulness of sentence extraction for summarization based on lexical, semantic, and discourse constraints. Such models often rely on different approaches including: identifying important keywords (Nenkova et al., 2006); topic signatures based on user queries (Lin and Hovy, 2002; Conroy et al., 2006; Harabagiu et al., 2007); high frequency content word feature based learning (Nenkova and Vanderwende, 2005a; Nenkova and Vanderwende, 2005b), to name a few. Recent research focusing on the extraction of latent concepts from document clusters are close in spirit to our work (Barzilay and Lee, 2004; Daum´ eIII and Marcu, 2006; Eisenstein and Barzilay, 2008; Tang et al., 2009; Wang et al., 2009). Some of these work (Haghighi and Vanderwende, 2009; Celikyilmaz and Hakkani-Tur, 2010) focus on the discovery of hierarchical concepts from documents (from abstract to specific) using extensions of hie"
P11-1050,P06-1039,0,0.256303,"opically coherent sentences. Prior research has demonstrated the usefulness of sentence extraction for generating summary text 491 taking advantage of surface level features such as word repetition, position in text, cue phrases, etc, (Radev, 2004; Nenkova and Vanderwende, 2005a; Wan and Yang, 2006; Nenkova et al., 2006). Because documents have pre-defined structures (e.g., sections, paragraphs, sentences) for different levels of concepts in a hierarchy, most recent summarization work has focused on structured probabilistic models to represent the corpus concepts (Barzilay et al., 1999; Daum´ e-III and Marcu, 2006; Eisenstein and Barzilay, 2008; Tang et al., 2009; Chen et al., 2000; Wang et al., 2009). In particular (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010) build hierarchical topic models to identify salient sentences that contain abstract concepts rather than specific concepts. Nonetheless, all these systems crucially rely on extracting various levels of generality from documents, focusing little on redundancy and coherence issues in model building. A model than can focus on both issues is deemed to be more beneficial for a summarization task. Topical coherence in text involve"
P11-1050,D08-1035,0,0.0784198,"nces. Prior research has demonstrated the usefulness of sentence extraction for generating summary text 491 taking advantage of surface level features such as word repetition, position in text, cue phrases, etc, (Radev, 2004; Nenkova and Vanderwende, 2005a; Wan and Yang, 2006; Nenkova et al., 2006). Because documents have pre-defined structures (e.g., sections, paragraphs, sentences) for different levels of concepts in a hierarchy, most recent summarization work has focused on structured probabilistic models to represent the corpus concepts (Barzilay et al., 1999; Daum´ e-III and Marcu, 2006; Eisenstein and Barzilay, 2008; Tang et al., 2009; Chen et al., 2000; Wang et al., 2009). In particular (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010) build hierarchical topic models to identify salient sentences that contain abstract concepts rather than specific concepts. Nonetheless, all these systems crucially rely on extracting various levels of generality from documents, focusing little on redundancy and coherence issues in model building. A model than can focus on both issues is deemed to be more beneficial for a summarization task. Topical coherence in text involves identifying key concepts, the"
P11-1050,N09-1041,0,0.767879,"491 taking advantage of surface level features such as word repetition, position in text, cue phrases, etc, (Radev, 2004; Nenkova and Vanderwende, 2005a; Wan and Yang, 2006; Nenkova et al., 2006). Because documents have pre-defined structures (e.g., sections, paragraphs, sentences) for different levels of concepts in a hierarchy, most recent summarization work has focused on structured probabilistic models to represent the corpus concepts (Barzilay et al., 1999; Daum´ e-III and Marcu, 2006; Eisenstein and Barzilay, 2008; Tang et al., 2009; Chen et al., 2000; Wang et al., 2009). In particular (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010) build hierarchical topic models to identify salient sentences that contain abstract concepts rather than specific concepts. Nonetheless, all these systems crucially rely on extracting various levels of generality from documents, focusing little on redundancy and coherence issues in model building. A model than can focus on both issues is deemed to be more beneficial for a summarization task. Topical coherence in text involves identifying key concepts, the relationships between these concepts, and linking these relationships into a hierarchy. In this paper, w"
P11-1050,N06-2046,0,0.0200565,"r’s query addressing different levels of detail. Recent approaches to the summarization task has somewhat focused on the redundancy and coherence issues. In this paper, we introduce a series of new generative models for multiple-documents, based on a discovery of hierarchical topics and their correlations to extract topically coherent sentences. Prior research has demonstrated the usefulness of sentence extraction for generating summary text 491 taking advantage of surface level features such as word repetition, position in text, cue phrases, etc, (Radev, 2004; Nenkova and Vanderwende, 2005a; Wan and Yang, 2006; Nenkova et al., 2006). Because documents have pre-defined structures (e.g., sections, paragraphs, sentences) for different levels of concepts in a hierarchy, most recent summarization work has focused on structured probabilistic models to represent the corpus concepts (Barzilay et al., 1999; Daum´ e-III and Marcu, 2006; Eisenstein and Barzilay, 2008; Tang et al., 2009; Chen et al., 2000; Wang et al., 2009). In particular (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010) build hierarchical topic models to identify salient sentences that contain abstract concepts rather than s"
P11-1050,P09-2075,0,0.255258,"action for generating summary text 491 taking advantage of surface level features such as word repetition, position in text, cue phrases, etc, (Radev, 2004; Nenkova and Vanderwende, 2005a; Wan and Yang, 2006; Nenkova et al., 2006). Because documents have pre-defined structures (e.g., sections, paragraphs, sentences) for different levels of concepts in a hierarchy, most recent summarization work has focused on structured probabilistic models to represent the corpus concepts (Barzilay et al., 1999; Daum´ e-III and Marcu, 2006; Eisenstein and Barzilay, 2008; Tang et al., 2009; Chen et al., 2000; Wang et al., 2009). In particular (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010) build hierarchical topic models to identify salient sentences that contain abstract concepts rather than specific concepts. Nonetheless, all these systems crucially rely on extracting various levels of generality from documents, focusing little on redundancy and coherence issues in model building. A model than can focus on both issues is deemed to be more beneficial for a summarization task. Topical coherence in text involves identifying key concepts, the relationships between these concepts, and linking these r"
P11-1050,C00-1072,0,\N,Missing
P12-1035,W04-3003,0,0.0551261,"nent is a challenging task not only because there are no a priori constraints on what a user might say, but also systems must generalize from a tractably small amount of labeled training data. In this paper, we argue that each of these components are interdependent and should be modeled simultaneously. We build a joint understanding framework and introduce a multi-layer context model for semantic representation of utterances of multiple domains. Although different strategies can be applied, typically a cascaded approach is used where each semantic component is modeled separately/sequentially (Begeja et al., 2004), focusing less on interrelated aspects, i.e., dialog’s domain, user’s intentions, and semantic tags that can be shared across domains. Recent work on SLU (Jeong and Lee, 2008; Wang, 2010) presents joint modeling of two components, i.e., the domain and slot or dialog act and slot components together. Furthermore, most of these systems rely on labeled training utterances, focusing little on issues such as information sharing between the discourse and word level components across different domains, or variations in use of language. To deal with de330 Proceedings of the 50th Annual Meeting of the"
P12-1035,P06-1039,0,0.0575331,"tion of seed labeled data and information from web queries as informative prior to design a novel utterance understanding model in §3 & §4, (iii) comparison of our results to supervised sequential and joint learning methods on NL utterances in §5. We conclude that our generative model achieves noticeable improvement compared to discriminative models when labeled data is scarce. 2 Background Language understanding has been well studied in the context of question/answering (Harabagiu and Hickl, 2006; Liang et al., 2011), entailment (Sammons et al., 2010), summarization (Hovy et al., 2005; Daum´ e-III and Marcu, 2006), spoken language understanding (Tur and Mori, 2011; Dinarelli et al., 2009), query understanding (Popescu et al., 2010; Li, 2010; Reisinger and Pasca, 2011), etc. However data sources in VPA systems pose new challenges, such as variability and ambiguities in natural language, or short utterances that rarely contain contextual information, etc. Thus, SLU plays an important role in allowing any sophisticated spoken dialog system (e.g., DARPA Calo (Berry et al., 2011), Siri, etc.) to take the correct machine actions. A common approach to building SLU framework 331 is to model its semantic compon"
P12-1035,E09-1024,0,0.0199052,"rior to design a novel utterance understanding model in §3 & §4, (iii) comparison of our results to supervised sequential and joint learning methods on NL utterances in §5. We conclude that our generative model achieves noticeable improvement compared to discriminative models when labeled data is scarce. 2 Background Language understanding has been well studied in the context of question/answering (Harabagiu and Hickl, 2006; Liang et al., 2011), entailment (Sammons et al., 2010), summarization (Hovy et al., 2005; Daum´ e-III and Marcu, 2006), spoken language understanding (Tur and Mori, 2011; Dinarelli et al., 2009), query understanding (Popescu et al., 2010; Li, 2010; Reisinger and Pasca, 2011), etc. However data sources in VPA systems pose new challenges, such as variability and ambiguities in natural language, or short utterances that rarely contain contextual information, etc. Thus, SLU plays an important role in allowing any sophisticated spoken dialog system (e.g., DARPA Calo (Berry et al., 2011), Siri, etc.) to take the correct machine actions. A common approach to building SLU framework 331 is to model its semantic components separately, assuming that the context (domain) is given a priori. Earli"
P12-1035,P06-1114,0,0.0219595,"Bayesian framework for semantic parsing of natural language (NL) utterances in a unifying framework in §4, (ii) representation of seed labeled data and information from web queries as informative prior to design a novel utterance understanding model in §3 & §4, (iii) comparison of our results to supervised sequential and joint learning methods on NL utterances in §5. We conclude that our generative model achieves noticeable improvement compared to discriminative models when labeled data is scarce. 2 Background Language understanding has been well studied in the context of question/answering (Harabagiu and Hickl, 2006; Liang et al., 2011), entailment (Sammons et al., 2010), summarization (Hovy et al., 2005; Daum´ e-III and Marcu, 2006), spoken language understanding (Tur and Mori, 2011; Dinarelli et al., 2009), query understanding (Popescu et al., 2010; Li, 2010; Reisinger and Pasca, 2011), etc. However data sources in VPA systems pose new challenges, such as variability and ambiguities in natural language, or short utterances that rarely contain contextual information, etc. Thus, SLU plays an important role in allowing any sophisticated spoken dialog system (e.g., DARPA Calo (Berry et al., 2011), Siri, et"
P12-1035,P10-1136,0,0.176359,"i) comparison of our results to supervised sequential and joint learning methods on NL utterances in §5. We conclude that our generative model achieves noticeable improvement compared to discriminative models when labeled data is scarce. 2 Background Language understanding has been well studied in the context of question/answering (Harabagiu and Hickl, 2006; Liang et al., 2011), entailment (Sammons et al., 2010), summarization (Hovy et al., 2005; Daum´ e-III and Marcu, 2006), spoken language understanding (Tur and Mori, 2011; Dinarelli et al., 2009), query understanding (Popescu et al., 2010; Li, 2010; Reisinger and Pasca, 2011), etc. However data sources in VPA systems pose new challenges, such as variability and ambiguities in natural language, or short utterances that rarely contain contextual information, etc. Thus, SLU plays an important role in allowing any sophisticated spoken dialog system (e.g., DARPA Calo (Berry et al., 2011), Siri, etc.) to take the correct machine actions. A common approach to building SLU framework 331 is to model its semantic components separately, assuming that the context (domain) is given a priori. Earlier work takes dialog act identification as a classifi"
P12-1035,P11-1060,0,0.0471928,"antic parsing of natural language (NL) utterances in a unifying framework in §4, (ii) representation of seed labeled data and information from web queries as informative prior to design a novel utterance understanding model in §3 & §4, (iii) comparison of our results to supervised sequential and joint learning methods on NL utterances in §5. We conclude that our generative model achieves noticeable improvement compared to discriminative models when labeled data is scarce. 2 Background Language understanding has been well studied in the context of question/answering (Harabagiu and Hickl, 2006; Liang et al., 2011), entailment (Sammons et al., 2010), summarization (Hovy et al., 2005; Daum´ e-III and Marcu, 2006), spoken language understanding (Tur and Mori, 2011; Dinarelli et al., 2009), query understanding (Popescu et al., 2010; Li, 2010; Reisinger and Pasca, 2011), etc. However data sources in VPA systems pose new challenges, such as variability and ambiguities in natural language, or short utterances that rarely contain contextual information, etc. Thus, SLU plays an important role in allowing any sophisticated spoken dialog system (e.g., DARPA Calo (Berry et al., 2011), Siri, etc.) to take the corre"
P12-1035,W10-2607,0,0.0288136,"a sources in VPA systems pose new challenges, such as variability and ambiguities in natural language, or short utterances that rarely contain contextual information, etc. Thus, SLU plays an important role in allowing any sophisticated spoken dialog system (e.g., DARPA Calo (Berry et al., 2011), Siri, etc.) to take the correct machine actions. A common approach to building SLU framework 331 is to model its semantic components separately, assuming that the context (domain) is given a priori. Earlier work takes dialog act identification as a classification task to capture the user’s intentions (Margolis et al., 2010) and slot filling as a sequence learning task specific to a given domain class (Wang et al., 2009; Li, 2010). Since these tasks are considered as a pipeline, the errors of each component are transfered to the next, causing robustness issues. Ideally, these components should be modeled simultaneously considering the dependencies between them. For example, in a local domain application, users may require information about a sub-domain (movies, hotels, etc.), and for each sub-domain, they may want to take different actions (find a movie, call a restaurant or book a hotel) using domain specific at"
P12-1035,D09-1026,0,0.01027,"owledge. ‡ Here HMM assumption over utterance words is used. In hierarchical topic models (Blei et al., 2003; Mimno et al., 2007), etc., topics are represented as distributions over words, and each document expresses an admixture of these topics, both of which have symmetric Dirichlet (Dir) prior distributions. Symmetric Dirichlet distributions are often used, since there is typically no prior knowledge favoring one component over another. In the topic model literature, such constraints are sometimes used to deterministically allocate topic assignments to known labels (Labeled Topic Modeling (Ramage et al., 2009)) or in terms of pre-learnt topics encoded as prior knowledge on topic distributions in documents (Reisinger and Pas¸ca, 2009). Similar to previous work, we define a latent topic per each known semantic component label, e.g., five domain topics for five defined domains. Different from earlier work though, we also inject knowledge that we extract from several resources including entity lists from web search query click logs as well as seed labeled training utterances as prior information. We constrain the generation of the semantic components of our model by encoding prior knowledge in terms of"
P12-1035,P09-1070,0,0.0485326,"Missing"
P12-1035,P11-1120,0,0.0198551,"son of our results to supervised sequential and joint learning methods on NL utterances in §5. We conclude that our generative model achieves noticeable improvement compared to discriminative models when labeled data is scarce. 2 Background Language understanding has been well studied in the context of question/answering (Harabagiu and Hickl, 2006; Liang et al., 2011), entailment (Sammons et al., 2010), summarization (Hovy et al., 2005; Daum´ e-III and Marcu, 2006), spoken language understanding (Tur and Mori, 2011; Dinarelli et al., 2009), query understanding (Popescu et al., 2010; Li, 2010; Reisinger and Pasca, 2011), etc. However data sources in VPA systems pose new challenges, such as variability and ambiguities in natural language, or short utterances that rarely contain contextual information, etc. Thus, SLU plays an important role in allowing any sophisticated spoken dialog system (e.g., DARPA Calo (Berry et al., 2011), Siri, etc.) to take the correct machine actions. A common approach to building SLU framework 331 is to model its semantic components separately, assuming that the context (domain) is given a priori. Earlier work takes dialog act identification as a classification task to capture the u"
P12-1035,P10-1122,0,0.0125332,"(NL) utterances in a unifying framework in §4, (ii) representation of seed labeled data and information from web queries as informative prior to design a novel utterance understanding model in §3 & §4, (iii) comparison of our results to supervised sequential and joint learning methods on NL utterances in §5. We conclude that our generative model achieves noticeable improvement compared to discriminative models when labeled data is scarce. 2 Background Language understanding has been well studied in the context of question/answering (Harabagiu and Hickl, 2006; Liang et al., 2011), entailment (Sammons et al., 2010), summarization (Hovy et al., 2005; Daum´ e-III and Marcu, 2006), spoken language understanding (Tur and Mori, 2011; Dinarelli et al., 2009), query understanding (Popescu et al., 2010; Li, 2010; Reisinger and Pasca, 2011), etc. However data sources in VPA systems pose new challenges, such as variability and ambiguities in natural language, or short utterances that rarely contain contextual information, etc. Thus, SLU plays an important role in allowing any sophisticated spoken dialog system (e.g., DARPA Calo (Berry et al., 2011), Siri, etc.) to take the correct machine actions. A common approa"
P12-1035,P11-1036,0,0.0317206,"associated with d = 1..KD multinod . Each domain d, mial domain-topic distributions θD is represented as a distribution over a = 1, .., KA da (θ d → θ da ). In our MCM model, we dialog acts θA D A assume that each utterance is represented as a hidden Markov model with KS slot states. Each state generates n-grams according to a multinomial n-gram distribution. Once domain Du and act Aud topics are sampled for u, a slot state topic Sujd is drawn to generate each segment wuj of u by considering the word-tag sequence frequencies based on a simple HMM assumption, similar to the content models of (Sauper et al., 2011). Initial and transition probability distributions over the HMM states are sampled from Dirichlet distribution over slots θSds . Each slot state s generates words according to multinomial word distribution φsS . We also keep track of the frequency of vocabulary terms wj ’s in a V ×KD matrix MD . Every time a wj is sampled for a domain d, we increment its count, a degree of domain bearing 333 1: 2: 3: 4: 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: for each domain d ← 1, ..., KD d ? † draw domain dist. θD ∼ Dir(αD ) , for each dialog-act a ← 1, ..., KA da ? draw dialog act dist. θA ∼ Dir(αA ), fo"
P13-1090,D07-1109,0,0.0384019,"A common property of several context-based word clustering techniques, e.g., Brown clustering (Brown et al., 1992), Clustering by Committee (Pantel, 2003), etc., is that they mainly cluster based on local context such as nearby words. Standard topic models, such as Latent Dirichlet Allocation (LDA) (Blei et al., 2003), use a bag-of-words approach, which disregards word order and clusters words together that appear in a similar global context. Such models have been effective in discovering lexicons in many NLP tasks, e.g., named-entity recognition (Guo et al., 2009), word-sense disambiguation (Boyd-Graber et al., 2007; Li et al., 2010), syntactic/semantic parsing (Griffiths et al., 2005; Singh et al., 2010), speaker identification (Nyugen et al., 2012), etc. Recent topic models consider word sequence information in documents (Griffiths et al., 2005; Moon et al., 2010). The Hidden Topic Markov Model (HTMM) by (Gruber et al., 2005), for instance, models sentences in documents as Markov chains, assuming all words in a sentence have the same topic. While MTR has a similar Markovian property, we encode features on words to allow each word in an utterance to sample from any of the given semantic tags, as in ”wha"
P13-1090,J92-4003,0,0.687657,"es of sampling words from the correct semantic tag. MTR constrains the generation of a tag si given the previous tag si−1 and the current wi based on cj,i by using a vocabulary specific Beta prior, ψv ∼Beta(ηv ) 1 , on each word in vocabulary wv=1,..V . We inject the prior information on semantic tags to define values of the base measure ηv using external knowledge from two sources: (a) Entity Priors (ηS ): Prior probability on named-entities and descriptive tags denoted as (II) Semantic Clustering. A common property of several context-based word clustering techniques, e.g., Brown clustering (Brown et al., 1992), Clustering by Committee (Pantel, 2003), etc., is that they mainly cluster based on local context such as nearby words. Standard topic models, such as Latent Dirichlet Allocation (LDA) (Blei et al., 2003), use a bag-of-words approach, which disregards word order and clusters words together that appear in a similar global context. Such models have been effective in discovering lexicons in many NLP tasks, e.g., named-entity recognition (Guo et al., 2009), word-sense disambiguation (Boyd-Graber et al., 2007; Li et al., 2010), syntactic/semantic parsing (Griffiths et al., 2005; Singh et al., 2010"
P13-1090,W10-2608,0,0.175697,"ally, a semantic tagging model require large amount of domain specific data to achieve good 914 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 914–923, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics cally labeled target data, it re-trains a new CRFmodel. Although our iterative SSL learning model can deal with the training and test data mismatch, it neglects the performance effects caused by adapting the source domain to the target domain. In fact, most SSL methods used for adaptation, e.g., (Zhu, 2005), (Daum´ e-III, 2010), (Subramanya et al., 2010), etc., do not emphasize this issue. With this in mind, we introduce a new iterative training algorithm, Retrospective Learning, as our second contribution. While retrospective learning iteratively trains CRF models with the automatically annotated target data (explained above), it keeps track of the errors of the previous iterations so as to carry the properties of both the source and target domains. In short, through a series of experiments we show how MTR clustering provides additional information to SSL on the target domain utterances, and greatly impacts semanti"
P13-1090,N09-1032,0,0.0240209,"ive tags denoted as (II) Semantic Clustering. A common property of several context-based word clustering techniques, e.g., Brown clustering (Brown et al., 1992), Clustering by Committee (Pantel, 2003), etc., is that they mainly cluster based on local context such as nearby words. Standard topic models, such as Latent Dirichlet Allocation (LDA) (Blei et al., 2003), use a bag-of-words approach, which disregards word order and clusters words together that appear in a similar global context. Such models have been effective in discovering lexicons in many NLP tasks, e.g., named-entity recognition (Guo et al., 2009), word-sense disambiguation (Boyd-Graber et al., 2007; Li et al., 2010), syntactic/semantic parsing (Griffiths et al., 2005; Singh et al., 2010), speaker identification (Nyugen et al., 2012), etc. Recent topic models consider word sequence information in documents (Griffiths et al., 2005; Moon et al., 2010). The Hidden Topic Markov Model (HTMM) by (Gruber et al., 2005), for instance, models sentences in documents as Markov chains, assuming all words in a sentence have the same topic. While MTR has a similar Markovian property, we encode features on words to allow each word in an utterance to s"
P13-1090,P06-1063,0,0.0201079,"Missing"
P13-1090,P10-1116,0,0.0240466,"al context-based word clustering techniques, e.g., Brown clustering (Brown et al., 1992), Clustering by Committee (Pantel, 2003), etc., is that they mainly cluster based on local context such as nearby words. Standard topic models, such as Latent Dirichlet Allocation (LDA) (Blei et al., 2003), use a bag-of-words approach, which disregards word order and clusters words together that appear in a similar global context. Such models have been effective in discovering lexicons in many NLP tasks, e.g., named-entity recognition (Guo et al., 2009), word-sense disambiguation (Boyd-Graber et al., 2007; Li et al., 2010), syntactic/semantic parsing (Griffiths et al., 2005; Singh et al., 2010), speaker identification (Nyugen et al., 2012), etc. Recent topic models consider word sequence information in documents (Griffiths et al., 2005; Moon et al., 2010). The Hidden Topic Markov Model (HTMM) by (Gruber et al., 2005), for instance, models sentences in documents as Markov chains, assuming all words in a sentence have the same topic. While MTR has a similar Markovian property, we encode features on words to allow each word in an utterance to sample from any of the given semantic tags, as in ”what are [scary]genre"
P13-1090,P10-1136,0,0.0288695,"[Named Entities] director: James Cameron, Woody Allen,... actor: Ryan Gosling, Woody Allen,... title: Manhattan, Midnight in Paris,... [Descriptive Tags] restriction: similar, suitable, free,rate,... description: oscar winning, new release, gardening,... genre: spooky, comedies, feel good, romance,... Table 1: Samples of semantically tagged utterances from movie domain, named-entities and descriptive tags. ing the need for significant manual labor (Tur and DeMori, 2011). Recent work on similar tasks overcome these challenges using SSL methods as follows: • (Wang et al., 2009; Li et al., 2009; Li, 2010; Liu et al., 2011) investigate web query tagging using semi-supervised sequence models. They extract semantic lexicons from unlabeled web queries, to use as features. Our work differs from these, in that, rather than just detecting named-entities, our utterances include descriptive tags (see Table 1). • Typically the source domain has different distribution than the target domain, due to topic shifts in time, newly introduced features (e.g., until recently online articles did not include facebook ”like” feature.), etc. Adapting the source domain using unlabeled data is the key to achieving go"
P13-1090,J93-2004,0,0.0445574,"function to have a dependency on the prior model predictions. Thus, R-SSL encodes the history of the prior pre919 and contains a test-set vocabulary that is twice as large as the one in the development set. As for unlabeled data we crawled the web and collected around 100,000 questions that are similar in style and length to the ones in QuestionBank, e.g. ”wh” questions. There are 36 different tag sets in the Penn dataset which includes tag labels for verbs, nouns, adjectives, adverbs, modal, determiners, prepositions, etc. More information about the Penn Tree-bank tag set can be found here (Marcus et al., 1993). interact with the media system as if they were talking to a person. Our data from target domain is internally collected from real-use scenarios of our spoken dialog system. The transcribed text forms of these utterances are obtained from speech recognition engine. Although the crowd-sourced data is similar to target domain, in terms of pre-defined user intentions, the target domain contains more descriptive vocabulary, which is almost twice as large as the source domain. This causes data-mismatch issues and hence provides a perfect test-bed for a domain adaptation task. In total, our corpus"
P13-1090,D10-1020,0,0.0257542,"h as Latent Dirichlet Allocation (LDA) (Blei et al., 2003), use a bag-of-words approach, which disregards word order and clusters words together that appear in a similar global context. Such models have been effective in discovering lexicons in many NLP tasks, e.g., named-entity recognition (Guo et al., 2009), word-sense disambiguation (Boyd-Graber et al., 2007; Li et al., 2010), syntactic/semantic parsing (Griffiths et al., 2005; Singh et al., 2010), speaker identification (Nyugen et al., 2012), etc. Recent topic models consider word sequence information in documents (Griffiths et al., 2005; Moon et al., 2010). The Hidden Topic Markov Model (HTMM) by (Gruber et al., 2005), for instance, models sentences in documents as Markov chains, assuming all words in a sentence have the same topic. While MTR has a similar Markovian property, we encode features on words to allow each word in an utterance to sample from any of the given semantic tags, as in ”what are [scary]genre movies by [Hitchcock]director ?”. In LDA, common words tend to dominate all topics causing related words to end up in different topics. In (Petterson et al., 2010), the vectorbased features of words are used as prior information in LDA"
P13-1090,P12-1009,0,0.0263526,"Pantel, 2003), etc., is that they mainly cluster based on local context such as nearby words. Standard topic models, such as Latent Dirichlet Allocation (LDA) (Blei et al., 2003), use a bag-of-words approach, which disregards word order and clusters words together that appear in a similar global context. Such models have been effective in discovering lexicons in many NLP tasks, e.g., named-entity recognition (Guo et al., 2009), word-sense disambiguation (Boyd-Graber et al., 2007; Li et al., 2010), syntactic/semantic parsing (Griffiths et al., 2005; Singh et al., 2010), speaker identification (Nyugen et al., 2012), etc. Recent topic models consider word sequence information in documents (Griffiths et al., 2005; Moon et al., 2010). The Hidden Topic Markov Model (HTMM) by (Gruber et al., 2005), for instance, models sentences in documents as Markov chains, assuming all words in a sentence have the same topic. While MTR has a similar Markovian property, we encode features on words to allow each word in an utterance to sample from any of the given semantic tags, as in ”what are [scary]genre movies by [Hitchcock]director ?”. In LDA, common words tend to dominate all topics causing related words to end up in"
P13-1090,D11-1130,0,0.0149871,"rent distribution than the target domain, due to topic shifts in time, newly introduced features (e.g., until recently online articles did not include facebook ”like” feature.), etc. Adapting the source domain using unlabeled data is the key to achieving good performance across domains. Recent adaptation methods for SSL use: expectation minimization (Daum´ e-III, 2010) graph-based learning (Chapelle et al., 2006; Zhu, 2005), etc. In (Subramanya et al., 2010) an efficient iterative SSL method is described for syntactic tagging, using graph-based learning to smooth POS tag posteriors. However, (Reisinger and Mooney, 2011) argues that vector space models, such as graph-learning, may fail to capture the richness of word meaning, as similarity is not a globally consistent metric. Rather than graph-learning, we present a new SSL using a probabilistic model, MTR, to cluster words based on co-occurrence statistics. • Most iterative SSL methods, do not keep track of the errors made, nor consider the divergence from the original model. (Lavoie et al., 2011) argues that iterative learning models should mitigate new errors made by the model at each iteration by Related Work and Motivation (I) Semi-Supervised Tagging. Su"
P13-1090,N10-1009,0,0.0130897,"rown et al., 1992), Clustering by Committee (Pantel, 2003), etc., is that they mainly cluster based on local context such as nearby words. Standard topic models, such as Latent Dirichlet Allocation (LDA) (Blei et al., 2003), use a bag-of-words approach, which disregards word order and clusters words together that appear in a similar global context. Such models have been effective in discovering lexicons in many NLP tasks, e.g., named-entity recognition (Guo et al., 2009), word-sense disambiguation (Boyd-Graber et al., 2007; Li et al., 2010), syntactic/semantic parsing (Griffiths et al., 2005; Singh et al., 2010), speaker identification (Nyugen et al., 2012), etc. Recent topic models consider word sequence information in documents (Griffiths et al., 2005; Moon et al., 2010). The Hidden Topic Markov Model (HTMM) by (Gruber et al., 2005), for instance, models sentences in documents as Markov chains, assuming all words in a sentence have the same topic. While MTR has a similar Markovian property, we encode features on words to allow each word in an utterance to sample from any of the given semantic tags, as in ”what are [scary]genre movies by [Hitchcock]director ?”. In LDA, common words tend to dominate"
P13-1090,D10-1017,0,0.216536,"c tagging model require large amount of domain specific data to achieve good 914 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 914–923, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics cally labeled target data, it re-trains a new CRFmodel. Although our iterative SSL learning model can deal with the training and test data mismatch, it neglects the performance effects caused by adapting the source domain to the target domain. In fact, most SSL methods used for adaptation, e.g., (Zhu, 2005), (Daum´ e-III, 2010), (Subramanya et al., 2010), etc., do not emphasize this issue. With this in mind, we introduce a new iterative training algorithm, Retrospective Learning, as our second contribution. While retrospective learning iteratively trains CRF models with the automatically annotated target data (explained above), it keeps track of the errors of the previous iterations so as to carry the properties of both the source and target domains. In short, through a series of experiments we show how MTR clustering provides additional information to SSL on the target domain utterances, and greatly impacts semantic tagging performance. Spec"
P17-5004,W13-4073,0,0.0263856,"ponse Natural Language Generation (NLG) Where are you located? Dialogue Management (DM) • Dialogue State Tracking (DST) • Dialogue Policy Optimization System Action / Policy request_location Backend Knowledge Providers Figure 1: Pipeline framework of spoken dialog system. W S I find action ↓ ↓ O B-genre find movie movies ↓ O this ↓ B-date weekend ↓ I-date forcement learning setting. Dialogue Management The state-of-the-art dialog managers focus on monitoring the dialog progress by neural dialog state tracking models. Among the initial models are the RNN based dialog state tracking approaches (Henderson et al., 2013) that has shown to outperform Bayesian networks (Thomson and Young, 2010). More recent work on Neural Dialog Managers that provide conjoint representations between the utterances, slot-value pairs as well as knowledge graph representations (Wen et al., 2016; Mrkˇsi´c et al., 2016) demonstrate that using neural dialog models can overcome current obstacles of deploying dialogue systems in larger dialog domains. Figure 2: An example utterance with annotations of semantic slots in IOB format (S) and intent (I), B-date and I-date denote the date slot. 4 Deep Learning Based Dialogue System With the"
P17-5004,I17-1074,1,0.888554,"chitecture can be merged with CRFs (Xu and Sarikaya, 2013). Yao et al. (2013) and Mesnil et al. (2015) later employed RNNs for sequence labeling in order to perform slot filling. Such architectures have later been extended to jointly model intent detection and slot filling in multiple domains (Hakkani-T¨ur et al., 2016; Jaech et al., 2016). End-to-end memory networks have been shown to provide a good mechanism for integrating longer term knowledge context and shorter term dialogue context into these models (Chen et al., 2016b,c). In addition, the importance of the LU module is investigated in Li et al. (2017a), where different types of errors from LU may degrade the whole system performance in an reinNatural Language Generation The RNNbased models have been applied to language generation for both chit-chat and task-orientated dialogue systems (Vinyals and Le, 2015; Wen et al., 2015b). The RNN-based NLG can learn from unaligned data by jointly optimizing sentence planning and surface realization, and language variation can be easily achieved by sampling from output candidates (Wen et al., 2015a). Moreover, Wen et al. (2015b) improved the prior work by adding a gating mechanism for controlling the"
P17-5004,P17-1163,0,0.078703,"Missing"
P17-5004,W15-4639,0,0.0489578,"Missing"
P17-5004,J80-3005,0,0.746031,"Missing"
P17-5004,D15-1199,0,0.0125654,"ultiple domains (Hakkani-T¨ur et al., 2016; Jaech et al., 2016). End-to-end memory networks have been shown to provide a good mechanism for integrating longer term knowledge context and shorter term dialogue context into these models (Chen et al., 2016b,c). In addition, the importance of the LU module is investigated in Li et al. (2017a), where different types of errors from LU may degrade the whole system performance in an reinNatural Language Generation The RNNbased models have been applied to language generation for both chit-chat and task-orientated dialogue systems (Vinyals and Le, 2015; Wen et al., 2015b). The RNN-based NLG can learn from unaligned data by jointly optimizing sentence planning and surface realization, and language variation can be easily achieved by sampling from output candidates (Wen et al., 2015a). Moreover, Wen et al. (2015b) improved the prior work by adding a gating mechanism for controlling the dialogue act during generation in order to avoid semantics repetition, showing promising results. 5 Recent Trends and Challenges on Learning Dialogues This part will focus on discussing the recent trends and current challenges on dialogue system technology. 10 End-to-End Learnin"
P17-5004,W16-3601,0,0.0243641,"tion, showing promising results. 5 Recent Trends and Challenges on Learning Dialogues This part will focus on discussing the recent trends and current challenges on dialogue system technology. 10 End-to-End Learning for Dialogue System With the power of neural networks, there are more and more attempts for learning dialogue systems in an end-to-end fashion. Different learning frameworks are applied, including supervised learning and reinforcement learning. This part will discuss the work about end-to-end learning for dialogues (Dhingra et al., 2016; Wen et al., 2016; Williams and Zweig, 2016; Zhao and Eskenazi, 2016; Li et al., 2017b). Recent advance of deep learning has inspired many applications of neural models to dialogue systems. Wen et al. (2016) and Bordes and Weston (2016) introduced a network-based end-to-end trainable task-oriented dialogue system, which treated dialogue system learning as the problem of learning a mapping from dialogue histories to system responses, and applied an encoder-decoder model to train the whole system. However, the system is trained in a supervised fashion, thus requires a lot of training data, and may not be able to explore the unknown space that does not exist in t"
P19-1547,W06-1615,0,0.35447,"Missing"
P19-1547,Q18-1039,0,0.0519878,"Missing"
P19-1547,P15-1047,0,0.0314803,"13) popular. In particular, work on zeroshot utterance intent detection has relied on varied resources such as click logs (Dauphin et al., 2013) and manually defined domain ontologies (Kumar et al., 2017), as well as models such as deep structured semantic models (Chen et al., 2016) and capsule networks (Xia et al., 2018). Zero-shot semantic parsing is addressed in Krishnamurthy et al. (2017) and Herzig and Berant (2018) and specifically for SLU utilizing external resources such as label ontologies in Ferreira et al. (2015a,b) and handwritten intent attributes in Yazdani and Henderson (2015); Chen et al. (2015). Our work is closest in spirit to Bapna et al. (2017) and Lee and Jha (2018), who employ textual slot descriptions to scale to unseen intents/slots. Since slots tend to take semantically similar values across utterances, we augment our model with example values, which are easier for developers to define than manual alignments across schemas (Li et al., 2011). Problem Statement We frame our conditional sequence tagging task as follows: given a user utterance with T tokens and a slot type, we predict inside-outside-begin (IOB) tags {y1 , y2 . . . yT } using 3-way classification per token, based"
P19-1547,N18-3018,0,0.0159203,"the 57th Annual Meeting of the Association for Computational Linguistics, pages 5484–5490 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics Figure 2: Illustration of the overall model with all inputs and outputs shown. 2 3 Related Work Settings with resource-poor domains are typically addressed by adapting from resource-rich domains (Blitzer et al., 2006; Pan et al., 2010; Chen et al., 2018; Guo et al., 2018; Shah et al., 2018). To this end approaches such as domain adversarial learning (Liu and Lane, 2017) and multi-task learning (Jaech et al., 2016; Goyal et al., 2018; Siddhant et al., 2018) have been adapted to SLU and related tasks (Henderson et al., 2014). Work targeting domain adaptation specifically for this area includes, modeling slots as hierarchical concepts (Zhu and Yu, 2018) and using ensembles of models trained on data-rich domains (Gaˇsi´c et al., 2015; Kim et al., 2017; Jha et al., 2018). The availability of task descriptions has made zero-shot learning (Norouzi et al., 2013; Socher et al., 2013) popular. In particular, work on zeroshot utterance intent detection has relied on varied resources such as click logs (Dauphin et al., 2013) and man"
P19-1547,W18-5036,0,0.116804,"Missing"
P19-1547,D18-1498,1,0.909248,"Missing"
P19-1547,D18-1190,0,0.026869,"dels trained on data-rich domains (Gaˇsi´c et al., 2015; Kim et al., 2017; Jha et al., 2018). The availability of task descriptions has made zero-shot learning (Norouzi et al., 2013; Socher et al., 2013) popular. In particular, work on zeroshot utterance intent detection has relied on varied resources such as click logs (Dauphin et al., 2013) and manually defined domain ontologies (Kumar et al., 2017), as well as models such as deep structured semantic models (Chen et al., 2016) and capsule networks (Xia et al., 2018). Zero-shot semantic parsing is addressed in Krishnamurthy et al. (2017) and Herzig and Berant (2018) and specifically for SLU utilizing external resources such as label ontologies in Ferreira et al. (2015a,b) and handwritten intent attributes in Yazdani and Henderson (2015); Chen et al. (2015). Our work is closest in spirit to Bapna et al. (2017) and Lee and Jha (2018), who employ textual slot descriptions to scale to unseen intents/slots. Since slots tend to take semantically similar values across utterances, we augment our model with example values, which are easier for developers to define than manual alignments across schemas (Li et al., 2011). Problem Statement We frame our conditional"
P19-1547,N18-3019,0,0.0596957,"adapting from resource-rich domains (Blitzer et al., 2006; Pan et al., 2010; Chen et al., 2018; Guo et al., 2018; Shah et al., 2018). To this end approaches such as domain adversarial learning (Liu and Lane, 2017) and multi-task learning (Jaech et al., 2016; Goyal et al., 2018; Siddhant et al., 2018) have been adapted to SLU and related tasks (Henderson et al., 2014). Work targeting domain adaptation specifically for this area includes, modeling slots as hierarchical concepts (Zhu and Yu, 2018) and using ensembles of models trained on data-rich domains (Gaˇsi´c et al., 2015; Kim et al., 2017; Jha et al., 2018). The availability of task descriptions has made zero-shot learning (Norouzi et al., 2013; Socher et al., 2013) popular. In particular, work on zeroshot utterance intent detection has relied on varied resources such as click logs (Dauphin et al., 2013) and manually defined domain ontologies (Kumar et al., 2017), as well as models such as deep structured semantic models (Chen et al., 2016) and capsule networks (Xia et al., 2018). Zero-shot semantic parsing is addressed in Krishnamurthy et al. (2017) and Herzig and Berant (2018) and specifically for SLU utilizing external resources such as label"
P19-1547,D14-1181,0,0.00308553,"(Luong et al., 2015). exk = Nk 1 X eki , 1≤k ≤K Nk (3) i=1 αix = sof tmax({hi Wa exk ∀k}), 1≤i≤T eai = K X αixk × exk (4) (5) k=1 Tagger: We feed the concatenated utterance, slot description and example encodings to a den dimensional bidirectional LSTM. The output hidden states X = {xi ∈ Rden , 1≤i≤T } are used for a 3-way IOB tag classification per token. X = BiLST M ({hi ⊕ ds ⊕ eai , 1≤i≤T }) yi = sof tmax(Wt xi + bt ), 1≤i≤T Parameters: We use fixed dw =128-dim pretrained word embeddings2 for all tokens. We also train per-character embeddings, fed to a 2-layer convolutional neural network (Kim, 2014) to get a dc =32-dim token embedding. For all inputs, the dwc =160-dim final embedding is the concatenation of the word and char-CNN embeddings. The RNN encoders have hidden state size den =128. All trainable weights are shared across intents and slots. The model relies largely on fixed word embeddings to generalize to new intents/slots. Datasets and Experiments In this section we describe the datasets used for evaluation, baselines compared against, and more details on the experimental setup. Datasets: In order to evaluate cross-domain transfer learning ability and robustness to misaligned sc"
P19-1547,P17-1060,0,0.0431657,"ally addressed by adapting from resource-rich domains (Blitzer et al., 2006; Pan et al., 2010; Chen et al., 2018; Guo et al., 2018; Shah et al., 2018). To this end approaches such as domain adversarial learning (Liu and Lane, 2017) and multi-task learning (Jaech et al., 2016; Goyal et al., 2018; Siddhant et al., 2018) have been adapted to SLU and related tasks (Henderson et al., 2014). Work targeting domain adaptation specifically for this area includes, modeling slots as hierarchical concepts (Zhu and Yu, 2018) and using ensembles of models trained on data-rich domains (Gaˇsi´c et al., 2015; Kim et al., 2017; Jha et al., 2018). The availability of task descriptions has made zero-shot learning (Norouzi et al., 2013; Socher et al., 2013) popular. In particular, work on zeroshot utterance intent detection has relied on varied resources such as click logs (Dauphin et al., 2013) and manually defined domain ontologies (Kumar et al., 2017), as well as models such as deep structured semantic models (Chen et al., 2016) and capsule networks (Xia et al., 2018). Zero-shot semantic parsing is addressed in Krishnamurthy et al. (2017) and Herzig and Berant (2018) and specifically for SLU utilizing external reso"
P19-1547,W18-5045,1,0.899604,"Missing"
P19-1547,D17-1160,0,0.0183926,"2018) and using ensembles of models trained on data-rich domains (Gaˇsi´c et al., 2015; Kim et al., 2017; Jha et al., 2018). The availability of task descriptions has made zero-shot learning (Norouzi et al., 2013; Socher et al., 2013) popular. In particular, work on zeroshot utterance intent detection has relied on varied resources such as click logs (Dauphin et al., 2013) and manually defined domain ontologies (Kumar et al., 2017), as well as models such as deep structured semantic models (Chen et al., 2016) and capsule networks (Xia et al., 2018). Zero-shot semantic parsing is addressed in Krishnamurthy et al. (2017) and Herzig and Berant (2018) and specifically for SLU utilizing external resources such as label ontologies in Ferreira et al. (2015a,b) and handwritten intent attributes in Yazdani and Henderson (2015); Chen et al. (2015). Our work is closest in spirit to Bapna et al. (2017) and Lee and Jha (2018), who employ textual slot descriptions to scale to unseen intents/slots. Since slots tend to take semantically similar values across utterances, we augment our model with example values, which are easier for developers to define than manual alignments across schemas (Li et al., 2011). Problem Statem"
P19-1547,D16-1223,0,0.224009,"Missing"
P19-1547,W00-0726,0,0.0757435,"Missing"
P19-1547,D18-1131,1,0.880796,"Missing"
P19-1547,D15-1166,0,0.0246213,"n encoding ds ∈ Rdwc of the slot description by mean-pooling the embeddings for the S slot description tokens. S 1X d = di S s (2) i=1 5 Slot example encoder: We first obtain encodings {exk ∈ Rdwc , 1≤k ≤K} for each slot example value by mean-pooling the Nk token embeddings. Then, we compute an attention weighted encoding of all K slot examples {eai ∈ Rdwc , i≤1≤T } for each utterance token, with the utterance token encoding as attention context. Here, αix ∈ RK denotes attention weights over all K slot examples corresponding to the ith utterance token, obtained with general cosine similarity (Luong et al., 2015). exk = Nk 1 X eki , 1≤k ≤K Nk (3) i=1 αix = sof tmax({hi Wa exk ∀k}), 1≤i≤T eai = K X αixk × exk (4) (5) k=1 Tagger: We feed the concatenated utterance, slot description and example encodings to a den dimensional bidirectional LSTM. The output hidden states X = {xi ∈ Rden , 1≤i≤T } are used for a 3-way IOB tag classification per token. X = BiLST M ({hi ⊕ ds ⊕ eai , 1≤i≤T }) yi = sof tmax(Wt xi + bt ), 1≤i≤T Parameters: We use fixed dw =128-dim pretrained word embeddings2 for all tokens. We also train per-character embeddings, fed to a 2-layer convolutional neural network (Kim, 2014) to get a"
P19-1547,D18-1348,0,0.0260501,"includes, modeling slots as hierarchical concepts (Zhu and Yu, 2018) and using ensembles of models trained on data-rich domains (Gaˇsi´c et al., 2015; Kim et al., 2017; Jha et al., 2018). The availability of task descriptions has made zero-shot learning (Norouzi et al., 2013; Socher et al., 2013) popular. In particular, work on zeroshot utterance intent detection has relied on varied resources such as click logs (Dauphin et al., 2013) and manually defined domain ontologies (Kumar et al., 2017), as well as models such as deep structured semantic models (Chen et al., 2016) and capsule networks (Xia et al., 2018). Zero-shot semantic parsing is addressed in Krishnamurthy et al. (2017) and Herzig and Berant (2018) and specifically for SLU utilizing external resources such as label ontologies in Ferreira et al. (2015a,b) and handwritten intent attributes in Yazdani and Henderson (2015); Chen et al. (2015). Our work is closest in spirit to Bapna et al. (2017) and Lee and Jha (2018), who employ textual slot descriptions to scale to unseen intents/slots. Since slots tend to take semantically similar values across utterances, we augment our model with example values, which are easier for developers to define"
P19-1547,D15-1027,0,0.0635193,"t al., 2013; Socher et al., 2013) popular. In particular, work on zeroshot utterance intent detection has relied on varied resources such as click logs (Dauphin et al., 2013) and manually defined domain ontologies (Kumar et al., 2017), as well as models such as deep structured semantic models (Chen et al., 2016) and capsule networks (Xia et al., 2018). Zero-shot semantic parsing is addressed in Krishnamurthy et al. (2017) and Herzig and Berant (2018) and specifically for SLU utilizing external resources such as label ontologies in Ferreira et al. (2015a,b) and handwritten intent attributes in Yazdani and Henderson (2015); Chen et al. (2015). Our work is closest in spirit to Bapna et al. (2017) and Lee and Jha (2018), who employ textual slot descriptions to scale to unseen intents/slots. Since slots tend to take semantically similar values across utterances, we augment our model with example values, which are easier for developers to define than manual alignments across schemas (Li et al., 2011). Problem Statement We frame our conditional sequence tagging task as follows: given a user utterance with T tokens and a slot type, we predict inside-outside-begin (IOB) tags {y1 , y2 . . . yT } using 3-way classificat"
P19-1547,W18-5047,0,0.118767,"el with all inputs and outputs shown. 2 3 Related Work Settings with resource-poor domains are typically addressed by adapting from resource-rich domains (Blitzer et al., 2006; Pan et al., 2010; Chen et al., 2018; Guo et al., 2018; Shah et al., 2018). To this end approaches such as domain adversarial learning (Liu and Lane, 2017) and multi-task learning (Jaech et al., 2016; Goyal et al., 2018; Siddhant et al., 2018) have been adapted to SLU and related tasks (Henderson et al., 2014). Work targeting domain adaptation specifically for this area includes, modeling slots as hierarchical concepts (Zhu and Yu, 2018) and using ensembles of models trained on data-rich domains (Gaˇsi´c et al., 2015; Kim et al., 2017; Jha et al., 2018). The availability of task descriptions has made zero-shot learning (Norouzi et al., 2013; Socher et al., 2013) popular. In particular, work on zeroshot utterance intent detection has relied on varied resources such as click logs (Dauphin et al., 2013) and manually defined domain ontologies (Kumar et al., 2017), as well as models such as deep structured semantic models (Chen et al., 2016) and capsule networks (Xia et al., 2018). Zero-shot semantic parsing is addressed in Krishn"
W04-2314,W01-1614,0,\N,Missing
W04-2314,W01-0902,0,\N,Missing
W04-2314,P97-1035,0,\N,Missing
W04-2314,P99-1025,0,\N,Missing
W04-3218,P02-1049,0,0.0217751,"ing methods. Preliminary results are given for cluster interpretation and dynamic model adaptation using the clusters obtained. 1 Introduction The deployment of large scale automatic spoken dialog systems, like How May I Help You?SM (HMIHY) (Gorin et al., 1997), makes available large corpora of real human-machine dialog interactions. Traditionally, this data is used for supervised system evaluation. For instance, in (Kamm et al., 1999) they propose a static analysis aimed at measuring the performance of a dialog system, especially in an attempt to automatically estimate user satisfaction. In (Hastie et al., 2002), a dynamic stratDilek Hakkani-Tur AT&T Labs Florham Park, NJ, USA dtur@ research.att.com egy in the error handling process is proposed. In all these studies, supervised learning techniques are used in order to classify dialogs to predict user satisfaction or dialog failures. A novel approach to the exploitation of dialog corpora is for speech recognition and language understanding modeling. In fact, such corpora allow for a multidimensional analysis of speech and language models of dialog systems. Our work differs from previous studies in the algorithmic approach and learning scenario. First"
W05-0404,J99-2004,0,\N,Missing
W05-0404,W04-2416,0,\N,Missing
W05-0404,J93-2004,0,\N,Missing
W05-0404,J99-3003,0,\N,Missing
W05-0404,J93-2006,0,\N,Missing
W05-0404,A88-1019,0,\N,Missing
W05-0404,W03-0421,0,\N,Missing
W05-0404,J03-4003,0,\N,Missing
W05-0404,J95-4004,0,\N,Missing
W05-0404,J01-2002,0,\N,Missing
W05-0404,W04-2412,0,\N,Missing
W10-1201,U06-1009,0,0.0111971,"A typical QA system has a pipeline structure starting from extraction of candidate sentences to ranking true answers. Some approaches to QA use keyword-based techniques to locate candidate passages/sentences in the retrieved documents and then filter based on the presence of the desired answer type in candidate text. Ranking is then done using syntactic features to characterize similarity to query. In cases where simple question formulation is not satisfactory, many advanced QA systems implement more sophisticated syntactic, semantic and contextual processing such as named-entity recognition (Molla et al., 2006), coreference resolution (Vicedo and Ferrandez, 2000), logical inferences (abduction 1 or entailment) (Harabagiu and Hickl, 2006) translation (Ma and McKeowon, 2009), etc., to improve answer ranking. For instance, how questions, or spatially constrained questions, etc., require such types of deeper understanding of the question and the retrieved documents/passages. Many studies on QA have focused on discriminative models to predict a function of matching features between each question and candidate passage (set of sentences), namely q/a pairs, e.g., (Ng et al., 2001; Echihabi and Marcu, 2003;"
W10-1201,W01-0509,0,0.0103904,"med-entity recognition (Molla et al., 2006), coreference resolution (Vicedo and Ferrandez, 2000), logical inferences (abduction 1 or entailment) (Harabagiu and Hickl, 2006) translation (Ma and McKeowon, 2009), etc., to improve answer ranking. For instance, how questions, or spatially constrained questions, etc., require such types of deeper understanding of the question and the retrieved documents/passages. Many studies on QA have focused on discriminative models to predict a function of matching features between each question and candidate passage (set of sentences), namely q/a pairs, e.g., (Ng et al., 2001; Echihabi and Marcu, 2003; Harabagiu and Hickl, 2006; Shen and Klakow, 2006; Celikyilmaz et al., 2009). Despite their success, they have some room for improvement which are not usually raised, e.g., they require hand engineered features; or cascade features learnt separately from other modules in a QA pipeline, thus propagating errors. The structures to be learned can become more complex than the amount of training data, e.g., alignment, entailment, translation, etc. In such cases, other source of information, e.g., unlabeled examples, or human prior knowledge, should be used to improve perfo"
W10-1201,P03-1003,0,0.0134613,"ition (Molla et al., 2006), coreference resolution (Vicedo and Ferrandez, 2000), logical inferences (abduction 1 or entailment) (Harabagiu and Hickl, 2006) translation (Ma and McKeowon, 2009), etc., to improve answer ranking. For instance, how questions, or spatially constrained questions, etc., require such types of deeper understanding of the question and the retrieved documents/passages. Many studies on QA have focused on discriminative models to predict a function of matching features between each question and candidate passage (set of sentences), namely q/a pairs, e.g., (Ng et al., 2001; Echihabi and Marcu, 2003; Harabagiu and Hickl, 2006; Shen and Klakow, 2006; Celikyilmaz et al., 2009). Despite their success, they have some room for improvement which are not usually raised, e.g., they require hand engineered features; or cascade features learnt separately from other modules in a QA pipeline, thus propagating errors. The structures to be learned can become more complex than the amount of training data, e.g., alignment, entailment, translation, etc. In such cases, other source of information, e.g., unlabeled examples, or human prior knowledge, should be used to improve performance. Generative modelin"
W10-1201,P06-1114,0,0.0452493,"approaches to QA use keyword-based techniques to locate candidate passages/sentences in the retrieved documents and then filter based on the presence of the desired answer type in candidate text. Ranking is then done using syntactic features to characterize similarity to query. In cases where simple question formulation is not satisfactory, many advanced QA systems implement more sophisticated syntactic, semantic and contextual processing such as named-entity recognition (Molla et al., 2006), coreference resolution (Vicedo and Ferrandez, 2000), logical inferences (abduction 1 or entailment) (Harabagiu and Hickl, 2006) translation (Ma and McKeowon, 2009), etc., to improve answer ranking. For instance, how questions, or spatially constrained questions, etc., require such types of deeper understanding of the question and the retrieved documents/passages. Many studies on QA have focused on discriminative models to predict a function of matching features between each question and candidate passage (set of sentences), namely q/a pairs, e.g., (Ng et al., 2001; Echihabi and Marcu, 2003; Harabagiu and Hickl, 2006; Shen and Klakow, 2006; Celikyilmaz et al., 2009). Despite their success, they have some room for impro"
W10-1201,P09-2084,0,0.0123974,"niques to locate candidate passages/sentences in the retrieved documents and then filter based on the presence of the desired answer type in candidate text. Ranking is then done using syntactic features to characterize similarity to query. In cases where simple question formulation is not satisfactory, many advanced QA systems implement more sophisticated syntactic, semantic and contextual processing such as named-entity recognition (Molla et al., 2006), coreference resolution (Vicedo and Ferrandez, 2000), logical inferences (abduction 1 or entailment) (Harabagiu and Hickl, 2006) translation (Ma and McKeowon, 2009), etc., to improve answer ranking. For instance, how questions, or spatially constrained questions, etc., require such types of deeper understanding of the question and the retrieved documents/passages. Many studies on QA have focused on discriminative models to predict a function of matching features between each question and candidate passage (set of sentences), namely q/a pairs, e.g., (Ng et al., 2001; Echihabi and Marcu, 2003; Harabagiu and Hickl, 2006; Shen and Klakow, 2006; Celikyilmaz et al., 2009). Despite their success, they have some room for improvement which are not usually raised,"
W10-1201,P06-1112,0,0.00878227,"icedo and Ferrandez, 2000), logical inferences (abduction 1 or entailment) (Harabagiu and Hickl, 2006) translation (Ma and McKeowon, 2009), etc., to improve answer ranking. For instance, how questions, or spatially constrained questions, etc., require such types of deeper understanding of the question and the retrieved documents/passages. Many studies on QA have focused on discriminative models to predict a function of matching features between each question and candidate passage (set of sentences), namely q/a pairs, e.g., (Ng et al., 2001; Echihabi and Marcu, 2003; Harabagiu and Hickl, 2006; Shen and Klakow, 2006; Celikyilmaz et al., 2009). Despite their success, they have some room for improvement which are not usually raised, e.g., they require hand engineered features; or cascade features learnt separately from other modules in a QA pipeline, thus propagating errors. The structures to be learned can become more complex than the amount of training data, e.g., alignment, entailment, translation, etc. In such cases, other source of information, e.g., unlabeled examples, or human prior knowledge, should be used to improve performance. Generative modeling is a way of encoding this additional information"
W10-1201,D09-1057,1,\N,Missing
W10-1201,P09-1081,1,\N,Missing
W10-1204,N07-1026,0,0.0262417,"oduction One of the important steps in Question Answering (QA) is question understanding to identify semantic components of questions. In this paper, we investigate question understanding based on a machine learning approach to discover semantic components (Table 1). An important issue in information extraction from text is that one often deals with insufficient labeled data and large number of unlabeled data, which have led to improvements in semi-supervised learning (SSL) methods, e.g., (Belkin and Niyogi., 2002b), (Zhou et al., 2004). Recently, graph based SSL methods have gained interest (Alexandrescu and Kirchhoff, 2007), (Goldberg and Zhu, 2009). These methods create graphs whose vertices correspond to labeled and unlabeled data, while the edge weights encode the similarity between each pair of data points. Classification is performed using these graphs by scoring unlabeled points in such a way 27 Dilek Hakkani-Tur International Computer Science Institute Berkeley, CA dilek@icsi.berkeley.edu W hat} f ilm introduced Jar Jar |{z {z Binks}? |{z } |{z } | other f ocus event topic Semantic Components & Named-Entitiy Types topic: ’Jar’ (Begin-Topic); ’Jar’ (In-Topic) ; ’Binks’ (In-Topic)(HUMAN:Individual) focus: ’"
W10-1204,W04-2504,0,0.0092967,"ike answer type, focus, event, etc. The ’answer-type’ is a quantity that a question is seeking. A question ’topic’ usually represents major context/constraint of a question (”Jar Jar Binks” in Table 1). A question ’focus’ (e.g., film) denotes a certain aspect (or descriptive feature) of a question ’topic’. To extract topic-focus from questions, (Hajicova et al., 1993) used rule-based approaches via dependency parser structures. (Burger, 2006) implemented parsers and a mixture of rule-based and learning methods to extract different salient features such as question type, event, entities, etc. (Chai and Jin, 2004) explored semantic units based on their discourse relations via rule-based systems. In (Duan et al., 2008) a language model is presented to extract semantic components from questions. Similarly, (Fan et al., 2008)’s semantic chunk annotation uses conditional random fields (CRF) (Lafferty et al., 2001) to annotate semantic chunks of questions in Chinese. Our work aparts from these studies in that we use a graph-based SSL method to extract semantic components from unla28 beled questions. Graph-based methods are suitable for labeling tasks because when two lexical units in different questions are"
W10-1204,P08-1019,0,0.0339081,"’topic’ usually represents major context/constraint of a question (”Jar Jar Binks” in Table 1). A question ’focus’ (e.g., film) denotes a certain aspect (or descriptive feature) of a question ’topic’. To extract topic-focus from questions, (Hajicova et al., 1993) used rule-based approaches via dependency parser structures. (Burger, 2006) implemented parsers and a mixture of rule-based and learning methods to extract different salient features such as question type, event, entities, etc. (Chai and Jin, 2004) explored semantic units based on their discourse relations via rule-based systems. In (Duan et al., 2008) a language model is presented to extract semantic components from questions. Similarly, (Fan et al., 2008)’s semantic chunk annotation uses conditional random fields (CRF) (Lafferty et al., 2001) to annotate semantic chunks of questions in Chinese. Our work aparts from these studies in that we use a graph-based SSL method to extract semantic components from unla28 beled questions. Graph-based methods are suitable for labeling tasks because when two lexical units in different questions are close in the intrinsic geometry of question forms, their semantic components (labels) will be similar to"
W10-1204,W08-1601,0,0.0247264,"focus’ (e.g., film) denotes a certain aspect (or descriptive feature) of a question ’topic’. To extract topic-focus from questions, (Hajicova et al., 1993) used rule-based approaches via dependency parser structures. (Burger, 2006) implemented parsers and a mixture of rule-based and learning methods to extract different salient features such as question type, event, entities, etc. (Chai and Jin, 2004) explored semantic units based on their discourse relations via rule-based systems. In (Duan et al., 2008) a language model is presented to extract semantic components from questions. Similarly, (Fan et al., 2008)’s semantic chunk annotation uses conditional random fields (CRF) (Lafferty et al., 2001) to annotate semantic chunks of questions in Chinese. Our work aparts from these studies in that we use a graph-based SSL method to extract semantic components from unla28 beled questions. Graph-based methods are suitable for labeling tasks because when two lexical units in different questions are close in the intrinsic geometry of question forms, their semantic components (labels) will be similar to each other. Labels vary smoothly along the geodesics, i.e., manifold assumption, which plays an essential r"
W10-1204,W09-2203,0,0.0217431,"in Question Answering (QA) is question understanding to identify semantic components of questions. In this paper, we investigate question understanding based on a machine learning approach to discover semantic components (Table 1). An important issue in information extraction from text is that one often deals with insufficient labeled data and large number of unlabeled data, which have led to improvements in semi-supervised learning (SSL) methods, e.g., (Belkin and Niyogi., 2002b), (Zhou et al., 2004). Recently, graph based SSL methods have gained interest (Alexandrescu and Kirchhoff, 2007), (Goldberg and Zhu, 2009). These methods create graphs whose vertices correspond to labeled and unlabeled data, while the edge weights encode the similarity between each pair of data points. Classification is performed using these graphs by scoring unlabeled points in such a way 27 Dilek Hakkani-Tur International Computer Science Institute Berkeley, CA dilek@icsi.berkeley.edu W hat} f ilm introduced Jar Jar |{z {z Binks}? |{z } |{z } | other f ocus event topic Semantic Components & Named-Entitiy Types topic: ’Jar’ (Begin-Topic); ’Jar’ (In-Topic) ; ’Binks’ (In-Topic)(HUMAN:Individual) focus: ’film’ (Begin-Focus) (DESCR"
W10-1204,E93-1022,0,0.0600814,"iments in section 7 yield performance improvement in comparison to other labeling methods on different datasets. Finally we draw conclusions. 2 Related Work on Question Analysis An important step in question analysis is extracting semantic components like answer type, focus, event, etc. The ’answer-type’ is a quantity that a question is seeking. A question ’topic’ usually represents major context/constraint of a question (”Jar Jar Binks” in Table 1). A question ’focus’ (e.g., film) denotes a certain aspect (or descriptive feature) of a question ’topic’. To extract topic-focus from questions, (Hajicova et al., 1993) used rule-based approaches via dependency parser structures. (Burger, 2006) implemented parsers and a mixture of rule-based and learning methods to extract different salient features such as question type, event, entities, etc. (Chai and Jin, 2004) explored semantic units based on their discourse relations via rule-based systems. In (Duan et al., 2008) a language model is presented to extract semantic components from questions. Similarly, (Fan et al., 2008)’s semantic chunk annotation uses conditional random fields (CRF) (Lafferty et al., 2001) to annotate semantic chunks of questions in Chin"
W10-1204,P03-1054,0,0.00285714,"y, only one node per token is introduced to the graph for known(true) token/label relations. We find the best question label sequence via Viterbi algorithm (Forney, 1973). 3.1 Feature Extraction For Labeling Task The following pre-processing modules are built for feature extraction prior to graph construction. 3.1.1 Pre-Processing For Feature Extraction Phrase Analysis(PA): Using basic syntactic analysis (shallow parsing), the PA module re-builds phrases from linguistic structures such as nounphrases (NN), basic prepositional phrases (PP) or verb groups (VG). Using Stanford dependency parser (Klein and Manning, 2003), (Marneffe et al., 2006), which produces 48 different grammatical relations, PA module re-constructs the phrases. For example for the question in Table 1, dependency parser generates two relations: − nn(Binks-3, Jar-1) and nn(Binks-3, Jar-2), PA reveals ”Jar Jar Binks” as a noun phrase reconstructing the nn:noun compound modifier. We also extract part of speech tags of questions via dependency parser to be used for feature extraction. Question Dependency Relations (QDR): Using shallow semantics, we decode underlying Stanford dependency trees (Marneffe et al., 2006) that embody linguistic rela"
W10-1204,de-marneffe-etal-2006-generating,0,\N,Missing
W12-1816,P11-1009,0,0.127302,"to be sent to dialog manager for taking the appropriate system action. Three key tasks of an SLU system are domain classification, intent determination and slot filling (Tur and Mori, 2011). While the state-of-the-art SLU systems rely on data-driven methods, collecting and annotating naturally spoken utterances to train the required statistical models is often costly The use of click information obtained through massive search query click logs has been the focus of previous research. Specifically, query logs have been used for building more robust web search and better information retrieval (Pantel and Fuxman, 2011; Li et al., 2008), improve personalization experience and understand social networking behaviors (Wang et al., 2011), etc. The use of query logs in spoken dialog research is fairly new. In this paper, we will survey the recent research on utilizing the search query logs to obtain more accurate and robust spoken dialog systems, focusing on the SLU. Later in the discussion section, we will discuss the implimications on the dialog models. The paper is organized as follows: In § 2, we briefly describe query click logs. We then summarize recent research papers to give a snapshot of how user search"
W17-5514,J86-3001,0,0.741206,"g for ? U: Around 5 pm tomorrow night. S: Do you have a theatre in mind? U: Find italian restaurants in Mountain View S: What price range are you looking for ? U: cheap S: Ristorante Giovanni is a nice Italian restaurant in Mountain View. U: That works. thanks. Table 2: A sample dialogue obtained from recombining a dialogue from the movies and find-restaurant datasets. • The new recombined dialogue {(tx1 , fx1 ), ...(txk , fxk ), (tyl , fyl ), ...(tyny , fyny )}. The key idea behind the recombination approach is the conditional independence of sub-dialogues aimed at performing distinct tasks (Grosz and Sidner, 1986). We exploit the presence of task intents, or intents that denote a switch in the primary task the user is trying to perform, since they are a strong indicator of a switch in the focus of the dialogue. We exploit the independence of the sub-dialogue following these intents from the previous dialogue context, to generate synthetic dialogues with multi-domain context. The recombination process is described as follows: Let a dialogue d be defined as a sequence of turns and corresponding semantic labels (domain, intent and slot annotations) {(td1 , fd1 ), (td2 , fd2 ), ...(tdnd , fdnd }. To obtain"
W17-5514,D16-1223,0,0.042785,"richer context during training. 2 Related Work The task of understanding a user utterance is typically broken down into 3 tasks: domain classification, intent classification and slot-filling (Tur and De Mori, 2011). Most modern approaches to Spoken language understanding involve training machine learning models on labeled training data (Young, 2002; Hahn et al., 2011; Wang et al., 2005, among others). More recently, recurrent neural network (RNN) based approaches have been shown to perform exceedingly well on spoken language understanding tasks (Mesnil et al., 2015; Hakkani-T¨ur et al., 2016; Kurata et al., 2016, among others). RNN based approaches have also been applied successfully to other tasks for di3 Model Architecture We compare the performance of 3 model architectures for encoding dialogue context on a multidomain dialogue dataset. Let the dialogue be a sequence of system and user utterances Dt = 104 Figure 3: Architecture of the dialogue context encoder for the cosine similarity based memory network. ances, we append special positional tokens to each utterance. {u1 , u2 ...ut } and at time step t we are trying to output the parse of a user utterance ut , given Dt . Let any utterance uk be a"
W17-5514,W16-3603,0,0.063988,"rez and Liu, 2016, among others), policy learning (Su et al., 2015) and system response generation (Wen et al., 2015, 2016, among others). In parallel, joint modeling of tasks and addition of contextual signals has been shown to result in performance gains for several applications. Modeling domain, intent and slots in a joint RNN model was shown to result in reduction of overall frame error rates (Hakkani-T¨ur et al., 2016). Joint modeling of intent classification and language modeling showed promising improvements in intent recognition, especially in the presence of noisy speech recognition (Liu and Lane, 2016). Similarly, models incorporating more context from dialogue history (Chen et al., 2016) or semantic context from the frame (Dauphin et al., 2014; Bapna et al., 2017) tend to outperform models without context and have shown potential for greater generalization on spoken language understanding and related tasks. (Dhingra et al., 2016) show improved performance on an informational dialogue agent by incorporating knowledge base context into their dialogue system. Using dialogue context was shown to boost performance for end to end dialogue (Bordes and Weston, 2016) and next utterance prediction ("
W17-5514,N07-2038,0,0.0749235,"user-agent interactions comprising of dialog acts and slots based on the interplay of a simulated user and a rule based dialogue policy. (ii) Using a crowd sourcing platform to elicit natural language utterances that align with the semantics of the generated interactions. The goal of the spoken language understanding module of our dialogue system is to map each user utterance into frame based semantics that can be processed by the downstream components. Tables describing the intents and slots present in the dataset can be found in the appendix. We use a stochastic agenda-based user simulator (Schatzmann et al., 2007; Shah et al., 2016) for interplay with our rule based system policy. The user goal is specified in terms of a tuple of slots, which denote the user constraints. Some constraints might be unspecified, in which case the user is indifferent to the value of those slots. At any given turn, the simulator samples a user dialogue act from a set of acceptable actions based on (i) the user goal and agenda that includes slots that still need to be specified, (ii) a randomly chosen user profile (co-operative/aggressive, verbose/succinct etc.) and (iii) the previous user and The architecture is depicted i"
W17-5514,W15-4655,0,0.0677632,"Missing"
W17-5514,N16-1015,0,0.0362695,"Missing"
W17-5514,D15-1199,0,0.0168034,"ing module, which typically parses user utterances into semantic frames, composed of domains, intents and slots (Tur and De Mori, 2011), that can then be processed by downstream dia103 Proceedings of the SIGDIAL 2017 Conference, pages 103–114, c Saarbr¨ucken, Germany, 15-17 August 2017. 2017 Association for Computational Linguistics Figure 2: Architecture of the Memory and current utterance context encoder. alogue systems, like dialogue state tracking (Henderson, 2015; Henderson et al., 2014; Perez and Liu, 2016, among others), policy learning (Su et al., 2015) and system response generation (Wen et al., 2015, 2016, among others). In parallel, joint modeling of tasks and addition of contextual signals has been shown to result in performance gains for several applications. Modeling domain, intent and slots in a joint RNN model was shown to result in reduction of overall frame error rates (Hakkani-T¨ur et al., 2016). Joint modeling of intent classification and language modeling showed promising improvements in intent recognition, especially in the presence of noisy speech recognition (Liu and Lane, 2016). Similarly, models incorporating more context from dialogue history (Chen et al., 2016) or seman"
W18-5045,W17-5514,1,0.84878,"f each user utterance and a dialogue state tracking (DST) or belief tracking component, which keeps track of the conversation context and the dialogue state (DS). Typically, DST uses the 376 Proceedings of the SIGDIAL 2018 Conference, pages 376–384, c Melbourne, Australia, 12-14 July 2018. 2018 Association for Computational Linguistics Utterance: Slot Tags: Table ↓ O for ↓ O two ↓ B-# at ↓ O Olive ↓ B-rest Garden ↓ I-rest results for LU. Hakkani-T¨ur et al. 2016 used a joint RNN for intents, acts and slots to achieve better overall frame accuracy. In addition, models such as Chen et al. 2016, Bapna et al. 2017 and Su et al. 2018 further improve LU results by incorporating context from dialogue history. Henderson et al. 2014 proposed a single joint model for single-turn LU and multi-turn DST to improve belief tracking performance. However, it relied on manually constructed semantic dictionaries to identify alternative mentions of ontology items that vary lexically or morphologically. Such an approach is not scalable to more complex domains (Mrkˇsi´c et al., 2017) as it is challenging to construct semantic dictionaries that can cover all possible entity mentions that occur naturally in a variety of f"
W18-5045,N18-1194,0,0.0294818,"and a dialogue state tracking (DST) or belief tracking component, which keeps track of the conversation context and the dialogue state (DS). Typically, DST uses the 376 Proceedings of the SIGDIAL 2018 Conference, pages 376–384, c Melbourne, Australia, 12-14 July 2018. 2018 Association for Computational Linguistics Utterance: Slot Tags: Table ↓ O for ↓ O two ↓ B-# at ↓ O Olive ↓ B-rest Garden ↓ I-rest results for LU. Hakkani-T¨ur et al. 2016 used a joint RNN for intents, acts and slots to achieve better overall frame accuracy. In addition, models such as Chen et al. 2016, Bapna et al. 2017 and Su et al. 2018 further improve LU results by incorporating context from dialogue history. Henderson et al. 2014 proposed a single joint model for single-turn LU and multi-turn DST to improve belief tracking performance. However, it relied on manually constructed semantic dictionaries to identify alternative mentions of ontology items that vary lexically or morphologically. Such an approach is not scalable to more complex domains (Mrkˇsi´c et al., 2017) as it is challenging to construct semantic dictionaries that can cover all possible entity mentions that occur naturally in a variety of forms in natural lan"
W18-5045,W14-4340,0,0.475254,"le=two, time=7 pm Acts: User: Acts: State: Figure 1: A dialogue with user intent, user and system dialogue acts, and dialogue state. semantic parse generated by LU to update the DS at every dialogue turn. The DS accumulates the preferences specified by the user over the dialogue and is used to make requests to a backend. The results from the backend and the dialogue state are then used by a dialogue policy module to generate the next system response. Pipelining dialogue system components often leads to error propagation, hence joint modeling of these components has recently gained popularity (Henderson et al., 2014; Mrkˇsi´c et al., 2017; Liu and Lane, 2017), owing to computational efficiency as well as the potential ability to recover from errors introduced by LU. However, combining joint modeling with the ability to scale to multiple domains and handle slots with a large set of possible values, potentially containing entities not seen during training, are active areas of research. In this work, we propose a single, joint model for LU and DST trained with multi-task learning. Similar to Liu and Lane 2017, our model employs a hierarchical recurrent neural network to encode the dialogue context. Intermed"
W18-5045,W00-0726,0,0.0358282,"Missing"
W18-5045,W13-4067,0,0.0206676,"ns to be used as features by different tasks in our framework. The section also defines and outlines the implementation of the LU and DST tasks. Section 4 describes our setup for scheduled sampling. We then conclude with experiments and discussion of results. 2 Related Work The initial motivation for dialogue state tracking came from the uncertainty in speech recognition and other sources (Williams and Young, 2007), as well as to provide a comprehensive input to a downstream dialogue policy component deciding the next system action. Proposed belief tracking models have ranged from rule-based (Wang and Lemon, 2013), to generative (Thomson and Young, 2010), discriminative (Henderson et al., 2014), other maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). Language understanding has commonly been modeled as a combination of intent and dialogue act classification and slot tagging (Tur and De Mori, 2011). Recently, recurrent neural network (RNN) based approaches have shown good 3 Model Architecture Let a dialogue be a sequence of T turns, each turn containing a user utterance and the preceding system dialogue acts output by the dialogue manager. Figure 3 gives an overview of our m"
W18-5045,W16-3603,0,0.0233307,"th predictions from the previous turn are used. This causes a mismatch between training and inference behavior. We use scheduled sampling (Bengio et al., 2015) to bridge this 380 Figure 4: Illustration of scheduled sampling for training the candidate scorer. The left figure shows the two locations in our setup where we can perform scheduled sampling, while the plot on the right shows the variation of sampling probabilities pc and pD with training step. See Section 4 for details. 5 mismatch. Scheduled sampling has been shown to achieve improved slot tagging performance on single turn datasets (Liu and Lane, 2016). Figure 4 shows our setup for scheduled sampling for DST, which is carried out at two different locations - slot tags and dialogue state. The major contributions of our work are two-fold. First, we hypothesize that joint modeling of LU and DST results in a computationally efficient model with fewer parameters without compromising performance. Second, we propose the use of scheduled sampling to improve the robustness of DST during inference. To this end, we conduct experiments across the following two setups. The performance of slot tagger is critical to DST because any slot value missed by th"
W18-5045,W13-4068,0,0.026323,"ST tasks. Section 4 describes our setup for scheduled sampling. We then conclude with experiments and discussion of results. 2 Related Work The initial motivation for dialogue state tracking came from the uncertainty in speech recognition and other sources (Williams and Young, 2007), as well as to provide a comprehensive input to a downstream dialogue policy component deciding the next system action. Proposed belief tracking models have ranged from rule-based (Wang and Lemon, 2013), to generative (Thomson and Young, 2010), discriminative (Henderson et al., 2014), other maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). Language understanding has commonly been modeled as a combination of intent and dialogue act classification and slot tagging (Tur and De Mori, 2011). Recently, recurrent neural network (RNN) based approaches have shown good 3 Model Architecture Let a dialogue be a sequence of T turns, each turn containing a user utterance and the preceding system dialogue acts output by the dialogue manager. Figure 3 gives an overview of our model architecture, which includes a user utterance encoder, a system act encoder, a state encoder, a slot tagger and a candidate"
W18-5045,W14-4339,0,0.0131395,"for scheduled sampling. We then conclude with experiments and discussion of results. 2 Related Work The initial motivation for dialogue state tracking came from the uncertainty in speech recognition and other sources (Williams and Young, 2007), as well as to provide a comprehensive input to a downstream dialogue policy component deciding the next system action. Proposed belief tracking models have ranged from rule-based (Wang and Lemon, 2013), to generative (Thomson and Young, 2010), discriminative (Henderson et al., 2014), other maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). Language understanding has commonly been modeled as a combination of intent and dialogue act classification and slot tagging (Tur and De Mori, 2011). Recently, recurrent neural network (RNN) based approaches have shown good 3 Model Architecture Let a dialogue be a sequence of T turns, each turn containing a user utterance and the preceding system dialogue acts output by the dialogue manager. Figure 3 gives an overview of our model architecture, which includes a user utterance encoder, a system act encoder, a state encoder, a slot tagger and a candidate scorer. At each turn t ∈ {1, ..., T },"
W18-5045,P17-1163,0,0.0921948,"Missing"
W18-5045,E17-1029,0,0.01166,"mentions of ontology items that vary lexically or morphologically. Such an approach is not scalable to more complex domains (Mrkˇsi´c et al., 2017) as it is challenging to construct semantic dictionaries that can cover all possible entity mentions that occur naturally in a variety of forms in natural language. Mrkˇsi´c et al. 2017 proposed the NBT model which eliminates the LU step by directly operating on the user utterance. However, their approach requires iterating through the set of all possible values for a slot, which could be large or potentially unbounded (e.g. date, time, usernames). Perez and Liu 2017 incorporated end-to-end memory networks, as introduced in Sukhbaatar et al. 2015, into state tracking and Liu and Lane 2017 proposed an end-toend model for belief tracking. However, these two approaches cannot accommodate OOV slot values as they represent DS as a distribution over all possible slot values seen in the training set. To handle large value sets and OOV slot values, Rastogi et al. 2017 proposed an approach, where a set of value candidates is formed at each turn using dialogue context. The DST then operates on this set of candidates. In this work, we adopt a similar approach, but o"
W19-5917,D15-1166,0,0.161114,"Missing"
W19-5917,K16-1028,0,0.0317511,"pirically show the effectiveness of the proposed model compared to several baselines including (Ghazvininejad et al., 2018; Zhang et al., 2018) through both automatic evaluation metrics and human evaluation on C ONVA I 2 dataset. 1 Introduction Recently, deep neural networks have achieved stateof-the-art results in various tasks including computer vision, natural language and speech processing. Specifically, neural sequence-to-sequence models (Sutskever et al., 2014; Bahdanau et al., 2015) have led to great progress in important downstream NLP tasks like text summarization (Rush et al., 2015; Nallapati et al., 2016; See et al., 2017; ∗ Work done while interning at Google AI. Tan et al., 2017; Yavuz et al., 2018), machine translation (Cho et al., 2014; Sutskever et al., 2014; Luong et al., 2015; Bahdanau et al., 2015), and reading comprehension (Xiong et al., 2017). However, achieving satisfactory performance on dialogue still remains an open problem. This is because dialogues can have multiple valid responses with varying semantic content. This is vastly different from the aforementioned tasks, where the generation is more conveniently and uniquely constrained by the input source. Although neural models"
W19-5917,P02-1040,0,0.106055,"updated during training. We set the size of LSTM hidden layer to 100 for both encoder and decoder. The encoder and decoder vocabularies and embeddings are shared. A shared LSTM encoder is used for encoding both dialogue context and facts of external knowledge source. The model parameters are optimized using Main Results 4.3.1 Automatic Evaluation In Table 1, we present our results in comparison with the existing and proposed baseline models. We report the performance of each model across several metrics commonly used for evaluation of text generation models including perplexity, corpus BLEU (Papineni et al., 2002), ROUGE-L (Lin and Och, 2004), CIDEr (Vedantam et al., 2014). As expected, S EQ 2S EQ + B EST FACT R E SPONSE model and its +COPY version outperform all the other models across all the evaluation metrics. This model pinpoints the importance of selecting the most suitable fact in the persona for the response to be generated at each turn, justifying our underlying motivation for conducting this experiment as highlighted in Section 3.2.1. However, the most suitable fact for the response is not available in the real application scenario, where the models are responsible for picking the useful piec"
W19-5917,D11-1054,0,0.0461131,"oftly combine the copying probabilities with the decoder’s generation probabilities over a fixed vocabulary into a final output probability distribution over an extended vocabulary. We empirically show the effectiveness of the proposed D EEP C OPY model compared to several baselines including (Ghazvininejad et al., 2018; Zhang et al., 2018) on C ONVA I 2 challenge. 2 Related Work Earlier work on data-driven, end-to-end approaches to conversational response generation treated the task as statistical machine translation, where the goal is to generate a response given the previous dialogue turn (Ritter et al., 2011; Vinyals and Le, 2015). While these studies resulted in a paradigm change compared to earlier work, they do not include mechanisms to represent conversation context. To tackle this problem and have a better representation of conversation context as input to generation, (Serban et al., 2016) proposed hierarchical recurrent encoder-decoder (HRED) networks. HRED combines two RNNs, one at the token level, modeling individual turns, and one at the dialogue level, inputting turn representations from the tokenlevel RNNs. However, utterances generated by such neural response generation systems are of"
W19-5917,D15-1044,0,0.0435315,"ogue context. We empirically show the effectiveness of the proposed model compared to several baselines including (Ghazvininejad et al., 2018; Zhang et al., 2018) through both automatic evaluation metrics and human evaluation on C ONVA I 2 dataset. 1 Introduction Recently, deep neural networks have achieved stateof-the-art results in various tasks including computer vision, natural language and speech processing. Specifically, neural sequence-to-sequence models (Sutskever et al., 2014; Bahdanau et al., 2015) have led to great progress in important downstream NLP tasks like text summarization (Rush et al., 2015; Nallapati et al., 2016; See et al., 2017; ∗ Work done while interning at Google AI. Tan et al., 2017; Yavuz et al., 2018), machine translation (Cho et al., 2014; Sutskever et al., 2014; Luong et al., 2015; Bahdanau et al., 2015), and reading comprehension (Xiong et al., 2017). However, achieving satisfactory performance on dialogue still remains an open problem. This is because dialogues can have multiple valid responses with varying semantic content. This is vastly different from the aforementioned tasks, where the generation is more conveniently and uniquely constrained by the input source"
W19-5917,P17-1099,0,0.508206,"systems: they tend to generate short and dull responses that are often too generic. Furthermore, these models do not ground conversational responses on knowledge and facts, resulting in turns that are not accurate, informative and engaging for the users. In this paper, we propose and experiment with a series of response generation models that aim to serve in the general scenario where in addition to the dialogue context, relevant unstructured external knowledge in the form of text is also assumed to be available for models to harness. Our proposed approach extends pointer-generator networks (See et al., 2017) by allowing the decoder to hierarchically attend and copy from external knowledge in addition to the dialogue context. We empirically show the effectiveness of the proposed model compared to several baselines including (Ghazvininejad et al., 2018; Zhang et al., 2018) through both automatic evaluation metrics and human evaluation on C ONVA I 2 dataset. 1 Introduction Recently, deep neural networks have achieved stateof-the-art results in various tasks including computer vision, natural language and speech processing. Specifically, neural sequence-to-sequence models (Sutskever et al., 2014; Bah"
W19-5917,P16-1094,0,0.358066,"mon problems include inconsistency in personality, dull and generic responses, and unawareness of long-term dialogue context. To alleviate these limitations, we turn our focus on a different problem setting for dialogue response generation where the model is provided a set of relevant textual facts (speaker persona descriptions) and is allowed to harness this knowledge when generating responses in a multi-turn dialogue. To handle the personality inconsistency issue, we ground our dialogue generation model on external knowledge facts which are a list of persona descriptions in our application (Li et al., 2016a; Zhang et al., 2018). We explicitly use the dialogue history as memory for the model to condition on which potentially encourages a more natural conversation flow. Towards encouraging generation of more specific and appropriate responses while avoiding generic and dull ones, we use a hierarchical pointer network in our model such that it can copy content from two sources: current dialogue history and persona descriptions. In this work, we propose a novel and general ar122 Proceedings of the SIGDial 2019 Conference, pages 122–132 c Stockholm, Sweden, 11-13 September 2019. 2019 Association for"
W19-5917,N16-1014,0,0.304202,"mon problems include inconsistency in personality, dull and generic responses, and unawareness of long-term dialogue context. To alleviate these limitations, we turn our focus on a different problem setting for dialogue response generation where the model is provided a set of relevant textual facts (speaker persona descriptions) and is allowed to harness this knowledge when generating responses in a multi-turn dialogue. To handle the personality inconsistency issue, we ground our dialogue generation model on external knowledge facts which are a list of persona descriptions in our application (Li et al., 2016a; Zhang et al., 2018). We explicitly use the dialogue history as memory for the model to condition on which potentially encourages a more natural conversation flow. Towards encouraging generation of more specific and appropriate responses while avoiding generic and dull ones, we use a hierarchical pointer network in our model such that it can copy content from two sources: current dialogue history and persona descriptions. In this work, we propose a novel and general ar122 Proceedings of the SIGDial 2019 Conference, pages 122–132 c Stockholm, Sweden, 11-13 September 2019. 2019 Association for"
W19-5917,P04-1077,0,0.109054,"the size of LSTM hidden layer to 100 for both encoder and decoder. The encoder and decoder vocabularies and embeddings are shared. A shared LSTM encoder is used for encoding both dialogue context and facts of external knowledge source. The model parameters are optimized using Main Results 4.3.1 Automatic Evaluation In Table 1, we present our results in comparison with the existing and proposed baseline models. We report the performance of each model across several metrics commonly used for evaluation of text generation models including perplexity, corpus BLEU (Papineni et al., 2002), ROUGE-L (Lin and Och, 2004), CIDEr (Vedantam et al., 2014). As expected, S EQ 2S EQ + B EST FACT R E SPONSE model and its +COPY version outperform all the other models across all the evaluation metrics. This model pinpoints the importance of selecting the most suitable fact in the persona for the response to be generated at each turn, justifying our underlying motivation for conducting this experiment as highlighted in Section 3.2.1. However, the most suitable fact for the response is not available in the real application scenario, where the models are responsible for picking the useful pieces of information pertaining"
W19-5917,P18-1138,0,0.0255006,"dividual turns, and one at the dialogue level, inputting turn representations from the tokenlevel RNNs. However, utterances generated by such neural response generation systems are often generic and contentless (Vinyals and Le, 2015). To improve the diversity and content of generated responses, HRED was later extended with a latent variable that aims to model the higher level aspects (such as topic) of the generated responses, resulting in the VHRED approach (Serban et al., 2017). Another challenge for dialogue response generation is the integration of knowledge into the generated responses. (Liu et al., 2018) extracted facts relevant to a dialogue from knowledge using string matching, named entity recognition and linking, found additional entities from knowledge that are most relevant to the facts by a neural similarity scorer, and used these as input context features for the dialogue generation RNN. (Ghazvininejad et al., 2018) used end-to-end memory networks to base the generated responses on knowledge, where an attention over the knowledge relevant to the conversation context is estimated, and multiple knowledge representations are included as input during the decoding of responses. In this wor"
W19-5917,P17-1108,0,0.0165597,"including (Ghazvininejad et al., 2018; Zhang et al., 2018) through both automatic evaluation metrics and human evaluation on C ONVA I 2 dataset. 1 Introduction Recently, deep neural networks have achieved stateof-the-art results in various tasks including computer vision, natural language and speech processing. Specifically, neural sequence-to-sequence models (Sutskever et al., 2014; Bahdanau et al., 2015) have led to great progress in important downstream NLP tasks like text summarization (Rush et al., 2015; Nallapati et al., 2016; See et al., 2017; ∗ Work done while interning at Google AI. Tan et al., 2017; Yavuz et al., 2018), machine translation (Cho et al., 2014; Sutskever et al., 2014; Luong et al., 2015; Bahdanau et al., 2015), and reading comprehension (Xiong et al., 2017). However, achieving satisfactory performance on dialogue still remains an open problem. This is because dialogues can have multiple valid responses with varying semantic content. This is vastly different from the aforementioned tasks, where the generation is more conveniently and uniquely constrained by the input source. Although neural models appear to generate meaningful responses when trained with sufficiently large"
W19-5917,W18-5713,0,0.0429664,"l., 2017). Subsequently, we introduce the proposed D EEP C OPY model with a hierarchical pointer network and our training process. 3.1 Problem Setup 3.2.2 Let x = (x1 , x2 , . . . , xn ) denote the tokens in the dialogue history. The dialogue is accompanied by a set of K relevant supporting facts, where (i) (i) (i) f (i) = (f1 , f2 , . . . , fni ) is the list of tokens in the i-th fact. Our goal is to generate the response as a sequence of tokens y = (y1 , y2 , . . . , ym ) using the dialogue history and supporting facts. Note here that we are not interested in retrieval/ranking based models (Weston et al., 2018) which rely on a set of candidate responses. Generative models are essential for this problem because we want to incorporate content from new facts during inference which may not be present in the training set. Hence, using a predefined set of candidates may not ensure high coverage. 3.2 Baseline Models In this section, we describe several baseline response generation models including the ones from existing work (Ghazvininejad et al., 2018; Zhang et al., 2018) and the in-house ones we propose as additional baselines. 3.2.1 Seq2Seq In a sequence-to-sequence model with attention (Bahdanau et al."
W19-5917,D18-1406,1,0.778673,"ninejad et al., 2018; Zhang et al., 2018) through both automatic evaluation metrics and human evaluation on C ONVA I 2 dataset. 1 Introduction Recently, deep neural networks have achieved stateof-the-art results in various tasks including computer vision, natural language and speech processing. Specifically, neural sequence-to-sequence models (Sutskever et al., 2014; Bahdanau et al., 2015) have led to great progress in important downstream NLP tasks like text summarization (Rush et al., 2015; Nallapati et al., 2016; See et al., 2017; ∗ Work done while interning at Google AI. Tan et al., 2017; Yavuz et al., 2018), machine translation (Cho et al., 2014; Sutskever et al., 2014; Luong et al., 2015; Bahdanau et al., 2015), and reading comprehension (Xiong et al., 2017). However, achieving satisfactory performance on dialogue still remains an open problem. This is because dialogues can have multiple valid responses with varying semantic content. This is vastly different from the aforementioned tasks, where the generation is more conveniently and uniquely constrained by the input source. Although neural models appear to generate meaningful responses when trained with sufficiently large datasets in the chit-"
W19-5917,P18-1205,0,0.0823409,"per, we propose and experiment with a series of response generation models that aim to serve in the general scenario where in addition to the dialogue context, relevant unstructured external knowledge in the form of text is also assumed to be available for models to harness. Our proposed approach extends pointer-generator networks (See et al., 2017) by allowing the decoder to hierarchically attend and copy from external knowledge in addition to the dialogue context. We empirically show the effectiveness of the proposed model compared to several baselines including (Ghazvininejad et al., 2018; Zhang et al., 2018) through both automatic evaluation metrics and human evaluation on C ONVA I 2 dataset. 1 Introduction Recently, deep neural networks have achieved stateof-the-art results in various tasks including computer vision, natural language and speech processing. Specifically, neural sequence-to-sequence models (Sutskever et al., 2014; Bahdanau et al., 2015) have led to great progress in important downstream NLP tasks like text summarization (Rush et al., 2015; Nallapati et al., 2016; See et al., 2017; ∗ Work done while interning at Google AI. Tan et al., 2017; Yavuz et al., 2018), machine translation"
W19-5917,N16-1004,0,0.171665,"the decoder state. M EM N ET +FACTATTENTION. At each decoder step, we use the decoder state to attend over the value embeddings (m1 , m2 , . . . , mK ) correspond(f ) ing to facts, and obtain a context vector ct . This model is similar to the generative profile memory network (Zhang et al., 2018), where we apply attention only on facts, and we set the decoder’s initial state to the combined summary u ˆ. M EM N ET +F ULL ATTENTION. This model employs attention over both facts and dialogue context at each decoder step. The two attention modules (c) (f ) are combined by concatenating ct and ct (Zoph and Knight, 2016). 3.2.3 Seq2Seq with Copy Mechanism Seq2seq models can only generate tokens present in a fixed vocabulary obtained from the training set. Pointer-generator network (See et al., 2017) extends the attentional sequence-to-sequence model (Bahdanau et al., 2015) by employing a pointer network (Vinyals et al., 2015). It has two decoding modes, copying and generating, which are com124 Figure 1: Overview of our proposed approach as described in Section 3.3. The decoder state dt is used to attend over dialogue context and knowledge source to generate distributions for copying tokens from these sources."
W19-5926,N16-1101,0,0.0166584,"okens are first augmented by their corresponding per-token video representations and then encoded by a bidirectional LSTM (Section 3.3). Similarly, in the Dialogue Context Encoder, the dialogue context is encoded by a bidirectional LSTM (Section 3.4). Finally, in the Answer Decoder, the outputs from the Video-Augmented Question Encoder and the Dialogue Context Encoder are used as attention memory for the LSTM decoder to predict the answer sentence (Section 3.5). Our encoders and decoder work in the same way as the multi-source sequence-to-sequence models with attention (Zoph and Knight, 2016; Firat et al., 2016). sion method and propose to use Maximum Mutual Information (MMI) (Bahl et al., 1986) as the training objective. Besides the HRE architecture, the multi-source sequence-to-sequence (Multi-Source Seq2Seq) architecture with attention (Zoph and Knight, 2016; Firat et al., 2016) is also commonly applied (Pasunuru and Bansal, 2019; Kumar et al., 2019; Yeh et al., 2019). Previous works (Sanabria et al., 2019; Le et al., 2019; Pasunuru and Bansal, 2019) also explore various attention mechanisms to incorporate the different modal inputs, such as hierarchical attention (Libovick`y and Helcl, 2017) and"
W19-5926,W05-0909,0,0.0242562,"odule summarizes the video sequence efficiently aggregating the visual features by question-guided attention and weighted summation and performing gating with a question-guided gate vector, both of which can be done in parallel across all frames. 4.2 5.1 Results Comparison with Existing Methods We evaluate our proposed approach using the same natural language generation evaluation toolkit NLGEval (Sharma et al., 2017) as the previous approaches. The corpus-wide scores of the following unsupervised automated metrics are reported, including BLEU-1 through BLEU-4 (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), ROUGE-L (Lin and Och, 2004) and CIDEr (Vedantam et al., 2015). The results of our models in comparison with the previous approaches are shown in Table 2. We report the mean and standard deviation scores of 5 runs using random initialization and early stopping on the public (prototype) validation set. We apply our model in two scenarios: single-turn and multi-turn VideoQA. The only difference is that in singleturn VideoQA, the dialogue context encoder is excluded from the model. First we observe that our proposed multi-turn VideoQA model significantly outperforms the single-turn VideoQA model"
W19-5926,P02-1040,0,0.104677,"on-guided video representation module summarizes the video sequence efficiently aggregating the visual features by question-guided attention and weighted summation and performing gating with a question-guided gate vector, both of which can be done in parallel across all frames. 4.2 5.1 Results Comparison with Existing Methods We evaluate our proposed approach using the same natural language generation evaluation toolkit NLGEval (Sharma et al., 2017) as the previous approaches. The corpus-wide scores of the following unsupervised automated metrics are reported, including BLEU-1 through BLEU-4 (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), ROUGE-L (Lin and Och, 2004) and CIDEr (Vedantam et al., 2015). The results of our models in comparison with the previous approaches are shown in Table 2. We report the mean and standard deviation scores of 5 runs using random initialization and early stopping on the public (prototype) validation set. We apply our model in two scenarios: single-turn and multi-turn VideoQA. The only difference is that in singleturn VideoQA, the dialogue context encoder is excluded from the model. First we observe that our proposed multi-turn VideoQA model significantly outper"
W19-5926,D18-1167,0,0.0574919,"titive performance, in comparison with existing approaches (Section 5). 2 2.2 VideoQA is a more complex task. As a video is a sequence of images, it contains not only appearance information but also motion and transitions. Therefore, VideoQA requires spatial and temporal aggregation of image features to encode the video into a question-relevant representation. Hence, temporal frame-level attention is utilized to model the temporal dynamics, where framelevel attribute detection and unified video representation are learned jointly (Ye et al., 2017; Xu et al., 2017; Mun et al., 2017). Similarly, Lei et al. (2018) use Faster R-CNN (Ren et al., 2015b) trained with the Visual Genome (Krishna et al., 2017) dataset to detect object and attribute regions in each frame, which are used as input features to the question answering model. Previous works also adopt various forms of external memory (Sukhbaatar et al., 2015; Kumar et al., 2016; Graves et al., 2016) to store question information, which allows multiple iterations of questionconditioned inference on the video features (Na et al., 2017; Kim et al., 2017; Zeng et al., 2017; Gao et al., 2018; Chenyou Fan, 2019). Related Work In the recent years, research"
W19-5926,P17-2031,0,0.0299703,"Missing"
W19-5926,P04-1077,0,0.0902874,"efficiently aggregating the visual features by question-guided attention and weighted summation and performing gating with a question-guided gate vector, both of which can be done in parallel across all frames. 4.2 5.1 Results Comparison with Existing Methods We evaluate our proposed approach using the same natural language generation evaluation toolkit NLGEval (Sharma et al., 2017) as the previous approaches. The corpus-wide scores of the following unsupervised automated metrics are reported, including BLEU-1 through BLEU-4 (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), ROUGE-L (Lin and Och, 2004) and CIDEr (Vedantam et al., 2015). The results of our models in comparison with the previous approaches are shown in Table 2. We report the mean and standard deviation scores of 5 runs using random initialization and early stopping on the public (prototype) validation set. We apply our model in two scenarios: single-turn and multi-turn VideoQA. The only difference is that in singleturn VideoQA, the dialogue context encoder is excluded from the model. First we observe that our proposed multi-turn VideoQA model significantly outperforms the single-turn VideoQA model. This suggests that the addi"
W19-5926,W18-1819,0,0.0164175,"-turn VideoQA model significantly outperforms the single-turn VideoQA model. This suggests that the additional dialogue context input can provide supplementary information from the question and visual features, and thus is helpful for generating the correct answer. Secondly, comparing the single-turn VideoQA models, our approach outperforms the existing approaches across all automatic evaluation metrics. This suggests the effectiveness of our proposed question-guided video representations for VideoQA. When comparing Experimental Setup We implement our models using the Tensor2Tensor framework (Vaswani et al., 2018). The question and dialogue context tokens are both embedded with the same randomly-initialized word embedding matrix, which is also shared with the answer decoder’s output embedding. The dimension of the word embedding is 256, the same dimension to which the I3D-RGB features are transformed. All of our LSTM encoders and decoder 220 Single-Turn VideoQA Models BLEU-1 BLEU-2 BLEU-3 BLEU-4 METEOR ROUGE-L CIDEr Na¨ıve Fusion Multi-source Seq2Seq Ours 27.7 29.56±0.75 17.5 18.60±0.49 11.8 13.16±0.33 8.3 8.83 9.77±0.21 11.7 12.43 13.19±0.20 28.8 34.23 34.29±0.19 74.0 95.54 101.75±1.03 Multi-Turn Vide"
W19-5926,N16-1004,0,0.0154981,"Encoder, the question tokens are first augmented by their corresponding per-token video representations and then encoded by a bidirectional LSTM (Section 3.3). Similarly, in the Dialogue Context Encoder, the dialogue context is encoded by a bidirectional LSTM (Section 3.4). Finally, in the Answer Decoder, the outputs from the Video-Augmented Question Encoder and the Dialogue Context Encoder are used as attention memory for the LSTM decoder to predict the answer sentence (Section 3.5). Our encoders and decoder work in the same way as the multi-source sequence-to-sequence models with attention (Zoph and Knight, 2016; Firat et al., 2016). sion method and propose to use Maximum Mutual Information (MMI) (Bahl et al., 1986) as the training objective. Besides the HRE architecture, the multi-source sequence-to-sequence (Multi-Source Seq2Seq) architecture with attention (Zoph and Knight, 2016; Firat et al., 2016) is also commonly applied (Pasunuru and Bansal, 2019; Kumar et al., 2019; Yeh et al., 2019). Previous works (Sanabria et al., 2019; Le et al., 2019; Pasunuru and Bansal, 2019) also explore various attention mechanisms to incorporate the different modal inputs, such as hierarchical attention (Libovick`y"
W19-5932,E17-1029,0,0.106553,"constrained by the predefined set of possible values (Liu and Lane, 2017). However, these approaches are not applicable for unseen values and do not scale for large or potentially unbounded vocabulary (Nouri and Hosseini-Asl, 2018). To address these concerns, a class of methods employing scoring mechanisms to predict the slot value from a endogenously defined set of candidates have been proposed (Rastogi et al., 2017; Goel et al., 2018). In these methods, the candidates are derived from either a predefined ontology or by extraction of a word or n-grams in the prior dialog context. Previously, Perez and Liu (2017) also formulated state tracking as a machine reading comprehension problem. However, their model architecture used a memory network which is relatively complex and still assumes a fixed-set vocabulary. Perhaps, the most similar technique to our work is the pointer networks proposed by Xu and Hu (2018) wherein an attention-based mechanism is • We present the task of dialog state tracking as making three sequential decisions: i) a binary carryover decision by a simple slot carryover model ii) a slot type decision by a slot type model iii) a slot span decision by an attentive reading comprehensio"
W19-5932,D18-1547,0,0.207263,"Missing"
W19-5932,N18-1202,0,0.0193564,"ar, for pre-trained word vectors pi , we experiment with using deep contextualized word embeddings using BERT (Devlin et al., 2018). For RNN, we use a one layer bidirectional long short-term memory network (LSTM) and each di is the concatenation of two LSTMs from both directions, i.e., ← − → − di = ( di ; di ). Furthermore, we denote e(t) as our dialog embedding at turn t as follows: Deep Contextual Word Embeddings The recent advancements in the neural representation of words includes using character embeddings (Seo et al., 2016) and more recently using contextualized embeddings such as ELMO (Peters et al., 2018) and BERT (Devlin et al., 2018). These methods are usually trained on a very large corpus using a language model objective and show superior results across a variety of tasks. Given their wide applicability (Liu et al., 2019), we employ these architectures in our dialog state tracking task. 3 Encoding ← − − → e(t) = (d1 ; dL ) (2) Question Encoding In our methodology, we formulate questions qi defined earlier as what is the value for slot i? For each dialog, there are M similar questions corresponding to M slots, therefore, we represent each question qi as a fixeddimension vector qi to learn."
W19-5932,D16-1264,0,0.100073,"Missing"
W19-5932,P17-1171,0,0.105851,"ssage and hence state-of-the-art models are developed in such a way that a fixed vocabulary for an answer is usually not required. Motivated by the limitations of previous dialog state tracking methods and the recent advances in reading comprehension (Chen, 2018), we propose a reading comprehension based approach to dialog state tracking. In our approach, we view the dialog as a passage and ask the question what is the state of the current dialog? We use a simple attention-based neural network model to find answer spans by directly pointing to the tokens within the dialog, which is similar to Chen et al. (2017). In addition to this attentive reading model, we also introduce two simple models into our dialog state tracking pipeline, a slot carryover model to help the tracker make a binary decision whether the slot values from the previous turn should be used; a slot type model to predict whether the answer is {Yes, No, DontCare, Span}, which is similar to Zhu et al. (2018). To summarize our contributions: Agent: User: Hotel Taxi I need to book a hotel in the east that has 4 stars. area=east, stars=4 I can help you with that. What is your price range? That doesn’t matter if it has free wifi and parkin"
W19-5932,P18-2069,0,0.120183,". To adopt a flexible approach and inspired by the state-of-the-art reading comprehension approaches, we propose a classifier that predicts the type of slot value at each turn. In our setting, we prescribe the output space to be {Yes, No, DontCare, Span} where Span indicates the slot value is a named entity which can be found within the dialog. As shown in Figure 1, we concatenate the dialog embedding e(t) with the question encoding qi for slot i as the input to the affine layer A to predict the slot type Ti (t) as: We use the recently-released MultiWOZ-2.0 dataset (Budzianowski et al., 2018; Ramadan et al., 2018) to test our approach. This dataset consists of multi-domain conversations from seven domains with a total of 37 slots across domains. Many of these slot types such as day and people are shared across multiple domains. In our experiments, we process each slot independently by considering the concatenation of slot domain, slot category, and slot name, e.g., {bus.book.people}, {restaurant.semi.food}. An example of conversation is shown in Table 1. We use standard training/development/test present in the data set. It is worth-noting that the dataset in the current form has certain annotation erro"
W19-5932,Q19-1016,0,0.0216024,"1 Introduction A task-oriented spoken dialog system involves continuous interaction with a machine agent and a human who wants to accomplish a predefined task through speech. Broadly speaking, the system has *Authors contributed equally. **We note that after publication, a new state-of-the-art can now be obtained with a similar attention mechanism followed by a enoder-decoder architecture (Wu et al., 2019). 264 Proceedings of the SIGDial 2019 Conference, pages 264–273 c Stockholm, Sweden, 11-13 September 2019. 2019 Association for Computational Linguistics User: Hotel Agent: User: Hotel 2017; Reddy et al., 2019) require us to find the answer spans within the given passage and hence state-of-the-art models are developed in such a way that a fixed vocabulary for an answer is usually not required. Motivated by the limitations of previous dialog state tracking methods and the recent advances in reading comprehension (Chen, 2018), we propose a reading comprehension based approach to dialog state tracking. In our approach, we view the dialog as a passage and ask the question what is the state of the current dialog? We use a simple attention-based neural network model to find answer spans by directly pointi"
W19-5932,D13-1020,0,0.0936135,"Missing"
W19-5932,Q18-1023,0,0.0432868,"Missing"
W19-5932,N19-1112,0,0.0214576,"the concatenation of two LSTMs from both directions, i.e., ← − → − di = ( di ; di ). Furthermore, we denote e(t) as our dialog embedding at turn t as follows: Deep Contextual Word Embeddings The recent advancements in the neural representation of words includes using character embeddings (Seo et al., 2016) and more recently using contextualized embeddings such as ELMO (Peters et al., 2018) and BERT (Devlin et al., 2018). These methods are usually trained on a very large corpus using a language model objective and show superior results across a variety of tasks. Given their wide applicability (Liu et al., 2019), we employ these architectures in our dialog state tracking task. 3 Encoding ← − − → e(t) = (d1 ; dL ) (2) Question Encoding In our methodology, we formulate questions qi defined earlier as what is the value for slot i? For each dialog, there are M similar questions corresponding to M slots, therefore, we represent each question qi as a fixeddimension vector qi to learn. 3.3 Models Overview In our full model set up, three different model components are used to make a sequence of predictions: first, we use a slot carryover model for deciding whether to carryover a slot value from the last turn"
W19-5932,2005.sigdial-1.4,0,0.186291,"Missing"
W19-5932,P19-1078,0,0.123132,"Missing"
W19-5932,P18-1134,0,0.128035,"s to predict the slot value from a endogenously defined set of candidates have been proposed (Rastogi et al., 2017; Goel et al., 2018). In these methods, the candidates are derived from either a predefined ontology or by extraction of a word or n-grams in the prior dialog context. Previously, Perez and Liu (2017) also formulated state tracking as a machine reading comprehension problem. However, their model architecture used a memory network which is relatively complex and still assumes a fixed-set vocabulary. Perhaps, the most similar technique to our work is the pointer networks proposed by Xu and Hu (2018) wherein an attention-based mechanism is • We present the task of dialog state tracking as making three sequential decisions: i) a binary carryover decision by a simple slot carryover model ii) a slot type decision by a slot type model iii) a slot span decision by an attentive reading comprehension model. We show effectiveness of this approach. • We adopt recent progress in large pretrained contextual word embeddings, i.e., BERT (Devlin et al., 2018) into dialog state tracking, and get considerable improvement. • We show our proposed model outperforms more complex previously published methods"
W19-8608,N15-1124,0,0.0316596,"MT metrics such as BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005) are widely adopted for evaluating dialog generation. ROUGE (Lin and Hovy, 2003), which is also used for chatbot evaluation, is a popular metric for text summarization. These metrics primarily rely on token-level overlap over a corpus (also synonymy in the case of METEOR), and therefore are not well-suited for dialog generation since a valid conversational response may not have any token-level or even semantic-level overlap with the ground truths. While the shortcomings of these metrics are well known for MT (Graham, 2015; Espinosa et al., 2010), the problem is aggravated for dialog generation evaluation because of the much larger output space (Liu et al., 2016; Novikova et al., 2017). However, due to the lack of clear alternatives, these metrics are still widely used for evaluating response generation (Ritter et al., 2011; Lowe et al., 2017). To ensure comparability with other approaches, we report results on these metrics for our models. To tackle the shortcomings of automatic metrics, there have been efforts to build models to score conversations. Lowe et al. (2017) train a model to predict the score of a s"
W19-8608,P18-1152,0,0.0147094,"odies of work. Automatic Evaluation of Conversations: Improving System Response Generation: Seq2Seq models have allowed researchers to train dialog models without relying on handcrafted dialog acts and slot values. Using maximum mutual 66 information (MMI) (Li et al., 2015) was one of the earlier attempts to make conversational responses more diverse (Serban et al., 2016b,a). Shao et al. (2017) use a segment ranking beam search to produce more diverse responses. Our method extends the strategy employed by Shao et al. (2017) utilizing a trained model as the reranking function and is similar to Holtzman et al. (2018) but with different kind of trained model. More recently, there have been works which aim to alleviate this problem by incorporating conversation-specific rewards in the learning process. Yao et al. (2016) use the IDF value of generated sentences as a reward signal. Xing et al. (2017) use topics as an additional input while decoding to produce more specific responses. Li et al. (2016b) add personal information to make system responses more user specific.Li et al. (2017) use distillation to train different models at different levels of specificity and use reinforcement learning to pick the appr"
W19-8608,N16-1014,0,0.104965,"ersations. Lowe et al. (2017) train a model to predict the score of a system response given a dialog context. However, they work with tiny data sets (around 4000 sentences) in a non-spoken setting. Tao et al. (2017) address the expensive annotation process by adding in unsupervised data. However, their metric is not interpretable, and the results are also not shown on a spoken setting. Our work differs from the aforementioned works as the output of our system is interpretable at each dialog turn. There has also been work on building evaluation systems that focus on specific aspects of dialog. Li et al. (2016c) use features for information flow, Yu et al. (2016) use features for turn-level appropriateness. However, these metrics are based on a narrow aspect of the conversation and fail to capture broad ranges of phenomena that lead to a good dialog. Related Works There are two major themes in this work. The first is building evaluators that allow us to estimate human perceptions of coherence, topicality, and interestingness of responses in a conversational context. The second is the use of evaluators to guide the generation process. As a result, this work is related to two distinct bodies of work."
W19-8608,P16-1094,0,0.240321,"ersations. Lowe et al. (2017) train a model to predict the score of a system response given a dialog context. However, they work with tiny data sets (around 4000 sentences) in a non-spoken setting. Tao et al. (2017) address the expensive annotation process by adding in unsupervised data. However, their metric is not interpretable, and the results are also not shown on a spoken setting. Our work differs from the aforementioned works as the output of our system is interpretable at each dialog turn. There has also been work on building evaluation systems that focus on specific aspects of dialog. Li et al. (2016c) use features for information flow, Yu et al. (2016) use features for turn-level appropriateness. However, these metrics are based on a narrow aspect of the conversation and fail to capture broad ranges of phenomena that lead to a good dialog. Related Works There are two major themes in this work. The first is building evaluators that allow us to estimate human perceptions of coherence, topicality, and interestingness of responses in a conversational context. The second is the use of evaluators to guide the generation process. As a result, this work is related to two distinct bodies of work."
W19-8608,W05-0909,0,0.0867711,"compare various response generation systems or as a signal to improve response generation. Second, we experiment with two complementary ways to incorporate explicit feedback to the response generation systems and show improvement in dialog quality using automatic metrics as well as human evaluation. 2 Learning automatic evaluation of conversation quality has a long history (Walker et al., 1997). However, we still do not have widely accepted solutions. Due to the similarity between conversational response generation and MT, automatic MT metrics such as BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005) are widely adopted for evaluating dialog generation. ROUGE (Lin and Hovy, 2003), which is also used for chatbot evaluation, is a popular metric for text summarization. These metrics primarily rely on token-level overlap over a corpus (also synonymy in the case of METEOR), and therefore are not well-suited for dialog generation since a valid conversational response may not have any token-level or even semantic-level overlap with the ground truths. While the shortcomings of these metrics are well known for MT (Graham, 2015; Espinosa et al., 2010), the problem is aggravated for dialog generation"
W19-8608,J08-1001,0,0.0546675,"Missing"
W19-8608,D16-1127,0,0.166637,"ersations. Lowe et al. (2017) train a model to predict the score of a system response given a dialog context. However, they work with tiny data sets (around 4000 sentences) in a non-spoken setting. Tao et al. (2017) address the expensive annotation process by adding in unsupervised data. However, their metric is not interpretable, and the results are also not shown on a spoken setting. Our work differs from the aforementioned works as the output of our system is interpretable at each dialog turn. There has also been work on building evaluation systems that focus on specific aspects of dialog. Li et al. (2016c) use features for information flow, Yu et al. (2016) use features for turn-level appropriateness. However, these metrics are based on a narrow aspect of the conversation and fail to capture broad ranges of phenomena that lead to a good dialog. Related Works There are two major themes in this work. The first is building evaluators that allow us to estimate human perceptions of coherence, topicality, and interestingness of responses in a conversational context. The second is the use of evaluators to guide the generation process. As a result, this work is related to two distinct bodies of work."
W19-8608,N03-1020,0,0.305929,"tion. Second, we experiment with two complementary ways to incorporate explicit feedback to the response generation systems and show improvement in dialog quality using automatic metrics as well as human evaluation. 2 Learning automatic evaluation of conversation quality has a long history (Walker et al., 1997). However, we still do not have widely accepted solutions. Due to the similarity between conversational response generation and MT, automatic MT metrics such as BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005) are widely adopted for evaluating dialog generation. ROUGE (Lin and Hovy, 2003), which is also used for chatbot evaluation, is a popular metric for text summarization. These metrics primarily rely on token-level overlap over a corpus (also synonymy in the case of METEOR), and therefore are not well-suited for dialog generation since a valid conversational response may not have any token-level or even semantic-level overlap with the ground truths. While the shortcomings of these metrics are well known for MT (Graham, 2015; Espinosa et al., 2010), the problem is aggravated for dialog generation evaluation because of the much larger output space (Liu et al., 2016; Novikova"
W19-8608,D16-1230,0,0.0543629,"ROUGE (Lin and Hovy, 2003), which is also used for chatbot evaluation, is a popular metric for text summarization. These metrics primarily rely on token-level overlap over a corpus (also synonymy in the case of METEOR), and therefore are not well-suited for dialog generation since a valid conversational response may not have any token-level or even semantic-level overlap with the ground truths. While the shortcomings of these metrics are well known for MT (Graham, 2015; Espinosa et al., 2010), the problem is aggravated for dialog generation evaluation because of the much larger output space (Liu et al., 2016; Novikova et al., 2017). However, due to the lack of clear alternatives, these metrics are still widely used for evaluating response generation (Ritter et al., 2011; Lowe et al., 2017). To ensure comparability with other approaches, we report results on these metrics for our models. To tackle the shortcomings of automatic metrics, there have been efforts to build models to score conversations. Lowe et al. (2017) train a model to predict the score of a system response given a dialog context. However, they work with tiny data sets (around 4000 sentences) in a non-spoken setting. Tao et al. (201"
W19-8608,W15-4640,0,0.0276097,"Systems Lab, University of Trento syi@caltech.edu, goelrahul@google.com, {tagyoung,behnam,anuvenk,raeferg,hakkanit}@amazon.com, chdrak@uber.com, alessandra.cervone@unitn.it Abstract engage in more social conversations. Building systems that can have a general conversation in an open domain setting is a challenging problem, but it is an important step towards more natural humanmachine interactions. Recently, there has been significant interest in building chatbots (Sordoni et al., 2015; Wen et al., 2015) fueled by the availability of dialog data sets such as Ubuntu, Twitter, and Movie dialogs (Lowe et al., 2015; Ritter et al., 2011; Danescu-NiculescuMizil and Lee, 2011). However, as most chatbots are text-based, work on human-machine spoken dialog is relatively under-explored, partly due to lack of such dialog corpora. Spoken dialog poses additional challenges such as automatic speech recognition errors and divergence between spoken and written language. Sequence-to-sequence (seq2seq) models (Sutskever et al., 2014) and their extensions (Luong et al., 2015; Sordoni et al., 2015; Li et al., 2015), which are used for neural machine translation (MT), have been widely adopted for dialog generation syste"
W19-8608,D15-1166,0,0.0473276,"lding chatbots (Sordoni et al., 2015; Wen et al., 2015) fueled by the availability of dialog data sets such as Ubuntu, Twitter, and Movie dialogs (Lowe et al., 2015; Ritter et al., 2011; Danescu-NiculescuMizil and Lee, 2011). However, as most chatbots are text-based, work on human-machine spoken dialog is relatively under-explored, partly due to lack of such dialog corpora. Spoken dialog poses additional challenges such as automatic speech recognition errors and divergence between spoken and written language. Sequence-to-sequence (seq2seq) models (Sutskever et al., 2014) and their extensions (Luong et al., 2015; Sordoni et al., 2015; Li et al., 2015), which are used for neural machine translation (MT), have been widely adopted for dialog generation systems. In MT, given a source sentence, the correctness of the target sentence can be measured by semantic similarity to the source sentence. However, in open-domain conversations, a generic utterance such as “sounds good” could be a valid response to a large variety of statements. These seq2seq models are commonly trained on a maximum likelihood objective, which leads the models to place uniform importance on all user utterance and system response pairs"
W19-8608,marelli-etal-2014-sick,0,0.0223533,"o used similar NE features in their ranker. c) Concatenated last states of a BiLSTM (1 layer, 600 dim) The selected dimensions and network structures followed the original paper (Vaswani et al., 2017). All models were trained with a batch size of 400 using Adam optimizer with learning rate of 5e-4. To measure the sentence embedding quality, we evaluate our models on a few standard classification tasks. The models are used to get sentence representation, which are passed through feedforward networks that are trained for the following classification tasks: (i) Semantic Textual Similarity (STS) (Marelli et al., 2014), (ii) Question Type Classification (TREC) (Voorhees and Dang, 2003), (iii) Subjectivity Classification (SUBJ) (Pang and Lee, 2004). Table 1 shows the different models’ performances on these tasks. Based on this, we choose the Transformer as our sentence encoder as it was overall the best performing while being fast. 4.2 Features • Topic: We use a one-hot representation of a dialog turn topic predicted by a conversational topic model (Guo et al., 2017) that classifies a given dialog turn into one of 26 pre-defined classes like Sports and Movies. • Response Similarity: Cosine similarity between"
W19-8608,D17-1235,0,0.0199848,"perceptions of coherence, topicality, and interestingness of responses in a conversational context. The second is the use of evaluators to guide the generation process. As a result, this work is related to two distinct bodies of work. Automatic Evaluation of Conversations: Improving System Response Generation: Seq2Seq models have allowed researchers to train dialog models without relying on handcrafted dialog acts and slot values. Using maximum mutual 66 information (MMI) (Li et al., 2015) was one of the earlier attempts to make conversational responses more diverse (Serban et al., 2016b,a). Shao et al. (2017) use a segment ranking beam search to produce more diverse responses. Our method extends the strategy employed by Shao et al. (2017) utilizing a trained model as the reranking function and is similar to Holtzman et al. (2018) but with different kind of trained model. More recently, there have been works which aim to alleviate this problem by incorporating conversation-specific rewards in the learning process. Yao et al. (2016) use the IDF value of generated sentences as a reward signal. Xing et al. (2017) use topics as an additional input while decoding to produce more specific responses. Li e"
W19-8608,D17-2014,0,0.0213669,"are also used: features, e.g., dialog acts and topics as described in Section 4.3. We experiment with different ways to encode the responses (Section 4.1) as well as with different feature combinations (Figure 1). 4.1 • Dialog Act: Serban et al. (2017) show that dialog act (DA) features could be useful for response selection rankers. Following this, we use model (Khatri et al., 2018)-predicted DAs (Stolcke et al., 1998) of user utterances and system responses as an indicator feature. Sentence Embeddings We pretrained models that produce sentence embeddings using the ParlAI chitchat data set (Miller et al., 2017). We use the Quick-Thought (QT) loss (Logeswaran and Lee, 2018) to train the embeddings. Our word embeddings are initialized with FastText (Bojanowski et al., 2016) to capture the sub-word features and then fine-tuned. We encode sentences into embeddings using the following methods: • Entity Grid: Cervone et al. (2018); Barzilay and Lapata (2008) show that entities and DA transitions across turns can be strong features for assessing dialog coherence. Starting from a grid representation of the turns of the conversation as a matrix (DAs × entities), these features are designed to capture the pat"
W19-8608,N15-1020,0,0.0246778,"anities and Social Sciences, California Institute of Technology, 2 Google, 3 Uber AI, 5 Alexa AI, Amazon 4 Signals and Interactive Systems Lab, University of Trento syi@caltech.edu, goelrahul@google.com, {tagyoung,behnam,anuvenk,raeferg,hakkanit}@amazon.com, chdrak@uber.com, alessandra.cervone@unitn.it Abstract engage in more social conversations. Building systems that can have a general conversation in an open domain setting is a challenging problem, but it is an important step towards more natural humanmachine interactions. Recently, there has been significant interest in building chatbots (Sordoni et al., 2015; Wen et al., 2015) fueled by the availability of dialog data sets such as Ubuntu, Twitter, and Movie dialogs (Lowe et al., 2015; Ritter et al., 2011; Danescu-NiculescuMizil and Lee, 2011). However, as most chatbots are text-based, work on human-machine spoken dialog is relatively under-explored, partly due to lack of such dialog corpora. Spoken dialog poses additional challenges such as automatic speech recognition errors and divergence between spoken and written language. Sequence-to-sequence (seq2seq) models (Sutskever et al., 2014) and their extensions (Luong et al., 2015; Sordoni et al.,"
W19-8608,D17-1238,0,0.124888,"Missing"
W19-8608,P04-1035,0,0.0103618,"twork structures followed the original paper (Vaswani et al., 2017). All models were trained with a batch size of 400 using Adam optimizer with learning rate of 5e-4. To measure the sentence embedding quality, we evaluate our models on a few standard classification tasks. The models are used to get sentence representation, which are passed through feedforward networks that are trained for the following classification tasks: (i) Semantic Textual Similarity (STS) (Marelli et al., 2014), (ii) Question Type Classification (TREC) (Voorhees and Dang, 2003), (iii) Subjectivity Classification (SUBJ) (Pang and Lee, 2004). Table 1 shows the different models’ performances on these tasks. Based on this, we choose the Transformer as our sentence encoder as it was overall the best performing while being fast. 4.2 Features • Topic: We use a one-hot representation of a dialog turn topic predicted by a conversational topic model (Guo et al., 2017) that classifies a given dialog turn into one of 26 pre-defined classes like Sports and Movies. • Response Similarity: Cosine similarity between user utterance embedding and system response embedding is used as a feature. • Length: We use the token-level length of the user u"
W19-8608,P02-1040,0,0.103955,"system can be used independently to compare various response generation systems or as a signal to improve response generation. Second, we experiment with two complementary ways to incorporate explicit feedback to the response generation systems and show improvement in dialog quality using automatic metrics as well as human evaluation. 2 Learning automatic evaluation of conversation quality has a long history (Walker et al., 1997). However, we still do not have widely accepted solutions. Due to the similarity between conversational response generation and MT, automatic MT metrics such as BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005) are widely adopted for evaluating dialog generation. ROUGE (Lin and Hovy, 2003), which is also used for chatbot evaluation, is a popular metric for text summarization. These metrics primarily rely on token-level overlap over a corpus (also synonymy in the case of METEOR), and therefore are not well-suited for dialog generation since a valid conversational response may not have any token-level or even semantic-level overlap with the ground truths. While the shortcomings of these metrics are well known for MT (Graham, 2015; Espinosa et al., 2010), the probl"
W19-8608,D11-1054,0,0.263257,"sity of Trento syi@caltech.edu, goelrahul@google.com, {tagyoung,behnam,anuvenk,raeferg,hakkanit}@amazon.com, chdrak@uber.com, alessandra.cervone@unitn.it Abstract engage in more social conversations. Building systems that can have a general conversation in an open domain setting is a challenging problem, but it is an important step towards more natural humanmachine interactions. Recently, there has been significant interest in building chatbots (Sordoni et al., 2015; Wen et al., 2015) fueled by the availability of dialog data sets such as Ubuntu, Twitter, and Movie dialogs (Lowe et al., 2015; Ritter et al., 2011; Danescu-NiculescuMizil and Lee, 2011). However, as most chatbots are text-based, work on human-machine spoken dialog is relatively under-explored, partly due to lack of such dialog corpora. Spoken dialog poses additional challenges such as automatic speech recognition errors and divergence between spoken and written language. Sequence-to-sequence (seq2seq) models (Sutskever et al., 2014) and their extensions (Luong et al., 2015; Sordoni et al., 2015; Li et al., 2015), which are used for neural machine translation (MT), have been widely adopted for dialog generation systems. In MT, given a so"
W19-8608,H93-1012,0,0.0607284,"Missing"
W19-8608,P97-1035,0,0.634178,"versational encoding schemes to build a conversational evaluation system that can provide explicit turn-level feedback to a response generation system on the highly subjective task. This system can be used independently to compare various response generation systems or as a signal to improve response generation. Second, we experiment with two complementary ways to incorporate explicit feedback to the response generation systems and show improvement in dialog quality using automatic metrics as well as human evaluation. 2 Learning automatic evaluation of conversation quality has a long history (Walker et al., 1997). However, we still do not have widely accepted solutions. Due to the similarity between conversational response generation and MT, automatic MT metrics such as BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005) are widely adopted for evaluating dialog generation. ROUGE (Lin and Hovy, 2003), which is also used for chatbot evaluation, is a popular metric for text summarization. These metrics primarily rely on token-level overlap over a corpus (also synonymy in the case of METEOR), and therefore are not well-suited for dialog generation since a valid conversational response may n"
W19-8608,D15-1199,0,0.0493925,"Missing"
W19-8608,W16-3649,0,0.0185775,"t the score of a system response given a dialog context. However, they work with tiny data sets (around 4000 sentences) in a non-spoken setting. Tao et al. (2017) address the expensive annotation process by adding in unsupervised data. However, their metric is not interpretable, and the results are also not shown on a spoken setting. Our work differs from the aforementioned works as the output of our system is interpretable at each dialog turn. There has also been work on building evaluation systems that focus on specific aspects of dialog. Li et al. (2016c) use features for information flow, Yu et al. (2016) use features for turn-level appropriateness. However, these metrics are based on a narrow aspect of the conversation and fail to capture broad ranges of phenomena that lead to a good dialog. Related Works There are two major themes in this work. The first is building evaluators that allow us to estimate human perceptions of coherence, topicality, and interestingness of responses in a conversational context. The second is the use of evaluators to guide the generation process. As a result, this work is related to two distinct bodies of work. Automatic Evaluation of Conversations: Improving Syst"
W19-8608,P18-1102,0,0.0181227,"recently, there have been works which aim to alleviate this problem by incorporating conversation-specific rewards in the learning process. Yao et al. (2016) use the IDF value of generated sentences as a reward signal. Xing et al. (2017) use topics as an additional input while decoding to produce more specific responses. Li et al. (2016b) add personal information to make system responses more user specific.Li et al. (2017) use distillation to train different models at different levels of specificity and use reinforcement learning to pick the appropriate system response. Zhou et al. (2017) and Zhang et al. (2018) introduce latent factors in the seq2seq models that control specificity in neural response generation. There has been recent work which combines responses from multiple sub-systems (Serban et al., 2017; Papaioannou et al., 2017) and ranks them to output the final system response. Our method complements these approaches by introducing a novel learned-estimator model as the additional reward signal. 3 erally are much longer (mean: 23.2 tokens). 3.1 Annotations Asking annotators to measure coherence and engagement directly is a time-consuming task. We observed that we could collect data much fas"
W19-8608,P09-2025,0,\N,Missing
W19-8608,W11-0609,0,\N,Missing
W19-8608,D17-1237,0,\N,Missing
W19-8608,P17-1103,0,\N,Missing
W19-8657,P17-1162,0,0.0261827,"orecast (Liang et al., 2009) with few exceptions (Lebret et al., 2016). In the literature for QA, most approaches retrieve answers directly or generate answers jointly with the retrieval, and answers are usually entities or lists of entities (Dodge et al., 2015). On the contrary, in NLG we assume the answer has already been retrieved, and the goal is to generate text matching it. The field of QA which most strictly relates to our work is answer generation, where current approaches are also based on encoder-decoder networks encoding information directly from a knowledge base (Yin et al., 2016; He et al., 2017; Wei and Zhang, 2019). An additional challenge to answer generation is that there are no publicly available datasets for this task (Fu and Feng, 2018). Our approach differs from answer generation in that we structure the task as in NLG dialog literature with a MR-to-text approach. 3 Size 51k 5k 6k 16k 67k Datasets Question Answering Source data Our source for generating the MRtext pairs are thousands of open-domain factual question-answer pairs from commercial data. The domains covered in this data are manifold, including geography (e.g. ‘is canada bigger than united states’ in Table 7), hist"
W19-8657,N18-1014,0,0.196329,"nificantly in terms of naturalness of generated text and efficiency in encoding the MR information (i.e. Slot Error Rate). Interestingly, we find it improves for some of the human evaluation metrics. We also observe that using conversational context improves the quality of generated responses. In our second set of experiments, we investigate whether jointly training NLG models for task-oriented dialog and QA improves performances. To this end, we experiment with learning NLG models in a multi-task setting between NLG for dialog State of the art NLG models for dialog (Dušek and Jurcıcek, 2016; Juraska et al., 2018) mostly use end-to-end neural EncoderDecoder approaches with attention (Bahdanau et al., 2014) and re-ranking (Dušek et al., 2018). Ensembling is another technique employed to boost model performance (Juraska et al., 2018). Using delexicalization (Henderson et al., 2014), i.e., the process of substituting slot values with slot types in the generated text, has also shown improvements in many settings. However, recent work also depicted the disadvantages of delexicalization (Nayak et al., 2017). In our work, we compare and combine both delixecalized and lexicalized inputs for the NLG system. 454"
W19-8657,P19-1080,0,0.0700791,"boost model performance (Juraska et al., 2018). Using delexicalization (Henderson et al., 2014), i.e., the process of substituting slot values with slot types in the generated text, has also shown improvements in many settings. However, recent work also depicted the disadvantages of delexicalization (Nayak et al., 2017). In our work, we compare and combine both delixecalized and lexicalized inputs for the NLG system. 454 NLG for dialog has been mostly tested in controlled environments using task-oriented, single domain datasets with limited ontologies (Wen et al., 2015; Novikova et al., 2017; Balakrishnan et al., 2019). Although Wen et al. (2016) perform multi-domain task-oriented NLG experiments, the ontologies used are still limited for such settings. Finally, while research has shown how encoding the previous utterance leads to better performances (Dušek and Jurcicek, 2016), most settings consider the turns in isolation (Wen et al., 2015; Novikova et al., 2017). In our work, we perform open-domain NLG with significantly larger ontologies and also evaluate the impact of adding the context to the input. E2E SFX QA.1 QA.2 QA.3 3.1 Slots 8 12 147 210 369 DAs 1 8 1 1 1 Words 2453 438 702 1528 2963 Domain rest"
W19-8657,D16-1128,0,0.0516899,"Missing"
W19-8657,W16-3622,0,0.0841612,"azon Alexa AI. ‡ s Work done while working at Amazon Alexa AI. 453 Proceedings of The 12th International Conference on Natural Language Generation, pages 453–462, c Tokyo, Japan, 28 Oct - 1 Nov, 2019. 2019 Association for Computational Linguistics our QA data and SFX. Our experiments show that learning models in a multi-task setting lead to better performances in terms of naturalness of the generated output for both tasks. This work has several contributions: versational context, even though the previous utterances in the dialog have been shown to improve the performance of task-oriented NLG (Dušek and Jurcicek, 2016). These characteristics of current approaches to NLG can be linked to the fact that a vast majority of dialog NLG research is tested on a single domain where the dialog agent performs simple tasks such as giving information about a restaurant, with few exceptions (Wen et al., 2016). 1. We apply the MR-to-text framework (typical of NLG for task-oriented dialog) to a opendomain QA application. 2. We explore the importance of adding the previous conversational context to improve the quality of the generated output. However, with the rise of conversational agents such as Amazon Alexa and Google As"
W19-8657,P09-1011,0,0.0167049,"e question “when was kentucky founded” can be “1792” or “kentucky formed in 1792”. This shows an interesting difference between our QA data and task-oriented NLG datasets. While for task-oriented NLG all valid responses for a single MR have the same slot types (i.e., the ones in the input MR), in our dataset this is not always true. NLG for text and QA Recent work around NLG for text involves generating text using structured data using the encoder-decoder networks (Mei et al., 2016). Similarly to dialog, NLG for text has also been addressed in controlled environments such as weather forecast (Liang et al., 2009) with few exceptions (Lebret et al., 2016). In the literature for QA, most approaches retrieve answers directly or generate answers jointly with the retrieval, and answers are usually entities or lists of entities (Dodge et al., 2015). On the contrary, in NLG we assume the answer has already been retrieved, and the goal is to generate text matching it. The field of QA which most strictly relates to our work is answer generation, where current approaches are also based on encoder-decoder networks encoding information directly from a knowledge base (Yin et al., 2016; He et al., 2017; Wei and Zha"
W19-8657,P16-2008,0,0.112265,"mance does not degrade significantly in terms of naturalness of generated text and efficiency in encoding the MR information (i.e. Slot Error Rate). Interestingly, we find it improves for some of the human evaluation metrics. We also observe that using conversational context improves the quality of generated responses. In our second set of experiments, we investigate whether jointly training NLG models for task-oriented dialog and QA improves performances. To this end, we experiment with learning NLG models in a multi-task setting between NLG for dialog State of the art NLG models for dialog (Dušek and Jurcıcek, 2016; Juraska et al., 2018) mostly use end-to-end neural EncoderDecoder approaches with attention (Bahdanau et al., 2014) and re-ranking (Dušek et al., 2018). Ensembling is another technique employed to boost model performance (Juraska et al., 2018). Using delexicalization (Henderson et al., 2014), i.e., the process of substituting slot values with slot types in the generated text, has also shown improvements in many settings. However, recent work also depicted the disadvantages of delexicalization (Nayak et al., 2017). In our work, we compare and combine both delixecalized and lexicalized inputs"
W19-8657,D15-1166,0,0.0312507,"), we report different types of Slot Error Rate (SER). In dialog NLG approaches SER shows the number of correct slots in the output compared to the input MR. We refer to this metric as SERmr to differentiate it from its modified versions we introduce next. The formula (Wen et al., 2015) is: Encoder-Decoder with Attention Following recent state-of-the-art approaches to NLG for dialog (Juraska et al., 2018; Balakrishnan et al., 2019), our models are based on the EncoderDecoder with Attention framework. In particular, we use bidirectional Gated Recurrent Units (GRU) and Luong general attention (Luong et al., 2015) as our baseline. While we also experimented with other types of architectures, such as using Long-Short-Term Memory Units (Hochreiter and Schmidhuber, 1997) instead of GRUs and different types of attention (including Bahdanau attention (Bahdanau et al., 2014) and Luong dot attention (Luong et al., 2015), this combination gave us the best results for our setting. Depending on the encoder used, either slot type or slot value, we refer to this model as Enc MR (slot types) or Enc MR (slot values). SERmr = (1) where Nmr is the total number of slots in the input MR and pmr , qmr are respectively th"
W19-8657,W18-6539,0,0.0121424,"ngly, we find it improves for some of the human evaluation metrics. We also observe that using conversational context improves the quality of generated responses. In our second set of experiments, we investigate whether jointly training NLG models for task-oriented dialog and QA improves performances. To this end, we experiment with learning NLG models in a multi-task setting between NLG for dialog State of the art NLG models for dialog (Dušek and Jurcıcek, 2016; Juraska et al., 2018) mostly use end-to-end neural EncoderDecoder approaches with attention (Bahdanau et al., 2014) and re-ranking (Dušek et al., 2018). Ensembling is another technique employed to boost model performance (Juraska et al., 2018). Using delexicalization (Henderson et al., 2014), i.e., the process of substituting slot values with slot types in the generated text, has also shown improvements in many settings. However, recent work also depicted the disadvantages of delexicalization (Nayak et al., 2017). In our work, we compare and combine both delixecalized and lexicalized inputs for the NLG system. 454 NLG for dialog has been mostly tested in controlled environments using task-oriented, single domain datasets with limited ontolog"
W19-8657,N16-1086,0,0.0288433,"e source data are varied, and range from a simple entity to a fully formed answer, as in Table 1 example where valid answers to the question “when was kentucky founded” can be “1792” or “kentucky formed in 1792”. This shows an interesting difference between our QA data and task-oriented NLG datasets. While for task-oriented NLG all valid responses for a single MR have the same slot types (i.e., the ones in the input MR), in our dataset this is not always true. NLG for text and QA Recent work around NLG for text involves generating text using structured data using the encoder-decoder networks (Mei et al., 2016). Similarly to dialog, NLG for text has also been addressed in controlled environments such as weather forecast (Liang et al., 2009) with few exceptions (Lebret et al., 2016). In the literature for QA, most approaches retrieve answers directly or generate answers jointly with the retrieval, and answers are usually entities or lists of entities (Dodge et al., 2015). On the contrary, in NLG we assume the answer has already been retrieved, and the goal is to generate text matching it. The field of QA which most strictly relates to our work is answer generation, where current approaches are also b"
W19-8657,N18-1017,0,0.0198963,"ate answers jointly with the retrieval, and answers are usually entities or lists of entities (Dodge et al., 2015). On the contrary, in NLG we assume the answer has already been retrieved, and the goal is to generate text matching it. The field of QA which most strictly relates to our work is answer generation, where current approaches are also based on encoder-decoder networks encoding information directly from a knowledge base (Yin et al., 2016; He et al., 2017; Wei and Zhang, 2019). An additional challenge to answer generation is that there are no publicly available datasets for this task (Fu and Feng, 2018). Our approach differs from answer generation in that we structure the task as in NLG dialog literature with a MR-to-text approach. 3 Size 51k 5k 6k 16k 67k Datasets Question Answering Source data Our source for generating the MRtext pairs are thousands of open-domain factual question-answer pairs from commercial data. The domains covered in this data are manifold, including geography (e.g. ‘is canada bigger than united states’ in Table 7), history (e.g. ‘when was kentucky founded’ in Table 1), present-day QA NLG datasets We generate the NLG inputoutput pairs for QA from our source data. In or"
W19-8657,C18-1300,1,0.849803,"., 2015)) and a Question-Answering (QA) dataset. In NLG the input is typically a Meaning Representation (MR) and the output is its textual realization (Text). Each MR is composed of a Dialog Act (bold) and a list of slot type (italic)-value pairs. Compared to most NLG datasets, our QA corpus also has the previous question (context) as input. While in the task-oriented setting we observe a one-to-one relation between slots in the input and the ones realized in the text, the same is not true for QA. sisting of a Dialog Act (DA) and a list of associated slots. While the DA (Stolcke et al., 2000; Mezza et al., 2018) expresses the intent of the utterance to be generated (e.g. “inform” in Table 1), the slots, organized as slot type-slot value pairs (e.g. food:‘french’ in Table 1), represent the information which has to be conveyed in the generated text. So far statistical NLG for dialog has mainly been investigated in research for task-oriented applications (e.g. restaurant reservation, bus information) in narrow, controlled environments with limited ontologies, i.e. considering a small set of DAs and slot types (respectively 12 and 8 in the popular San Francisco restaurant dataset (SFX) (Wen et al., 2015)"
W19-8657,W17-5525,0,0.0628973,"e generated (e.g. “inform” in Table 1), the slots, organized as slot type-slot value pairs (e.g. food:‘french’ in Table 1), represent the information which has to be conveyed in the generated text. So far statistical NLG for dialog has mainly been investigated in research for task-oriented applications (e.g. restaurant reservation, bus information) in narrow, controlled environments with limited ontologies, i.e. considering a small set of DAs and slot types (respectively 12 and 8 in the popular San Francisco restaurant dataset (SFX) (Wen et al., 2015), 8 and 1 in the recent E2E NLG challenge (Novikova et al., 2017)). Furthermore, most datasets consider MRs in isolation (Novikova et al., 2017) i.e., they lack conIntroduction In dialog literature Natural Language Generation (NLG) is framed as the task of generating natural language responses that faithfully convey the semantic information given by a Meaning Representation (MR). A MR is typically a structure con∗ s Work done during internship at Amazon Alexa AI. † s Work done while working at Amazon Alexa AI. ‡ s Work done while working at Amazon Alexa AI. 453 Proceedings of The 12th International Conference on Natural Language Generation, pages 453–462, c"
W19-8657,P19-1596,0,0.0278234,"Missing"
W19-8657,J00-3003,0,0.106286,"Missing"
W19-8657,N16-1015,0,0.0934673,"that learning models in a multi-task setting lead to better performances in terms of naturalness of the generated output for both tasks. This work has several contributions: versational context, even though the previous utterances in the dialog have been shown to improve the performance of task-oriented NLG (Dušek and Jurcicek, 2016). These characteristics of current approaches to NLG can be linked to the fact that a vast majority of dialog NLG research is tested on a single domain where the dialog agent performs simple tasks such as giving information about a restaurant, with few exceptions (Wen et al., 2016). 1. We apply the MR-to-text framework (typical of NLG for task-oriented dialog) to a opendomain QA application. 2. We explore the importance of adding the previous conversational context to improve the quality of the generated output. However, with the rise of conversational agents such as Amazon Alexa and Google Assistant, there is an increasing interest in complex multidomain tasks. These systems typically rely on hand-crafted NLG, but this approach cannot scale to the complex ontologies which may be required in real-world applications (e.g. booking a trip). 3. We investigate the possibilit"
W19-8657,D15-1199,0,0.0846688,"Missing"
W19-8657,W16-0106,0,0.0318929,"such as weather forecast (Liang et al., 2009) with few exceptions (Lebret et al., 2016). In the literature for QA, most approaches retrieve answers directly or generate answers jointly with the retrieval, and answers are usually entities or lists of entities (Dodge et al., 2015). On the contrary, in NLG we assume the answer has already been retrieved, and the goal is to generate text matching it. The field of QA which most strictly relates to our work is answer generation, where current approaches are also based on encoder-decoder networks encoding information directly from a knowledge base (Yin et al., 2016; He et al., 2017; Wei and Zhang, 2019). An additional challenge to answer generation is that there are no publicly available datasets for this task (Fu and Feng, 2018). Our approach differs from answer generation in that we structure the task as in NLG dialog literature with a MR-to-text approach. 3 Size 51k 5k 6k 16k 67k Datasets Question Answering Source data Our source for generating the MRtext pairs are thousands of open-domain factual question-answer pairs from commercial data. The domains covered in this data are manifold, including geography (e.g. ‘is canada bigger than united states’"
