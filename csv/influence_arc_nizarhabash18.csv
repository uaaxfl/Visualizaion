2003.mtsummit-papers.20,J93-2003,0,0.00485042,"anish surface to English lexeme pairs is used with a unigram language model to resolve any ambiguity. This system is considered the baseline. Systran (SYST): This is a commercial Transferbased (purely symbolic) MT system. The version used is Systran Spanish-English Professional edition with four translation glossaries (Political Science, Military Science, Legal and Business/Economics).4 Systran’s Spanish-English has been developed over several hundred person-years and is considered here the industry standard of Spanish-English MT. IBM Model 4 (IBM4): This is a primarily statistical MT system (Brown et al., 1993). The translation model was trained using Giza (Al-Onaizan et al., 1999) on 50,000 Spanish-English sentence pairs from the UN Spanish-English corpus (Graff, 1994). Simple tokenization was used and consisted of down-casing all words and separating all punctuation marks. The language model is built from the English side of the training data in addition to 450,000 sentences from the English side of the Arabic-English UN corpus (Jinxi, 2002). Decoding is done using ISI ReWrite Decoder (Germann and Marcu, 2000).5 Matador (MTDR): All of the system’s modules described earlier are used. The Structural"
2003.mtsummit-papers.20,habash-2000-oxygen,1,0.803575,"e model that is based on structural relations between lexemes. This is different from the last step (Statistical Ranking) in three ways: (1) it is structural not wordorder-based, (2) it is based on lexemes not final surface forms, and (3) its effect is only seen on lexical selection whereas the n-gram statistical ranking determines both lexical selection and linearization. Next is the linearization step, where a rule-based grammar is used to create a word lattice that encodes the different possible realizations of the sentence. The grammar is implemented using the linearization engine oxyGen (Habash, 2000). Finally, the word lattice is converted into a Halogen-compatible forest to be ranked with Halogen’s Statistical Forest Ranker (Langkilde, 2000). Further details on generation in GHMT are provided in (Habash, 2002) and (Habash and Dorr, 2002). Matador. For purposes of comparison, four systems are evaluated using test sets from three corpora with different genre. The evaluation metric used is Bleu (BiLingual Evaluation Understudy) (Papineni et al., 2001). Bleu is a method of automatic translation evaluation that is quick, inexpensive and language independent. The Bleu score is basically an N-g"
2003.mtsummit-papers.20,W02-2125,1,0.845256,"Abstract This paper describes and evaluates Matador, an implemented large-scale Spanish-English MT system built in the Generation-Heavy Hybrid Machine Translation (GHMT) approach. An extensive evaluation shows that Matador has a higher degree of robustness and superior output quality, in terms of grammaticality and accuracy, when compared to a primarily statistical approach. 1 Introduction 2 Overview of Matador This paper describes and evaluates Matador, an implemented large-scale Spanish-English MT system built in the Generation-Heavy Hybrid Machine Translation (GHMT) approach introduced in (Habash, 2002; Habash and Dorr, 2002). GHMT is an asymmetrical hybrid approach that addresses the issue of MT resource poverty in source-poor/target-rich language pairs by exploiting symbolic and statistical target-language (TL) resources. Expected source-language (SL) resources include a syntactic parser and a simple one-to-many translation dictionary. No transfer rules or complex interlingual representations are used. Rich TL symbolic resources such as word lexical semantics, categorial variations and subcategorization frames are used to overgenerate multiple structural variations from a TL-glossed synta"
2003.mtsummit-papers.20,habash-dorr-2002-handling,1,0.917593,"paper describes and evaluates Matador, an implemented large-scale Spanish-English MT system built in the Generation-Heavy Hybrid Machine Translation (GHMT) approach. An extensive evaluation shows that Matador has a higher degree of robustness and superior output quality, in terms of grammaticality and accuracy, when compared to a primarily statistical approach. 1 Introduction 2 Overview of Matador This paper describes and evaluates Matador, an implemented large-scale Spanish-English MT system built in the Generation-Heavy Hybrid Machine Translation (GHMT) approach introduced in (Habash, 2002; Habash and Dorr, 2002). GHMT is an asymmetrical hybrid approach that addresses the issue of MT resource poverty in source-poor/target-rich language pairs by exploiting symbolic and statistical target-language (TL) resources. Expected source-language (SL) resources include a syntactic parser and a simple one-to-many translation dictionary. No transfer rules or complex interlingual representations are used. Rich TL symbolic resources such as word lexical semantics, categorial variations and subcategorization frames are used to overgenerate multiple structural variations from a TL-glossed syntactic dependency represen"
2003.mtsummit-papers.20,N03-1013,1,0.818114,"ion is accomplished through a simple word replacement algorithm. Matching is done using the word and POS. If the word-POS pair is not available, the translation algorithm attempts to back off to a union of all the translations of the word for all available parts of speech. 5 Exerge: Expansive Rich Generation for English Exerge is a reusable GHMT generation component for translating from other languages into English. 5.1 Exerge Resources Exerge utilizes three symbolic and two statistical English resources. The symbolic resources include the wordclass lexicon, the categorial variation database (Habash and Dorr, 2003) and the syntactic thematic linking map. 2. Spanish-English word-lists from freedict.com, Statistical resources include a surface n-gram model and spanish.about.com and the web site of the freely a structural n-gram model. 1 available multilingual dictionary Ergane. . The first of the symbolic resources is the word3. A Spanish-English word list of abbreviations exclass lexicon, which defines verbs and prepositions in tracted from a part of the UN parallel corpus (none terms of their subcategorization frames and lexical conof the testing set used later was included). ceptual primitives. A singl"
2003.mtsummit-papers.20,C90-3030,0,0.0157461,"ariants of (2) are expansively created using lexical semantic information and other English-specific heavy resources. The following are only a few of these variants: EXERGE Surface N−grams Linearization Lexical/Structural Selection Structural N−grams Spanish Dependency English Lexemes Syntactic Assignment Spanish Dependency Spanish Lexemes Structural Expansion Spanish Sentence Thematic Linking Restructuring Translation Analysis ... ... ... ... ... ... Linearization English Sentences Figure 1: Matador: Spanish-English Generation-Heavy Machine Translation (3) system based on Constraint Grammar (Karlsson, 1990). Connexor’s output is a functional dependency that is somewhat incompatible with the input expected by Exerge. On the one hand, the functional dependencies for Spanish include thematic relations such as location and instrument. These relations are specified directly between a verb and its object regardless of the existence of a preposition. In this aspect, Connexor’s output is deeper than what Exerge expects. On the other hand, some features closer to the surface form are kept such as complex verb chains signifying passivization. Other problems with parsing with Connexor include its The first"
2003.mtsummit-papers.20,A00-2023,0,0.202257,"stical language model. The overgenerated variants score higher than direct word translations, e.g., the topranked output in this example is Maria buttered the bread. (5) Maria buttered the bread -47.0841 Maria Maria Maria Maria Maria Maria butters the bread breaded the butter breads the butter buttered the loaf butters the loaf put the butter on bread -47.2994 -48.7334 -48.835 -51.3784 -51.5937 -54.128 Matador uses some off-the-shelf components, namely the Connexor Spanish parser for analysis (Tapanainen and Jarvinen, 1997) and the Halogen Forest Ranker for surface N-gram ranking (in Exerge) (Langkilde, 2000). All other components were created or extracted as part of this research. An online-demo of Matador is available at http://clipdemos.umiacs.umd.edu/matador/. 3 Analysis Spanish analysis in Matador utilizes the Connexor parser (Tapanainen and Jarvinen, 1997), a symbolically driven rest of this section focuses on four specific phenomena: auxiliary verb chains, reflexive clitic “se”, depassivization and pro drop restoration. First, auxiliary verb chains are replaced with the features they specify such as perfect/progressive aspect or passive voice. For example, the auxiliary estar and the verb p"
2003.mtsummit-papers.20,1983.tc-1.13,0,0.385103,"Missing"
2003.mtsummit-papers.20,2001.mtsummit-papers.68,0,0.152165,"ic overgeneration accounts for possible translation divergences, cases where the underlying concept or “gist” of a sentence is distributed differently in two languages such as to put butter and to butter (Dorr, 1993). The overgeneration is constrained by multiple statistical TL models including surface n-grams and structural n-grams. The source-target asymmetry of systems developed in this approach makes them more easily retargetable to new source languages (provided a SL parser and translation dictionary). An evaluation of Matador’s translation quality is conducted using the IBM Bleu metric (Papineni et al., 2001) and comparing against three systems—simple gisting, primarily statistical (IBM Model 4) and purely symbolic (Systran)—over three corpora (UN, FBIS and Bible). The evaluation shows that although Matador scores lower than IBM Model 4 on the corpus where all language models were trained (UN), Matador has a higher degree of robustness and scores higher when tested on text with new genre (Bible). Additionally, the evaluation shows that Matador’s output quality, in terms of grammaticality and accuracy, is superior to IBM Model 4. The next section is an overview of Matador. This is followed by three"
2003.mtsummit-papers.20,A97-1011,0,0.0166661,"reads breaded) the (OR butter The bilberry))) These different sequences are then ranked using a statistical language model. The overgenerated variants score higher than direct word translations, e.g., the topranked output in this example is Maria buttered the bread. (5) Maria buttered the bread -47.0841 Maria Maria Maria Maria Maria Maria butters the bread breaded the butter breads the butter buttered the loaf butters the loaf put the butter on bread -47.2994 -48.7334 -48.835 -51.3784 -51.5937 -54.128 Matador uses some off-the-shelf components, namely the Connexor Spanish parser for analysis (Tapanainen and Jarvinen, 1997) and the Halogen Forest Ranker for surface N-gram ranking (in Exerge) (Langkilde, 2000). All other components were created or extracted as part of this research. An online-demo of Matador is available at http://clipdemos.umiacs.umd.edu/matador/. 3 Analysis Spanish analysis in Matador utilizes the Connexor parser (Tapanainen and Jarvinen, 1997), a symbolically driven rest of this section focuses on four specific phenomena: auxiliary verb chains, reflexive clitic “se”, depassivization and pro drop restoration. First, auxiliary verb chains are replaced with the features they specify such as perfe"
2003.mtsummit-systems.8,habash-2000-oxygen,1,0.827073,"t the last two are rameters. The max conflation and max inflation paramemuch different. ters are integers. If thematic linking is turned off (option In the linearization step, the dependency trees in (3) No), then Matador becomes a dependency gister. The are converted into a word lattice compressing multiple Spanish parse tree is not modified and is treated as if it possible sentences: A rule-based grammar is used to crewas an English parse tree in generation. All other paramate the word lattice. The grammar is implemented using eters are ignored in such case. the linearization engine oxyGen (Habash, 2000). If the structural expansion parameter is turned off and (4) (OR (SEQ Maria (OR puts put) the (OR butter thematic linking is on, then the Spanish parse tree will be bilberry) (OR on into) (OR bread loaf)) converted into a thematic dependency but no conflations (SEQ Maria (OR lays laid) the (OR butter or inflations are allowed. When the structural expansion bilberry) (OR at into) (OR bread loaf)) parameter is turned on, the maximally allowable number (SEQ Maria (OR butters buttered) the (OR bread loaf)) of conflations or inflations is specified by the max con(SEQ Maria (OR breads breaded) the"
2003.mtsummit-systems.8,W02-2125,1,0.854122,"Missing"
2003.mtsummit-systems.8,habash-dorr-2002-handling,1,0.836276,"Demonstration Matador: Spanish-English GHMT Nizar Habash Institute for Advanced Computer Studies University of Maryland College Park, MD 20740 habash@umiacs.umd.edu http://umiacs.umd.edu/labs/CLIP Abstract This paper presents the online demo of Matador, a large-scale Spanish-English machine translation system implemented following the Generation-heavy Hybrid Machine Translation (GHMT) approach. 1 Introduction 2 Overview of Matador Matador is a Spanish-English machine translation (MT) system implemented following the Generation-heavy Hybrid approach to Machine Translation (GHMT) (Habash, 2002; Habash and Dorr, 2002). The focus of GHMT is addressing resource poverty in MT by exploiting symbolic and statistical target language resources in source-poor/target-rich language pairs. Expected source language resources include a syntactic parser and a simple one-to-many translation dictionary. No transfer rules, complex interlingual representations or parallel corpora are used. Rich target language symbolic resources such as word lexical semantics, categorial variations and subcategorization frames are used to overgenerate multiple structural variations from a target-glossed syntactic dependency representation o"
2003.mtsummit-systems.8,A00-2023,0,0.0293493,")) of conflations or inflations is specified by the max con(SEQ Maria (OR breads breaded) the (OR butter flation and max inflation parameters. bilberry))) The structural n-gram pruning parameter controls whether structural n-grams are used to do lexical selecThese different sequences are then ranked using a tion over the generated parse trees. The purpose of strucstatistical language model. Matador uses an off-thetural n-gram pruning is to constrain the overgeneration of shelf component for this step: Halogen’s Statistical Forthe previous steps using a language model that is based est Ranker (Langkilde, 2000). The overgenerated varion structural relations between lexemes. This is different ants score higher than direct word translations, e.g., the from the Halogen language model in that it is structural top-ranked output in this example is Maria buttered the not word-order-based and in that it is based on lexemes bread. not final surface forms. The structural n-gram language (5) Maria buttered the bread -47.0841 model was created using 127,000 parsed sentences from Maria butters the bread -47.2994 the English side of the Spanish-English (Graff, 1994) and Maria breaded the butter -48.7334 Arabic-En"
2003.mtsummit-systems.8,W02-2103,0,0.018409,"side of the Spanish-English (Graff, 1994) and Maria breaded the butter -48.7334 Arabic-English (Jinxi, 2002) UN corpus covering over 3 Maria breads the butter -48.835 Maria buttered the loaf -51.3784 million words. The model is limited to bigrams. Figure 2: Matador Online Demo Diacritized Character a´ e´ ´i o´ u´ n˜ u¨ Table 1: Explicit Diacritics Explicitly Dia- Diacritized critized Charac- Character ter ´ A a’ ´ e’ E ´I i’ ´ o’ O ´ u’ U ˜ N n ¨ U u” 3.3 Halogen Options The interface allows the user to control two parameters to the surface N-gram ranking component implemented using Halogen (Langkilde-Geary, 2002). First, the language model can be selected as either the UN language model or Halogen News model. The UN language model is built from 500,000 sentences from the English side of the Spanish-English (Graff, 1994) and Arabic-English (Jinxi, 2002) UN corpus. The Halogen news model was provided as part of the Halogen package. It is trained on 250 million words from various news sources such as the Wall Street Journal and AP Newswire. Both language models were created using the CMU Statistical Toolkit (Clarkson and Rosenfeld, 1997). Besides the difference in genre and size, the UN language model wa"
2003.mtsummit-systems.8,A97-1011,0,0.0412828,"t requires very expensive resources on top of syntactic parsers, and (b) Statistical MT, which requires very large parallel corpora (possibly annotated) that are hard to obtain for most languages too. 2 A more detailed discussion of Matador including an extensive evaluation has been submitted to this conference’s main session. (1) (puso :subj Maria :obj (mantequilla :mod la) :mod (en :obj (pan :mod el))) This dependency tree specifies that Maria is the subject of the verb puso and that mantequilla is the object. Parsing in Matador is implemented using the off-theshelf Connexor Spanish parser (Tapanainen and Jarvinen, 1997). In the translation step, each of the Spanish words in the dependency tree are mapped into sets of English words: (2) ((lay locate place put render set stand) :subj Maria :obj ((butter bilberry) :mod the) :mod ((on in into at) :obj ((bread loaf) :mod the))) During generation, different variants of the dependency tree are expansively created using lexical semantic EXERGE Surface N−grams Linearization Lexical/Structural Selection Structural N−grams Spanish Dependency English Lexemes Syntactic Assignment Spanish Dependency Spanish Lexemes Structural Expansion Spanish Sentence Thematic Linking Re"
2003.mtsummit-systems.9,P00-1059,0,0.012259,"., 2002; Dorr et al., 2000; Resnik, 1999; Hearst, 1998). WordNet is the most well-developed and widely used lexical database of English (Fellbaum, 1998). In WordNet, both types of lexical relations are specified among words with the same part of speech (verbs, nouns, adjectives and adverbs). WordNet has been used by many researchers for different purposes ranging from the construction or extension of knowledge bases such as SENSUS (Knight and Luk, 1994) or the Lexical Conceptual Structure Verb Database (LVD) (Green et al., 2001) to the faking of meaning ambiguity as part of system evaluation (Bangalore and Rambow, 2000). In the context of these projects, one criticism of WordNet is its lack of cross-categorial links, such as verb-noun or noun-adjective relations. Mel’ˇcuk approaches lexical relations by defining a lexical combinatorial zone that specifies semantically related lexemes through Lexical Functions (LF). These functions define a correspondence between a key lexical item and a set of related lexical items (Mel’ˇcuk, 1988). There are two types of functions: paradigmatic and syntagmatic (Ramos et al., 1994). Paradigmatic LFs associate a lexical item with related lexical items. The relation can be sem"
2003.mtsummit-systems.9,dorr-etal-2000-building,1,0.840179,"(Habash and Dorr, 2003). The CatVar is web-browseable at http://clipdemos.umiacs.umd.edu/catvar/. 2 Background Lexical relations describe relative relationships among different lexemes. Lexical relations are either hierarchical taxonomic relations (such as hypernymy, hyponymy and entailments) or nonhierarchical congruence relations (such as identity, overlap, synonymy and antonymy) (Cruse, 1986). Resources specifying the relations among lexical items such as WordNet (Fellbaum, 1998) and HowNet (Dong, 2000) (among others) have inspired the work of many researchers in NLP (Carpuat et al., 2002; Dorr et al., 2000; Resnik, 1999; Hearst, 1998). WordNet is the most well-developed and widely used lexical database of English (Fellbaum, 1998). In WordNet, both types of lexical relations are specified among words with the same part of speech (verbs, nouns, adjectives and adverbs). WordNet has been used by many researchers for different purposes ranging from the construction or extension of knowledge bases such as SENSUS (Knight and Luk, 1994) or the Lexical Conceptual Structure Verb Database (LVD) (Green et al., 2001) to the faking of meaning ambiguity as part of system evaluation (Bangalore and Rambow, 2000"
2003.mtsummit-systems.9,P01-1032,1,0.829252,"2000) (among others) have inspired the work of many researchers in NLP (Carpuat et al., 2002; Dorr et al., 2000; Resnik, 1999; Hearst, 1998). WordNet is the most well-developed and widely used lexical database of English (Fellbaum, 1998). In WordNet, both types of lexical relations are specified among words with the same part of speech (verbs, nouns, adjectives and adverbs). WordNet has been used by many researchers for different purposes ranging from the construction or extension of knowledge bases such as SENSUS (Knight and Luk, 1994) or the Lexical Conceptual Structure Verb Database (LVD) (Green et al., 2001) to the faking of meaning ambiguity as part of system evaluation (Bangalore and Rambow, 2000). In the context of these projects, one criticism of WordNet is its lack of cross-categorial links, such as verb-noun or noun-adjective relations. Mel’ˇcuk approaches lexical relations by defining a lexical combinatorial zone that specifies semantically related lexemes through Lexical Functions (LF). These functions define a correspondence between a key lexical item and a set of related lexical items (Mel’ˇcuk, 1988). There are two types of functions: paradigmatic and syntagmatic (Ramos et al., 1994)."
2003.mtsummit-systems.9,W02-2125,1,0.804117,"o pun˜ aladas a John (literally, ‘Mary gave stabs to John’) being translated into Mary stabbed John. In GHMT, the input SL dependency structure is maintained while all words are translated to TL. Generating a conflated version of the input is conditional upon the existence of a categorial variant of a TL word that satisfies lexical semantic and thematic consistency con&quot; # straints. For example,  0 is a categorial variant   # of  and it maintains   ’s thematic role in the example above as ,   . Details on the databases used to verify the additional constraints are available in (Habash, 2002). 5 Conclusions and Future Work We have presented our approach to constructing a new large-scale database containing categorial vari6 See (Habash and Dorr, 2003) for more details about the other two applications. ations of English words. Future work includes improving the word-cluster ratio and absorbing more of the single-word clusters into existing clusters or other single-word clusters. We are also considering enrichment of the clusters with types of derivational relations such as “nominal-event” or “doer” to complement part-of-speech labels. Other lexical semantic features such telicity, s"
2003.mtsummit-systems.9,N03-1013,1,0.149995,"le to the research community. We expect that the contribution of this resource will become more widely recognized through its future incorporation into additional NLP applications. For example, it is the intention of UMD researchers and WordNet 1.7 developers to use CatVar information for more rapid development and extension of WordNet and mutual validation of both resources. This paper discusses other available resources and how they differ from the CatVar database. We then discuss how and what resources were used to build CatVar. For a more detailed discussion and evaluation of CatVar, see (Habash and Dorr, 2003). The CatVar is web-browseable at http://clipdemos.umiacs.umd.edu/catvar/. 2 Background Lexical relations describe relative relationships among different lexemes. Lexical relations are either hierarchical taxonomic relations (such as hypernymy, hyponymy and entailments) or nonhierarchical congruence relations (such as identity, overlap, synonymy and antonymy) (Cruse, 1986). Resources specifying the relations among lexical items such as WordNet (Fellbaum, 1998) and HowNet (Dong, 2000) (among others) have inspired the work of many researchers in NLP (Carpuat et al., 2002; Dorr et al., 2000; Resn"
2003.mtsummit-systems.9,habash-dorr-2002-handling,1,0.87938,"Missing"
2003.mtsummit-systems.9,P98-1116,0,0.0144195,"Missing"
2003.mtsummit-systems.9,P96-1004,0,0.027651,"Missing"
2003.mtsummit-systems.9,J93-2004,0,0.0239844,"Missing"
2003.mtsummit-systems.9,C92-3145,0,\N,Missing
2003.mtsummit-systems.9,C00-1007,0,\N,Missing
2003.mtsummit-systems.9,P02-1040,0,\N,Missing
2003.mtsummit-systems.9,C98-1112,0,\N,Missing
2003.mtsummit-systems.9,dorr-etal-2002-duster,1,\N,Missing
2006.amta-papers.7,E06-1032,0,0.0204439,"guistic Data Consortium (LDC). We use an Arabic-English parallel corpus of about 5 million words to train the translation model.5 For Arabic preprocessing, the Arabic Treebank scheme is used (Habash and Sadat, 2006). All systems use the same surface trigram language model, trained on approximately 340 million words of English newswire text from the English Gigaword corpus.6 English preprocessing simply included downcasing, separating punctuation from words and splitting off “’s”. Trigram language models are implemented using the SRILM toolkit (Stolcke, 2002). Both BLEU (Papineni et al., 2002; Callison-Burch et al., 2006) and NIST (Doddington, 2002) metric scores are reported. All scores are computed against four references with n-grams of maximum length four. As a post-processing step, the translations of all systems are true-cased, and all results reported below refer to the case-sensitive BLEU and NIST scores. We conducted three sets of evaluations that explore different aspects of the data sets and the system variants: a full system evaluation, a genre-specific evaluation, and a qualitative evaluation of specific linguistic phenomena. 6.1 Full Evaluation Six system variants are compared: • G IST is a simpl"
2006.amta-papers.7,P05-1066,0,0.16191,"rphological preprocessing helps, but only for smaller corpora. Habash and Sadat (2006) reached similar conclusions on a much larger set of experiments including various preprocessing schemes and techniques. They showed that genre variation interacts with preprocessing decisions. Within our approach, working with Arabic morphology is especially challenging. We discuss this issue in more detail in Section 3. 2.2 MT Hybridization More recently a number of statistical MT approaches included syntactic information as part of the preprocessing phase, the decoding phase or the n-best rescoring phase. Collins et al. (2005) incorporated syntactic information as part of preprocessing the parallel corpus. A series of transformations on the source parse trees were applied to make the order of the sourcelanguage words and phrases closer to that of the target language. The same reordering was done for a new source sentence before decoding. They showed a modest statistically significant improvement over basic phrase-based MT. Quirk et al. (2005) used sub-graphs of dependency trees to deal with word-order differences between the source and the target language. During training, dependency graphs on the source side were"
2006.amta-papers.7,P97-1003,0,0.0433478,"and training data size. Symbolic MT approaches tend to capture more abstract generalizations about the languages they translate between compared to statistical MT. This comes at a cost of being more complex than statistical MT, involving more human effort, and depending on already existing resources for morphological analysis and parsing. This dependence on existing resources highlights the problem of variation in morphological representations for Arabic. In a typical situation, the in58 put/output text of an MT system is in simple whitespace tokenization. But, a statistical parser (such as (Collins, 1997) or (Bikel, 2002)) trained out-of-thebox on the Penn Arabic Treebank (Maamouri et al., 2004) assumes the same kind of tokenization it uses (4-way normalized segments into conjunction, particle, word and pronominal clitic). This means a separate tokenizer is needed to convert input text to this representation (Habash and Rambow, 2005; Diab et al., 2004). An additional issue with a treebank-trained statistical parser is that its input/output is in normalized segmentation that does not contain morphological information such as features or lexemes that are important for translation. Arabic-English"
2006.amta-papers.7,N04-4038,0,0.0379168,"endence on existing resources highlights the problem of variation in morphological representations for Arabic. In a typical situation, the in58 put/output text of an MT system is in simple whitespace tokenization. But, a statistical parser (such as (Collins, 1997) or (Bikel, 2002)) trained out-of-thebox on the Penn Arabic Treebank (Maamouri et al., 2004) assumes the same kind of tokenization it uses (4-way normalized segments into conjunction, particle, word and pronominal clitic). This means a separate tokenizer is needed to convert input text to this representation (Habash and Rambow, 2005; Diab et al., 2004). An additional issue with a treebank-trained statistical parser is that its input/output is in normalized segmentation that does not contain morphological information such as features or lexemes that are important for translation. Arabic-English dictionaries use lexemes and proper translation of features, such as number and tense, requires access to these features in both source and target languages. As a result, additional conversion is needed to relate the normalized segmentation to the lexeme and feature level. Of course, in principle, the treebank and parser could be modified to be at the"
2006.amta-papers.7,H05-1085,0,0.0456068,"and to butter (Dorr, 1993). The overgeneration is constrained by multiple statistical targetlanguage models including surface n-grams and structural n-grams. The source-target asymmetry of systems developed in this approach makes them more easily retargetable to new source languages (provided a source-language parser and translation dictionary). In this paper, we describe these two specific extensions for Arabic in detail (Section 4). SMT quality focused on morphologically rich languages such as German (Nießen and Ney, 2004); Spanish, Catalan, and Serbian (Popovi´c and Ney, 2004); and Czech (Goldwater and McClosky, 2005). These studies examined the effects of various kinds of tokenization, lemmatization and part-of-speech (POS) tagging and showed a positive effect on SMT quality. Lee (2004) investigated the use of automatic alignment of POS-tagged English and affix-stem segmented Arabic to determine appropriate tokenizations of Arabic. Her results showed that morphological preprocessing helps, but only for smaller corpora. Habash and Sadat (2006) reached similar conclusions on a much larger set of experiments including various preprocessing schemes and techniques. They showed that genre variation interacts wi"
2006.amta-papers.7,habash-dorr-2002-handling,1,0.840173,"T implementations in Section 3. Section 4 describes the Arabic components of our basic GHMT system. Section 5 describes the extensions we made to integrate SMT components into the GHMT system. Section 6 presents three evaluations of multiple MT system variants. 2 Previous Work We discuss research related to our approach in the areas of generation-heavy MT and MT hybridization. 2.1 Generation-Heavy MT GHMT is an asymmetrical hybrid approach that addresses the issue of MT resource poverty in source-poor/target-rich language pairs by exploiting symbolic and statistical target-language resources (Habash and Dorr, 2002; Habash, 2003a; Habash, 56 Proceedings of the 7th Conference of the Association for Machine Translation in the Americas, pages 56-65, Cambridge, August 2006. ©2006 The Association for Machine Translation in the Americas 2003b). Expected source-language resources include a syntactic parser and a simple one-to-many translation dictionary. No transfer rules or complex interlingual representations are used. Rich targetlanguage symbolic resources such as word lexical semantics, categorial variations and subcategorization frames are used to overgenerate multiple structural variations from a target-"
2006.amta-papers.7,P05-1071,1,0.921181,"sis and parsing. This dependence on existing resources highlights the problem of variation in morphological representations for Arabic. In a typical situation, the in58 put/output text of an MT system is in simple whitespace tokenization. But, a statistical parser (such as (Collins, 1997) or (Bikel, 2002)) trained out-of-thebox on the Penn Arabic Treebank (Maamouri et al., 2004) assumes the same kind of tokenization it uses (4-way normalized segments into conjunction, particle, word and pronominal clitic). This means a separate tokenizer is needed to convert input text to this representation (Habash and Rambow, 2005; Diab et al., 2004). An additional issue with a treebank-trained statistical parser is that its input/output is in normalized segmentation that does not contain morphological information such as features or lexemes that are important for translation. Arabic-English dictionaries use lexemes and proper translation of features, such as number and tense, requires access to these features in both source and target languages. As a result, additional conversion is needed to relate the normalized segmentation to the lexeme and feature level. Of course, in principle, the treebank and parser could be m"
2006.amta-papers.7,N06-2013,1,0.900599,"SMT quality focused on morphologically rich languages such as German (Nießen and Ney, 2004); Spanish, Catalan, and Serbian (Popovi´c and Ney, 2004); and Czech (Goldwater and McClosky, 2005). These studies examined the effects of various kinds of tokenization, lemmatization and part-of-speech (POS) tagging and showed a positive effect on SMT quality. Lee (2004) investigated the use of automatic alignment of POS-tagged English and affix-stem segmented Arabic to determine appropriate tokenizations of Arabic. Her results showed that morphological preprocessing helps, but only for smaller corpora. Habash and Sadat (2006) reached similar conclusions on a much larger set of experiments including various preprocessing schemes and techniques. They showed that genre variation interacts with preprocessing decisions. Within our approach, working with Arabic morphology is especially challenging. We discuss this issue in more detail in Section 3. 2.2 MT Hybridization More recently a number of statistical MT approaches included syntactic information as part of the preprocessing phase, the decoding phase or the n-best rescoring phase. Collins et al. (2005) incorporated syntactic information as part of preprocessing the"
2006.amta-papers.7,koen-2004-pharaoh,0,0.392152,"ic N/ap N/ap N Nap writer;author clerk authors;writers authors;writers PV IV PV_Pass IV_Pass_yu write write be written;be fated;be destined be written;be fated;be destined kuwfiy˜_1 AJ Kufic/from_Kufa/of_Kufa kAtib_1 N katab-u_1 V author/clerk/writer be_destined/be_fated/ be_written/destine/fate/write 5 Integration of SMT Components into GHMT The main challenge for integrating SMT components into GHMT is that the conception of the phrase (anything beyond a single word) is radically different. Phrase-based SMT systems take a phrase to be a sequence of words with no hidden underlying structure (Koehn, 2004). On the other hand, for systems that use parsers, like GHMT, a phrase has a linguistic structure that defines it and its behavior in a bigger context. Both kinds come with problems. Statistical phrases are created from alignments, which may not be clean. This results in jagged edges to many phrases. For example, the phrase . on the other hand , the (containing seven words starting with a period and ending with “the”) overlaps multiple linguistic phrase boundaries. Another related phenomenon is that of statistical hallucination, e.g., the translation of AlswdAn w (literally, Sudan and) into en"
2006.amta-papers.7,N04-4015,0,0.0389125,"stems developed in this approach makes them more easily retargetable to new source languages (provided a source-language parser and translation dictionary). In this paper, we describe these two specific extensions for Arabic in detail (Section 4). SMT quality focused on morphologically rich languages such as German (Nießen and Ney, 2004); Spanish, Catalan, and Serbian (Popovi´c and Ney, 2004); and Czech (Goldwater and McClosky, 2005). These studies examined the effects of various kinds of tokenization, lemmatization and part-of-speech (POS) tagging and showed a positive effect on SMT quality. Lee (2004) investigated the use of automatic alignment of POS-tagged English and affix-stem segmented Arabic to determine appropriate tokenizations of Arabic. Her results showed that morphological preprocessing helps, but only for smaller corpora. Habash and Sadat (2006) reached similar conclusions on a much larger set of experiments including various preprocessing schemes and techniques. They showed that genre variation interacts with preprocessing decisions. Within our approach, working with Arabic morphology is especially challenging. We discuss this issue in more detail in Section 3. 2.2 MT Hybridiz"
2006.amta-papers.7,P03-1021,0,0.016325,"Missing"
2006.amta-papers.7,P02-1040,0,0.0743345,"available from the Linguistic Data Consortium (LDC). We use an Arabic-English parallel corpus of about 5 million words to train the translation model.5 For Arabic preprocessing, the Arabic Treebank scheme is used (Habash and Sadat, 2006). All systems use the same surface trigram language model, trained on approximately 340 million words of English newswire text from the English Gigaword corpus.6 English preprocessing simply included downcasing, separating punctuation from words and splitting off “’s”. Trigram language models are implemented using the SRILM toolkit (Stolcke, 2002). Both BLEU (Papineni et al., 2002; Callison-Burch et al., 2006) and NIST (Doddington, 2002) metric scores are reported. All scores are computed against four references with n-grams of maximum length four. As a post-processing step, the translations of all systems are true-cased, and all results reported below refer to the case-sensitive BLEU and NIST scores. We conducted three sets of evaluations that explore different aspects of the data sets and the system variants: a full system evaluation, a genre-specific evaluation, and a qualitative evaluation of specific linguistic phenomena. 6.1 Full Evaluation Six system variants ar"
2006.amta-papers.7,popovic-ney-2004-towards,0,0.0433443,"Missing"
2006.amta-papers.7,P05-1034,0,0.104069,"tion More recently a number of statistical MT approaches included syntactic information as part of the preprocessing phase, the decoding phase or the n-best rescoring phase. Collins et al. (2005) incorporated syntactic information as part of preprocessing the parallel corpus. A series of transformations on the source parse trees were applied to make the order of the sourcelanguage words and phrases closer to that of the target language. The same reordering was done for a new source sentence before decoding. They showed a modest statistically significant improvement over basic phrase-based MT. Quirk et al. (2005) used sub-graphs of dependency trees to deal with word-order differences between the source and the target language. During training, dependency graphs on the source side were projected onto the target side by using the alignment links between words in the two languages. The use of syntactic information is the main difference between their approach and phrase-based statistical MT approaches. During decoding, the different subgraphs were combined in order to generate the most likely dependency tree. This approach has been shown to provide significant improvements over a Research into MT hybrids"
2006.amta-papers.7,2006.amta-papers.25,1,0.654799,"more genre-independent than SMT approaches. We believe this is a result of the Arabic linguistic resources we use being biased towards news-genre. For example, the Arabic treebank used for training the parser is only in the news genre. The Buckwalter lexicon potentially also has some internal bias toward news genre because it was developed in tandem with the Arabic treebank. 6.3 Qualitative Evaluation Automatic evaluation systems are often criticized for not capturing linguistic subtleties. This is clearly apparent in the field’s moving back toward using human evaluation metrics such as HTER (Snover et al., 2006). We conducted a small human evaluation of verb and subject realization in eight random documents from MT04. The documents contained 47 sentences and reflect the distribution of genre in the MT04 test set. We compare three systems G HMT, G HMT P HARAOH and P HARAOH. The evaluation was conducted using one bilingual Arabic-English speaker (native Arabic, almost native English). The task is to determine for every verb that appears in the Arabic input whether it is Table 4: Verb and subject realization in eight documents from MT04 Genre News Speech Editorial All Verb Count 46 48 29 123 G HMT Verbs"
2006.amta-papers.7,J04-2003,0,\N,Missing
2006.amta-papers.7,N04-1021,0,\N,Missing
2007.mtsummit-papers.20,E06-1032,0,0.0410528,"Missing"
2007.mtsummit-papers.20,H05-1085,0,0.0261799,"Missing"
2007.mtsummit-papers.20,P05-1071,1,0.813749,"r investigation, we define different diacritization schemes (DS) highlighting the different linguistic phenomena observed in natural text. We preprocess the Arabic source text in the context of phrase-based SMT using these different DSs. We also explore two different alignment modes, where a diacritization scheme is either used or not used for alignment purposes. 4.1 Diacritization Schemes We define six different diacritization schemes that are inspired by our observations of the relevant naturally occurring diacritics. For all of the schemes, we use the MADA system for Arabic disambiguation (Habash and Rambow, 2005; Habash and Rambow, 2007). The fully disambiguated form of a word is marked for all its morphological features and is also fully diacritized. For each scheme, we selectively delete diacritics that are irrelevant to that scheme given the scheme’s defined features of interest. The following are the defined diacritization schemes: • NONE: This is the baseline DS, in which all diacritics are absent, including the naturally occurring ones; • PASS: This is an inflectional DS which marks the verb passivization (u) only. It is only used on verbs marked by MADA as passive and where the (u) is explicit"
2007.mtsummit-papers.20,N07-2014,1,0.770482,"e different diacritization schemes (DS) highlighting the different linguistic phenomena observed in natural text. We preprocess the Arabic source text in the context of phrase-based SMT using these different DSs. We also explore two different alignment modes, where a diacritization scheme is either used or not used for alignment purposes. 4.1 Diacritization Schemes We define six different diacritization schemes that are inspired by our observations of the relevant naturally occurring diacritics. For all of the schemes, we use the MADA system for Arabic disambiguation (Habash and Rambow, 2005; Habash and Rambow, 2007). The fully disambiguated form of a word is marked for all its morphological features and is also fully diacritized. For each scheme, we selectively delete diacritics that are irrelevant to that scheme given the scheme’s defined features of interest. The following are the defined diacritization schemes: • NONE: This is the baseline DS, in which all diacritics are absent, including the naturally occurring ones; • PASS: This is an inflectional DS which marks the verb passivization (u) only. It is only used on verbs marked by MADA as passive and where the (u) is explicitly present;6 • C-M: This i"
2007.mtsummit-papers.20,N06-2013,1,0.830406,"Missing"
2007.mtsummit-papers.20,koen-2004-pharaoh,0,0.035562,"95 0.4195 0.4389 PASS 0.4507 0.4538 0.4202 0.4141 0.4416 0.4389 C-M 0.4354 0.4411 0.3977 0.4047 0.4217 0.4290 GEM 0.4341 0.4444 0.4128 0.4059 0.4310 0.4304 SUK 0.4482 0.4536 0.4173 0.4195 0.4410 0.4392 FULL 0.4293 0.4307 0.3898 0.3938 0.4177 0.4183 Table 2: BLEU score results obtained for all the diacritization schemes in both alignment strategies on 3 different test sets, MT03, MT04 and MT05 MT evaluation test set (M T 02). We report results on the 2003, 2004 and 2005 NIST MT evaluation test sets. 5.2 SMT System In all our experiments, we use an off-the-shelf phrasebased SMT system, Pharaoh (Koehn, 2004). Trigram language models are implemented using the SRILM toolkit (Stolcke, 2002). Decoding weights are optimized using Och’s algorithm (Och, 2003). The weights are optimized over the BLEU metric (Papineni et al., 2002), which is the evaluation metric we use.7 We use the BLEU metric in a mode insensitive to casing. For each of the diacritization schemes described above, we train two systems per each alignment strategy. The results are described in the next section. 5.3 Results and Discussion Table 2 illustrates the BLEU scores obtained for the different diacritization schemes (DS) and the diff"
2007.mtsummit-papers.20,N04-4015,0,0.0862022,"Missing"
2007.mtsummit-papers.20,J03-1002,0,0.00653548,"Missing"
2007.mtsummit-papers.20,P03-1021,0,0.00601817,"0.4304 SUK 0.4482 0.4536 0.4173 0.4195 0.4410 0.4392 FULL 0.4293 0.4307 0.3898 0.3938 0.4177 0.4183 Table 2: BLEU score results obtained for all the diacritization schemes in both alignment strategies on 3 different test sets, MT03, MT04 and MT05 MT evaluation test set (M T 02). We report results on the 2003, 2004 and 2005 NIST MT evaluation test sets. 5.2 SMT System In all our experiments, we use an off-the-shelf phrasebased SMT system, Pharaoh (Koehn, 2004). Trigram language models are implemented using the SRILM toolkit (Stolcke, 2002). Decoding weights are optimized using Och’s algorithm (Och, 2003). The weights are optimized over the BLEU metric (Papineni et al., 2002), which is the evaluation metric we use.7 We use the BLEU metric in a mode insensitive to casing. For each of the diacritization schemes described above, we train two systems per each alignment strategy. The results are described in the next section. 5.3 Results and Discussion Table 2 illustrates the BLEU scores obtained for the different diacritization schemes (DS) and the different alignment strategies A LIGN BASIC and A LIGN R EMAP. From Table 2, the worst results are those obtained with the FULL condition across the th"
2007.mtsummit-papers.20,P02-1040,0,0.0760371,"4293 0.4307 0.3898 0.3938 0.4177 0.4183 Table 2: BLEU score results obtained for all the diacritization schemes in both alignment strategies on 3 different test sets, MT03, MT04 and MT05 MT evaluation test set (M T 02). We report results on the 2003, 2004 and 2005 NIST MT evaluation test sets. 5.2 SMT System In all our experiments, we use an off-the-shelf phrasebased SMT system, Pharaoh (Koehn, 2004). Trigram language models are implemented using the SRILM toolkit (Stolcke, 2002). Decoding weights are optimized using Och’s algorithm (Och, 2003). The weights are optimized over the BLEU metric (Papineni et al., 2002), which is the evaluation metric we use.7 We use the BLEU metric in a mode insensitive to casing. For each of the diacritization schemes described above, we train two systems per each alignment strategy. The results are described in the next section. 5.3 Results and Discussion Table 2 illustrates the BLEU scores obtained for the different diacritization schemes (DS) and the different alignment strategies A LIGN BASIC and A LIGN R EMAP. From Table 2, the worst results are those obtained with the FULL condition across the three evaluation sets for both alignment strategies A LIGN BASIC and A LIG"
2007.mtsummit-papers.20,popovic-ney-2004-towards,0,0.0543886,"Missing"
2007.mtsummit-papers.20,W04-1612,0,0.186591,"Missing"
2007.mtsummit-papers.20,P06-1073,0,0.240084,"Missing"
2007.mtsummit-papers.29,P05-1066,0,0.179196,"abic parsing and rule design may be needed. In the next section, we discuss and contrast related work. Section 3 presents issues of Arabic syntax in the context of MT and describes the parser we used. Section 4 describes our approach to rule extraction and application. Section 5 presents and discusses the experimental results. 2 Related Research Much research has been done on utilizing syntactic information within SMT. The approaches used vary in the place of applying syntactic knowledge: for preprocessing, decoding or n-best rescoring and on the source language, target language or both (see (Collins et al., 2005) and (Xia and McCord, 2004) for a general review of different approaches). The approach presented here fits within the class of source-language preprocessing for SMT. It uses full syntactic dependency representations to learn syntactic preprocessing (reordering) rules automatically. The underlying model we use is that of phrase-based SMT (Koehn, 2004). Phrase-based SMT does not utilize any explicit syntactic information. However, it models syntax implicitly in two important ways: (a.) the phrases, which can be as large as 7 or more words, capture syntactic reordering between the source phrase"
2007.mtsummit-papers.29,2007.mtsummit-papers.16,0,0.0618549,"rule representation is a context-free dependency, which is much richer than Zhang et al. (2007)’s but effectively the same as that of (Xia and McCord, 2004) except in three specific ways: our rules are all unlexicalized, the relations between children and verbal parents are labeled and childless nodes are marked to add a bit more information of the bigger rule context. Fourthly, like (Xia and McCord, 2004) but unlike (Zhang et al., 2007), we reorder the training data and do not use lattice expansions for the source sentence. Finally, although our results generally agree with 2 In this volume, Crego and Mariño (2007) describe a similar approach that combines reordering and decoding. the findings from both, they disagree with (Xia and McCord, 2004) on the issue of using distortion in the decoder. Our results show an additional improvement over basic reordering when distortion is turned on. This is perhaps due to quality of the Arabic parser we used which, although state-of-the-art, has a large room for improvement. 3 Arabic Syntactic Parsing 3.1 Arabic Syntactic Issues Arabic is a morpho-syntactically complex language with many differences from English. We describe here three prominent syntactic features o"
2007.mtsummit-papers.29,N07-2007,1,0.878698,"Missing"
2007.mtsummit-papers.29,P05-1071,1,0.823637,"of parsing technology, some of our design decisions were shaped by its current limitations. In this section we describe the different steps and decisions made for producing the parses we use. 3.2.1 Tokenization and POS Tagging For tokenization, we use the PATB tokenization scheme: 4-way normalized segments into conjunction, particle, word and pronominal clitic. For POS tagging, we use the collapsed tagset for PATB (24 tags), which is what the Bikel parser uses for Arabic. Tokenization and POS tagging are done using the publicly available Morphological Analysis and Disambiguation (MADA) tool (Habash and Rambow, 2005) together with TOKAN, a general tokenizer for Arabic (Habash and Sadat, 2006). MADA tags Arabic words using fourteen sub-tags (a very large tagset – in practice over 2,200 tags). This tagset is first reduced for the parser as described above. Moreover, for rule-extraction and application, we use a further-reduced tagset of 14 tags, that abstracts away all inflectional features (such as verbal tense or nominal number). What optimal tokenization and tagset to use for Arabic-English syntactic reordering is an empirical question that we do not attempt to answer here. We leave it to future work. 3."
2007.mtsummit-papers.29,N06-2013,1,0.937012,"e of our decisions in this paper. First, Arabic words are morphologically complex containing clitics whose translations are represented separately in English and sometimes in a different order. For instance, possessive pronominal enclitics are attached to the noun they modify in Arabic but their translation precedes the English translation of the noun:    kitAbu+hu3 ‘book+his → his book’. Other clitics include the definite article   Al+ ‘the’, the conjunction  w+ ‘and’ and the preposition  l+ ‘of/for’, among others. Separating some of these clitics have been shown to help SMT (Habash and Sadat, 2006). In this paper we do not investigate which clitics to separate, but instead we use the Penn Arabic Treebank (PATB) (Maamouri et al., 2004) tokenization scheme which splits three classes of clitics only. This scheme is most compatible out-of-thebox with statistical parsers trained on the PATB (However, it does not cliticize the definite article as can be seen in Figure 1). We plan to investigate different tokenization schemes for syntactic preprocessing in future work. Secondly, Arabic verb subjects may be: (a.) prodropped (verb conjugated), (b.) pre-verbal, or (c.) postverbal. The PATB labels"
2007.mtsummit-papers.29,2006.amta-papers.7,1,0.888185,"Missing"
2007.mtsummit-papers.29,D07-1116,1,0.804676,"and all of its children are aligned. We then traverse the parse tree PS and extract, at each node with children, a pairing of condition (C) and reordering (R): C is simply the ordered dependency and R is the target order of its nodes. In the case that a dependency node is not linked (typically, a failure in the alignment step), we ignore that child completely. In the case when multiple ordering are possible due to overlapping alignments, we produce all possible reorderings and give them 8 We use Yamcha’s default settings: standard SVM with 2nd degree polynomial kernel and 1 slack variable. 9 Habash et al. (2007) attempt to do this for the task of automatic case prediction in Arabic. Table 1: Examples of extracted rules Condition (C) [VB]1 ,SBJ/NN2 ,OBJ/NN3 ,MOD/PUNC4 [NN]1 ,MOD/JJ02 [NN]1 ,MOD/JJ02 ,MOD/IN3 [IN]1 ,MOD/NN2 equal probability. The intuition here is that different specific occurrences of C will have different kinds of alignment errors associated with them, but that good reorderings will have high co-occurrence rate and rise to the top claiming more of the probability. For example, the first node in the parse in Figure 1 is a verb with three children: a subject, an object and  a punctuat"
2007.mtsummit-papers.29,koen-2004-pharaoh,0,0.0498823,"has been done on utilizing syntactic information within SMT. The approaches used vary in the place of applying syntactic knowledge: for preprocessing, decoding or n-best rescoring and on the source language, target language or both (see (Collins et al., 2005) and (Xia and McCord, 2004) for a general review of different approaches). The approach presented here fits within the class of source-language preprocessing for SMT. It uses full syntactic dependency representations to learn syntactic preprocessing (reordering) rules automatically. The underlying model we use is that of phrase-based SMT (Koehn, 2004). Phrase-based SMT does not utilize any explicit syntactic information. However, it models syntax implicitly in two important ways: (a.) the phrases, which can be as large as 7 or more words, capture syntactic reordering between the source phrase and target phrase; and (b.) the distortion feature in the decoder allows some reordering to be considered by language model ranking. Distortion is typically controlled by a parameter specifying the maximum distance allowed between any two phrases moved to be direct neighbors. Distortion comes at a cost of decreasing the efficiency of the decoder. This"
2007.mtsummit-papers.29,P03-1004,0,0.0833449,"Missing"
2007.mtsummit-papers.29,J03-1002,0,0.00934322,"Missing"
2007.mtsummit-papers.29,P03-1021,0,0.114086,"Missing"
2007.mtsummit-papers.29,P02-1040,0,0.0894783,"Missing"
2007.mtsummit-papers.29,P97-1037,0,0.0238131,"it models syntax implicitly in two important ways: (a.) the phrases, which can be as large as 7 or more words, capture syntactic reordering between the source phrase and target phrase; and (b.) the distortion feature in the decoder allows some reordering to be considered by language model ranking. Distortion is typically controlled by a parameter specifying the maximum distance allowed between any two phrases moved to be direct neighbors. Distortion comes at a cost of decreasing the efficiency of the decoder. This is an advantage to source preprocessing since monotonic decoding is polynomial (Tillmann et al., 1997). We describe in this paper some results comparing the value of adding reordering with and without distortion and with different phrase sizes. Collins et al. (2005) describe a technique for preprocessing German to look more like English syntactically. They used six transformations that are applied on German parsed text to reorder it before passing it on to the standard phrase based system. They show a moderate statistically significant improvement. Our work differs from theirs crucially in that our preprocessing rules are learned automatically. Xia and McCord (2004) describe an approach for tr"
2007.mtsummit-papers.29,C04-1073,0,0.598997,"n may be needed. In the next section, we discuss and contrast related work. Section 3 presents issues of Arabic syntax in the context of MT and describes the parser we used. Section 4 describes our approach to rule extraction and application. Section 5 presents and discusses the experimental results. 2 Related Research Much research has been done on utilizing syntactic information within SMT. The approaches used vary in the place of applying syntactic knowledge: for preprocessing, decoding or n-best rescoring and on the source language, target language or both (see (Collins et al., 2005) and (Xia and McCord, 2004) for a general review of different approaches). The approach presented here fits within the class of source-language preprocessing for SMT. It uses full syntactic dependency representations to learn syntactic preprocessing (reordering) rules automatically. The underlying model we use is that of phrase-based SMT (Koehn, 2004). Phrase-based SMT does not utilize any explicit syntactic information. However, it models syntax implicitly in two important ways: (a.) the phrases, which can be as large as 7 or more words, capture syntactic reordering between the source phrase and target phrase; and (b.)"
2007.mtsummit-papers.29,W07-0401,0,0.274409,"ordering rules are acquired automatically using source and target parses and word alignment. The reordering rules they use are in a context-free constituency representation with marked heads. The rules are mostly lexicalized. Xia and McCord (2004) use source and target parses to constraint which word alignments are used for rule extraction. Their results show that there is a positive effect to reordering when the decoder is run monotonically (i.e. without additional distortion-based reordering). The value of reordering is diminished if the decoder is run in a non-monotonic way. Most recently, Zhang et al. (2007) described a similar approach to Xia and McCord (2004)’s. They use chunking (shallow parsing) to learn reordering rules for Chinese-English SMT. They use unlexicalized contextfree chunk tags (XPs) and POS tags on the source side only. They use the intersection of forward and backward Giza++ alignments but without motivating their choice empirically. Most interestingly, they allow all possible learned reordering to be used to create a lattice that is input to the decoder. They do not apply the reordering rules to their training data (unlike Xia and McCord (2004)).2 The approach presented here i"
2007.mtsummit-papers.39,W05-0909,0,0.0435449,"to characteristics of the translation input is growing more and more difficult. Problems are aggravated further in the case of speech translation (of e.g. broadcast news, talkshows, etc.), where the input to the translation module is provided by an automatic speech recognition (ASR) system whose performance also influences the quality of the final translation output. During machine translation (MT) system development, automatic evaluation criteria are commonly used to judge performance, such as the BLEU score (Papineni et al. 2002), the NIST score (Doddington 2002), or, more recently, METEOR (Banerjee & Lavie 2005). Although the use of fully automated evaluation criteria is helpful in accelerating the system development cycle, all of the above criteria have shown to be inferior to human judgments of translation performance. Moreover, they do not yield any insight into precisely which input characteristics caused particular translation errors, or which system components need to be improved in order to reach the desired performance level. Human analysis of machine translation errors, on the other hand, is costly and time-intensive and can typically not be performed on a regular basis in the course of syst"
2007.mtsummit-papers.39,E06-1005,0,0.0419776,"Missing"
2007.mtsummit-papers.39,niessen-etal-2000-evaluation,0,0.0362707,"tained from human annotations and are statistically related to measurements of the overall system performance. The various input document features are then ranked with respect to their impact on translation performance. Previous Work Most work on error analysis in statistical machine translation has made use of extensive human analysis, such as classifying unsatisfactory output into categories such as wrong word choice, missing content words, missing function words, etc. (see e.g. Koehn 2003, Och et al. 2003). Previous work on automatic or semi-automatic error analysis in SMT systems includes Niessen et al. (2000), Popovic et al. (2006a) and Popovic et al. (2006b). In Niessen et al. (2002), a graphical user interface was presented that automatically extracts various error measures for translation candidates and thus facilitates manual error analysis. In Popovic et al. (2006a) and Popovic et al. (2006b), errors in an English-Spanish statistical MT system were analyzed with respect to their syntactic and morphological origin. This was done by modifying the references and the machine translation output by eliminating morphological inflections or suspected reordered constituents, and by analyzing the resul"
2007.mtsummit-papers.39,P02-1040,0,0.0911609,"As a consequence, diagnosing problems in translation performance and relating them to characteristics of the translation input is growing more and more difficult. Problems are aggravated further in the case of speech translation (of e.g. broadcast news, talkshows, etc.), where the input to the translation module is provided by an automatic speech recognition (ASR) system whose performance also influences the quality of the final translation output. During machine translation (MT) system development, automatic evaluation criteria are commonly used to judge performance, such as the BLEU score (Papineni et al. 2002), the NIST score (Doddington 2002), or, more recently, METEOR (Banerjee & Lavie 2005). Although the use of fully automated evaluation criteria is helpful in accelerating the system development cycle, all of the above criteria have shown to be inferior to human judgments of translation performance. Moreover, they do not yield any insight into precisely which input characteristics caused particular translation errors, or which system components need to be improved in order to reach the desired performance level. Human analysis of machine translation errors, on the other hand, is costly and time-"
2007.mtsummit-papers.39,W06-3101,0,0.229094,"Missing"
2007.mtsummit-ucnlg.9,C00-1007,0,0.0607579,"ing: restricting the machine to a specific space of linguistic rules or more abstractly to a formal space of allowable linguistic rules. These two dimensions are orthogonal. HL components tend to be deep as in traditional “symbolic/rule-based” MT and NLG, but can also be shallow as in templates in NLG or word-based MT. ML components tend to be shallow as in phrase tables in MT and n-gram language models for MT and NLG (Brown and Frederking, 1995; Langkilde and Knight, 1998). But much research has been going on in using deeper representations in MT (Collins et al., 2005) and language modeling (Bangalore and Rambow, 2000). All positions on both dimensions come with disadvantages – there is no obvious “sweet spot” on this two-dimensional continuum. For instance, both linguistic and surface models are prone to hallucinating/over-generating constructions that are suboptimal or flat-out wrong. These can be a result of ML misalignment or HL over-abstraction. Similarly, HL may be more concise and less redundant compared to ML, but it tends to miss a lot of “less obvious” cases. Additionally, both are prone to coverage limitations, whether it be the domain and genre of the corpus or the focus of the linguist producin"
2007.mtsummit-ucnlg.9,1995.tmi-1.17,0,0.0646319,"machine learned (ML) rules. There are many possible instances in between these two extremes that can include different degrees of manual human interference in pure machine learning: restricting the machine to a specific space of linguistic rules or more abstractly to a formal space of allowable linguistic rules. These two dimensions are orthogonal. HL components tend to be deep as in traditional “symbolic/rule-based” MT and NLG, but can also be shallow as in templates in NLG or word-based MT. ML components tend to be shallow as in phrase tables in MT and n-gram language models for MT and NLG (Brown and Frederking, 1995; Langkilde and Knight, 1998). But much research has been going on in using deeper representations in MT (Collins et al., 2005) and language modeling (Bangalore and Rambow, 2000). All positions on both dimensions come with disadvantages – there is no obvious “sweet spot” on this two-dimensional continuum. For instance, both linguistic and surface models are prone to hallucinating/over-generating constructions that are suboptimal or flat-out wrong. These can be a result of ML misalignment or HL over-abstraction. Similarly, HL may be more concise and less redundant compared to ML, but it tends t"
2007.mtsummit-ucnlg.9,P05-1066,0,0.023049,"nual human interference in pure machine learning: restricting the machine to a specific space of linguistic rules or more abstractly to a formal space of allowable linguistic rules. These two dimensions are orthogonal. HL components tend to be deep as in traditional “symbolic/rule-based” MT and NLG, but can also be shallow as in templates in NLG or word-based MT. ML components tend to be shallow as in phrase tables in MT and n-gram language models for MT and NLG (Brown and Frederking, 1995; Langkilde and Knight, 1998). But much research has been going on in using deeper representations in MT (Collins et al., 2005) and language modeling (Bangalore and Rambow, 2000). All positions on both dimensions come with disadvantages – there is no obvious “sweet spot” on this two-dimensional continuum. For instance, both linguistic and surface models are prone to hallucinating/over-generating constructions that are suboptimal or flat-out wrong. These can be a result of ML misalignment or HL over-abstraction. Similarly, HL may be more concise and less redundant compared to ML, but it tends to miss a lot of “less obvious” cases. Additionally, both are prone to coverage limitations, whether it be the domain and genre"
2007.mtsummit-ucnlg.9,2003.mtsummit-systems.9,1,0.762594,"the domain and genre of the corpus or the focus of the linguist producing the data to build the model. It is possible to define a common framework for MT and NLG in which every component of MT or NLG can be categorized as either (1) meaningpreserving transformation, whether one-to-one or one-to-many (or even many-to-many) or (2) hypothesis reranking using features from any part of the system. In the context of meaning-preserving transformations, sharable resources between NLG and MT have to be monolingual. These include resources that map one language into itself such as categorial variation (Habash and Dorr, 2003) or WordNet-based synset expansion (Fellbaum, 1997); and resources that map from a deep representation 64 to a shallower one such as morphological generators (Habash, 2004) or interlingual lexicons (Dorr, 1993). Components in the context of reranking can be shared by both MT and NLG, as in n-gram language models or syntax-based language models (Brown and Frederking, 1995; Langkilde and Knight, 1998; Bangalore and Rambow, 2000). Within the framework described above, the main difference between end-to-end MT and NLG is their input representation: MT expects shallow surface words in a different ("
2007.mtsummit-ucnlg.9,P98-1116,0,0.036106,"There are many possible instances in between these two extremes that can include different degrees of manual human interference in pure machine learning: restricting the machine to a specific space of linguistic rules or more abstractly to a formal space of allowable linguistic rules. These two dimensions are orthogonal. HL components tend to be deep as in traditional “symbolic/rule-based” MT and NLG, but can also be shallow as in templates in NLG or word-based MT. ML components tend to be shallow as in phrase tables in MT and n-gram language models for MT and NLG (Brown and Frederking, 1995; Langkilde and Knight, 1998). But much research has been going on in using deeper representations in MT (Collins et al., 2005) and language modeling (Bangalore and Rambow, 2000). All positions on both dimensions come with disadvantages – there is no obvious “sweet spot” on this two-dimensional continuum. For instance, both linguistic and surface models are prone to hallucinating/over-generating constructions that are suboptimal or flat-out wrong. These can be a result of ML misalignment or HL over-abstraction. Similarly, HL may be more concise and less redundant compared to ML, but it tends to miss a lot of “less obvious"
2007.mtsummit-ucnlg.9,E93-1066,0,0.0160371,"presentations. This entails the presence of generation’s dual process, analysis, to produce the representation on which NLG components will operate. This is an added cost for shallow SMT. For shared components, such as language models, improvements done in the NLG community can transfer easily to SMT, obviously. However, deeper integration can be more involved. NLG components can be used to perform expansions on the target language side that fill gaps in SMT models. This is very helpful particularly when translating into morphologically rich languages such as Arabic (Habash, 2004) or Turkish (Oflazer, 1993). For these languages, the cost of modeling the complex but regular morphology is cheaper than acquiring more data. Expansions of the SMT hypothesis space using NLG components operating at deeper levels such as semantics are also possible (Dorr and Habash, 2002). Here, NLG components (operating on the target language through analysis and back generation) extend the SMT target-language search space with alternative paraphrases that are included in the reranking. Although NLG is typically expected to be a later component producing the target language, this is not a necessity. For instance, model"
2008.amta-papers.9,P02-1033,0,0.0292428,"earning Snyder and Barzilay (2008) describe an approach for unsupervised learning of cross-lingual morphological segmentation using parallel corpora for three Semitic languages (Arabic, Hebrew and Aramaic) and English. Their models jointly induce morpheme boundaries for the studied languages and identified cross-lingual morpheme patterns. Their work overlaps research in unsupervised morphology learning and research in multilingual learning. Much research has been done in multilingual learning to build tools exploiting parallel data from morphology to word sense tagging (Yarowsky et al., 2001; Diab and Resnik, 2002; Rogati et al., 2003). Research in unsupervised morphological learning explores ways of deriving morphology information from redundancy in the data (Goldsmith, 2001; Creutz and Lagus, 2007). Urdu NLP Relative to other languages with similar populations, Urdu has not received a lot of attention (Hussain, 2004b). A close sister language of Urdu, Hindi, has received relatively more attention. One particular publication on Hindi is relevant here as it explores similar issues: Mahesh and Sinha (2007) exploit rich morphology in Hindi to handle translation divergences between Hindi and English in a"
2008.amta-papers.9,J01-2001,0,0.0210716,"uages (Arabic, Hebrew and Aramaic) and English. Their models jointly induce morpheme boundaries for the studied languages and identified cross-lingual morpheme patterns. Their work overlaps research in unsupervised morphology learning and research in multilingual learning. Much research has been done in multilingual learning to build tools exploiting parallel data from morphology to word sense tagging (Yarowsky et al., 2001; Diab and Resnik, 2002; Rogati et al., 2003). Research in unsupervised morphological learning explores ways of deriving morphology information from redundancy in the data (Goldsmith, 2001; Creutz and Lagus, 2007). Urdu NLP Relative to other languages with similar populations, Urdu has not received a lot of attention (Hussain, 2004b). A close sister language of Urdu, Hindi, has received relatively more attention. One particular publication on Hindi is relevant here as it explores similar issues: Mahesh and Sinha (2007) exploit rich morphology in Hindi to handle translation divergences between Hindi and English in a rule-based MT approach. One of the earlier papers we could find on Urdu and MT is by Jones and Havrilla (1998), in which they described a formalism for learning tran"
2008.amta-papers.9,N06-2013,1,0.809926,"n an unsupervised manner from multilingual data (specifically phrase tables extracted from automatically aligned parallel data, which are arguably “lightly supervised”). The morphological rules learned cluster morphological phenomena in the source language (Urdu) that are OOV Handling in Machine Translation Much work in MT has shown that orthographic and morpho-syntactic preprocessing of the training and test data reduces data sparsity and OOV rates. This is especially true for languages with rich morphology such as Spanish, Catalan, and Serbian (Popovi´c and Ney, 2004) and Arabic (Lee, 2004; Habash and Sadat, 2006). We are interested here in the specific task of on-line OOV handling. The most common solution for such OOV words is to delete them from the output – thus gaming precision-based evaluation metrics such as BLEU (Papineni et al., 2002). We will not consider this “solution.” Some previous approaches anticipate OOV words that are potentially morphologically related to in-vocabulary (INV) words. For example, Yang and Kirchhoff (2006) extend phrase tables with back-off phrase variants that are segmented into smaller morphological units. Test data OOV terms are segmented in a similar manner. Talbot"
2008.amta-papers.9,P08-2015,1,0.729327,"orne (2006) propose a language-independent approach for modeling lexical redundancy for MT. They use this ap1 108 http://www.nist.gov/speech/tests/mt/2008/doc/ [8th AMTA conference, Hawaii, 21-25 October 2008] Humayoun, 2006). We will not discuss syntactic issues in this work. We also present a preliminary analysis of the types of OOVs seen in Urdu to further motivate our work. not relevant to the target language (English). By relating an OOV term to an INV term using one of these rules, we can expand existing phrase tables with “recycled phrases” of the INV terms. This approach is similar to Habash (2008)’s work on Arabic online OOV handling except that unlike his work on morphological expansion which required a morphological analyzer, we do not need one; instead we learn the morphology mapping automatically. As such, we restrict ourselves to not using any of the existing morphological analyzers for Urdu (Hussain, 2004a; Humayoun, 2006). The work of Snyder and Barzilay (2008) is close to our work; however, unlike them, we are asymmetrically interested in modeling aspects of one language (Urdu) that are irrelevant to the other language (English). We expect our approach to be more useful for mor"
2008.amta-papers.9,W04-1614,0,0.399192,"ual morpheme patterns. Their work overlaps research in unsupervised morphology learning and research in multilingual learning. Much research has been done in multilingual learning to build tools exploiting parallel data from morphology to word sense tagging (Yarowsky et al., 2001; Diab and Resnik, 2002; Rogati et al., 2003). Research in unsupervised morphological learning explores ways of deriving morphology information from redundancy in the data (Goldsmith, 2001; Creutz and Lagus, 2007). Urdu NLP Relative to other languages with similar populations, Urdu has not received a lot of attention (Hussain, 2004b). A close sister language of Urdu, Hindi, has received relatively more attention. One particular publication on Hindi is relevant here as it explores similar issues: Mahesh and Sinha (2007) exploit rich morphology in Hindi to handle translation divergences between Hindi and English in a rule-based MT approach. One of the earlier papers we could find on Urdu and MT is by Jones and Havrilla (1998), in which they described a formalism for learning transfer rules for Urdu-English MT. Humayoun (2006) describes a suite of resources for Urdu processing and Hussain (2004a) discusses in great details"
2008.amta-papers.9,jones-havrilla-1998-twisted,0,0.0418477,"of deriving morphology information from redundancy in the data (Goldsmith, 2001; Creutz and Lagus, 2007). Urdu NLP Relative to other languages with similar populations, Urdu has not received a lot of attention (Hussain, 2004b). A close sister language of Urdu, Hindi, has received relatively more attention. One particular publication on Hindi is relevant here as it explores similar issues: Mahesh and Sinha (2007) exploit rich morphology in Hindi to handle translation divergences between Hindi and English in a rule-based MT approach. One of the earlier papers we could find on Urdu and MT is by Jones and Havrilla (1998), in which they described a formalism for learning transfer rules for Urdu-English MT. Humayoun (2006) describes a suite of resources for Urdu processing and Hussain (2004a) discusses in great details the workings of a morphological analyzer for Urdu. In 2008, Urdu was chosen as one of languages from which to translate into English in the National Institute of Standards and Technology (NIST) MT Evaluation competition.1 We use the data provided by NIST in this paper and report results on its development and test sets. In this paper, we describe and evaluate an approach to on-line OOV handling i"
2008.amta-papers.9,koen-2004-pharaoh,0,0.0173123,"reparation before we could use it. In particular, we use an implementation of Gale and Church (1993)’s sentence alignment algorithm to align the Urdu and English sentences in the parallel corpus. We extend the corpus with paired UrduEnglish entries from the lexicon. The presence of the lexicon may positively bias the automatic learn4.3 Building the Phrase-based MT Baseline We built our baseline system using standard resources for phrase-based MT. Word alignment is done with GIZA++ (Och and Ney, 2003). Phrase table extraction and decoding are done using resources from the Pharaoh system suite (Koehn, 2004). Tuning was done use Och’s Minimum Error Training (MERT) method (Och, 2003). A trigram English language model was implemented using the SRILM 4 5 111 http://unicode.org/charts/PDF/U0600.pdf http://unicode.org/charts/PDF/UFB50.pdf [8th AMTA conference, Hawaii, 21-25 October 2008] we plan to investigate how to modify the weights using the probabilities of the learned rules. toolkit (Stolcke, 2002) applied to the English side of the training data. Section 6 contains the evaluation results for the baseline system. 5.2 Our system learned 2,274,392 rules (1,137,196 bidirectional rules), which we ra"
2008.amta-papers.9,N04-4015,0,0.0176281,"s learned in an unsupervised manner from multilingual data (specifically phrase tables extracted from automatically aligned parallel data, which are arguably “lightly supervised”). The morphological rules learned cluster morphological phenomena in the source language (Urdu) that are OOV Handling in Machine Translation Much work in MT has shown that orthographic and morpho-syntactic preprocessing of the training and test data reduces data sparsity and OOV rates. This is especially true for languages with rich morphology such as Spanish, Catalan, and Serbian (Popovi´c and Ney, 2004) and Arabic (Lee, 2004; Habash and Sadat, 2006). We are interested here in the specific task of on-line OOV handling. The most common solution for such OOV words is to delete them from the output – thus gaming precision-based evaluation metrics such as BLEU (Papineni et al., 2002). We will not consider this “solution.” Some previous approaches anticipate OOV words that are potentially morphologically related to in-vocabulary (INV) words. For example, Yang and Kirchhoff (2006) extend phrase tables with back-off phrase variants that are segmented into smaller morphological units. Test data OOV terms are segmented in"
2008.amta-papers.9,2007.mtsummit-papers.57,0,0.0290267,"o build tools exploiting parallel data from morphology to word sense tagging (Yarowsky et al., 2001; Diab and Resnik, 2002; Rogati et al., 2003). Research in unsupervised morphological learning explores ways of deriving morphology information from redundancy in the data (Goldsmith, 2001; Creutz and Lagus, 2007). Urdu NLP Relative to other languages with similar populations, Urdu has not received a lot of attention (Hussain, 2004b). A close sister language of Urdu, Hindi, has received relatively more attention. One particular publication on Hindi is relevant here as it explores similar issues: Mahesh and Sinha (2007) exploit rich morphology in Hindi to handle translation divergences between Hindi and English in a rule-based MT approach. One of the earlier papers we could find on Urdu and MT is by Jones and Havrilla (1998), in which they described a formalism for learning transfer rules for Urdu-English MT. Humayoun (2006) describes a suite of resources for Urdu processing and Hussain (2004a) discusses in great details the workings of a morphological analyzer for Urdu. In 2008, Urdu was chosen as one of languages from which to translate into English in the National Institute of Standards and Technology (NI"
2008.amta-papers.9,J03-1002,0,0.00366556,"r. Although some amount of simple preprocessing was done in the provided data, we still needed to do additional preparation before we could use it. In particular, we use an implementation of Gale and Church (1993)’s sentence alignment algorithm to align the Urdu and English sentences in the parallel corpus. We extend the corpus with paired UrduEnglish entries from the lexicon. The presence of the lexicon may positively bias the automatic learn4.3 Building the Phrase-based MT Baseline We built our baseline system using standard resources for phrase-based MT. Word alignment is done with GIZA++ (Och and Ney, 2003). Phrase table extraction and decoding are done using resources from the Pharaoh system suite (Koehn, 2004). Tuning was done use Och’s Minimum Error Training (MERT) method (Och, 2003). A trigram English language model was implemented using the SRILM 4 5 111 http://unicode.org/charts/PDF/U0600.pdf http://unicode.org/charts/PDF/UFB50.pdf [8th AMTA conference, Hawaii, 21-25 October 2008] we plan to investigate how to modify the weights using the probabilities of the learned rules. toolkit (Stolcke, 2002) applied to the English side of the training data. Section 6 contains the evaluation results f"
2008.amta-papers.9,P03-1021,0,0.0145837,"Gale and Church (1993)’s sentence alignment algorithm to align the Urdu and English sentences in the parallel corpus. We extend the corpus with paired UrduEnglish entries from the lexicon. The presence of the lexicon may positively bias the automatic learn4.3 Building the Phrase-based MT Baseline We built our baseline system using standard resources for phrase-based MT. Word alignment is done with GIZA++ (Och and Ney, 2003). Phrase table extraction and decoding are done using resources from the Pharaoh system suite (Koehn, 2004). Tuning was done use Och’s Minimum Error Training (MERT) method (Och, 2003). A trigram English language model was implemented using the SRILM 4 5 111 http://unicode.org/charts/PDF/U0600.pdf http://unicode.org/charts/PDF/UFB50.pdf [8th AMTA conference, Hawaii, 21-25 October 2008] we plan to investigate how to modify the weights using the probabilities of the learned rules. toolkit (Stolcke, 2002) applied to the English side of the training data. Section 6 contains the evaluation results for the baseline system. 5.2 Our system learned 2,274,392 rules (1,137,196 bidirectional rules), which we rank based on redundancy in supporting examples in the data (or weight). There"
2008.amta-papers.9,P02-1040,0,0.0768342,"n the source language (Urdu) that are OOV Handling in Machine Translation Much work in MT has shown that orthographic and morpho-syntactic preprocessing of the training and test data reduces data sparsity and OOV rates. This is especially true for languages with rich morphology such as Spanish, Catalan, and Serbian (Popovi´c and Ney, 2004) and Arabic (Lee, 2004; Habash and Sadat, 2006). We are interested here in the specific task of on-line OOV handling. The most common solution for such OOV words is to delete them from the output – thus gaming precision-based evaluation metrics such as BLEU (Papineni et al., 2002). We will not consider this “solution.” Some previous approaches anticipate OOV words that are potentially morphologically related to in-vocabulary (INV) words. For example, Yang and Kirchhoff (2006) extend phrase tables with back-off phrase variants that are segmented into smaller morphological units. Test data OOV terms are segmented in a similar manner. Talbot and Osborne (2006) propose a language-independent approach for modeling lexical redundancy for MT. They use this ap1 108 http://www.nist.gov/speech/tests/mt/2008/doc/ [8th AMTA conference, Hawaii, 21-25 October 2008] Humayoun, 2006)."
2008.amta-papers.9,popovic-ney-2004-towards,0,0.0534883,"Missing"
2008.amta-papers.9,P03-1050,0,0.019265,"ilay (2008) describe an approach for unsupervised learning of cross-lingual morphological segmentation using parallel corpora for three Semitic languages (Arabic, Hebrew and Aramaic) and English. Their models jointly induce morpheme boundaries for the studied languages and identified cross-lingual morpheme patterns. Their work overlaps research in unsupervised morphology learning and research in multilingual learning. Much research has been done in multilingual learning to build tools exploiting parallel data from morphology to word sense tagging (Yarowsky et al., 2001; Diab and Resnik, 2002; Rogati et al., 2003). Research in unsupervised morphological learning explores ways of deriving morphology information from redundancy in the data (Goldsmith, 2001; Creutz and Lagus, 2007). Urdu NLP Relative to other languages with similar populations, Urdu has not received a lot of attention (Hussain, 2004b). A close sister language of Urdu, Hindi, has received relatively more attention. One particular publication on Hindi is relevant here as it explores similar issues: Mahesh and Sinha (2007) exploit rich morphology in Hindi to handle translation divergences between Hindi and English in a rule-based MT approach"
2008.amta-papers.9,P08-1084,0,0.0603905,"d are spelling expansion, morphological expansion, dictionary term expansion and proper name transliteration. The techniques are used to extend the phrase table with recycled or novel phrases. His results show a consistent improvement over a state-of-theart baseline in terms of BLEU and a manual error analysis. The work presented in this paper is in the intersection of multiple active areas of research. In particular we briefly describe three areas: unsupervised multilingual learning of morphology, OOV handling in Machine Translation and Urdu NLP. Unsupervised Multilingual Morphology Learning Snyder and Barzilay (2008) describe an approach for unsupervised learning of cross-lingual morphological segmentation using parallel corpora for three Semitic languages (Arabic, Hebrew and Aramaic) and English. Their models jointly induce morpheme boundaries for the studied languages and identified cross-lingual morpheme patterns. Their work overlaps research in unsupervised morphology learning and research in multilingual learning. Much research has been done in multilingual learning to build tools exploiting parallel data from morphology to word sense tagging (Yarowsky et al., 2001; Diab and Resnik, 2002; Rogati et a"
2008.amta-papers.9,P06-1122,0,0.0912738,", 2006). We are interested here in the specific task of on-line OOV handling. The most common solution for such OOV words is to delete them from the output – thus gaming precision-based evaluation metrics such as BLEU (Papineni et al., 2002). We will not consider this “solution.” Some previous approaches anticipate OOV words that are potentially morphologically related to in-vocabulary (INV) words. For example, Yang and Kirchhoff (2006) extend phrase tables with back-off phrase variants that are segmented into smaller morphological units. Test data OOV terms are segmented in a similar manner. Talbot and Osborne (2006) propose a language-independent approach for modeling lexical redundancy for MT. They use this ap1 108 http://www.nist.gov/speech/tests/mt/2008/doc/ [8th AMTA conference, Hawaii, 21-25 October 2008] Humayoun, 2006). We will not discuss syntactic issues in this work. We also present a preliminary analysis of the types of OOVs seen in Urdu to further motivate our work. not relevant to the target language (English). By relating an OOV term to an INV term using one of these rules, we can expand existing phrase tables with “recycled phrases” of the INV terms. This approach is similar to Habash (200"
2008.amta-papers.9,W07-0705,0,0.0209241,"s follows. Section 2 presents previous related research. Section 3 presents some relevant background on Urdu linguistics and profiles specific problems for UrduEnglish MT. Section 4 describes our baseline MT system. Section 5 details the morphology variation rule learning approach and discusses the different types of learned rules. Section 6 presents our system evaluation and results. 107 [8th AMTA conference, Hawaii, 21-25 October 2008] 2 Related Work proach to smooth phrase-based translation models. Their approach does not target OOVs in particular, but clearly helps address many OOV cases. Vilar et al. (2007) address spelling-variant OOVs in MT through on-line re-tokenization into letters and combination with a word-based system. Habash (2008) compares and combines four techniques for online handling of Out-of-Vocabulary words in ArabicEnglish phrase-based MT. The techniques used are spelling expansion, morphological expansion, dictionary term expansion and proper name transliteration. The techniques are used to extend the phrase table with recycled or novel phrases. His results show a consistent improvement over a state-of-theart baseline in terms of BLEU and a manual error analysis. The work pre"
2008.amta-papers.9,E06-1006,0,0.0221845,"sparsity and OOV rates. This is especially true for languages with rich morphology such as Spanish, Catalan, and Serbian (Popovi´c and Ney, 2004) and Arabic (Lee, 2004; Habash and Sadat, 2006). We are interested here in the specific task of on-line OOV handling. The most common solution for such OOV words is to delete them from the output – thus gaming precision-based evaluation metrics such as BLEU (Papineni et al., 2002). We will not consider this “solution.” Some previous approaches anticipate OOV words that are potentially morphologically related to in-vocabulary (INV) words. For example, Yang and Kirchhoff (2006) extend phrase tables with back-off phrase variants that are segmented into smaller morphological units. Test data OOV terms are segmented in a similar manner. Talbot and Osborne (2006) propose a language-independent approach for modeling lexical redundancy for MT. They use this ap1 108 http://www.nist.gov/speech/tests/mt/2008/doc/ [8th AMTA conference, Hawaii, 21-25 October 2008] Humayoun, 2006). We will not discuss syntactic issues in this work. We also present a preliminary analysis of the types of OOVs seen in Urdu to further motivate our work. not relevant to the target language (English)"
2008.amta-papers.9,H01-1035,0,0.0200748,"ltilingual Morphology Learning Snyder and Barzilay (2008) describe an approach for unsupervised learning of cross-lingual morphological segmentation using parallel corpora for three Semitic languages (Arabic, Hebrew and Aramaic) and English. Their models jointly induce morpheme boundaries for the studied languages and identified cross-lingual morpheme patterns. Their work overlaps research in unsupervised morphology learning and research in multilingual learning. Much research has been done in multilingual learning to build tools exploiting parallel data from morphology to word sense tagging (Yarowsky et al., 2001; Diab and Resnik, 2002; Rogati et al., 2003). Research in unsupervised morphological learning explores ways of deriving morphology information from redundancy in the data (Goldsmith, 2001; Creutz and Lagus, 2007). Urdu NLP Relative to other languages with similar populations, Urdu has not received a lot of attention (Hussain, 2004b). A close sister language of Urdu, Hindi, has received relatively more attention. One particular publication on Hindi is relevant here as it explores similar issues: Mahesh and Sinha (2007) exploit rich morphology in Hindi to handle translation divergences between"
2008.amta-papers.9,J93-1004,0,\N,Missing
2008.amta-papers.9,D08-1076,0,\N,Missing
2009.mtsummit-caasl.5,J93-1004,0,\N,Missing
2009.mtsummit-caasl.5,1994.amta-1.26,0,\N,Missing
2009.mtsummit-caasl.5,C92-4203,0,\N,Missing
2009.mtsummit-caasl.5,H01-1035,0,\N,Missing
2009.mtsummit-caasl.5,N04-4015,0,\N,Missing
2009.mtsummit-caasl.5,N09-1013,0,\N,Missing
2009.mtsummit-caasl.5,C96-2141,0,\N,Missing
2009.mtsummit-caasl.5,C94-2178,0,\N,Missing
2009.mtsummit-caasl.5,C94-1009,0,\N,Missing
2009.mtsummit-caasl.5,H05-1022,0,\N,Missing
2009.mtsummit-caasl.5,P05-1071,1,\N,Missing
2009.mtsummit-caasl.5,P91-1022,0,\N,Missing
2009.mtsummit-caasl.5,P96-1018,0,\N,Missing
2009.mtsummit-caasl.5,P93-1004,0,\N,Missing
2009.mtsummit-caasl.5,P08-2030,1,\N,Missing
2009.mtsummit-caasl.5,N06-2013,1,\N,Missing
2009.mtsummit-caasl.5,W05-0703,1,\N,Missing
2009.mtsummit-caasl.5,H91-1026,0,\N,Missing
2009.mtsummit-caasl.5,J03-1002,0,\N,Missing
2009.mtsummit-caasl.5,1991.mtsummit-papers.8,0,\N,Missing
2009.mtsummit-caasl.5,P06-1086,1,\N,Missing
2009.mtsummit-caasl.5,widdows-etal-2002-using,0,\N,Missing
2009.mtsummit-caasl.5,N07-2007,1,\N,Missing
2010.amta-srw.4,J90-2002,0,0.48683,"East somewhat closer together by better understanding each other’s societies. 1 In certain respects, Arabic Dialects have morpho-syntactic features closer to Hebrew than Modern Standard Arabic, e.g., the absence of nominal case and verbal mood, the behavior of the feminine ending in genitive constructions, the gendernumber invariance of the relativizer, and the dominance of SVO order over VSO order. We do not discuss Arabic dialects here. Alon Lavie Shuly Wintner LTI Dept. of Computer Science Carnegie Mellon U. U. of Haifa Pittsburgh, PA Haifa, Israel The dominant paradigm in contemporary MT (Brown et al., 1990) relies on large-scale parallel corpora from which correspondences between the two languages can be extracted. However, such abundant parallel corpora currently exist only for few language pairs; and low- and medium-density languages (Varga et al., 2005) require alternative approaches. Specifically, no parallel corpora exist for Hebrew–Arabic.2 As an alternative to the pure statistical approach, we are currently developing a Hebrew-to-Arabic MT system, using the Stat-XFER framework (Lavie, 2008), which is particularly suited for low-resource language pairs. We discuss in Section 2 some linguis"
2010.amta-srw.4,N06-2013,1,0.867525,"encode information on gender and rationality of nouns, which is crucial for enforcing N-Adj agreement. The implication is that in order to generate Arabic, one must overgenerate both masculine and feminine forms, delegating the choice to the language model, which chooses poorly in long-distance dependencies. 3.2 Morphological challenges Translating between two morphologically rich languages poses challenges in analysis, transfer and generation. The complex morphology induces an inherent data sparsity problem, and the limitation imposed by the dearth of available parallel corpora is magnified (Habash and Sadat, 2006). We use a morphological analyzer (Itai and Wintner, 2008) for the Hebrew source, with no morphological disambiguation module.4 This causes many wrong analyses to be processed and dramatically increases the size of the hypothesis lattice. For generation, we use an Arabic morphological generator (Habash, 2004) which requires proper specification of the morpho-syntactic features in order to generate the correct inflected form. Clitics are generated separately and then attached as a postprocess (El Kholy and Habash, 2010). 3.3 Syntactic challenges Arabic word order is relatively free, as in Hebre"
2010.amta-srw.4,W09-0425,1,0.763174,"ntrols the underlying parsing and transfer process. Crucially, Stat-XFER is a statistical MT framework, which uses statistical information to weigh word translations, phrase correspondences and target-language hypotheses; in contrast to other paradigms, however, it can utilize both automatically-created and manuallycrafted language resources, including dictionaries, morphological processors and transfer rules. Stat-XFER has been used as a platform for developing MT systems for Hindi-to-English (Lavie et al., 2003), Hebrew-to-English (Lavie et al., 2004), Chinese-to-English, French-to-English (Hanneman et al., 2009) and many other low-resource language pairs, such as Inupiaq-to-English or Mapudungunto-Spanish. Specifically, we use a Hebrew morphological analyzer (Itai and Wintner, 2008), a mediumsized dictionary, an Arabic morphological generator (Habash, 2004), and a tokenized version of the Arabic Gigaword (Graff et al., 2006) corpus as a language model. We manually constructed a grammar, currently consisting of 42 rules. Some rules manipulate morphemes. After decoding (which uses the language model) we detokenize the output sentence in its morpheme representation (El Kholy and Habash, 2010) to produce"
2010.amta-srw.4,D07-1005,0,0.0596921,"Missing"
2010.amta-srw.4,2004.tmi-1.1,1,0.873797,"linear combination of several features, and a beam-search controls the underlying parsing and transfer process. Crucially, Stat-XFER is a statistical MT framework, which uses statistical information to weigh word translations, phrase correspondences and target-language hypotheses; in contrast to other paradigms, however, it can utilize both automatically-created and manuallycrafted language resources, including dictionaries, morphological processors and transfer rules. Stat-XFER has been used as a platform for developing MT systems for Hindi-to-English (Lavie et al., 2003), Hebrew-to-English (Lavie et al., 2004), Chinese-to-English, French-to-English (Hanneman et al., 2009) and many other low-resource language pairs, such as Inupiaq-to-English or Mapudungunto-Spanish. Specifically, we use a Hebrew morphological analyzer (Itai and Wintner, 2008), a mediumsized dictionary, an Arabic morphological generator (Habash, 2004), and a tokenized version of the Arabic Gigaword (Graff et al., 2006) corpus as a language model. We manually constructed a grammar, currently consisting of 42 rules. Some rules manipulate morphemes. After decoding (which uses the language model) we detokenize the output sentence in its"
2010.amta-srw.4,J05-4003,0,0.0364466,"pected to be ambiguous; however, Google produces the following wrong translations in such cases: (15) atm / atn =⇒ Ant you.pl.m / you.pl.f =⇒ you.sg.m/f amrti say.1sg.past qlt say.1sg.past lkm =⇒ to+you.2.pl.m-dat. =⇒ lk to+you.2.sg.m/f-gen. The second test uses the fact that plural nouns in English are unspecified for gender, whereas in Hebrew and Arabic they are. Here, gender is lost in translation of plurality, and the decoder chose the most common option according to the LM. (16) mwrim / mwrwt =⇒ mςlmyn teachers.m / teachers.f =⇒ teachers.m 5 A third approach is to use comparable corpora (Munteanu and Marcu, 2005); but with no parallel data whatsoever, this is unlikely to succeed. 6 http://www.google.com/language_tools, accessed May 5th, 2010. 7 Another Hebrew-to-Arabic MT system, http://www. microsofttranslator.com/, also uses English as a pivot language, and shows similar characteristics. In the third test, we use words which are lexically ambiguous in English but not in Hebrew or Arabic. (17)(a) Tblh =⇒ TAwl¯ h table (data) =⇒ table (furniture) (b) bnq =⇒ sAHl bank (financial) =⇒ bank (shore) (c) idni =⇒ ktyb manual (by-hand) =⇒ manual (booklet) Finally, we used proper names and morphologically comp"
2010.amta-srw.4,1987.mtsummit-1.16,0,0.657819,"ures: person, gender, number, aspect (perfective, imperfective and imperative), voice (passive or active), and mood (indicative, subjunctive or jussive). For every noun, 72 forms are returned (excluding possible clitics), as a result of the various values of the features gender, number, case, possessiveness and definiteness. 4 Possible approaches As the standard paradigm of statistical MT is not applicable to Hebrew-to-Arabic MT, due to the dearth of available parallel corpora, two alternatives present themselves. One is translating using a third language (most naturally, English) as a pivot (Muraki, 1987; Wu and Wang, 2007); the other is relying on linguistically-motivated transfer rules, augmented by deep linguistic processing of both the source and the target languages.5 We consider both approaches below. 4.1 Using English as pivot The dominant Hebrew-to-Arabic MT system is Google’s.6 Google has been known to use ‘bridge’ languages in translation (Kumar et al., 2007). We provide evidence that Google’s Hebrew-to-Arabic MT uses English as a pivot, and demonstrate the shortcomings of this approach.7 As a first test, we use the number- and genderambiguity of second-person pronouns in English (y"
2010.amta-srw.4,P07-1108,0,0.0214551,"gender, number, aspect (perfective, imperfective and imperative), voice (passive or active), and mood (indicative, subjunctive or jussive). For every noun, 72 forms are returned (excluding possible clitics), as a result of the various values of the features gender, number, case, possessiveness and definiteness. 4 Possible approaches As the standard paradigm of statistical MT is not applicable to Hebrew-to-Arabic MT, due to the dearth of available parallel corpora, two alternatives present themselves. One is translating using a third language (most naturally, English) as a pivot (Muraki, 1987; Wu and Wang, 2007); the other is relying on linguistically-motivated transfer rules, augmented by deep linguistic processing of both the source and the target languages.5 We consider both approaches below. 4.1 Using English as pivot The dominant Hebrew-to-Arabic MT system is Google’s.6 Google has been known to use ‘bridge’ languages in translation (Kumar et al., 2007). We provide evidence that Google’s Hebrew-to-Arabic MT uses English as a pivot, and demonstrate the shortcomings of this approach.7 As a first test, we use the number- and genderambiguity of second-person pronouns in English (you). Since Hebrew an"
2010.jeptalnrecital-long.29,P08-2039,0,0.407573,"Missing"
2010.jeptalnrecital-long.29,E09-1011,0,0.0257442,"Missing"
2010.jeptalnrecital-long.29,N03-2002,0,0.0928914,"Missing"
2010.jeptalnrecital-long.29,E06-1032,0,0.056935,"Missing"
2010.jeptalnrecital-long.29,W09-0809,1,0.754485,"Missing"
2010.jeptalnrecital-long.29,H05-1085,0,0.050413,"Missing"
2010.jeptalnrecital-long.29,P05-1071,1,0.923475,"Missing"
2010.jeptalnrecital-long.29,N06-2013,1,0.930359,"Missing"
2010.jeptalnrecital-long.29,W04-3250,0,0.230534,"Missing"
2010.jeptalnrecital-long.29,P07-2045,0,0.0201559,"Missing"
2010.jeptalnrecital-long.29,N04-4015,0,0.0759046,"Missing"
2010.jeptalnrecital-long.29,J03-1002,0,0.0109151,"Missing"
2010.jeptalnrecital-long.29,W07-0704,0,0.114208,"Missing"
2010.jeptalnrecital-long.29,P02-1040,0,0.079098,"Missing"
2010.jeptalnrecital-long.29,N07-2037,0,0.351696,"Missing"
2010.jeptalnrecital-long.29,N06-2051,0,0.0487623,"Missing"
2010.jeptalnrecital-long.30,J04-4004,0,0.047035,"Missing"
2010.jeptalnrecital-long.30,P08-1009,0,0.250799,"Missing"
2010.jeptalnrecital-long.30,P05-1066,0,0.234944,"Missing"
2010.jeptalnrecital-long.30,W08-0307,1,0.881445,"Missing"
2010.jeptalnrecital-long.30,2009.mtsummit-caasl.4,0,0.320418,"Missing"
2010.jeptalnrecital-long.30,2007.mtsummit-papers.29,1,0.925361,"Missing"
2010.jeptalnrecital-long.30,P05-1071,1,0.858081,"Missing"
2010.jeptalnrecital-long.30,P09-2056,1,0.892285,"Missing"
2010.jeptalnrecital-long.30,N06-2013,1,0.890456,"Missing"
2010.jeptalnrecital-long.30,D09-1024,0,0.128164,"Missing"
2010.jeptalnrecital-long.30,D07-1103,0,0.0946636,"Missing"
2010.jeptalnrecital-long.30,W04-3250,0,0.0389722,"Missing"
2010.jeptalnrecital-long.30,P07-2045,0,0.0192157,"Missing"
2010.jeptalnrecital-long.30,2006.amta-papers.11,0,0.104292,"Missing"
2010.jeptalnrecital-long.30,W10-1402,1,0.885541,"Missing"
2010.jeptalnrecital-long.30,P08-1114,1,0.90466,"Missing"
2010.jeptalnrecital-long.30,W03-3017,0,0.133964,"Missing"
2010.jeptalnrecital-long.30,nivre-etal-2006-maltparser,0,0.0427623,"Missing"
2010.jeptalnrecital-long.30,J03-1002,0,0.00818449,"Missing"
2010.jeptalnrecital-long.30,P02-1040,0,0.0795527,"Missing"
2010.jeptalnrecital-long.30,2006.amta-papers.25,0,0.0336817,"Missing"
2010.jeptalnrecital-long.30,C04-1073,0,0.282836,"Missing"
2010.jeptalnrecital-long.30,W07-0401,0,0.276404,"Missing"
2010.jeptalnrecital-long.30,P06-1073,0,0.0472667,"Missing"
2011.mtsummit-papers.24,P11-2062,1,0.882066,"ons in the future. Form abstraction, however, is a double edged sword since it will lead to numerous matching points between the output and reference. To address this concern, AMEANA uses a word matching (alignment) algorithm that minimizes the number of morphological differences and sentence-relative word position. 3 Related Work Recent efforts reported on improving the quality of MT evaluation using stemming and/or paraphrasing to match output reference translations (Denkowski 2 In broken plurals, the functional number (plural) is inconsistent with the morphological ending (singular sufﬁx) (Alkuhlani and Habash, 2011). Plurality is indicated using a word template realized as a stem that is different from the singular stem. 226 and Lavie, 2010; Snover et al., 2009). None of these techniques provide detailed error analyses at the morphological level. Several publications deﬁned different error classiﬁcations and typologies for the purpose of evaluation of single systems, or comparison between systems (Flanagan, 1994; Vilar et al., 2006; Farr´us et al., 2010). Kirchhoff et al. (2007) developed a framework for semi-automatically analyzing characteristics of input documents to MT systems that determine output p"
2011.mtsummit-papers.24,W10-1751,0,0.0237532,"tive (afﬁxes and stems) and/or templatic (root and patterns) morphology. Second is Morphological Ambiguity: words with different lemmas can have the same inﬂected form. As such, a word form can have more than one morphological analysis (represented as a lemma and a set of feature-value pairs). This is especially problematic for languages with reduced orthographies such as Arabic or Hebrew. Using an abstraction of the word, such as the stem or the lemma, to match output and reference words can address the harshness of exact form matching. Stemming has been shown to be helpful in MT evaluation (Denkowski and Lavie, 2010); but simple stemming is not sufﬁcient when dealing with morphologically rich languages as it suffers from errors of omission and errors of commission (Krovetz, 1993): words with the same core meaning not sharing the same stem, and words with different core meanings sharing the same stem. This is especially problematic for words with templatic morphology, e.g., broken plurals in Arabic.2 Furthermore, simple stemming does not properly address ambiguity as most shallow stemmers do not provide more than one stem for a given word. A more sophisticated stemming approach using a morphological analyz"
2011.mtsummit-papers.24,2010.jeptalnrecital-long.29,1,0.917339,"Missing"
2011.mtsummit-papers.24,2010.eamt-1.12,0,0.0286204,"Missing"
2011.mtsummit-papers.24,P05-1071,1,0.910408,"ce                        Figure 1: Output word o2 has at least one common lemma with reference words r2 and rm−1 . Our alignment algorithm selects edges minimizing differences in features (primarily) and relative positions (secondarily), while maximizing the number of paired output-reference words. words producing a set of lemmas and their associated analyses for each word. A morphological disambiguator or part-of-speech (POS) tagger can be used to limit the choices given to AMEANA, e.g., (Habash and Rambow, 2005). This is not required and perhaps even not desirable given error propagation resulting from running a disambiguator on automatically generated text. Second: Graph Construction We build a graph where each word is represented by a node. We draw an edge for each output-reference word pair if there is at least one common lemma between them. Each edge receives a weight based on the following equation: W = min (Dab ) +    Pa Pb   Sa − S  2 b We deﬁne a and b as words in output and reference. For each pair of morphological analyses for a and b sharing the same lemma, we compute the count of"
2011.mtsummit-papers.24,2007.mtsummit-papers.39,1,0.617681,"nkowski 2 In broken plurals, the functional number (plural) is inconsistent with the morphological ending (singular sufﬁx) (Alkuhlani and Habash, 2011). Plurality is indicated using a word template realized as a stem that is different from the singular stem. 226 and Lavie, 2010; Snover et al., 2009). None of these techniques provide detailed error analyses at the morphological level. Several publications deﬁned different error classiﬁcations and typologies for the purpose of evaluation of single systems, or comparison between systems (Flanagan, 1994; Vilar et al., 2006; Farr´us et al., 2010). Kirchhoff et al. (2007) developed a framework for semi-automatically analyzing characteristics of input documents to MT systems that determine output performance. The framework heavily depends on human annotation. To our knowledge, there haven’t been many efforts to build publicly available error analysis tools for MT output with focus on rich morphology. Popovi´c and Ney (2006) provided precision and recall measures of MT output for different verbal inﬂections, but they only focus on Spanish verbs. Their word matching technique is a based on PER which may not be sufﬁcient to apply in more general settings (i.e., no"
2011.mtsummit-papers.24,P07-2045,0,0.0208149,"Missing"
2011.mtsummit-papers.24,J03-1002,0,0.00394599,"able lists every word in the MT output (column 1) with the reference word used to modify it (column 2). Column 3 speciﬁes the reference-match category: exact match indicates the MT output word appears in the reference; unmatchable indicates no match is found; and lemma match indicates a lemma-level match. For lemma match cases, the differences in MT output and reference morphological features are speciﬁed in columns 4 and 5. 2007) trained on an English-Arabic parallel corpus of about 135k sentences (4 million words). Phrasetable maximum phrase length is 8. Word alignment is done using GIZA++ (Och and Ney, 2003) run on the lemma level of representation. Lemmatization as well as tokenization (discussed below) is done using the MADA+TOKAN toolkit (Habash and Rambow, 2005). A 5-gram language model is based on 200M words from the Arabic Gigaword together and the Arabic side of the training data (Stolcke, 2002). Decoding weight optimization (Och, 2003) is done using 300 sentences from the 2004 NIST MT evaluation test set (MT04). Systems are compared on their performance on the 2005 NIST MT evaluation set (MT05). This Arabic-English test set has four English references. We invert it by selecting the ﬁrst E"
2011.mtsummit-papers.24,P03-1021,0,0.0285592,"T output and reference morphological features are speciﬁed in columns 4 and 5. 2007) trained on an English-Arabic parallel corpus of about 135k sentences (4 million words). Phrasetable maximum phrase length is 8. Word alignment is done using GIZA++ (Och and Ney, 2003) run on the lemma level of representation. Lemmatization as well as tokenization (discussed below) is done using the MADA+TOKAN toolkit (Habash and Rambow, 2005). A 5-gram language model is based on 200M words from the Arabic Gigaword together and the Arabic side of the training data (Stolcke, 2002). Decoding weight optimization (Och, 2003) is done using 300 sentences from the 2004 NIST MT evaluation test set (MT04). Systems are compared on their performance on the 2005 NIST MT evaluation set (MT05). This Arabic-English test set has four English references. We invert it by selecting the ﬁrst English reference to be our input and use the Arabic side as the only reference. The three systems vary as follows: the D0 system uses no morphological tokenization whatsoever; the T B system uses the PATB tokenization scheme (Maamouri et al., 2004); and the L EM system uses PATB tokenization and keeps the main word in lemma form. T B has be"
2011.mtsummit-papers.24,W07-0704,0,0.0678016,"Missing"
2011.mtsummit-papers.24,P02-1040,0,0.104768,"cally for Englishto-Arabic MT. Most published research on MT targets translation into English, a morphologically poor language; however, MT into languages with richer morphology has been receiving increasing attention (Oﬂazer and Durgar El-Kahlout, 2007; El Kholy and Habash, 2010; Williams and Koehn, 2011). Sections 2 and 3 present the motivation of this work and related efforts, respectively. Section 4 discusses our approach to building AMEANA. Sections 5 and 6 report on a case study including detailed analysis and veriﬁcation. 2 Motivation Most MT automatic evaluation metrics, such as BLEU (Papineni et al., 2002), focus on comparing an MT output against a set of references in order to assign a similarity score. The scores are typically based on exact word matching, a particularly harsh measure especially for morphologically rich languages. This is due in part to two phenomena. First is Morphological Richness: words sharing the same core meaning (represented by the lemma or lexeme) can be said to inﬂect for different morphological features, e.g., gender and number. These features can realize using concatenative (afﬁxes and stems) and/or templatic (root and patterns) morphology. Second is Morphological"
2011.mtsummit-papers.24,W09-0441,0,0.0278986,"dress this concern, AMEANA uses a word matching (alignment) algorithm that minimizes the number of morphological differences and sentence-relative word position. 3 Related Work Recent efforts reported on improving the quality of MT evaluation using stemming and/or paraphrasing to match output reference translations (Denkowski 2 In broken plurals, the functional number (plural) is inconsistent with the morphological ending (singular sufﬁx) (Alkuhlani and Habash, 2011). Plurality is indicated using a word template realized as a stem that is different from the singular stem. 226 and Lavie, 2010; Snover et al., 2009). None of these techniques provide detailed error analyses at the morphological level. Several publications deﬁned different error classiﬁcations and typologies for the purpose of evaluation of single systems, or comparison between systems (Flanagan, 1994; Vilar et al., 2006; Farr´us et al., 2010). Kirchhoff et al. (2007) developed a framework for semi-automatically analyzing characteristics of input documents to MT systems that determine output performance. The framework heavily depends on human annotation. To our knowledge, there haven’t been many efforts to build publicly available error an"
2011.mtsummit-papers.24,P11-4010,0,0.0661516,"th focus on rich morphology. Popovi´c and Ney (2006) provided precision and recall measures of MT output for different verbal inﬂections, but they only focus on Spanish verbs. Their word matching technique is a based on PER which may not be sufﬁcient to apply in more general settings (i.e., not just verbs). Tantug et al. (2008) created a tool which is closely related to our work. They extended the BLEU and METEOR metrics to handle errors in Turkish morphology. Their matching algorithm uses Turkish word roots and a wordnet hierarchy, and it produces oracle score comparable to what AMEANA does. Stymne (2011) presented a tool for annotation of bilingual segments intended for error analysis of MT. It utilizes a given error typology to annotate translations from an MT system. The tool does not provide detailed morphological error analysis. 4 Approach In this section, we describe the algorithm used in aligning the output words with their matching reference words. The alignment is then used to produce detailed morphological-error diagnostics and an oracularly modiﬁed output to use with MT evaluation metrics. A sample of these diagnostics is shown in Section 6. 4.1 Alignment Algorithm For every sentenc"
2011.mtsummit-papers.24,vilar-etal-2006-error,0,0.129559,"Missing"
2011.mtsummit-papers.24,W11-2126,0,0.017719,"sing any evaluation metric. AMEANA is a language independent tool except that a morphological analyzer must be provided for a given language. Although AMEANA can be used in a variety of NLP tasks involving text generation, we focus here on usability in the context of Machine Translation (MT) and demonstrate it speciﬁcally for Englishto-Arabic MT. Most published research on MT targets translation into English, a morphologically poor language; however, MT into languages with richer morphology has been receiving increasing attention (Oﬂazer and Durgar El-Kahlout, 2007; El Kholy and Habash, 2010; Williams and Koehn, 2011). Sections 2 and 3 present the motivation of this work and related efforts, respectively. Section 4 discusses our approach to building AMEANA. Sections 5 and 6 report on a case study including detailed analysis and veriﬁcation. 2 Motivation Most MT automatic evaluation metrics, such as BLEU (Papineni et al., 2002), focus on comparing an MT output against a set of references in order to assign a similarity score. The scores are typically based on exact word matching, a particularly harsh measure especially for morphologically rich languages. This is due in part to two phenomena. First is Morpho"
2011.mtsummit-papers.24,tantug-etal-2008-bleu,0,\N,Missing
2011.mtsummit-papers.24,D08-1076,0,\N,Missing
2012.amta-papers.12,D07-1090,0,0.0406081,"Missing"
2012.amta-papers.12,condon-etal-2010-evaluation,0,0.0288918,"Missing"
2012.amta-papers.12,J10-3008,0,0.0205943,"Missing"
2012.amta-papers.12,2008.amta-govandcom.8,0,0.106547,"Missing"
2012.amta-papers.12,P05-1045,0,0.00385752,"val accuracy, and focuses on sentences that should be relevant but are judged irrelevant due to errors in result translation. End-to-end (TLIR): MT is used for both retrieval and relevance annotation. This setting represents the full end-to-end TLIR system, where MT has an impact on both retrieval and result understanding. 2 Comparing query translation methods is not the focus of this paper, so query translations are identical across all experimental settings. HT is never used for query translation. 4 4.1 Experiments Query Extraction Queries were created by running the Stanford NE recognizer (Finkel et al., 2005) on one of the HTs. This list of all possible NE queries for the corpus was filtered to remove near-duplicates and incorrectly tagged phrases. After relevance annotation, queries that had one or zero results were filtered. The average number of relevant sentences per query was 8 for NW and 5 for WB. 4.2 MT systems We use two pre-existing state-of-the-art ArabicEnglish SMT systems with widely different implementations MT A was built using HiFST (de Gispert et al., 2010), a hierarchical phrase-based SMT system implemented using finite state transducers. It is trained on all the parallel corpora"
2012.amta-papers.12,P08-1045,0,0.0455666,"Missing"
2012.amta-papers.12,P07-2045,0,0.00489355,"e-of-the-art ArabicEnglish SMT systems with widely different implementations MT A was built using HiFST (de Gispert et al., 2010), a hierarchical phrase-based SMT system implemented using finite state transducers. It is trained on all the parallel corpora in the NIST MT08 Arabic Constrained Data track (5.9M parallel sentences). The first-pass 4-gram language model (LM) is trained on the English side of the parallel text and Gigaword 3. The second-pass 5-gram LM is a zerocutoff stupid-backoff (Brants et al., 2007) estimated using 6.6B words of English newswire text. MT B was built using Moses (Koehn et al., 2007), and is a non-hierarchical phrase-based system. It is trained on 3.2M sentences of parallel text using several LDC corpora including some available only through the GALE program (e.g., LDC2004T17, LDC2004E72, LDC2005E46 and LDC2004T18). The data includes some sentences from the ISI corpus (LDC2007T08) and UN corpus (LDC2004E13) selected to specifically add vocabulary absent in the other resources. The Arabic text is tokenized and lemmatized using the MADA+TOKAN system (Habash et al., 2009). The system uses a 5-gram LM that was trained on Gigaword 4. Both systems are tuned for BLEU score using"
2012.amta-papers.12,P09-2084,0,0.0241542,"built from Wikipedia, the CIA world factbook and the NEs from the Buckwalter analyzer dictionary (Buckwalter, 2004). Since all of the queries are NEs, this dictionary is a high-precision, but low recall resource. If the translation is not found, a phrase table from MT B is used as a dictionary. The final back-off searches a large corpus of machine translated documents, which is a lower precision resource. This resource simulates the task context that a large CLIR corpus would provide; prior work has shown that words that are deleted in one sentence are often successfully translated in others (Ma and McKeown, 2009). If the translation is still not found, the original query is expanded using synonyms extracted from Wikipedia, and then the cascaded translation is applied again. 5 Analysis of Baselines Figure 2 shows results from all experimental settings; in this section we discuss the results for QT and DT. All of the models are evaluated on the newswire and web genres (the top and bottom charts, respectively) and MT A and MT B (left and 3 http://www.crowdflower.com right, respectively). Each setting is analyzed four different ways, summarized in Table 1. This analysis demonstrates the strengths and weak"
2012.amta-papers.12,P99-1027,0,0.060703,"end TLIR task. For instance, in the NW genre, QT has higher MAP than DT in the CLIR evaluation (Lost in Retrieval), but DT has higher (translated) MAP than QT in the TLIR evaluation (End-to-End). This highlights the limitations of evaluating CLIR models without taking result translation into account. 6 Lost and Found in Retrieval The baseline QT and DT models are both severely affected by errors in MT. A better retrieval model would retrieve all the relevant results, but rank the translations that appear relevant the highest. Several hybrid methods for combining QT and DT exist. For instance, McCarley (1999) and Chen and Gey (2003) describe methods for combining the results of separate QT and DT searches using re-ranking. We chose to use the simultaneous multilingual IR (SMLIR) model from (Parton et al., 2008) because it requires only a single index and a single search at runtime, and does not require tuning a re-ranker. SMLIR: In the SMLIR model, each sentence is indexed as a bilingual sentence with different fields for each language, and the structured query is composed of both query-language and documentlanguage terms. In a CLIR evaluation without result translation, SMLIR outperformed both QT"
2012.amta-papers.12,P02-1040,0,0.0821984,"Missing"
2012.amta-papers.12,2012.eamt-1.34,1,0.742334,"Missing"
2012.amta-papers.12,W07-0707,0,0.0223677,"Missing"
2012.amta-papers.12,P10-1063,0,0.0608833,"Missing"
2012.amta-papers.12,2011.mtsummit-papers.58,0,0.0630676,"Missing"
2012.amta-papers.12,stymne-ahrenberg-2010-using,0,0.0405724,"Missing"
2012.amta-papers.12,vilar-etal-2006-error,0,0.0338232,"Missing"
2012.eamt-1.34,D07-1090,0,0.0231043,"urced human adequacy judgments. 5.1 MT Systems We used state-of-the art Arabic-English MT systems with widely different implementations. MT A was built using HiFST (de Gispert et al., 115 2010), a hierarchical phrase-based SMT system implemented using finite state transducers. It is trained on all the parallel corpora in the NIST MT08 Arabic Constrained Data track (5.9M parallel sentences, 150M words per language). The first-pass 4-gram language model (LM) is trained on the English side of the parallel text and a subset of Gigaword 3. The second-pass 5-gram LM is a zero-cutoff stupid-backoff (Brants et al., 2007) estimated using 6.6B words of English newswire text. MT B was built using Moses (Koehn et al., 2007), and is a non-hierarchical phrase-based system. It is trained on 3.2M sentences of parallel text (65M words on the English side) using several LDC corpora including some available only through the GALE program (e.g., LDC2004T17, LDC2004E72, LDC2005E46 and LDC2004T18). The data includes some sentences from the ISI corpus (LDC2007T08) and UN corpus (LDC2004E13) selected to specifically add vocabulary absent in the other resources. The Arabic text is tokenized and lemmatized using the MADA+TOKAN"
2012.eamt-1.34,W07-0718,0,0.119192,"Missing"
2012.eamt-1.34,condon-etal-2010-evaluation,0,0.0924787,"Missing"
2012.eamt-1.34,J10-3008,1,0.869312,"Missing"
2012.eamt-1.34,W11-2107,0,0.0302277,"LDC2004E13) selected to specifically add vocabulary absent in the other resources. The Arabic text is tokenized and lemmatized using the MADA+TOKAN system (Habash et al., 2009). Lemmas are used for Giza++ alignment only. The tokenization scheme used is the Penn Arabic Treebank scheme (Habash, 2010; Sadat and Habash, 2006). The system uses a 5-gram LM that was trained on Gigaword 4. Both systems are tuned for BLEU score using MERT. 5.2 Automatic and Human Evaluation We ran several automatic metrics on the baseline MT output and the post-edited MT output: BLEU (Papineni et al., 2002), Meteor-a (Denkowski and Lavie, 2011) and TERp-a (Snover et al., 2009). BLEU is based on n-gram precision, while Meteor takes both precision and recall into account. TERp also implicitly takes precision and recall into account, since it is similar to edit distance. Both Meteor and TERp allow more flexible n-gram matching than BLEU, since they allow matching across stems, synonyms and paraphrases. Meteor-a and TERp-a are both tuned to have high correlation with human adequacy judgments. In contrast to automatic system-level metrics, human judgments can give a nuanced sentencelevel view of particular aspects of the MT. In order to"
2012.eamt-1.34,2008.amta-govandcom.8,0,0.625824,"Missing"
2012.eamt-1.34,2006.eamt-1.27,0,0.119724,"Missing"
2012.eamt-1.34,P05-1045,0,0.00482056,"ons for the errors, and 3) apply the suggestions. All the APEs use identical algorithms for steps 1 and 2, and only differ in how they apply the suggestions. The algorithms are language-pair independent, though we carried out all of our experiments on Arabic-English MT. 4.1 Pre-Processing The Arabic source text was analyzed and tokenized using MADA+TOKAN (Habash et al., 2009). Each MT system used a different tokenization scheme, so the source sentences were processed in two separate pipelines. Separate named entity recognizers (NER) were built for each pipeline using the Stanford NER toolkit (Finkel et al., 2005), by training on CoNLL and ACE data. Each translated English sentence was re-cased using Moses and then analyzed using the Stanford CoreNLP pipeline to get part-of-speech (POS) tags (Toutanova et al., 2003) and NER (Finkel et al., 2005). 4.2 Detecting Errors and Suggesting Corrections The APEs address specific adequacy errors that we have found to be most detrimental for the CLQA task: content words that are not translated at all, content words that are translated to function words, and mistranslated named entities. In the error detection step, these types of errors are detected via an algorit"
2012.eamt-1.34,2007.mtsummit-papers.34,0,0.285131,"Missing"
2012.eamt-1.34,P07-2045,0,0.0106204,"widely different implementations. MT A was built using HiFST (de Gispert et al., 115 2010), a hierarchical phrase-based SMT system implemented using finite state transducers. It is trained on all the parallel corpora in the NIST MT08 Arabic Constrained Data track (5.9M parallel sentences, 150M words per language). The first-pass 4-gram language model (LM) is trained on the English side of the parallel text and a subset of Gigaword 3. The second-pass 5-gram LM is a zero-cutoff stupid-backoff (Brants et al., 2007) estimated using 6.6B words of English newswire text. MT B was built using Moses (Koehn et al., 2007), and is a non-hierarchical phrase-based system. It is trained on 3.2M sentences of parallel text (65M words on the English side) using several LDC corpora including some available only through the GALE program (e.g., LDC2004T17, LDC2004E72, LDC2005E46 and LDC2004T18). The data includes some sentences from the ISI corpus (LDC2007T08) and UN corpus (LDC2004E13) selected to specifically add vocabulary absent in the other resources. The Arabic text is tokenized and lemmatized using the MADA+TOKAN system (Habash et al., 2009). Lemmas are used for Giza++ alignment only. The tokenization scheme used"
2012.eamt-1.34,P09-2084,0,0.399041,"ionary extracted from the Buckwalter analyzer (Buckwalter, 2004) and an English synonym dictionary from the CIA World Factbook.1 They are high precision and low recall: most errors do not have matches in the dictionaries, but when they do, they are often correct, particularly for NEs. 1 http://www.cia.gov/library/publications/the-world-factbook 113 Background MT corpus: Since our motivation is CLQA, we also draw on a resource specific to CLQA: a background corpus of about 120,000 Arabic newswire and web documents that have been translated into English by a state-of-the-art industry MT system. Ma and McKeown (2009) were able to exploit a similar pseudo-parallel corpus to correct deleted verbs, since words deleted in one sentence are frequently correctly translated in other sentences. For each error, the source-language phrase is converted into a query to search all three resources. Then the target-language results are aggregated and ranked by overall confidence scores. The confidence scores are a weighted combination of phrase translation probability, number of dictionary matches and term frequencies in the background corpus. The weights were set manually on a development corpus. 4.3 Rule-Based APE Tabl"
2012.eamt-1.34,P02-1040,0,0.0914811,"orpus (LDC2007T08) and UN corpus (LDC2004E13) selected to specifically add vocabulary absent in the other resources. The Arabic text is tokenized and lemmatized using the MADA+TOKAN system (Habash et al., 2009). Lemmas are used for Giza++ alignment only. The tokenization scheme used is the Penn Arabic Treebank scheme (Habash, 2010; Sadat and Habash, 2006). The system uses a 5-gram LM that was trained on Gigaword 4. Both systems are tuned for BLEU score using MERT. 5.2 Automatic and Human Evaluation We ran several automatic metrics on the baseline MT output and the post-edited MT output: BLEU (Papineni et al., 2002), Meteor-a (Denkowski and Lavie, 2011) and TERp-a (Snover et al., 2009). BLEU is based on n-gram precision, while Meteor takes both precision and recall into account. TERp also implicitly takes precision and recall into account, since it is similar to edit distance. Both Meteor and TERp allow more flexible n-gram matching than BLEU, since they allow matching across stems, synonyms and paraphrases. Meteor-a and TERp-a are both tuned to have high correlation with human adequacy judgments. In contrast to automatic system-level metrics, human judgments can give a nuanced sentencelevel view of part"
2012.eamt-1.34,C10-2109,1,0.93042,"was re-cased using Moses and then analyzed using the Stanford CoreNLP pipeline to get part-of-speech (POS) tags (Toutanova et al., 2003) and NER (Finkel et al., 2005). 4.2 Detecting Errors and Suggesting Corrections The APEs address specific adequacy errors that we have found to be most detrimental for the CLQA task: content words that are not translated at all, content words that are translated to function words, and mistranslated named entities. In the error detection step, these types of errors are detected via an algorithm from prior work that uses bilingual POS tags and word alignments (Parton and McKeown, 2010). Each flagged error consists of one or more source-language tokens and zero or more target-language tokens. In the error correction step, the source and target sentences and all the flagged errors are passed to the suggestion generator, which uses the following three resources. Phrase Table: The phrase table from MT B is used as a phrase dictionary (described in more detail in ??). Dictionaries: We also use a translation dictionary extracted from Wikipedia, a bilingual name dictionary extracted from the Buckwalter analyzer (Buckwalter, 2004) and an English synonym dictionary from the CIA Worl"
2012.eamt-1.34,W07-0707,0,0.119951,"Missing"
2012.eamt-1.34,P06-1001,1,0.825975,"is trained on 3.2M sentences of parallel text (65M words on the English side) using several LDC corpora including some available only through the GALE program (e.g., LDC2004T17, LDC2004E72, LDC2005E46 and LDC2004T18). The data includes some sentences from the ISI corpus (LDC2007T08) and UN corpus (LDC2004E13) selected to specifically add vocabulary absent in the other resources. The Arabic text is tokenized and lemmatized using the MADA+TOKAN system (Habash et al., 2009). Lemmas are used for Giza++ alignment only. The tokenization scheme used is the Penn Arabic Treebank scheme (Habash, 2010; Sadat and Habash, 2006). The system uses a 5-gram LM that was trained on Gigaword 4. Both systems are tuned for BLEU score using MERT. 5.2 Automatic and Human Evaluation We ran several automatic metrics on the baseline MT output and the post-edited MT output: BLEU (Papineni et al., 2002), Meteor-a (Denkowski and Lavie, 2011) and TERp-a (Snover et al., 2009). BLEU is based on n-gram precision, while Meteor takes both precision and recall into account. TERp also implicitly takes precision and recall into account, since it is similar to edit distance. Both Meteor and TERp allow more flexible n-gram matching than BLEU,"
2012.eamt-1.34,N07-1064,0,0.200693,"Missing"
2012.eamt-1.34,W09-0441,0,0.0362319,"d vocabulary absent in the other resources. The Arabic text is tokenized and lemmatized using the MADA+TOKAN system (Habash et al., 2009). Lemmas are used for Giza++ alignment only. The tokenization scheme used is the Penn Arabic Treebank scheme (Habash, 2010; Sadat and Habash, 2006). The system uses a 5-gram LM that was trained on Gigaword 4. Both systems are tuned for BLEU score using MERT. 5.2 Automatic and Human Evaluation We ran several automatic metrics on the baseline MT output and the post-edited MT output: BLEU (Papineni et al., 2002), Meteor-a (Denkowski and Lavie, 2011) and TERp-a (Snover et al., 2009). BLEU is based on n-gram precision, while Meteor takes both precision and recall into account. TERp also implicitly takes precision and recall into account, since it is similar to edit distance. Both Meteor and TERp allow more flexible n-gram matching than BLEU, since they allow matching across stems, synonyms and paraphrases. Meteor-a and TERp-a are both tuned to have high correlation with human adequacy judgments. In contrast to automatic system-level metrics, human judgments can give a nuanced sentencelevel view of particular aspects of the MT. In order to compare adequacy across APEs, we"
2012.eamt-1.34,2011.mtsummit-papers.58,0,0.271781,"Missing"
2012.eamt-1.34,stymne-ahrenberg-2010-using,0,0.0853294,"Missing"
2012.eamt-1.34,2011.mtsummit-papers.16,0,0.0686158,"Missing"
2012.eamt-1.34,N03-1033,0,0.00674048,"though we carried out all of our experiments on Arabic-English MT. 4.1 Pre-Processing The Arabic source text was analyzed and tokenized using MADA+TOKAN (Habash et al., 2009). Each MT system used a different tokenization scheme, so the source sentences were processed in two separate pipelines. Separate named entity recognizers (NER) were built for each pipeline using the Stanford NER toolkit (Finkel et al., 2005), by training on CoNLL and ACE data. Each translated English sentence was re-cased using Moses and then analyzed using the Stanford CoreNLP pipeline to get part-of-speech (POS) tags (Toutanova et al., 2003) and NER (Finkel et al., 2005). 4.2 Detecting Errors and Suggesting Corrections The APEs address specific adequacy errors that we have found to be most detrimental for the CLQA task: content words that are not translated at all, content words that are translated to function words, and mistranslated named entities. In the error detection step, these types of errors are detected via an algorithm from prior work that uses bilingual POS tags and word alignments (Parton and McKeown, 2010). Each flagged error consists of one or more source-language tokens and zero or more target-language tokens. In"
2012.eamt-1.34,vilar-etal-2006-error,0,0.177624,"Missing"
2012.eamt-1.34,W11-2152,0,\N,Missing
2012.eamt-1.34,2010.iwslt-keynotes.2,0,\N,Missing
2012.eamt-1.34,P10-2033,1,\N,Missing
2012.eamt-1.6,W09-0809,1,0.906186,"Missing"
2012.eamt-1.6,P05-1071,1,0.81476,"te the rest of the morphological features and inflected forms in later steps. The output of lexical translation is input to the morphological generation step directly or is first enriched by additional morphological features predicted in the morphology prediction step. 4.2 In training the CRF model, we use the same data used in training the lexical translation step (Section 5). We create three datasets from this data. The first is the original gold data where we train the CRF module on clean Arabic text and gold feature values that are determined using a state-ofthe-art POS tagger for Arabic (Habash and Rambow, 2005). Although the automatic tagging does produce errors, we still call this data set gold since the Arabic is correctly inflected naturally occurring text. The second dataset is created by translating the whole data using the translation model created by the lexical translation step. The intuition here is to model lexical translation errors by training the CRF models on data similar in quality to its expected input. The last dataset is the combination of gold and translated dataset. Morphology Prediction Morphology prediction takes the output of lexical translation and tries to enrich it by predi"
2012.eamt-1.6,N06-2013,1,0.925368,"Missing"
2012.eamt-1.6,P03-1054,0,0.00417219,"dequacy and fluency of the translation quality. Starting from column three till the end are percentages of the error contributed by each morphological features. Since multiple errors can occur, these values overlap. sist of the Arabic output from the lexical translation step (lemma plus certain features), the equivalent aligned English word, English POS and English context (+/- two words). The Syntax features consist of the English parent word in a dependency tree, the dependency relation and the equivalent Arabic output word of the English parent. English is parsed using the Stanford Parser (Klein and Manning, 2003). A L EM ) plus zero or more morphological features. We use an abstract representation for the morphological features so that each word is represented as a lemma and a set of feature-value pairs. Table 2 shows a sample sentence in the above-mentioned representations. This way we simplify the translation task by targeting a less complex output. The key point here is to keep the morphological features that help the translation task and then try to generate the rest of the morphological features and inflected forms in later steps. The output of lexical translation is input to the morphological ge"
2012.eamt-1.6,P07-2045,0,0.00689207,"c Treebank (LDC2005E46), and Ummah (LDC2004T18). Word alignment is done using GIZA++ (Och and Ney, 2003). For language modeling, we use 200M words from the Arabic Gigaword Corpus (LDC2007T40) together with the Arabic side of our training data. We used 5-grams for all LMs implemented using the SRILM toolkit (Stolcke, 2002). MADA is used to tokenize the Arabic text and produce lemmas and their accompanied morphological features. English preprocessing simply includes down-casing, separating punctuation and splitting off “’s”. All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). The decoding weight optimization was done using a set of 300 sentences from the 2004 NIST MT evaluation test set (MT04). The tuning is based on tokenized Arabic without detokenization. We use a maximum phrase length of size 8. We report results on the 2005 NIST MT evaluation set (MT05). These test sets were created for ArabicEnglish MT and have four English references. We arbitrarily picked the first English reference to be source and used the Arabic source as the only reference. We evaluate using BLEU-4 (Papineni et al., 2002). Our baseline replicates the work of El Kholy and Habash (2010a)"
2012.eamt-1.6,W04-3250,0,0.179932,"Missing"
2012.eamt-1.6,P07-1017,0,0.125696,"Missing"
2012.eamt-1.6,J03-1002,0,0.00658036,"Missing"
2012.eamt-1.6,P02-1040,0,0.0848743,"Missing"
2012.eamt-1.6,N07-2037,0,0.0497276,"Missing"
2012.eamt-1.6,P08-1059,0,0.161903,"Missing"
2012.eamt-1.6,P10-1047,0,0.233124,"Missing"
2012.eamt-1.6,2010.amta-papers.4,0,0.526688,"he translation models. Both lexical translation and generation are implemented as phrase-based SMT systems (Koehn et al., 2007). Morphology prediction is an optional step implemented using a supervised discriminative learning model. Generation can be done from lemmas and any subset of Arabic inflectional features. Detokenization simply stitches the words and clitics together as a post-processing step (Badr et al., 2008; El Kholy and Habash, 2010a). We follow numerous previously published efforts on the value of tokenization for EnglishArabic SMT (Badr et al., 2008; El Kholy and Habash, 2010a; Al-Haj and Lavie, 2010) and focus on the question of how to improve the translation of tokenized words using deeper representations, namely lemmas and features. Within our framework, we can model the translation of different Arabic linguistic features as part of the lexical translation step, as part of the generation step, or model them using an independent morphology prediction step. Some features, such as clitics, can be modeled well through simple tokenization and detokenization (which can be thought of as part of lexical translation). We build on a previous effort in improving the quality of the English-to-Arabi"
2012.eamt-1.6,P11-2062,1,0.891714,"Missing"
2012.eamt-1.6,P08-2039,0,0.14258,"in English is not expressed morphologically. When translating from English into Arabic, we expect to be able to model shared morphological features more than absent features or features expressed only syntactically in English or Arabic, e.g., the possessive construction. Another approach is to model translation and morphology independently in a sequential manner. A common method within this approach is to morphologically preprocess the training data before training the translation models, e.g., morphological tokenization of clitics (Habash and Sadat, 2006; Oflazer and Durgar El-Kahlout, 2007; Badr et al., 2008). Tokenization reduces sparsity of the data and increases the symmetry between source and target, which in return improves the quality of the translation. There is a large space of different tokenization schemes for Arabic. In our experiments, we use the Penn Arabic Treebank (PATB) tokenization scheme which was shown in previous effort by El Kholy and Habash (2010a) to perform well when translating into Arabic. As a result of tokenization, a post-processing step is needed to recombine (detokenize) the clitics back to the word. This is a somewhat complex task involving several orthographic and"
2012.eamt-1.6,E06-1032,0,0.0421314,"Missing"
2012.eamt-1.6,P11-1004,0,0.132554,"Missing"
2012.eamt-1.6,2010.jeptalnrecital-long.29,1,0.845918,"Missing"
2012.eamt-1.6,2011.mtsummit-papers.24,1,0.849525,"Missing"
2012.eamt-1.6,W12-1514,1,\N,Missing
2012.eamt-1.6,W07-0704,0,\N,Missing
2012.eamt-1.8,W05-0909,0,0.123176,"Missing"
2012.eamt-1.8,N10-1031,0,0.0294327,"Missing"
2012.eamt-1.8,P08-1115,0,0.0245243,"s overaggressive segmentation, as it eliminates OOV words, but comes up with completely unrelated words instead. Conclusions and Future Work We explored a range of preprocessing solutions for Hebrew-English SMT. Our best system, using a morphological analyzer and tagger, increases 3.5 BLEU points over a no-tokenization baseline on a blind test set. The next best result we got (as measured by BLEU) uses Morfessor, an unsupervised morphological segmenter. In the future, we plan to explore combinations of the different tokenization schemes, both pre- and post-translation, perhaps using lattices (Dyer et al., 2008). We also plan to consider Hebrew-specific OOV solutions similar to work by Habash (2008) on Arabic. Acknowledgments The work presented here was supported in part by a Google research award. We would like to thank Or Biran, Alon Lavie, Yuval Marton, and Shuly Wintner for helpful feedback and discussions. References Preliminary Combination Experiments In a preliminary combination experiment, we considered two simple ideas to combine the power of H TAG with other systems. First, for every sentence in the output of H TAG, if the sentence has an OOV, and M ORF does not, we replace the H TAG output"
2012.eamt-1.8,2004.tmi-1.1,0,0.190678,"ty and increases source-target symmetry (particularly when the target is morphologically poor, as in English). However, the value of preprocessing generally decreases with added training data, and is highly dependent on the language pair and particular preprocessing approach (Popovi´c and Ney, 2004; Lee, 2004; Goldwater and McClosky, 2005; Habash and Sadat, 2006; Fishel and Kirik, 2010; Al-Haj and Lavie, 2012). In this paper, we present results from a set of experiments to determine an optimal preprocessing method for Hebrew-English SMT, a language pair with limited previously published work (Lavie et al., 2004; Lembersky et al., 2011). We report on three types of preprocessing techniques using deterministic regular-expressions, unsupervised morphology learning, and morphological analysis and c 2012 European Association for Machine Translation. 43 bic (Itai and Wintner, 2008; Shilon et al., 2012; Habash, 2010). Similar to Arabic, Hebrew orthography uses optional diacritics and its morphology uses both root-pattern and affixational mechanisms. Hebrew inflects for gender, number, person, state, tense and definiteness. Furthermore, Hebrew has a set of attachable clitics that are typically separate word"
2012.eamt-1.8,N04-4015,0,0.419777,"ments. Nießen and Ney (2004) studied the impact of various types of morphosyntactic restructuring on German-English SMT and Popovi´c and Ney (2004) studied the effect of splitting words into stems and suffixes on SMT into English from Spanish, Catalan and Serbian. Their results show significant error reduction when stemming is used. Koehn and Knight (2003) compared different methods for compound splitting when translating from German to English. All of their methods improve SMT quality over a nosplitting baseline; however, the methods with the highest accuracy are not the best SMT performers. Lee (2004) investigated the use of automatic alignment of POS tagged English and affix-stem segmented Arabic to determine whether affixes should be kept separate, deleted or reattached to stems. Her results show that morphological preprocessing helps, but only for the smaller corpora sizes she investigated. As size increases, the benefits diminish. Goldwater and McClosky (2005) showed that incorporating various methods for specifying morphological information in Czech-English SMT (e.g., lemmatization and different styles of segMuch research in statistical machine translation (SMT) has shown the importan"
2012.eamt-1.8,D11-1034,0,0.0456338,"rce-target symmetry (particularly when the target is morphologically poor, as in English). However, the value of preprocessing generally decreases with added training data, and is highly dependent on the language pair and particular preprocessing approach (Popovi´c and Ney, 2004; Lee, 2004; Goldwater and McClosky, 2005; Habash and Sadat, 2006; Fishel and Kirik, 2010; Al-Haj and Lavie, 2012). In this paper, we present results from a set of experiments to determine an optimal preprocessing method for Hebrew-English SMT, a language pair with limited previously published work (Lavie et al., 2004; Lembersky et al., 2011). We report on three types of preprocessing techniques using deterministic regular-expressions, unsupervised morphology learning, and morphological analysis and c 2012 European Association for Machine Translation. 43 bic (Itai and Wintner, 2008; Shilon et al., 2012; Habash, 2010). Similar to Arabic, Hebrew orthography uses optional diacritics and its morphology uses both root-pattern and affixational mechanisms. Hebrew inflects for gender, number, person, state, tense and definiteness. Furthermore, Hebrew has a set of attachable clitics that are typically separate words in English, e.g., conju"
2012.eamt-1.8,P03-1021,0,0.034421,"Missing"
2012.eamt-1.8,P02-1040,0,0.0865054,"Missing"
2012.eamt-1.8,popovic-ney-2004-towards,0,0.060011,"Missing"
2012.eamt-1.8,N07-1029,0,0.0671347,"Missing"
2012.eamt-1.8,P08-1084,0,0.0266403,"paper is closest in its approach to Habash and Sadat (2006). We refer to their work further below. We do not discuss efforts on translation into morphologically rich languages although similar approaches have been investigated (El Kholy and Habash, 2012a; Al-Haj and Lavie, 2012) As for the use of unsupervised morphology in SMT, Virpioja et al. (2007) and Fishel and Kirik (2010) presented some experiments with mixed results. They suggested that language pairs different from those they studied (Danish-Finnish-Swedish and Estonian-English, respectively), may benefit from unsupervised morphology. Snyder and Barzilay (2008) presented results on learning Hebrew morphology using parallel and monolingual resources. Until recently, there has not been much parallel Hebrew-English data (Tsvetkov and Wintner, 2010), and consequently little work on HebrewEnglish SMT. Lavie et al. (2004) built a transferbased translation system for Hebrew-English and so did Shilon et al. (2012) for translation between Hebrew and Arabic. Lembersky et al. (2011), using the above-mentioned parallel corpus, compared the behavior of different SMT systems using training data sets that vary in reference translation directionality. To our knowle"
2012.eamt-1.8,tsvetkov-wintner-2010-automatic,0,0.309328,"milar approaches have been investigated (El Kholy and Habash, 2012a; Al-Haj and Lavie, 2012) As for the use of unsupervised morphology in SMT, Virpioja et al. (2007) and Fishel and Kirik (2010) presented some experiments with mixed results. They suggested that language pairs different from those they studied (Danish-Finnish-Swedish and Estonian-English, respectively), may benefit from unsupervised morphology. Snyder and Barzilay (2008) presented results on learning Hebrew morphology using parallel and monolingual resources. Until recently, there has not been much parallel Hebrew-English data (Tsvetkov and Wintner, 2010), and consequently little work on HebrewEnglish SMT. Lavie et al. (2004) built a transferbased translation system for Hebrew-English and so did Shilon et al. (2012) for translation between Hebrew and Arabic. Lembersky et al. (2011), using the above-mentioned parallel corpus, compared the behavior of different SMT systems using training data sets that vary in reference translation directionality. To our knowledge this is the first study comparing different tokenization techniques for HebrewEnglish SMT. We successfully show that unsupervised morphology segmentation helps for HebrewEnglish SMT, b"
2012.eamt-1.8,2007.mtsummit-papers.65,0,0.015742,"the different methods are combined. Habash and Sadat (2006) compared a variety of what they called tokenization schemes and techniques for Arabic-English SMT. Their work and that of Lee (2004) are especially relevant since Arabic is a Semitic language like Hebrew. This paper is closest in its approach to Habash and Sadat (2006). We refer to their work further below. We do not discuss efforts on translation into morphologically rich languages although similar approaches have been investigated (El Kholy and Habash, 2012a; Al-Haj and Lavie, 2012) As for the use of unsupervised morphology in SMT, Virpioja et al. (2007) and Fishel and Kirik (2010) presented some experiments with mixed results. They suggested that language pairs different from those they studied (Danish-Finnish-Swedish and Estonian-English, respectively), may benefit from unsupervised morphology. Snyder and Barzilay (2008) presented results on learning Hebrew morphology using parallel and monolingual resources. Until recently, there has not been much parallel Hebrew-English data (Tsvetkov and Wintner, 2010), and consequently little work on HebrewEnglish SMT. Lavie et al. (2004) built a transferbased translation system for Hebrew-English and s"
2012.eamt-1.8,2012.eamt-1.6,1,0.884747,"Missing"
2012.eamt-1.8,fishel-kirik-2010-linguistically,0,0.0678663,"a, tokenization, segmentation) on translation quality. The common wisdom in the field is that such preprocessing helps, especially for morphologically rich languages, such as Arabic, Spanish or Finnish, because it reduces model sparsity and increases source-target symmetry (particularly when the target is morphologically poor, as in English). However, the value of preprocessing generally decreases with added training data, and is highly dependent on the language pair and particular preprocessing approach (Popovi´c and Ney, 2004; Lee, 2004; Goldwater and McClosky, 2005; Habash and Sadat, 2006; Fishel and Kirik, 2010; Al-Haj and Lavie, 2012). In this paper, we present results from a set of experiments to determine an optimal preprocessing method for Hebrew-English SMT, a language pair with limited previously published work (Lavie et al., 2004; Lembersky et al., 2011). We report on three types of preprocessing techniques using deterministic regular-expressions, unsupervised morphology learning, and morphological analysis and c 2012 European Association for Machine Translation. 43 bic (Itai and Wintner, 2008; Shilon et al., 2012; Habash, 2010). Similar to Arabic, Hebrew orthography uses optional diacritics"
2012.eamt-1.8,H05-1085,0,0.0791714,"(2003) compared different methods for compound splitting when translating from German to English. All of their methods improve SMT quality over a nosplitting baseline; however, the methods with the highest accuracy are not the best SMT performers. Lee (2004) investigated the use of automatic alignment of POS tagged English and affix-stem segmented Arabic to determine whether affixes should be kept separate, deleted or reattached to stems. Her results show that morphological preprocessing helps, but only for the smaller corpora sizes she investigated. As size increases, the benefits diminish. Goldwater and McClosky (2005) showed that incorporating various methods for specifying morphological information in Czech-English SMT (e.g., lemmatization and different styles of segMuch research in statistical machine translation (SMT) has shown the importance of morphological preprocessing (aka, tokenization, segmentation) on translation quality. The common wisdom in the field is that such preprocessing helps, especially for morphologically rich languages, such as Arabic, Spanish or Finnish, because it reduces model sparsity and increases source-target symmetry (particularly when the target is morphologically poor, as i"
2012.eamt-1.8,N06-2013,1,0.926179,"ogical preprocessing (aka, tokenization, segmentation) on translation quality. The common wisdom in the field is that such preprocessing helps, especially for morphologically rich languages, such as Arabic, Spanish or Finnish, because it reduces model sparsity and increases source-target symmetry (particularly when the target is morphologically poor, as in English). However, the value of preprocessing generally decreases with added training data, and is highly dependent on the language pair and particular preprocessing approach (Popovi´c and Ney, 2004; Lee, 2004; Goldwater and McClosky, 2005; Habash and Sadat, 2006; Fishel and Kirik, 2010; Al-Haj and Lavie, 2012). In this paper, we present results from a set of experiments to determine an optimal preprocessing method for Hebrew-English SMT, a language pair with limited previously published work (Lavie et al., 2004; Lembersky et al., 2011). We report on three types of preprocessing techniques using deterministic regular-expressions, unsupervised morphology learning, and morphological analysis and c 2012 European Association for Machine Translation. 43 bic (Itai and Wintner, 2008; Shilon et al., 2012; Habash, 2010). Similar to Arabic, Hebrew orthography u"
2012.eamt-1.8,P08-2015,1,0.892956,"ted words instead. Conclusions and Future Work We explored a range of preprocessing solutions for Hebrew-English SMT. Our best system, using a morphological analyzer and tagger, increases 3.5 BLEU points over a no-tokenization baseline on a blind test set. The next best result we got (as measured by BLEU) uses Morfessor, an unsupervised morphological segmenter. In the future, we plan to explore combinations of the different tokenization schemes, both pre- and post-translation, perhaps using lattices (Dyer et al., 2008). We also plan to consider Hebrew-specific OOV solutions similar to work by Habash (2008) on Arabic. Acknowledgments The work presented here was supported in part by a Google research award. We would like to thank Or Biran, Alon Lavie, Yuval Marton, and Shuly Wintner for helpful feedback and discussions. References Preliminary Combination Experiments In a preliminary combination experiment, we considered two simple ideas to combine the power of H TAG with other systems. First, for every sentence in the output of H TAG, if the sentence has an OOV, and M ORF does not, we replace the H TAG output with the M ORF output (C OMBO 1 in Table 4). Note that if a M ORF sentence has even one"
2012.eamt-1.8,E03-1076,0,0.0427033,"system uses Morfessor, an unsupervised morphological segmenter, and obtains almost 3.0 BLEU points over the baseline. 1 2 Introduction Related Work A wide range of preprocessing techniques have been studied for a variety of language pairs requiring different treatments. Nießen and Ney (2004) studied the impact of various types of morphosyntactic restructuring on German-English SMT and Popovi´c and Ney (2004) studied the effect of splitting words into stems and suffixes on SMT into English from Spanish, Catalan and Serbian. Their results show significant error reduction when stemming is used. Koehn and Knight (2003) compared different methods for compound splitting when translating from German to English. All of their methods improve SMT quality over a nosplitting baseline; however, the methods with the highest accuracy are not the best SMT performers. Lee (2004) investigated the use of automatic alignment of POS tagged English and affix-stem segmented Arabic to determine whether affixes should be kept separate, deleted or reattached to stems. Her results show that morphological preprocessing helps, but only for the smaller corpora sizes she investigated. As size increases, the benefits diminish. Goldwat"
2012.eamt-1.8,P07-2045,0,0.00902322,"ov and Wintner (2010). We split the data into training, tuning, development, and test sets. The training and tuning data sets are used for training and tuning the translation models. Experiments were initially run on the development data set, and finally run on the test data set when all settings and schemes were finalized. Table 3 presents the data subset details. In the baseline, the Hebrew data is tokenized just to split punctuation. English data is whitespace/punctuation tokenized and lowercased. The English MT output is true-cased using the recaser tool that is part of the Moses toolkit (Koehn et al., 2007). The recaser is trained on the English side of the training and tuning sets. For the baseline and all of the experiments, the preprocessing is applied to all data sets - training, tuning, development, and test. After preprocessing, but before training, we filter down to sentences of 100 tokens or less in length. As a result, with more tokenization, there are fewer eligible sentences. The difference is minor, however. We train the translation models and decode with the Moses toolkit (Koehn et al., 2007). We used two English language models, held constant across all experiments: a trigram langu"
2012.eamt-1.8,W04-3250,0,0.191073,"Missing"
2012.eamt-1.8,D08-1076,0,\N,Missing
2012.eamt-1.8,J04-2003,0,\N,Missing
2013.mtsummit-papers.16,al-sabbagh-girju-2010-mining,0,0.257071,"Missing"
2013.mtsummit-papers.16,altantawy-etal-2010-morphological,1,0.88472,"ition research. Habash et al. (2012b) developed a conventional orthography for dialectal Arabic (CODA) designed for developing computational models of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) com"
2013.mtsummit-papers.16,W11-4416,1,0.855594,"t al. (2012b) developed a conventional orthography for dialectal Arabic (CODA) designed for developing computational models of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that"
2013.mtsummit-papers.16,E06-1047,1,0.8586,"; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) converted DA into MSA using a dialectal morphological analyzer and various mapping rules. Salloum and Habash (2011)’s DA morphological analyzer (ADAM), was built by extending a MSA analyzer in a noisy fashion. Their goal was to maximize analyzability not correctness. Mohamed et al. (2012) described a method for translating disambiguated MSA to Eg"
2013.mtsummit-papers.16,N13-1066,1,0.827322,"e authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. design principles, development tools and guidelines for speech recognition research. Habash et al. (2012b) developed a conventional orthography for dialectal Arabic (CODA) designed for developing computational models of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers h"
2013.mtsummit-papers.16,P05-1071,1,0.761472,"ar, dual and plural are reduced to singular and plural. Masculine and feminine values of gender feature are not distinguished in TUN except for the third person singular. Patterns carry a general meaning, the MSA pattern Ai12a33, for example, denotes the change of state. This pattern is not used in TUN and Tunisians express the state change by using the pattern 12A3 which not exists in MSA. Furthermore, some MSA patterns are not defined in TUN and vice versa. 4 Tools and Resources Our architecture relies on the morphological processing tool MAGEAD and on a transfer lexicon. 4.1 MAGEAD MAGEAD (Habash and Rambow, 2005) is a morphological analyzer and generator for the Arabic language family (MSA and Arabic dialects). MAGEAD relates (bidirectionally) a lexeme and a set of linguistic features to a surface word form through a sequence of transformations. In a generation perspective, the features are translated to abstract morphemes which are then ordered, and expressed as concrete morphemes. The concrete templatic morphemes are interdigitated and affixes added, finally morphological and phonological rewrite rules are applied. 4.1.1 Lexeme and Features Morphological analyses are represented in terms of a lexeme"
2013.mtsummit-papers.16,P06-1086,1,0.951348,"delines for speech recognition research. Habash et al. (2012b) developed a conventional orthography for dialectal Arabic (CODA) designed for developing computational models of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic,"
2013.mtsummit-papers.16,W05-0703,1,0.894943,"lopment tools and guidelines for speech recognition research. Habash et al. (2012b) developed a conventional orthography for dialectal Arabic (CODA) designed for developing computational models of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to"
2013.mtsummit-papers.16,habash-etal-2012-conventional,1,0.925187,"independence of mapping roots and patterns is optimal in reducing overall ambiguity and increasing recall. 1 Introduction The Arabic language has many variants. Modern Standard Arabic (MSA) is one of them. It is the official language of all Arab countries. However, MSA is the native language of no Arabic speakers. It is used for education, printed and spoken media. There exists also a variety of Arabic dialects which are the native languages of Arabic speakers. Unlike MSA, Dialectal Arabic (DA) varieties are only spoken. Therefore, there is no standard orthographic conventions (Habash, 2010; Habash et al., 2012b). Most of the Arabic natural language processing (NLP) resources are built in order to process MSA. Very few works on processing dialects have been established, and mainly for Egyptian, Iraqi and Levantine Arabic. In this work, we focus on the Tunisian Arabic dialect (TUN), an important yet less studied Arabic dialect. We propose to transform it into a form that is close to MSA by using morphological analysis and generation in order to take advantage of MSA NLP tools. Our approach relies on modeling the translation process over the deep morphological representations of roots and patterns, co"
2013.mtsummit-papers.16,N13-1044,1,0.842075,"chine Translation Summit (Nice, September 2–6, 2013), p. 125–134. c 2013 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. design principles, development tools and guidelines for speech recognition research. Habash et al. (2012b) developed a conventional orthography for dialectal Arabic (CODA) designed for developing computational models of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to"
2013.mtsummit-papers.16,J00-1006,0,0.400564,"(3) &lt;zhr,V1tV2V3,iaa> + at Simple interdigitation of root, pattern and vocalism then yields the form iztahar+at. 4.1.4 MAGEAD Rules MAGEAD uses two types of rules. Morphophonemic/phonological rules map from the morphemic representation to the phonological and orthographic representations. Orthographic rules rewrite only the orthographic representation. For our example, we get /izdaharat/ at the phonological level (as opposed to /iztaharat/). Using standard MSA diacritized orthography, our example becomes Aizdaharat. Removing the diacritics turns this into the more familiar Azdhrt. We follow (Kiraz, 2000) in using a multi-tape representation. MAGEAD extend the analysis of Kiraz by introducing a fifth tier. The five tiers are used as follows: Tier 1: pattern and affixational morphemes; Tier 2: root; Tier 3: vocalism; Tier 4: phonological representation; Tier 5: orthographic representation. In the generation direction, tiers 1 through 3 are always input tiers. Tier 4 is first an output tier, and subsequently an input tier. Tier 5 is always an output tier. 4.1.5 From MSA to Tunisian We adapted MAGEAD to process TUN verbs. Our effort concentrated on the orthographic representation. Changes concern"
2013.mtsummit-papers.16,P12-2035,0,0.0237282,"e, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) converted DA into MSA using a dialectal morphological analyzer and various mapping rules. Salloum and Habash (2011)’s DA morphological analyzer (ADAM), was built by extending a MSA analyzer in a noisy fashion. Their goal was to maximize analyzability not correctness. Mohamed et al. (2012) described a method for translating disambiguated MSA to Egyptian Arabic using a rule-based system. Their system reduced OOVs and improved POS tagging accuracy. In this paper, we explore a similar approach to previous efforts (Sawaf, 2010; Mohamed et al., 2012; Salloum and Habash, 2013) but using a well-motivated deep morphological representation based on the MAGEAD approach (Habash and Rambow, 2006). Our solution is bi-directional unlike previous efforts and we demonstrate our approach on Tunisian Arabic. 3 Morphology: MSA vs Tunisian Arabic Many similarities and differences exist between MSA"
2013.mtsummit-papers.16,2006.amta-papers.21,0,0.0163821,"s of Arabic dialects. CODA was used in the design of a morphological analyzer for Egyptian Arabic (Habash et al., 2012a), as well as a morphological disambiguation system for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence fr"
2013.mtsummit-papers.16,W11-2602,1,0.878992,"e morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) converted DA into MSA using a dialectal morphological analyzer and various mapping rules. Salloum and Habash (2011)’s DA morphological analyzer (ADAM), was built by extending a MSA analyzer in a noisy fashion. Their goal was to maximize analyzability not correctness. Mohamed et al. (2012) described a method for translating disambiguated MSA to Egyptian Arabic using a rule-based system. Their system reduced OOVs and improved POS tagging accuracy. In this paper, we explore a similar approach to previous efforts (Sawaf, 2010; Mohamed et al., 2012; Salloum and Habash"
2013.mtsummit-papers.16,N13-1036,1,0.796057,"that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) converted DA into MSA using a dialectal morphological analyzer and various mapping rules. Salloum and Habash (2011)’s DA morphological analyzer (ADAM), was built by extending a MSA analyzer in a noisy fashion. Their goal was to maximize analyzability not correctness. Mohamed et al. (2012) described a method for translating disambiguated MSA to Egyptian Arabic using a rule-based system. Their system reduced OOVs and improved POS tagging accuracy. In this paper, we explore a similar approach to previous efforts (Sawaf, 2010; Mohamed et al., 2012; Salloum and Habash, 2013) but using a well-motiv"
2013.mtsummit-papers.16,2010.amta-papers.5,0,0.416846,"ithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) converted DA into MSA using a dialectal morphological analyzer and various mapping rules. Salloum and Habash (2011)’s DA morphological analyzer (ADAM), was built by extending a MSA analyzer in a noisy fashion. Their goal was to maximize analyzability not correctness. Mohamed et al. (2012) described a method for translating disambiguated MSA to Egyptian Arabic using a rule-based system. Their system reduced OOVs and improved POS tagging accuracy. In this paper, we explore a similar approach to previous efforts (Sawaf, 2010; Mohamed et al"
2013.mtsummit-papers.16,N12-1006,0,0.11258,"ystem for Egyptian Arabic (Habash et al., 2013) and a system for normalizing spontaneous orthography (Eskander et al., 2013). A morphological analyzer and generator for Arabic dialects (MAGEAD) was also developed for MSA and Levantine Arabic (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010; Altantawy et al., 2011). AlSabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut machine translation outof-vocabulary (OOV) words by half. Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data using crowd-sourcing. Several researchers have considered the idea of exploiting existing MSA rich resources to build tools for DA NLP. For example, in order to use MSA treebanks to parse Levantine Arabic, Chiang et al. (2006) compared three methods that rely on translating between MSA and Levantine. Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) converted DA into MSA using a dialectal morphological analy"
2013.mtsummit-papers.16,W05-0909,0,0.192592,"Missing"
2013.mtsummit-papers.16,E06-1032,0,0.0212101,"Missing"
2013.mtsummit-papers.16,fishel-etal-2012-terra,0,0.0320987,"Missing"
2013.mtsummit-papers.16,2005.mtsummit-papers.11,0,0.016339,"Missing"
2013.mtsummit-papers.16,max-etal-2010-contrastive,0,0.0225119,"Missing"
2013.mtsummit-papers.16,W03-0301,0,0.0575504,"Missing"
2013.mtsummit-papers.16,C00-2163,0,0.162528,"Missing"
2013.mtsummit-papers.16,2011.eamt-1.36,0,0.0293463,"Missing"
2013.mtsummit-papers.16,W06-3101,0,0.0604473,"Missing"
2013.mtsummit-papers.16,2006.amta-papers.25,0,0.0798075,"Missing"
2013.mtsummit-papers.16,C08-1141,0,0.0294622,"Missing"
2013.mtsummit-papers.16,J03-1002,0,0.00754575,"Missing"
2013.mtsummit-papers.16,P02-1040,0,0.086357,"Missing"
2013.mtsummit-papers.16,W12-2301,1,\N,Missing
2014.eamt-1.16,J93-2003,0,0.0391312,"e translation through a third language (called pivot or bridge language) for which there exist abundant parallel corpora with the source and target languages. The literature covers many pivoting techniques. One of the best performing techniques, phrase pivoting (Utiyama and Isahara, 2007), builds an induced new phrase table between the source and target. Our effort in this paper is based on phrase pivoting. We focus on word alignment to improve translation quality. Word alignment is an essential step in building an SMT system. The most commonly used alignment models, such as IBM Model serial (Brown et al., 1993) and HMM (Och and Ney, 2003), all assume one-to-many alignments. However, the target is to produce a manyto-many word alignment model. A common practice solution in most state-of-the-art MT systems 2 Background In this section, we briefly describe different symmetrization heuristics. We then explain how symmetrization affects phrase extraction and discuss the motivation for our approach. 2.1 Symmetrization Heuristics The simplest approach is to merge the two directional alignment functions using a symmetrization heuristic to produce a many-to-many alignment matrix (Och et al., 1999; Och and Ne"
2014.eamt-1.16,P11-2031,0,0.0368182,"Missing"
2014.eamt-1.16,P07-1092,0,0.206812,"orithm (starting with union symmetrization) { generate the list of possible pivot unigram Lp } −→ ←− AU pt = Apt ∪ Apt AFpt = AU pt for (i, j) ∈ AFpt do if Wi ∈ / Lp then AFpt = AFpt − {(i, j)} end if end for return AFpt been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence pivoting technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (Khalilov et al., 2008). The second strategy is based on phrase pivoting (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009; El Kholy et al., a; El Kholy et al., b). In phrase pivoting, a new source-target phrase table (translation model) is induced from source-pivot and pivot-target phrase tables. Lexical weights and translation probabilities are computed from the two translation models. The third strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). In this paper, we build on the phrase pivoting approach, which has been shown to be the best with comparable s"
2014.eamt-1.16,P11-1043,0,0.016289,"s paper, we build on the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007). There are some recent efforts regarding alignment symmetrization or combination. In a related work to our approach but for direct SMT systems, Deng and Zhou (2009) performs alignment symmetrization as an optimization process to maximize the number of phrase translations that can be extracted within a sentence pair. There are other approaches that do not depend on heuristics. Among these are efforts that depend on unsupervised methods (Liang et al., 2006; DeNero and Macherey, 2011) where they jointly learn two directional alignment models. In another direction, Grac¸a et al. (2007) improve bidirectional models by incorporating agreement constraints to EM training using Posterior Regularization (PR). Moreover, DeNero and Macherey (2011) proposed a model based aligner combination using dual decomposition. Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006;"
2014.eamt-1.16,P09-2058,0,0.0176429,"phrase tables. Lexical weights and translation probabilities are computed from the two translation models. The third strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). In this paper, we build on the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007). There are some recent efforts regarding alignment symmetrization or combination. In a related work to our approach but for direct SMT systems, Deng and Zhou (2009) performs alignment symmetrization as an optimization process to maximize the number of phrase translations that can be extracted within a sentence pair. There are other approaches that do not depend on heuristics. Among these are efforts that depend on unsupervised methods (Liang et al., 2006; DeNero and Macherey, 2011) where they jointly learn two directional alignment models. In another direction, Grac¸a et al. (2007) improve bidirectional models by incorporating agreement constraints to EM training using Posterior Regularization (PR). Moreover, DeNero and Macherey (2011) proposed a model b"
2014.eamt-1.16,2010.jeptalnrecital-long.29,1,0.896996,"Missing"
2014.eamt-1.16,W09-0809,1,0.849515,"pend on unsupervised methods (Liang et al., 2006; DeNero and Macherey, 2011) where they jointly learn two directional alignment models. In another direction, Grac¸a et al. (2007) improve bidirectional models by incorporating agreement constraints to EM training using Posterior Regularization (PR). Moreover, DeNero and Macherey (2011) proposed a model based aligner combination using dual decomposition. Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve translation quality. Until recently, there has not been much parallel Hebrew-English (Tsvetkov and Wintner, 2010) and Hebrew-Arabic data, and consequently little work on Hebrew-English and Hebrew-Arabic SMT. Lavie et al. (2004) built a transfer-based translation system for Hebrew-English and so did Shilon et al. (2012) for translation between Hebrew and Arabic. To our knowledge this is the first study improving phrase-pivot SMT fo"
2014.eamt-1.16,W09-0431,1,0.8966,"onstraints for which phrase pairs can be extracted. In the standard heuristic (Koehn et al., 2003) for phrase pair extraction, the extracted phrase pair should be consistent and contain at least one word-based link. Moreover, no word inside the phrase pair is aligned to a word outside it. Figure 1 shows examples of phrase pairs that obey or violate the consistency constraint. Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity problem (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have 64 Algorithm 1 Symmetrization Relaxation Algorithm (starting with union symmetrization) { generate the list of possible pivot unigram Lp } −→ ←− AU pt = Apt ∪ Apt AFpt = AU pt for (i, j) ∈ AFpt do if Wi ∈ / Lp then AFpt = AFpt − {(i, j)} end if end for return AFpt been presented in"
2014.eamt-1.16,2008.iwslt-papers.1,0,0.712854,"s is that they act as constraints for which phrase pairs can be extracted. In the standard heuristic (Koehn et al., 2003) for phrase pair extraction, the extracted phrase pair should be consistent and contain at least one word-based link. Moreover, no word inside the phrase pair is aligned to a word outside it. Figure 1 shows examples of phrase pairs that obey or violate the consistency constraint. Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity problem (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have 64 Algorithm 1 Symmetrization Relaxation Algorithm (starting with union symmetrization) { generate the list of possible pivot unigram Lp } −→ ←− AU pt = Apt ∪ Apt AFpt = AU pt for (i, j) ∈ AFpt do if Wi ∈ / Lp then AFpt = AFpt − {(i, j)} end if end for return A"
2014.eamt-1.16,P05-1071,1,0.609608,"ticle + È@ Al+ ‘the’, and the class of pronominal enclitics, e.g., Ñë+ +hm ‘their/them’. Beyond these clitics, Arabic words inflect for person, gender, number, aspect, mood, voice, state and case. This morphological richness leads to thousands of inflected forms per lemma and a high degree of ambiguity: about 12 analyses per word, typically corresponding to two lemmas on average (Habash, 2010). We follow El Kholy and Habash (2010a) and use the PATB tokenization scheme (Maamouri et al., 2004) in our experiments which separates all clitics except for the determiner clitic Al+. We use MADA v3.1 (Habash and Rambow, 2005; Habash et al., 2009) to tokenize the Arabic text. We only evaluate on detokenized and orthographically correct (enriched) output following the work of El Kholy and Habash (2010b). Similar to Arabic, Hebrew poses computational processing challenges typical of Semitic languages (Itai and Wintner, 2008; Shilon et al., 2012; Habash, 2010). Hebrew inflects for gender, number, person, state, tense and definiteness. Furthermore, Hebrew has a set of attachable clitics that are typically separate words in English, e.g., conjunctions (such as +! וw+ ‘and’),5 prepositions (such as +! בb+ ‘in’), the"
2014.eamt-1.16,N06-2013,1,0.878668,"ero and Macherey, 2011) where they jointly learn two directional alignment models. In another direction, Grac¸a et al. (2007) improve bidirectional models by incorporating agreement constraints to EM training using Posterior Regularization (PR). Moreover, DeNero and Macherey (2011) proposed a model based aligner combination using dual decomposition. Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve translation quality. Until recently, there has not been much parallel Hebrew-English (Tsvetkov and Wintner, 2010) and Hebrew-Arabic data, and consequently little work on Hebrew-English and Hebrew-Arabic SMT. Lavie et al. (2004) built a transfer-based translation system for Hebrew-English and so did Shilon et al. (2012) for translation between Hebrew and Arabic. To our knowledge this is the first study improving phrase-pivot SMT for Hebrew-Arabic SMT. We successfully show that relax"
2014.eamt-1.16,A00-1002,0,0.191781,"Missing"
2014.eamt-1.16,2008.iwslt-evaluation.17,0,0.483402,"ts in extracting phrases is that they act as constraints for which phrase pairs can be extracted. In the standard heuristic (Koehn et al., 2003) for phrase pair extraction, the extracted phrase pair should be consistent and contain at least one word-based link. Moreover, no word inside the phrase pair is aligned to a word outside it. Figure 1 shows examples of phrase pairs that obey or violate the consistency constraint. Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity problem (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have 64 Algorithm 1 Symmetrization Relaxation Algorithm (starting with union symmetrization) { generate the list of possible pivot unigram Lp } −→ ←− AU pt = Apt ∪ Apt AFpt = AU pt for (i, j) ∈ AFpt do if Wi ∈ / Lp then AFpt = AFpt − {(i, j)}"
2014.eamt-1.16,P07-2045,0,0.00953444,"at more English-Arabic data are available. The English-Arabic parallel corpus is a subset of available data from LDC.4 The Hebrew-English corpus is available from sentence-aligned corpus produced by Tsvetkov and Wintner (2010). Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight optimization. Weights are optimized using a set of 517 sentences (single reference) developed by Shilon et al. (2010). We use a maximum phrase length of size 8 across all models. We report results on a HebrewArabic evaluation set of 300 sentences with three references developed by Shilon et al. (2010). We evaluate using BLEU-4 (Papineni et al., 2002), 4 The log values of 2.718 and 1 will lead to a binary representation in the log linear space. LDC Catalog IDs: LDC2004T17, LDC2005E46, LDC2004T18 67 LDC2004E72, Symm. GDFA GDFA R U UR I METEOR v1.4 (L"
2014.eamt-1.16,2009.mtsummit-papers.7,0,0.234208,"s aligned to a word outside it. Figure 1 shows examples of phrase pairs that obey or violate the consistency constraint. Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity problem (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have 64 Algorithm 1 Symmetrization Relaxation Algorithm (starting with union symmetrization) { generate the list of possible pivot unigram Lp } −→ ←− AU pt = Apt ∪ Apt AFpt = AU pt for (i, j) ∈ AFpt do if Wi ∈ / Lp then AFpt = AFpt − {(i, j)} end if end for return AFpt been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence pivoting technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target langu"
2014.eamt-1.16,J10-4005,0,0.0176505,"exists in the union (U). Adding the constraint (-and), only allows alignment points between two unaligned words to be added. 2.2 Figure 1: Phrase-pairs consistency constraints with word alignment (black squares are alignment points and the shaded area is a proposed phrase pair): The first example from the left obeys the consistency heuristic, which is violated in the second example (one alignment point in the second column is outside the phrase pair). The third example obeys the consistency heuristic despite the fact that it includes an unaligned word on the right. This diagram is taken from Koehn (2010). The consistency constraint leads to an inverse relationship between the number of alignment points and the number of phrase pairs extracted; the fewer alignment points, the more phrase pairs can be extracted. This relationship is not valid in the extreme situation with no alignment points at all; in this extreme case, no phrase pairs are extracted. A major issue in this heuristic is its sensitivity to word alignment errors. Since the consistency constraint is based on the alignment, an error could prevent the extraction of many good phrase pairs. In the context of phrase pivoting, this event"
2014.eamt-1.16,W07-0734,0,0.0742861,"Missing"
2014.eamt-1.16,2004.eamt-1.14,0,0.740688,"sition. Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve translation quality. Until recently, there has not been much parallel Hebrew-English (Tsvetkov and Wintner, 2010) and Hebrew-Arabic data, and consequently little work on Hebrew-English and Hebrew-Arabic SMT. Lavie et al. (2004) built a transfer-based translation system for Hebrew-English and so did Shilon et al. (2012) for translation between Hebrew and Arabic. To our knowledge this is the first study improving phrase-pivot SMT for Hebrew-Arabic SMT. We successfully show that relaxing alignment symmetrization targeting pivoting and combining the extracted phrases with the best baseline system improve translation quality. 4 Approach In this section, we explain our approach in relaxing the symmetrization process to improve the matching in phrase-pivot SMT. We then discuss our approach in combining the phrase pairs ext"
2014.eamt-1.16,N06-1014,0,0.0475391,"t al., 2008). In this paper, we build on the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007). There are some recent efforts regarding alignment symmetrization or combination. In a related work to our approach but for direct SMT systems, Deng and Zhou (2009) performs alignment symmetrization as an optimization process to maximize the number of phrase translations that can be extracted within a sentence pair. There are other approaches that do not depend on heuristics. Among these are efforts that depend on unsupervised methods (Liang et al., 2006; DeNero and Macherey, 2011) where they jointly learn two directional alignment models. In another direction, Grac¸a et al. (2007) improve bidirectional models by incorporating agreement constraints to EM training using Posterior Regularization (PR). Moreover, DeNero and Macherey (2011) proposed a model based aligner combination using dual decomposition. Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 20"
2014.eamt-1.16,J03-1002,0,0.0821124,"language (called pivot or bridge language) for which there exist abundant parallel corpora with the source and target languages. The literature covers many pivoting techniques. One of the best performing techniques, phrase pivoting (Utiyama and Isahara, 2007), builds an induced new phrase table between the source and target. Our effort in this paper is based on phrase pivoting. We focus on word alignment to improve translation quality. Word alignment is an essential step in building an SMT system. The most commonly used alignment models, such as IBM Model serial (Brown et al., 1993) and HMM (Och and Ney, 2003), all assume one-to-many alignments. However, the target is to produce a manyto-many word alignment model. A common practice solution in most state-of-the-art MT systems 2 Background In this section, we briefly describe different symmetrization heuristics. We then explain how symmetrization affects phrase extraction and discuss the motivation for our approach. 2.1 Symmetrization Heuristics The simplest approach is to merge the two directional alignment functions using a symmetrization heuristic to produce a many-to-many alignment matrix (Och et al., 1999; Och and Ney, 2003; Koehn et al., 2003)"
2014.eamt-1.16,W99-0604,0,0.107173,"serial (Brown et al., 1993) and HMM (Och and Ney, 2003), all assume one-to-many alignments. However, the target is to produce a manyto-many word alignment model. A common practice solution in most state-of-the-art MT systems 2 Background In this section, we briefly describe different symmetrization heuristics. We then explain how symmetrization affects phrase extraction and discuss the motivation for our approach. 2.1 Symmetrization Heuristics The simplest approach is to merge the two directional alignment functions using a symmetrization heuristic to produce a many-to-many alignment matrix (Och et al., 1999; Och and Ney, 2003; Koehn et al., 2003). One of the approaches is to take the intersection (I) of the two directional alignments. Intersection alignment matrices are very sparse and express only one-to-one relationship between words. As a result, we get a high precision in alignment due to the agreement of both models and a very low recall. An alternative approach is to look at the two c 2014 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. 63 alignments as containing complementary information. Therefore, the union (U) of t"
2014.eamt-1.16,P03-1021,0,0.0244112,"ailable. The English-Arabic parallel corpus is a subset of available data from LDC.4 The Hebrew-English corpus is available from sentence-aligned corpus produced by Tsvetkov and Wintner (2010). Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight optimization. Weights are optimized using a set of 517 sentences (single reference) developed by Shilon et al. (2010). We use a maximum phrase length of size 8 across all models. We report results on a HebrewArabic evaluation set of 300 sentences with three references developed by Shilon et al. (2010). We evaluate using BLEU-4 (Papineni et al., 2002), 4 The log values of 2.718 and 1 will lead to a binary representation in the log linear space. LDC Catalog IDs: LDC2004T17, LDC2005E46, LDC2004T18 67 LDC2004E72, Symm. GDFA GDFA R U UR I METEOR v1.4 (Lavie and Agarwal, 2007) a"
2014.eamt-1.16,P02-1040,0,0.0909769,"e Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight optimization. Weights are optimized using a set of 517 sentences (single reference) developed by Shilon et al. (2010). We use a maximum phrase length of size 8 across all models. We report results on a HebrewArabic evaluation set of 300 sentences with three references developed by Shilon et al. (2010). We evaluate using BLEU-4 (Papineni et al., 2002), 4 The log values of 2.718 and 1 will lead to a binary representation in the log linear space. LDC Catalog IDs: LDC2004T17, LDC2005E46, LDC2004T18 67 LDC2004E72, Symm. GDFA GDFA R U UR I METEOR v1.4 (Lavie and Agarwal, 2007) and TER (Snover et al., 2006). 5.2 Linguistic Preprocessing In this section we present our motivation and choice for preprocessing Arabic, Hebrew and English data. Both Arabic and Hebrew are morphologically complex languages (Fabri et al., 2014). One aspect of Arabic’s complexity is its various attachable clitics and numerous morphological features (Habash, 2010). which i"
2014.eamt-1.16,2010.amta-srw.4,1,0.362478,"sentence-aligned corpus produced by Tsvetkov and Wintner (2010). Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight optimization. Weights are optimized using a set of 517 sentences (single reference) developed by Shilon et al. (2010). We use a maximum phrase length of size 8 across all models. We report results on a HebrewArabic evaluation set of 300 sentences with three references developed by Shilon et al. (2010). We evaluate using BLEU-4 (Papineni et al., 2002), 4 The log values of 2.718 and 1 will lead to a binary representation in the log linear space. LDC Catalog IDs: LDC2004T17, LDC2005E46, LDC2004T18 67 LDC2004E72, Symm. GDFA GDFA R U UR I METEOR v1.4 (Lavie and Agarwal, 2007) and TER (Snover et al., 2006). 5.2 Linguistic Preprocessing In this section we present our motivation and choice for preprocessing Arabic,"
2014.eamt-1.16,2012.eamt-1.8,1,0.630111,"and Wintner, 2008; Shilon et al., 2012; Habash, 2010). Hebrew inflects for gender, number, person, state, tense and definiteness. Furthermore, Hebrew has a set of attachable clitics that are typically separate words in English, e.g., conjunctions (such as +! וw+ ‘and’),5 prepositions (such as +! בb+ ‘in’), the definite article (+! הh+ ‘the’), or pronouns (such as !Mה+ +hm ‘their’). These issues contribute to a high degree of ambiguity that is a challenge to translation from Hebrew to English or to any other language. We use the best preprocessing scheme for Hebrew (HTAG) identified by Singh and Habash (2012) . English, our pivot language, is quite different from both Arabic and Hebrew. English is morphologically poor and barely inflects for number, BLEU 20.4 20.8 20.1 20.7 20.8 METEOR 33.4 34.0 33.5 34.0 34.0 TER 62.7 62.4 62.7 62.5 63.6 Table 2: Symmetrization relaxation results for different symmetrization methods. The best performer is the relaxed grow-diag-final-and (GDFA R). (GDFA R) BLEU score is statistically significant over the baseline (GDFA) with p-value = 0.12. All other results are not statistically significant. person and tense. English preprocessing simply includes down-casing, sep"
2014.eamt-1.16,2006.amta-papers.25,0,0.0602663,"Missing"
2014.eamt-1.16,tsvetkov-wintner-2010-automatic,0,0.490187,"or Regularization (PR). Moreover, DeNero and Macherey (2011) proposed a model based aligner combination using dual decomposition. Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve translation quality. Until recently, there has not been much parallel Hebrew-English (Tsvetkov and Wintner, 2010) and Hebrew-Arabic data, and consequently little work on Hebrew-English and Hebrew-Arabic SMT. Lavie et al. (2004) built a transfer-based translation system for Hebrew-English and so did Shilon et al. (2012) for translation between Hebrew and Arabic. To our knowledge this is the first study improving phrase-pivot SMT for Hebrew-Arabic SMT. We successfully show that relaxing alignment symmetrization targeting pivoting and combining the extracted phrases with the best baseline system improve translation quality. 4 Approach In this section, we explain our approach in relaxing the symmetrization p"
2014.eamt-1.16,N07-1061,0,0.691899,"1.2 BLEU points) on Hebrew-to-Arabic SMT pivoting on English. 1 Introduction One of the main issues in statistical machine translation (SMT) is the scarcity of parallel data for many language pairs especially when the source and target languages are morphologically rich. A common SMT solution to the lack of parallel data is to pivot the translation through a third language (called pivot or bridge language) for which there exist abundant parallel corpora with the source and target languages. The literature covers many pivoting techniques. One of the best performing techniques, phrase pivoting (Utiyama and Isahara, 2007), builds an induced new phrase table between the source and target. Our effort in this paper is based on phrase pivoting. We focus on word alignment to improve translation quality. Word alignment is an essential step in building an SMT system. The most commonly used alignment models, such as IBM Model serial (Brown et al., 1993) and HMM (Och and Ney, 2003), all assume one-to-many alignments. However, the target is to produce a manyto-many word alignment model. A common practice solution in most state-of-the-art MT systems 2 Background In this section, we briefly describe different symmetrizati"
2014.eamt-1.16,P09-1018,0,0.354542,"e of alignment points in extracting phrases is that they act as constraints for which phrase pairs can be extracted. In the standard heuristic (Koehn et al., 2003) for phrase pair extraction, the extracted phrase pair should be consistent and contain at least one word-based link. Moreover, no word inside the phrase pair is aligned to a word outside it. Figure 1 shows examples of phrase pairs that obey or violate the consistency constraint. Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity problem (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have 64 Algorithm 1 Symmetrization Relaxation Algorithm (starting with union symmetrization) { generate the list of possible pivot unigram Lp } −→ ←− AU pt = Apt ∪ Apt AFpt = AU pt for (i, j) ∈ AFpt do if Wi ∈ / Lp then"
2014.eamt-1.16,P10-1047,0,0.19019,"ong these are efforts that depend on unsupervised methods (Liang et al., 2006; DeNero and Macherey, 2011) where they jointly learn two directional alignment models. In another direction, Grac¸a et al. (2007) improve bidirectional models by incorporating agreement constraints to EM training using Posterior Regularization (PR). Moreover, DeNero and Macherey (2011) proposed a model based aligner combination using dual decomposition. Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve translation quality. Until recently, there has not been much parallel Hebrew-English (Tsvetkov and Wintner, 2010) and Hebrew-Arabic data, and consequently little work on Hebrew-English and Hebrew-Arabic SMT. Lavie et al. (2004) built a transfer-based translation system for Hebrew-English and so did Shilon et al. (2012) for translation between Hebrew and Arabic. To our knowledge this is the first study impr"
2015.mtsummit-papers.9,2008.iwslt-papers.1,0,0.0217392,"a. Next, we briefly discuss some related work. In Section 3, we review the best performing pivoting strategy and how we use it. In Section 4, we discuss the linguistic differences among Hebrew, Arabic, and the pivot language, English. This is followed by our approach to using morphology constraints in Section 5. We finally present our experimental results in Section 6 and a case study in Section 7. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the targ"
2015.mtsummit-papers.9,2012.eamt-1.60,0,0.0198574,"as well as model combination to improve Hebrew-Arabic pivot translation quality. 6.1 Experimental Setup In our pivoting experiments, we build two SMT models; one model to translate from Hebrew to English, and another model to translate from English to Arabic. The English-Arabic parallel corpus is about (≈ 60M words) and is available from LDC6 and GALE7 constrained data. The Hebrew-English corpus is about (≈ 1M words) and is available from sentence-aligned corpus produced by Tsvetkov and Wintner (2010). For the direct Hebrew-Arabic SMT model, we use a TED parallel corpus of about (≈ 2M words) (Cettolo et al., 2012). Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight optimization. Weights are optimized using a tuning set of 517 sentences developed by Shilon et al. (2010). We use a maximum phrase length of size 8 across all mo"
2015.mtsummit-papers.9,P07-1092,0,0.0280351,"and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (Khalilov et al., 2008). The second strategy is based on phrase pivoting (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009). In phrase pivoting, a new source-target phrase table (translation model) is induced from sourcepivot and pivot-target phrase tables. Lexical weights and translation probabilities are computed from the two translation models. The third strategy is to create a synthetic source-target corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). In this paper, we use the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007). There ha"
2015.mtsummit-papers.9,2010.jeptalnrecital-long.29,1,0.835856,"Missing"
2015.mtsummit-papers.9,2011.mtsummit-papers.24,1,0.893391,"Missing"
2015.mtsummit-papers.9,2014.eamt-1.16,1,0.666374,"Missing"
2015.mtsummit-papers.9,P13-2073,1,0.6392,"Missing"
2015.mtsummit-papers.9,W09-0809,1,0.832592,"pivot phrase table (El Kholy et al., 2013). These features provide quality scores based on the number of alignment links between words in the source phrase to words of the target phrase. In this work, we extend on the connectivity scores with morphological constraints through which we provide quality scores based on the morphological compatibility between the connected/aligned source and target words. Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve the quality of translation. Until recently, there has not been much parallel Hebrew-English and Hebrew-Arabic data (Tsvetkov and Wintner, 2010), and consequently little work on Hebrew-English and HebrewProceedings of MT Summit XV, vol.1: MT Researchers' Track Miami, Oct 30 - Nov 3, 2015 |p. 105 Translation Model Hebrew-English English-Arabic Pivot Hebrew-Arabic Training Corpora Size ≈1M words ≈60M words N/A Phrase Table # Phrase Pa"
2015.mtsummit-papers.9,W09-0431,1,0.839062,"cuss some related work. In Section 3, we review the best performing pivoting strategy and how we use it. In Section 4, we discuss the linguistic differences among Hebrew, Arabic, and the pivot language, English. This is followed by our approach to using morphology constraints in Section 5. We finally present our experimental results in Section 6 and a case study in Section 7. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (Khalilov"
2015.mtsummit-papers.9,N06-2013,1,0.68225,"atures provide quality scores based on the number of alignment links between words in the source phrase to words of the target phrase. In this work, we extend on the connectivity scores with morphological constraints through which we provide quality scores based on the morphological compatibility between the connected/aligned source and target words. Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve the quality of translation. Until recently, there has not been much parallel Hebrew-English and Hebrew-Arabic data (Tsvetkov and Wintner, 2010), and consequently little work on Hebrew-English and HebrewProceedings of MT Summit XV, vol.1: MT Researchers' Track Miami, Oct 30 - Nov 3, 2015 |p. 105 Translation Model Hebrew-English English-Arabic Pivot Hebrew-Arabic Training Corpora Size ≈1M words ≈60M words N/A Phrase Table # Phrase Pairs Size 3,002,887 327MB 111,702,225 14GB > 30 Bill"
2015.mtsummit-papers.9,A00-1002,0,0.21538,"Missing"
2015.mtsummit-papers.9,2008.iwslt-evaluation.17,0,0.051511,"Missing"
2015.mtsummit-papers.9,2009.mtsummit-papers.7,0,0.0199487,"hology constraints in Section 5. We finally present our experimental results in Section 6 and a case study in Section 7. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (Khalilov et al., 2008). The second strategy is based on phrase pivoting (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009). In phrase pivoting, a new source-target phrase table (translation model) is induced from sourcepivot and pivot-target phra"
2015.mtsummit-papers.9,D07-1091,0,0.0513103,"er the phrase pairs used in pivoting based on log-linear scores as discussed in Section 3, however, this doesn’t solve the low quality problem. 3 Arabic transliteration throughout the paper is presented in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007). 4 The following Hebrew 1-to-1 transliteration is used (in Hebrew alphabetical order): abgdhwzxTiklmns‘pcqrˇst. All examples are undiacritized and final forms are not distinguished from non-final forms. Proceedings of MT Summit XV, vol.1: MT Researchers' Track Miami, Oct 30 - Nov 3, 2015 |p. 107 Similar to factored translation models (Koehn and Hoang, 2007) where linguistic (morphology) features are augmented to the translation model to improve the translation quality, our approach to address the quality problem is based on constructing a list of synchronous morphology constraints between the source and target languages. These constraints are used to generate scores to determine the quality of pivot phrase pairs. However, unlike factored models, we do not use the morphology in generation and the morphology information comes completely from external resources. In addition, since we work in the pivoting space, we only apply the morphology constrai"
2015.mtsummit-papers.9,P07-2045,0,0.0244318,"pivoting strategy in detail as we describe how we built our baseline for Arabic-Hebrew via pivoting on English. We also discuss how we overcome the large expansion of source-to-target phrase pairs in the process of creating a pivot phrase table. In phrase pivoting (which is sometimes called triangulation or phrase table multiplication), we train a Hebrew-Arabic and an English-Arabic translation models, such as those used in the sentence pivoting technique. Based on these two models, we induce a new Hebrew-Arabic translation model. Since our models are based on a Moses phrase-based SMT system (Koehn et al., 2007), we use the standard set of phrase-based translation probability distributions.1 We follow Utiyama and Isahara (2007) in computing the pivot phrase pair probabilities. The following are the set of equations used to compute the lexical probabilities (pw ) and the phrase translation probabilities (φ): P φ(h|a) = φ(h|e)φ(e|a) e P φ(a|h) = φ(a|e)φ(e|h) Pe pw (h|a) = pw (h|e)pw (e|a) e P pw (a|h) = pw (a|e)pw (e|h) e Above, h is the Hebrew source phrase; e is the English pivot phrase that is common in both Hebrew-English translation model and English-Arabic translation model; and a is the Arabic t"
2015.mtsummit-papers.9,W07-0733,0,0.0389756,", it would make sense to measure the effect of combining (a) the pivot model with added morphology constraints, and (b) the direct model trained on the parallel data used to induce the morphology constraints. We perform the combination using Moses’ phrase table combination techniques. Translation options are collected from one table, and additional options are collected from the other tables. If the same translation option (in terms of identical input phrase and output phrase) is found in multiple tables, separate translation options are created for each occurrence, but with different scores (Koehn and Schroeder, 2007). We show results over a learning curve in Section 6.5. 6 Experiments In this section, we present a set of experiments comparing the use of rule-based versus induced morphology constraint features in phrase-pivot SMT as well as model combination to improve Hebrew-Arabic pivot translation quality. 6.1 Experimental Setup In our pivoting experiments, we build two SMT models; one model to translate from Hebrew to English, and another model to translate from English to Arabic. The English-Arabic parallel corpus is about (≈ 60M words) and is available from LDC6 and GALE7 constrained data. The Hebrew"
2015.mtsummit-papers.9,2004.eamt-1.14,0,0.0401494,"the quality of translation. Until recently, there has not been much parallel Hebrew-English and Hebrew-Arabic data (Tsvetkov and Wintner, 2010), and consequently little work on Hebrew-English and HebrewProceedings of MT Summit XV, vol.1: MT Researchers' Track Miami, Oct 30 - Nov 3, 2015 |p. 105 Translation Model Hebrew-English English-Arabic Pivot Hebrew-Arabic Training Corpora Size ≈1M words ≈60M words N/A Phrase Table # Phrase Pairs Size 3,002,887 327MB 111,702,225 14GB > 30 Billion ≈2.5TB Table 1: Translation Models Phrase Table comparison in terms of number of lines and sizes. Arabic SMT. Lavie et al. (2004) built a transfer-based translation system for Hebrew-English and so did Shilon et al. (2012) for translation between Hebrew and Arabic. Our previous work discussed above (El Kholy et al., 2013) was demonstrated on Hebrew-Arabic with English pivoting. 3 Phrase Pivoting In this section, we review the phrase pivoting strategy in detail as we describe how we built our baseline for Arabic-Hebrew via pivoting on English. We also discuss how we overcome the large expansion of source-to-target phrase pairs in the process of creating a pivot phrase table. In phrase pivoting (which is sometimes called"
2015.mtsummit-papers.9,P15-2094,0,0.0139788,"own to be the best with comparable settings (Utiyama and Isahara, 2007). There has been recent efforts in improving phrase pivoting. One effort focused on improving alignment symmetrization targeting pivot phrase systems (El Kholy and Habash, 2014). In another recent effort, Multi-Synchronous Context-free Grammar (MSCFG) is leveraged to triangulate source-pivot and pivot-target synchronous Context-free Grammar (SCFG) rule tables into a source-target-pivot MSCFG rule table that helps in remembering the pivot during decoding. Also, pivot LMs are used to assess the naturalness of the derivation (Miura et al., 2015). In our own previous work, we demonstrated quality improvement using connectivity strength features between the source and target phrase pairs in the pivot phrase table (El Kholy et al., 2013). These features provide quality scores based on the number of alignment links between words in the source phrase to words of the target phrase. In this work, we extend on the connectivity scores with morphological constraints through which we provide quality scores based on the morphological compatibility between the connected/aligned source and target words. Since both Hebrew and Arabic are morphologic"
2015.mtsummit-papers.9,P03-1021,0,0.0524344,"vailable from sentence-aligned corpus produced by Tsvetkov and Wintner (2010). For the direct Hebrew-Arabic SMT model, we use a TED parallel corpus of about (≈ 2M words) (Cettolo et al., 2012). Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight optimization. Weights are optimized using a tuning set of 517 sentences developed by Shilon et al. (2010). We use a maximum phrase length of size 8 across all models. We report results on a Hebrew-Arabic development set (Dev) of 500 sentence with a single reference and an evaluation set (Test) of 300 sentences with three references developed by Shilon et al. (2010). We evaluate using BLEU-4 (Papineni et al., 2002). 6 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008"
2015.mtsummit-papers.9,J03-1002,0,0.00489157,"translation quality. 6.1 Experimental Setup In our pivoting experiments, we build two SMT models; one model to translate from Hebrew to English, and another model to translate from English to Arabic. The English-Arabic parallel corpus is about (≈ 60M words) and is available from LDC6 and GALE7 constrained data. The Hebrew-English corpus is about (≈ 1M words) and is available from sentence-aligned corpus produced by Tsvetkov and Wintner (2010). For the direct Hebrew-Arabic SMT model, we use a TED parallel corpus of about (≈ 2M words) (Cettolo et al., 2012). Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight optimization. Weights are optimized using a tuning set of 517 sentences developed by Shilon et al. (2010). We use a maximum phrase length of size 8 across all models. We report results on a Hebrew-Arabic development se"
2015.mtsummit-papers.9,P02-1040,0,0.0936508,"ge models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight optimization. Weights are optimized using a tuning set of 517 sentences developed by Shilon et al. (2010). We use a maximum phrase length of size 8 across all models. We report results on a Hebrew-Arabic development set (Dev) of 500 sentence with a single reference and an evaluation set (Test) of 300 sentences with three references developed by Shilon et al. (2010). We evaluate using BLEU-4 (Papineni et al., 2002). 6 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56, LDC2008G05, LDC2009E16, LDC2009G01. 7 Global Autonomous Language Exploitation, or GALE, was a DARPA-funded research project. Proceedings of MT Summit XV, vol.1: MT Researchers' Track Miami, Oct 30 - Nov 3, 2015 |p. 110 6.2 Baselines We compare the performance of adding the connectivity strength features (+Conn) to the phrase pivoting SMT model (Phrase Pivot) and building a direct SMT model using all parallel He-Ar cor"
2015.mtsummit-papers.9,2010.amta-srw.4,1,0.827218,"l, we use a TED parallel corpus of about (≈ 2M words) (Cettolo et al., 2012). Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight optimization. Weights are optimized using a tuning set of 517 sentences developed by Shilon et al. (2010). We use a maximum phrase length of size 8 across all models. We report results on a Hebrew-Arabic development set (Dev) of 500 sentence with a single reference and an evaluation set (Test) of 300 sentences with three references developed by Shilon et al. (2010). We evaluate using BLEU-4 (Papineni et al., 2002). 6 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56, LDC2008G05, LDC2009E16, LDC2009G01. 7 Global Autonomous Language Exploitation, or GALE, was a DARPA-funded re"
2015.mtsummit-papers.9,2012.eamt-1.8,1,0.851749,"es typical of Semitic languages (Itai and Wintner, 2008; Shilon et al., 2012). Hebrew orthography also uses optional diacritics and its morphology inflects for gender, number, person, state, tense and definiteness. Furthermore, Similar to Arabic, Hebrew has a set of attachable clitics, e.g., conjunctions (such as +! וw+4 ‘and’), prepositions (such as +! בb+ ‘in’), the definite article (+! הh+ ‘the’), or pronouns (such as !Mה+ +hm ‘their’). These issues contribute to a high degree of ambiguity that is a challenge to translation from Hebrew to English or to any other language. We follow Singh and Habash (2012)’s best preprocessing setup which utilized a Hebrew tagger (Adler, 2007) and produced a tokenization scheme that separated all clitics. English, our pivot language, is quite different from both Arabic and Hebrew. English is poor in morphology and barely inflects for number and tense, and for person in a limited context. English preprocessing simply includes down-casing, separating punctuation and splitting off “’s”. 5 Approach One of the main challenges in phrase pivoting is the very large size of the induced phrase table. It becomes even more challenging if either the source or target languag"
2015.mtsummit-papers.9,tsvetkov-wintner-2010-automatic,0,0.166839,"ores based on the morphological compatibility between the connected/aligned source and target words. Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve the quality of translation. Until recently, there has not been much parallel Hebrew-English and Hebrew-Arabic data (Tsvetkov and Wintner, 2010), and consequently little work on Hebrew-English and HebrewProceedings of MT Summit XV, vol.1: MT Researchers' Track Miami, Oct 30 - Nov 3, 2015 |p. 105 Translation Model Hebrew-English English-Arabic Pivot Hebrew-Arabic Training Corpora Size ≈1M words ≈60M words N/A Phrase Table # Phrase Pairs Size 3,002,887 327MB 111,702,225 14GB > 30 Billion ≈2.5TB Table 1: Translation Models Phrase Table comparison in terms of number of lines and sizes. Arabic SMT. Lavie et al. (2004) built a transfer-based translation system for Hebrew-English and so did Shilon et al. (2012) for translation between Hebrew"
2015.mtsummit-papers.9,N07-1061,0,0.409166,"on baseline with a direct model built from parallel data. 1 Introduction One of the main challenges in statistical machine translation (SMT) is the scarcity of parallel data for many language pairs especially when the source and target languages are morphologically rich. A common SMT solution to the lack of parallel data is to pivot the translation through a third language (called pivot or bridge language) for which there exist abundant parallel corpora with the source and target languages. The literature covers many pivoting techniques. One of the best performing techniques, phrase pivoting (Utiyama and Isahara, 2007), builds an induced new phrase table between the source and target. One of the main issues of this technique is that the size of the newly created pivot phrase table is very large. Moreover, many of the produced phrase pairs are of low quality which affects the translation choices during decoding and the overall translation quality. In this paper, we focus on improving phrase pivoting. We introduce morphology constraint scores which are added to the log linear space of features in order to determine the quality of the pivot phrase pairs. We compare two methods of generating the morphology cons"
2015.mtsummit-papers.9,P09-1018,0,0.0166644,"direct model built from given parallel data. Next, we briefly discuss some related work. In Section 3, we review the best performing pivoting strategy and how we use it. In Section 4, we discuss the linguistic differences among Hebrew, Arabic, and the pivot language, English. This is followed by our approach to using morphology constraints in Section 5. We finally present our experimental results in Section 6 and a case study in Section 7. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then tra"
2015.mtsummit-papers.9,P10-1047,0,0.0210764,"d target phrase pairs in the pivot phrase table (El Kholy et al., 2013). These features provide quality scores based on the number of alignment links between words in the source phrase to words of the target phrase. In this work, we extend on the connectivity scores with morphological constraints through which we provide quality scores based on the morphological compatibility between the connected/aligned source and target words. Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve the quality of translation. Until recently, there has not been much parallel Hebrew-English and Hebrew-Arabic data (Tsvetkov and Wintner, 2010), and consequently little work on Hebrew-English and HebrewProceedings of MT Summit XV, vol.1: MT Researchers' Track Miami, Oct 30 - Nov 3, 2015 |p. 105 Translation Model Hebrew-English English-Arabic Pivot Hebrew-Arabic Training Corpora Size ≈1M words ≈60M words N/A"
2020.acl-main.695,E17-2067,0,0.0305779,"en a corpus and lexicon. First, we cluster lexicon forms into cells. Then we cluster forms into paradigms given their fixed cell membership. To maintain tractability, clustering assumes a one-to-one mapping of forms to slots. Following cell and paradigm clustering, we predict forms to realize empty slots given one of the lexicon forms assigned to a cell in Clustering into Cells We use a heuristic method to determine the number of cells and what lexicon forms to assign to each. Inspired by work on inductive biases in word embeddings (Pennington et al., 2014; Trask et al., 2015; Goldberg, 2016; Avraham and Goldberg, 2017; Tu et al., 2017), we train morphosyntactically biased embeddings on the corpus and use them to k-means cluster lexicon forms into cells. Following Erdmann et al. (2018), we emphasize morphosyntactically salient dimensions in embedding space by manipulating hyperparameters in fastText (Bojanowski et al., 2017). Specifically, to encourage grouping of morphologically related words, fastText computes a word’s embedding as the sum of its subword embeddings for all subword sequences between 3 and 6 characters long (Schütze, 1993). We shorten this range to 2 to 4 to bias the grouping toward shared"
2020.acl-main.695,E17-1032,0,0.183936,"Missing"
2020.acl-main.695,P19-1376,0,0.0196105,"y. Some cognitive works suggest the PCFP cannot be too difficult for any language (Dale et al., 1998; Ackerman and Malouf, 2013, 2015; Blevins et al., 2017; Cotterell et al., 2019). Neural models can test and extend such proposals (Cotterell et al., 2018a; Silfverberg and Hulden, 2018). A related vein of work discusses how speakers inflect nonce words (Berko, 1958; Plunkett and Juola, 1999; Yang, 2015), e.g., is the past tense of sping, spinged or spung? There is a long tradition of modeling past-tense generation with neural networks (Rumelhart and McClelland, 1986; Kirov and Cotterell, 2018; Corkery et al., 2019). On the engineering side, Durrett and DeNero (2013) inspired much recent work, which has since benefited from large inflectional datasets (Kirov et al., 2018) and advances in neural sequence modeling (Bahdanau et al., 2015). Shared tasks have drawn extra attention to the PCFP (Cotterell et al., 2016a, 2017, 2018c; McCarthy et al., 2019). 3 The Paradigm Discovery Problem Paradigm discovery is a natural next step in computational morphology, building on related minimally or indirectly supervised works (§2.2) to bridge the gap between unsupervised traditions (§2.1) and supervised work on the PCF"
2020.acl-main.695,Q19-1021,1,0.85462,"dels can guess a word’s plural having only seen its singular, but the child must bootstrap morphological knowledge from scratch, first learning that singular–plural is a relevant distinction. Thus, the PDP must be at least partially solved before the PCFP can be attempted. Yet, as a supervised task, the PCFP is more easily studied, and has received much attention on its own, especially from the word-and-paradigm camp of morphological theory. Some cognitive works suggest the PCFP cannot be too difficult for any language (Dale et al., 1998; Ackerman and Malouf, 2013, 2015; Blevins et al., 2017; Cotterell et al., 2019). Neural models can test and extend such proposals (Cotterell et al., 2018a; Silfverberg and Hulden, 2018). A related vein of work discusses how speakers inflect nonce words (Berko, 1958; Plunkett and Juola, 1999; Yang, 2015), e.g., is the past tense of sping, spinged or spung? There is a long tradition of modeling past-tense generation with neural networks (Rumelhart and McClelland, 1986; Kirov and Cotterell, 2018; Corkery et al., 2019). On the engineering side, Durrett and DeNero (2013) inspired much recent work, which has since benefited from large inflectional datasets (Kirov et al., 2018)"
2020.acl-main.695,N18-2087,1,0.928989,"must bootstrap morphological knowledge from scratch, first learning that singular–plural is a relevant distinction. Thus, the PDP must be at least partially solved before the PCFP can be attempted. Yet, as a supervised task, the PCFP is more easily studied, and has received much attention on its own, especially from the word-and-paradigm camp of morphological theory. Some cognitive works suggest the PCFP cannot be too difficult for any language (Dale et al., 1998; Ackerman and Malouf, 2013, 2015; Blevins et al., 2017; Cotterell et al., 2019). Neural models can test and extend such proposals (Cotterell et al., 2018a; Silfverberg and Hulden, 2018). A related vein of work discusses how speakers inflect nonce words (Berko, 1958; Plunkett and Juola, 1999; Yang, 2015), e.g., is the past tense of sping, spinged or spung? There is a long tradition of modeling past-tense generation with neural networks (Rumelhart and McClelland, 1986; Kirov and Cotterell, 2018; Corkery et al., 2019). On the engineering side, Durrett and DeNero (2013) inspired much recent work, which has since benefited from large inflectional datasets (Kirov et al., 2018) and advances in neural sequence modeling (Bahdanau et al., 2015). Shared"
2020.acl-main.695,K18-3001,1,0.853843,"rvised morphological paradigm completion. Given only a small corpus and lexicon of verbal lemmata, participating systems must propose full paradigms for each lemma. By contrast, our framework does not reveal how many paradigms should be generated, nor do we privilege a specific form as the lemma, but we do use a larger lexicon of exclusively verbal or nominal forms. Their proposed baseline uses distributional context for POS tagging and features, but does not train embeddings as the corpus is small. 2.2 Subtasks of Paradigm Discovery A few works address subtasks of the PDP. Erdmann and Habash (2018) learn paradigm membership from raw text, but do not sort paradigms into cells. Boyé and Schalchli (2019) discuss the paradigm cell finding problem, identifying the cell (but not paradigm) realized by a given form. Lee (2015) clusters forms into cells across inflection classes. Beniamine et al. (2018) group paradigms into inflection classes, and Eskander et al. (2013) induce inflection classes and lemmata from cell labels. 2.3 The Paradigm Cell Filling Problem The PCFP is the task of predicting unseen inflected forms given morphologically labeled input. PCFP models can guess a word’s plural ha"
2020.acl-main.695,K17-2001,1,0.898483,"Missing"
2020.acl-main.695,P16-1156,1,0.930366,"i.e., they realize the same morphosyntactic properties 3. SG . PRES, but in different paradigms. Acquiring such paradigmatic knowledge enables us to produce unseen inflectional variants of new vocabulary items, i.e. to complete morphological paradigms. Much work has addressed this task, which Ackerman et al. (2009) call the paradigm cell filling problem (PCFP),1 but few have discussed inducing paradigmatic knowledge from scratch, which we call the paradigm discovery problem (PDP).2 1 In the NLP literature, this task is called morphological reinflection or morphological inflection generation (Cotterell et al., 2016a); this is only a difference in nomenclature. 2 Elsner et al. (2019) call the task the paradigm cell discovery problem; we drop cell to distinguish our task from As an unsupervised task, the PDP poses challenges for modeling and evaluation and has yet to be attempted in its full form (Elsner et al., 2019). However, we contend there is much to be gained from formalizing and studying the PDP. There are insights for cognitive modeling to be won (Pinker, 2001; Goldwater, 2007) and intuitions on combating sparse data for language generation (King and White, 2018) to be accrued. Unsupervised langua"
2020.acl-main.695,J98-3001,0,0.192601,"Missing"
2020.acl-main.695,D11-1057,0,0.266604,"(e.g., bring 6= br + ing) with high accuracy, they do not attempt to solve the PDP. They do, however, reveal which forms take the same affixes (e.g., walked, talked), not which forms occupy the same cell (e.g., walked, brought). Indeed, they explicitly struggle with irregular morphology. Segmenters also cannot easily model non-concatenative phenomena like ablaut, vowel harmony and templatic processes. Two works have proposed tasks which can be considered alternative formulations of the PDP, using either minimal or indirect supervision to bootstrap their models. We discuss each in turn. First, Dreyer and Eisner (2011) use a generative model to cluster forms into paradigms and cells with a Bayesian non-parametric mixture of weighted finite-state transducers. They present a PDP framework which, in principle, could be fully unsupervised, but their model requires a small seed of labeled data to get key information like the number of cells distinguished, making it less relevant cognitively. In contrast, our task is not directly supervised and focuses on distributional context. Second, contemporaneous to our work, Jin et al. (2020) propose a similar framework for SIGMORPHON 2020’s shared task on unsupervised mor"
2020.acl-main.695,N13-1138,0,0.166655,"be too difficult for any language (Dale et al., 1998; Ackerman and Malouf, 2013, 2015; Blevins et al., 2017; Cotterell et al., 2019). Neural models can test and extend such proposals (Cotterell et al., 2018a; Silfverberg and Hulden, 2018). A related vein of work discusses how speakers inflect nonce words (Berko, 1958; Plunkett and Juola, 1999; Yang, 2015), e.g., is the past tense of sping, spinged or spung? There is a long tradition of modeling past-tense generation with neural networks (Rumelhart and McClelland, 1986; Kirov and Cotterell, 2018; Corkery et al., 2019). On the engineering side, Durrett and DeNero (2013) inspired much recent work, which has since benefited from large inflectional datasets (Kirov et al., 2018) and advances in neural sequence modeling (Bahdanau et al., 2015). Shared tasks have drawn extra attention to the PCFP (Cotterell et al., 2016a, 2017, 2018c; McCarthy et al., 2019). 3 The Paradigm Discovery Problem Paradigm discovery is a natural next step in computational morphology, building on related minimally or indirectly supervised works (§2.2) to bridge the gap between unsupervised traditions (§2.1) and supervised work on the PCFP (§2.3). In the PCFP, 7779 Corpus The cat watched m"
2020.acl-main.695,W18-5806,1,0.852738,"ared task on unsupervised morphological paradigm completion. Given only a small corpus and lexicon of verbal lemmata, participating systems must propose full paradigms for each lemma. By contrast, our framework does not reveal how many paradigms should be generated, nor do we privilege a specific form as the lemma, but we do use a larger lexicon of exclusively verbal or nominal forms. Their proposed baseline uses distributional context for POS tagging and features, but does not train embeddings as the corpus is small. 2.2 Subtasks of Paradigm Discovery A few works address subtasks of the PDP. Erdmann and Habash (2018) learn paradigm membership from raw text, but do not sort paradigms into cells. Boyé and Schalchli (2019) discuss the paradigm cell finding problem, identifying the cell (but not paradigm) realized by a given form. Lee (2015) clusters forms into cells across inflection classes. Beniamine et al. (2018) group paradigms into inflection classes, and Eskander et al. (2013) induce inflection classes and lemmata from cell labels. 2.3 The Paradigm Cell Filling Problem The PCFP is the task of predicting unseen inflected forms given morphologically labeled input. PCFP models can guess a word’s plural ha"
2020.acl-main.695,W19-4214,1,0.815752,"cell. Our algorithm greedily builds paradigms cell by cell. To gauge the quality of a candidate paradigm, we first identify its base and exponents. Following Beniamine et al. (2018), we define π’s base, bπ , as the longest common subsequence shared by all forms in π.56 For each form f in π, we define the exponent xf as the subsequences of f that remain after removing bπ , i.e., xf is a tuple of affixes. For example, if π contains words wxyxz and axx, bπ is xx and the exponents are (&lt;w, y, z&gt;) and (&lt;a), respectively.7 Inspired by unsupervised maximum matching in greedy tokenization (Guo, 1997; Erdmann et al., 2019), we define the following paradigm score function: score(π) = X   |bπ |− |xf | (2) 1: 2: 3: 4: 5: 6: 7: 8: fj0 ∈Cj 9: 10: 11: 12: 13: 5 The fact that we use a subsequence, instead of a substring, means that we can handle non-concatenative morphology. 6 We note that the longest common subsequence may be found with a polynomial-time dynamic program; however, there will not exist an algorithm whose runtime is polynomial in the number of strings unless P = NP (Maier, 1978). 7 We use word start (&lt;) and end (&gt;) tokens to distinguish exponents; they do not count as exponent characters in eq. (2). 8"
2020.acl-main.695,P18-2089,1,0.840933,"ng assumes a one-to-one mapping of forms to slots. Following cell and paradigm clustering, we predict forms to realize empty slots given one of the lexicon forms assigned to a cell in Clustering into Cells We use a heuristic method to determine the number of cells and what lexicon forms to assign to each. Inspired by work on inductive biases in word embeddings (Pennington et al., 2014; Trask et al., 2015; Goldberg, 2016; Avraham and Goldberg, 2017; Tu et al., 2017), we train morphosyntactically biased embeddings on the corpus and use them to k-means cluster lexicon forms into cells. Following Erdmann et al. (2018), we emphasize morphosyntactically salient dimensions in embedding space by manipulating hyperparameters in fastText (Bojanowski et al., 2017). Specifically, to encourage grouping of morphologically related words, fastText computes a word’s embedding as the sum of its subword embeddings for all subword sequences between 3 and 6 characters long (Schütze, 1993). We shorten this range to 2 to 4 to bias the grouping toward shared affixes rather than (usually longer) shared stems. This helps recognize that the same affix is likely to realize the same cell, e.g., watch +ed and follow +ed. We limit t"
2020.acl-main.695,D13-1105,1,0.825814,"nominal forms. Their proposed baseline uses distributional context for POS tagging and features, but does not train embeddings as the corpus is small. 2.2 Subtasks of Paradigm Discovery A few works address subtasks of the PDP. Erdmann and Habash (2018) learn paradigm membership from raw text, but do not sort paradigms into cells. Boyé and Schalchli (2019) discuss the paradigm cell finding problem, identifying the cell (but not paradigm) realized by a given form. Lee (2015) clusters forms into cells across inflection classes. Beniamine et al. (2018) group paradigms into inflection classes, and Eskander et al. (2013) induce inflection classes and lemmata from cell labels. 2.3 The Paradigm Cell Filling Problem The PCFP is the task of predicting unseen inflected forms given morphologically labeled input. PCFP models can guess a word’s plural having only seen its singular, but the child must bootstrap morphological knowledge from scratch, first learning that singular–plural is a relevant distinction. Thus, the PDP must be at least partially solved before the PCFP can be attempted. Yet, as a supervised task, the PCFP is more easily studied, and has received much attention on its own, especially from the word-"
2020.acl-main.695,W99-0904,0,0.49395,"Missing"
2020.acl-main.695,J01-2001,0,0.284034,"Missing"
2020.acl-main.695,K19-1014,1,0.855013,"onal data. The use of orthographic data for morphological tasks is problematic, but standard in the field, due to scarcity of phonologically transcribed data (Malouf et al., 2020). 7780 Predictions paradigm 1 paradigm 2 paradigm 3 paradigm 4 cell 1 watched followed «seed» «seened» cell 2 watching «following» «seeing» «seening» cell 3 «watches» follows «sees» «seens» cell 4 «watch» «follow» see seen Table 2: Toy predictions made from the corpus and lexicon in Table 1, to be evaluated against the toy gold grid. Again, bracketed «forms» are those not occurring in the lexicon. in UD and UniMorph (Gorman et al., 2019; Malouf et al., 2020). Unlike the gold grid, the lexicon retains overabundant realizations, requiring systems to handle such phenomena. For each language, the raw sentences used to augment the corpus add over 1 million additional words. For German and Russian, we sample sentences from OpenSubtitles (Lison and Tiedemann, 2016), for Latin, the Latin Library (Johnson et al., 2016), and for English and Arabic, Gigaword (Parker et al., 2011a,b). Supplementary sentences are preprocessed via Moses (Koehn et al., 2007) to split punctuation, and, for supported languages, clitics. Table 3 shows corpus"
2020.acl-main.695,J97-4004,0,0.109447,"m the same cell. Our algorithm greedily builds paradigms cell by cell. To gauge the quality of a candidate paradigm, we first identify its base and exponents. Following Beniamine et al. (2018), we define π’s base, bπ , as the longest common subsequence shared by all forms in π.56 For each form f in π, we define the exponent xf as the subsequences of f that remain after removing bπ , i.e., xf is a tuple of affixes. For example, if π contains words wxyxz and axx, bπ is xx and the exponents are (&lt;w, y, z&gt;) and (&lt;a), respectively.7 Inspired by unsupervised maximum matching in greedy tokenization (Guo, 1997; Erdmann et al., 2019), we define the following paradigm score function: score(π) = X   |bπ |− |xf | (2) 1: 2: 3: 4: 5: 6: 7: 8: fj0 ∈Cj 9: 10: 11: 12: 13: 5 The fact that we use a subsequence, instead of a substring, means that we can handle non-concatenative morphology. 6 We note that the longest common subsequence may be found with a polynomial-time dynamic program; however, there will not exist an algorithm whose runtime is polynomial in the number of strings unless P = NP (Maier, 1978). 7 We use word start (&lt;) and end (&gt;) tokens to distinguish exponents; they do not count as exponent c"
2020.acl-main.695,2020.acl-main.598,0,0.247281,"ect supervision to bootstrap their models. We discuss each in turn. First, Dreyer and Eisner (2011) use a generative model to cluster forms into paradigms and cells with a Bayesian non-parametric mixture of weighted finite-state transducers. They present a PDP framework which, in principle, could be fully unsupervised, but their model requires a small seed of labeled data to get key information like the number of cells distinguished, making it less relevant cognitively. In contrast, our task is not directly supervised and focuses on distributional context. Second, contemporaneous to our work, Jin et al. (2020) propose a similar framework for SIGMORPHON 2020’s shared task on unsupervised morphological paradigm completion. Given only a small corpus and lexicon of verbal lemmata, participating systems must propose full paradigms for each lemma. By contrast, our framework does not reveal how many paradigms should be generated, nor do we privilege a specific form as the lemma, but we do use a larger lexicon of exclusively verbal or nominal forms. Their proposed baseline uses distributional context for POS tagging and features, but does not train embeddings as the corpus is small. 2.2 Subtasks of Paradig"
2020.acl-main.695,W18-3605,0,0.0295523,"phological inflection generation (Cotterell et al., 2016a); this is only a difference in nomenclature. 2 Elsner et al. (2019) call the task the paradigm cell discovery problem; we drop cell to distinguish our task from As an unsupervised task, the PDP poses challenges for modeling and evaluation and has yet to be attempted in its full form (Elsner et al., 2019). However, we contend there is much to be gained from formalizing and studying the PDP. There are insights for cognitive modeling to be won (Pinker, 2001; Goldwater, 2007) and intuitions on combating sparse data for language generation (King and White, 2018) to be accrued. Unsupervised language processing also has natural applications in the documentation of endangered languages (Zamaraeva et al., 2019) where a lot of annotated data is never likely to exist. Our formalization of the PDP offers a starting point for future work on unsupervised morphological paradigm completion. Our paper presents a concrete formalization of the PDP. Then, as a baseline for future work, we introduce a heuristic benchmark system. Our benchmark system takes an unannotated text corpus and a lexicon of words from the corpus to be analyzed. It first clusters the lexicon"
2020.acl-main.695,L18-1293,1,0.928002,"erell et al., 2019). Neural models can test and extend such proposals (Cotterell et al., 2018a; Silfverberg and Hulden, 2018). A related vein of work discusses how speakers inflect nonce words (Berko, 1958; Plunkett and Juola, 1999; Yang, 2015), e.g., is the past tense of sping, spinged or spung? There is a long tradition of modeling past-tense generation with neural networks (Rumelhart and McClelland, 1986; Kirov and Cotterell, 2018; Corkery et al., 2019). On the engineering side, Durrett and DeNero (2013) inspired much recent work, which has since benefited from large inflectional datasets (Kirov et al., 2018) and advances in neural sequence modeling (Bahdanau et al., 2015). Shared tasks have drawn extra attention to the PCFP (Cotterell et al., 2016a, 2017, 2018c; McCarthy et al., 2019). 3 The Paradigm Discovery Problem Paradigm discovery is a natural next step in computational morphology, building on related minimally or indirectly supervised works (§2.2) to bridge the gap between unsupervised traditions (§2.1) and supervised work on the PCFP (§2.3). In the PCFP, 7779 Corpus The cat watched me watching it . I followed the show but she had n’t seen it . Let ’s see who follows your logic . Lexicon w"
2020.acl-main.695,P07-2045,0,0.00621406,"ain, bracketed «forms» are those not occurring in the lexicon. in UD and UniMorph (Gorman et al., 2019; Malouf et al., 2020). Unlike the gold grid, the lexicon retains overabundant realizations, requiring systems to handle such phenomena. For each language, the raw sentences used to augment the corpus add over 1 million additional words. For German and Russian, we sample sentences from OpenSubtitles (Lison and Tiedemann, 2016), for Latin, the Latin Library (Johnson et al., 2016), and for English and Arabic, Gigaword (Parker et al., 2011a,b). Supplementary sentences are preprocessed via Moses (Koehn et al., 2007) to split punctuation, and, for supported languages, clitics. Table 3 shows corpus and lexicon sizes. 3.3 Metrics A system attemping the PDP is expected to output a morphologically organized grid in which rows and columns are arbitrarily ordered, but ideally, each row corresponds to a gold paradigm and each column to a gold cell. Aligning rows to paradigms and columns to cells is non-trivial, making it difficult to simply compute accuracy over gold grid slots. Furthermore, cluster-based metrics (Rosenberg and Hirschberg, 2007) are difficult to apply as forms can appear in multiple columns or r"
2020.acl-main.695,N15-2022,0,0.0209498,"digms should be generated, nor do we privilege a specific form as the lemma, but we do use a larger lexicon of exclusively verbal or nominal forms. Their proposed baseline uses distributional context for POS tagging and features, but does not train embeddings as the corpus is small. 2.2 Subtasks of Paradigm Discovery A few works address subtasks of the PDP. Erdmann and Habash (2018) learn paradigm membership from raw text, but do not sort paradigms into cells. Boyé and Schalchli (2019) discuss the paradigm cell finding problem, identifying the cell (but not paradigm) realized by a given form. Lee (2015) clusters forms into cells across inflection classes. Beniamine et al. (2018) group paradigms into inflection classes, and Eskander et al. (2013) induce inflection classes and lemmata from cell labels. 2.3 The Paradigm Cell Filling Problem The PCFP is the task of predicting unseen inflected forms given morphologically labeled input. PCFP models can guess a word’s plural having only seen its singular, but the child must bootstrap morphological knowledge from scratch, first learning that singular–plural is a relevant distinction. Thus, the PDP must be at least partially solved before the PCFP ca"
2020.acl-main.695,L16-1147,0,0.0156269,"eening» cell 3 «watches» follows «sees» «seens» cell 4 «watch» «follow» see seen Table 2: Toy predictions made from the corpus and lexicon in Table 1, to be evaluated against the toy gold grid. Again, bracketed «forms» are those not occurring in the lexicon. in UD and UniMorph (Gorman et al., 2019; Malouf et al., 2020). Unlike the gold grid, the lexicon retains overabundant realizations, requiring systems to handle such phenomena. For each language, the raw sentences used to augment the corpus add over 1 million additional words. For German and Russian, we sample sentences from OpenSubtitles (Lison and Tiedemann, 2016), for Latin, the Latin Library (Johnson et al., 2016), and for English and Arabic, Gigaword (Parker et al., 2011a,b). Supplementary sentences are preprocessed via Moses (Koehn et al., 2007) to split punctuation, and, for supported languages, clitics. Table 3 shows corpus and lexicon sizes. 3.3 Metrics A system attemping the PDP is expected to output a morphologically organized grid in which rows and columns are arbitrarily ordered, but ideally, each row corresponds to a gold paradigm and each column to a gold cell. Aligning rows to paradigms and columns to cells is non-trivial, making it diffi"
2020.acl-main.695,2020.scil-1.52,0,0.0134249,"i.e., slots realized by multiple forms, and remove all but the most frequently attested realization in UD. While some languages permit overabundance (Thornton, 2010), it often indicates typographical or annotation errors 3 Aligning UniMorph and UD requires removing diacritics in (Latin and Arabic) UniMorph corpora to match UD. This can obscure some morphosyntactic distinctions but is more consistent with natural orthography in distributional data. The use of orthographic data for morphological tasks is problematic, but standard in the field, due to scarcity of phonologically transcribed data (Malouf et al., 2020). 7780 Predictions paradigm 1 paradigm 2 paradigm 3 paradigm 4 cell 1 watched followed «seed» «seened» cell 2 watching «following» «seeing» «seening» cell 3 «watches» follows «sees» «seens» cell 4 «watch» «follow» see seen Table 2: Toy predictions made from the corpus and lexicon in Table 1, to be evaluated against the toy gold grid. Again, bracketed «forms» are those not occurring in the lexicon. in UD and UniMorph (Gorman et al., 2019; Malouf et al., 2020). Unlike the gold grid, the lexicon retains overabundant realizations, requiring systems to handle such phenomena. For each language, the"
2020.acl-main.695,W18-6011,1,0.85496,"lar to the corpus created by Vylomova et al. (2019). As a system does not know which lexicon forms will be evaluated in the gold grid, it must model the entire lexicon, which should contain a realistic distribution over rare words and inflection classes having been directly extracted from distributional data (Bybee, 2003; Lignos and Yang, 2018). To ensure the gold grid is reasonably clean, we take all word–lemma–feature tuples from the UD portion of the corpus matching the specified POS and convert the features to a morphosyntactic cell identifier compatible with UniMorph representation as in McCarthy et al. (2018).3 Then we check which word–lemma–cell tuples also occur in UniMorph. For each unique lemma in this intersection, the full paradigm is added as a row to the gold grid. To filter typos and annotation discrepancies, we identify any overabundant slots, i.e., slots realized by multiple forms, and remove all but the most frequently attested realization in UD. While some languages permit overabundance (Thornton, 2010), it often indicates typographical or annotation errors 3 Aligning UniMorph and UD requires removing diacritics in (Latin and Arabic) UniMorph corpora to match UD. This can obscure some"
2020.acl-main.695,W19-4226,1,0.679152,"ect nonce words (Berko, 1958; Plunkett and Juola, 1999; Yang, 2015), e.g., is the past tense of sping, spinged or spung? There is a long tradition of modeling past-tense generation with neural networks (Rumelhart and McClelland, 1986; Kirov and Cotterell, 2018; Corkery et al., 2019). On the engineering side, Durrett and DeNero (2013) inspired much recent work, which has since benefited from large inflectional datasets (Kirov et al., 2018) and advances in neural sequence modeling (Bahdanau et al., 2015). Shared tasks have drawn extra attention to the PCFP (Cotterell et al., 2016a, 2017, 2018c; McCarthy et al., 2019). 3 The Paradigm Discovery Problem Paradigm discovery is a natural next step in computational morphology, building on related minimally or indirectly supervised works (§2.2) to bridge the gap between unsupervised traditions (§2.1) and supervised work on the PCFP (§2.3). In the PCFP, 7779 Corpus The cat watched me watching it . I followed the show but she had n’t seen it . Let ’s see who follows your logic . Lexicon watching, seen, follows, watched, followed, see Gold Grid paradigm 1 paradigm 2 paradigm 3 cell 1 «watch» «follow» see cell 2 «watches» follows «sees» cell 3 watching «following» «s"
2020.acl-main.695,Q15-1012,0,0.338073,"Missing"
2020.acl-main.695,L16-1262,0,0.0610659,"Missing"
2020.acl-main.695,D14-1162,0,0.0838528,"ark system for proposing a morphologically organized grid given a corpus and lexicon. First, we cluster lexicon forms into cells. Then we cluster forms into paradigms given their fixed cell membership. To maintain tractability, clustering assumes a one-to-one mapping of forms to slots. Following cell and paradigm clustering, we predict forms to realize empty slots given one of the lexicon forms assigned to a cell in Clustering into Cells We use a heuristic method to determine the number of cells and what lexicon forms to assign to each. Inspired by work on inductive biases in word embeddings (Pennington et al., 2014; Trask et al., 2015; Goldberg, 2016; Avraham and Goldberg, 2017; Tu et al., 2017), we train morphosyntactically biased embeddings on the corpus and use them to k-means cluster lexicon forms into cells. Following Erdmann et al. (2018), we emphasize morphosyntactically salient dimensions in embedding space by manipulating hyperparameters in fastText (Bojanowski et al., 2017). Specifically, to encourage grouping of morphologically related words, fastText computes a word’s embedding as the sum of its subword embeddings for all subword sequences between 3 and 6 characters long (Schütze, 1993). We"
2020.acl-main.695,D07-1043,0,0.0730775,"d (Parker et al., 2011a,b). Supplementary sentences are preprocessed via Moses (Koehn et al., 2007) to split punctuation, and, for supported languages, clitics. Table 3 shows corpus and lexicon sizes. 3.3 Metrics A system attemping the PDP is expected to output a morphologically organized grid in which rows and columns are arbitrarily ordered, but ideally, each row corresponds to a gold paradigm and each column to a gold cell. Aligning rows to paradigms and columns to cells is non-trivial, making it difficult to simply compute accuracy over gold grid slots. Furthermore, cluster-based metrics (Rosenberg and Hirschberg, 2007) are difficult to apply as forms can appear in multiple columns or rows. Thus, we propose novel metrics that are lexical, based on analogical relationships between forms. We propose a set of PDP metrics, to measure how well organized lexicon forms are in the grid, and a set of PCFP metrics, to measure how well the system anticipates unattested inflectional variants. All metrics support non-canonical phenomena such as defective paradigms and overabundant slots. 3.3.1 PDP Metrics A form f ’s paradigm mates are all those forms that co-occur in at least one paradigm with f . f ’s paradigm F-score"
2020.acl-main.695,D18-1315,0,0.0493291,"ical knowledge from scratch, first learning that singular–plural is a relevant distinction. Thus, the PDP must be at least partially solved before the PCFP can be attempted. Yet, as a supervised task, the PCFP is more easily studied, and has received much attention on its own, especially from the word-and-paradigm camp of morphological theory. Some cognitive works suggest the PCFP cannot be too difficult for any language (Dale et al., 1998; Ackerman and Malouf, 2013, 2015; Blevins et al., 2017; Cotterell et al., 2019). Neural models can test and extend such proposals (Cotterell et al., 2018a; Silfverberg and Hulden, 2018). A related vein of work discusses how speakers inflect nonce words (Berko, 1958; Plunkett and Juola, 1999; Yang, 2015), e.g., is the past tense of sping, spinged or spung? There is a long tradition of modeling past-tense generation with neural networks (Rumelhart and McClelland, 1986; Kirov and Cotterell, 2018; Corkery et al., 2019). On the engineering side, Durrett and DeNero (2013) inspired much recent work, which has since benefited from large inflectional datasets (Kirov et al., 2018) and advances in neural sequence modeling (Bahdanau et al., 2015). Shared tasks have drawn extra attention"
2020.acl-main.695,N19-1203,1,0.854484,"DP For a given language and POS, we create a corpus, lexicon, and gold grid based on a Universal Dependencies (UD) corpus (Nivre et al., 2016). At a high level, the corpus includes raw, non-UD sentences, and UD sentences stripped of annotations. The lexicon includes all forms occurring in the UD sentences with the specified POS (potentially including variant spellings and typographical errors). The gold grid consists of full paradigms for every word which co-occurs in UD and the UniMorph lexicon (Kirov et al., 2018) with a matching lemma–cell analysis; this is similar to the corpus created by Vylomova et al. (2019). As a system does not know which lexicon forms will be evaluated in the gold grid, it must model the entire lexicon, which should contain a realistic distribution over rare words and inflection classes having been directly extracted from distributional data (Bybee, 2003; Lignos and Yang, 2018). To ensure the gold grid is reasonably clean, we take all word–lemma–feature tuples from the UD portion of the corpus matching the specified POS and convert the features to a morphosyntactic cell identifier compatible with UniMorph representation as in McCarthy et al. (2018).3 Then we check which word–l"
2020.acl-main.695,D18-1268,0,0.0934499,"Missing"
2020.acl-main.695,W19-6005,0,0.0193758,"radigm cell discovery problem; we drop cell to distinguish our task from As an unsupervised task, the PDP poses challenges for modeling and evaluation and has yet to be attempted in its full form (Elsner et al., 2019). However, we contend there is much to be gained from formalizing and studying the PDP. There are insights for cognitive modeling to be won (Pinker, 2001; Goldwater, 2007) and intuitions on combating sparse data for language generation (King and White, 2018) to be accrued. Unsupervised language processing also has natural applications in the documentation of endangered languages (Zamaraeva et al., 2019) where a lot of annotated data is never likely to exist. Our formalization of the PDP offers a starting point for future work on unsupervised morphological paradigm completion. Our paper presents a concrete formalization of the PDP. Then, as a baseline for future work, we introduce a heuristic benchmark system. Our benchmark system takes an unannotated text corpus and a lexicon of words from the corpus to be analyzed. It first clusters the lexicon by cell and then by paradigm making use of distributional semantics and string similarity. Finally, it uses this clustering as silver-standard super"
2020.acl-main.695,W17-2632,0,0.0231066,"st, we cluster lexicon forms into cells. Then we cluster forms into paradigms given their fixed cell membership. To maintain tractability, clustering assumes a one-to-one mapping of forms to slots. Following cell and paradigm clustering, we predict forms to realize empty slots given one of the lexicon forms assigned to a cell in Clustering into Cells We use a heuristic method to determine the number of cells and what lexicon forms to assign to each. Inspired by work on inductive biases in word embeddings (Pennington et al., 2014; Trask et al., 2015; Goldberg, 2016; Avraham and Goldberg, 2017; Tu et al., 2017), we train morphosyntactically biased embeddings on the corpus and use them to k-means cluster lexicon forms into cells. Following Erdmann et al. (2018), we emphasize morphosyntactically salient dimensions in embedding space by manipulating hyperparameters in fastText (Bojanowski et al., 2017). Specifically, to encourage grouping of morphologically related words, fastText computes a word’s embedding as the sum of its subword embeddings for all subword sequences between 3 and 6 characters long (Schütze, 1993). We shorten this range to 2 to 4 to bias the grouping toward shared affixes rather tha"
2020.acl-main.695,Q17-1010,0,\N,Missing
2020.acl-main.736,N16-3003,0,0.0252284,"is mainly spoken, and lacks a standard orthography (Habash et al., 2012a). The lack of a standard orthography further increases sparsity and ambiguity, hence requiring explicit normalization. Habash et al. (2012a, 2018) proposed CODA, a Conventional Orthography for Dialectal Arabic, which aims to provide a conventionalized orthography across the various Arabic dialects. We use CODA as the reference for the normalization task. 2.2 Morphological Tagging Arabic morphological tagging and disambiguation have been studied extensively in literature, with contributions for MSA (Khalifa et al., 2016; Abdelali et al., 2016; Habash and Rambow, 2005; Diab et al., 2004), and DA (Habash et al., 2013; Al-Sabbagh and Girju, 2012; Duh and Kirchhoff, 2005). There are also several recent contributions that showed significant accuracy improvement using deep learning models (Zalmout et al., 2018; Inoue et al., 2017; Zalmout and Habash, 2017; Heigold et al., 2016). In addition to other deep learning contributions that showed limited success for Arabic (Shen et al., 2016). Most of these contributions model the different morphological features separately, or focus on a limited feature subset. We elaborate on the contribution"
2020.acl-main.736,D15-1274,0,0.0657726,"n Num Stt a i f s na a i m s na a i f s na a i m s na na na f s c na na m s i na na m s i Cas na na na na n g g Enc0 dobj3mp dobj3mp dobj3mp dobj3mp poss3mp 0 0 Table 1: A subset of all the possible analyses for the word ÑîDÖ Ï lmthm. Notice that in the last two analyses the words are disambiguated through the lemmas and diacritized forms only, and they share all the other features. Diacritization has generally been an active area of research (Darwish et al., 2017; Zitouni et al., 2006; Nelken and Shieber, 2005). More recent contributions use Deep Learning models in different configurations; Belinkov and Glass (2015) model diacritization as a classification task, using Long Short Term Memory (LSTM) cells. And Abandah et al. (2015) use LSTMs to model diacritization as a sequence transcription task, similar to Mubarak et al. (2019) who model diacritization as a sequence-to-sequence task. Early contributions for lemmatization used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which had a limited capacity for modeling unseen words or lemmas. There were also several contributions that utilize a joint tagging and lemmatization approach, using CRFs and Maximum Entropy models (Müller et al., 2"
2020.acl-main.736,N18-1126,0,0.265228,"ization approach, using CRFs and Maximum Entropy models (Müller et al., 2015; Chrupala et al., 2008). Other contributions approached lemmatization as a lemma selection task (Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. Many of the lemmatization models for Arabic use a similar approach (Pasha et al., 2014; Roth et al., 2008). More recently, sequenceto-sequence models with attention (Bahdanau et al., 2014) have been shown useful in several NLP tasks, with several lemmatization contributions (Malaviya et al., 2019; Bergmanis and Goldwater, 2018; Pütz et al., 2018). Other contributions use additional morphosyntactic features as part of the modeling architecture (Kanerva et al., 2019; Kondratyuk et al., 2018), somewhat similar to our approach. 2.4 Joint Morphological Modeling in Arabic There are also several contributions for the joint modeling of the different morphological features in Arabic. However, most of these contributions use separate models for each of the features, and usually use a ranking step to select the best overall morphological analysis from an external morphological analyzer (Roth et al., 2008; Habash and Rambow, 2"
2020.acl-main.736,Q17-1010,0,0.343579,"to get a single representation, aj , for all the features: afj = aj = Nf X afj,n n=1 num [apos ; ...; avox j ] j ; ...; aj Where Nf is the set of possible candidate values for each feature f (from the analyzer). The aj vector does not constitute a hard constraint and can be discarded if a morphological analyzer is not used. Several previous contributions for Arabic showed that pretraining the word embeddings is very useful (Erdmann et al., 2018; Watson et al., 2018; Zalmout and Habash, 2017), including the baselines used in this paper. We therefore pre-train the word embeddings with FastText (Bojanowski et al., 2017), using a large external dataset. The pre-trained embeddings are fixed during the model training. The character and tag embeddings are learnt within the model. We use a multitask learning setup to train the different morphological features jointly, through sharing the parameters of the hidden layers in the BiLSTM network. The input is also shared, through the vj vector. The output of the network is then fed to a separate non-linearity function, output layer, and softmax, for a probability distribution of each of the features separately. Figure 1 shows the overall tagging architecture. 3.2 Enco"
2020.acl-main.736,chrupala-etal-2008-learning,0,0.105873,"Missing"
2020.acl-main.736,W17-1302,0,0.563234,"0 0 0 0 3 verb 0 0 0 0 2 verb 0 0 0 0 2 verb 0 0 0 0 1 noun 0 0 0 0 na noun 0 0 li (prep) 0 na noun 0 0 li (prep) 0 na Asp p p p p na na na Vox Mod Gen Num Stt a i f s na a i m s na a i f s na a i m s na na na f s c na na m s i na na m s i Cas na na na na n g g Enc0 dobj3mp dobj3mp dobj3mp dobj3mp poss3mp 0 0 Table 1: A subset of all the possible analyses for the word ÑîDÖ Ï lmthm. Notice that in the last two analyses the words are disambiguated through the lemmas and diacritized forms only, and they share all the other features. Diacritization has generally been an active area of research (Darwish et al., 2017; Zitouni et al., 2006; Nelken and Shieber, 2005). More recent contributions use Deep Learning models in different configurations; Belinkov and Glass (2015) model diacritization as a classification task, using Long Short Term Memory (LSTM) cells. And Abandah et al. (2015) use LSTMs to model diacritization as a sequence transcription task, similar to Mubarak et al. (2019) who model diacritization as a sequence-to-sequence task. Early contributions for lemmatization used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which had a limited capacity for modeling unseen words or le"
2020.acl-main.736,L18-1015,0,0.0354147,"Missing"
2020.acl-main.736,N04-4038,0,0.0510598,"phy (Habash et al., 2012a). The lack of a standard orthography further increases sparsity and ambiguity, hence requiring explicit normalization. Habash et al. (2012a, 2018) proposed CODA, a Conventional Orthography for Dialectal Arabic, which aims to provide a conventionalized orthography across the various Arabic dialects. We use CODA as the reference for the normalization task. 2.2 Morphological Tagging Arabic morphological tagging and disambiguation have been studied extensively in literature, with contributions for MSA (Khalifa et al., 2016; Abdelali et al., 2016; Habash and Rambow, 2005; Diab et al., 2004), and DA (Habash et al., 2013; Al-Sabbagh and Girju, 2012; Duh and Kirchhoff, 2005). There are also several recent contributions that showed significant accuracy improvement using deep learning models (Zalmout et al., 2018; Inoue et al., 2017; Zalmout and Habash, 2017; Heigold et al., 2016). In addition to other deep learning contributions that showed limited success for Arabic (Shen et al., 2016). Most of these contributions model the different morphological features separately, or focus on a limited feature subset. We elaborate on the contributions with some joint modeling aspects later in t"
2020.acl-main.736,W05-0708,0,0.099449,"ses sparsity and ambiguity, hence requiring explicit normalization. Habash et al. (2012a, 2018) proposed CODA, a Conventional Orthography for Dialectal Arabic, which aims to provide a conventionalized orthography across the various Arabic dialects. We use CODA as the reference for the normalization task. 2.2 Morphological Tagging Arabic morphological tagging and disambiguation have been studied extensively in literature, with contributions for MSA (Khalifa et al., 2016; Abdelali et al., 2016; Habash and Rambow, 2005; Diab et al., 2004), and DA (Habash et al., 2013; Al-Sabbagh and Girju, 2012; Duh and Kirchhoff, 2005). There are also several recent contributions that showed significant accuracy improvement using deep learning models (Zalmout et al., 2018; Inoue et al., 2017; Zalmout and Habash, 2017; Heigold et al., 2016). In addition to other deep learning contributions that showed limited success for Arabic (Shen et al., 2016). Most of these contributions model the different morphological features separately, or focus on a limited feature subset. We elaborate on the contributions with some joint modeling aspects later in the section. 2.3 Diacritization and Lemmatization • Non-lexicalized features: aspect"
2020.acl-main.736,P18-2089,1,0.846206,"ags are alternatives and do not constitute a sequence) (Zalmout and Habash, 2019). We concatenate the individual afj vectors for each morphological feature f of each word, to get a single representation, aj , for all the features: afj = aj = Nf X afj,n n=1 num [apos ; ...; avox j ] j ; ...; aj Where Nf is the set of possible candidate values for each feature f (from the analyzer). The aj vector does not constitute a hard constraint and can be discarded if a morphological analyzer is not used. Several previous contributions for Arabic showed that pretraining the word embeddings is very useful (Erdmann et al., 2018; Watson et al., 2018; Zalmout and Habash, 2017), including the baselines used in this paper. We therefore pre-train the word embeddings with FastText (Bojanowski et al., 2017), using a large external dataset. The pre-trained embeddings are fixed during the model training. The character and tag embeddings are learnt within the model. We use a multitask learning setup to train the different morphological features jointly, through sharing the parameters of the hidden layers in the BiLSTM network. The input is also shared, through the vj vector. The output of the network is then fed to a separate"
2020.acl-main.736,N13-1066,1,0.725565,"icted tags are on the word level. The different granularities might create some biases, and we found that backpropagating gradients from the decoder to the tagger network leads to instability at the tagger. Therefore, we prevent the decoder from backpropagating gradients to the tagger during training. This is consistent with the model of Kondratyuk et al. (2018). 3.4 Surface Form Normalization We use the term normalization in the sense of enriched normalization introduced by El Kholy and Habash (2012) for MSA; and in the sense of spelling conventionalization (into CODA) for DA as described by Eskander et al. (2013). Both are non-trivial tasks comparable to true-casing or spelling correction for other languages. The normalization task is particularly important for dialectal content, which lack a standardized orthography. The training data that we use has the diacritized annotations already in the CODA normalized form for E GY. So the output sequence of the diacritization task should be both the diacritized and CODA normalized version of the input sequence. This normalization is learnt explicitly in our character level sequence-to-sequence model. For MSA there is no need for CODA normalization, so the nor"
2020.acl-main.736,P98-1062,0,0.295676,"h et al. (2015) use LSTMs to model diacritization as a sequence transcription task, similar to Mubarak et al. (2019) who model diacritization as a sequence-to-sequence task. Early contributions for lemmatization used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which had a limited capacity for modeling unseen words or lemmas. There were also several contributions that utilize a joint tagging and lemmatization approach, using CRFs and Maximum Entropy models (Müller et al., 2015; Chrupala et al., 2008). Other contributions approached lemmatization as a lemma selection task (Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. Many of the lemmatization models for Arabic use a similar approach (Pasha et al., 2014; Roth et al., 2008). More recently, sequenceto-sequence models with attention (Bahdanau et al., 2014) have been shown useful in several NLP tasks, with several lemmatization contributions (Malaviya et al., 2019; Bergmanis and Goldwater, 2018; Pütz et al., 2018). Other contributions use additional morphosyntactic features as part of the modeling architecture (Kanerva et al., 2019; Kondratyuk et al., 2018"
2020.acl-main.736,W12-2301,1,0.912155,"itics, question proclitics. Table 1 shows an example highlighting the different morphological features. The example presents a subset of the possible analyses for the word ÑîDÖ Ï lmthm.2 Disambiguation using the non-lexicalized features only is not conclusive enough, as we see in the last two analyses, where the lemma and diacritization only can disambiguate the right analysis. Dialectal Arabic (DA) includes several dialects of Arabic, like E GY, that vary by the geographical location in the Arab world. DA is also Semitic and an MRL, but it is mainly spoken, and lacks a standard orthography (Habash et al., 2012a). The lack of a standard orthography further increases sparsity and ambiguity, hence requiring explicit normalization. Habash et al. (2012a, 2018) proposed CODA, a Conventional Orthography for Dialectal Arabic, which aims to provide a conventionalized orthography across the various Arabic dialects. We use CODA as the reference for the normalization task. 2.2 Morphological Tagging Arabic morphological tagging and disambiguation have been studied extensively in literature, with contributions for MSA (Khalifa et al., 2016; Abdelali et al., 2016; Habash and Rambow, 2005; Diab et al., 2004), and"
2020.acl-main.736,P05-1071,1,0.751634,"lacks a standard orthography (Habash et al., 2012a). The lack of a standard orthography further increases sparsity and ambiguity, hence requiring explicit normalization. Habash et al. (2012a, 2018) proposed CODA, a Conventional Orthography for Dialectal Arabic, which aims to provide a conventionalized orthography across the various Arabic dialects. We use CODA as the reference for the normalization task. 2.2 Morphological Tagging Arabic morphological tagging and disambiguation have been studied extensively in literature, with contributions for MSA (Khalifa et al., 2016; Abdelali et al., 2016; Habash and Rambow, 2005; Diab et al., 2004), and DA (Habash et al., 2013; Al-Sabbagh and Girju, 2012; Duh and Kirchhoff, 2005). There are also several recent contributions that showed significant accuracy improvement using deep learning models (Zalmout et al., 2018; Inoue et al., 2017; Zalmout and Habash, 2017; Heigold et al., 2016). In addition to other deep learning contributions that showed limited success for Arabic (Shen et al., 2016). Most of these contributions model the different morphological features separately, or focus on a limited feature subset. We elaborate on the contributions with some joint modelin"
2020.acl-main.736,N07-2014,1,0.514378,"and Goldwater, 2018; Pütz et al., 2018). Other contributions use additional morphosyntactic features as part of the modeling architecture (Kanerva et al., 2019; Kondratyuk et al., 2018), somewhat similar to our approach. 2.4 Joint Morphological Modeling in Arabic There are also several contributions for the joint modeling of the different morphological features in Arabic. However, most of these contributions use separate models for each of the features, and usually use a ranking step to select the best overall morphological analysis from an external morphological analyzer (Roth et al., 2008; Habash and Rambow, 2007). MADAMIRA (Pasha et al., 2014) is a popular system for Arabic morphological tagging and disambiguation. It uses SVMs for the different nonlexicalized features, and n-gram language models for the lemmas and diacritized forms. Zalmout and Habash (2017) presented a neural extension of this model, with LSTM taggers for the individual features, and neural language models for the lexicalized features. Inoue et al. (2017) used multi-task learning for fine-grained POS tagging, modeling the different morphological features jointly, but they do not model lemmas or diacritized forms. Zalmout and Habash"
2020.acl-main.736,N13-1044,1,0.887355,"The lack of a standard orthography further increases sparsity and ambiguity, hence requiring explicit normalization. Habash et al. (2012a, 2018) proposed CODA, a Conventional Orthography for Dialectal Arabic, which aims to provide a conventionalized orthography across the various Arabic dialects. We use CODA as the reference for the normalization task. 2.2 Morphological Tagging Arabic morphological tagging and disambiguation have been studied extensively in literature, with contributions for MSA (Khalifa et al., 2016; Abdelali et al., 2016; Habash and Rambow, 2005; Diab et al., 2004), and DA (Habash et al., 2013; Al-Sabbagh and Girju, 2012; Duh and Kirchhoff, 2005). There are also several recent contributions that showed significant accuracy improvement using deep learning models (Zalmout et al., 2018; Inoue et al., 2017; Zalmout and Habash, 2017; Heigold et al., 2016). In addition to other deep learning contributions that showed limited success for Arabic (Shen et al., 2016). Most of these contributions model the different morphological features separately, or focus on a limited feature subset. We elaborate on the contributions with some joint modeling aspects later in the section. 2.3 Diacritizatio"
2020.acl-main.736,K17-1042,0,0.0968838,"aims to provide a conventionalized orthography across the various Arabic dialects. We use CODA as the reference for the normalization task. 2.2 Morphological Tagging Arabic morphological tagging and disambiguation have been studied extensively in literature, with contributions for MSA (Khalifa et al., 2016; Abdelali et al., 2016; Habash and Rambow, 2005; Diab et al., 2004), and DA (Habash et al., 2013; Al-Sabbagh and Girju, 2012; Duh and Kirchhoff, 2005). There are also several recent contributions that showed significant accuracy improvement using deep learning models (Zalmout et al., 2018; Inoue et al., 2017; Zalmout and Habash, 2017; Heigold et al., 2016). In addition to other deep learning contributions that showed limited success for Arabic (Shen et al., 2016). Most of these contributions model the different morphological features separately, or focus on a limited feature subset. We elaborate on the contributions with some joint modeling aspects later in the section. 2.3 Diacritization and Lemmatization • Non-lexicalized features: aspect (asp), case (cas), gender (gen), person (per), part-ofDiacritization and lemmatization are very useful for tasks like information retrieval, machine translati"
2020.acl-main.736,C16-2047,1,0.86324,"tic and an MRL, but it is mainly spoken, and lacks a standard orthography (Habash et al., 2012a). The lack of a standard orthography further increases sparsity and ambiguity, hence requiring explicit normalization. Habash et al. (2012a, 2018) proposed CODA, a Conventional Orthography for Dialectal Arabic, which aims to provide a conventionalized orthography across the various Arabic dialects. We use CODA as the reference for the normalization task. 2.2 Morphological Tagging Arabic morphological tagging and disambiguation have been studied extensively in literature, with contributions for MSA (Khalifa et al., 2016; Abdelali et al., 2016; Habash and Rambow, 2005; Diab et al., 2004), and DA (Habash et al., 2013; Al-Sabbagh and Girju, 2012; Duh and Kirchhoff, 2005). There are also several recent contributions that showed significant accuracy improvement using deep learning models (Zalmout et al., 2018; Inoue et al., 2017; Zalmout and Habash, 2017; Heigold et al., 2016). In addition to other deep learning contributions that showed limited success for Arabic (Shen et al., 2016). Most of these contributions model the different morphological features separately, or focus on a limited feature subset. We elabor"
2020.acl-main.736,D18-1532,0,0.0420884,"Missing"
2020.acl-main.736,D15-1166,0,0.0742594,"the dw -dimensional word embedding of the word j in which character i appears in. Given the characters of input sentence c and its lemmatized equivalent y, the goal is to model P (yk |ci , wj ). We then feed the input vectors to a network of two Bi-LSTM layers for the hidden representation at the encoder. 3.3 Decoders We use separate decoders for lemmatization and diacritization, with two LSTM layers for each. Both decoders share the same input and parameters of the encoder Bi-LSTM network. For each decoder, we condition on the decoder output of the previous step, along with Luong attention (Luong et al., 2015) over the encoder outputs hi , and the predicted tags from the tagger. We use the last encoder output as the initial states for the decoder layers. We use scheduled sampling (Bengio et al., 2015) during training, and feed the dc -dimensional character embeddings at every time step. But we found empirically that using a constant sampling probability instead of scheduling provides better results. 8300 We also use dropout on the non-recurrent connections of both the encoder and decoder layers during training. The decoder outputs are fed to a softmax layer that reshapes the vectors to dimension dv"
2020.acl-main.736,N19-1155,0,0.0608861,"oint tagging and lemmatization approach, using CRFs and Maximum Entropy models (Müller et al., 2015; Chrupala et al., 2008). Other contributions approached lemmatization as a lemma selection task (Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. Many of the lemmatization models for Arabic use a similar approach (Pasha et al., 2014; Roth et al., 2008). More recently, sequenceto-sequence models with attention (Bahdanau et al., 2014) have been shown useful in several NLP tasks, with several lemmatization contributions (Malaviya et al., 2019; Bergmanis and Goldwater, 2018; Pütz et al., 2018). Other contributions use additional morphosyntactic features as part of the modeling architecture (Kanerva et al., 2019; Kondratyuk et al., 2018), somewhat similar to our approach. 2.4 Joint Morphological Modeling in Arabic There are also several contributions for the joint modeling of the different morphological features in Arabic. However, most of these contributions use separate models for each of the features, and usually use a ranking step to select the best overall morphological analysis from an external morphological analyzer (Roth et"
2020.acl-main.736,N19-1248,0,0.10727,"ÑîDÖ Ï lmthm. Notice that in the last two analyses the words are disambiguated through the lemmas and diacritized forms only, and they share all the other features. Diacritization has generally been an active area of research (Darwish et al., 2017; Zitouni et al., 2006; Nelken and Shieber, 2005). More recent contributions use Deep Learning models in different configurations; Belinkov and Glass (2015) model diacritization as a classification task, using Long Short Term Memory (LSTM) cells. And Abandah et al. (2015) use LSTMs to model diacritization as a sequence transcription task, similar to Mubarak et al. (2019) who model diacritization as a sequence-to-sequence task. Early contributions for lemmatization used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which had a limited capacity for modeling unseen words or lemmas. There were also several contributions that utilize a joint tagging and lemmatization approach, using CRFs and Maximum Entropy models (Müller et al., 2015; Chrupala et al., 2008). Other contributions approached lemmatization as a lemma selection task (Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological"
2020.acl-main.736,D15-1272,0,0.0145799,"and Glass (2015) model diacritization as a classification task, using Long Short Term Memory (LSTM) cells. And Abandah et al. (2015) use LSTMs to model diacritization as a sequence transcription task, similar to Mubarak et al. (2019) who model diacritization as a sequence-to-sequence task. Early contributions for lemmatization used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which had a limited capacity for modeling unseen words or lemmas. There were also several contributions that utilize a joint tagging and lemmatization approach, using CRFs and Maximum Entropy models (Müller et al., 2015; Chrupala et al., 2008). Other contributions approached lemmatization as a lemma selection task (Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. Many of the lemmatization models for Arabic use a similar approach (Pasha et al., 2014; Roth et al., 2008). More recently, sequenceto-sequence models with attention (Bahdanau et al., 2014) have been shown useful in several NLP tasks, with several lemmatization contributions (Malaviya et al., 2019; Bergmanis and Goldwater, 2018; Pütz et al., 2018). Other contributions use a"
2020.acl-main.736,W05-0711,0,0.339047,"b 0 0 0 0 1 noun 0 0 0 0 na noun 0 0 li (prep) 0 na noun 0 0 li (prep) 0 na Asp p p p p na na na Vox Mod Gen Num Stt a i f s na a i m s na a i f s na a i m s na na na f s c na na m s i na na m s i Cas na na na na n g g Enc0 dobj3mp dobj3mp dobj3mp dobj3mp poss3mp 0 0 Table 1: A subset of all the possible analyses for the word ÑîDÖ Ï lmthm. Notice that in the last two analyses the words are disambiguated through the lemmas and diacritized forms only, and they share all the other features. Diacritization has generally been an active area of research (Darwish et al., 2017; Zitouni et al., 2006; Nelken and Shieber, 2005). More recent contributions use Deep Learning models in different configurations; Belinkov and Glass (2015) model diacritization as a classification task, using Long Short Term Memory (LSTM) cells. And Abandah et al. (2015) use LSTMs to model diacritization as a sequence transcription task, similar to Mubarak et al. (2019) who model diacritization as a sequence-to-sequence task. Early contributions for lemmatization used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which had a limited capacity for modeling unseen words or lemmas. There were also several contributions that"
2020.acl-main.736,pasha-etal-2014-madamira,1,0.921999,"Missing"
2020.acl-main.736,P08-2030,1,0.609454,"d finite state machines (Schmid et al., 2004; Minnen et al., 2001), which had a limited capacity for modeling unseen words or lemmas. There were also several contributions that utilize a joint tagging and lemmatization approach, using CRFs and Maximum Entropy models (Müller et al., 2015; Chrupala et al., 2008). Other contributions approached lemmatization as a lemma selection task (Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. Many of the lemmatization models for Arabic use a similar approach (Pasha et al., 2014; Roth et al., 2008). More recently, sequenceto-sequence models with attention (Bahdanau et al., 2014) have been shown useful in several NLP tasks, with several lemmatization contributions (Malaviya et al., 2019; Bergmanis and Goldwater, 2018; Pütz et al., 2018). Other contributions use additional morphosyntactic features as part of the modeling architecture (Kanerva et al., 2019; Kondratyuk et al., 2018), somewhat similar to our approach. 2.4 Joint Morphological Modeling in Arabic There are also several contributions for the joint modeling of the different morphological features in Arabic. However, most of these"
2020.acl-main.736,schmid-etal-2004-smor,0,0.0301132,"the other features. Diacritization has generally been an active area of research (Darwish et al., 2017; Zitouni et al., 2006; Nelken and Shieber, 2005). More recent contributions use Deep Learning models in different configurations; Belinkov and Glass (2015) model diacritization as a classification task, using Long Short Term Memory (LSTM) cells. And Abandah et al. (2015) use LSTMs to model diacritization as a sequence transcription task, similar to Mubarak et al. (2019) who model diacritization as a sequence-to-sequence task. Early contributions for lemmatization used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which had a limited capacity for modeling unseen words or lemmas. There were also several contributions that utilize a joint tagging and lemmatization approach, using CRFs and Maximum Entropy models (Müller et al., 2015; Chrupala et al., 2008). Other contributions approached lemmatization as a lemma selection task (Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. Many of the lemmatization models for Arabic use a similar approach (Pasha et al., 2014; Roth et al., 2008). More recently, sequencet"
2020.acl-main.736,C16-1018,0,0.0268108,"Tagging Arabic morphological tagging and disambiguation have been studied extensively in literature, with contributions for MSA (Khalifa et al., 2016; Abdelali et al., 2016; Habash and Rambow, 2005; Diab et al., 2004), and DA (Habash et al., 2013; Al-Sabbagh and Girju, 2012; Duh and Kirchhoff, 2005). There are also several recent contributions that showed significant accuracy improvement using deep learning models (Zalmout et al., 2018; Inoue et al., 2017; Zalmout and Habash, 2017; Heigold et al., 2016). In addition to other deep learning contributions that showed limited success for Arabic (Shen et al., 2016). Most of these contributions model the different morphological features separately, or focus on a limited feature subset. We elaborate on the contributions with some joint modeling aspects later in the section. 2.3 Diacritization and Lemmatization • Non-lexicalized features: aspect (asp), case (cas), gender (gen), person (per), part-ofDiacritization and lemmatization are very useful for tasks like information retrieval, machine translation, and text-to-speech, among others. 1 For more information on Arabic natural language processing, see (Habash, 2010). 2 Arabic transliteration is presented"
2020.acl-main.736,D18-1097,1,0.85209,"nd do not constitute a sequence) (Zalmout and Habash, 2019). We concatenate the individual afj vectors for each morphological feature f of each word, to get a single representation, aj , for all the features: afj = aj = Nf X afj,n n=1 num [apos ; ...; avox j ] j ; ...; aj Where Nf is the set of possible candidate values for each feature f (from the analyzer). The aj vector does not constitute a hard constraint and can be discarded if a morphological analyzer is not used. Several previous contributions for Arabic showed that pretraining the word embeddings is very useful (Erdmann et al., 2018; Watson et al., 2018; Zalmout and Habash, 2017), including the baselines used in this paper. We therefore pre-train the word embeddings with FastText (Bojanowski et al., 2017), using a large external dataset. The pre-trained embeddings are fixed during the model training. The character and tag embeddings are learnt within the model. We use a multitask learning setup to train the different morphological features jointly, through sharing the parameters of the hidden layers in the BiLSTM network. The input is also shared, through the vj vector. The output of the network is then fed to a separate non-linearity functi"
2020.acl-main.736,N18-1087,1,0.849162,"ialectal Arabic, which aims to provide a conventionalized orthography across the various Arabic dialects. We use CODA as the reference for the normalization task. 2.2 Morphological Tagging Arabic morphological tagging and disambiguation have been studied extensively in literature, with contributions for MSA (Khalifa et al., 2016; Abdelali et al., 2016; Habash and Rambow, 2005; Diab et al., 2004), and DA (Habash et al., 2013; Al-Sabbagh and Girju, 2012; Duh and Kirchhoff, 2005). There are also several recent contributions that showed significant accuracy improvement using deep learning models (Zalmout et al., 2018; Inoue et al., 2017; Zalmout and Habash, 2017; Heigold et al., 2016). In addition to other deep learning contributions that showed limited success for Arabic (Shen et al., 2016). Most of these contributions model the different morphological features separately, or focus on a limited feature subset. We elaborate on the contributions with some joint modeling aspects later in the section. 2.3 Diacritization and Lemmatization • Non-lexicalized features: aspect (asp), case (cas), gender (gen), person (per), part-ofDiacritization and lemmatization are very useful for tasks like information retrieva"
2020.acl-main.736,D17-1073,1,0.488613,"onventionalized orthography across the various Arabic dialects. We use CODA as the reference for the normalization task. 2.2 Morphological Tagging Arabic morphological tagging and disambiguation have been studied extensively in literature, with contributions for MSA (Khalifa et al., 2016; Abdelali et al., 2016; Habash and Rambow, 2005; Diab et al., 2004), and DA (Habash et al., 2013; Al-Sabbagh and Girju, 2012; Duh and Kirchhoff, 2005). There are also several recent contributions that showed significant accuracy improvement using deep learning models (Zalmout et al., 2018; Inoue et al., 2017; Zalmout and Habash, 2017; Heigold et al., 2016). In addition to other deep learning contributions that showed limited success for Arabic (Shen et al., 2016). Most of these contributions model the different morphological features separately, or focus on a limited feature subset. We elaborate on the contributions with some joint modeling aspects later in the section. 2.3 Diacritization and Lemmatization • Non-lexicalized features: aspect (asp), case (cas), gender (gen), person (per), part-ofDiacritization and lemmatization are very useful for tasks like information retrieval, machine translation, and text-to-speech, am"
2020.acl-main.736,P19-1173,1,0.696354,"h and Rambow, 2007). MADAMIRA (Pasha et al., 2014) is a popular system for Arabic morphological tagging and disambiguation. It uses SVMs for the different nonlexicalized features, and n-gram language models for the lemmas and diacritized forms. Zalmout and Habash (2017) presented a neural extension of this model, with LSTM taggers for the individual features, and neural language models for the lexicalized features. Inoue et al. (2017) used multi-task learning for fine-grained POS tagging, modeling the different morphological features jointly, but they do not model lemmas or diacritized forms. Zalmout and Habash (2019) also used multitask learning for the different non-lexicalized morphological features, and neural language models for lemmas and diacritized forms. This model currently provides state-of-the-art results for Arabic. In the models that rely on morphological analyzers (Zalmout and Habash, 2019, 2017; Pasha et al., 2014) surface form normalization are byproducts of selecting the correct analysis, rather than being explicitly modeled. 3 Approach Non-lexicalized features are usually modeled on the word level, whereas lexicalized features are better handled through character level models. Moreover,"
2020.acl-main.736,P06-1073,0,0.200964,"0 2 verb 0 0 0 0 2 verb 0 0 0 0 1 noun 0 0 0 0 na noun 0 0 li (prep) 0 na noun 0 0 li (prep) 0 na Asp p p p p na na na Vox Mod Gen Num Stt a i f s na a i m s na a i f s na a i m s na na na f s c na na m s i na na m s i Cas na na na na n g g Enc0 dobj3mp dobj3mp dobj3mp dobj3mp poss3mp 0 0 Table 1: A subset of all the possible analyses for the word ÑîDÖ Ï lmthm. Notice that in the last two analyses the words are disambiguated through the lemmas and diacritized forms only, and they share all the other features. Diacritization has generally been an active area of research (Darwish et al., 2017; Zitouni et al., 2006; Nelken and Shieber, 2005). More recent contributions use Deep Learning models in different configurations; Belinkov and Glass (2015) model diacritization as a classification task, using Long Short Term Memory (LSTM) cells. And Abandah et al. (2015) use LSTMs to model diacritization as a sequence transcription task, similar to Mubarak et al. (2019) who model diacritization as a sequence-to-sequence task. Early contributions for lemmatization used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which had a limited capacity for modeling unseen words or lemmas. There were also"
2020.coling-demos.11,2020.lrec-1.373,1,0.896683,"variety of its dialects. As such, there is a great need to have user-friendly interfaces for searching on Arabic words and their relations targeting Arabic teachers and learners. However, a small minority of dictionaries in general (and none in Arabic to our knowledge) specify the readability level of their words, let alone their lexical relations with other words. The system we present in this paper exploits a number of developments in Arabic natural language processing (NLP) by different groups of researchers (Black et al., 2006; Graff et al., 2009; Taji et al., 2018; Obeid et al., 2020; Al Khalil et al., 2020) to develop a new online thesaurus that (a) supports different search modes (inflected word, lemma, root and English gloss), (b) provides five types of lexical relations (synonyms, antonyms, hypernyms, hyponyms and related), and (c) indicates the readability level of the word on a five-scale system. This interface allows Arabic speakers and learners to benefit from advances in Arabic NLP technologies. And by exposing these technologies to a large number of users, we expect their feedback will help the researchers who developed the computational and lexical components to identify gaps and error"
2020.coling-demos.11,elkateb-etal-2006-building,0,0.0868538,"mbedded its morphological analyser, CALIMA Star (Taji et al., 2018), in our online system to determine all the lemmas associated with a user’s input in word mode. CALIMA Star extends the Standard Arabic Morphological Analyzer (SAMA) (Graff et al., 2009) with a number of additional morphological features. The database covers over 40 thousand lemmas and links each to a part-of-speech (POS), root and English gloss, all of which can be searched on in our interface. Lexical Modeling with Arabic WordNet Arabic WordNet (AWN) is a public lexical database of semantic relations between words in Arabic (ElKateb et al., 2006; Black et al., 2006). AWN was developed based on the methods used in EuroWordNet (EWN) (Rodríguez et al., 1998), and is directly mappable to it and to the Princeton Wordnet of English (Fellbaum, 1998). The AWN database currently has 16,066 entries, out of which 5,036 are multi-word phrases. Basic entries are represented as lemmas abstracted from morphological inflections. The AWN entries are organized in 14,284 synonym sets (synsets), some of which are connected through lexical relations such as antonymy, hypernymmy, and others. The AWN is the Thesaurus backbone of our system. We focus on fiv"
2020.coling-demos.11,pasha-etal-2014-madamira,1,0.835124,"Missing"
2020.coling-demos.11,W18-5816,1,0.930983,"m spoken by modern-day Arabs, who speak a variety of its dialects. As such, there is a great need to have user-friendly interfaces for searching on Arabic words and their relations targeting Arabic teachers and learners. However, a small minority of dictionaries in general (and none in Arabic to our knowledge) specify the readability level of their words, let alone their lexical relations with other words. The system we present in this paper exploits a number of developments in Arabic natural language processing (NLP) by different groups of researchers (Black et al., 2006; Graff et al., 2009; Taji et al., 2018; Obeid et al., 2020; Al Khalil et al., 2020) to develop a new online thesaurus that (a) supports different search modes (inflected word, lemma, root and English gloss), (b) provides five types of lexical relations (synonyms, antonyms, hypernyms, hyponyms and related), and (c) indicates the readability level of the word on a five-scale system. This interface allows Arabic speakers and learners to benefit from advances in Arabic NLP technologies. And by exposing these technologies to a large number of users, we expect their feedback will help the researchers who developed the computational and"
2020.coling-main.225,N16-1127,1,0.752843,"Missing"
2020.coling-main.225,C96-1058,0,0.0527063,"s in representation, we hypothesize that parsing the two treebank formalism along side each other will help improve both parsing outcomes. 3 Model We briefly describe the single task Easy-First (EF) parsing algorithm Kiperwasser and Goldberg (2016) and its components, then we discuss the multitask extension (MEF) inspired by (Constant et al., 2016) adapted to the tree-structured LSTM in terms of the updated parsing algorithm and its components. 3.1 Single-task Model The EF parsing model builds dependency trees bottom-up. Intuitively, it can be seen as a greedy version of the Eisner algorithm (Eisner, 1996) where each span contains at most one subtree and where each subtree, once created, is fixed and must be a part of the final structure. The algorithm maintains a sequence of pending subtrees. Two adjacent subtrees in the sequence may combine, by adding an arc from the root of one subtree to the other, and be replaced by a new (bigger) subtree. Since there are few subtrees to consider — at most n + 1 pending subtrees for a sentence of n words — the context of each decision, ie each arc creation between subtrees, can depend on the whole subtrees involved provided they can be encoded with a fixed"
2020.coling-main.225,Q13-1033,0,0.0220107,"main contributor is not the sharing of lexical information, as is commonly done in multitask systems, but the sharing of partial dependency trees given as input for arc weight prediction. Future work will explore further sharing between parsers. In particular, we expect tree encoders could benefit from the additional information (although redundancy with tree sharing in the score function 2505 could hurt the system). We also plan to work on model improvements to address the limitation arising from added dimensions. For instance, with the addition of the second dimension, the notion of oracle (Goldberg and Nivre, 2013) used for training becomes more fragile, since the number of correct actions grows, and the order in which to perform them is unknown and can have some long term consequences on the action in the other dimension. It would be interesting to explore how reinforcement learning, where the notion of planning ahead is crucial, could help. Acknowledgements This work is partially supported by a public grant overseen by the French National Research Agency (ANR) as part of the program Investissements d’Avenir (reference: ANR-10-LABX-0083). It contributes to the IdEx Université de Paris - ANR-18-IDEX-000"
2020.coling-main.225,P09-2056,1,0.867584,"ntroduction Dependency parsing is the task of assigning a syntactic structure to a sentence by linking its words with binary asymmetrical typed relations. In addition to syntactic information, dependency representations encode some semantic aspects of the sentence which make them important to downstream applications including sentiment analysis (Tai et al., 2015) and information extraction (Miwa and Bansal, 2016). In this paper we are interested in Arabic dependency parsing for which two formalisms have been developed (See §2). The first is the Columbia Arabic Treebank (CATiB) representation (Habash and Roth, 2009), which is inspired by Arabic traditional grammar and which focus on modeling syntactic and morpho-syntactic agreement and case assignment. The second is the Universal Dependency (UD) representation (Taji et al., 2017), which has relatively more focus on semantic/thematic relations, and which is coordinated in design with a number of other languages (Nivre et al., 2017). While previous work on Arabic dependency parsing (Marton et al., 2013; Taji et al., 2017) tackled these formalisms separately, we argue that they stand to benefit from multitask learning (MTL) (Caruana, 1993). MTL allows for m"
2020.coling-main.225,D17-1206,0,0.0202368,"sentences using parallel treebanks. Deep neural networks are particularly suited for multitask scenarios via straightforward parameter and representation sharing. Some hidden layers can be shared across all tasks while output layers are kept separate. In fact, most deep learning architectures for language processing start with sequential encoding components such as BiLSTMs or Transformer layers which can be readily shared across multiple tasks. This approach is widely applicable even to tasks that use very different formalisms and do not have parallel annotations (Søgaard and Goldberg, 2016; Hashimoto et al., 2017). This type of sharing has also been shown to benefit (semantic and syntactic) dependency parsing, both transition-based (Stymne et al., 2018; Kurita and Søgaard, 2019) and graph-based (Sato et al., 2017; Lindemann et al., 2019). In addition to simple parameter sharing, joint inference across multiple tasks has been shown to be beneficial. Peng et al. (2017) perform decoding jointly across multiple semantic dependency formalisms with cross-task This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 24"
2020.coling-main.225,P18-1035,0,0.0195942,"s which makes it computationally expensive. On the same task, Kurita and Søgaard (2019) describe a model that shares a representation of the complete partial parse forest of one dimension while taking decisions on the other. This is similar in spirit to our sharing of parameters and representations. Furthermore, they show that their transition-based parser effectively learns easy-first strategies with policy gradient based reinforcement learning. This motivates further our choice of parsing framework. In fact, several other multitask systems for semantic dependency parsing have been proposed (Hershcovich et al., 2018; Stanovsky and Dagan, 2018; Peng et al., 2018; Lindemann et al., 2019; Prange et al., 2019) but none of them build on the easy-first framework nor target the Arabic language. Along the lines of multitask easy-first parsers, Constant et al. (2016) introduced a joint model for learning from multiple treebanks simultaneously. They show that syntactic dependency representations and tree-based representations of multiword expressions can help each other. However, they do not use a neural architecture and perform experiments only on English and French. When no parallel annotations on the same text"
2020.coling-main.225,Q16-1032,0,0.172354,"tive Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 2497 Proceedings of the 28th International Conference on Computational Linguistics, pages 2497–2508 Barcelona, Spain (Online), December 8-13, 2020 factors that score combinations of substructures from each (Peng et al., 2017). Joint inference however comes with increased computational cost. To address this issue, we introduce a multitask learning model for dependency parsing (§3.2). This model is based on greedy arc selection similar to the neural easy-first approach proposed in (Kiperwasser and Goldberg, 2016) (§3). We use tree-structured LSTMs to encode substructures (partial trees) in each formalism which are then concatenated across tasks and scored jointly. Hence, we model interactions between substructures across tasks while keeping computational complexity low thanks to the easy-first framework. Furthermore, this approach enables the sharing of various components between tasks, a richer sharing than the mere sequential encoder sharing found in most multitask systems (Kurita and Søgaard, 2019). Our multitask architecture outperforms the single-task parser on both formalisms (§4.3). The parser"
2020.coling-main.225,P19-1232,0,0.201716,"me hidden layers can be shared across all tasks while output layers are kept separate. In fact, most deep learning architectures for language processing start with sequential encoding components such as BiLSTMs or Transformer layers which can be readily shared across multiple tasks. This approach is widely applicable even to tasks that use very different formalisms and do not have parallel annotations (Søgaard and Goldberg, 2016; Hashimoto et al., 2017). This type of sharing has also been shown to benefit (semantic and syntactic) dependency parsing, both transition-based (Stymne et al., 2018; Kurita and Søgaard, 2019) and graph-based (Sato et al., 2017; Lindemann et al., 2019). In addition to simple parameter sharing, joint inference across multiple tasks has been shown to be beneficial. Peng et al. (2017) perform decoding jointly across multiple semantic dependency formalisms with cross-task This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 2497 Proceedings of the 28th International Conference on Computational Linguistics, pages 2497–2508 Barcelona, Spain (Online), December 8-13, 2020 factors that score comb"
2020.coling-main.225,P19-1450,0,0.0851213,"ayers are kept separate. In fact, most deep learning architectures for language processing start with sequential encoding components such as BiLSTMs or Transformer layers which can be readily shared across multiple tasks. This approach is widely applicable even to tasks that use very different formalisms and do not have parallel annotations (Søgaard and Goldberg, 2016; Hashimoto et al., 2017). This type of sharing has also been shown to benefit (semantic and syntactic) dependency parsing, both transition-based (Stymne et al., 2018; Kurita and Søgaard, 2019) and graph-based (Sato et al., 2017; Lindemann et al., 2019). In addition to simple parameter sharing, joint inference across multiple tasks has been shown to be beneficial. Peng et al. (2017) perform decoding jointly across multiple semantic dependency formalisms with cross-task This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 2497 Proceedings of the 28th International Conference on Computational Linguistics, pages 2497–2508 Barcelona, Spain (Online), December 8-13, 2020 factors that score combinations of substructures from each (Peng et al., 2017). Joi"
2020.coling-main.225,J13-1008,1,0.803312,"ted in Arabic dependency parsing for which two formalisms have been developed (See §2). The first is the Columbia Arabic Treebank (CATiB) representation (Habash and Roth, 2009), which is inspired by Arabic traditional grammar and which focus on modeling syntactic and morpho-syntactic agreement and case assignment. The second is the Universal Dependency (UD) representation (Taji et al., 2017), which has relatively more focus on semantic/thematic relations, and which is coordinated in design with a number of other languages (Nivre et al., 2017). While previous work on Arabic dependency parsing (Marton et al., 2013; Taji et al., 2017) tackled these formalisms separately, we argue that they stand to benefit from multitask learning (MTL) (Caruana, 1993). MTL allows for more training data to be exploited while benefiting from the structural or statistical similarities between the tasks. We therefore propose to learn CATiB and UD dependency trees jointly on the same input sentences using parallel treebanks. Deep neural networks are particularly suited for multitask scenarios via straightforward parameter and representation sharing. Some hidden layers can be shared across all tasks while output layers are ke"
2020.coling-main.225,P16-1105,0,0.0280411,"tion tests show that the main contribution of this reduction is given by sharing tree representation between tasks, and not simply sharing BiLSTM layers as is usually performed in NLP multitask systems. 1 Introduction Dependency parsing is the task of assigning a syntactic structure to a sentence by linking its words with binary asymmetrical typed relations. In addition to syntactic information, dependency representations encode some semantic aspects of the sentence which make them important to downstream applications including sentiment analysis (Tai et al., 2015) and information extraction (Miwa and Bansal, 2016). In this paper we are interested in Arabic dependency parsing for which two formalisms have been developed (See §2). The first is the Columbia Arabic Treebank (CATiB) representation (Habash and Roth, 2009), which is inspired by Arabic traditional grammar and which focus on modeling syntactic and morpho-syntactic agreement and case assignment. The second is the Universal Dependency (UD) representation (Taji et al., 2017), which has relatively more focus on semantic/thematic relations, and which is coordinated in design with a number of other languages (Nivre et al., 2017). While previous work"
2020.coling-main.225,nivre-etal-2006-maltparser,0,0.113115,"mponents. We found that for CATiB, the LAS score of the best system decreased on the 2504 DEV set from 86.66 to 86.41 in the pipeline setup CATiB → UD, and to 86.37 in UD → CATiB. For UD, the score decreased from 85.17 to 85.06 in pipeline CATiB → UD and to 85.00 in UD → CATiB. 5 Related Work Arabic Syntactic Dependency Parsing Earlier work on syntactic dependency parsing for Arabic had focused mainly on CATiB representation. Marton et al. (2013) explored the use several morpho-syntactic features in the easy-first framework, while Shahrour et al. (2015; Shahrour et al. (2016) used MaltParser (Nivre et al., 2006). Taji et al. (2017) presented the UD treebank more recently and conducted experiments on CATiB and UD separately in a single-task settings. Multitask systems that have been developed for Arabic were part of efforts to build one multilingual system for all UD dependencies. We present the first effort on multitask joint parsing for multiple Arabic formalisms. Multitask Dependency Parsing Research towards using multitask deep learning settings to resolve NLP tasks has been an active ongoing subject since the early work of Collobert and Weston (2008) where a single model is trained to perform mul"
2020.coling-main.225,S15-2153,0,0.0940977,"Missing"
2020.coling-main.225,P17-1186,0,0.29345,"as BiLSTMs or Transformer layers which can be readily shared across multiple tasks. This approach is widely applicable even to tasks that use very different formalisms and do not have parallel annotations (Søgaard and Goldberg, 2016; Hashimoto et al., 2017). This type of sharing has also been shown to benefit (semantic and syntactic) dependency parsing, both transition-based (Stymne et al., 2018; Kurita and Søgaard, 2019) and graph-based (Sato et al., 2017; Lindemann et al., 2019). In addition to simple parameter sharing, joint inference across multiple tasks has been shown to be beneficial. Peng et al. (2017) perform decoding jointly across multiple semantic dependency formalisms with cross-task This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 2497 Proceedings of the 28th International Conference on Computational Linguistics, pages 2497–2508 Barcelona, Spain (Online), December 8-13, 2020 factors that score combinations of substructures from each (Peng et al., 2017). Joint inference however comes with increased computational cost. To address this issue, we introduce a multitask learning model for dep"
2020.coling-main.225,N18-1135,0,0.0179694,"me task, Kurita and Søgaard (2019) describe a model that shares a representation of the complete partial parse forest of one dimension while taking decisions on the other. This is similar in spirit to our sharing of parameters and representations. Furthermore, they show that their transition-based parser effectively learns easy-first strategies with policy gradient based reinforcement learning. This motivates further our choice of parsing framework. In fact, several other multitask systems for semantic dependency parsing have been proposed (Hershcovich et al., 2018; Stanovsky and Dagan, 2018; Peng et al., 2018; Lindemann et al., 2019; Prange et al., 2019) but none of them build on the easy-first framework nor target the Arabic language. Along the lines of multitask easy-first parsers, Constant et al. (2016) introduced a joint model for learning from multiple treebanks simultaneously. They show that syntactic dependency representations and tree-based representations of multiword expressions can help each other. However, they do not use a neural architecture and perform experiments only on English and French. When no parallel annotations on the same text are available, it has been shown that a single"
2020.coling-main.225,K19-1017,0,0.0212216,"a model that shares a representation of the complete partial parse forest of one dimension while taking decisions on the other. This is similar in spirit to our sharing of parameters and representations. Furthermore, they show that their transition-based parser effectively learns easy-first strategies with policy gradient based reinforcement learning. This motivates further our choice of parsing framework. In fact, several other multitask systems for semantic dependency parsing have been proposed (Hershcovich et al., 2018; Stanovsky and Dagan, 2018; Peng et al., 2018; Lindemann et al., 2019; Prange et al., 2019) but none of them build on the easy-first framework nor target the Arabic language. Along the lines of multitask easy-first parsers, Constant et al. (2016) introduced a joint model for learning from multiple treebanks simultaneously. They show that syntactic dependency representations and tree-based representations of multiword expressions can help each other. However, they do not use a neural architecture and perform experiments only on English and French. When no parallel annotations on the same text are available, it has been shown that a single model can be trained to perform multiple task"
2020.coling-main.225,K17-3007,0,0.133901,"asks while output layers are kept separate. In fact, most deep learning architectures for language processing start with sequential encoding components such as BiLSTMs or Transformer layers which can be readily shared across multiple tasks. This approach is widely applicable even to tasks that use very different formalisms and do not have parallel annotations (Søgaard and Goldberg, 2016; Hashimoto et al., 2017). This type of sharing has also been shown to benefit (semantic and syntactic) dependency parsing, both transition-based (Stymne et al., 2018; Kurita and Søgaard, 2019) and graph-based (Sato et al., 2017; Lindemann et al., 2019). In addition to simple parameter sharing, joint inference across multiple tasks has been shown to be beneficial. Peng et al. (2017) perform decoding jointly across multiple semantic dependency formalisms with cross-task This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 2497 Proceedings of the 28th International Conference on Computational Linguistics, pages 2497–2508 Barcelona, Spain (Online), December 8-13, 2020 factors that score combinations of substructures from each"
2020.coling-main.225,D15-1152,1,0.899631,"Missing"
2020.coling-main.225,C16-2048,1,0.90366,"Missing"
2020.coling-main.225,P16-2038,0,0.0675848,"es jointly on the same input sentences using parallel treebanks. Deep neural networks are particularly suited for multitask scenarios via straightforward parameter and representation sharing. Some hidden layers can be shared across all tasks while output layers are kept separate. In fact, most deep learning architectures for language processing start with sequential encoding components such as BiLSTMs or Transformer layers which can be readily shared across multiple tasks. This approach is widely applicable even to tasks that use very different formalisms and do not have parallel annotations (Søgaard and Goldberg, 2016; Hashimoto et al., 2017). This type of sharing has also been shown to benefit (semantic and syntactic) dependency parsing, both transition-based (Stymne et al., 2018; Kurita and Søgaard, 2019) and graph-based (Sato et al., 2017; Lindemann et al., 2019). In addition to simple parameter sharing, joint inference across multiple tasks has been shown to be beneficial. Peng et al. (2017) perform decoding jointly across multiple semantic dependency formalisms with cross-task This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. Li"
2020.coling-main.225,D18-1263,0,0.0169475,"onally expensive. On the same task, Kurita and Søgaard (2019) describe a model that shares a representation of the complete partial parse forest of one dimension while taking decisions on the other. This is similar in spirit to our sharing of parameters and representations. Furthermore, they show that their transition-based parser effectively learns easy-first strategies with policy gradient based reinforcement learning. This motivates further our choice of parsing framework. In fact, several other multitask systems for semantic dependency parsing have been proposed (Hershcovich et al., 2018; Stanovsky and Dagan, 2018; Peng et al., 2018; Lindemann et al., 2019; Prange et al., 2019) but none of them build on the easy-first framework nor target the Arabic language. Along the lines of multitask easy-first parsers, Constant et al. (2016) introduced a joint model for learning from multiple treebanks simultaneously. They show that syntactic dependency representations and tree-based representations of multiword expressions can help each other. However, they do not use a neural architecture and perform experiments only on English and French. When no parallel annotations on the same text are available, it has been"
2020.coling-main.225,P18-2098,0,0.241027,"Missing"
2020.coling-main.225,P15-1150,0,0.0534435,"D compared to a single-task baseline, and ablation tests show that the main contribution of this reduction is given by sharing tree representation between tasks, and not simply sharing BiLSTM layers as is usually performed in NLP multitask systems. 1 Introduction Dependency parsing is the task of assigning a syntactic structure to a sentence by linking its words with binary asymmetrical typed relations. In addition to syntactic information, dependency representations encode some semantic aspects of the sentence which make them important to downstream applications including sentiment analysis (Tai et al., 2015) and information extraction (Miwa and Bansal, 2016). In this paper we are interested in Arabic dependency parsing for which two formalisms have been developed (See §2). The first is the Columbia Arabic Treebank (CATiB) representation (Habash and Roth, 2009), which is inspired by Arabic traditional grammar and which focus on modeling syntactic and morpho-syntactic agreement and case assignment. The second is the Universal Dependency (UD) representation (Taji et al., 2017), which has relatively more focus on semantic/thematic relations, and which is coordinated in design with a number of other l"
2020.coling-main.225,W17-1320,1,0.93229,"code some semantic aspects of the sentence which make them important to downstream applications including sentiment analysis (Tai et al., 2015) and information extraction (Miwa and Bansal, 2016). In this paper we are interested in Arabic dependency parsing for which two formalisms have been developed (See §2). The first is the Columbia Arabic Treebank (CATiB) representation (Habash and Roth, 2009), which is inspired by Arabic traditional grammar and which focus on modeling syntactic and morpho-syntactic agreement and case assignment. The second is the Universal Dependency (UD) representation (Taji et al., 2017), which has relatively more focus on semantic/thematic relations, and which is coordinated in design with a number of other languages (Nivre et al., 2017). While previous work on Arabic dependency parsing (Marton et al., 2013; Taji et al., 2017) tackled these formalisms separately, we argue that they stand to benefit from multitask learning (MTL) (Caruana, 1993). MTL allows for more training data to be exploited while benefiting from the structural or statistical similarities between the tasks. We therefore propose to learn CATiB and UD dependency trees jointly on the same input sentences usin"
2020.coling-main.412,N18-1126,0,0.0715909,"tirely on the morphological analyzer, and would usually involve other tasks that might help the disambiguation pipeline (like POS tagging). Other data-driven models approach lemmatization as a classification task (Müller et al., 2015; Chrupala et al., 2008), through obtaining the set of edit operations that transform words into lemmas, and then learning to select the optimal lemma from a set of candidates. These candidates are generated by applying all possible edit-trees learned from the training data. There were also several lemmatization contributions utilizing sequence-to-sequence models (Bergmanis and Goldwater, 2018; Pütz et al., 2018), which consider lemmatization as a generation task. Several other contributions use additional morphosyntactic features as part of the modeling architecture (Kanerva et al., 2019; Kondratyuk et al., 2018). As far as we are aware, no other contributions explicitly utilize other word-level features, like embeddings, stems, or orthographic patterns, in lemmatization. 3 Approach Greedy vs Gold Stems The stem is the form of the word after all inflectional affixes are removed from the surface form. The surface form can be represented as (prefix+stem+suffix), so stemming removes"
2020.coling-main.412,C10-3009,0,0.0138699,"e 1: Examples highlighting the complexity of lemmatization in MSA. Examples 1a-c highlight cases where greedy features, albeit different from their gold values, can consistently help across words. Examples 2a-b are ambiguous cases but with identical gold and greedy features; while, in examples 3a-b, greedy features are inconsistent with gold features and the disambiguation task is more involved. 2 Related Work Lemmatization has been shown to be very useful in several NLP tasks, including machine translation (Sennrich and Haddow, 2016; Fraser et al., 2012) and parsing (Dozat and Manning, 2018; Björkelund et al., 2010; Seddah et al., 2010), among others. Early contributions used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which could not handle unseen words and had limited in-context modeling capacity. Other contributions approached lemmatization as a lemma-selection task (Roth et al., 2008; Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. These systems handled in-context analysis better, but had a limited capability of modeling unseen words. To handle unseen words, these models rely entirely on the morpholo"
2020.coling-main.412,Q17-1010,0,0.110061,"Missing"
2020.coling-main.412,chrupala-etal-2008-learning,0,0.109474,"Missing"
2020.coling-main.412,P18-2077,0,0.0162907,"+_A_+y bb k+_A_+y bb Table 1: Examples highlighting the complexity of lemmatization in MSA. Examples 1a-c highlight cases where greedy features, albeit different from their gold values, can consistently help across words. Examples 2a-b are ambiguous cases but with identical gold and greedy features; while, in examples 3a-b, greedy features are inconsistent with gold features and the disambiguation task is more involved. 2 Related Work Lemmatization has been shown to be very useful in several NLP tasks, including machine translation (Sennrich and Haddow, 2016; Fraser et al., 2012) and parsing (Dozat and Manning, 2018; Björkelund et al., 2010; Seddah et al., 2010), among others. Early contributions used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which could not handle unseen words and had limited in-context modeling capacity. Other contributions approached lemmatization as a lemma-selection task (Roth et al., 2008; Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. These systems handled in-context analysis better, but had a limited capability of modeling unseen words. To handle unseen words, these models rely"
2020.coling-main.412,D13-1105,1,0.870968,"Missing"
2020.coling-main.412,P98-1062,0,0.12695,"nsistent with gold features and the disambiguation task is more involved. 2 Related Work Lemmatization has been shown to be very useful in several NLP tasks, including machine translation (Sennrich and Haddow, 2016; Fraser et al., 2012) and parsing (Dozat and Manning, 2018; Björkelund et al., 2010; Seddah et al., 2010), among others. Early contributions used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which could not handle unseen words and had limited in-context modeling capacity. Other contributions approached lemmatization as a lemma-selection task (Roth et al., 2008; Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. These systems handled in-context analysis better, but had a limited capability of modeling unseen words. To handle unseen words, these models rely entirely on the morphological analyzer, and would usually involve other tasks that might help the disambiguation pipeline (like POS tagging). Other data-driven models approach lemmatization as a classification task (Müller et al., 2015; Chrupala et al., 2008), through obtaining the set of edit operations that transform words into lemmas, and th"
2020.coling-main.412,E12-1068,0,0.0248073,"w_+ sf Al+__A_+ ktb Al+__A_+ ktb k+_A_+y bb k+_A_+y bb Table 1: Examples highlighting the complexity of lemmatization in MSA. Examples 1a-c highlight cases where greedy features, albeit different from their gold values, can consistently help across words. Examples 2a-b are ambiguous cases but with identical gold and greedy features; while, in examples 3a-b, greedy features are inconsistent with gold features and the disambiguation task is more involved. 2 Related Work Lemmatization has been shown to be very useful in several NLP tasks, including machine translation (Sennrich and Haddow, 2016; Fraser et al., 2012) and parsing (Dozat and Manning, 2018; Björkelund et al., 2010; Seddah et al., 2010), among others. Early contributions used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which could not handle unseen words and had limited in-context modeling capacity. Other contributions approached lemmatization as a lemma-selection task (Roth et al., 2008; Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. These systems handled in-context analysis better, but had a limited capability of modeling unseen words. To h"
2020.coling-main.412,D18-1532,0,0.0330122,"Missing"
2020.coling-main.412,D15-1166,0,0.0468024,"hitecture We use a similar architecture to Lematus (Bergmanis and Goldwater, 2018) as a baseline. The model is based on a context-aware character-level sequence-to-sequence architecture, where context is modeled through a sliding window around the target word. Lematus uses a fixed 20-character window for each side. However, our experiments show that respecting the word-boundaries, by looking at the characters of the n words before and after the target word, provides better results. We use two LSTM layers for both the encoder and decoder (bidirectional for the encoder). We use Luong attention (Luong et al., 2015) over the encoder outputs hi , and use the last encoder output as the initial state for the decoder. Conditioning on the Subwords at the Encoder We condition on the different subwords through concatenating their embedding vector with the input character embeddings. Each character embedding ci is replaced by the concatenation [ci ; wj ] before being fed to the encoder, where wj is the subword embedding for the word in which character i appears in. These features are incorporated at training time and runtime, and do not rely on expensive gold data. This is why we use the greedy stems, patterns,"
2020.coling-main.412,D15-1272,0,0.0189323,"modeling capacity. Other contributions approached lemmatization as a lemma-selection task (Roth et al., 2008; Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. These systems handled in-context analysis better, but had a limited capability of modeling unseen words. To handle unseen words, these models rely entirely on the morphological analyzer, and would usually involve other tasks that might help the disambiguation pipeline (like POS tagging). Other data-driven models approach lemmatization as a classification task (Müller et al., 2015; Chrupala et al., 2008), through obtaining the set of edit operations that transform words into lemmas, and then learning to select the optimal lemma from a set of candidates. These candidates are generated by applying all possible edit-trees learned from the training data. There were also several lemmatization contributions utilizing sequence-to-sequence models (Bergmanis and Goldwater, 2018; Pütz et al., 2018), which consider lemmatization as a generation task. Several other contributions use additional morphosyntactic features as part of the modeling architecture (Kanerva et al., 2019; Kon"
2020.coling-main.412,pasha-etal-2014-madamira,1,0.762529,"Missing"
2020.coling-main.412,P08-2030,1,0.483554,"y features are inconsistent with gold features and the disambiguation task is more involved. 2 Related Work Lemmatization has been shown to be very useful in several NLP tasks, including machine translation (Sennrich and Haddow, 2016; Fraser et al., 2012) and parsing (Dozat and Manning, 2018; Björkelund et al., 2010; Seddah et al., 2010), among others. Early contributions used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which could not handle unseen words and had limited in-context modeling capacity. Other contributions approached lemmatization as a lemma-selection task (Roth et al., 2008; Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. These systems handled in-context analysis better, but had a limited capability of modeling unseen words. To handle unseen words, these models rely entirely on the morphological analyzer, and would usually involve other tasks that might help the disambiguation pipeline (like POS tagging). Other data-driven models approach lemmatization as a classification task (Müller et al., 2015; Chrupala et al., 2008), through obtaining the set of edit operations that transform wor"
2020.coling-main.412,schmid-etal-2004-smor,0,0.0103402,"features, albeit different from their gold values, can consistently help across words. Examples 2a-b are ambiguous cases but with identical gold and greedy features; while, in examples 3a-b, greedy features are inconsistent with gold features and the disambiguation task is more involved. 2 Related Work Lemmatization has been shown to be very useful in several NLP tasks, including machine translation (Sennrich and Haddow, 2016; Fraser et al., 2012) and parsing (Dozat and Manning, 2018; Björkelund et al., 2010; Seddah et al., 2010), among others. Early contributions used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which could not handle unseen words and had limited in-context modeling capacity. Other contributions approached lemmatization as a lemma-selection task (Roth et al., 2008; Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. These systems handled in-context analysis better, but had a limited capability of modeling unseen words. To handle unseen words, these models rely entirely on the morphological analyzer, and would usually involve other tasks that might help the disambiguation pipeline (like P"
2020.coling-main.412,W10-1410,0,0.0766024,"Missing"
2020.coling-main.412,W16-2209,0,0.0262137,"_yw_+ bt Al+_yw_+ bt wll+_yw_+ sf Al+__A_+ ktb Al+__A_+ ktb k+_A_+y bb k+_A_+y bb Table 1: Examples highlighting the complexity of lemmatization in MSA. Examples 1a-c highlight cases where greedy features, albeit different from their gold values, can consistently help across words. Examples 2a-b are ambiguous cases but with identical gold and greedy features; while, in examples 3a-b, greedy features are inconsistent with gold features and the disambiguation task is more involved. 2 Related Work Lemmatization has been shown to be very useful in several NLP tasks, including machine translation (Sennrich and Haddow, 2016; Fraser et al., 2012) and parsing (Dozat and Manning, 2018; Björkelund et al., 2010; Seddah et al., 2010), among others. Early contributions used finite state machines (Schmid et al., 2004; Minnen et al., 2001), which could not handle unseen words and had limited in-context modeling capacity. Other contributions approached lemmatization as a lemma-selection task (Roth et al., 2008; Ezeiza et al., 1998), where the goal is to select the correct lemma from a set of lemmas provided by a morphological analyzer. These systems handled in-context analysis better, but had a limited capability of model"
2020.coling-main.412,D17-1073,1,0.935031,"rain the pretrained MSA embeddings, and the BOLT Arabic Forum Discussions corpus (Tracey et al., 2018) for the E GY embeddings. Baselines We use several baselines to highlight different aspects of the contributions. The first baseline is based on a simple maximum likelihood estimation (MLE) approach. We use the training data to identify the most common lemma for each surface form without considering the context, and use this word-lemma mapping for inference. At inference time we return the mapped lemma if the word is seen in the training 4678 Model Maximum Likelihood Estimation (MLE) LSTM LM (Zalmout and Habash, 2017) Seq2seq+attention Limited context seq2seq+attention* (baseline) + Morfessor base words + Greedy roots + Greedy stems + Greedy patterns + Pretrained n-grams (FastText) + Pretrained Morfessor base words + Pretrained greedy roots + Pretrained greedy stems + Pretrained greedy patterns + Multitask learning with predicted roots + Multitask learning with predicted stems + Multitask learning with predicted patterns Gold Stems (oracle) MSA 90.6 92.5 93.5 94.1 95.0 95.1 95.1 94.5 95.4 95.2 95.3 95.4 94.9 95.0 94.5 94.0 95.6 E GY 77.5 82.8 76.6 81.8 82.0 82.2 81.9 80.8 83.3 82.4 82.6 82.8 81.8 81.9 81.5"
2020.coling-main.412,P19-1173,1,0.891037,"Missing"
2020.gebnlp-1.12,P17-1183,0,0.0187964,"c parallel gender corpus has many of such spelling confusions. 4 Joint Gender Reinflection Model In this section, we discuss the motivation behind our model architecture as well as the integration of the linguistic features. We also describe the training settings and the model’s hyperparameters for reproducibility. 4.1 Motivation Sequence-to-sequence models have achieved significant results in grammatical error correction (GEC) (Chollampatt and Ng, 2018; Junczys-Dowmunt et al., 2018; Grundkiewicz et al., 2019) and morphological reinflection tasks (Faruqui et al., 2016; Kann and Schütze, 2016; Aharoni and Goldberg, 2017). Many of these problems are modeled on the word-level, however, such models usually require large amounts of training data to achieve good results. Character-level sequence-to-sequence models can be superior in mitigating the lack of training data and in dealing with subtle morphological reinflection. Further, pre-trained distributed word representations have also shown to be helpful if integrated properly within character-level sequence-to-sequence models (Watson et al., 2018). We formulate the gender reinflection problem as a user-aware grammatical error correction (UGEC) task at the charac"
2020.gebnlp-1.12,P11-2062,1,0.880036,"rantee that we map from feminine to masculine in every context. For example,  the noun word éÒêÓ mhm~ ‘mission/assignment’ is only feminine and has no meaningful masculine form, as opposed to the adjective  mhm~ ‘important [feminine singular]’ discussed above. éÒêÓ These facts pose major challenges to deep learning models attempting to learn from limited supervised or even large unsupervised data. In this work, we make use of morphological analyzers that indicate all the possible gender information of the words in terms of their functional (grammatical) and form-based (affixational) values (Alkuhlani and Habash, 2011). 141 Orthographic Ambiguity and Noise Arabic uses diacritics to specify short vowels and consonantal doubling. These diacritics are optional and generally unwritten, leaving readers to decipher words using  J» knt can be diacritized as kuntu ‘I contextual and templatic morphology clues. For example, the verb I was’, kunta ‘You [masculine] were’, or kunti ‘You [feminine] were’. This is a challenge for identifying the words that need to change for a first-person target gender. In addition to the issue of orthographic ambiguity, unedited MSA text is reported to be quite noisy with spelling erro"
2020.gebnlp-1.12,Q17-1010,0,0.0115858,"c Features and Word Embeddings We explore adding word-level morphological features as well as pre-trained distributed word representations to the character embeddings. We use the CALIMAStar Arabic morphological analyzer (Taji et al., 2018) to obtain word-level functional gender features (Alkuhlani and Habash, 2011).5 We represent the morphological features for word wj as a four-dimension one-hot vector µwj ∈ R4 . Each element of this one-hot vector represents whether the word wj is masculine or feminine as well as if the analysis was obtained with or without spelling backoff. We use FastText (Bojanowski et al., 2017) to learn distributed word representations and we denote the FastText word embedding for word wj as ρwj ∈ RF . Similarly to Watson et al. (2018), we added the word-level features to the character embeddings only on the encoder side. Each character embedding exi is then enriched with ρwj and µwj to create a single vector [exi ; µwj ; ρwj ] ∈ RE+4+F which we feed to the encoder, where wj is the word containing character xi . Inference At inference time, we use greedy decoding to find the most likely sequence:6 yˆ1:m = argmax P (ˆ y |x1:n , g) = argmax yˆ∈Vy yˆ∈Vy Y P (yˆt |ˆ y1:t−1 , x1:n , g) y"
2020.gebnlp-1.12,N19-3002,0,0.013635,"ude and present future work in Section 8. 2 Related Work Many NLP systems have the ability to embed and amplify societal (gender, racial, religious, etc.) biases across a variety of core tasks such as coreference resolution (Rudinger et al., 2018; Zhao et al., 2018a), machine translation (Rabinovich et al., 2017; Vanmassenhove et al., 2018; Font and Costa-jussà, 2019; Moryossef et al., 2019; Stanovsky et al., 2019; Stafanoviˇcs et al., 2020; Gonen and Webster, 2020), named entity recognition (Mehrabi et al., 2019), dialogue systems (Dinan et al., 2019), and language modeling (Lu et al., 2018; Bordia and Bowman, 2019). For the case of gender bias, various research efforts have shown that this could be caused by either human-generated training datasets (Font and Costa-jussà, 2019; Habash et al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017; Caliskan et al., 2017; Manzini et al., 2019), or language models (Kurita et al., 2019; Zhao et al., 2019). To mitigate this problem, several researchers 2 3 Arabic transliteration is in the HSB scheme (Habash et al., 2007). https://github.com/CAMeL-Lab/gender-reinflection 140 proposed approaches in which they focus mainly on debiasing wor"
2020.gebnlp-1.12,P17-1074,0,0.0126789,"on metric (Papineni et al., 2002), however, we believe that BLEU is not a suitable metric for our task due to the high similarity between the input and output sentences. We use SacreBLEU (Post, 2018) to compute the BLEU scores. Additionally, we use the MaxMatch (M2 ) scorer (Dahlmeier and Ng, 2012) to compute the word-level edits between the input and reinflected output. We report the precision, recall, and F0.5 scores calculated against the gold edits, which were also created by the M2 scorer. We are aware that there are other tools to consider for word-level edit calculation such as ERRANT (Bryant et al., 2017), but we did not use them as they require additional dependencies to work for Arabic. Input Gender Identification Our sequence-to-sequence model does not explicitly identify the gender of the input sentence; however, we consider any attempted change (or lack thereof) to the input as a signal for the implicit gender identification: if our model reinflects the source sentence, then we consider the gender of this sentence to be the opposite of the given target gender. But if the model does not reinflect the source sentence, then we consider the gender of this sentence to be the same as the target"
2020.gebnlp-1.12,D14-1179,0,0.027343,"Missing"
2020.gebnlp-1.12,N12-1067,0,0.14311,"tely. In this paper, we compare to their results using the publicly available Arabic parallel gender corpus they built – a parallel corpus of first-person-singular Arabic sentences that are gender-annotated and reinflected. However, our work is different from theirs in that we jointly learn reinflection for both masculine and feminine genders together. We also model identification implicitly with reinflection in a single architecture. Furthermore, we formulate the problem as a user-aware grammatical error correction task (UGEC). As such, we use as our primary metric the MaxMatch (M2 ) scorer (Dahlmeier and Ng, 2012), which is far more meaningful than the BLEU (Papineni et al., 2002) metric used by Habash et al. (2019) for this task. 3 Arabic Linguistic Background Modern Standard Arabic (MSA) NLP systems and more specifically those using deep learning, face several challenges when it comes to gender expression including morphological richness, orthographic ambiguity and noise. Morphological Richness and Complexity Arabic has a rich morphological system that inflects for gender, number, person, case, state, aspect, mood and voice, in addition to numerous attachable clitics (prepositions, particles, pronoun"
2020.gebnlp-1.12,2020.emnlp-main.23,0,0.0175873,"no-gender expressions. We are not aware of any sociolinguistics published research that discusses such alternatives for Arabic, although there are growing grassroots efforts, e.g., the Ebdal Project.1 1 Introduction The recent advances in machine learning have propelled the field of Natural Language Processing (NLP) forward at a great pace and raised expectation about the quality of results and especially their impact in a social context, including not only race (Merullo et al., 2019) and politics (Fan et al., 2019), but also gender identities (Font and Costa-jussà, 2019; Dinan et al., 2019; Dinan et al., 2020). Human-generated data, reflective of the gender discrimination and sexist stereotypes perpetrated through language and speaker’s lexical choices, is considered the primary source of these biases (Maass and Arcuri, 1996; Menegatti and Rubini, 2017). However, Habash et al. (2019) pointed out that NLP gender biases do not just exist in human-generated training data, and models built from it; but also stem from gender-blind (i.e., gender-unaware) systems designed to generate a single text output without considering any target gender information. Such systems propagate the biases of the models the"
2020.gebnlp-1.12,D19-1664,0,0.0610199,"Missing"
2020.gebnlp-1.12,N16-1077,0,0.0267881,"d Tiedemann, 2016) they use to build the Arabic parallel gender corpus has many of such spelling confusions. 4 Joint Gender Reinflection Model In this section, we discuss the motivation behind our model architecture as well as the integration of the linguistic features. We also describe the training settings and the model’s hyperparameters for reproducibility. 4.1 Motivation Sequence-to-sequence models have achieved significant results in grammatical error correction (GEC) (Chollampatt and Ng, 2018; Junczys-Dowmunt et al., 2018; Grundkiewicz et al., 2019) and morphological reinflection tasks (Faruqui et al., 2016; Kann and Schütze, 2016; Aharoni and Goldberg, 2017). Many of these problems are modeled on the word-level, however, such models usually require large amounts of training data to achieve good results. Character-level sequence-to-sequence models can be superior in mitigating the lack of training data and in dealing with subtle morphological reinflection. Further, pre-trained distributed word representations have also shown to be helpful if integrated properly within character-level sequence-to-sequence models (Watson et al., 2018). We formulate the gender reinflection problem as a user-aware g"
2020.gebnlp-1.12,W19-3821,0,0.0842555,"other alternatives such as non-binary gender or no-gender expressions. We are not aware of any sociolinguistics published research that discusses such alternatives for Arabic, although there are growing grassroots efforts, e.g., the Ebdal Project.1 1 Introduction The recent advances in machine learning have propelled the field of Natural Language Processing (NLP) forward at a great pace and raised expectation about the quality of results and especially their impact in a social context, including not only race (Merullo et al., 2019) and politics (Fan et al., 2019), but also gender identities (Font and Costa-jussà, 2019; Dinan et al., 2019; Dinan et al., 2020). Human-generated data, reflective of the gender discrimination and sexist stereotypes perpetrated through language and speaker’s lexical choices, is considered the primary source of these biases (Maass and Arcuri, 1996; Menegatti and Rubini, 2017). However, Habash et al. (2019) pointed out that NLP gender biases do not just exist in human-generated training data, and models built from it; but also stem from gender-blind (i.e., gender-unaware) systems designed to generate a single text output without considering any target gender information. Such syste"
2020.gebnlp-1.12,W19-3621,0,0.02337,"ve shown that this could be caused by either human-generated training datasets (Font and Costa-jussà, 2019; Habash et al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017; Caliskan et al., 2017; Manzini et al., 2019), or language models (Kurita et al., 2019; Zhao et al., 2019). To mitigate this problem, several researchers 2 3 Arabic transliteration is in the HSB scheme (Habash et al., 2007). https://github.com/CAMeL-Lab/gender-reinflection 140 proposed approaches in which they focus mainly on debiasing word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b; Gonen and Goldberg, 2019) or using counterfactual data augmentation techniques (Lu et al., 2018; Zhao et al., 2018a; Zmigrod et al., 2019; Hall Maudslay et al., 2019). Most of the solutions were mainly proposed to reduce gender bias in English and may not work as well when it comes to morphologically rich languages. Nevertheless, there have been recent studies that explored the gender bias problem in languages other than English. Zhao et al. (2020) studied gender bias which is exhibited by multilingual embeddings in four languages (English, German, French, and Spanish) and demonstrated that such bias can impact cross-"
2020.gebnlp-1.12,2020.findings-emnlp.180,0,0.0173518,"architecture. Then, we present the experimental setup in Section 5 and discuss the results in Section 6. An error analysis is given in Section 7. We conclude and present future work in Section 8. 2 Related Work Many NLP systems have the ability to embed and amplify societal (gender, racial, religious, etc.) biases across a variety of core tasks such as coreference resolution (Rudinger et al., 2018; Zhao et al., 2018a), machine translation (Rabinovich et al., 2017; Vanmassenhove et al., 2018; Font and Costa-jussà, 2019; Moryossef et al., 2019; Stanovsky et al., 2019; Stafanoviˇcs et al., 2020; Gonen and Webster, 2020), named entity recognition (Mehrabi et al., 2019), dialogue systems (Dinan et al., 2019), and language modeling (Lu et al., 2018; Bordia and Bowman, 2019). For the case of gender bias, various research efforts have shown that this could be caused by either human-generated training datasets (Font and Costa-jussà, 2019; Habash et al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017; Caliskan et al., 2017; Manzini et al., 2019), or language models (Kurita et al., 2019; Zhao et al., 2019). To mitigate this problem, several researchers 2 3 Arabic transliteration is in"
2020.gebnlp-1.12,W19-4427,0,0.0189068,"Ya, and Ta-Marbuta, since the OpenSubtitles 2018 corpus (Lison and Tiedemann, 2016) they use to build the Arabic parallel gender corpus has many of such spelling confusions. 4 Joint Gender Reinflection Model In this section, we discuss the motivation behind our model architecture as well as the integration of the linguistic features. We also describe the training settings and the model’s hyperparameters for reproducibility. 4.1 Motivation Sequence-to-sequence models have achieved significant results in grammatical error correction (GEC) (Chollampatt and Ng, 2018; Junczys-Dowmunt et al., 2018; Grundkiewicz et al., 2019) and morphological reinflection tasks (Faruqui et al., 2016; Kann and Schütze, 2016; Aharoni and Goldberg, 2017). Many of these problems are modeled on the word-level, however, such models usually require large amounts of training data to achieve good results. Character-level sequence-to-sequence models can be superior in mitigating the lack of training data and in dealing with subtle morphological reinflection. Further, pre-trained distributed word representations have also shown to be helpful if integrated properly within character-level sequence-to-sequence models (Watson et al., 2018). We"
2020.gebnlp-1.12,W19-3822,1,0.0533142,"eld of Natural Language Processing (NLP) forward at a great pace and raised expectation about the quality of results and especially their impact in a social context, including not only race (Merullo et al., 2019) and politics (Fan et al., 2019), but also gender identities (Font and Costa-jussà, 2019; Dinan et al., 2019; Dinan et al., 2020). Human-generated data, reflective of the gender discrimination and sexist stereotypes perpetrated through language and speaker’s lexical choices, is considered the primary source of these biases (Maass and Arcuri, 1996; Menegatti and Rubini, 2017). However, Habash et al. (2019) pointed out that NLP gender biases do not just exist in human-generated training data, and models built from it; but also stem from gender-blind (i.e., gender-unaware) systems designed to generate a single text output without considering any target gender information. Such systems propagate the biases of the models they use. One example is the I-ama-doctor/I-am-a-nurse problem in machine translation (MT) systems targeting many morphologically 1 https://www.facebook.com/EbdalProject/ This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licen"
2020.gebnlp-1.12,D19-1530,0,0.0179616,"rd embeddings (Bolukbasi et al., 2016; Zhao et al., 2017; Caliskan et al., 2017; Manzini et al., 2019), or language models (Kurita et al., 2019; Zhao et al., 2019). To mitigate this problem, several researchers 2 3 Arabic transliteration is in the HSB scheme (Habash et al., 2007). https://github.com/CAMeL-Lab/gender-reinflection 140 proposed approaches in which they focus mainly on debiasing word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b; Gonen and Goldberg, 2019) or using counterfactual data augmentation techniques (Lu et al., 2018; Zhao et al., 2018a; Zmigrod et al., 2019; Hall Maudslay et al., 2019). Most of the solutions were mainly proposed to reduce gender bias in English and may not work as well when it comes to morphologically rich languages. Nevertheless, there have been recent studies that explored the gender bias problem in languages other than English. Zhao et al. (2020) studied gender bias which is exhibited by multilingual embeddings in four languages (English, German, French, and Spanish) and demonstrated that such bias can impact cross-lingual transfer learning tasks. Zmigrod et al. (2019) used a counterfactual data augmentation approach and developed a generative model to c"
2020.gebnlp-1.12,N18-1055,0,0.0260361,"ly normalized space for Alif, Ya, and Ta-Marbuta, since the OpenSubtitles 2018 corpus (Lison and Tiedemann, 2016) they use to build the Arabic parallel gender corpus has many of such spelling confusions. 4 Joint Gender Reinflection Model In this section, we discuss the motivation behind our model architecture as well as the integration of the linguistic features. We also describe the training settings and the model’s hyperparameters for reproducibility. 4.1 Motivation Sequence-to-sequence models have achieved significant results in grammatical error correction (GEC) (Chollampatt and Ng, 2018; Junczys-Dowmunt et al., 2018; Grundkiewicz et al., 2019) and morphological reinflection tasks (Faruqui et al., 2016; Kann and Schütze, 2016; Aharoni and Goldberg, 2017). Many of these problems are modeled on the word-level, however, such models usually require large amounts of training data to achieve good results. Character-level sequence-to-sequence models can be superior in mitigating the lack of training data and in dealing with subtle morphological reinflection. Further, pre-trained distributed word representations have also shown to be helpful if integrated properly within character-level sequence-to-sequence model"
2020.gebnlp-1.12,P16-2090,0,0.0285595,"y use to build the Arabic parallel gender corpus has many of such spelling confusions. 4 Joint Gender Reinflection Model In this section, we discuss the motivation behind our model architecture as well as the integration of the linguistic features. We also describe the training settings and the model’s hyperparameters for reproducibility. 4.1 Motivation Sequence-to-sequence models have achieved significant results in grammatical error correction (GEC) (Chollampatt and Ng, 2018; Junczys-Dowmunt et al., 2018; Grundkiewicz et al., 2019) and morphological reinflection tasks (Faruqui et al., 2016; Kann and Schütze, 2016; Aharoni and Goldberg, 2017). Many of these problems are modeled on the word-level, however, such models usually require large amounts of training data to achieve good results. Character-level sequence-to-sequence models can be superior in mitigating the lack of training data and in dealing with subtle morphological reinflection. Further, pre-trained distributed word representations have also shown to be helpful if integrated properly within character-level sequence-to-sequence models (Watson et al., 2018). We formulate the gender reinflection problem as a user-aware grammatical error correct"
2020.gebnlp-1.12,W19-3823,0,0.0175934,"d Costa-jussà, 2019; Moryossef et al., 2019; Stanovsky et al., 2019; Stafanoviˇcs et al., 2020; Gonen and Webster, 2020), named entity recognition (Mehrabi et al., 2019), dialogue systems (Dinan et al., 2019), and language modeling (Lu et al., 2018; Bordia and Bowman, 2019). For the case of gender bias, various research efforts have shown that this could be caused by either human-generated training datasets (Font and Costa-jussà, 2019; Habash et al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017; Caliskan et al., 2017; Manzini et al., 2019), or language models (Kurita et al., 2019; Zhao et al., 2019). To mitigate this problem, several researchers 2 3 Arabic transliteration is in the HSB scheme (Habash et al., 2007). https://github.com/CAMeL-Lab/gender-reinflection 140 proposed approaches in which they focus mainly on debiasing word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b; Gonen and Goldberg, 2019) or using counterfactual data augmentation techniques (Lu et al., 2018; Zhao et al., 2018a; Zmigrod et al., 2019; Hall Maudslay et al., 2019). Most of the solutions were mainly proposed to reduce gender bias in English and may not work as well when it comes to m"
2020.gebnlp-1.12,L16-1147,0,0.0167557,"noise result in a high degree of morphological confusability and model sparsity. For  instance, a common spelling error of writing the Ta-Marbuta ( è ~) as Ha ( è h) results in interpreting the ( è h) as a possessive pronoun clitic attached to a masculine noun: éJ . KA¿ kAtb~ ‘writer [feminine]’. éJ.KA¿ kAtbh ‘his writer [masculine]’, vs Normalizing the text may solve some issues related to noise and ambiguity. In this paper, we follow Habash et al. (2019)’s decision to evaluate within an orthographically normalized space for Alif, Ya, and Ta-Marbuta, since the OpenSubtitles 2018 corpus (Lison and Tiedemann, 2016) they use to build the Arabic parallel gender corpus has many of such spelling confusions. 4 Joint Gender Reinflection Model In this section, we discuss the motivation behind our model architecture as well as the integration of the linguistic features. We also describe the training settings and the model’s hyperparameters for reproducibility. 4.1 Motivation Sequence-to-sequence models have achieved significant results in grammatical error correction (GEC) (Chollampatt and Ng, 2018; Junczys-Dowmunt et al., 2018; Grundkiewicz et al., 2019) and morphological reinflection tasks (Faruqui et al., 20"
2020.gebnlp-1.12,D15-1166,0,0.0845227,"Missing"
2020.gebnlp-1.12,N19-1062,0,0.0210389,", 2017; Vanmassenhove et al., 2018; Font and Costa-jussà, 2019; Moryossef et al., 2019; Stanovsky et al., 2019; Stafanoviˇcs et al., 2020; Gonen and Webster, 2020), named entity recognition (Mehrabi et al., 2019), dialogue systems (Dinan et al., 2019), and language modeling (Lu et al., 2018; Bordia and Bowman, 2019). For the case of gender bias, various research efforts have shown that this could be caused by either human-generated training datasets (Font and Costa-jussà, 2019; Habash et al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017; Caliskan et al., 2017; Manzini et al., 2019), or language models (Kurita et al., 2019; Zhao et al., 2019). To mitigate this problem, several researchers 2 3 Arabic transliteration is in the HSB scheme (Habash et al., 2007). https://github.com/CAMeL-Lab/gender-reinflection 140 proposed approaches in which they focus mainly on debiasing word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b; Gonen and Goldberg, 2019) or using counterfactual data augmentation techniques (Lu et al., 2018; Zhao et al., 2018a; Zmigrod et al., 2019; Hall Maudslay et al., 2019). Most of the solutions were mainly proposed to reduce gender bias in English an"
2020.gebnlp-1.12,D19-1666,0,0.0496671,"Missing"
2020.gebnlp-1.12,W19-3807,0,0.0221462,"our model for joint gender reinflection and describes the encoder-decoder architecture. Then, we present the experimental setup in Section 5 and discuss the results in Section 6. An error analysis is given in Section 7. We conclude and present future work in Section 8. 2 Related Work Many NLP systems have the ability to embed and amplify societal (gender, racial, religious, etc.) biases across a variety of core tasks such as coreference resolution (Rudinger et al., 2018; Zhao et al., 2018a), machine translation (Rabinovich et al., 2017; Vanmassenhove et al., 2018; Font and Costa-jussà, 2019; Moryossef et al., 2019; Stanovsky et al., 2019; Stafanoviˇcs et al., 2020; Gonen and Webster, 2020), named entity recognition (Mehrabi et al., 2019), dialogue systems (Dinan et al., 2019), and language modeling (Lu et al., 2018; Bordia and Bowman, 2019). For the case of gender bias, various research efforts have shown that this could be caused by either human-generated training datasets (Font and Costa-jussà, 2019; Habash et al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017; Caliskan et al., 2017; Manzini et al., 2019), or language models (Kurita et al., 2019; Zhao et al., 2019). To"
2020.gebnlp-1.12,P02-1040,0,0.107682,"vailable Arabic parallel gender corpus they built – a parallel corpus of first-person-singular Arabic sentences that are gender-annotated and reinflected. However, our work is different from theirs in that we jointly learn reinflection for both masculine and feminine genders together. We also model identification implicitly with reinflection in a single architecture. Furthermore, we formulate the problem as a user-aware grammatical error correction task (UGEC). As such, we use as our primary metric the MaxMatch (M2 ) scorer (Dahlmeier and Ng, 2012), which is far more meaningful than the BLEU (Papineni et al., 2002) metric used by Habash et al. (2019) for this task. 3 Arabic Linguistic Background Modern Standard Arabic (MSA) NLP systems and more specifically those using deep learning, face several challenges when it comes to gender expression including morphological richness, orthographic ambiguity and noise. Morphological Richness and Complexity Arabic has a rich morphological system that inflects for gender, number, person, case, state, aspect, mood and voice, in addition to numerous attachable clitics (prepositions, particles, pronouns) (Habash, 2010). This results in a large number of forms for any"
2020.gebnlp-1.12,W18-6319,0,0.0119102,". (2019). After merging the corpora we ended up with 17,132 sentence pairs for training (T RAIN), 2,448 for development (D EV), and 4,896 for testing (T EST). All of our systems are trained to take a source sentence and a target gender as input to produce a gender-reinflected target sentence as described in section 4.2. 5.2 Metrics Gender Reinflection We follow Habash et al. (2019) and use BLEU as an evaluation metric (Papineni et al., 2002), however, we believe that BLEU is not a suitable metric for our task due to the high similarity between the input and output sentences. We use SacreBLEU (Post, 2018) to compute the BLEU scores. Additionally, we use the MaxMatch (M2 ) scorer (Dahlmeier and Ng, 2012) to compute the word-level edits between the input and reinflected output. We report the precision, recall, and F0.5 scores calculated against the gold edits, which were also created by the M2 scorer. We are aware that there are other tools to consider for word-level edit calculation such as ERRANT (Bryant et al., 2017), but we did not use them as they require additional dependencies to work for Arabic. Input Gender Identification Our sequence-to-sequence model does not explicitly identify the g"
2020.gebnlp-1.12,E17-1101,0,0.0254015,"some Arabic linguistic facts related to grammatical gender. Section 4 introduces our model for joint gender reinflection and describes the encoder-decoder architecture. Then, we present the experimental setup in Section 5 and discuss the results in Section 6. An error analysis is given in Section 7. We conclude and present future work in Section 8. 2 Related Work Many NLP systems have the ability to embed and amplify societal (gender, racial, religious, etc.) biases across a variety of core tasks such as coreference resolution (Rudinger et al., 2018; Zhao et al., 2018a), machine translation (Rabinovich et al., 2017; Vanmassenhove et al., 2018; Font and Costa-jussà, 2019; Moryossef et al., 2019; Stanovsky et al., 2019; Stafanoviˇcs et al., 2020; Gonen and Webster, 2020), named entity recognition (Mehrabi et al., 2019), dialogue systems (Dinan et al., 2019), and language modeling (Lu et al., 2018; Bordia and Bowman, 2019). For the case of gender bias, various research efforts have shown that this could be caused by either human-generated training datasets (Font and Costa-jussà, 2019; Habash et al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017; Caliskan et al., 2017; Manzin"
2020.gebnlp-1.12,N18-2002,0,0.0458667,"Missing"
2020.gebnlp-1.12,2020.wmt-1.73,0,0.0349747,"Missing"
2020.gebnlp-1.12,P19-1164,0,0.0147204,"der reinflection and describes the encoder-decoder architecture. Then, we present the experimental setup in Section 5 and discuss the results in Section 6. An error analysis is given in Section 7. We conclude and present future work in Section 8. 2 Related Work Many NLP systems have the ability to embed and amplify societal (gender, racial, religious, etc.) biases across a variety of core tasks such as coreference resolution (Rudinger et al., 2018; Zhao et al., 2018a), machine translation (Rabinovich et al., 2017; Vanmassenhove et al., 2018; Font and Costa-jussà, 2019; Moryossef et al., 2019; Stanovsky et al., 2019; Stafanoviˇcs et al., 2020; Gonen and Webster, 2020), named entity recognition (Mehrabi et al., 2019), dialogue systems (Dinan et al., 2019), and language modeling (Lu et al., 2018; Bordia and Bowman, 2019). For the case of gender bias, various research efforts have shown that this could be caused by either human-generated training datasets (Font and Costa-jussà, 2019; Habash et al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017; Caliskan et al., 2017; Manzini et al., 2019), or language models (Kurita et al., 2019; Zhao et al., 2019). To mitigate this problem,"
2020.gebnlp-1.12,W18-5816,1,0.835155,"the decoder (d) hidden state ht , the context vector ct , and the embedding of the predicted symbol from the previous (d) time step eyˆt−1 to create vector zt = [ht ; ct ; eyˆt−1 ; eg ] ∈ RH+2H+E+J . We finally project zt to a vector of size |Vy |followed by a softmax layer to model the distribution over the target vocabulary PVy (ˆ yt ) = softmax (Wb zt + bb ). 143 Linguistic Features and Word Embeddings We explore adding word-level morphological features as well as pre-trained distributed word representations to the character embeddings. We use the CALIMAStar Arabic morphological analyzer (Taji et al., 2018) to obtain word-level functional gender features (Alkuhlani and Habash, 2011).5 We represent the morphological features for word wj as a four-dimension one-hot vector µwj ∈ R4 . Each element of this one-hot vector represents whether the word wj is masculine or feminine as well as if the analysis was obtained with or without spelling backoff. We use FastText (Bojanowski et al., 2017) to learn distributed word representations and we denote the FastText word embedding for word wj as ρwj ∈ RF . Similarly to Watson et al. (2018), we added the word-level features to the character embeddings only on"
2020.gebnlp-1.12,D18-1334,0,0.0216965,"acts related to grammatical gender. Section 4 introduces our model for joint gender reinflection and describes the encoder-decoder architecture. Then, we present the experimental setup in Section 5 and discuss the results in Section 6. An error analysis is given in Section 7. We conclude and present future work in Section 8. 2 Related Work Many NLP systems have the ability to embed and amplify societal (gender, racial, religious, etc.) biases across a variety of core tasks such as coreference resolution (Rudinger et al., 2018; Zhao et al., 2018a), machine translation (Rabinovich et al., 2017; Vanmassenhove et al., 2018; Font and Costa-jussà, 2019; Moryossef et al., 2019; Stanovsky et al., 2019; Stafanoviˇcs et al., 2020; Gonen and Webster, 2020), named entity recognition (Mehrabi et al., 2019), dialogue systems (Dinan et al., 2019), and language modeling (Lu et al., 2018; Bordia and Bowman, 2019). For the case of gender bias, various research efforts have shown that this could be caused by either human-generated training datasets (Font and Costa-jussà, 2019; Habash et al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017; Caliskan et al., 2017; Manzini et al., 2019), or language"
2020.gebnlp-1.12,D18-1097,1,0.931313,"rundkiewicz et al., 2019) and morphological reinflection tasks (Faruqui et al., 2016; Kann and Schütze, 2016; Aharoni and Goldberg, 2017). Many of these problems are modeled on the word-level, however, such models usually require large amounts of training data to achieve good results. Character-level sequence-to-sequence models can be superior in mitigating the lack of training data and in dealing with subtle morphological reinflection. Further, pre-trained distributed word representations have also shown to be helpful if integrated properly within character-level sequence-to-sequence models (Watson et al., 2018). We formulate the gender reinflection problem as a user-aware grammatical error correction (UGEC) task at the character-level. We also explore leveraging linguistic knowledge on the word-level as well as pre-trained word embeddings to enhance the performance of the model. 4.2 Model Architecture Given an input sequence x1:n ∈ Vx containing k words w1:k ∈ Vw , a gender-reinflected output sequence y1:m ∈ Vy , and a target gender g ∈ {F, M }, the goal is to model an auto-regressive distribution which is defined over the target vocabulary:4 PVy (y1:m |x1:n , g) = m Y P (yt |y1:t−1 , x1:n , g; θ);"
2020.gebnlp-1.12,D17-1323,0,0.0292491,"a), machine translation (Rabinovich et al., 2017; Vanmassenhove et al., 2018; Font and Costa-jussà, 2019; Moryossef et al., 2019; Stanovsky et al., 2019; Stafanoviˇcs et al., 2020; Gonen and Webster, 2020), named entity recognition (Mehrabi et al., 2019), dialogue systems (Dinan et al., 2019), and language modeling (Lu et al., 2018; Bordia and Bowman, 2019). For the case of gender bias, various research efforts have shown that this could be caused by either human-generated training datasets (Font and Costa-jussà, 2019; Habash et al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017; Caliskan et al., 2017; Manzini et al., 2019), or language models (Kurita et al., 2019; Zhao et al., 2019). To mitigate this problem, several researchers 2 3 Arabic transliteration is in the HSB scheme (Habash et al., 2007). https://github.com/CAMeL-Lab/gender-reinflection 140 proposed approaches in which they focus mainly on debiasing word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b; Gonen and Goldberg, 2019) or using counterfactual data augmentation techniques (Lu et al., 2018; Zhao et al., 2018a; Zmigrod et al., 2019; Hall Maudslay et al., 2019). Most of the solutions were mainl"
2020.gebnlp-1.12,N18-2003,0,0.0510292,"ome related work. In Section 3, we present some Arabic linguistic facts related to grammatical gender. Section 4 introduces our model for joint gender reinflection and describes the encoder-decoder architecture. Then, we present the experimental setup in Section 5 and discuss the results in Section 6. An error analysis is given in Section 7. We conclude and present future work in Section 8. 2 Related Work Many NLP systems have the ability to embed and amplify societal (gender, racial, religious, etc.) biases across a variety of core tasks such as coreference resolution (Rudinger et al., 2018; Zhao et al., 2018a), machine translation (Rabinovich et al., 2017; Vanmassenhove et al., 2018; Font and Costa-jussà, 2019; Moryossef et al., 2019; Stanovsky et al., 2019; Stafanoviˇcs et al., 2020; Gonen and Webster, 2020), named entity recognition (Mehrabi et al., 2019), dialogue systems (Dinan et al., 2019), and language modeling (Lu et al., 2018; Bordia and Bowman, 2019). For the case of gender bias, various research efforts have shown that this could be caused by either human-generated training datasets (Font and Costa-jussà, 2019; Habash et al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016;"
2020.gebnlp-1.12,D18-1521,0,0.0642243,"ome related work. In Section 3, we present some Arabic linguistic facts related to grammatical gender. Section 4 introduces our model for joint gender reinflection and describes the encoder-decoder architecture. Then, we present the experimental setup in Section 5 and discuss the results in Section 6. An error analysis is given in Section 7. We conclude and present future work in Section 8. 2 Related Work Many NLP systems have the ability to embed and amplify societal (gender, racial, religious, etc.) biases across a variety of core tasks such as coreference resolution (Rudinger et al., 2018; Zhao et al., 2018a), machine translation (Rabinovich et al., 2017; Vanmassenhove et al., 2018; Font and Costa-jussà, 2019; Moryossef et al., 2019; Stanovsky et al., 2019; Stafanoviˇcs et al., 2020; Gonen and Webster, 2020), named entity recognition (Mehrabi et al., 2019), dialogue systems (Dinan et al., 2019), and language modeling (Lu et al., 2018; Bordia and Bowman, 2019). For the case of gender bias, various research efforts have shown that this could be caused by either human-generated training datasets (Font and Costa-jussà, 2019; Habash et al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016;"
2020.gebnlp-1.12,N19-1064,0,0.0142373,"Moryossef et al., 2019; Stanovsky et al., 2019; Stafanoviˇcs et al., 2020; Gonen and Webster, 2020), named entity recognition (Mehrabi et al., 2019), dialogue systems (Dinan et al., 2019), and language modeling (Lu et al., 2018; Bordia and Bowman, 2019). For the case of gender bias, various research efforts have shown that this could be caused by either human-generated training datasets (Font and Costa-jussà, 2019; Habash et al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017; Caliskan et al., 2017; Manzini et al., 2019), or language models (Kurita et al., 2019; Zhao et al., 2019). To mitigate this problem, several researchers 2 3 Arabic transliteration is in the HSB scheme (Habash et al., 2007). https://github.com/CAMeL-Lab/gender-reinflection 140 proposed approaches in which they focus mainly on debiasing word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b; Gonen and Goldberg, 2019) or using counterfactual data augmentation techniques (Lu et al., 2018; Zhao et al., 2018a; Zmigrod et al., 2019; Hall Maudslay et al., 2019). Most of the solutions were mainly proposed to reduce gender bias in English and may not work as well when it comes to morphologically rich"
2020.gebnlp-1.12,P19-1161,0,0.017333,"al., 2019), pre-trained word embeddings (Bolukbasi et al., 2016; Zhao et al., 2017; Caliskan et al., 2017; Manzini et al., 2019), or language models (Kurita et al., 2019; Zhao et al., 2019). To mitigate this problem, several researchers 2 3 Arabic transliteration is in the HSB scheme (Habash et al., 2007). https://github.com/CAMeL-Lab/gender-reinflection 140 proposed approaches in which they focus mainly on debiasing word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b; Gonen and Goldberg, 2019) or using counterfactual data augmentation techniques (Lu et al., 2018; Zhao et al., 2018a; Zmigrod et al., 2019; Hall Maudslay et al., 2019). Most of the solutions were mainly proposed to reduce gender bias in English and may not work as well when it comes to morphologically rich languages. Nevertheless, there have been recent studies that explored the gender bias problem in languages other than English. Zhao et al. (2020) studied gender bias which is exhibited by multilingual embeddings in four languages (English, German, French, and Spanish) and demonstrated that such bias can impact cross-lingual transfer learning tasks. Zmigrod et al. (2019) used a counterfactual data augmentation approach and deve"
2020.lrec-1.373,L18-1366,1,0.922902,"be publicly available. Keywords: Readability, Lexicon, Arabic 1. Introduction Modeling readability levels is relevant to a range of natural language processing (NLP) tasks from developing language education applications to user profiling. Much work has been done on readability leveling and its assessment and specification in English leading to the development of many resources and tools. However, this is not the case for many other languages. The work presented in this paper is part of a project on Simplification of Arabic Masterpieces for Extensive Reading (SAMER) (Al Khalil et al., 2017; Al Khalil et al., 2018). Specifically, we discuss the challenges of, and solutions to, the development of a large-scale leveled readability lexicon for Modern Standard Arabic (MSA). Although some aspects of the effort are Arabic specific, we situate it within the larger frameworks of approaches to readability lexicon development. Our contributions include the following: • We define a five-level readability scale for MSA targeting native speakers and create annotation guidelines for it. • We manually annotate a 26,578-lemma lexicon in triplicate by language professionals from three different regions in the Arab world"
2020.lrec-1.373,L18-1535,1,0.893442,"Missing"
2020.lrec-1.373,W12-2205,0,0.0110373,"guage learning. This project aims to map the most common 9,000 words in nine languages (including Arabic) onto Common European Framework of Reference for Languages (CEFR) levels through corpus-based frequency analysis and comparisons between translated language pairs across the said nine languages. Research on the design and use of word frequency lists is abundant in English and other world languages. Of particular relevance to this paper, however, are the novel ways and techniques that some researchers use to address the challenges and shortcomings faced in creating these lists. For example, Brooke et al. (2012) created lexicons where words are classified based on the readability of the web documents they appear in and the words they co-occur with. Another example is Ehara (2018) who used crowd sourcing to simulate testing on the vocabulary size test, a wellstudied English vocabulary test, by one hundred test-takers – producing a reliable English vocabulary knowledge data set of Japanese learners of English. In the field of Arabic education, intuition and experience form the basis in most projects involving readability lev3054 Category All Words Punctuation OOV 888 Latin Script Proper Noun Capitalize"
2020.lrec-1.373,L18-1076,0,0.0198751,"Missing"
2020.lrec-1.373,pasha-etal-2014-madamira,1,0.838425,". acquired from Arabic news sources, and (b) the Hindawi Corpus, a corpus of Arabic literature built by collecting 129 works of fiction available in the public domain from the online catalog of the Hindawi Foundation.5 We specifically took a sample of ∼11M tokens in balanced distribution from the Arabic Gigaword corpus (5,594,256 tokens) and the Hindawi corpus (5,594,310 tokens). Automatic Lemmatization We automatically annotated each token in our corpus in context with morphological information including lemma and part-of-speech (POS) using the MADAMIRA tool for morphological disambiguation (Pasha et al., 2014). MADAMIRA out-of-vocabulary (OOV) tokens are all collapsed into the lemma “OOV”. Digits are also collapsed into the lemma “888”. The total number of unique lemmas is 31,542. Categorical and Frequency Filtering We decided that certain categories should be excluded from annotation for obvious reasons, namely, punctuation marks, digits, Latin script words, and OOV. We also excluded abbreviations, proper nouns, and nouns and adjectives that refer to nationalities (identified through English gloss capitalization) because those lemmas are more closely associated with a person’s general knowledge th"
2020.lrec-1.373,W18-3703,1,0.842635,"inal clauses, and percentage of definite nouns. Al-Khalifa and Al-Ajlan (2010) processed educational materials for elementary, intermediate and secondary schools in Saudi Arabia using features such as average word length in letters and syllables, term frequency (ratio of duplicated words), and a bigram language model with a machine learning classifier. Forsyth (2014) used a machine learning approach to process the online curriculum of the Defense Language Institute Foreign Language Center and concluded that most (19 out of 20) of the best features are from the POS-based frequency feature set. Saddiki et al. (2018) presented results on the use of a large number of morphological and syntactic features and n-gram models to automatically predict Arabic readability level for native and nonnative speakers. The KELLY project (Kilgarriff et al., 2014) is another notable research effort that aims to develop monolingual and bilingual word lists for language learning. This project aims to map the most common 9,000 words in nine languages (including Arabic) onto Common European Framework of Reference for Languages (CEFR) levels through corpus-based frequency analysis and comparisons between translated language pai"
2020.lrec-1.480,N16-3003,0,0.06809,"lied on the existence of the Buckwalter Morphological Analyzer (BAMA) (Buckwalter, 2004) and its later version the Standard Arabic Morphological Analyzer (SAMA) (Maamouri 3895 et al., 2010). Among such efforts, are MADAMIRA (Pasha et al., 2014) and it predecessors MADA (Habash and Rambow, 2005; Roth et al., 2008; Habash et al., 2009; Habash et al., 2013) and AMIRA (Diab et al., 2004; Diab et al., 2007). MADAMIRA uses a morphological analyzer and SVMsbased taggers for different features, along with n-gram language models for lemmatization and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approaches attempt to exploit linguistic similarity between MSA and Arabic dialects to build dialect tools using existing MSA resources (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Zribi et al., 2013; Salloum and Habash, 2014; Hamdi et al., 2015; Albogamy and Ramsay, 2015; Eskander et al., 2016). MAGEAD is a morphological ana"
2020.lrec-1.480,R15-1001,0,0.0269576,"on and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approaches attempt to exploit linguistic similarity between MSA and Arabic dialects to build dialect tools using existing MSA resources (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Zribi et al., 2013; Salloum and Habash, 2014; Hamdi et al., 2015; Albogamy and Ramsay, 2015; Eskander et al., 2016). MAGEAD is a morphological analyzer that models Arabic dialects together with MSA using a common multi-tape finite-statemachine framework (Habash and Rambow, 2006). Zribi et al. (2013) adapt an MSA analyzer, Al-Khalil (Boudlal et al., 2010), to Tunisian Arabic, where they modify the derivation patterns and add Tunisian-specific roots and patterns. Eskander et al. (2016), on the other hand, presented a paradigm completion approach to generate morphological analyzers for low-resource dialects using morphologically annotated corpora. They then make use of available MSA an"
2020.lrec-1.480,L18-1620,0,0.0116937,"the results using both an SVM-Rank and Bi-LSTM-CRF models (Samih et al., 2017b). Darwish et al. (2017) use Bi-LSTM models to train a POS tagger, and compared it against SVM-based model. The SVM model in their system outperformed the neural model, even with incorporating pre-trained embeddings. Other notable contributions include the work of Inoue et al. (2017), who used multi-task learning to model fine-grained POS tags, using the individual morphosyntactic features. More recently, Zalmout and Habash (2017) presented the first neural based full morphological disambiguation system for Arabic. Alharbi et al. (2018) also use a Bi-LSTM model for GLF POS tagging, with good results. In this work, we introduce the first morphological analysis and disambiguation system for GLF. We base our work on Zalmout and Habash (2019), and we use the data from Khalifa et al. (2018). 3. Relevant Linguistic Background Gulf Arabic We follow the definition of GLF mentioned in (Khalifa et al., 2016a), as the variety of Arabic spoken by indigenous populations residing the six countries of the Gulf Cooperation Council (GCC): Saudi Arabia, United Arab Emirates, Qatar, Kuwait, Bahrain, and Oman. In this work, the GLF data used in"
2020.lrec-1.480,P11-2062,1,0.814849,"lasses (ICs) generated from available morphological annotations. The set of inflectional forms for a given lexeme is called a paradigm. The completion is performed on the level of POS tags present in the data, where all the possible morphosyntactic feature combinations from the words that share the same POS tag are collected. This set of potential feature combinations represent the slots for inflected forms in the ICs. Using this set to indicate the potential slots, the algorithm goes through each of the lemmas in the 3 We use form-based not functional gender and number features in this work (Alkuhlani and Habash, 2011). 3897 Split Sentences Tokens Types Analyses T ype Analyses Lemma TRAIN TEST 12,274 1,499 1,452 162,031 20,198 20,100 20,079 5,090 4,980 1.28 1.14 1.15 3.69 2.53 2.48 ALL 15,225 202,329 22,924 1.29 3.89 DEV Table 2: Statistics on TRAIN, DEV, and TEST in terms of number of sentences, tokens, and types, as well as an ambiguity measure (analyses per type) and a richness measure (analyses per lemma). Note that ‘ALL’ represents the statistics on the entire corpus as a whole and not the sum of the splits. dataset and fills the corresponding slot in the IC using all the inflected forms of that lemma"
2020.lrec-1.480,W19-4615,1,0.818158,"tated in a similar style to the PATB. The aforementioned MADAMIRA and YAMAMA systems were extended to EGY using CALIMA (Habash et al., 2012) and ARZATB (Maamouri et al., 2012). Jarrar et al. (2014) released the Curras Corpus of Palestinian Arabic, also annotated in the PATB morphology style. Darwish et al. (2018) used a CRF model for a multi-dialect POS tagging, using a small annotated Twitter corpus for several dialects. Erdmann et al. (2019) developed a de-lexical segmentation tool for dialectal content. Their model is mainly unsupervised, relying on a small grammar of closed-class affixes. Alshargi et al. (2019) presented morphologically annotated corpora for seven different dialects. Regarding GLF specifically, Khalifa et al. (2017) presented a morphological analyzer for Gulf verbs, covering segmentation, POS, and lemmatization details for Gulf verbal paradigms. Khalifa et al. (2018) also presented a largescale morphologically annotated corpus of Emirati Arabic, extracted from online novels, with about 200K words. The annotation includes tokenization, POS, lemmatization, English glosses and dialect identification, as the corpus includes traces of other dialects, along with MSA content. So far, the m"
2020.lrec-1.480,L18-1535,1,0.852169,"Missing"
2020.lrec-1.480,L16-1170,0,0.260915,"f the Buckwalter Morphological Analyzer (BAMA) (Buckwalter, 2004) and its later version the Standard Arabic Morphological Analyzer (SAMA) (Maamouri 3895 et al., 2010). Among such efforts, are MADAMIRA (Pasha et al., 2014) and it predecessors MADA (Habash and Rambow, 2005; Roth et al., 2008; Habash et al., 2009; Habash et al., 2013) and AMIRA (Diab et al., 2004; Diab et al., 2007). MADAMIRA uses a morphological analyzer and SVMsbased taggers for different features, along with n-gram language models for lemmatization and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approaches attempt to exploit linguistic similarity between MSA and Arabic dialects to build dialect tools using existing MSA resources (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Zribi et al., 2013; Salloum and Habash, 2014; Hamdi et al., 2015; Albogamy and Ramsay, 2015; Eskander et al., 2016). MAGEAD is a morphological analyzer that models Arabic dia"
2020.lrec-1.480,W17-1316,0,0.0189802,"of-the-art. Heigold et al. (2016) developed character-based neural models for morphological tagging for 14 different languages, including Arabic, using the UD treebank. Samih et al. (2017a) used a Bi-LSTM-CRF architecture and pre-trained character embeddings for the segmentation of EGY tweets. They then build up on this approach using a similar architecture for segmentation in multiple dialects, through combining the training datasets for the different dialects, and train a unified segmentation model. They report the results using both an SVM-Rank and Bi-LSTM-CRF models (Samih et al., 2017b). Darwish et al. (2017) use Bi-LSTM models to train a POS tagger, and compared it against SVM-based model. The SVM model in their system outperformed the neural model, even with incorporating pre-trained embeddings. Other notable contributions include the work of Inoue et al. (2017), who used multi-task learning to model fine-grained POS tags, using the individual morphosyntactic features. More recently, Zalmout and Habash (2017) presented the first neural based full morphological disambiguation system for Arabic. Alharbi et al. (2018) also use a Bi-LSTM model for GLF POS tagging, with good results. In this work, we"
2020.lrec-1.480,L18-1015,0,0.0115351,"et and tagger for EGY. Habash et al. (2012) presented CALIMA, a morphological analyzer for EGY, which was built by extending the Egyptian Colloquial Arabic Lexicon (ECAL) (Kilany et al., 2002). The LDC has also released the EGY treebank (ARZATB) (Maamouri et al., 2012). The treebank is morphologically annotated in a similar style to the PATB. The aforementioned MADAMIRA and YAMAMA systems were extended to EGY using CALIMA (Habash et al., 2012) and ARZATB (Maamouri et al., 2012). Jarrar et al. (2014) released the Curras Corpus of Palestinian Arabic, also annotated in the PATB morphology style. Darwish et al. (2018) used a CRF model for a multi-dialect POS tagging, using a small annotated Twitter corpus for several dialects. Erdmann et al. (2019) developed a de-lexical segmentation tool for dialectal content. Their model is mainly unsupervised, relying on a small grammar of closed-class affixes. Alshargi et al. (2019) presented morphologically annotated corpora for seven different dialects. Regarding GLF specifically, Khalifa et al. (2017) presented a morphological analyzer for Gulf verbs, covering segmentation, POS, and lemmatization details for Gulf verbal paradigms. Khalifa et al. (2018) also presente"
2020.lrec-1.480,N04-4038,0,0.0104589,"was based on a corpus of 50,000 words. Later, the LDC released the Penn Arabic Treebank (PATB) (Maamouri et al., 2004), which was substantially larger, and supported many further efforts on Arabic morphological modeling. The PATB relied on the existence of the Buckwalter Morphological Analyzer (BAMA) (Buckwalter, 2004) and its later version the Standard Arabic Morphological Analyzer (SAMA) (Maamouri 3895 et al., 2010). Among such efforts, are MADAMIRA (Pasha et al., 2014) and it predecessors MADA (Habash and Rambow, 2005; Roth et al., 2008; Habash et al., 2009; Habash et al., 2013) and AMIRA (Diab et al., 2004; Diab et al., 2007). MADAMIRA uses a morphological analyzer and SVMsbased taggers for different features, along with n-gram language models for lemmatization and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approaches attempt to exploit linguistic similarity between MSA and Arabic dialects to build dial"
2020.lrec-1.480,W05-0708,0,0.098126,"rphological analyzer and SVMsbased taggers for different features, along with n-gram language models for lemmatization and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approaches attempt to exploit linguistic similarity between MSA and Arabic dialects to build dialect tools using existing MSA resources (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Zribi et al., 2013; Salloum and Habash, 2014; Hamdi et al., 2015; Albogamy and Ramsay, 2015; Eskander et al., 2016). MAGEAD is a morphological analyzer that models Arabic dialects together with MSA using a common multi-tape finite-statemachine framework (Habash and Rambow, 2006). Zribi et al. (2013) adapt an MSA analyzer, Al-Khalil (Boudlal et al., 2010), to Tunisian Arabic, where they modify the derivation patterns and add Tunisian-specific roots and patterns. Eskander et al. (2016), on the other hand, presented a paradigm completion approach to generate morphologic"
2020.lrec-1.480,W12-5611,0,0.0484238,"Missing"
2020.lrec-1.480,W19-4214,1,0.82591,"tian Colloquial Arabic Lexicon (ECAL) (Kilany et al., 2002). The LDC has also released the EGY treebank (ARZATB) (Maamouri et al., 2012). The treebank is morphologically annotated in a similar style to the PATB. The aforementioned MADAMIRA and YAMAMA systems were extended to EGY using CALIMA (Habash et al., 2012) and ARZATB (Maamouri et al., 2012). Jarrar et al. (2014) released the Curras Corpus of Palestinian Arabic, also annotated in the PATB morphology style. Darwish et al. (2018) used a CRF model for a multi-dialect POS tagging, using a small annotated Twitter corpus for several dialects. Erdmann et al. (2019) developed a de-lexical segmentation tool for dialectal content. Their model is mainly unsupervised, relying on a small grammar of closed-class affixes. Alshargi et al. (2019) presented morphologically annotated corpora for seven different dialects. Regarding GLF specifically, Khalifa et al. (2017) presented a morphological analyzer for Gulf verbs, covering segmentation, POS, and lemmatization details for Gulf verbal paradigms. Khalifa et al. (2018) also presented a largescale morphologically annotated corpus of Emirati Arabic, extracted from online novels, with about 200K words. The annotatio"
2020.lrec-1.480,2020.lrec-1.508,1,0.797622,"hat guarantees annotation efficiency, hence, the representation of tags used is often more readable and explainable to the human annotator. The data we use from Khalifa et al. (2018) was annotated using the MADARi morphological annotation interface (Obeid et al., 2018). Where for each word in context the annotators were asked to produce a CODA spelling, then tokenize and assign a single condensed tag 1 Arabic script transliteration is presented in the Habash-SoudiBuckwalter transliteration scheme (Habash et al., 2007). 2 The specific city dialects were of Beirut, Cairo, Doha, Tunis and Rabat (Eryani et al., 2020). that includes the core POS along with the functional morphological features for each token. Computationally, a more verbose representation of the analysis is usually used to have more control over modeling choices. In this work, we follow the same format used in previous efforts (Habash, 2007; Pasha et al., 2014), where we have a vector like representation of feature value pairs. We therefore map from the condensed representation to the more verbose one. This mapping includes POS tags, clitics position mapping, and stemming. Table 1 shows the two different representations side by side for th"
2020.lrec-1.480,D13-1105,1,0.809353,"Morphological analyzers are rich resources that can be used as lexical and grammatical references. In a number of popular tools for Arabic morphological disambiguation, the task is defined as an in-context ranking of the out-of-context morphological analyses produced by an analyzer (Habash et al., 2009; Pasha et al., 2014). There are different ways of building morphological analyzers: manually, automatically, or semi-automatically. In this work, we use two manually created morphological analyzers for MSA and EGY. However, for GLF, we use the approach of paradigm completion as demonstrated by Eskander et al. (2013a) and Eskander et al. (2016). Paradigm completion makes use of the templatic nature of Arabic to model morphology through roots and patterns. The approach mainly aims at completing the inflectional classes (ICs) generated from available morphological annotations. The set of inflectional forms for a given lexeme is called a paradigm. The completion is performed on the level of POS tags present in the data, where all the possible morphosyntactic feature combinations from the words that share the same POS tag are collected. This set of potential feature combinations represent the slots for infle"
2020.lrec-1.480,N13-1066,1,0.777158,"Morphological analyzers are rich resources that can be used as lexical and grammatical references. In a number of popular tools for Arabic morphological disambiguation, the task is defined as an in-context ranking of the out-of-context morphological analyses produced by an analyzer (Habash et al., 2009; Pasha et al., 2014). There are different ways of building morphological analyzers: manually, automatically, or semi-automatically. In this work, we use two manually created morphological analyzers for MSA and EGY. However, for GLF, we use the approach of paradigm completion as demonstrated by Eskander et al. (2013a) and Eskander et al. (2016). Paradigm completion makes use of the templatic nature of Arabic to model morphology through roots and patterns. The approach mainly aims at completing the inflectional classes (ICs) generated from available morphological annotations. The set of inflectional forms for a given lexeme is called a paradigm. The completion is performed on the level of POS tags present in the data, where all the possible morphosyntactic feature combinations from the words that share the same POS tag are collected. This set of potential feature combinations represent the slots for infle"
2020.lrec-1.480,C16-1326,1,0.932155,"recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approaches attempt to exploit linguistic similarity between MSA and Arabic dialects to build dialect tools using existing MSA resources (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Zribi et al., 2013; Salloum and Habash, 2014; Hamdi et al., 2015; Albogamy and Ramsay, 2015; Eskander et al., 2016). MAGEAD is a morphological analyzer that models Arabic dialects together with MSA using a common multi-tape finite-statemachine framework (Habash and Rambow, 2006). Zribi et al. (2013) adapt an MSA analyzer, Al-Khalil (Boudlal et al., 2010), to Tunisian Arabic, where they modify the derivation patterns and add Tunisian-specific roots and patterns. Eskander et al. (2016), on the other hand, presented a paradigm completion approach to generate morphological analyzers for low-resource dialects using morphologically annotated corpora. They then make use of available MSA and EGY analyzers as backo"
2020.lrec-1.480,C16-1132,1,0.830613,"s performance to the quality of the analyzer, especially when generating open class features such as lemmas. In this work we use state-of-the-art neural architectures that have the ability to model morphologically rich and complex languages such as Arabic and its different verities. Neural-based contributions for Arabic Morphology Neural-based contributions for Arabic NLP are relatively scarce and specific to individual tasks rather than full morphological disambiguation. Among the contributions that utilize morphological structures to enhance the neural models in different NLP tasks, we note Guzmán et al. (2016) for machine translation, and Abandah et al. (2015) for diacritization. Shen et al. (2016) applied their Bi-LSTM morphological disambiguation model on MSA, but did not present any improvements over the state-of-the-art. Heigold et al. (2016) developed character-based neural models for morphological tagging for 14 different languages, including Arabic, using the UD treebank. Samih et al. (2017a) used a Bi-LSTM-CRF architecture and pre-trained character embeddings for the segmentation of EGY tweets. They then build up on this approach using a similar architecture for segmentation in multiple dia"
2020.lrec-1.480,P05-1071,1,0.773113,"g One of the earliest morphological tagging systems for Arabic was presented by Khoja (2001); it was based on a corpus of 50,000 words. Later, the LDC released the Penn Arabic Treebank (PATB) (Maamouri et al., 2004), which was substantially larger, and supported many further efforts on Arabic morphological modeling. The PATB relied on the existence of the Buckwalter Morphological Analyzer (BAMA) (Buckwalter, 2004) and its later version the Standard Arabic Morphological Analyzer (SAMA) (Maamouri 3895 et al., 2010). Among such efforts, are MADAMIRA (Pasha et al., 2014) and it predecessors MADA (Habash and Rambow, 2005; Roth et al., 2008; Habash et al., 2009; Habash et al., 2013) and AMIRA (Diab et al., 2004; Diab et al., 2007). MADAMIRA uses a morphological analyzer and SVMsbased taggers for different features, along with n-gram language models for lemmatization and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approa"
2020.lrec-1.480,P06-1086,1,0.797895,"SVMsbased taggers for different features, along with n-gram language models for lemmatization and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approaches attempt to exploit linguistic similarity between MSA and Arabic dialects to build dialect tools using existing MSA resources (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Zribi et al., 2013; Salloum and Habash, 2014; Hamdi et al., 2015; Albogamy and Ramsay, 2015; Eskander et al., 2016). MAGEAD is a morphological analyzer that models Arabic dialects together with MSA using a common multi-tape finite-statemachine framework (Habash and Rambow, 2006). Zribi et al. (2013) adapt an MSA analyzer, Al-Khalil (Boudlal et al., 2010), to Tunisian Arabic, where they modify the derivation patterns and add Tunisian-specific roots and patterns. Eskander et al. (2016), on the other hand, presented a paradigm completion approach to generate morphological analyzers for low-reso"
2020.lrec-1.480,W12-2301,1,0.897501,"atemachine framework (Habash and Rambow, 2006). Zribi et al. (2013) adapt an MSA analyzer, Al-Khalil (Boudlal et al., 2010), to Tunisian Arabic, where they modify the derivation patterns and add Tunisian-specific roots and patterns. Eskander et al. (2016), on the other hand, presented a paradigm completion approach to generate morphological analyzers for low-resource dialects using morphologically annotated corpora. They then make use of available MSA and EGY analyzers as backoff. Dialect-Specific Contributions Al-Sabbagh and Girju (2012) presented a POS annotated data set and tagger for EGY. Habash et al. (2012) presented CALIMA, a morphological analyzer for EGY, which was built by extending the Egyptian Colloquial Arabic Lexicon (ECAL) (Kilany et al., 2002). The LDC has also released the EGY treebank (ARZATB) (Maamouri et al., 2012). The treebank is morphologically annotated in a similar style to the PATB. The aforementioned MADAMIRA and YAMAMA systems were extended to EGY using CALIMA (Habash et al., 2012) and ARZATB (Maamouri et al., 2012). Jarrar et al. (2014) released the Curras Corpus of Palestinian Arabic, also annotated in the PATB morphology style. Darwish et al. (2018) used a CRF model for"
2020.lrec-1.480,N13-1044,1,0.95339,"s presented by Khoja (2001); it was based on a corpus of 50,000 words. Later, the LDC released the Penn Arabic Treebank (PATB) (Maamouri et al., 2004), which was substantially larger, and supported many further efforts on Arabic morphological modeling. The PATB relied on the existence of the Buckwalter Morphological Analyzer (BAMA) (Buckwalter, 2004) and its later version the Standard Arabic Morphological Analyzer (SAMA) (Maamouri 3895 et al., 2010). Among such efforts, are MADAMIRA (Pasha et al., 2014) and it predecessors MADA (Habash and Rambow, 2005; Roth et al., 2008; Habash et al., 2009; Habash et al., 2013) and AMIRA (Diab et al., 2004; Diab et al., 2007). MADAMIRA uses a morphological analyzer and SVMsbased taggers for different features, along with n-gram language models for lemmatization and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approaches attempt to exploit linguistic similarity between MSA and"
2020.lrec-1.480,L18-1574,1,0.924835,"Missing"
2020.lrec-1.480,W15-3207,1,0.836895,"dels for lemmatization and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approaches attempt to exploit linguistic similarity between MSA and Arabic dialects to build dialect tools using existing MSA resources (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Zribi et al., 2013; Salloum and Habash, 2014; Hamdi et al., 2015; Albogamy and Ramsay, 2015; Eskander et al., 2016). MAGEAD is a morphological analyzer that models Arabic dialects together with MSA using a common multi-tape finite-statemachine framework (Habash and Rambow, 2006). Zribi et al. (2013) adapt an MSA analyzer, Al-Khalil (Boudlal et al., 2010), to Tunisian Arabic, where they modify the derivation patterns and add Tunisian-specific roots and patterns. Eskander et al. (2016), on the other hand, presented a paradigm completion approach to generate morphological analyzers for low-resource dialects using morphologically annotated corpora. They then m"
2020.lrec-1.480,K17-1042,0,0.0162359,"the segmentation of EGY tweets. They then build up on this approach using a similar architecture for segmentation in multiple dialects, through combining the training datasets for the different dialects, and train a unified segmentation model. They report the results using both an SVM-Rank and Bi-LSTM-CRF models (Samih et al., 2017b). Darwish et al. (2017) use Bi-LSTM models to train a POS tagger, and compared it against SVM-based model. The SVM model in their system outperformed the neural model, even with incorporating pre-trained embeddings. Other notable contributions include the work of Inoue et al. (2017), who used multi-task learning to model fine-grained POS tags, using the individual morphosyntactic features. More recently, Zalmout and Habash (2017) presented the first neural based full morphological disambiguation system for Arabic. Alharbi et al. (2018) also use a Bi-LSTM model for GLF POS tagging, with good results. In this work, we introduce the first morphological analysis and disambiguation system for GLF. We base our work on Zalmout and Habash (2019), and we use the data from Khalifa et al. (2018). 3. Relevant Linguistic Background Gulf Arabic We follow the definition of GLF mentione"
2020.lrec-1.480,W14-3603,1,0.840398,"GY analyzers as backoff. Dialect-Specific Contributions Al-Sabbagh and Girju (2012) presented a POS annotated data set and tagger for EGY. Habash et al. (2012) presented CALIMA, a morphological analyzer for EGY, which was built by extending the Egyptian Colloquial Arabic Lexicon (ECAL) (Kilany et al., 2002). The LDC has also released the EGY treebank (ARZATB) (Maamouri et al., 2012). The treebank is morphologically annotated in a similar style to the PATB. The aforementioned MADAMIRA and YAMAMA systems were extended to EGY using CALIMA (Habash et al., 2012) and ARZATB (Maamouri et al., 2012). Jarrar et al. (2014) released the Curras Corpus of Palestinian Arabic, also annotated in the PATB morphology style. Darwish et al. (2018) used a CRF model for a multi-dialect POS tagging, using a small annotated Twitter corpus for several dialects. Erdmann et al. (2019) developed a de-lexical segmentation tool for dialectal content. Their model is mainly unsupervised, relying on a small grammar of closed-class affixes. Alshargi et al. (2019) presented morphologically annotated corpora for seven different dialects. Regarding GLF specifically, Khalifa et al. (2017) presented a morphological analyzer for Gulf verbs,"
2020.lrec-1.480,L16-1679,1,0.675922,"(BAMA) (Buckwalter, 2004) and its later version the Standard Arabic Morphological Analyzer (SAMA) (Maamouri 3895 et al., 2010). Among such efforts, are MADAMIRA (Pasha et al., 2014) and it predecessors MADA (Habash and Rambow, 2005; Roth et al., 2008; Habash et al., 2009; Habash et al., 2013) and AMIRA (Diab et al., 2004; Diab et al., 2007). MADAMIRA uses a morphological analyzer and SVMsbased taggers for different features, along with n-gram language models for lemmatization and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approaches attempt to exploit linguistic similarity between MSA and Arabic dialects to build dialect tools using existing MSA resources (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Zribi et al., 2013; Salloum and Habash, 2014; Hamdi et al., 2015; Albogamy and Ramsay, 2015; Eskander et al., 2016). MAGEAD is a morphological analyzer that models Arabic dialects together with MSA using a c"
2020.lrec-1.480,C16-2047,1,0.701293,"(BAMA) (Buckwalter, 2004) and its later version the Standard Arabic Morphological Analyzer (SAMA) (Maamouri 3895 et al., 2010). Among such efforts, are MADAMIRA (Pasha et al., 2014) and it predecessors MADA (Habash and Rambow, 2005; Roth et al., 2008; Habash et al., 2009; Habash et al., 2013) and AMIRA (Diab et al., 2004; Diab et al., 2007). MADAMIRA uses a morphological analyzer and SVMsbased taggers for different features, along with n-gram language models for lemmatization and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approaches attempt to exploit linguistic similarity between MSA and Arabic dialects to build dialect tools using existing MSA resources (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Zribi et al., 2013; Salloum and Habash, 2014; Hamdi et al., 2015; Albogamy and Ramsay, 2015; Eskander et al., 2016). MAGEAD is a morphological analyzer that models Arabic dialects together with MSA using a c"
2020.lrec-1.480,W17-1305,1,0.851684,"h et al., 2012) and ARZATB (Maamouri et al., 2012). Jarrar et al. (2014) released the Curras Corpus of Palestinian Arabic, also annotated in the PATB morphology style. Darwish et al. (2018) used a CRF model for a multi-dialect POS tagging, using a small annotated Twitter corpus for several dialects. Erdmann et al. (2019) developed a de-lexical segmentation tool for dialectal content. Their model is mainly unsupervised, relying on a small grammar of closed-class affixes. Alshargi et al. (2019) presented morphologically annotated corpora for seven different dialects. Regarding GLF specifically, Khalifa et al. (2017) presented a morphological analyzer for Gulf verbs, covering segmentation, POS, and lemmatization details for Gulf verbal paradigms. Khalifa et al. (2018) also presented a largescale morphologically annotated corpus of Emirati Arabic, extracted from online novels, with about 200K words. The annotation includes tokenization, POS, lemmatization, English glosses and dialect identification, as the corpus includes traces of other dialects, along with MSA content. So far, the mentioned efforts regarding disambiguation suffer from two main issues. First, they require explicit feature engineering whic"
2020.lrec-1.480,L18-1607,1,0.872268,"hology style. Darwish et al. (2018) used a CRF model for a multi-dialect POS tagging, using a small annotated Twitter corpus for several dialects. Erdmann et al. (2019) developed a de-lexical segmentation tool for dialectal content. Their model is mainly unsupervised, relying on a small grammar of closed-class affixes. Alshargi et al. (2019) presented morphologically annotated corpora for seven different dialects. Regarding GLF specifically, Khalifa et al. (2017) presented a morphological analyzer for Gulf verbs, covering segmentation, POS, and lemmatization details for Gulf verbal paradigms. Khalifa et al. (2018) also presented a largescale morphologically annotated corpus of Emirati Arabic, extracted from online novels, with about 200K words. The annotation includes tokenization, POS, lemmatization, English glosses and dialect identification, as the corpus includes traces of other dialects, along with MSA content. So far, the mentioned efforts regarding disambiguation suffer from two main issues. First, they require explicit feature engineering which can lead to over fitting and not being able to generalize to new dialects. Second, those systems rely heavily on pre-existing morphological analyzers to"
2020.lrec-1.480,W14-3605,1,0.881877,"Missing"
2020.lrec-1.480,L18-1415,1,0.882231,"Missing"
2020.lrec-1.480,pasha-etal-2014-madamira,1,0.952477,". Modern Standard Arabic Morphological Modeling One of the earliest morphological tagging systems for Arabic was presented by Khoja (2001); it was based on a corpus of 50,000 words. Later, the LDC released the Penn Arabic Treebank (PATB) (Maamouri et al., 2004), which was substantially larger, and supported many further efforts on Arabic morphological modeling. The PATB relied on the existence of the Buckwalter Morphological Analyzer (BAMA) (Buckwalter, 2004) and its later version the Standard Arabic Morphological Analyzer (SAMA) (Maamouri 3895 et al., 2010). Among such efforts, are MADAMIRA (Pasha et al., 2014) and it predecessors MADA (Habash and Rambow, 2005; Roth et al., 2008; Habash et al., 2009; Habash et al., 2013) and AMIRA (Diab et al., 2004; Diab et al., 2007). MADAMIRA uses a morphological analyzer and SVMsbased taggers for different features, along with n-gram language models for lemmatization and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and"
2020.lrec-1.480,P08-2030,1,0.827775,"phological tagging systems for Arabic was presented by Khoja (2001); it was based on a corpus of 50,000 words. Later, the LDC released the Penn Arabic Treebank (PATB) (Maamouri et al., 2004), which was substantially larger, and supported many further efforts on Arabic morphological modeling. The PATB relied on the existence of the Buckwalter Morphological Analyzer (BAMA) (Buckwalter, 2004) and its later version the Standard Arabic Morphological Analyzer (SAMA) (Maamouri 3895 et al., 2010). Among such efforts, are MADAMIRA (Pasha et al., 2014) and it predecessors MADA (Habash and Rambow, 2005; Roth et al., 2008; Habash et al., 2009; Habash et al., 2013) and AMIRA (Diab et al., 2004; Diab et al., 2007). MADAMIRA uses a morphological analyzer and SVMsbased taggers for different features, along with n-gram language models for lemmatization and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approaches attempt to exp"
2020.lrec-1.480,P06-1001,1,0.670113,"analyzers with respect to the disambiguation model. The rest of the paper is structured as follows. We present related work in Section 2, and briefly discuss the linguistic background of GLF and its challenges in Section 3. We present the morphological analyzer creation process in Section 4. In Sections 5 and 6, we present our experimental setup and evaluation, respectively. We conclude and outline future work in Section 7. 2. Related Work In the past two decades, there have been a lot of efforts on morphological modeling for Arabic, as it proved to be useful in a number downstream NLP tasks (Sadat and Habash, 2006; El Kholy and Habash, 2012; Halabi, 2016; Baly et al., 2017). In this section we review early efforts on morphological modeling of MSA and dialectal Arabic. We then present the latest neural-based contributions with special interest in Arabic. Modern Standard Arabic Morphological Modeling One of the earliest morphological tagging systems for Arabic was presented by Khoja (2001); it was based on a corpus of 50,000 words. Later, the LDC released the Penn Arabic Treebank (PATB) (Maamouri et al., 2004), which was substantially larger, and supported many further efforts on Arabic morphological mod"
2020.lrec-1.480,W17-1306,0,0.0159721,"and specific to individual tasks rather than full morphological disambiguation. Among the contributions that utilize morphological structures to enhance the neural models in different NLP tasks, we note Guzmán et al. (2016) for machine translation, and Abandah et al. (2015) for diacritization. Shen et al. (2016) applied their Bi-LSTM morphological disambiguation model on MSA, but did not present any improvements over the state-of-the-art. Heigold et al. (2016) developed character-based neural models for morphological tagging for 14 different languages, including Arabic, using the UD treebank. Samih et al. (2017a) used a Bi-LSTM-CRF architecture and pre-trained character embeddings for the segmentation of EGY tweets. They then build up on this approach using a similar architecture for segmentation in multiple dialects, through combining the training datasets for the different dialects, and train a unified segmentation model. They report the results using both an SVM-Rank and Bi-LSTM-CRF models (Samih et al., 2017b). Darwish et al. (2017) use Bi-LSTM models to train a POS tagger, and compared it against SVM-based model. The SVM model in their system outperformed the neural model, even with incorporati"
2020.lrec-1.480,K17-1043,0,0.0127769,"and specific to individual tasks rather than full morphological disambiguation. Among the contributions that utilize morphological structures to enhance the neural models in different NLP tasks, we note Guzmán et al. (2016) for machine translation, and Abandah et al. (2015) for diacritization. Shen et al. (2016) applied their Bi-LSTM morphological disambiguation model on MSA, but did not present any improvements over the state-of-the-art. Heigold et al. (2016) developed character-based neural models for morphological tagging for 14 different languages, including Arabic, using the UD treebank. Samih et al. (2017a) used a Bi-LSTM-CRF architecture and pre-trained character embeddings for the segmentation of EGY tweets. They then build up on this approach using a similar architecture for segmentation in multiple dialects, through combining the training datasets for the different dialects, and train a unified segmentation model. They report the results using both an SVM-Rank and Bi-LSTM-CRF models (Samih et al., 2017b). Darwish et al. (2017) use Bi-LSTM models to train a POS tagger, and compared it against SVM-based model. The SVM model in their system outperformed the neural model, even with incorporati"
2020.lrec-1.480,C16-1018,0,0.0217967,"such as lemmas. In this work we use state-of-the-art neural architectures that have the ability to model morphologically rich and complex languages such as Arabic and its different verities. Neural-based contributions for Arabic Morphology Neural-based contributions for Arabic NLP are relatively scarce and specific to individual tasks rather than full morphological disambiguation. Among the contributions that utilize morphological structures to enhance the neural models in different NLP tasks, we note Guzmán et al. (2016) for machine translation, and Abandah et al. (2015) for diacritization. Shen et al. (2016) applied their Bi-LSTM morphological disambiguation model on MSA, but did not present any improvements over the state-of-the-art. Heigold et al. (2016) developed character-based neural models for morphological tagging for 14 different languages, including Arabic, using the UD treebank. Samih et al. (2017a) used a Bi-LSTM-CRF architecture and pre-trained character embeddings for the segmentation of EGY tweets. They then build up on this approach using a similar architecture for segmentation in multiple dialects, through combining the training datasets for the different dialects, and train a uni"
2020.lrec-1.480,D18-1097,1,0.882059,"Missing"
2020.lrec-1.480,D17-1073,1,0.878484,"combining the training datasets for the different dialects, and train a unified segmentation model. They report the results using both an SVM-Rank and Bi-LSTM-CRF models (Samih et al., 2017b). Darwish et al. (2017) use Bi-LSTM models to train a POS tagger, and compared it against SVM-based model. The SVM model in their system outperformed the neural model, even with incorporating pre-trained embeddings. Other notable contributions include the work of Inoue et al. (2017), who used multi-task learning to model fine-grained POS tags, using the individual morphosyntactic features. More recently, Zalmout and Habash (2017) presented the first neural based full morphological disambiguation system for Arabic. Alharbi et al. (2018) also use a Bi-LSTM model for GLF POS tagging, with good results. In this work, we introduce the first morphological analysis and disambiguation system for GLF. We base our work on Zalmout and Habash (2019), and we use the data from Khalifa et al. (2018). 3. Relevant Linguistic Background Gulf Arabic We follow the definition of GLF mentioned in (Khalifa et al., 2016a), as the variety of Arabic spoken by indigenous populations residing the six countries of the Gulf Cooperation Council (GC"
2020.lrec-1.480,I13-1133,0,0.0262245,"ferent features, along with n-gram language models for lemmatization and diacritization. More recent efforts include Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) and YAMAMA (Khalifa et al., 2016b), which are out-of-context taggers/segmenters that use different techniques to achieve reasonable performance and fast running time. Adaptation of MSA Tools and Resources for Dialectal Arabic A number of approaches attempt to exploit linguistic similarity between MSA and Arabic dialects to build dialect tools using existing MSA resources (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Zribi et al., 2013; Salloum and Habash, 2014; Hamdi et al., 2015; Albogamy and Ramsay, 2015; Eskander et al., 2016). MAGEAD is a morphological analyzer that models Arabic dialects together with MSA using a common multi-tape finite-statemachine framework (Habash and Rambow, 2006). Zribi et al. (2013) adapt an MSA analyzer, Al-Khalil (Boudlal et al., 2010), to Tunisian Arabic, where they modify the derivation patterns and add Tunisian-specific roots and patterns. Eskander et al. (2016), on the other hand, presented a paradigm completion approach to generate morphological analyzers for low-resource dialects using"
2020.lrec-1.508,L18-1577,0,0.0183933,".com/ 4130 2. Related Work Automatic DA processing has been attracting a considerable amount of research in NLP (Shoufan and Al-Ameri, 2015), facilitated by the newly developed monolingual and multilingual dialectal corpora. Several mono-dialectal corpora covering different Arabic dialects at different granularity levels (region, country and city levels) were built and made available (McNeil and Faiza, 2011; Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Badrashiny and Diab, 2016; Zaghouani and Charfi, 2018; Abdul-Mageed et al., 2018). As for dialect-to-dialect parallel corpora, Bouamor et al. (2018) presented the MADAR Corpus, a large-scale collection of parallel sentences covering the dialects of 25 Arab cities alongside the English, French and MSA parallel texts. This resource was a commissioned translation of the Basic Traveling Expression Corpus (BTEC) (Takezawa et al., 2007) sentences from English and French to the different dialects. It includes two corpora. The first corpus (Corpus-26) consists of 2,000 sentences translated into 25 Arab city dialects in parallel. The second corpus (Corpus6) has 10,000 additional se"
2020.lrec-1.508,C16-1115,0,0.0123356,"pelling conventionalization”. 2 http://resources.camel-lab.com/ 4130 2. Related Work Automatic DA processing has been attracting a considerable amount of research in NLP (Shoufan and Al-Ameri, 2015), facilitated by the newly developed monolingual and multilingual dialectal corpora. Several mono-dialectal corpora covering different Arabic dialects at different granularity levels (region, country and city levels) were built and made available (McNeil and Faiza, 2011; Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Badrashiny and Diab, 2016; Zaghouani and Charfi, 2018; Abdul-Mageed et al., 2018). As for dialect-to-dialect parallel corpora, Bouamor et al. (2018) presented the MADAR Corpus, a large-scale collection of parallel sentences covering the dialects of 25 Arab cities alongside the English, French and MSA parallel texts. This resource was a commissioned translation of the Basic Traveling Expression Corpus (BTEC) (Takezawa et al., 2007) sentences from English and French to the different dialects. It includes two corpora. The first corpus (Corpus-26) consists of 2,000 sentences translated into 25 Arab city dialects in parall"
2020.lrec-1.508,W14-1604,1,0.86826,"ts have been introduced to modernize and extend Arabic orthography and develop orthographic conventions for Arabic dialects. Habash et al. (2012) introduced the concept of Conventional Orthography for Dialectal Arabic (CODA), the very first effort to present a set of guidelines and exception lists for Egyptian Arabic orthography. Although the first CODA was developed for Egyptian Arabic, it was designed with extensibility in mind. As Egyptian CODA began to be integrated into several Egyptian Arabic resources (Maamouri et al., 2014; Diab et al., 2014; Pasha et al., 2014; Eskander et al., 2013; Al-Badrashiny et al., 2014), other efforts began to extend CODA’s coverage into new dialects. 2014 saw the creation of two additional guidelines, Tunisian CODA (Zribi et al., 2014) and Palestinian CODA (Jarrar et al., 2014). Using a variant of CODA adopted for speech recognition, Ali et al. (2014) demonstrated reduced out of vocabulary (OOV) and perplexity for texts rendered in CODA. More dialects have followed since then, with the creation of Algerian CODA (Saadane and Habash, 2015), Moroccan CODA and Yemeni CODA(AlShargi et al., 2016), and Gulf CODA (Khalifa et al., 2018). More recently, CODA has garnered the interest"
2020.lrec-1.508,2014.iwslt-papers.1,0,0.00968304,"d exception lists for Egyptian Arabic orthography. Although the first CODA was developed for Egyptian Arabic, it was designed with extensibility in mind. As Egyptian CODA began to be integrated into several Egyptian Arabic resources (Maamouri et al., 2014; Diab et al., 2014; Pasha et al., 2014; Eskander et al., 2013; Al-Badrashiny et al., 2014), other efforts began to extend CODA’s coverage into new dialects. 2014 saw the creation of two additional guidelines, Tunisian CODA (Zribi et al., 2014) and Palestinian CODA (Jarrar et al., 2014). Using a variant of CODA adopted for speech recognition, Ali et al. (2014) demonstrated reduced out of vocabulary (OOV) and perplexity for texts rendered in CODA. More dialects have followed since then, with the creation of Algerian CODA (Saadane and Habash, 2015), Moroccan CODA and Yemeni CODA(AlShargi et al., 2016), and Gulf CODA (Khalifa et al., 2018). More recently, CODA has garnered the interest of literacy, pedagogy, and heritage specialists as a convenient orthographic standard, such as a website that teaches Palestinian Arabic,3 amongst others. These efforts were unified in overall principles, namely in how to spell open class words. But during creation of t"
2020.lrec-1.508,L18-1535,1,0.896504,"ional Orthography for Dialectal Arabic (CODA) (Habash et al., 2012; Jarrar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Khalifa et al., 2016; Habash et al., 2018). The majority of resources involving CODA annotation consider it a side task to efforts like morphological disambiguation, diacritization and lemmatization, as opposed to being the main target task (CODA for CODA). In this paper, we explore and report on the task of CODA annotation, i.e., spelling correction into the CODA convention.1 We work with a unique corpus of parallel multiple Arabic dialects, the MADAR Corpus (Bouamor et al., 2018), focusing on five cities: Beirut, Cairo, Doha, Rabat and Tunis. Our contributions are threefold. First, we created a parallel CODA version of a parallel multi-dialectal corpus, a unique resource, first of its kind. Second, we describe and follow a bootstrapping technique for CODA creation, and we report on its speed and initial accuracy under different pre-existing resource settings. Finally, we quantify the degrees of similarity across the dialects we work on using the annotated data in both Raw and CODA spaces. As expected CODA reduces the overall vocabulary within dialects and increases th"
2020.lrec-1.508,W19-4622,1,0.759668,"ext normalization for Arabic dialects. We present results on a bootstrapping technique we use to speed up the CODA annotation, as well as on the degree of similarity across the dialects before and after CODA annotation. Keywords: Dialects, Corpora, Spelling Correction, Conventional Orthography for Dialectal Arabic 1. Introduction While the standard form of any language is the variety most likely to receive attention from natural language processing (NLP) researchers and developers, more research is on the rise to address the needs of non-standard varieties and dialects (Zampieri et al., 2019; Bouamor et al., 2019). The Arabic language, spoken by over 400 million people, is in fact a collective of multiple variants, among which Modern Standard Arabic (MSA) is considered the official primarily written variety of education and culture, even though it is not the native language of any speakers. The other variants are known collectively as Dialectal Arabic (DA), but often classified regionally (as Egyptian, North African, Levantine, Gulf, Yemeni) or sub-regionally (i.e, Tunisian, Moroccan, Lebanese, and Qatari). Arabic dialects are the true native languages historically connected to Classical Arabic and man"
2020.lrec-1.508,cotterell-callison-burch-2014-multi,0,0.013415,"rpose, we find the term “spelling correction” in a NLP context clearer than “spelling conventionalization”. 2 http://resources.camel-lab.com/ 4130 2. Related Work Automatic DA processing has been attracting a considerable amount of research in NLP (Shoufan and Al-Ameri, 2015), facilitated by the newly developed monolingual and multilingual dialectal corpora. Several mono-dialectal corpora covering different Arabic dialects at different granularity levels (region, country and city levels) were built and made available (McNeil and Faiza, 2011; Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Badrashiny and Diab, 2016; Zaghouani and Charfi, 2018; Abdul-Mageed et al., 2018). As for dialect-to-dialect parallel corpora, Bouamor et al. (2018) presented the MADAR Corpus, a large-scale collection of parallel sentences covering the dialects of 25 Arab cities alongside the English, French and MSA parallel texts. This resource was a commissioned translation of the Basic Traveling Expression Corpus (BTEC) (Takezawa et al., 2007) sentences from English and French to the different dialects. It includes two corpora. The first corpus (Corpus-26) con"
2020.lrec-1.508,diab-etal-2014-tharwa,1,0.838048,"and applications. To alleviate this bottleneck, several efforts have been introduced to modernize and extend Arabic orthography and develop orthographic conventions for Arabic dialects. Habash et al. (2012) introduced the concept of Conventional Orthography for Dialectal Arabic (CODA), the very first effort to present a set of guidelines and exception lists for Egyptian Arabic orthography. Although the first CODA was developed for Egyptian Arabic, it was designed with extensibility in mind. As Egyptian CODA began to be integrated into several Egyptian Arabic resources (Maamouri et al., 2014; Diab et al., 2014; Pasha et al., 2014; Eskander et al., 2013; Al-Badrashiny et al., 2014), other efforts began to extend CODA’s coverage into new dialects. 2014 saw the creation of two additional guidelines, Tunisian CODA (Zribi et al., 2014) and Palestinian CODA (Jarrar et al., 2014). Using a variant of CODA adopted for speech recognition, Ali et al. (2014) demonstrated reduced out of vocabulary (OOV) and perplexity for texts rendered in CODA. More dialects have followed since then, with the creation of Algerian CODA (Saadane and Habash, 2015), Moroccan CODA and Yemeni CODA(AlShargi et al., 2016), and Gulf CO"
2020.lrec-1.508,N13-1066,1,0.929863,"ttleneck, several efforts have been introduced to modernize and extend Arabic orthography and develop orthographic conventions for Arabic dialects. Habash et al. (2012) introduced the concept of Conventional Orthography for Dialectal Arabic (CODA), the very first effort to present a set of guidelines and exception lists for Egyptian Arabic orthography. Although the first CODA was developed for Egyptian Arabic, it was designed with extensibility in mind. As Egyptian CODA began to be integrated into several Egyptian Arabic resources (Maamouri et al., 2014; Diab et al., 2014; Pasha et al., 2014; Eskander et al., 2013; Al-Badrashiny et al., 2014), other efforts began to extend CODA’s coverage into new dialects. 2014 saw the creation of two additional guidelines, Tunisian CODA (Zribi et al., 2014) and Palestinian CODA (Jarrar et al., 2014). Using a variant of CODA adopted for speech recognition, Ali et al. (2014) demonstrated reduced out of vocabulary (OOV) and perplexity for texts rendered in CODA. More dialects have followed since then, with the creation of Algerian CODA (Saadane and Habash, 2015), Moroccan CODA and Yemeni CODA(AlShargi et al., 2016), and Gulf CODA (Khalifa et al., 2018). More recently, C"
2020.lrec-1.508,habash-etal-2012-conventional,1,0.893253,"he degree of sparsity in the data. Such noise can be handled using modeling techniques that normalize and cluster variants if DA is the input to the system, e.g. in machine translation from dialects to other languages. However, when the dialect is the target output, as in speech recognition systems (Ali, 2018), or machine translation into the dialects (Erdmann et al., 2017), evaluation and thus optimization may struggle. A number of efforts in Arabic NLP have argued for the creation of a common convention for Arabic dialect spelling, named Conventional Orthography for Dialectal Arabic (CODA) (Habash et al., 2012; Jarrar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Khalifa et al., 2016; Habash et al., 2018). The majority of resources involving CODA annotation consider it a side task to efforts like morphological disambiguation, diacritization and lemmatization, as opposed to being the main target task (CODA for CODA). In this paper, we explore and report on the task of CODA annotation, i.e., spelling correction into the CODA convention.1 We work with a unique corpus of parallel multiple Arabic dialects, the MADAR Corpus (Bouamor et al., 2018), focusing on five cities: Beirut, Cairo, Doh"
2020.lrec-1.508,L18-1574,1,0.897446,"as Dialectal Arabic (DA), but often classified regionally (as Egyptian, North African, Levantine, Gulf, Yemeni) or sub-regionally (i.e, Tunisian, Moroccan, Lebanese, and Qatari). Arabic dialects are the true native languages historically connected to Classical Arabic and many other regional languages. These dialects are primarily spoken, though their dominance on social media is on the rise. Lacking official recognition, they do not have standard orthographies. As a result, dialectal text tends to have a lot of variety and noise (from a computational linguistics point of view). For instance, Habash et al. (2018) reported 27 different spellings for the Egyptian Arabic utterance /mabiPulha:S/ “he does not say it”, that vary in terms of etymological or phonetic spelling decisions. This high degree of noise is a major challenge for NLP system development as it increases the degree of sparsity in the data. Such noise can be handled using modeling techniques that normalize and cluster variants if DA is the input to the system, e.g. in machine translation from dialects to other languages. However, when the dialect is the target output, as in speech recognition systems (Ali, 2018), or machine translation int"
2020.lrec-1.508,W14-3603,1,0.959932,"in the data. Such noise can be handled using modeling techniques that normalize and cluster variants if DA is the input to the system, e.g. in machine translation from dialects to other languages. However, when the dialect is the target output, as in speech recognition systems (Ali, 2018), or machine translation into the dialects (Erdmann et al., 2017), evaluation and thus optimization may struggle. A number of efforts in Arabic NLP have argued for the creation of a common convention for Arabic dialect spelling, named Conventional Orthography for Dialectal Arabic (CODA) (Habash et al., 2012; Jarrar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Khalifa et al., 2016; Habash et al., 2018). The majority of resources involving CODA annotation consider it a side task to efforts like morphological disambiguation, diacritization and lemmatization, as opposed to being the main target task (CODA for CODA). In this paper, we explore and report on the task of CODA annotation, i.e., spelling correction into the CODA convention.1 We work with a unique corpus of parallel multiple Arabic dialects, the MADAR Corpus (Bouamor et al., 2018), focusing on five cities: Beirut, Cairo, Doha, Rabat and Tunis. O"
2020.lrec-1.508,W14-3627,1,0.840234,"ntext clearer than “spelling conventionalization”. 2 http://resources.camel-lab.com/ 4130 2. Related Work Automatic DA processing has been attracting a considerable amount of research in NLP (Shoufan and Al-Ameri, 2015), facilitated by the newly developed monolingual and multilingual dialectal corpora. Several mono-dialectal corpora covering different Arabic dialects at different granularity levels (region, country and city levels) were built and made available (McNeil and Faiza, 2011; Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Badrashiny and Diab, 2016; Zaghouani and Charfi, 2018; Abdul-Mageed et al., 2018). As for dialect-to-dialect parallel corpora, Bouamor et al. (2018) presented the MADAR Corpus, a large-scale collection of parallel sentences covering the dialects of 25 Arab cities alongside the English, French and MSA parallel texts. This resource was a commissioned translation of the Basic Traveling Expression Corpus (BTEC) (Takezawa et al., 2007) sentences from English and French to the different dialects. It includes two corpora. The first corpus (Corpus-26) consists of 2,000 sentences translated into 2"
2020.lrec-1.508,L16-1679,1,0.896251,"hat normalize and cluster variants if DA is the input to the system, e.g. in machine translation from dialects to other languages. However, when the dialect is the target output, as in speech recognition systems (Ali, 2018), or machine translation into the dialects (Erdmann et al., 2017), evaluation and thus optimization may struggle. A number of efforts in Arabic NLP have argued for the creation of a common convention for Arabic dialect spelling, named Conventional Orthography for Dialectal Arabic (CODA) (Habash et al., 2012; Jarrar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Khalifa et al., 2016; Habash et al., 2018). The majority of resources involving CODA annotation consider it a side task to efforts like morphological disambiguation, diacritization and lemmatization, as opposed to being the main target task (CODA for CODA). In this paper, we explore and report on the task of CODA annotation, i.e., spelling correction into the CODA convention.1 We work with a unique corpus of parallel multiple Arabic dialects, the MADAR Corpus (Bouamor et al., 2018), focusing on five cities: Beirut, Cairo, Doha, Rabat and Tunis. Our contributions are threefold. First, we created a parallel CODA ve"
2020.lrec-1.508,L18-1607,1,0.958153,"sha et al., 2014; Eskander et al., 2013; Al-Badrashiny et al., 2014), other efforts began to extend CODA’s coverage into new dialects. 2014 saw the creation of two additional guidelines, Tunisian CODA (Zribi et al., 2014) and Palestinian CODA (Jarrar et al., 2014). Using a variant of CODA adopted for speech recognition, Ali et al. (2014) demonstrated reduced out of vocabulary (OOV) and perplexity for texts rendered in CODA. More dialects have followed since then, with the creation of Algerian CODA (Saadane and Habash, 2015), Moroccan CODA and Yemeni CODA(AlShargi et al., 2016), and Gulf CODA (Khalifa et al., 2018). More recently, CODA has garnered the interest of literacy, pedagogy, and heritage specialists as a convenient orthographic standard, such as a website that teaches Palestinian Arabic,3 amongst others. These efforts were unified in overall principles, namely in how to spell open class words. But during creation of these CODA extensions, each dialect tended to curate its own list of exceptional spellings for closed class words. With the growing number of dialects being incorporated, Habash et al. (2018) presented a more Unified Guidelines and Resources for Arabic Dialect Orthography — dubbed C"
2020.lrec-1.508,maamouri-etal-2014-developing,1,0.845875,"ing efficient NLP tools and applications. To alleviate this bottleneck, several efforts have been introduced to modernize and extend Arabic orthography and develop orthographic conventions for Arabic dialects. Habash et al. (2012) introduced the concept of Conventional Orthography for Dialectal Arabic (CODA), the very first effort to present a set of guidelines and exception lists for Egyptian Arabic orthography. Although the first CODA was developed for Egyptian Arabic, it was designed with extensibility in mind. As Egyptian CODA began to be integrated into several Egyptian Arabic resources (Maamouri et al., 2014; Diab et al., 2014; Pasha et al., 2014; Eskander et al., 2013; Al-Badrashiny et al., 2014), other efforts began to extend CODA’s coverage into new dialects. 2014 saw the creation of two additional guidelines, Tunisian CODA (Zribi et al., 2014) and Palestinian CODA (Jarrar et al., 2014). Using a variant of CODA adopted for speech recognition, Ali et al. (2014) demonstrated reduced out of vocabulary (OOV) and perplexity for texts rendered in CODA. More dialects have followed since then, with the creation of Algerian CODA (Saadane and Habash, 2015), Moroccan CODA and Yemeni CODA(AlShargi et al.,"
2020.lrec-1.508,W14-3605,1,0.878926,"losed class spelling in more detail and unifying the CODA creation process. CODA* has since been used to represent over two dozen Arabic dialects. It is worth noting that in recent years, the problem of spell checking and spelling error correction for Arabic has been investigated in a number of research effort (Attia et al., 2016; Watson et al., 2018). The QALB (Qatar Arabic Language Bank) project (Zaghouani et al., 2014) aimed at building an annotated corpus of manually corrected MSA text for building automatic correction tools, and it was used in two shared tasks on MSA spelling correction (Mohit et al., 2014; Rozovskaya et al., 2015). 3. 3.1. CODA: Conventional Orthography for Dialectal Arabic The Orthography of Arabic and its Dialects As mentioned in the introduction, Arabic is a family of variants, among which MSA is the official standard language. However, MSA is not the native language of any speakers of Arabic. In unscripted situations where spoken MSA would typically be required (such as talk shows on TV), speakers usually resort to repeated code-switching between their dialects and MSA (Abu-Melhim, 1991; Bassiouney, 2009). Arabic dialects vary phonologically, lexically, and morphologically"
2020.lrec-1.508,pasha-etal-2014-madamira,1,0.846361,"To alleviate this bottleneck, several efforts have been introduced to modernize and extend Arabic orthography and develop orthographic conventions for Arabic dialects. Habash et al. (2012) introduced the concept of Conventional Orthography for Dialectal Arabic (CODA), the very first effort to present a set of guidelines and exception lists for Egyptian Arabic orthography. Although the first CODA was developed for Egyptian Arabic, it was designed with extensibility in mind. As Egyptian CODA began to be integrated into several Egyptian Arabic resources (Maamouri et al., 2014; Diab et al., 2014; Pasha et al., 2014; Eskander et al., 2013; Al-Badrashiny et al., 2014), other efforts began to extend CODA’s coverage into new dialects. 2014 saw the creation of two additional guidelines, Tunisian CODA (Zribi et al., 2014) and Palestinian CODA (Jarrar et al., 2014). Using a variant of CODA adopted for speech recognition, Ali et al. (2014) demonstrated reduced out of vocabulary (OOV) and perplexity for texts rendered in CODA. More dialects have followed since then, with the creation of Algerian CODA (Saadane and Habash, 2015), Moroccan CODA and Yemeni CODA(AlShargi et al., 2016), and Gulf CODA (Khalifa et al.,"
2020.lrec-1.508,W15-3204,1,0.771221,"in more detail and unifying the CODA creation process. CODA* has since been used to represent over two dozen Arabic dialects. It is worth noting that in recent years, the problem of spell checking and spelling error correction for Arabic has been investigated in a number of research effort (Attia et al., 2016; Watson et al., 2018). The QALB (Qatar Arabic Language Bank) project (Zaghouani et al., 2014) aimed at building an annotated corpus of manually corrected MSA text for building automatic correction tools, and it was used in two shared tasks on MSA spelling correction (Mohit et al., 2014; Rozovskaya et al., 2015). 3. 3.1. CODA: Conventional Orthography for Dialectal Arabic The Orthography of Arabic and its Dialects As mentioned in the introduction, Arabic is a family of variants, among which MSA is the official standard language. However, MSA is not the native language of any speakers of Arabic. In unscripted situations where spoken MSA would typically be required (such as talk shows on TV), speakers usually resort to repeated code-switching between their dialects and MSA (Abu-Melhim, 1991; Bassiouney, 2009). Arabic dialects vary phonologically, lexically, and morphologically from MSA and from each ot"
2020.lrec-1.508,W15-3208,1,0.943213,"sing modeling techniques that normalize and cluster variants if DA is the input to the system, e.g. in machine translation from dialects to other languages. However, when the dialect is the target output, as in speech recognition systems (Ali, 2018), or machine translation into the dialects (Erdmann et al., 2017), evaluation and thus optimization may struggle. A number of efforts in Arabic NLP have argued for the creation of a common convention for Arabic dialect spelling, named Conventional Orthography for Dialectal Arabic (CODA) (Habash et al., 2012; Jarrar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Khalifa et al., 2016; Habash et al., 2018). The majority of resources involving CODA annotation consider it a side task to efforts like morphological disambiguation, diacritization and lemmatization, as opposed to being the main target task (CODA for CODA). In this paper, we explore and report on the task of CODA annotation, i.e., spelling correction into the CODA convention.1 We work with a unique corpus of parallel multiple Arabic dialects, the MADAR Corpus (Bouamor et al., 2018), focusing on five cities: Beirut, Cairo, Doha, Rabat and Tunis. Our contributions are threefold. First, we crea"
2020.lrec-1.508,salama-etal-2014-youdacc,1,0.839767,"rrection” in a NLP context clearer than “spelling conventionalization”. 2 http://resources.camel-lab.com/ 4130 2. Related Work Automatic DA processing has been attracting a considerable amount of research in NLP (Shoufan and Al-Ameri, 2015), facilitated by the newly developed monolingual and multilingual dialectal corpora. Several mono-dialectal corpora covering different Arabic dialects at different granularity levels (region, country and city levels) were built and made available (McNeil and Faiza, 2011; Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Badrashiny and Diab, 2016; Zaghouani and Charfi, 2018; Abdul-Mageed et al., 2018). As for dialect-to-dialect parallel corpora, Bouamor et al. (2018) presented the MADAR Corpus, a large-scale collection of parallel sentences covering the dialects of 25 Arab cities alongside the English, French and MSA parallel texts. This resource was a commissioned translation of the Basic Traveling Expression Corpus (BTEC) (Takezawa et al., 2007) sentences from English and French to the different dialects. It includes two corpora. The first corpus (Corpus-26) consists of 2,000 senten"
2020.lrec-1.508,W15-3205,0,0.0127336,"that the term “spelling correction” evokes a claim of an “official standard,” we observe that there are no authorities interested in creating such a standard in the Arab world. And given the growing number of NLP papers and tools working with CODA, it is slowly becoming the de facto standard, at least for NLP. Finally, for the sake of clarity of purpose, we find the term “spelling correction” in a NLP context clearer than “spelling conventionalization”. 2 http://resources.camel-lab.com/ 4130 2. Related Work Automatic DA processing has been attracting a considerable amount of research in NLP (Shoufan and Al-Ameri, 2015), facilitated by the newly developed monolingual and multilingual dialectal corpora. Several mono-dialectal corpora covering different Arabic dialects at different granularity levels (region, country and city levels) were built and made available (McNeil and Faiza, 2011; Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Badrashiny and Diab, 2016; Zaghouani and Charfi, 2018; Abdul-Mageed et al., 2018). As for dialect-to-dialect parallel corpora, Bouamor et al. (2018) presented the MADAR Corpus, a large-scale coll"
2020.lrec-1.508,D18-1097,1,0.800849,"exceptional spellings for closed class words. With the growing number of dialects being incorporated, Habash et al. (2018) presented a more Unified Guidelines and Resources for Arabic Dialect Orthography — dubbed CODA* (CODA-Star) as in for any dialect — specifying closed class spelling in more detail and unifying the CODA creation process. CODA* has since been used to represent over two dozen Arabic dialects. It is worth noting that in recent years, the problem of spell checking and spelling error correction for Arabic has been investigated in a number of research effort (Attia et al., 2016; Watson et al., 2018). The QALB (Qatar Arabic Language Bank) project (Zaghouani et al., 2014) aimed at building an annotated corpus of manually corrected MSA text for building automatic correction tools, and it was used in two shared tasks on MSA spelling correction (Mohit et al., 2014; Rozovskaya et al., 2015). 3. 3.1. CODA: Conventional Orthography for Dialectal Arabic The Orthography of Arabic and its Dialects As mentioned in the introduction, Arabic is a family of variants, among which MSA is the official standard language. However, MSA is not the native language of any speakers of Arabic. In unscripted situat"
2020.lrec-1.508,L18-1111,0,0.0169579,"2 http://resources.camel-lab.com/ 4130 2. Related Work Automatic DA processing has been attracting a considerable amount of research in NLP (Shoufan and Al-Ameri, 2015), facilitated by the newly developed monolingual and multilingual dialectal corpora. Several mono-dialectal corpora covering different Arabic dialects at different granularity levels (region, country and city levels) were built and made available (McNeil and Faiza, 2011; Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Badrashiny and Diab, 2016; Zaghouani and Charfi, 2018; Abdul-Mageed et al., 2018). As for dialect-to-dialect parallel corpora, Bouamor et al. (2018) presented the MADAR Corpus, a large-scale collection of parallel sentences covering the dialects of 25 Arab cities alongside the English, French and MSA parallel texts. This resource was a commissioned translation of the Basic Traveling Expression Corpus (BTEC) (Takezawa et al., 2007) sentences from English and French to the different dialects. It includes two corpora. The first corpus (Corpus-26) consists of 2,000 sentences translated into 25 Arab city dialects in parallel. The second corpus (Corpu"
2020.lrec-1.508,zaghouani-etal-2014-large,1,0.862129,"of dialects being incorporated, Habash et al. (2018) presented a more Unified Guidelines and Resources for Arabic Dialect Orthography — dubbed CODA* (CODA-Star) as in for any dialect — specifying closed class spelling in more detail and unifying the CODA creation process. CODA* has since been used to represent over two dozen Arabic dialects. It is worth noting that in recent years, the problem of spell checking and spelling error correction for Arabic has been investigated in a number of research effort (Attia et al., 2016; Watson et al., 2018). The QALB (Qatar Arabic Language Bank) project (Zaghouani et al., 2014) aimed at building an annotated corpus of manually corrected MSA text for building automatic correction tools, and it was used in two shared tasks on MSA spelling correction (Mohit et al., 2014; Rozovskaya et al., 2015). 3. 3.1. CODA: Conventional Orthography for Dialectal Arabic The Orthography of Arabic and its Dialects As mentioned in the introduction, Arabic is a family of variants, among which MSA is the official standard language. However, MSA is not the native language of any speakers of Arabic. In unscripted situations where spoken MSA would typically be required (such as talk shows on"
2020.lrec-1.508,P11-2007,0,0.149465,"east for NLP. Finally, for the sake of clarity of purpose, we find the term “spelling correction” in a NLP context clearer than “spelling conventionalization”. 2 http://resources.camel-lab.com/ 4130 2. Related Work Automatic DA processing has been attracting a considerable amount of research in NLP (Shoufan and Al-Ameri, 2015), facilitated by the newly developed monolingual and multilingual dialectal corpora. Several mono-dialectal corpora covering different Arabic dialects at different granularity levels (region, country and city levels) were built and made available (McNeil and Faiza, 2011; Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Badrashiny and Diab, 2016; Zaghouani and Charfi, 2018; Abdul-Mageed et al., 2018). As for dialect-to-dialect parallel corpora, Bouamor et al. (2018) presented the MADAR Corpus, a large-scale collection of parallel sentences covering the dialects of 25 Arab cities alongside the English, French and MSA parallel texts. This resource was a commissioned translation of the Basic Traveling Expression Corpus (BTEC) (Takezawa et al., 2007) sentences from English and French to the different dialects. It"
2020.lrec-1.508,N12-1006,0,0.0286398,"ke of clarity of purpose, we find the term “spelling correction” in a NLP context clearer than “spelling conventionalization”. 2 http://resources.camel-lab.com/ 4130 2. Related Work Automatic DA processing has been attracting a considerable amount of research in NLP (Shoufan and Al-Ameri, 2015), facilitated by the newly developed monolingual and multilingual dialectal corpora. Several mono-dialectal corpora covering different Arabic dialects at different granularity levels (region, country and city levels) were built and made available (McNeil and Faiza, 2011; Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Badrashiny and Diab, 2016; Zaghouani and Charfi, 2018; Abdul-Mageed et al., 2018). As for dialect-to-dialect parallel corpora, Bouamor et al. (2018) presented the MADAR Corpus, a large-scale collection of parallel sentences covering the dialects of 25 Arab cities alongside the English, French and MSA parallel texts. This resource was a commissioned translation of the Basic Traveling Expression Corpus (BTEC) (Takezawa et al., 2007) sentences from English and French to the different dialects. It includes two corpo"
2020.lrec-1.508,zribi-etal-2014-conventional,1,0.933241,"ise can be handled using modeling techniques that normalize and cluster variants if DA is the input to the system, e.g. in machine translation from dialects to other languages. However, when the dialect is the target output, as in speech recognition systems (Ali, 2018), or machine translation into the dialects (Erdmann et al., 2017), evaluation and thus optimization may struggle. A number of efforts in Arabic NLP have argued for the creation of a common convention for Arabic dialect spelling, named Conventional Orthography for Dialectal Arabic (CODA) (Habash et al., 2012; Jarrar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Khalifa et al., 2016; Habash et al., 2018). The majority of resources involving CODA annotation consider it a side task to efforts like morphological disambiguation, diacritization and lemmatization, as opposed to being the main target task (CODA for CODA). In this paper, we explore and report on the task of CODA annotation, i.e., spelling correction into the CODA convention.1 We work with a unique corpus of parallel multiple Arabic dialects, the MADAR Corpus (Bouamor et al., 2018), focusing on five cities: Beirut, Cairo, Doha, Rabat and Tunis. Our contributions are"
2020.lrec-1.60,W18-5027,1,0.500023,"by Artstein et al. (2015), who first introduced the term time-offset interaction. Developing, streamlining, and making the process of creating TOIAs affordable are important goals. But building such systems is not an easy task because the interaction with the avatars should ideally be as close as possible to a real, human-to-human interaction. This critical feature poses challenges from an engineering point of view (for instance, connecting the video clips flawlessly) and from many other points of view related to dialogue management and natural language processing. We refer to the work by Abu Ali et al. (2018) for a detailed description of the TOIA platform we use for storing and accessing video clips, and for interpreting the interrogator’s input. The first step to build a TOIA involves the creation of its Knowledge Base. This database consists of a set of pairs, and answer video clips. The answer clips include recordings of the avatar’s answers, and clarification requests (e.g., “Can you repeat your question?”), as well as filler sequences to play while the system is waiting for the next question (e.g., the avatar adjusting her hair). One interesting problem is how to best construct this KB in th"
2020.lrec-1.60,D17-1070,0,0.0130101,"chniques, which usually address a reading comprehension task. For instance work on the SQuAD dataset (Rajpurkar et al., 2016), the Ubuntu dialogue corpus (Lowe et al., 2015), and bAbI2 (Weston et al., 2015) are designed to perform time reasoning and inductive logic (Kumar et al., 2016). Techniques include recurrent neural network models (RNN) such as sequence2sequence, word embeddings, and LSTMs. It is worth mentioning that word or sentence pre-trained embeddings alone are a simple tool to produce powerful results. Recent examples are Google’s BERT (Devlin et al., 2018), Facebook’s InferSent (Conneau et al., 2017), and OpenAI’s GPT (Radford et al., 2018). While large data sets are available and the recent success of deep learning techniques suit big data, we make available a smaller data set aimed at the practical implementation of a TOIA available for the every-day user. Finally, it is worth pointing out that the evaluation of dialogue systems is an area of research where - to the best of our knowledge - no established or robust methodology seems to exist yet for two main inter-related reasons: automatic metrics do not correlate well with human judgments, and human judgments are difficult to measure ("
2020.lrec-1.60,W15-4640,0,0.0499577,"to address two primary Natural Language Processing (NLP) challenges: understanding the user question, and generating a sensible answer. From the IR standpoint, they must also search into a large enough KB to retrieve the right answer(s) across many different topics. These KBs usually come from different contexts such as Twitter or Wikipedia pages (Ritter et al., 2010; Wilcock, 2012). Some dialogue management systems use question answering techniques, which usually address a reading comprehension task. For instance work on the SQuAD dataset (Rajpurkar et al., 2016), the Ubuntu dialogue corpus (Lowe et al., 2015), and bAbI2 (Weston et al., 2015) are designed to perform time reasoning and inductive logic (Kumar et al., 2016). Techniques include recurrent neural network models (RNN) such as sequence2sequence, word embeddings, and LSTMs. It is worth mentioning that word or sentence pre-trained embeddings alone are a simple tool to produce powerful results. Recent examples are Google’s BERT (Devlin et al., 2018), Facebook’s InferSent (Conneau et al., 2017), and OpenAI’s GPT (Radford et al., 2018). While large data sets are available and the recent success of deep learning techniques suit big data, we make"
2020.lrec-1.60,P17-1103,0,0.0397935,"Missing"
2020.lrec-1.60,P02-1040,0,0.107025,"Missing"
2020.lrec-1.60,D16-1264,0,0.176501,"Missing"
2020.lrec-1.60,N10-1020,0,0.0192373,"g the sequence of a conversation). Dialogue data, techniques, and evaluation Social bots are expected to entertain the user hence and are often evaluated by the number of turns they can make in conversations (Khatri et al., 2018).1 They are designed to address two primary Natural Language Processing (NLP) challenges: understanding the user question, and generating a sensible answer. From the IR standpoint, they must also search into a large enough KB to retrieve the right answer(s) across many different topics. These KBs usually come from different contexts such as Twitter or Wikipedia pages (Ritter et al., 2010; Wilcock, 2012). Some dialogue management systems use question answering techniques, which usually address a reading comprehension task. For instance work on the SQuAD dataset (Rajpurkar et al., 2016), the Ubuntu dialogue corpus (Lowe et al., 2015), and bAbI2 (Weston et al., 2015) are designed to perform time reasoning and inductive logic (Kumar et al., 2016). Techniques include recurrent neural network models (RNN) such as sequence2sequence, word embeddings, and LSTMs. It is worth mentioning that word or sentence pre-trained embeddings alone are a simple tool to produce powerful results. Rec"
2020.lrec-1.60,2005.sigdial-1.6,0,0.235785,"Missing"
2020.lrec-1.60,W15-4629,0,0.226873,"long with some error analysis. In Section 5, we discuss the most interesting problems encountered in the analysis of the Margarita Dialogue Corpus, such as threshold selection and corpus expansion. 476 2. Related Work We start this section with discussing the work that most inspired our efforts. We then contextualize our work within the broader category of dialogue systems. Finally we introduce the most common types of training data sets, techniques and evaluations available for research in dialogues. The New Dimensions in Testimony project The New Dimensions in Testimony project presented by Traum et al. (2015b) inspired us and Abu Ali et al. (2018) to work on TOIAs. Traum et al. (2015b) built a time-offset interaction with a Holocaust survivor, Mr. Pinchas Gutter. We built our TOIA following the same methodology, whereby we prepared a limited (compared to the original project’s vast) set of pairs in advance. In other words, we guessed what questions might be asked of the avatar. The Dialogue Manager of Abu Ali et al. (2018) uses a statistical classifier based on traditional techniques from the IR arena. The work by Traum et al. (2015b) develops a proof-of-concept that enables short conversations a"
2020.lrec-1.60,W12-6006,0,0.0136433,"onversation). Dialogue data, techniques, and evaluation Social bots are expected to entertain the user hence and are often evaluated by the number of turns they can make in conversations (Khatri et al., 2018).1 They are designed to address two primary Natural Language Processing (NLP) challenges: understanding the user question, and generating a sensible answer. From the IR standpoint, they must also search into a large enough KB to retrieve the right answer(s) across many different topics. These KBs usually come from different contexts such as Twitter or Wikipedia pages (Ritter et al., 2010; Wilcock, 2012). Some dialogue management systems use question answering techniques, which usually address a reading comprehension task. For instance work on the SQuAD dataset (Rajpurkar et al., 2016), the Ubuntu dialogue corpus (Lowe et al., 2015), and bAbI2 (Weston et al., 2015) are designed to perform time reasoning and inductive logic (Kumar et al., 2016). Techniques include recurrent neural network models (RNN) such as sequence2sequence, word embeddings, and LSTMs. It is worth mentioning that word or sentence pre-trained embeddings alone are a simple tool to produce powerful results. Recent examples are"
2020.lrec-1.60,W13-4065,0,0.0263577,"ts. Dialogue systems Dialogue systems fall along two central axis pairs: modular (or task-driven) versus end-toend (or social bots), and structured versus unstructured. Modular systems, like the commercially available Siri, Alexa, Cortana, or Google Assistant, train multiple models to support a set of tasks (Guo and Seltzer, 2012), while end-to-end systems train a single learning algorithm on dialogue data (Serban et al., 2016; Shum et al., 2018). Similarly, structured systems assume a logical representation for the information exchanged in conversation - for example, slot-filling techniques (Williams et al., 2013; Fast et al., 2018) - which unstructured systems do not require (Gao et al., 2019). A dialogue system like a TOIA formulates a new category of chatbots that can be named ‘self-narrative bots’ (SNB). In terms of NLP tasks, they are a middle ground between social bots and task-driven bots: they may use a combination of structured and unstructured data for training. SNBs will be able to understand an interrogator’s question in order to match it to a sensible answer. At the same time, they must be able to engage in a multi-turn conversation, hence they may use reading comprehension of contexts re"
2020.lrec-1.868,N16-3003,0,0.0607792,"ide range for the depth of information that morphological analyzers can produce, with very shallow analyzers on one end (Vanni and Zajac, 1996), to analyzers producing form-based, functional, and lexical features as well as morpheme forms (Buckwalter, 2002; Smrž, 2007; Boudlal et al., 2010; Alkuhlani and Habash, 2011; Boudchiche et al., 2017). Systems such as MADA (Habash et al., 2009) and MADAMIRA (Pasha et al., 2014) disambiguate the analyses that are produced by a morphological analyzer. Zalmout and Habash (2017) outline a neural model that follows the same approach. Alternatively, Farasa (Abdelali et al., 2016) relies on probabilistic models to produce high tokenization accuracy, and YAMAMA (Khalifa et al., 2016b) uses the same approach to produce MADAMIRA-like disambiguated analyses. For Arabic dialects, Zalmout et al. (2018) present a neural system that does morphological tagging and disambiguation for Egyptian Arabic. Named Entity Recognition While some Arabic NER systems have used rule-based approaches (Shaalan and Raza, 2009; Zaghouani, 2012; Aboaoga and Aziz, 2013), most recent Arabic NER systems integrate machine learning in their architectures (Benajiba and Rosso, 2008; AbdelRahman et al., 2"
2020.lrec-1.868,abdul-mageed-diab-2014-sana,0,0.0303454,"task (Zampieri et al., 2017), encouraging researchers to submit systems to recognize the dialect of speech transcripts along with acoustic features for dialects of four main regions: Egyptian, Gulf, Levantine and North African, in addition to MSA. The dataset used in these tasks is different from the dataset we use in this work in its genre, size and the dialects covered. Sentiment Analysis Arabic SA is a well studied problem that has many proposed solutions. These solutions span a wide array of methods such as developing lexiconbased conventional machine learning models (Badaro et al., 2014; Abdul-Mageed and Diab, 2014) or deep learning models (Abu Farha and Magdy, 2019; Badaro et al., 2018; Baly et al., 2017). More recently, fine-tuning large pre-trained language models has achieved state-of-the-art results on various NLP tasks. ElJundi et al. (2019) developed a universal language model for Arabic (hULMonA) which was pre-trained on a large corpus of Wikipedia sentences and compared its performance to multilingual BERT (mBERT) (Devlin et al., 2018) on the task of Arabic SA after fine-tuning. They have shown that although mBERT was only trained on Modern Standard Arabic (MSA), it can still achieve state-of-th"
2020.lrec-1.868,W19-4621,0,0.035259,"Missing"
2020.lrec-1.868,W14-1604,1,0.895706,"Missing"
2020.lrec-1.868,P11-2062,1,0.571227,"representations paired with word-form derivation rules (Beesley et al., 1989; Beesley, 1996; Habash and Rambow, 2006; Smrž, 2007) to pre-compiled representations of the different components needed for morphological analysis (Buckwalter, 2002; Graff et al., 2009; Habash, 2007). Previous efforts also show a wide range for the depth of information that morphological analyzers can produce, with very shallow analyzers on one end (Vanni and Zajac, 1996), to analyzers producing form-based, functional, and lexical features as well as morpheme forms (Buckwalter, 2002; Smrž, 2007; Boudlal et al., 2010; Alkuhlani and Habash, 2011; Boudchiche et al., 2017). Systems such as MADA (Habash et al., 2009) and MADAMIRA (Pasha et al., 2014) disambiguate the analyses that are produced by a morphological analyzer. Zalmout and Habash (2017) outline a neural model that follows the same approach. Alternatively, Farasa (Abdelali et al., 2016) relies on probabilistic models to produce high tokenization accuracy, and YAMAMA (Khalifa et al., 2016b) uses the same approach to produce MADAMIRA-like disambiguated analyses. For Arabic dialects, Zalmout et al. (2018) present a neural system that does morphological tagging and disambiguation"
2020.lrec-1.868,2020.osact-1.2,0,0.204837,"17). More recently, fine-tuning large pre-trained language models has achieved state-of-the-art results on various NLP tasks. ElJundi et al. (2019) developed a universal language model for Arabic (hULMonA) which was pre-trained on a large corpus of Wikipedia sentences and compared its performance to multilingual BERT (mBERT) (Devlin et al., 2018) on the task of Arabic SA after fine-tuning. They have shown that although mBERT was only trained on Modern Standard Arabic (MSA), it can still achieve state-of-the-art results on some datasets if it’s fine-tuned on dialectal Arabic data. Furthermore, Antoun et al. (2020) pre-trained an Arabic specific BERT (AraBERT) and were able to achieve state-of-the-art results on several downstream tasks. 3.2. we discuss the capabilities of the mentioned tools and we provide a rough comparison in Table 2. MADAMIRA provides a single, yet configurable, mode of operation revolving around it’s morphological analyzer. When disambiguation is enabled, features such as POS tagging, tokenization, segmentation, lemmatization, NER and base-phrase chunking become available. MADAMIRA was designed specifically for Arabic and supports both MSA and Egyptian and primarily provides a CLI,"
2020.lrec-1.868,W14-3623,1,0.778799,"f a dedicated shared task (Zampieri et al., 2017), encouraging researchers to submit systems to recognize the dialect of speech transcripts along with acoustic features for dialects of four main regions: Egyptian, Gulf, Levantine and North African, in addition to MSA. The dataset used in these tasks is different from the dataset we use in this work in its genre, size and the dialects covered. Sentiment Analysis Arabic SA is a well studied problem that has many proposed solutions. These solutions span a wide array of methods such as developing lexiconbased conventional machine learning models (Badaro et al., 2014; Abdul-Mageed and Diab, 2014) or deep learning models (Abu Farha and Magdy, 2019; Badaro et al., 2018; Baly et al., 2017). More recently, fine-tuning large pre-trained language models has achieved state-of-the-art results on various NLP tasks. ElJundi et al. (2019) developed a universal language model for Arabic (hULMonA) which was pre-trained on a large corpus of Wikipedia sentences and compared its performance to multilingual BERT (mBERT) (Devlin et al., 2018) on the task of Arabic SA after fine-tuning. They have shown that although mBERT was only trained on Modern Standard Arabic (MSA), it"
2020.lrec-1.868,S18-1036,0,0.0394015,"Missing"
2020.lrec-1.868,C96-1017,0,0.578118,"rrently addressed by CAMeL Tools. We also discuss some of the software suites that have inspired the design of CAMeL Tools. 3.1. NLP Tasks We briefly survey the different efforts for a variety of Arabic NLP tasks. Specifically, we discuss those tasks that are relevant to CAMeL Tools at the time of publishing. These include morphological modeling, NER, DID and SA. Morphological Modeling Efforts on Arabic morphological modeling have varied over a number of dimensions, ranging from very abstract and linguistically rich representations paired with word-form derivation rules (Beesley et al., 1989; Beesley, 1996; Habash and Rambow, 2006; Smrž, 2007) to pre-compiled representations of the different components needed for morphological analysis (Buckwalter, 2002; Graff et al., 2009; Habash, 2007). Previous efforts also show a wide range for the depth of information that morphological analyzers can produce, with very shallow analyzers on one end (Vanni and Zajac, 1996), to analyzers producing form-based, functional, and lexical features as well as morpheme forms (Buckwalter, 2002; Smrž, 2007; Boudlal et al., 2010; Alkuhlani and Habash, 2011; Boudchiche et al., 2017). Systems such as MADA (Habash et al.,"
2020.lrec-1.868,L18-1535,1,0.894288,"Missing"
2020.lrec-1.868,L16-1170,0,0.019765,"provides Arabic support through unofficial bindings to Stanford CoreNLP. 4. Design and Implementation CAMeL Tools is an open-source package consisting of a set of Python APIs with accompanying command-line tools that are thin wrap these APIs. In this section we discuss the design decisions behind CAMeL Tools and how it was implemented. Software Suites While most efforts focus on individual tasks, there are few that provide multiple capabilities in the form of a unified toolkit. These can be classified as Arabic specific, such as MADAMIRA (Pasha et al., 2014) and Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) or multi-lingual, such as Stanford CoreNLP (Manning et al., 2014). Below 4.1. Motivation There are two main issues with currently available tools that prompted us to develop CAMeL Tools and influenced its design: 2 http://qatsdemo.cloudapp.net/farasa/ Fragmented Packages and Standards Tools tend to focus on one task with no easy way to glue together different packages. Some tools do provide APIs, making this easier, but others only provide command-line tools. This leads to overhead writing glue code including interfaces to different packages and parsers for different output formats. Lack of F"
2020.lrec-1.868,P13-1153,0,0.0325251,"ation accuracy, and YAMAMA (Khalifa et al., 2016b) uses the same approach to produce MADAMIRA-like disambiguated analyses. For Arabic dialects, Zalmout et al. (2018) present a neural system that does morphological tagging and disambiguation for Egyptian Arabic. Named Entity Recognition While some Arabic NER systems have used rule-based approaches (Shaalan and Raza, 2009; Zaghouani, 2012; Aboaoga and Aziz, 2013), most recent Arabic NER systems integrate machine learning in their architectures (Benajiba and Rosso, 2008; AbdelRahman et al., 2010; Mohammed and Omar, 2012; Oudah and Shaalan, 2012; Darwish, 2013; El Bazi and Laachfoubi, 2019). Benajiba and Rosso (2007) developed ANERsys, one of the earliest NER systems for Arabic. They built their own linguistic resources, which have become standard in Arabic NER literature: ANERcorp (i.e., an annotated corpus for Person, Location and Organization names) and ANERgazet (i.e., Person, Location and Organization gazetteers). In CAMeL Tools, we make use of all publicly available training data and compare our system to the work of Benajiba and Rosso (2008). Dialect Identification Salameh et al. (2018) introduced a fine-grained DID system covering the diale"
2020.lrec-1.868,W14-3629,0,0.0704396,"Missing"
2020.lrec-1.868,elfardy-diab-2012-simplified,0,0.0334642,"loped ANERsys, one of the earliest NER systems for Arabic. They built their own linguistic resources, which have become standard in Arabic NER literature: ANERcorp (i.e., an annotated corpus for Person, Location and Organization names) and ANERgazet (i.e., Person, Location and Organization gazetteers). In CAMeL Tools, we make use of all publicly available training data and compare our system to the work of Benajiba and Rosso (2008). Dialect Identification Salameh et al. (2018) introduced a fine-grained DID system covering the dialects of 25 cities from several countries across the Arab world. Elfardy and Diab (2012) presented a set of guidelines for token-level identification of dialectness. They later proposed a supervised approach for identifying whether a given sentence is prevalently MSA or Egyptian (Elfardy and Diab, 2013) using the Arabic Online Commentary Dataset (Zaidan and Suite Type Language CLI API Exposed Pre-processing Morphological Modeling Morphological Disambiguation POS Tagging Diacritization Tokenization/Segementation/Stemming Lemmatization Named Entity Recognition Sentiment Analysis Dialect ID Parsing CAMeL Tools Arabic Specific Python 3 3 3 3 3 3 3 3 3 3 3 3 Work in progress MADAMIRA"
2020.lrec-1.868,P13-2081,0,0.0266244,"Organization names) and ANERgazet (i.e., Person, Location and Organization gazetteers). In CAMeL Tools, we make use of all publicly available training data and compare our system to the work of Benajiba and Rosso (2008). Dialect Identification Salameh et al. (2018) introduced a fine-grained DID system covering the dialects of 25 cities from several countries across the Arab world. Elfardy and Diab (2012) presented a set of guidelines for token-level identification of dialectness. They later proposed a supervised approach for identifying whether a given sentence is prevalently MSA or Egyptian (Elfardy and Diab, 2013) using the Arabic Online Commentary Dataset (Zaidan and Suite Type Language CLI API Exposed Pre-processing Morphological Modeling Morphological Disambiguation POS Tagging Diacritization Tokenization/Segementation/Stemming Lemmatization Named Entity Recognition Sentiment Analysis Dialect ID Parsing CAMeL Tools Arabic Specific Python 3 3 3 3 3 3 3 3 3 3 3 3 Work in progress MADAMIRA Arabic Specific Java 3 3 Stanford CoreNLP Multilingual Java with Python bindings 3 3 Farasa Arabic Specific Java 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 Table 2: Feature comparison of CAMeL Tools, MADAMIRA, Stanfor"
2020.lrec-1.868,W19-4608,0,0.038158,"Missing"
2020.lrec-1.868,2020.lrec-1.508,1,0.799898,"Missing"
2020.lrec-1.868,P05-1071,1,0.516904,"ization, and POS tagging. 6.2. Disambiguation and Annotation Morphological disambiguation is the task of choosing an analysis of a word in context. Tasks such as diacritization, POS tagging, tokenization and lemmatization can be considered forms of disambiguation. When dealing with Arabic however, each of these tasks on their own, don’t fully disambiguate a word. In order to avoid confusion, we refer to the individual tasks on their own as annotation tasks. Traditionally, annotation tasks would be implemented independently of each other. We however, chose to use the one-fell-swoop approach of Habash and Rambow (2005). This approach entails predicting a set of features of a given word, ranking its out-of-context analyses based on the predicted features, and finally choosing the top ranked analysis. Annotation can then be achieved by retrieving the relevant feature from the ranked analysis. We provide two builtin disambiguators: a simple low-cost disambiguator based on a maximum likelihood estimation (MLE) model and a neural network disambiguator that provides improved disambiguation accuracy using multitask learning. Table 1(e) shows how these morphological disambiguators can disambiguate a word. MLE Disam"
2020.lrec-1.868,P06-1086,1,0.560632,"ed by CAMeL Tools. We also discuss some of the software suites that have inspired the design of CAMeL Tools. 3.1. NLP Tasks We briefly survey the different efforts for a variety of Arabic NLP tasks. Specifically, we discuss those tasks that are relevant to CAMeL Tools at the time of publishing. These include morphological modeling, NER, DID and SA. Morphological Modeling Efforts on Arabic morphological modeling have varied over a number of dimensions, ranging from very abstract and linguistically rich representations paired with word-form derivation rules (Beesley et al., 1989; Beesley, 1996; Habash and Rambow, 2006; Smrž, 2007) to pre-compiled representations of the different components needed for morphological analysis (Buckwalter, 2002; Graff et al., 2009; Habash, 2007). Previous efforts also show a wide range for the depth of information that morphological analyzers can produce, with very shallow analyzers on one end (Vanni and Zajac, 1996), to analyzers producing form-based, functional, and lexical features as well as morpheme forms (Buckwalter, 2002; Smrž, 2007; Boudlal et al., 2010; Alkuhlani and Habash, 2011; Boudchiche et al., 2017). Systems such as MADA (Habash et al., 2009) and MADAMIRA (Pasha"
2020.lrec-1.868,W12-2301,1,0.809821,"Missing"
2020.lrec-1.868,L18-1574,1,0.86402,"Missing"
2020.lrec-1.868,L16-1679,1,0.922631,"ers on one end (Vanni and Zajac, 1996), to analyzers producing form-based, functional, and lexical features as well as morpheme forms (Buckwalter, 2002; Smrž, 2007; Boudlal et al., 2010; Alkuhlani and Habash, 2011; Boudchiche et al., 2017). Systems such as MADA (Habash et al., 2009) and MADAMIRA (Pasha et al., 2014) disambiguate the analyses that are produced by a morphological analyzer. Zalmout and Habash (2017) outline a neural model that follows the same approach. Alternatively, Farasa (Abdelali et al., 2016) relies on probabilistic models to produce high tokenization accuracy, and YAMAMA (Khalifa et al., 2016b) uses the same approach to produce MADAMIRA-like disambiguated analyses. For Arabic dialects, Zalmout et al. (2018) present a neural system that does morphological tagging and disambiguation for Egyptian Arabic. Named Entity Recognition While some Arabic NER systems have used rule-based approaches (Shaalan and Raza, 2009; Zaghouani, 2012; Aboaoga and Aziz, 2013), most recent Arabic NER systems integrate machine learning in their architectures (Benajiba and Rosso, 2008; AbdelRahman et al., 2010; Mohammed and Omar, 2012; Oudah and Shaalan, 2012; Darwish, 2013; El Bazi and Laachfoubi, 2019). Be"
2020.lrec-1.868,C16-2047,1,0.933291,"ers on one end (Vanni and Zajac, 1996), to analyzers producing form-based, functional, and lexical features as well as morpheme forms (Buckwalter, 2002; Smrž, 2007; Boudlal et al., 2010; Alkuhlani and Habash, 2011; Boudchiche et al., 2017). Systems such as MADA (Habash et al., 2009) and MADAMIRA (Pasha et al., 2014) disambiguate the analyses that are produced by a morphological analyzer. Zalmout and Habash (2017) outline a neural model that follows the same approach. Alternatively, Farasa (Abdelali et al., 2016) relies on probabilistic models to produce high tokenization accuracy, and YAMAMA (Khalifa et al., 2016b) uses the same approach to produce MADAMIRA-like disambiguated analyses. For Arabic dialects, Zalmout et al. (2018) present a neural system that does morphological tagging and disambiguation for Egyptian Arabic. Named Entity Recognition While some Arabic NER systems have used rule-based approaches (Shaalan and Raza, 2009; Zaghouani, 2012; Aboaoga and Aziz, 2013), most recent Arabic NER systems integrate machine learning in their architectures (Benajiba and Rosso, 2008; AbdelRahman et al., 2010; Mohammed and Omar, 2012; Oudah and Shaalan, 2012; Darwish, 2013; El Bazi and Laachfoubi, 2019). Be"
2020.lrec-1.868,2020.lrec-1.480,1,0.789264,"Missing"
2020.lrec-1.868,W02-0109,0,0.202977,"more flexible usage of components compared to MADAMIRA. Stanford CoreNLP is a multilingual Java library, CLI and server providing multiple NLP components with varying support for different languages. Arabic support is provided for parsing, tokenization, POS tagging, sentence splitting and NER (a rule-based system using regular expressions). An official Python library is also available (Qi et al., 2018) which provides official bindings to CoreNLP as well as providing neural implementations for some of their components. It is worth noting that the commonly used Natural Language Toolkit (NLTK) (Loper and Bird, 2002) provides Arabic support through unofficial bindings to Stanford CoreNLP. 4. Design and Implementation CAMeL Tools is an open-source package consisting of a set of Python APIs with accompanying command-line tools that are thin wrap these APIs. In this section we discuss the design decisions behind CAMeL Tools and how it was implemented. Software Suites While most efforts focus on individual tasks, there are few that provide multiple capabilities in the form of a unified toolkit. These can be classified as Arabic specific, such as MADAMIRA (Pasha et al., 2014) and Farasa (Abdelali et al., 2016;"
2020.lrec-1.868,maamouri-etal-2014-developing,1,0.884529,"Missing"
2020.lrec-1.868,P14-5010,0,0.00311028,". 4. Design and Implementation CAMeL Tools is an open-source package consisting of a set of Python APIs with accompanying command-line tools that are thin wrap these APIs. In this section we discuss the design decisions behind CAMeL Tools and how it was implemented. Software Suites While most efforts focus on individual tasks, there are few that provide multiple capabilities in the form of a unified toolkit. These can be classified as Arabic specific, such as MADAMIRA (Pasha et al., 2014) and Farasa (Abdelali et al., 2016; Darwish and Mubarak, 2016) or multi-lingual, such as Stanford CoreNLP (Manning et al., 2014). Below 4.1. Motivation There are two main issues with currently available tools that prompted us to develop CAMeL Tools and influenced its design: 2 http://qatsdemo.cloudapp.net/farasa/ Fragmented Packages and Standards Tools tend to focus on one task with no easy way to glue together different packages. Some tools do provide APIs, making this easier, but others only provide command-line tools. This leads to overhead writing glue code including interfaces to different packages and parsers for different output formats. Lack of Flexibility Most tools don’t expose intermediate functionality. Thi"
2020.lrec-1.868,D15-1299,0,0.0245569,"layer with a softmax activation function to the last hidden state. We report results on both finetuned models and we provide the best of the two as part of CAMeL Tools. Datasets To ensure that mBERT and AraBERT can be generalized to classify the sentiment of dialectal tweets, we used various datasets for fine-tuning and evaluation. The first dialectal dataset is the Arabic Speech-Act and Sentiment Corpus of Tweets (ArSAS) (Elmadany et al., 2018) where each tweet is annotated for positive, negative, neutral, and mixed sentiment. The second dataset is the Arabic Sentiment Tweets Dataset (ASTD) (Nabil et al., 2015) that is in both Egyptian Arabic and MSA. Each tweet has a sentiment label of either positive, negative, neutral, or objective. The third dataset is SemEval-2017 task 4-A benchmark dataset (Rosenthal et al., 2017) which is in MSA and each tweet was annotated with a sentiment label of positive, negative, or neutral. Lastly, we used the Multi-Topic Corpus for Target-based Sentiment Analysis in Arabic Levantine Tweets (ArSenTD-Lev) (Baly et al., 2019) where tweet 7 Data split details are linked from https://camel-lab. github.io/camel_tools_updates/ CAMeL Tools AraBERT mBERT Mazajak ArSAS ASTD Sem"
2020.lrec-1.868,N19-4002,1,0.89514,"Missing"
2020.lrec-1.868,C12-1132,1,0.787917,"s to produce high tokenization accuracy, and YAMAMA (Khalifa et al., 2016b) uses the same approach to produce MADAMIRA-like disambiguated analyses. For Arabic dialects, Zalmout et al. (2018) present a neural system that does morphological tagging and disambiguation for Egyptian Arabic. Named Entity Recognition While some Arabic NER systems have used rule-based approaches (Shaalan and Raza, 2009; Zaghouani, 2012; Aboaoga and Aziz, 2013), most recent Arabic NER systems integrate machine learning in their architectures (Benajiba and Rosso, 2008; AbdelRahman et al., 2010; Mohammed and Omar, 2012; Oudah and Shaalan, 2012; Darwish, 2013; El Bazi and Laachfoubi, 2019). Benajiba and Rosso (2007) developed ANERsys, one of the earliest NER systems for Arabic. They built their own linguistic resources, which have become standard in Arabic NER literature: ANERcorp (i.e., an annotated corpus for Person, Location and Organization names) and ANERgazet (i.e., Person, Location and Organization gazetteers). In CAMeL Tools, we make use of all publicly available training data and compare our system to the work of Benajiba and Rosso (2008). Dialect Identification Salameh et al. (2018) introduced a fine-grained DID system cov"
2020.lrec-1.868,pasha-etal-2014-madamira,1,0.913796,"2006; Smrž, 2007) to pre-compiled representations of the different components needed for morphological analysis (Buckwalter, 2002; Graff et al., 2009; Habash, 2007). Previous efforts also show a wide range for the depth of information that morphological analyzers can produce, with very shallow analyzers on one end (Vanni and Zajac, 1996), to analyzers producing form-based, functional, and lexical features as well as morpheme forms (Buckwalter, 2002; Smrž, 2007; Boudlal et al., 2010; Alkuhlani and Habash, 2011; Boudchiche et al., 2017). Systems such as MADA (Habash et al., 2009) and MADAMIRA (Pasha et al., 2014) disambiguate the analyses that are produced by a morphological analyzer. Zalmout and Habash (2017) outline a neural model that follows the same approach. Alternatively, Farasa (Abdelali et al., 2016) relies on probabilistic models to produce high tokenization accuracy, and YAMAMA (Khalifa et al., 2016b) uses the same approach to produce MADAMIRA-like disambiguated analyses. For Arabic dialects, Zalmout et al. (2018) present a neural system that does morphological tagging and disambiguation for Egyptian Arabic. Named Entity Recognition While some Arabic NER systems have used rule-based approac"
2020.lrec-1.868,K18-2016,0,0.230182,"ms (Buckwalter, 2002; Smrž, 2007; Boudlal et al., 2010; Alkuhlani and Habash, 2011; Boudchiche et al., 2017). Systems such as MADA (Habash et al., 2009) and MADAMIRA (Pasha et al., 2014) disambiguate the analyses that are produced by a morphological analyzer. Zalmout and Habash (2017) outline a neural model that follows the same approach. Alternatively, Farasa (Abdelali et al., 2016) relies on probabilistic models to produce high tokenization accuracy, and YAMAMA (Khalifa et al., 2016b) uses the same approach to produce MADAMIRA-like disambiguated analyses. For Arabic dialects, Zalmout et al. (2018) present a neural system that does morphological tagging and disambiguation for Egyptian Arabic. Named Entity Recognition While some Arabic NER systems have used rule-based approaches (Shaalan and Raza, 2009; Zaghouani, 2012; Aboaoga and Aziz, 2013), most recent Arabic NER systems integrate machine learning in their architectures (Benajiba and Rosso, 2008; AbdelRahman et al., 2010; Mohammed and Omar, 2012; Oudah and Shaalan, 2012; Darwish, 2013; El Bazi and Laachfoubi, 2019). Benajiba and Rosso (2007) developed ANERsys, one of the earliest NER systems for Arabic. They built their own linguisti"
2020.lrec-1.868,S17-2088,0,0.0815669,"Missing"
2020.lrec-1.868,W14-5904,0,0.0223738,"critization Tokenization/Segementation/Stemming Lemmatization Named Entity Recognition Sentiment Analysis Dialect ID Parsing CAMeL Tools Arabic Specific Python 3 3 3 3 3 3 3 3 3 3 3 3 Work in progress MADAMIRA Arabic Specific Java 3 3 Stanford CoreNLP Multilingual Java with Python bindings 3 3 Farasa Arabic Specific Java 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 Table 2: Feature comparison of CAMeL Tools, MADAMIRA, Stanford CoreNLP and Farasa. Callison-Burch, 2011). Their system (Elfardy and Diab, 2012) combines a token-level DID approach with other features to train a Naive-Bayes classifier. Sadat et al. (2014) presented a bi-gram character-level model to identify the dialect of sentences in the social media context among dialects of 18 Arab countries. More recently, discriminating between Arabic dialects has been the goal of a dedicated shared task (Zampieri et al., 2017), encouraging researchers to submit systems to recognize the dialect of speech transcripts along with acoustic features for dialects of four main regions: Egyptian, Gulf, Levantine and North African, in addition to MSA. The dataset used in these tasks is different from the dataset we use in this work in its genre, size and the dial"
2020.lrec-1.868,C18-1113,1,0.92417,"et al., 2010; Mohammed and Omar, 2012; Oudah and Shaalan, 2012; Darwish, 2013; El Bazi and Laachfoubi, 2019). Benajiba and Rosso (2007) developed ANERsys, one of the earliest NER systems for Arabic. They built their own linguistic resources, which have become standard in Arabic NER literature: ANERcorp (i.e., an annotated corpus for Person, Location and Organization names) and ANERgazet (i.e., Person, Location and Organization gazetteers). In CAMeL Tools, we make use of all publicly available training data and compare our system to the work of Benajiba and Rosso (2008). Dialect Identification Salameh et al. (2018) introduced a fine-grained DID system covering the dialects of 25 cities from several countries across the Arab world. Elfardy and Diab (2012) presented a set of guidelines for token-level identification of dialectness. They later proposed a supervised approach for identifying whether a given sentence is prevalently MSA or Egyptian (Elfardy and Diab, 2013) using the Arabic Online Commentary Dataset (Zaidan and Suite Type Language CLI API Exposed Pre-processing Morphological Modeling Morphological Disambiguation POS Tagging Diacritization Tokenization/Segementation/Stemming Lemmatization Named"
2020.lrec-1.868,C16-2048,1,0.812555,"Missing"
2020.lrec-1.868,W07-0801,0,0.0619903,"o discuss some of the software suites that have inspired the design of CAMeL Tools. 3.1. NLP Tasks We briefly survey the different efforts for a variety of Arabic NLP tasks. Specifically, we discuss those tasks that are relevant to CAMeL Tools at the time of publishing. These include morphological modeling, NER, DID and SA. Morphological Modeling Efforts on Arabic morphological modeling have varied over a number of dimensions, ranging from very abstract and linguistically rich representations paired with word-form derivation rules (Beesley et al., 1989; Beesley, 1996; Habash and Rambow, 2006; Smrž, 2007) to pre-compiled representations of the different components needed for morphological analysis (Buckwalter, 2002; Graff et al., 2009; Habash, 2007). Previous efforts also show a wide range for the depth of information that morphological analyzers can produce, with very shallow analyzers on one end (Vanni and Zajac, 1996), to analyzers producing form-based, functional, and lexical features as well as morpheme forms (Buckwalter, 2002; Smrž, 2007; Boudlal et al., 2010; Alkuhlani and Habash, 2011; Boudchiche et al., 2017). Systems such as MADA (Habash et al., 2009) and MADAMIRA (Pasha et al., 2014"
2020.lrec-1.868,W18-5816,1,0.846665,"rates how these pre-processing utilities can be applied to an Arabic sentence. Specifically, we apply Arabic to Buckwalter transliteration, letter variant normalization, and tatweel removal. 6. Morphological Modeling Morphology is one of the most studied aspects of the Arabic language. The richness of Arabic makes the modeling of morphology a complex task, justifying the focus put on morphological analysis functionalities. 6.1. Analysis, Generation, and Reinflection As part of CAMeL Tools, we currently provide implementations of the CALIMAStar analyzer, generator, and reinflector described by Taji et al. (2018). These components operate on databases that are in the same format as the ALMORGEANA database (Habash, 2007), which extends the BAMA databases (Buckwalter, 2002) comprising three lexicon tables for prefixes, suffixes, and stems, and three compatibility tables for prefix-suffix, prefix-stem, and stem-suffix. CAMeL Tools include databases for MSA as well as the Egyptian and Gulf dialects. Analysis For our tool’s purposes, we define analysis as the identification of all the different readings (analyses) of a word out of context. Each of these readings is defined by a lexical features such as lem"
2020.lrec-1.868,X96-1024,0,0.19193,"R, DID and SA. Morphological Modeling Efforts on Arabic morphological modeling have varied over a number of dimensions, ranging from very abstract and linguistically rich representations paired with word-form derivation rules (Beesley et al., 1989; Beesley, 1996; Habash and Rambow, 2006; Smrž, 2007) to pre-compiled representations of the different components needed for morphological analysis (Buckwalter, 2002; Graff et al., 2009; Habash, 2007). Previous efforts also show a wide range for the depth of information that morphological analyzers can produce, with very shallow analyzers on one end (Vanni and Zajac, 1996), to analyzers producing form-based, functional, and lexical features as well as morpheme forms (Buckwalter, 2002; Smrž, 2007; Boudlal et al., 2010; Alkuhlani and Habash, 2011; Boudchiche et al., 2017). Systems such as MADA (Habash et al., 2009) and MADAMIRA (Pasha et al., 2014) disambiguate the analyses that are produced by a morphological analyzer. Zalmout and Habash (2017) outline a neural model that follows the same approach. Alternatively, Farasa (Abdelali et al., 2016) relies on probabilistic models to produce high tokenization accuracy, and YAMAMA (Khalifa et al., 2016b) uses the same a"
2020.lrec-1.868,D18-1097,1,0.902222,"Missing"
2020.lrec-1.868,zaghouani-etal-2014-large,1,0.86857,"Missing"
2020.lrec-1.868,P11-2007,0,0.0956214,"Missing"
2020.lrec-1.868,D17-1073,1,0.840819,"phological analysis (Buckwalter, 2002; Graff et al., 2009; Habash, 2007). Previous efforts also show a wide range for the depth of information that morphological analyzers can produce, with very shallow analyzers on one end (Vanni and Zajac, 1996), to analyzers producing form-based, functional, and lexical features as well as morpheme forms (Buckwalter, 2002; Smrž, 2007; Boudlal et al., 2010; Alkuhlani and Habash, 2011; Boudchiche et al., 2017). Systems such as MADA (Habash et al., 2009) and MADAMIRA (Pasha et al., 2014) disambiguate the analyses that are produced by a morphological analyzer. Zalmout and Habash (2017) outline a neural model that follows the same approach. Alternatively, Farasa (Abdelali et al., 2016) relies on probabilistic models to produce high tokenization accuracy, and YAMAMA (Khalifa et al., 2016b) uses the same approach to produce MADAMIRA-like disambiguated analyses. For Arabic dialects, Zalmout et al. (2018) present a neural system that does morphological tagging and disambiguation for Egyptian Arabic. Named Entity Recognition While some Arabic NER systems have used rule-based approaches (Shaalan and Raza, 2009; Zaghouani, 2012; Aboaoga and Aziz, 2013), most recent Arabic NER syste"
2020.lrec-1.868,P19-1173,1,0.889969,"Missing"
2020.lrec-1.868,N18-1087,1,0.850385,"as morpheme forms (Buckwalter, 2002; Smrž, 2007; Boudlal et al., 2010; Alkuhlani and Habash, 2011; Boudchiche et al., 2017). Systems such as MADA (Habash et al., 2009) and MADAMIRA (Pasha et al., 2014) disambiguate the analyses that are produced by a morphological analyzer. Zalmout and Habash (2017) outline a neural model that follows the same approach. Alternatively, Farasa (Abdelali et al., 2016) relies on probabilistic models to produce high tokenization accuracy, and YAMAMA (Khalifa et al., 2016b) uses the same approach to produce MADAMIRA-like disambiguated analyses. For Arabic dialects, Zalmout et al. (2018) present a neural system that does morphological tagging and disambiguation for Egyptian Arabic. Named Entity Recognition While some Arabic NER systems have used rule-based approaches (Shaalan and Raza, 2009; Zaghouani, 2012; Aboaoga and Aziz, 2013), most recent Arabic NER systems integrate machine learning in their architectures (Benajiba and Rosso, 2008; AbdelRahman et al., 2010; Mohammed and Omar, 2012; Oudah and Shaalan, 2012; Darwish, 2013; El Bazi and Laachfoubi, 2019). Benajiba and Rosso (2007) developed ANERsys, one of the earliest NER systems for Arabic. They built their own linguisti"
2020.lrec-1.868,W17-1201,0,0.0517645,"Missing"
2020.udw-1.19,W15-3206,0,0.0215813,"gurations. In this section, we review previous work that was done on developing tools for linguistic annotation, specifically syntactic annotation as well as joint syntax and morphology annotation. While the tools we present here all have great features, some features that we consider key for ease of annotation are also lacking. Morphological Annotation Tools A few tools exist to carry out morphological annotations. CorA (Bollmann et al., 2014) is an annotation tool for ‘non-standard’ language texts in German that has options for normalization, lemmatization, and morphological tagging. DIWAN (Al-Shargi and Rambow, 2015) and MADARi (Obeid et al., 2018) are morphological annotation interfaces designed specifically for Arabic text. Wasim (Alosaimy and Atwell, 2018) is a web-based tool for morphological annotation of inflectional languages that has some support for editing tokenization. None of these tools can be used to annotate for features that are beyond the ones they are initially designed for. Syntactic Annotation Tools The best known tool for dependency treebank creation is TrEd (Pajas, 2008), which is a graph visualization and manipulation program written in Perl. Although it can be configured to automat"
2020.udw-1.19,L18-1621,0,0.0178179,"as well as joint syntax and morphology annotation. While the tools we present here all have great features, some features that we consider key for ease of annotation are also lacking. Morphological Annotation Tools A few tools exist to carry out morphological annotations. CorA (Bollmann et al., 2014) is an annotation tool for ‘non-standard’ language texts in German that has options for normalization, lemmatization, and morphological tagging. DIWAN (Al-Shargi and Rambow, 2015) and MADARi (Obeid et al., 2018) are morphological annotation interfaces designed specifically for Arabic text. Wasim (Alosaimy and Atwell, 2018) is a web-based tool for morphological annotation of inflectional languages that has some support for editing tokenization. None of these tools can be used to annotate for features that are beyond the ones they are initially designed for. Syntactic Annotation Tools The best known tool for dependency treebank creation is TrEd (Pajas, 2008), which is a graph visualization and manipulation program written in Perl. Although it can be configured to automate frequently repeated operations, TrEd does not have a simple option for word tokenization, and can be difficult to install and learn. EasyTree ("
2020.udw-1.19,W14-0612,0,0.0285777,"n created in the context of all the work done on syntactic parsing and morphological analysis. Most tools are designed for one type of annotation only, and have limited configurations. In this section, we review previous work that was done on developing tools for linguistic annotation, specifically syntactic annotation as well as joint syntax and morphology annotation. While the tools we present here all have great features, some features that we consider key for ease of annotation are also lacking. Morphological Annotation Tools A few tools exist to carry out morphological annotations. CorA (Bollmann et al., 2014) is an annotation tool for ‘non-standard’ language texts in German that has options for normalization, lemmatization, and morphological tagging. DIWAN (Al-Shargi and Rambow, 2015) and MADARi (Obeid et al., 2018) are morphological annotation interfaces designed specifically for Arabic text. Wasim (Alosaimy and Atwell, 2018) is a web-based tool for morphological annotation of inflectional languages that has some support for editing tokenization. None of these tools can be used to annotate for features that are beyond the ones they are initially designed for. Syntactic Annotation Tools The best k"
2020.udw-1.19,W06-2920,0,0.192004,"ifferent annotators, such as user management, automatic parsing, and inter-annotator agreement reports. However, there is a tradeoff between having those features and having a lightweight and fast tool that can run offline, which we prioritized. Design and Implementation PALMYRA is a platform independent open-source software2 that is written entirely in JavaScript, HTML, and CSS. This makes it usable with modern browsers without the need of any installation or setup.3 Input File The most commonly used format for dependency parsing currently is the CoNLL-U format, a revised version of CoNLL-X (Buchholz and Marsi, 2006), that was made popular for its use in UD (Nivre et al., 2016). Because we want PALMYRA 2.0 to be usable by people annotating in different dependency representations, we decided to adopt this well established format for our files. Furthermore, PALMYRA 2.0 can be used to display any languages that can be encoded in Unicode. Entries in CoNLL-U files have ten columns that correspond to the following fields: ID, form, lemma, POS, XPOS, features, parent, relation, enhanced dependency, and miscellaneous. The POS field is what is used to populate the tree with POS tags. The XPOS field, if specified i"
2020.udw-1.19,W16-4011,0,0.0423763,"Missing"
2020.udw-1.19,P09-2056,1,0.70445,"d editable when annotating syntax, will allow annotators to look at the annotations in a different light, bringing to their attention different readings that may have been missed otherwise. The richness of a language’s morphology is not necessarily related to the richness of its treebank representation. Arabic, for example, is a very morphologically rich language, and it has different treebanks, with different representations. The Penn Arabic Treebank (PATB) (Maamouri et al., 2003) uses a constituency representation that is rich in morphological features. The Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), on the other hand, is a dependency representation with poor morphology. The designers of CATiB claimed that the simplified morphology was intended among other choices to speed annotation up. This motivated us to create a tool that is configurable and can work for multiple languages and morphosyntactic representations. The existence of these varying treebanks and different approaches to annotation naturally raise the need for a tool that can be used with the different representation schemes and languages. We sum up our desiderata for such a tool as follows: • A tool that is platform independe"
2020.udw-1.19,W19-8010,0,0.01576,"ne kind of annotation. It can be used to annotate syntax, event extraction, named entity detection, and coreference resolution, to mention a few. However, BRAT requires users to login to be able to annotate their text online, and it does not allow for web-based configuration of tag sets, and it does not support word tokenization. Another web-based tool is WebAnno (de Castilho et al., 2016) which allows the annotation of various layers of linguistic annotations, including semantic and syntactic annotations. But similar to BRAT, WebAnno does not support word tokenization. Finally, ConlluEditor (Heinecke, 2019) is an editor designed with UD in mind, allowing for the editing of syntactic information, as well as morphological features. It supports word tokenization editing, and displays multi-word tokens, empty nodes, and enhanced dependencies. However, ConlluEditor requires installation and a server setup. 3 Design Specifications In this section, we discuss the key decisions that we followed in designing PALMYRA 2.0. We are aware that there are various specification that are desirable by different annotators, such as user management, automatic parsing, and inter-annotator agreement reports. However,"
2020.udw-1.19,L18-1345,1,0.894384,"ings of the Fourth Workshop on Universal Dependencies (UDW 2020), pages 168–177 Barcelona, Spain (Online), December 13, 2020 • • • • • • • A tool that is open-source. A tool that is intuitive to use and requires minimal training. A tool that allows the text of the trees to be easily displayed and searched. A tool that can be used at any point in the annotation process. A tool that supports morphologically rich languages. A tool that is usable with various syntactic representations. A tool that is usable with various linguistic features. In our previous work describing the creation of PALMYRA (Javed et al., 2018) (henceforth, PALMYRA 1.0), we addressed platform independence by building a web-based dependency syntax annotation tool that did not require any installation. PALMYRA 1.0 uses an intuitive drag-and-drop interface, and has the options of annotating using both buttons and shortcut keys. PALMYRA 1.0’s most important feature is the ease of fixing tokenization errors caused by morphological analyzers or syntactic parsers, by allowing users to easily split and merge nodes in the displayed trees. In the new iteration of PALMYRA (henceforth, PALMYRA 2.0),1 we extend the tool’s ability to be used with"
2020.udw-1.19,L16-1371,0,0.0169837,"is a web-based tool for morphological annotation of inflectional languages that has some support for editing tokenization. None of these tools can be used to annotate for features that are beyond the ones they are initially designed for. Syntactic Annotation Tools The best known tool for dependency treebank creation is TrEd (Pajas, 2008), which is a graph visualization and manipulation program written in Perl. Although it can be configured to automate frequently repeated operations, TrEd does not have a simple option for word tokenization, and can be difficult to install and learn. EasyTree (Little and Tratz, 2016) is a light-weight tool designed to annotate dependency trees in browsers. It does not maintain sentence order of nodes, and it has no functionality for editing word tokenization. However, EasyTree is very intuitive to use, and it is the base on which PALMYRA is built. EasyTree’s successor, CrowdTree (Tratz and Phan, 2018), is designed to support human-in-the-loop methods as well as crowdsourcing, using a TrEd-inspired interface. It has a backend servlet that can train a parsing model during the annotation process, which helps produce automatic annotations for the annotators to start from. How"
2020.udw-1.19,J93-2004,0,0.0689083,"earch on automatic syntactic and morphological analysis. Treebanks can vary based on the syntactic representations they are in, and the languages they encode. There is a large number of syntactic representations that vary in terms of linguistic theories underlying them, and in terms of their file formats. The Universal Dependency (UD) representation (Nivre et al., 2016) aims to be applicable in all languages. UD is currently one of the most popular representations being available in 90 languages, but many other treebanks are designed for a limited number of languages. The Penn Treebank (PTB) (Marcus et al., 1993) is the most used representation for constituency treebanks, and it is available in a number of different languages including English (Marcus et al., 1993), Arabic (Maamouri et al., 2003), and Chinese (Xue et al., 2005). The Prague Dependency Treebank (PDT) (Böhmová et al., 2003) is another representation used to annotate treebanks in Czech (Böhmová et al., 2003) as well as Arabic (Hajiˇc et al., 2004). The annotation of syntactic trees with morphological features, especially for morphologically rich languages, is often done in a cascading manner: text is annotated first for morphology then fo"
2020.udw-1.19,L18-1415,1,0.848675,"evious work that was done on developing tools for linguistic annotation, specifically syntactic annotation as well as joint syntax and morphology annotation. While the tools we present here all have great features, some features that we consider key for ease of annotation are also lacking. Morphological Annotation Tools A few tools exist to carry out morphological annotations. CorA (Bollmann et al., 2014) is an annotation tool for ‘non-standard’ language texts in German that has options for normalization, lemmatization, and morphological tagging. DIWAN (Al-Shargi and Rambow, 2015) and MADARi (Obeid et al., 2018) are morphological annotation interfaces designed specifically for Arabic text. Wasim (Alosaimy and Atwell, 2018) is a web-based tool for morphological annotation of inflectional languages that has some support for editing tokenization. None of these tools can be used to annotate for features that are beyond the ones they are initially designed for. Syntactic Annotation Tools The best known tool for dependency treebank creation is TrEd (Pajas, 2008), which is a graph visualization and manipulation program written in Perl. Although it can be configured to automate frequently repeated operations"
2020.udw-1.19,pasha-etal-2014-madamira,1,0.879223,"Missing"
2020.udw-1.19,E12-2021,0,0.0809681,"Missing"
2020.udw-1.19,L18-1346,0,0.0113131,"(Pajas, 2008), which is a graph visualization and manipulation program written in Perl. Although it can be configured to automate frequently repeated operations, TrEd does not have a simple option for word tokenization, and can be difficult to install and learn. EasyTree (Little and Tratz, 2016) is a light-weight tool designed to annotate dependency trees in browsers. It does not maintain sentence order of nodes, and it has no functionality for editing word tokenization. However, EasyTree is very intuitive to use, and it is the base on which PALMYRA is built. EasyTree’s successor, CrowdTree (Tratz and Phan, 2018), is designed to support human-in-the-loop methods as well as crowdsourcing, using a TrEd-inspired interface. It has a backend servlet that can train a parsing model during the annotation process, which helps produce automatic annotations for the annotators to start from. However, CrowdTree does not support the annotation of any other linguistic features, or word tokenization. 1 We use the term PALMYRA to refer to the tool generically; and only specify the version number when discussing versionspecific features. 169 Joint Morphology and Syntax Annotation Tools BRAT (Stenetorp et al., 2012) is"
2020.wanlp-1.15,W14-1604,1,0.910419,"t accordingly. For example, the code  ¯ð mixed sequence w aletli Tuesday ‘and she-said-to-me Tuesday’ would be mapped to Tuesday úÍ IËA wqAlt ly Tuesday2 ‘and-she-said to-me Tuesday’. While the input and output here have the same number of words, they are not aligned one-to-one as Arabic spelling rules define words boundaries differently, an additional complexity of the task. There have been a number of efforts in natural language processing (NLP) that worked on this interesting phenomenon using a range of techniques from classical machine learning and n-gram language models (Darwish, 2014; Al-Badrashiny et al., 2014; Eskander et al., 2014) to sequence-to-sequence 1 Arabizi is a cross-lingual portmanteau of the English name of the Arabic language and the Arabic name of the English language, ø Q Êm.&apos; @ Ainjliyziy ‘Inglizi’. 2 All Arabic script examples are paired with a strict 1-to-1 transliteration in the HSB scheme (Habash et al., 2007). This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http:// creativecommons.org/licenses/by/4.0/. 167 Proceedings of the Fifth Arabic Natural Language Processing Workshop, pages 167–177 Barcelona, Spain (Online), Decem"
2020.wanlp-1.15,W14-3612,1,0.863513,"Missing"
2020.wanlp-1.15,Q17-1010,0,0.00730513,"rder of frequency) habibii, hbebe, habibi, 7abiby, 7abibi, hbebee, 7abeby, 7biby, habbii, 7bibi, 7abibii, hbybyy, hbbee, hbbebe, habiibii, habbyy, bbe, 7apipy, 7abiibii, 7abibyy, 7abebe, 169 7abby, 3abiibii, and 3abibi. Similarly, the Arabizi word arfo is paired with three different Arabic words: ςArfh‘I know it’, @ñ¯Q ¯ qrfwA ‘they made me loathe [something]’ and é¯Q ¯ qrfh ‘its nastiness’. é¯PA« We mitigate the noise and variability in modeling the Arabizi-to-Arabic transliteration as a character level sequence-to-sequence process. We also make use of word-level embeddings using FastText (Bojanowski et al., 2017) which models subword units within a bigger word-based context. Additionally, we handle common variations in social media text such as inconsistent capitalization and emphatic repetitions through global lower casing and repetition elision to two characters, e.g., Arabizi Habiiiiiibiiiiii is preprocessed to habiibii. Arabizi-Arabic Mis-alignment The CODA convention we target for Egyptian Arabic does not align word-to-word with Arabizi as explained above. There are both splits and merges of words. In Figure 1, word [5] ageblk ‘I bring to you’ is split into Ë I . J k. @ Ajyb lk, and words [6] an"
2020.wanlp-1.15,W12-4808,0,0.530737,"about 1M Arabizi words that are not tagged or transliterated. An earlier version of this data set was used by Al-Badrashiny et al. (2014) and Eskander et al. (2014). Unfortunately, since the versions used by these earlier efforts do not correspond to the public version of the data set, and are not determinable from it, we cannot compare to them directly. We report in this paper on the latest public version of the data (Chen et al., 2017), and we describe in detail the splits we follow to enable future comparisons with our results (see Section 5.1). 2.2 Pre-neural Models for Arabizi Processing Chalabi and Gerges (2012) presented a hybrid approach for Arabizi transliteration using manual and learned character mapping rules with a language model for ranking hypotheses. Their work does not address the detection of English words, punctuation, emoticons, and so on. Voss et al. (2014) focus on classifying tokens in Arabizi as Arabic or not. They work on a three-way classification of Moroccan Arabic, French and English. Darwish (2014) was the first effort to model the detection of Arabizi and non-Arabizi words before transliterating the Arabizi text. He employed a two-step system for identification and then conver"
2020.wanlp-1.15,D14-1179,0,0.0251242,"Missing"
2020.wanlp-1.15,W14-3629,0,0.634114,"he target script accordingly. For example, the code  ¯ð mixed sequence w aletli Tuesday ‘and she-said-to-me Tuesday’ would be mapped to Tuesday úÍ IËA wqAlt ly Tuesday2 ‘and-she-said to-me Tuesday’. While the input and output here have the same number of words, they are not aligned one-to-one as Arabic spelling rules define words boundaries differently, an additional complexity of the task. There have been a number of efforts in natural language processing (NLP) that worked on this interesting phenomenon using a range of techniques from classical machine learning and n-gram language models (Darwish, 2014; Al-Badrashiny et al., 2014; Eskander et al., 2014) to sequence-to-sequence 1 Arabizi is a cross-lingual portmanteau of the English name of the Arabic language and the Arabic name of the English language, ø Q Êm.&apos; @ Ainjliyziy ‘Inglizi’. 2 All Arabic script examples are paired with a strict 1-to-1 transliteration in the HSB scheme (Habash et al., 2007). This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http:// creativecommons.org/licenses/by/4.0/. 167 Proceedings of the Fifth Arabic Natural Language Processing Workshop, pages 167–177 Barc"
2020.wanlp-1.15,2020.wanlp-1.8,0,0.0107927,"ted the issue of processing Arabizi input with code switching using the data from A RABIZI C ORPUS. They used SVMs and decision trees to identify a larger tag set than Darwish (2014): Arabic, foreign, names, sounds, punctuation and emoticons. For transliteration, they used the Al-Badrashiny et al. (2014) model with more training data. 2.3 Neural Model for Arabizi Processing Deep learning models, specifically sequence-to-sequence (Seq2Seq) RNN models have shown a lot of success in the task of character-based transliteration for a number of languages (Rosca and Breuel, 2016; Kundu et al., 2018; Dershowitz and Terner, 2020). In the context of Arabizi, three efforts are particularly notable (Guellil et al., 2017; Younes et al., 2018; Younes et al., 2020). Guellil et al. (2017) and Younes et al. (2018) worked on mapping Algerian Arabizi and Tunisian Arabizi, respectively, to Arabic script. Both used Seq2Seq models at the character level. Younes et al. (2020) redefined the problem as a sequence labeling task using BiLSTM with CRF decoding. All of these approaches were focused on word-level transliteration and did not address issues of code-mixing and Arabizi identification automatically, although they acknowledge t"
2020.wanlp-1.15,W12-5611,0,0.0398682,"Missing"
2020.wanlp-1.15,N13-1066,1,0.816749,"uellil et al., 2017). We focus here on the work of Bies et al. (2014) since it is the largest by far, and because it targets a wellformed conventional orthography for dialectal Arabic, henceforth A RABIZI C ORPUS. Their data includes over 287K Egyptian Arabizi SMS and chat words that are automatically transliterated and manually validated. The corpus words are tagged for being Foreign, Name, Punctuation, sound, emoji/emoticon or the default Arabic. The Arabic text written in Arabizi is mapped to Arabic script using the conventional orthography for Dialectal Arabic (CODA) (Habash et al., 2012; Eskander et al., 2013; Habash et al., 2018). The CODA convention is close to Standard Arabic orthography while maintaining some of the unique morphological and lexical features of Dialectal Arabic. In addition to using different characters, CODA and Arabizi often use different word boundaries. Moreover, Arabizi is noisy and spontaneous while CODA is intended to be conservative and systematic. In addition to the parallel component, the A RABIZI C ORPUS includes about 1M Arabizi words that are not tagged or transliterated. An earlier version of this data set was used by Al-Badrashiny et al. (2014) and Eskander et al"
2020.wanlp-1.15,W14-3901,1,0.843363,"the code  ¯ð mixed sequence w aletli Tuesday ‘and she-said-to-me Tuesday’ would be mapped to Tuesday úÍ IËA wqAlt ly Tuesday2 ‘and-she-said to-me Tuesday’. While the input and output here have the same number of words, they are not aligned one-to-one as Arabic spelling rules define words boundaries differently, an additional complexity of the task. There have been a number of efforts in natural language processing (NLP) that worked on this interesting phenomenon using a range of techniques from classical machine learning and n-gram language models (Darwish, 2014; Al-Badrashiny et al., 2014; Eskander et al., 2014) to sequence-to-sequence 1 Arabizi is a cross-lingual portmanteau of the English name of the Arabic language and the Arabic name of the English language, ø Q Êm.&apos; @ Ainjliyziy ‘Inglizi’. 2 All Arabic script examples are paired with a strict 1-to-1 transliteration in the HSB scheme (Habash et al., 2007). This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http:// creativecommons.org/licenses/by/4.0/. 167 Proceedings of the Fifth Arabic Natural Language Processing Workshop, pages 167–177 Barcelona, Spain (Online), December 12, 2020 neural mode"
2020.wanlp-1.15,habash-etal-2012-conventional,1,0.71501,"019), and Algerian (Guellil et al., 2017). We focus here on the work of Bies et al. (2014) since it is the largest by far, and because it targets a wellformed conventional orthography for dialectal Arabic, henceforth A RABIZI C ORPUS. Their data includes over 287K Egyptian Arabizi SMS and chat words that are automatically transliterated and manually validated. The corpus words are tagged for being Foreign, Name, Punctuation, sound, emoji/emoticon or the default Arabic. The Arabic text written in Arabizi is mapped to Arabic script using the conventional orthography for Dialectal Arabic (CODA) (Habash et al., 2012; Eskander et al., 2013; Habash et al., 2018). The CODA convention is close to Standard Arabic orthography while maintaining some of the unique morphological and lexical features of Dialectal Arabic. In addition to using different characters, CODA and Arabizi often use different word boundaries. Moreover, Arabizi is noisy and spontaneous while CODA is intended to be conservative and systematic. In addition to the parallel component, the A RABIZI C ORPUS includes about 1M Arabizi words that are not tagged or transliterated. An earlier version of this data set was used by Al-Badrashiny et al. (2"
2020.wanlp-1.15,W18-2411,0,0.0121245,"line. They investigated the issue of processing Arabizi input with code switching using the data from A RABIZI C ORPUS. They used SVMs and decision trees to identify a larger tag set than Darwish (2014): Arabic, foreign, names, sounds, punctuation and emoticons. For transliteration, they used the Al-Badrashiny et al. (2014) model with more training data. 2.3 Neural Model for Arabizi Processing Deep learning models, specifically sequence-to-sequence (Seq2Seq) RNN models have shown a lot of success in the task of character-based transliteration for a number of languages (Rosca and Breuel, 2016; Kundu et al., 2018; Dershowitz and Terner, 2020). In the context of Arabizi, three efforts are particularly notable (Guellil et al., 2017; Younes et al., 2018; Younes et al., 2020). Guellil et al. (2017) and Younes et al. (2018) worked on mapping Algerian Arabizi and Tunisian Arabizi, respectively, to Arabic script. Both used Seq2Seq models at the character level. Younes et al. (2020) redefined the problem as a sequence labeling task using BiLSTM with CRF decoding. All of these approaches were focused on word-level transliteration and did not address issues of code-mixing and Arabizi identification automaticall"
2020.wanlp-1.15,D15-1166,0,0.0739367,"Missing"
2020.wanlp-1.15,D19-3037,0,0.02392,"ntified in a series of ∼80 experiments starting with the hyperparamters of Watson et al. (2018) and tuning to achieve the best accuracy and BLEU score on the dev set. Line2Line vs Word2Word During initial experiments, we observed that the model was rather forgetful and not well performing when fed complete Arabizi input utterances (henceforth, we will refer to this Seq2Seq setting as the L INE 2L INE setting). So, we considered the option of working at a W ORD 2W ORD level similar to Younes et al. (2018) and Guellil et al. (2017), with the exception of adding a small context window similar to Mubarak et al. (2019), which is not itself mapped, but only provides contextual information. Contextual tokens such as beginning of sentence &lt;bos&gt;, end of sentence &lt;eos&gt;, beginning of word (under focus) &lt;bow&gt;, and end of word (under focus) &lt;eow&gt; were added to aid the model in this setting. We experimented with context windows of size three, two, and one words, and found +/- one word to be the best. For example, the three-word Arabizi input Alf salama hahaha ‘A thousand times safe haha’, which is  paired with the Arabic éêë éÓC Ë@ Alf slAm~ hhh, is turned into the following three separate training input-output p"
2020.wanlp-1.15,P02-1040,0,0.107182,"Missing"
2020.wanlp-1.15,P16-1009,0,0.0654759,"Missing"
2020.wanlp-1.15,P16-3008,0,0.0373589,"Missing"
2020.wanlp-1.15,voss-etal-2014-finding,0,0.0216551,"the data set, and are not determinable from it, we cannot compare to them directly. We report in this paper on the latest public version of the data (Chen et al., 2017), and we describe in detail the splits we follow to enable future comparisons with our results (see Section 5.1). 2.2 Pre-neural Models for Arabizi Processing Chalabi and Gerges (2012) presented a hybrid approach for Arabizi transliteration using manual and learned character mapping rules with a language model for ranking hypotheses. Their work does not address the detection of English words, punctuation, emoticons, and so on. Voss et al. (2014) focus on classifying tokens in Arabizi as Arabic or not. They work on a three-way classification of Moroccan Arabic, French and English. Darwish (2014) was the first effort to model the detection of Arabizi and non-Arabizi words before transliterating the Arabizi text. He employed a two-step system for identification and then conversion. For identification, he used word and sequence-level features with CRF modeling to identify three tags: Arabic, foreign and others. For transliteration, he learned character level mappings from a small parallel corpus and used them to generate alternative mapp"
2020.wanlp-1.15,D18-1097,1,0.935465,"hough they acknowledge these issues. In this paper we present a single unified model that addresses the issues of Arabizi identification and conversion together using a Seq2Seq model. Although not Arabizi, a recent effort on automatic conversion of Judeo-Arabic text written in Hebrew script to Arabic script is relevant; Dershowitz and Terner (2020) also used a Seq2Seq RNN model and described a number of interesting tricks for addressing length mismatches and forgetfulness in the network. We refer to specific insights from their work in the paper. Also not Arabizi, but relevant, is the work of Watson et al. (2018), who achieved the current state-ofthe-art on Arabic spelling correction against a standard set using Seq2Seq models. Our baseline Seq2Seq set up is inspired by their work. 3 Arabizi Challenges and Task Definition Our task of mapping code-mixed Egyptian Arabizi and English input into code-mixed Egyptian Arabic and English poses a number of challenges. Arabizi Noise and Ambiguity While there are some common conventions for Arabizi-to-Arabic mapping, they are not strictly followed by far. This is further exacerbated by typical noisy spelling in spontaneous social media text. As a result, we have"
2020.wanlp-1.9,2020.wanlp-1.26,0,0.0901457,"Missing"
2020.wanlp-1.9,2020.wanlp-1.22,0,0.0733884,"Missing"
2020.wanlp-1.9,bouamor-etal-2014-multidialectal,1,0.809064,"received more attention relatively recently (Harrell, 1962; Cowell, 1964; Badawi, 1973; Brustad, 2000; Holes, 2004). A majority of DA computational efforts have targeted creating resources for country or regionally specific dialects (Gadalla et al., 1997; Diab et al., 2010; Al-Sabbagh and Girju, 2012; Sadat et al., 2014; Sma¨ıli et al., 2014; Jarrar et al., 2016; Khalifa et al., 2016; Al-Twairesh et al., 2018; El-Haj, 2020). The expansion into multi-dialectal data sets and models to identify them was initially done at the regional level (Zaidan and Callison-Burch, 2011; Elfardy et al., 2014; Bouamor et al., 2014; Meftouh et al., 2015). A number of Arabic dialect identification shared tasks were organized as part of the VarDial workshop. These focused on regional varieties such as Egyptian, Gulf, Levantine, and North African based on speech broadcast transcriptions (Malmasi et al., 2016) but also acoustic features (Zampieri et al., 2017) and phonetic features (Zampieri et al., 2018) extracted from raw audio. Althobaiti (2020) presents a recent survey of computational work on Arabic dialects. An early effort for creating finer grained parallel dialectal corpus and lexicon was done under the Multi Arabi"
2020.wanlp-1.9,W19-4622,1,0.341438,"translation. Their data was also used for dialectal identification at the city level (Salameh et al., 2018; Obeid et al., 2019) of 25 Arab cities. One issue with the MADAR data in the context of identification is that it was commissioned and not naturally occurring. Concurrently, larger Twitter-based datasets covering 10-21 countries were also introduced (Mubarak and Darwish, 2014; Abdul-Mageed et al., 2018; Zaghouani and Charfi, 2018). Researchers are also starting to introduce DA datasets labeled for socio-pragmatics, e.g., (Abbes et al., 2020; Mubarak et al., 2020). The MADAR shared task (Bouamor et al., 2019) comprised two subtasks, one focusing on 21 Arab countries exploiting Twitter data manually labeled at the user level, and another on 25 Arab cities mentioned above. During the same time as NADI, Abdul-Mageed et al. (2020) describe data and models at country, province, and city levels. The NADI shared task follows these pioneering works by availing data to the (Arabic) NLP community, and encouraging work on Arabic dialects. Similar to the MADAR shared task, we include a country-level dialect identification task (Subtask 1), and a sub-country dialect identification task (Subtask 2). However, ou"
2020.wanlp-1.9,2020.lrec-1.165,0,0.0905249,"2 Related Work As we explained in Section 1, Arabic could be viewed as comprised of 3 main types: CA, MSA, and DA. While CA and MSA have been studied and taught extensively, DA has only received more attention relatively recently (Harrell, 1962; Cowell, 1964; Badawi, 1973; Brustad, 2000; Holes, 2004). A majority of DA computational efforts have targeted creating resources for country or regionally specific dialects (Gadalla et al., 1997; Diab et al., 2010; Al-Sabbagh and Girju, 2012; Sadat et al., 2014; Sma¨ıli et al., 2014; Jarrar et al., 2016; Khalifa et al., 2016; Al-Twairesh et al., 2018; El-Haj, 2020). The expansion into multi-dialectal data sets and models to identify them was initially done at the regional level (Zaidan and Callison-Burch, 2011; Elfardy et al., 2014; Bouamor et al., 2014; Meftouh et al., 2015). A number of Arabic dialect identification shared tasks were organized as part of the VarDial workshop. These focused on regional varieties such as Egyptian, Gulf, Levantine, and North African based on speech broadcast transcriptions (Malmasi et al., 2016) but also acoustic features (Zampieri et al., 2017) and phonetic features (Zampieri et al., 2018) extracted from raw audio. Alth"
2020.wanlp-1.9,2020.wanlp-1.27,0,0.141485,"Missing"
2020.wanlp-1.9,W14-3911,0,0.018515,"tensively, DA has only received more attention relatively recently (Harrell, 1962; Cowell, 1964; Badawi, 1973; Brustad, 2000; Holes, 2004). A majority of DA computational efforts have targeted creating resources for country or regionally specific dialects (Gadalla et al., 1997; Diab et al., 2010; Al-Sabbagh and Girju, 2012; Sadat et al., 2014; Sma¨ıli et al., 2014; Jarrar et al., 2016; Khalifa et al., 2016; Al-Twairesh et al., 2018; El-Haj, 2020). The expansion into multi-dialectal data sets and models to identify them was initially done at the regional level (Zaidan and Callison-Burch, 2011; Elfardy et al., 2014; Bouamor et al., 2014; Meftouh et al., 2015). A number of Arabic dialect identification shared tasks were organized as part of the VarDial workshop. These focused on regional varieties such as Egyptian, Gulf, Levantine, and North African based on speech broadcast transcriptions (Malmasi et al., 2016) but also acoustic features (Zampieri et al., 2017) and phonetic features (Zampieri et al., 2018) extracted from raw audio. Althobaiti (2020) presents a recent survey of computational work on Arabic dialects. An early effort for creating finer grained parallel dialectal corpus and lexicon was done"
2020.wanlp-1.9,2020.wanlp-1.28,0,0.0931316,"Missing"
2021.conll-1.47,W14-3620,0,0.019777,"rankings in Table 3. 5.3 Revisiting the QALB 2014 Shared Task Submissions Our System vs M2 Scorer We compare the M2 Scorer results on the QALB 2014 (Mohit et al., 2014) shared task submissions with F1-based metrics over the error tags produced by A RETA. We calculate the reference error tags using the (Sraw , Sref ) pairs, and compare them to the predicted error tags using the pair (Sraw , Shyp ). The systems outputs we have access to are: CLMB (Rozovskaya et al., 2014), CMUQ (Jeblee et al., 2014), CP13 (Tomeh et al., 2014), CUFE (Nawar and Ragheb, 2014), GLTW (Zerrouki et al., 2014) and GWU (Attia et al., 2014). Table 3 presents these results and their associated system rankings. Table 4 compares the F1based metrics with the M2 Scorer results presented in Table 3 across all of the system outputs using Pearson correlation over F1 scores and rankings, and the average absolute ranking difference. We observe a high correlation between the Weighted Avg and M2 Scorer as well as the Micro Avg and M2 Scorer. In terms of ranking, the Macro Avg has the highest correlation and lowest average ranking difference with M2 Scorer. According to the F1 Weighted Avg, the best performing system is CLMB-1. This matches"
2021.conll-1.47,P17-1074,0,0.27935,"g analyses give helpful insights on the strengths and weaknesses of different submissions, which is more useful than the opaque M2 scoring metrics used in the shared task. A RETA employs a large Arabic morphological analyzer, but is completely unsupervised otherwise. We make A RETA publicly available. by-the-carfs redms bAlsyArh ÂHmr Introduction There has been a lot of interest recently in Automatic Error Evaluation for many languages. Many specialized shared tasks in grammatical error correction (GEC) and text normalization have used tools like M2 Scorer (Dahlmeier and Ng, 2012) and ERRANT (Bryant et al., 2017). In contrast with the opaque results of M2 Scorer based on extracted edits, ERRANT, designed primarily for English, allows for deep interpretation of GEC error types since it gives more detailed explanations. Error type explainability is helpful for many NLP applications, including second language learning. Arabic is a morphologically rich and complex language with a high degree of ambiguity at the orthographic, morphological, syntactic, lexical and semantic levels (Habash, 2010). Figure 1 presents a motivating example for the complexity of Arabic error type annotation (discussion in Section"
2021.conll-1.47,2020.conll-1.7,0,0.0376687,"matically extracts edits from parallel original and corrected sentences and classifies them using a rule-based framework. It was first applied to the CoNLL2014 shared task (Ng et al., 2014) to carry out detailed error type analyses. Most current GEC systems use ERRANT to annotate extracted edits and evaluate system outputs. The ERRANT taxonomy has 25 main error categories. SERRANT (Choshen et al., 2021) is a system for automatic classification of English grammatical errors that combines ERRANT (Bryant et al., 2017) with SE R C L, a taxonomy of Syntactic Errors and an automatic Classification (Choshen et al., 2020). SERRANT uses ERRANT’s annotations when they are informative and those provided by SE R C L otherwise. While the M2 Scorer is generic and can be applied to many languages to extract edits and evaluate GEC system quality, ERRANT and SERRANT focus more on linguistic aspects and give better explainability of error types. However, these frameworks require knowledge about the targeted language and are expensive to build. Furthermore, the ambiguity challenges that are part of the Arabic language make the task even more challenging since the error types can be interpreted differently for many words."
2021.conll-1.47,N12-1067,0,0.253867,"tical error correction. The resulting analyses give helpful insights on the strengths and weaknesses of different submissions, which is more useful than the opaque M2 scoring metrics used in the shared task. A RETA employs a large Arabic morphological analyzer, but is completely unsupervised otherwise. We make A RETA publicly available. by-the-carfs redms bAlsyArh ÂHmr Introduction There has been a lot of interest recently in Automatic Error Evaluation for many languages. Many specialized shared tasks in grammatical error correction (GEC) and text normalization have used tools like M2 Scorer (Dahlmeier and Ng, 2012) and ERRANT (Bryant et al., 2017). In contrast with the opaque results of M2 Scorer based on extracted edits, ERRANT, designed primarily for English, allows for deep interpretation of GEC error types since it gives more detailed explanations. Error type explainability is helpful for many NLP applications, including second language learning. Arabic is a morphologically rich and complex language with a high degree of ambiguity at the orthographic, morphological, syntactic, lexical and semantic levels (Habash, 2010). Figure 1 presents a motivating example for the complexity of Arabic error type a"
2021.conll-1.47,2011.mtsummit-papers.24,1,0.569026,"Missing"
2021.conll-1.47,W14-3618,0,0.034702,"Missing"
2021.conll-1.47,W04-1602,0,0.304548,"Missing"
2021.conll-1.47,W14-3605,1,0.751303,"le 1). The first word èPAJ ËAK. bAlsyArh has an attachable proclitic and as such includes both semantic and orthographic errors. And the second word QÔg @ ÂHmr includes two morphological errors (gender and definiteness). A system to identify the exact error types needs to be aware of not only the complexity of Arabic morphology but also the possibility of multiple co-occurring error types. We address these issues in A RETA’s design. 3 Related Work While M2 Scorer (Dahlmeier and Ng, 2012) has been used for automatic evaluation of GEC shared tasks in different languages (Ng et al., 2014, 2013; Mohit et al., 2014; Rozovskaya et al., 2015), a lot of attention has been paid to annotating and evaluating the output of English text correction systems, e.g., ERRANT (Bryant et al., 2017). There is still a lack of tools that allow such utility for other languages, including Arabic. In the rest of this section, we present the main tools for evaluating and annotating error types, some of the challenges of Arabic processing, and the Arabic error taxonomy which we modify. 3.1 M2 Scorer, ERRANT, and SERRANT The M2 Scorer (Dahlmeier and Ng, 2012) is a tool used for evaluating GEC systems based on F1 or F0.5 scores."
2021.conll-1.47,W14-3619,0,0.0661213,"lation between the M2 Scorer and A RETA’s F1-based metrics and rankings in Table 3. 5.3 Revisiting the QALB 2014 Shared Task Submissions Our System vs M2 Scorer We compare the M2 Scorer results on the QALB 2014 (Mohit et al., 2014) shared task submissions with F1-based metrics over the error tags produced by A RETA. We calculate the reference error tags using the (Sraw , Sref ) pairs, and compare them to the predicted error tags using the pair (Sraw , Shyp ). The systems outputs we have access to are: CLMB (Rozovskaya et al., 2014), CMUQ (Jeblee et al., 2014), CP13 (Tomeh et al., 2014), CUFE (Nawar and Ragheb, 2014), GLTW (Zerrouki et al., 2014) and GWU (Attia et al., 2014). Table 3 presents these results and their associated system rankings. Table 4 compares the F1based metrics with the M2 Scorer results presented in Table 3 across all of the system outputs using Pearson correlation over F1 scores and rankings, and the average absolute ranking difference. We observe a high correlation between the Weighted Avg and M2 Scorer as well as the Micro Avg and M2 Scorer. In terms of ranking, the Macro Avg has the highest correlation and lowest average ranking difference with M2 Scorer. According to the F1 Weight"
2021.conll-1.47,W14-1701,0,0.032101,"ALC error taxonomy (Table 1). The first word èPAJ ËAK. bAlsyArh has an attachable proclitic and as such includes both semantic and orthographic errors. And the second word QÔg @ ÂHmr includes two morphological errors (gender and definiteness). A system to identify the exact error types needs to be aware of not only the complexity of Arabic morphology but also the possibility of multiple co-occurring error types. We address these issues in A RETA’s design. 3 Related Work While M2 Scorer (Dahlmeier and Ng, 2012) has been used for automatic evaluation of GEC shared tasks in different languages (Ng et al., 2014, 2013; Mohit et al., 2014; Rozovskaya et al., 2015), a lot of attention has been paid to annotating and evaluating the output of English text correction systems, e.g., ERRANT (Bryant et al., 2017). There is still a lack of tools that allow such utility for other languages, including Arabic. In the rest of this section, we present the main tools for evaluating and annotating error types, some of the challenges of Arabic processing, and the Arabic error taxonomy which we modify. 3.1 M2 Scorer, ERRANT, and SERRANT The M2 Scorer (Dahlmeier and Ng, 2012) is a tool used for evaluating GEC systems b"
2021.conll-1.47,W13-3601,0,0.07034,"Missing"
2021.conll-1.47,I13-2001,1,0.751257,"Missing"
2021.conll-1.47,J03-1002,0,0.0234236,"Missing"
2021.conll-1.47,W15-3204,1,0.781841,"d èPAJ ËAK. bAlsyArh has an attachable proclitic and as such includes both semantic and orthographic errors. And the second word QÔg @ ÂHmr includes two morphological errors (gender and definiteness). A system to identify the exact error types needs to be aware of not only the complexity of Arabic morphology but also the possibility of multiple co-occurring error types. We address these issues in A RETA’s design. 3 Related Work While M2 Scorer (Dahlmeier and Ng, 2012) has been used for automatic evaluation of GEC shared tasks in different languages (Ng et al., 2014, 2013; Mohit et al., 2014; Rozovskaya et al., 2015), a lot of attention has been paid to annotating and evaluating the output of English text correction systems, e.g., ERRANT (Bryant et al., 2017). There is still a lack of tools that allow such utility for other languages, including Arabic. In the rest of this section, we present the main tools for evaluating and annotating error types, some of the challenges of Arabic processing, and the Arabic error taxonomy which we modify. 3.1 M2 Scorer, ERRANT, and SERRANT The M2 Scorer (Dahlmeier and Ng, 2012) is a tool used for evaluating GEC systems based on F1 or F0.5 scores. It uses a method called M"
2021.conll-1.47,W14-3622,1,0.863279,"Missing"
2021.conll-1.47,C16-2048,1,0.848474,"Missing"
2021.conll-1.47,W18-5816,1,0.833971,"oice (vox), mood (mod), state (stt) and case (cas). Furthermore, Arabic uses a number of attachable proclitics (prc0-2) and enclitics (enc0). Second, Arabic is orthographically very ambiguous due to the use of optional diacritics, which are almost always absent. Figure 2 demonstrates the various analyzes associated with two Arabic words. In some cases the analyses differ in part of speech (POS). To address these challenges, A RETA uses CAMeL Tools (Obeid et al., 2020), an open source Python toolkit for Arabic language processing. CAMeL Tools uses the CALIMA-Star Arabic morphological analyzer (Taji et al., 2018) and provides morphological disambiguation functionality over it. AMEANA (El Kholy and Habash, 2011), which also relies on morphological analyzers to provide morphological error analysis in the context of machine translation evaluation. However, A RETA addresses a wider range of error types, and is intended to be more general. 3.3 The Arabic Learner Corpus Error Taxonomy Alfaifi and Atwell (2014) proposed a taxonomy of 29 error tags for Arabic (See Table 1). They annotated a portion of Arabic Learner Corpus (ALC) dataset such that for each erroneous word, one of the classes of error is given a"
2021.conll-1.47,W14-3614,1,0.888682,"Missing"
2021.conll-1.47,W14-3616,0,0.025188,"d A RETA’s F1-based metrics and rankings in Table 3. 5.3 Revisiting the QALB 2014 Shared Task Submissions Our System vs M2 Scorer We compare the M2 Scorer results on the QALB 2014 (Mohit et al., 2014) shared task submissions with F1-based metrics over the error tags produced by A RETA. We calculate the reference error tags using the (Sraw , Sref ) pairs, and compare them to the predicted error tags using the pair (Sraw , Shyp ). The systems outputs we have access to are: CLMB (Rozovskaya et al., 2014), CMUQ (Jeblee et al., 2014), CP13 (Tomeh et al., 2014), CUFE (Nawar and Ragheb, 2014), GLTW (Zerrouki et al., 2014) and GWU (Attia et al., 2014). Table 3 presents these results and their associated system rankings. Table 4 compares the F1based metrics with the M2 Scorer results presented in Table 3 across all of the system outputs using Pearson correlation over F1 scores and rankings, and the average absolute ranking difference. We observe a high correlation between the Weighted Avg and M2 Scorer as well as the Micro Avg and M2 Scorer. In terms of ranking, the Macro Avg has the highest correlation and lowest average ranking difference with M2 Scorer. According to the F1 Weighted Avg, the best performing sy"
2021.humeval-1.9,W18-5027,1,0.442736,"Missing"
2021.humeval-1.9,W15-4640,0,0.0302165,"t there are less versatile questions (34) than one-sided ones (106) in the dev dialogues. Table 5: SR@k metrics on the test set only for the best performing models on SR@1 and SR@10. Repeating the same analysis on the answers, we have 152 versatile, 237 one-sided, and 118 in the intersection. 6.5 IR Metrics Given that a TOIA’s ability to engage in a conversation depends critically on retrieving a correct answer from the knowledge base, we focus on models (and hence metrics) used for Information Retrieval. The IR metrics we use to evaluate the answer retrieval ability of our TOIA are Recall@k (Lowe et al., 2015), Mean Average Precision (MAP), Mean Reciprocal Rank (MRR), and we include the Success Rate (SR@k) inspired by the work of Sakata et al. (2019). Success Rate is the fraction of questions for which at least one correct answer is ranked among the top k. Table 4 summarizes the retrieval metrics for four of the models we worked with. We added two benchmarks: a model that randomly picks any answer from the KB, and we used the average crowd ratings’ as a ‘retrieval’ model. When we compare the avatar maker’s annotations vs. the crowd’s annotations, we label an answer as ‘correct’ for the 81 Question"
2021.humeval-1.9,D19-5817,0,0.0259754,"hey require recording about 2,000 answers for building an avatar (Nishiyama et al., 2016; Jones, 2005). While these works focus more 1 https://ict.usc.edu/prototypes/vita/ www.soulmachines.com 3 www.storyfile.com 2 76 form dialogue format. Moreover, such systems often use text generation models which we didn’t use in our TOIA. Text generation methodologies are usually evaluated with n-gram based metrics (Merdivan et al., 2020) such as BLEU (Papineni et al., 2002), ROUGE (Lin, 2004) and METEOR (Banerjee and Lavie, 2005), which are often criticized for their poor alignment with human judgement (Chen et al., 2019). Across all these works as well as the datasets presented for study free-form conversations, there is a gap in addressing the question of what is a ‘good’ answer. This is an important question to address not only for evaluating the relevant NLP tasks, but also for defining an annotation methodology. 2.3 use – and for TOIAs in general – is too small for deep learning. We manage to overcome this limitation for a sentence similarity model (more on this in the next section) and plan to leverage transfer learning in future work. 3 Chierici et al. (2020) recorded twenty dialogues with twenty differ"
2021.humeval-1.9,2020.lrec-1.60,1,0.803263,"d for their poor alignment with human judgement (Chen et al., 2019). Across all these works as well as the datasets presented for study free-form conversations, there is a gap in addressing the question of what is a ‘good’ answer. This is an important question to address not only for evaluating the relevant NLP tasks, but also for defining an annotation methodology. 2.3 use – and for TOIAs in general – is too small for deep learning. We manage to overcome this limitation for a sentence similarity model (more on this in the next section) and plan to leverage transfer learning in future work. 3 Chierici et al. (2020) recorded twenty dialogues with twenty different interrogators who were each instructed to engage in a 15-minute conversation with a TOIA’s avatar maker. They then used ten randomly picked dialogues to define the training set (in the original data, these dialogues are labeled as ‘train’ but here we call them ‘development’ or ‘dev’ set as we use them as such). They used these dialogues as the inspiration for defining the KB of q-a pairs the avatar maker recorded in the TOIA. The MDC comprises conversations ‘on-topic’ and ‘wild’: half of the conversations are about the university attended by the"
2021.humeval-1.9,P02-1040,0,0.114122,"tries.2,3 The most recent TOIAs involve significant production costs, they are mainly used as museum attractions or training prototypes for the army, and they require recording about 2,000 answers for building an avatar (Nishiyama et al., 2016; Jones, 2005). While these works focus more 1 https://ict.usc.edu/prototypes/vita/ www.soulmachines.com 3 www.storyfile.com 2 76 form dialogue format. Moreover, such systems often use text generation models which we didn’t use in our TOIA. Text generation methodologies are usually evaluated with n-gram based metrics (Merdivan et al., 2020) such as BLEU (Papineni et al., 2002), ROUGE (Lin, 2004) and METEOR (Banerjee and Lavie, 2005), which are often criticized for their poor alignment with human judgement (Chen et al., 2019). Across all these works as well as the datasets presented for study free-form conversations, there is a gap in addressing the question of what is a ‘good’ answer. This is an important question to address not only for evaluating the relevant NLP tasks, but also for defining an annotation methodology. 2.3 use – and for TOIAs in general – is too small for deep learning. We manage to overcome this limitation for a sentence similarity model (more on"
2021.humeval-1.9,W11-0609,0,0.02527,"Missing"
2021.humeval-1.9,D16-1264,0,0.324623,"estion, different conversational question-answer threads may unravel. Also, not unexpected, different answers to a specific question can be acceptable and not cause a change in the overall conversational flow. So, how can we answer the question what is a ‘good’ (i.e., ‘right’, ‘correct’ or ‘relevant’) answer? Introduction Time-Offset Interaction Applications (TOIAs) (Artstein et al., 2015) are a sort of chatbot applications that lie between Question Answering (QA) and Information Retrieval (IR). They differ from QA in that a TOIA’s task is not about demonstrating comprehension of a text span (Rajpurkar et al., 2016; Reddy et al., 2019) but selecting a single (one-shot) appropriate answer from a restricted set of answers, a problem also known as Answer Retrieval (AR) or retrieval-based dialogue (Boussaha et al., 2019). Ideal TOIA interactions are expected to mirror a dialogue with a real person, including all the posWe explore this question using a publicly available dataset that was manually annotated by its avatar maker – the Margarita Dialogue Corpus (MDC) (Chierici et al., 2020). The best performing 75 Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval), pages 75–85 Online, April"
2021.humeval-1.9,Q19-1016,0,0.116557,"sational question-answer threads may unravel. Also, not unexpected, different answers to a specific question can be acceptable and not cause a change in the overall conversational flow. So, how can we answer the question what is a ‘good’ (i.e., ‘right’, ‘correct’ or ‘relevant’) answer? Introduction Time-Offset Interaction Applications (TOIAs) (Artstein et al., 2015) are a sort of chatbot applications that lie between Question Answering (QA) and Information Retrieval (IR). They differ from QA in that a TOIA’s task is not about demonstrating comprehension of a text span (Rajpurkar et al., 2016; Reddy et al., 2019) but selecting a single (one-shot) appropriate answer from a restricted set of answers, a problem also known as Answer Retrieval (AR) or retrieval-based dialogue (Boussaha et al., 2019). Ideal TOIA interactions are expected to mirror a dialogue with a real person, including all the posWe explore this question using a publicly available dataset that was manually annotated by its avatar maker – the Margarita Dialogue Corpus (MDC) (Chierici et al., 2020). The best performing 75 Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval), pages 75–85 Online, April 19, 2021. ©2021 Asso"
2021.humeval-1.9,J05-1001,0,0.177201,"s (transfer learning and low resources corpora). 2.1 The Evaluation Problem Recent TOIAs TOIAs have applications in a number of practical scenarios. For example, they are used for keeping historical memories (Traum et al., 2015b), job interview practice for young adults with developmental disabilities,1 and building digital humans across different industries.2,3 The most recent TOIAs involve significant production costs, they are mainly used as museum attractions or training prototypes for the army, and they require recording about 2,000 answers for building an avatar (Nishiyama et al., 2016; Jones, 2005). While these works focus more 1 https://ict.usc.edu/prototypes/vita/ www.soulmachines.com 3 www.storyfile.com 2 76 form dialogue format. Moreover, such systems often use text generation models which we didn’t use in our TOIA. Text generation methodologies are usually evaluated with n-gram based metrics (Merdivan et al., 2020) such as BLEU (Papineni et al., 2002), ROUGE (Lin, 2004) and METEOR (Banerjee and Lavie, 2005), which are often criticized for their poor alignment with human judgement (Chen et al., 2019). Across all these works as well as the datasets presented for study free-form conve"
2021.humeval-1.9,D16-1230,0,0.0392245,"Missing"
2021.humeval-1.9,W15-4629,0,0.186042,"retrieve an answer from a knowledge base and engage in a freeRelated Work We present a number of recent TOIAs, and data sets relevant for their study and development. While most of the related work focuses on large corpora, working with small datasets and addressing evaluation issues of TOIAs are interesting, practical problems both for the IR (what is ‘relevant’?) and the NLP communities (transfer learning and low resources corpora). 2.1 The Evaluation Problem Recent TOIAs TOIAs have applications in a number of practical scenarios. For example, they are used for keeping historical memories (Traum et al., 2015b), job interview practice for young adults with developmental disabilities,1 and building digital humans across different industries.2,3 The most recent TOIAs involve significant production costs, they are mainly used as museum attractions or training prototypes for the army, and they require recording about 2,000 answers for building an avatar (Nishiyama et al., 2016; Jones, 2005). While these works focus more 1 https://ict.usc.edu/prototypes/vita/ www.soulmachines.com 3 www.storyfile.com 2 76 form dialogue format. Moreover, such systems often use text generation models which we didn’t use i"
2021.humeval-1.9,D19-1670,0,0.0128026,"questions in the MDC’s dialogue sets (c). 4 Retrieval Models in the KB, we labeled them as 1’s to indicate a relevant match. We then sampled a number of irrelevant (or ‘wrong’) matches for every question, and labeled them as 0’s. We tried different sampling ratios, namely drawing one wrong match for every correct one (1:1), ten wrong ones (1:10), a hundred (1:100) and using all the available utterances (1:All). To increase the data size further and better generalize for questions phrased differently, we augmented the train data by sampling synthetic questions using the methodology proposed by Wei and Zou (2019) and their Python implementation.5 We fine-tuned BERT for 3 more epochs (we chose a few epochs as advised by Dodge et al. (2020)) using Wolf et al. (2019)’s Transformers library. We only report on BERT q-A 1:100 and BERT q-A 1:All as they were the best performing. We used five models for retrieving answers for the questions in the MDC dialogue dataset, and for shortlisting the top candidate responses for the ‘crowd’ annotation task. (1) TF-IDF q-Q: Let q be a query from a user (in our case, a question in the MDC dialogue dataset), and Q a question annotated in the MDC KB. We vectorized q and Q"
2021.humeval-1.9,2020.emnlp-demos.6,0,0.0363981,"Missing"
2021.sigdial-1.29,W18-5027,1,0.927605,"(aka avatar) may require prerecording about 2,000 video answers (Nishiyama et al., 2016; Jones, 2005). Chierici et al. (2020) proposed a more streamlined avatar development process, but it is still impractical for the everyday user: it involves transcribing and recording conversations based on brainstormed plausible utterances. Their work resulted in creating more than 400 prerecordings and manual annotations that took several days. Research into time-offset interactions needs to generalize and to streamline the avatar development process to make a mass use system. A first attempt made by Abu Ali et al. (2018) goes towards this direction and includes the possibility to chat with the avatars in different languages. Their system implementation is not simple to use because it has two separate, non-communicating components for recording videos and interacting with them. It also requires local installation and does not support multiple users. 1 https://ict.usc.edu/prototypes/vita/ www.storyfile.com,www.videoask.com 3 www.digitalhumans.com 4 www.soulmachines.com 2 265 Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 265–268 July 29–31, 2021. ©2021 Asso"
2021.sigdial-1.29,2021.humeval-1.9,1,0.852152,"Missing"
2021.sigdial-1.29,2020.lrec-1.60,1,0.774061,"abilities,1 and building digital humans across different industries. Storyfile, Typeform’s videoask are some examples of commercial applications.2 TOIAs may also be reminiscent of virtual assistants like Siri and Alexa and digitally animated characters like Digital Humans,3 and Soul Machines;4 however, these are not authentic representations of human beings which is TOIAs’ goal. The general public cannot afford current TOIA deployments due to their high production costs: creating a character (aka avatar) may require prerecording about 2,000 video answers (Nishiyama et al., 2016; Jones, 2005). Chierici et al. (2020) proposed a more streamlined avatar development process, but it is still impractical for the everyday user: it involves transcribing and recording conversations based on brainstormed plausible utterances. Their work resulted in creating more than 400 prerecordings and manual annotations that took several days. Research into time-offset interactions needs to generalize and to streamline the avatar development process to make a mass use system. A first attempt made by Abu Ali et al. (2018) goes towards this direction and includes the possibility to chat with the avatars in different languages. T"
2021.sigmorphon-1.25,K18-3001,1,0.679933,"l marker used for expressing case, familiarity, plurality, and (sometimes) gender within animate nouns. Pronouns are marked for different cases and honorificity levels. These paradigms are generated on the basis of a manually annotated corpus of Magahi folktales. We used a raw dataset from the literary domain. First, we annotated the dataset with the Universal Dependency morphological feature tags at token level using the CoNLL-U editor (Heinecke, 2019). We then converted the annotated dataset into the UniMorph schema using the script available for converting UD data into the UniMorph tagset (McCarthy et al., 2018). To finalize the data, we manually validated the dataset against the UniMorph schema (Sylak-Glassman et al., 2015a). Brajbhasha, or Braj is one of the Indo-Aryan languages spoken in the Western Indian states of Uttar Pradesh, Madhya Pradesh, and Rajasthan. Grierson (1908) groups Brajbhasha under Western Hindi of the Central Group in the Indo-Aryan family, along with other languages like Hindustani, Bangaru, Kannauji, and Bundeli. Braj is not generally used in education or for any official purposes in any Braj spoken state, but it has a very rich literary tradition. Also in order to preserve,"
2021.sigmorphon-1.25,K17-2001,1,0.858355,"Missing"
2021.sigmorphon-1.25,U19-1001,1,0.893844,"nje-ng ‘1/3PL-again-wrong-BENmeat-cook-PP’ (“I cooked the wrong meat for them again”). As shown, the form has several prefixes and suffixes attached to the stem. As in other Australian languages, long vowels are typically represented by double characters, and trills with “rr”.3 According to Evans’ (2003) analysis, the verb template contains 12 affix slots which include two incorporated noun classes, and derivational affixes such as the benefactive and comitative. The data included in this set are verbs extracted from the Kunwinjku translation of the Bible using the morphological analyzer from Lane and Bird (2019) and manually verified by human annotators. 3.2 Afro-Asiatic The Afro-Asiatic language family is represented by the Semitic subgroup. 3.2.1 Semitic: Classical Syriac Classical Syriac is a dialect of the Aramaic language and is attested as early as the 1st century CE. As with most Semitic languages, it displays non-concatenative morphology involving primarily tri-consonantal roots. Syriac nouns and adjectives are conventionally classified into three ‘states’— Emphatic, Absolute, Construct—which loosely correlate with the syntactic features of definiteness, indeterminacy and the genitive. There"
2021.sigmorphon-1.25,U19-1005,1,0.782664,"respect to morphology and realized in the UniMorph schema (Sylak-Glassman et al., 2015b). Morphosyntactic features (such as “the dative case” or “the past tense”) in the UniMorph occupy an intermediate position between the descriptive categories and comparative concepts. The set of features was initially established on the basis of analysis of typological literature, and refined with the addition of new languages to the UniMorph database (Kirov et al., 2018; McCarthy et al., 2020). Since 2016, SIGMORPHON organized shared tasks on morphological reinflection (Cotterell et al., 2016, 2017, 2018; McCarthy et al., 2019; Vylomova et al., 2020) that aimed at evaluating contemporary systems. Parallel to that, they also served as a platform for enriching the UniMorph database with new languages. For instance, the 2020 shared task (Vylomova et al., 2020) featured 90 typologically diverse languages derived from various linguistic resources. This year, we are bringing many under-resourced languages (languages of Peru, Russia, India, Australia, Papua New Guinea) and dialects (e.g., for Arabic and Kurdish). The sample is highly diverse: it contains languages with templatic, concatenative (fusional and agglutinative)"
2021.sigmorphon-1.25,W02-0604,0,0.0878472,"Missing"
2021.sigmorphon-1.25,U08-1018,0,0.0643919,"through affixation, compounding, or reduplication. The four types of Indonesian affixes are prefixes, suffixes, circumfixes (combination of prefixes and suffixes), and infixes (inside the base form). Indonesian uses both full and partial reduplication processes to form words. Full reduplication is often used to express the plural forms of nouns, while partial reduplication is typically used to derive forms that might have a different category than their base forms. Unlike English, the distinction between inflectional and derivational morphological processes in Indonesian is not always clear (Pisceldo et al., 2008). In this shared task, the Indonesian data is created by bootstrapping the data from an Indonesian Wikipedia dump. Using a list of possible Indonesian affixes, we collect unique word forms from Wikipedia and analyze them using MorphInd (Larasati et al., 2011), a morphological analyzer tool for Indonesian based on an FST. We manually create a mapping between the MorphInd tagset and the UniMorph schema. We then use this mapping and apply some additional rule-based formulas created by Indonesian linguists to build the final dataset (Table 9). 3.9.2 Malayo-Polynesian: Kodi/Kodhi Kodi or Kodhi [koâ"
2021.sigmorphon-1.25,N19-1119,0,0.0213266,"ugmentation technique presented by Anastasopoulos and Neubig (2019). More specifically, the team implemented an encoder–decoder model with an attention mechanism. The encoder processes a character sequence using an LSTM-based RNN with attention. Tags are encoded with a selfattention (Vaswani et al., 2017) position-invariant module. The decoder is an LSTM with separate attention mechanisms for the lemma and the tags. GUClasp focus their efforts on exploring strategies for training a multilingual model, in particular, they implement the following strategies: curriculum learning with competence (Platanios et al., 2019) based on character frequency and L BME GUClasp afb amh ara arz heb syc ame cni ind kod aym ckt itl gup bra bul ces ckb deu kmr mag nld pol por rus spa see ail evn sah tyv krl lud olo vep 92.39 98.16 99.76 95.27 97.46 21.71 82.46 99.5 81.31 94.62 99.98 44.74 32.4 14.75 58.52 98.9 98.03 99.46 97.98 98.21 70.2 98.28 99.54 99.85 98.07 99.82 78.28 6.84 51.9 99.95 99.97 99.88 59.46 99.72 99.72 81.71 93.81 94.86 87.12 89.93 10.57 55.94 93.36 55.68 87.1 99.97 52.63 31.28 21.31 56.91 96.46 94.00 96.60 91.94 98.09 72.24 94.91 98.52 99.11 94.32 97.65 40.97 6.46 51.5 99.69 99.78 98.50 59.46 98.2 97.05 sj"
2021.sigmorphon-1.25,2020.acl-main.597,1,0.915066,"arget inflected form—and removed all forms other than verbs, nouns, or adjectives. We then capped the dataset sizes to a maximum of 100,000 instances per language, subsampling when necessary. Finally, we create a 70–10–20 train–dev–test split per language, splitting the data across these sets at the instance level (as opposed to, e.g., the lemma one). As such, the information about a lemma’s declension or inflection class is spread out across these train, dev and test sets, making this task much simpler than if one had to predict the entire class from the lemma’s form alone, as done by, e.g., Williams et al. (2020) and Liu and Hulden (2021). 5 Baseline Systems The organizers provide four neural systems as baselines, a product of two models and optional data augmentation. The first model is a transformer (Vaswani et al., 2017, TRM), and the second model is an adaption of the transformer to character-level transduction tasks (Wu et al., 2021, CHR-TRM), which holds the state-of-the-art on the 2017 SIGMORPHON shared task data. Both models follow the hyperparameters of Wu et al. (2021). The optional data augmentation follows the technique proposed by Anastasopoulos and Neubig (2019). Rely14 The new languages"
2021.wanlp-1.10,N16-3003,0,0.0268095,"data is known a priori to be CA, then we select the CAMeLBERT-CA model; if the task data is known to be MSA, we select the CAMeLBERT-MSA model; otherwise, we use the CAMeLBERT-Mix model (for dialects, i.e.). We report on this model in Table 4 and 5 as CAMeLBERT-Star. It is noteworthy that this model is not the same as Comparison with Existing Models Table 5 compares our work with other existing models. We do not use models that require morphological pre-tokenization to allow direct comparison, and also because existing tokenization systems are mostly focused on MSA or EGY (Pasha et al., 2014; Abdelali et al., 2016; Obeid et al., 2020). We are aware that design decisions such as vocabulary size and number of training steps are not the same across these eight existing pre-trained models, which might be a contributing factor to their varying performances. We plan to investigate the effects of such decisions in future work. Task Performance Complementarity The best model on average is AraBERTv02 (X3 ); it wins or ties for a win in six out of 12 subtasks (four MSA and two DA). Our CAMeLBERT-Star is second overall on average, and it wins or ties for a win in four out of 12 subtasks (three DA, one CA). Intere"
2021.wanlp-1.10,2020.wanlp-1.9,1,0.906045,"tant than the pre-training data size. We exploit this insight in defining an optimized system selection model for the studied tasks. 1 Introduction Pre-trained language models such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019b) have shown significant success in a wide range of natural language processing (NLP) tasks in various languages. Arabic has benefited from extensive efforts in building dedicated pre-trained language models, achieving state-of-the-art results in a number of NLP tasks, across both Modern Standard Arabic (MSA) and Dialectal Arabic (DA) (Antoun et al., 2020; Abdul-Mageed et al., 2020a). However, it is hard to compare these models to understand what contributes to their performances because of their different design decisions and hyperparameters, such as data size, language variant, tokenization, vocabulary size, number of training steps, and so forth. Practically, one may empirically choose the best performing pre-trained model by fine-tuning it on a particular task; however, it is still unclear why a particular model is performing better than another and what design choices are contributing to its performance. To answer this question, we pre-trained various language mode"
2021.wanlp-1.10,W19-4621,0,0.0128008,"sets using the accuracy score. 4.3 Sentiment Analysis Dataset We used a combination of sentiment analysis datasets to fine-tune our models. The datasets are: (1) the Arabic Speech-Act and Sentiment Corpus of Tweets (ArSAS) (Elmadany et al., 2018); (2) the Arabic Sentiment Tweets Dataset (ASTD) (Nabil et al., 2015); (3) SemEval-2017 task 4-A benchmark dataset (Rosenthal et al., 2017); and (4) the Multi-Topic Corpus for Target-based Sentiment Analysis in Arabic Levantine Tweets (ArSenTD-Lev) (Baly et al., 2019). We combined and preprocessed the datasets in a similar way to what was done by Abu Farha and Magdy (2019) and Obeid et al. (2020). That is, we removed diacritics, URLs, and Twitter usernames from all the tweets. Experimental Setup Our models were finetuned on ArSenTD-Lev and the train splits from SemEval, ASTD, and ArSAS (23,327 tweets) on a single GPU for 3 epochs with a learning rate of 3e-5, batch size of 32, and a maximum sequence length of 128. After the fine-tuning, we used the best checkpoint based on a single dev set from SemEval, ASTD, and ArSAS to report results on the test sets. We used the F1P N score which was defined in the SemEval-2017 task 4-A; F1P N is the macro F1 score over the"
2021.wanlp-1.10,L18-1576,0,0.0321346,"Missing"
2021.wanlp-1.10,2020.osact-1.2,0,0.2166,"ng data is more important than the pre-training data size. We exploit this insight in defining an optimized system selection model for the studied tasks. 1 Introduction Pre-trained language models such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019b) have shown significant success in a wide range of natural language processing (NLP) tasks in various languages. Arabic has benefited from extensive efforts in building dedicated pre-trained language models, achieving state-of-the-art results in a number of NLP tasks, across both Modern Standard Arabic (MSA) and Dialectal Arabic (DA) (Antoun et al., 2020; Abdul-Mageed et al., 2020a). However, it is hard to compare these models to understand what contributes to their performances because of their different design decisions and hyperparameters, such as data size, language variant, tokenization, vocabulary size, number of training steps, and so forth. Practically, one may empirically choose the best performing pre-trained model by fine-tuning it on a particular task; however, it is still unclear why a particular model is performing better than another and what design choices are contributing to its performance. To answer this question, we pre-tr"
2021.wanlp-1.10,bouamor-etal-2014-multidialectal,1,0.880214,"Missing"
2021.wanlp-1.10,W19-4622,1,0.848151,"28. After the fine-tuning, we used the best checkpoint based on a single dev set from SemEval, ASTD, and ArSAS to report results on the test sets. We used the F1P N score which was defined in the SemEval-2017 task 4-A; F1P N is the macro F1 score over the positive and negative classes only while neglecting the neutral class. 4.4 Dialect Identification Dataset We fine-tuned our models on four different dialect identification datasets: (1) MADAR Corpus 26 which includes 26 labels; (2) MADAR Corpus 6 which includes six labels; (3) MADAR Twitter Corpus (Bouamor et al., 2018; Salameh et al., 2018; Bouamor et al., 2019) which includes 21 labels; and (4) NADI Country-level (AbdulMageed et al., 2020b) which includes 21 labels. The datasets were preprocessed by removing diacritics, URLs, and Twitter usernames while maintaining the same train, dev, and test splits for each dataset. Moreover, we collated the tweets belonging to a particular user in the MADAR Twitter Corpus in groups of 5 before feeding them to the model. We refer to this preprocessed version as MADARTwitter-5 to avoid confusion with the publicly available original MADAR Twitter Corpus. Experimental Setup Our models were finetuned for 10 epochs wi"
2021.wanlp-1.10,2020.acl-main.493,0,0.0111152,"itched pre-training using Wikipedia, Gigaword, and the OSCAR corpus. Most recently, Abdul-Mageed et al. (2020a) developed two models, ARBERT and MARBERT, pre-trained on a large collection of datasets in MSA and DA. They reported new stateof-the-art results on the majority of the datasets in their fine-tuning benchmark. Moreover, there have been various studies explaining why pre-trained language models perform well on downstream tasks either in monolingual (Hewitt and Manning, 2019; Jawahar et al., 2019; Liu et al., 2019a; Tenney et al., 2019a,b) or multilingual settings (Wu and Dredze, 2019; Chi et al., 2020; Kulmizev et al., 2020; Vuli´c et al., 2020). Most of these efforts leveraged probing techniques to explore the linguistic knowledge that is captured by pre-trained language models such as morphosyntactic and semantic knowledge. More recently, there have been additional efforts investigating the effects of pre-training data size and tokenization on the performance of pre-trained language models. Zhang et al. (2020) showed that pre-training RoBERTa requires 10M to 100M words to learn representations that reliably encode most syntactic and semantic features. However, a much larger quantity of d"
2021.wanlp-1.10,cotterell-callison-burch-2014-multi,0,0.0688368,"Missing"
2021.wanlp-1.10,N19-1423,0,0.173218,"three. We also examine the importance of pre-training data size by building additional models that are pre-trained on a scaled-down set of the MSA variant. We compare our different models to each other, as well as to eight publicly available models by fine-tuning them on five NLP tasks spanning 12 datasets. Our results suggest that the variant proximity of pre-training data to fine-tuning data is more important than the pre-training data size. We exploit this insight in defining an optimized system selection model for the studied tasks. 1 Introduction Pre-trained language models such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019b) have shown significant success in a wide range of natural language processing (NLP) tasks in various languages. Arabic has benefited from extensive efforts in building dedicated pre-trained language models, achieving state-of-the-art results in a number of NLP tasks, across both Modern Standard Arabic (MSA) and Dialectal Arabic (DA) (Antoun et al., 2020; Abdul-Mageed et al., 2020a). However, it is hard to compare these models to understand what contributes to their performances because of their different design decisions and hyperparameters, such as data size,"
2021.wanlp-1.10,2020.acl-main.375,0,0.0145807,"g using Wikipedia, Gigaword, and the OSCAR corpus. Most recently, Abdul-Mageed et al. (2020a) developed two models, ARBERT and MARBERT, pre-trained on a large collection of datasets in MSA and DA. They reported new stateof-the-art results on the majority of the datasets in their fine-tuning benchmark. Moreover, there have been various studies explaining why pre-trained language models perform well on downstream tasks either in monolingual (Hewitt and Manning, 2019; Jawahar et al., 2019; Liu et al., 2019a; Tenney et al., 2019a,b) or multilingual settings (Wu and Dredze, 2019; Chi et al., 2020; Kulmizev et al., 2020; Vuli´c et al., 2020). Most of these efforts leveraged probing techniques to explore the linguistic knowledge that is captured by pre-trained language models such as morphosyntactic and semantic knowledge. More recently, there have been additional efforts investigating the effects of pre-training data size and tokenization on the performance of pre-trained language models. Zhang et al. (2020) showed that pre-training RoBERTa requires 10M to 100M words to learn representations that reliably encode most syntactic and semantic features. However, a much larger quantity of data is needed for the m"
2021.wanlp-1.10,2020.lrec-1.165,0,0.0537853,"Missing"
2021.wanlp-1.10,N19-1419,0,0.0123424,"eral English-Arabic bilingual models dubbed GigaBERTs, where they studied the effectiveness of cross-lingual transfer learning and code-switched pre-training using Wikipedia, Gigaword, and the OSCAR corpus. Most recently, Abdul-Mageed et al. (2020a) developed two models, ARBERT and MARBERT, pre-trained on a large collection of datasets in MSA and DA. They reported new stateof-the-art results on the majority of the datasets in their fine-tuning benchmark. Moreover, there have been various studies explaining why pre-trained language models perform well on downstream tasks either in monolingual (Hewitt and Manning, 2019; Jawahar et al., 2019; Liu et al., 2019a; Tenney et al., 2019a,b) or multilingual settings (Wu and Dredze, 2019; Chi et al., 2020; Kulmizev et al., 2020; Vuli´c et al., 2020). Most of these efforts leveraged probing techniques to explore the linguistic knowledge that is captured by pre-trained language models such as morphosyntactic and semantic knowledge. More recently, there have been additional efforts investigating the effects of pre-training data size and tokenization on the performance of pre-trained language models. Zhang et al. (2020) showed that pre-training RoBERTa requires 10M to 1"
2021.wanlp-1.10,P19-1356,0,0.0138436,"ual models dubbed GigaBERTs, where they studied the effectiveness of cross-lingual transfer learning and code-switched pre-training using Wikipedia, Gigaword, and the OSCAR corpus. Most recently, Abdul-Mageed et al. (2020a) developed two models, ARBERT and MARBERT, pre-trained on a large collection of datasets in MSA and DA. They reported new stateof-the-art results on the majority of the datasets in their fine-tuning benchmark. Moreover, there have been various studies explaining why pre-trained language models perform well on downstream tasks either in monolingual (Hewitt and Manning, 2019; Jawahar et al., 2019; Liu et al., 2019a; Tenney et al., 2019a,b) or multilingual settings (Wu and Dredze, 2019; Chi et al., 2020; Kulmizev et al., 2020; Vuli´c et al., 2020). Most of these efforts leveraged probing techniques to explore the linguistic knowledge that is captured by pre-trained language models such as morphosyntactic and semantic knowledge. More recently, there have been additional efforts investigating the effects of pre-training data size and tokenization on the performance of pre-trained language models. Zhang et al. (2020) showed that pre-training RoBERTa requires 10M to 100M words to learn rep"
2021.wanlp-1.10,2020.emnlp-main.382,0,0.084089,"Missing"
2021.wanlp-1.10,N19-1112,0,0.148226,"nce of pre-training data size by building additional models that are pre-trained on a scaled-down set of the MSA variant. We compare our different models to each other, as well as to eight publicly available models by fine-tuning them on five NLP tasks spanning 12 datasets. Our results suggest that the variant proximity of pre-training data to fine-tuning data is more important than the pre-training data size. We exploit this insight in defining an optimized system selection model for the studied tasks. 1 Introduction Pre-trained language models such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019b) have shown significant success in a wide range of natural language processing (NLP) tasks in various languages. Arabic has benefited from extensive efforts in building dedicated pre-trained language models, achieving state-of-the-art results in a number of NLP tasks, across both Modern Standard Arabic (MSA) and Dialectal Arabic (DA) (Antoun et al., 2020; Abdul-Mageed et al., 2020a). However, it is hard to compare these models to understand what contributes to their performances because of their different design decisions and hyperparameters, such as data size, language variant, tokenization"
2021.wanlp-1.10,Y15-1004,0,0.0604818,"Missing"
2021.wanlp-1.10,2020.emnlp-main.632,0,0.0875708,"Missing"
2021.wanlp-1.10,D15-1299,0,0.0732032,"Missing"
2021.wanlp-1.10,2020.acl-main.156,0,0.0825257,"Missing"
2021.wanlp-1.10,pasha-etal-2014-madamira,1,0.837299,"Missing"
2021.wanlp-1.10,S17-2088,0,0.065031,"Missing"
2021.wanlp-1.10,2020.semeval-1.271,0,0.417822,"Missing"
2021.wanlp-1.10,salama-etal-2014-youdacc,1,0.882439,"Missing"
2021.wanlp-1.10,C18-1113,1,0.815036,"m sequence length of 128. After the fine-tuning, we used the best checkpoint based on a single dev set from SemEval, ASTD, and ArSAS to report results on the test sets. We used the F1P N score which was defined in the SemEval-2017 task 4-A; F1P N is the macro F1 score over the positive and negative classes only while neglecting the neutral class. 4.4 Dialect Identification Dataset We fine-tuned our models on four different dialect identification datasets: (1) MADAR Corpus 26 which includes 26 labels; (2) MADAR Corpus 6 which includes six labels; (3) MADAR Twitter Corpus (Bouamor et al., 2018; Salameh et al., 2018; Bouamor et al., 2019) which includes 21 labels; and (4) NADI Country-level (AbdulMageed et al., 2020b) which includes 21 labels. The datasets were preprocessed by removing diacritics, URLs, and Twitter usernames while maintaining the same train, dev, and test splits for each dataset. Moreover, we collated the tweets belonging to a particular user in the MADAR Twitter Corpus in groups of 5 before feeding them to the model. We refer to this preprocessed version as MADARTwitter-5 to avoid confusion with the publicly available original MADAR Twitter Corpus. Experimental Setup Our models were fin"
2021.wanlp-1.10,P19-1452,0,0.014568,"tudied the effectiveness of cross-lingual transfer learning and code-switched pre-training using Wikipedia, Gigaword, and the OSCAR corpus. Most recently, Abdul-Mageed et al. (2020a) developed two models, ARBERT and MARBERT, pre-trained on a large collection of datasets in MSA and DA. They reported new stateof-the-art results on the majority of the datasets in their fine-tuning benchmark. Moreover, there have been various studies explaining why pre-trained language models perform well on downstream tasks either in monolingual (Hewitt and Manning, 2019; Jawahar et al., 2019; Liu et al., 2019a; Tenney et al., 2019a,b) or multilingual settings (Wu and Dredze, 2019; Chi et al., 2020; Kulmizev et al., 2020; Vuli´c et al., 2020). Most of these efforts leveraged probing techniques to explore the linguistic knowledge that is captured by pre-trained language models such as morphosyntactic and semantic knowledge. More recently, there have been additional efforts investigating the effects of pre-training data size and tokenization on the performance of pre-trained language models. Zhang et al. (2020) showed that pre-training RoBERTa requires 10M to 100M words to learn representations that reliably encode most s"
2021.wanlp-1.10,2020.emnlp-main.586,0,0.0697447,"Missing"
2021.wanlp-1.10,D19-1077,0,0.0209708,"learning and code-switched pre-training using Wikipedia, Gigaword, and the OSCAR corpus. Most recently, Abdul-Mageed et al. (2020a) developed two models, ARBERT and MARBERT, pre-trained on a large collection of datasets in MSA and DA. They reported new stateof-the-art results on the majority of the datasets in their fine-tuning benchmark. Moreover, there have been various studies explaining why pre-trained language models perform well on downstream tasks either in monolingual (Hewitt and Manning, 2019; Jawahar et al., 2019; Liu et al., 2019a; Tenney et al., 2019a,b) or multilingual settings (Wu and Dredze, 2019; Chi et al., 2020; Kulmizev et al., 2020; Vuli´c et al., 2020). Most of these efforts leveraged probing techniques to explore the linguistic knowledge that is captured by pre-trained language models such as morphosyntactic and semantic knowledge. More recently, there have been additional efforts investigating the effects of pre-training data size and tokenization on the performance of pre-trained language models. Zhang et al. (2020) showed that pre-training RoBERTa requires 10M to 100M words to learn representations that reliably encode most syntactic and semantic features. However, a much la"
2021.wanlp-1.10,L18-1111,0,0.0536388,"Missing"
2021.wanlp-1.10,P11-2007,0,0.0981301,"Missing"
2021.wanlp-1.10,W19-4619,0,0.0350489,"Missing"
2021.wanlp-1.23,N16-3003,0,0.0575386,"Missing"
2021.wanlp-1.23,W14-1604,1,0.821641,"efulness. Commonly used name transliterations (Al-Onaizan and Knight, 2002) and so-called Arabizi transliteration (Darwish, 2014) tend to be lossy and inconsistent while strict orthographic transliterations such as Buckwalter’s (Buckwalter, 2004) tend to be exact but not easily readable. The ALA-LC transliteration is a relatively easy to read standard that requires a lot of details on phonology, morphology and semantics. There has been a sizable amount of work on mapping Arabizi to Arabic script using a range of techniques from rules to neural models Chalabi and Gerges (2012); Darwish (2014); Al-Badrashiny et al. (2014); Guellil et al. (2017); Younes et al. (2018); Shazal et al. (2020). In this paper we make use of a number of insights and techniques from work on Arabizi-to-Arabic script transliteration, but apply them in the opposite direction to map from Arabic script to a complex, detailed and strict Romanization. We compare rule-based and corpus-based techniques including a Seq2Seq model based on the publicly available code base of Shazal et al. (2020). 3 Data Collection Sources We collected bibliographic records from three publicly available xml dumps stored in the machine-readable cataloguing (MARC) st"
2021.wanlp-1.23,N09-1045,1,0.600799,"a number of special cases, e.g., the word áK bn ‘son of’ is Romanized as ibn, and proper noun ðQÔ« ςmrw is Romanized as ‘Amr. 5 Romanization Models We compare multiple Romanization models built using four basic techniques with different expectation about training data availability, contextual modeling, and system complexity. The models are listed in Table 2. CharTrans Technique Our baseline technique is an extremely simple character transliteration approach utilizing regular expressions and exception lists. This technique is built based on the ALA-LC guidelines, and is inspired by the work of Biadsy et al. (2009); it comprises 104 regex, 13 exceptions, and one capitalization rule (for entry-initial words). This technique accepts diacritized, undiacritized or partially diacritized input. Model Rules Simple uses CharTrans only. MorphTrans Technique This technique relies on the morphological disambiguation system MADAMIRA (Pasha et al., 2014) to provide diacritization, morpheme boundaries, POS tags and English glosses for the Arabic input. Morpheme boundaries are used to identify clitic hyphenation points. POS tags and capitalization in English glosses are used to decide on what to capitalize in the tran"
2021.wanlp-1.23,W12-4808,0,0.0350571,"ing in terms of detail, consistency, and usefulness. Commonly used name transliterations (Al-Onaizan and Knight, 2002) and so-called Arabizi transliteration (Darwish, 2014) tend to be lossy and inconsistent while strict orthographic transliterations such as Buckwalter’s (Buckwalter, 2004) tend to be exact but not easily readable. The ALA-LC transliteration is a relatively easy to read standard that requires a lot of details on phonology, morphology and semantics. There has been a sizable amount of work on mapping Arabizi to Arabic script using a range of techniques from rules to neural models Chalabi and Gerges (2012); Darwish (2014); Al-Badrashiny et al. (2014); Guellil et al. (2017); Younes et al. (2018); Shazal et al. (2020). In this paper we make use of a number of insights and techniques from work on Arabizi-to-Arabic script transliteration, but apply them in the opposite direction to map from Arabic script to a complex, detailed and strict Romanization. We compare rule-based and corpus-based techniques including a Seq2Seq model based on the publicly available code base of Shazal et al. (2020). 3 Data Collection Sources We collected bibliographic records from three publicly available xml dumps stored"
2021.wanlp-1.23,D14-1179,0,0.006458,"Missing"
2021.wanlp-1.23,W14-3629,0,0.0292663,", and CAMeL Tools (Obeid et al., 2020). In this paper we use MADAMIRA to provide diacritics, morpheme boundaries and English gloss capitalization information as part of a rulebased Romanization technique. Machine Transliteration Transliteration refers to the mapping of text from one script to another. Romanization is specifically transliteration into the Roman script (Beesley, 1997). There are many ways to transliterate and Romanize, varying in terms of detail, consistency, and usefulness. Commonly used name transliterations (Al-Onaizan and Knight, 2002) and so-called Arabizi transliteration (Darwish, 2014) tend to be lossy and inconsistent while strict orthographic transliterations such as Buckwalter’s (Buckwalter, 2004) tend to be exact but not easily readable. The ALA-LC transliteration is a relatively easy to read standard that requires a lot of details on phonology, morphology and semantics. There has been a sizable amount of work on mapping Arabizi to Arabic script using a range of techniques from rules to neural models Chalabi and Gerges (2012); Darwish (2014); Al-Badrashiny et al. (2014); Guellil et al. (2017); Younes et al. (2018); Shazal et al. (2020). In this paper we make use of a nu"
2021.wanlp-1.23,L16-1681,1,0.883471,"Missing"
2021.wanlp-1.23,D15-1166,0,0.00800557,"t of vocabulary), we back off to the MorphTrans technique (Model MLE Morph) or CharTrans Technique (Model MLE Simple). In Table 2, we also study the performance of MLE Simple with different corpus sizes. Seq2Seq Technique Our last technique also relies on existing training data. We use an encoderdecoder character-level sequence-to-sequence architecture closely following Shazal et al. (2020) (although in reverse direction). The encoder consists of two gated recurrent unit (GRU) layers (Cho et al., 2014) with only the first layer being bidirectional, and the decoder has two GRUs with attention (Luong et al., 2015). For the input, we used character embeddings concatenated with embeddings of the words in which the characters appear. For all other setting details, see Shazal et al. (2020)’s Line2Line model. We also show how Seq2Seq performs with different corpus sizes in Table 2. The Seq2Seq technique is known for occasionally dropping tokens, which in our case leads to misalignment with the Arabic input. To handle this issue in model Seq2Seq, we align its output and fill such gaps using the outputs produced by three other techniques, thus creating models Seq2Seq+Rules Morph, Seq2Seq+MLE Simple, and Seq2S"
2021.wanlp-1.23,pasha-etal-2014-madamira,1,0.852124,"Missing"
2021.wanlp-1.23,2020.wanlp-1.15,1,0.898534,") and so-called Arabizi transliteration (Darwish, 2014) tend to be lossy and inconsistent while strict orthographic transliterations such as Buckwalter’s (Buckwalter, 2004) tend to be exact but not easily readable. The ALA-LC transliteration is a relatively easy to read standard that requires a lot of details on phonology, morphology and semantics. There has been a sizable amount of work on mapping Arabizi to Arabic script using a range of techniques from rules to neural models Chalabi and Gerges (2012); Darwish (2014); Al-Badrashiny et al. (2014); Guellil et al. (2017); Younes et al. (2018); Shazal et al. (2020). In this paper we make use of a number of insights and techniques from work on Arabizi-to-Arabic script transliteration, but apply them in the opposite direction to map from Arabic script to a complex, detailed and strict Romanization. We compare rule-based and corpus-based techniques including a Seq2Seq model based on the publicly available code base of Shazal et al. (2020). 3 Data Collection Sources We collected bibliographic records from three publicly available xml dumps stored in the machine-readable cataloguing (MARC) standard, an international standard for storing and describing biblio"
2021.wanlp-1.28,bouamor-etal-2014-multidialectal,1,0.782333,"A has received more attention only in recent years. One major challenge with studying DA has been rarity of resources. For this reason, most pioneering DA works focused on creating resources, usually for only a small number of regions or countries (Gadalla et al., 1997; Diab et al., 2010; AlSabbagh and Girju, 2012; Sadat et al., 2014; Sma¨ıli et al., 2014; Jarrar et al., 2016; Khalifa et al., 2016; Al-Twairesh et al., 2018; El-Haj, 2020). A number of works introducing multi-dialectal data sets and regional level detection models followed (Zaidan and Callison-Burch, 2011; Elfardy et al., 2014; Bouamor et al., 2014; Meftouh et al., 2015). The Multi Arabic Dialects Application and Resources (MADAR) project (Bouamor et al., 2018) introduced finer-grained dialectal data and a lexicon. The MADAR data were used for dialect identification at the city level (Salameh et al., 2018; Obeid et al., 2019) of 25 Arab cities. An issue with the MADAR data, in the context of DA identification, is that it was commissioned and not naturally occurring. Several larger datasets covering 10-21 countries were also introduced (Mubarak and Darwish, 2014; Abdul-Mageed et al., 2018; Zaghouani and Charfi, 2018). These datasets come"
2021.wanlp-1.28,W19-4622,1,0.537072,"classification level next. 3.1 Country-level Classification • Subtask 1.1: Country-level MSA. The goal of Subtask 1.1 is to identify country level MSA from short written sentences (tweets). NADI 2021 Subtask 1.1 is novel since no previous works focused on teasing apart MSA by country of origin. • Subtask 1.2: Country-level DA. Subtask 1.2 is similar to Subtask 1.1, but focuses on identifying country level dialect from tweets. Subtask 1.2 is similar to previous works that have also taken country as their target (Mubarak and Darwish, 2014; Abdul-Mageed et al., 2018; Zaghouani and Charfi, 2018; Bouamor et al., 2019; Abdul-Mageed et al., 2020b). We provided labeled data to NADI 2021 participants with specific training (TRAIN) and development (DEV) splits. Each of the 21 labels corresponding to the 21 countries is represented in both TRAIN and DEV. Teams could score their models through an online system (codalab) on the DEV set before the deadline. We released our TEST set of unlabeled tweets shortly before the system submission deadline. We then invited participants to submit their predictions to the online scoring system housing the gold TEST set labels. Table 2 shows the distribution of the TRAIN, DEV,"
2021.wanlp-1.28,2020.lrec-1.165,0,0.0729724,"Arabic has three main categories: CA, MSA, and DA. While CA and MSA have been studied extensively (Harrell, 1962; Cowell, 1964; Badawi, 1973; Brustad, 2000; Holes, 2004), DA has received more attention only in recent years. One major challenge with studying DA has been rarity of resources. For this reason, most pioneering DA works focused on creating resources, usually for only a small number of regions or countries (Gadalla et al., 1997; Diab et al., 2010; AlSabbagh and Girju, 2012; Sadat et al., 2014; Sma¨ıli et al., 2014; Jarrar et al., 2016; Khalifa et al., 2016; Al-Twairesh et al., 2018; El-Haj, 2020). A number of works introducing multi-dialectal data sets and regional level detection models followed (Zaidan and Callison-Burch, 2011; Elfardy et al., 2014; Bouamor et al., 2014; Meftouh et al., 2015). The Multi Arabic Dialects Application and Resources (MADAR) project (Bouamor et al., 2018) introduced finer-grained dialectal data and a lexicon. The MADAR data were used for dialect identification at the city level (Salameh et al., 2018; Obeid et al., 2019) of 25 Arab cities. An issue with the MADAR data, in the context of DA identification, is that it was commissioned and not naturally occur"
2021.wanlp-1.28,W14-3911,0,0.0207609,"2000; Holes, 2004), DA has received more attention only in recent years. One major challenge with studying DA has been rarity of resources. For this reason, most pioneering DA works focused on creating resources, usually for only a small number of regions or countries (Gadalla et al., 1997; Diab et al., 2010; AlSabbagh and Girju, 2012; Sadat et al., 2014; Sma¨ıli et al., 2014; Jarrar et al., 2016; Khalifa et al., 2016; Al-Twairesh et al., 2018; El-Haj, 2020). A number of works introducing multi-dialectal data sets and regional level detection models followed (Zaidan and Callison-Burch, 2011; Elfardy et al., 2014; Bouamor et al., 2014; Meftouh et al., 2015). The Multi Arabic Dialects Application and Resources (MADAR) project (Bouamor et al., 2018) introduced finer-grained dialectal data and a lexicon. The MADAR data were used for dialect identification at the city level (Salameh et al., 2018; Obeid et al., 2019) of 25 Arab cities. An issue with the MADAR data, in the context of DA identification, is that it was commissioned and not naturally occurring. Several larger datasets covering 10-21 countries were also introduced (Mubarak and Darwish, 2014; Abdul-Mageed et al., 2018; Zaghouani and Charfi, 2018"
2021.wanlp-1.28,2021.wanlp-1.32,0,0.0786186,"Missing"
2021.wanlp-1.28,L16-1679,1,0.731098,"5. 2 Related Work As we explained in Section 1, Arabic has three main categories: CA, MSA, and DA. While CA and MSA have been studied extensively (Harrell, 1962; Cowell, 1964; Badawi, 1973; Brustad, 2000; Holes, 2004), DA has received more attention only in recent years. One major challenge with studying DA has been rarity of resources. For this reason, most pioneering DA works focused on creating resources, usually for only a small number of regions or countries (Gadalla et al., 1997; Diab et al., 2010; AlSabbagh and Girju, 2012; Sadat et al., 2014; Sma¨ıli et al., 2014; Jarrar et al., 2016; Khalifa et al., 2016; Al-Twairesh et al., 2018; El-Haj, 2020). A number of works introducing multi-dialectal data sets and regional level detection models followed (Zaidan and Callison-Burch, 2011; Elfardy et al., 2014; Bouamor et al., 2014; Meftouh et al., 2015). The Multi Arabic Dialects Application and Resources (MADAR) project (Bouamor et al., 2018) introduced finer-grained dialectal data and a lexicon. The MADAR data were used for dialect identification at the city level (Salameh et al., 2018; Obeid et al., 2019) of 25 Arab cities. An issue with the MADAR data, in the context of DA identification, is that it"
2021.wanlp-1.28,N19-4002,1,0.803112,"2010; AlSabbagh and Girju, 2012; Sadat et al., 2014; Sma¨ıli et al., 2014; Jarrar et al., 2016; Khalifa et al., 2016; Al-Twairesh et al., 2018; El-Haj, 2020). A number of works introducing multi-dialectal data sets and regional level detection models followed (Zaidan and Callison-Burch, 2011; Elfardy et al., 2014; Bouamor et al., 2014; Meftouh et al., 2015). The Multi Arabic Dialects Application and Resources (MADAR) project (Bouamor et al., 2018) introduced finer-grained dialectal data and a lexicon. The MADAR data were used for dialect identification at the city level (Salameh et al., 2018; Obeid et al., 2019) of 25 Arab cities. An issue with the MADAR data, in the context of DA identification, is that it was commissioned and not naturally occurring. Several larger datasets covering 10-21 countries were also introduced (Mubarak and Darwish, 2014; Abdul-Mageed et al., 2018; Zaghouani and Charfi, 2018). These datasets come from the Twitter domain, and hence are naturally-occurring. Several works have also focused on sociopragmatics meaning exploiting dialectal data. These include sentiment analysis (Abdul-Mageed et al., 2014), emotion (Alhuzali et al., 2018), age and gender (Abbes et al., 2020), offe"
2021.wanlp-1.28,W14-5904,0,0.0248499,", and a high-level description of submitted systems in Section 5. 2 Related Work As we explained in Section 1, Arabic has three main categories: CA, MSA, and DA. While CA and MSA have been studied extensively (Harrell, 1962; Cowell, 1964; Badawi, 1973; Brustad, 2000; Holes, 2004), DA has received more attention only in recent years. One major challenge with studying DA has been rarity of resources. For this reason, most pioneering DA works focused on creating resources, usually for only a small number of regions or countries (Gadalla et al., 1997; Diab et al., 2010; AlSabbagh and Girju, 2012; Sadat et al., 2014; Sma¨ıli et al., 2014; Jarrar et al., 2016; Khalifa et al., 2016; Al-Twairesh et al., 2018; El-Haj, 2020). A number of works introducing multi-dialectal data sets and regional level detection models followed (Zaidan and Callison-Burch, 2011; Elfardy et al., 2014; Bouamor et al., 2014; Meftouh et al., 2015). The Multi Arabic Dialects Application and Resources (MADAR) project (Bouamor et al., 2018) introduced finer-grained dialectal data and a lexicon. The MADAR data were used for dialect identification at the city level (Salameh et al., 2018; Obeid et al., 2019) of 25 Arab cities. An issue wit"
2021.wanlp-1.28,C18-1113,1,0.850076,"., 1997; Diab et al., 2010; AlSabbagh and Girju, 2012; Sadat et al., 2014; Sma¨ıli et al., 2014; Jarrar et al., 2016; Khalifa et al., 2016; Al-Twairesh et al., 2018; El-Haj, 2020). A number of works introducing multi-dialectal data sets and regional level detection models followed (Zaidan and Callison-Burch, 2011; Elfardy et al., 2014; Bouamor et al., 2014; Meftouh et al., 2015). The Multi Arabic Dialects Application and Resources (MADAR) project (Bouamor et al., 2018) introduced finer-grained dialectal data and a lexicon. The MADAR data were used for dialect identification at the city level (Salameh et al., 2018; Obeid et al., 2019) of 25 Arab cities. An issue with the MADAR data, in the context of DA identification, is that it was commissioned and not naturally occurring. Several larger datasets covering 10-21 countries were also introduced (Mubarak and Darwish, 2014; Abdul-Mageed et al., 2018; Zaghouani and Charfi, 2018). These datasets come from the Twitter domain, and hence are naturally-occurring. Several works have also focused on sociopragmatics meaning exploiting dialectal data. These include sentiment analysis (Abdul-Mageed et al., 2014), emotion (Alhuzali et al., 2018), age and gender (Abbe"
2021.wanlp-1.28,2021.wanlp-1.35,0,0.0644144,"Missing"
2021.wanlp-1.28,L18-1111,0,0.109857,"2011; Elfardy et al., 2014; Bouamor et al., 2014; Meftouh et al., 2015). The Multi Arabic Dialects Application and Resources (MADAR) project (Bouamor et al., 2018) introduced finer-grained dialectal data and a lexicon. The MADAR data were used for dialect identification at the city level (Salameh et al., 2018; Obeid et al., 2019) of 25 Arab cities. An issue with the MADAR data, in the context of DA identification, is that it was commissioned and not naturally occurring. Several larger datasets covering 10-21 countries were also introduced (Mubarak and Darwish, 2014; Abdul-Mageed et al., 2018; Zaghouani and Charfi, 2018). These datasets come from the Twitter domain, and hence are naturally-occurring. Several works have also focused on sociopragmatics meaning exploiting dialectal data. These include sentiment analysis (Abdul-Mageed et al., 2014), emotion (Alhuzali et al., 2018), age and gender (Abbes et al., 2020), offensive language (Mubarak et al., 2020), and sarcasm (Abu Farha and Magdy, 2020). Concurrent with our work, (Abdul-Mageed et al., 2020c) also describe data and models at country, province, and city levels. 1 The dataset is accessible via our GitHub at: https: //github.com/UBC-NLP/nadi. 245 The fir"
2021.wanlp-1.28,P11-2007,0,0.0259273,"ell, 1964; Badawi, 1973; Brustad, 2000; Holes, 2004), DA has received more attention only in recent years. One major challenge with studying DA has been rarity of resources. For this reason, most pioneering DA works focused on creating resources, usually for only a small number of regions or countries (Gadalla et al., 1997; Diab et al., 2010; AlSabbagh and Girju, 2012; Sadat et al., 2014; Sma¨ıli et al., 2014; Jarrar et al., 2016; Khalifa et al., 2016; Al-Twairesh et al., 2018; El-Haj, 2020). A number of works introducing multi-dialectal data sets and regional level detection models followed (Zaidan and Callison-Burch, 2011; Elfardy et al., 2014; Bouamor et al., 2014; Meftouh et al., 2015). The Multi Arabic Dialects Application and Resources (MADAR) project (Bouamor et al., 2018) introduced finer-grained dialectal data and a lexicon. The MADAR data were used for dialect identification at the city level (Salameh et al., 2018; Obeid et al., 2019) of 25 Arab cities. An issue with the MADAR data, in the context of DA identification, is that it was commissioned and not naturally occurring. Several larger datasets covering 10-21 countries were also introduced (Mubarak and Darwish, 2014; Abdul-Mageed et al., 2018; Zagh"
2021.wanlp-1.28,W17-1201,0,0.0998386,"Missing"
2021.wanlp-1.28,W18-3901,0,0.0455917,"Missing"
altantawy-etal-2010-morphological,C96-1017,0,\N,Missing
altantawy-etal-2010-morphological,C94-1029,0,\N,Missing
altantawy-etal-2010-morphological,J00-1006,0,\N,Missing
altantawy-etal-2010-morphological,P05-1071,1,\N,Missing
altantawy-etal-2010-morphological,W05-0703,1,\N,Missing
altantawy-etal-2010-morphological,P06-1086,1,\N,Missing
ayan-etal-2004-multi,carbonell-etal-2002-automatic,0,\N,Missing
ayan-etal-2004-multi,J93-2004,0,\N,Missing
ayan-etal-2004-multi,J93-2003,0,\N,Missing
ayan-etal-2004-multi,H01-1035,0,\N,Missing
ayan-etal-2004-multi,N01-1026,0,\N,Missing
ayan-etal-2004-multi,E99-1010,0,\N,Missing
ayan-etal-2004-multi,P02-1040,0,\N,Missing
ayan-etal-2004-multi,P02-1033,0,\N,Missing
ayan-etal-2004-multi,P01-1067,0,\N,Missing
ayan-etal-2004-multi,P03-1012,0,\N,Missing
ayan-etal-2004-multi,P02-1050,0,\N,Missing
ayan-etal-2004-multi,J00-2004,0,\N,Missing
ayan-etal-2004-multi,P03-2041,0,\N,Missing
ayan-etal-2004-multi,J97-2004,0,\N,Missing
ayan-etal-2004-multi,N03-1017,0,\N,Missing
ayan-etal-2004-multi,P02-1038,0,\N,Missing
ayan-etal-2004-multi,J03-1002,0,\N,Missing
ayan-etal-2004-multi,N03-1013,1,\N,Missing
ayan-etal-2004-multi,2003.mtsummit-systems.9,1,\N,Missing
ayan-etal-2004-multi,dorr-etal-2002-duster,1,\N,Missing
ayan-etal-2004-multi,P98-1004,0,\N,Missing
ayan-etal-2004-multi,C98-1004,0,\N,Missing
ayan-etal-2004-multi,P98-2162,0,\N,Missing
ayan-etal-2004-multi,C98-2157,0,\N,Missing
ayan-etal-2004-multi,P96-1024,0,\N,Missing
bouamor-etal-2014-multidialectal,N12-1006,0,\N,Missing
bouamor-etal-2014-multidialectal,2006.amta-papers.21,0,\N,Missing
bouamor-etal-2014-multidialectal,E06-1047,1,\N,Missing
bouamor-etal-2014-multidialectal,P13-2001,0,\N,Missing
bouamor-etal-2014-multidialectal,J14-1006,0,\N,Missing
bouamor-etal-2014-multidialectal,P11-1122,0,\N,Missing
bouamor-etal-2014-multidialectal,N13-1036,1,\N,Missing
bouamor-etal-2014-multidialectal,habash-etal-2012-conventional,1,\N,Missing
bouamor-etal-2014-multidialectal,N13-1044,1,\N,Missing
bouamor-etal-2014-multidialectal,pasha-etal-2014-madamira,1,\N,Missing
bouamor-etal-2014-multidialectal,I13-1048,0,\N,Missing
bouamor-etal-2014-multidialectal,zribi-etal-2014-conventional,1,\N,Missing
bouamor-etal-2014-multidialectal,P13-2081,0,\N,Missing
bouamor-etal-2014-multidialectal,al-sabbagh-girju-2010-mining,0,\N,Missing
bouamor-etal-2014-multidialectal,W12-2301,1,\N,Missing
bouamor-etal-2014-multidialectal,N07-5003,1,\N,Missing
C12-3048,E06-1047,1,0.890911,"Much work has been done on Modern Standard Arabic (MSA) natural language processing (NLP) and machine translation (MT). MSA has a wealth of resources in terms of morphological analyzers, disambiguation systems, annotated data, and parallel corpora. In comparison, research on dialectal Arabic (DA), the unstandardized spoken varieties of Arabic, is still lacking in NLP in general and MT in particular. In this paper we present Elissa, our DA-to-MSA MT system.1 To process Arabic dialects with available MSA tools, researchers have used different techniques to map DA words to their MSA equivalents (Chiang et al., 2006; Sawaf, 2010; Salloum and Habash, 2011). Having a publicly available tool that translates DAs to MSA can help researchers extend their MSA resources and tools to cover different Arabic dialects. Elissa currently handles Levantine, Egyptian, Iraqi, and to a lesser degree Gulf Arabic. The Elissa approach can be summarized as follows. First, Elissa uses different techniques to identify dialectal words in a source sentence. Then, Elissa produces MSA paraphrases for the selected words using a rule-based component that depends on the existence of a dialectal morphological analyzer, a list of morpho"
C12-3048,W05-0708,0,0.216695,"tized forms: Levantine wHayikitbuwhA and MSA wasayaktubuwnahA. All of the NLP challenges of MSA (e.g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DA-English corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Habash et al., 2012). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over one-third of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 1 Elissa’s home page can be found at http://nlp.ldeo.columbia.edu/elissa/. Arabic transliteration is presented in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007): (in alphabetical order) ˇ ¯  ˇ ςγfqklmnhwy and the additional symbols: ’ Z, Â @, A Abtθ jHxdðrzsšSDTD @, A @, wˆ ð&apos;, yˆ Zø&apos;, ħh è, ý ø. 2 386 3"
C12-3048,C12-2029,0,0.118833,"r. 1 Elissa’s home page can be found at http://nlp.ldeo.columbia.edu/elissa/. Arabic transliteration is presented in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007): (in alphabetical order) ˇ ¯  ˇ ςγfqklmnhwy and the additional symbols: ’ Z, Â @, A Abtθ jHxdðrzsšSDTD @, A @, wˆ ð&apos;, yˆ Zø&apos;, ħh è, ý ø. 2 386 3 Related Work Much work has been done in the context of MSA NLP (Habash, 2010). In contrast, research on DA NLP is still in its early stages: (Kilany et al., 2002; Kirchhoff et al., 2003; Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Chiang et al., 2006; Habash et al., 2012; Elfardy and Diab, 2012). Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA or other methods to collect word-pair lists have been explored (Abo Bakr et al., 2008; Sawaf, 2010; Salloum and Habash, 2011). Using closely related languages has been shown to improve MT quality when resources are limited (Hajiˇc"
C12-3048,W12-2301,1,0.132946,"g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DA-English corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Habash et al., 2012). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over one-third of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 1 Elissa’s home page can be found at http://nlp.ldeo.columbia.edu/elissa/. Arabic transliteration is presented in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007): (in alphabetical order) ˇ ¯  ˇ ςγfqklmnhwy and the additional symbols: ’ Z, Â @, A Abtθ jHxdðrzsšSDTD @, A @, wˆ ð&apos;, yˆ Zø&apos;, ħh è, ý ø. 2 386 3 Related Work Much work has been done in the context of MSA NLP (Habash, 2010). In contrast, rese"
C12-3048,P05-1071,1,0.899978,"Missing"
C12-3048,P06-1086,1,0.080244,"ayikitbuwhA and MSA wasayaktubuwnahA. All of the NLP challenges of MSA (e.g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DA-English corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Habash et al., 2012). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over one-third of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 1 Elissa’s home page can be found at http://nlp.ldeo.columbia.edu/elissa/. Arabic transliteration is presented in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007): (in alphabetical order) ˇ ¯  ˇ ςγfqklmnhwy and the additional symbols: ’ Z, Â @, A Abtθ jHxdðrzsšSDTD @, A @, wˆ ð&apos;, yˆ Zø&apos;, ħh è, ý ø. 2 386 3 Related Work Much work ha"
C12-3048,A00-1002,0,0.235536,"Missing"
C12-3048,D07-1005,0,0.0489915,"ools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA or other methods to collect word-pair lists have been explored (Abo Bakr et al., 2008; Sawaf, 2010; Salloum and Habash, 2011). Using closely related languages has been shown to improve MT quality when resources are limited (Hajiˇc et al., 2000; Zhang, 1998). This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). Sawaf (2010) built a hybrid DA-English MT system that uses an MSA pivoting approach. In his approach, DA is normalized into MSA using character-based DA normalization rules, a DA morphological analyzer, a DA normalization decoder that relies on language models, and a lexicon. Similarly, we use some character normalization rules, a DA morphological analyzer, and DA-MSA dictionaries. In contrast, we use hand-written morphological transfer rules that focuses on translating DA morphemes and lemmas to their MSA equivalents. We also provide our system to be used by other researchers. In previous w"
C12-3048,W11-2602,1,0.626364,"Standard Arabic (MSA) natural language processing (NLP) and machine translation (MT). MSA has a wealth of resources in terms of morphological analyzers, disambiguation systems, annotated data, and parallel corpora. In comparison, research on dialectal Arabic (DA), the unstandardized spoken varieties of Arabic, is still lacking in NLP in general and MT in particular. In this paper we present Elissa, our DA-to-MSA MT system.1 To process Arabic dialects with available MSA tools, researchers have used different techniques to map DA words to their MSA equivalents (Chiang et al., 2006; Sawaf, 2010; Salloum and Habash, 2011). Having a publicly available tool that translates DAs to MSA can help researchers extend their MSA resources and tools to cover different Arabic dialects. Elissa currently handles Levantine, Egyptian, Iraqi, and to a lesser degree Gulf Arabic. The Elissa approach can be summarized as follows. First, Elissa uses different techniques to identify dialectal words in a source sentence. Then, Elissa produces MSA paraphrases for the selected words using a rule-based component that depends on the existence of a dialectal morphological analyzer, a list of morphological transfer rules, and DA-MSA dicti"
C12-3048,2010.amta-papers.5,0,0.529582,"ne on Modern Standard Arabic (MSA) natural language processing (NLP) and machine translation (MT). MSA has a wealth of resources in terms of morphological analyzers, disambiguation systems, annotated data, and parallel corpora. In comparison, research on dialectal Arabic (DA), the unstandardized spoken varieties of Arabic, is still lacking in NLP in general and MT in particular. In this paper we present Elissa, our DA-to-MSA MT system.1 To process Arabic dialects with available MSA tools, researchers have used different techniques to map DA words to their MSA equivalents (Chiang et al., 2006; Sawaf, 2010; Salloum and Habash, 2011). Having a publicly available tool that translates DAs to MSA can help researchers extend their MSA resources and tools to cover different Arabic dialects. Elissa currently handles Levantine, Egyptian, Iraqi, and to a lesser degree Gulf Arabic. The Elissa approach can be summarized as follows. First, Elissa uses different techniques to identify dialectal words in a source sentence. Then, Elissa produces MSA paraphrases for the selected words using a rule-based component that depends on the existence of a dialectal morphological analyzer, a list of morphological trans"
C12-3048,N07-1061,0,0.0112206,"ly expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA or other methods to collect word-pair lists have been explored (Abo Bakr et al., 2008; Sawaf, 2010; Salloum and Habash, 2011). Using closely related languages has been shown to improve MT quality when resources are limited (Hajiˇc et al., 2000; Zhang, 1998). This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). Sawaf (2010) built a hybrid DA-English MT system that uses an MSA pivoting approach. In his approach, DA is normalized into MSA using character-based DA normalization rules, a DA morphological analyzer, a DA normalization decoder that relies on language models, and a lexicon. Similarly, we use some character normalization rules, a DA morphological analyzer, and DA-MSA dictionaries. In contrast, we use hand-written morphological transfer rules that focuses on translating DA morphemes and lemmas to their MSA equivalents. We also provide our system to be used by other resea"
C12-3048,N12-1006,0,0.212469,"Missing"
C12-3048,P98-2238,0,0.20469,"rchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA or other methods to collect word-pair lists have been explored (Abo Bakr et al., 2008; Sawaf, 2010; Salloum and Habash, 2011). Using closely related languages has been shown to improve MT quality when resources are limited (Hajiˇc et al., 2000; Zhang, 1998). This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). Sawaf (2010) built a hybrid DA-English MT system that uses an MSA pivoting approach. In his approach, DA is normalized into MSA using character-based DA normalization rules, a DA morphological analyzer, a DA normalization decoder that relies on language models, and a lexicon. Similarly, we use some character normalization rules, a DA morphological analyzer, and DA-MSA dictionaries. In contrast, we use hand-written mo"
C12-3048,C98-2233,0,\N,Missing
C16-1132,D14-1026,1,0.876215,"ation (Liu and Gildea, 2005; Giménez and Màrquez, 2007; Liu et al., 2010; Chen and Kuhn, 2011); (iii) morphology (Tantug et al., 2008); (iv) semantics (Dahlmeier et al., 2011; Lo et al., 2012) and (v) discourse (Guzmán et al., 2014b; Joty et al., 2014). Generally, these metrics have been focused on translation into English. However, there has been little attention into their direct applicability to languages with rich morphology. Our work focuses on automatic evaluation of translation into morphologically rich languages, Arabic more specifically. In that sense, our work is related to AL-BLEU (Bouamor et al., 2014) which is an adaptation of BLEU that gives partial credits for stem and morphological matchings of hypothesis and reference words. Here, in addition to using lexical information captured by n-gram metrics, we show that using morpho-syntactic representations can significantly improve the correlation with human judgments. Furthermore, we use a neural-network, which uses non-linearities to improve modeling. Over the past few years, neural network models have dramatically improved the state-of-the-art of different NLP applications (Goldberg, 2015). For instance, in SMT we have observed an increase"
C16-1132,E06-1032,0,0.161511,"Missing"
C16-1132,W12-3102,0,0.031103,"xplore this relationship more in depth in Section. 5.4. 5.3 Combination of Representations Given the complimentary information embedded in the different representations, it is natural to combine them to obtain a stronger metric. To combine different embedding representations, we simply concatenate the different embedding representations before feeding them to the network. Below, we present 4 Note that the Kendall’s τ results for M ETEOR are in the range of the results for translation from English into other two morphologically rich languages (German: 18.0 and Czech 16.0) reported in WMT 2012 (Callison-Burch et al., 2012) 1403 Kendall’s τ Combinations C. Embeddings and N-gram based metrics Lexical 14 5 METRICS+TOKEN 15 5 METRICS+NORM 16 5 METRICS+LEMMA Morpho-syntactic 17 5 METRICS+B UCKWALTER POS 18 5 METRICS+K ULICK POS 19 5 METRICS+S TANFORD POS 20 5 METRICS+CAT I BPOS result prev. best delta 23.62 24.17 23.51 24.35 23.22 21.17 ( -0.73) (+0.95) (+2.34) 29.81 23.58 21.79 18.93 25.49 18.12 18.12 18.12 (+4.32) (+5.46) (+3.67) (+0.81) 25.12 25.42 24.90 25.34 24.35 23.22 24.35 25.42 (+0.77) (+2.20) (+0.55) (-0.08) * 31.87 30.69 30.69 25.49 25.49 25.49 (+6.38) (+5.19) (+5.19) 25.56 25.42 25.45 28.35 25.12 25.42 2"
C16-1132,W11-2105,0,0.021929,"Section 2. We describe our approach in detail in Section 3; and we evaluate in Section 4. We present a discussion of our findings in Section 5. 2 Related Work Despite its well-known shortcomings (Callison-Burch et al., 2006), BLEU continues to be the de-facto MT evaluation metric. Several studies have attempted to improve upon it by taking into account different aspects of linguistic structures including: (i) synonym dictionaries or paraphrase tables (Denkowski and Lavie, 2011; Snover et al., 2010); (ii) syntactic information (Liu and Gildea, 2005; Giménez and Màrquez, 2007; Liu et al., 2010; Chen and Kuhn, 2011); (iii) morphology (Tantug et al., 2008); (iv) semantics (Dahlmeier et al., 2011; Lo et al., 2012) and (v) discourse (Guzmán et al., 2014b; Joty et al., 2014). Generally, these metrics have been focused on translation into English. However, there has been little attention into their direct applicability to languages with rich morphology. Our work focuses on automatic evaluation of translation into morphologically rich languages, Arabic more specifically. In that sense, our work is related to AL-BLEU (Bouamor et al., 2014) which is an adaptation of BLEU that gives partial credits for stem and m"
C16-1132,E03-1009,0,0.0349933,"ly on an syntactic neural parser (Socher et al., 2013), which increases the complexity of the evaluation setup, and is not readily available for every language. Here, we instead use morpho-syntactic representations which capture both syntactic and morphological aspects of language. In our experiments, these simple representations are powerful enough to provide state-of-the-art performance. In this work, we use neural network models to improve MT evaluation into Arabic using representations that capture morphology. Morphological structure has been shown to improve the quality of word clusters (Clark, 2003), word vector representations (Cotterell and Schütze, 2015) and neural language models (Botha and Blunsom, 2014). The novelty of our work resides in the way we integrate lexical and morpho-syntactic distributed representations into a neural-network. We demonstrate that combining several sources of complementary information is useful to capture sentence similarity in a translation evaluation scenario. And arguably, capture complex phenomena like morphological agreement. 3 Approach We use a pairwise approach to translation evaluation (Guzmán et al., 2014a) using neural networks. We use neural ne"
C16-1132,N15-1140,0,0.137724,"for tuning system parameters, it is crucial that the MT metrics correctly handle morphology. Most recently, deep learning models have been used more heavily in different parts of the natural language processing (NLP) community, including MT and MT evaluation. One of the main advantages of such models is the use of distributed word representations (embeddings). It has been shown that word embeddings are able to capture to certain semantic and syntactic aspects of words (Mikolov et al., 2013). Further refinements allow the inclusion of morphological information into distributed representations (Cotterell and Schütze, 2015). Word embeddings have been shown to help with modeling textual similarity well in the context of MT evaluation for MT into English (Guzmán et al., 2015), and community Question Answering (Guzmán et al., 2016). Nonetheless little exploration has been done on the use of embeddings for MT into MRL. In this paper, we investigate how embeddings obtained from different levels of lexical and morphosyntactic linguistic analysis can improve MT evaluation into a MRL. Specifically we report on Arabic, a language with complex and rich morphology paired with a high degree of ambiguity (Habash, 2010). Our"
C16-1132,W11-2106,0,0.0261248,"Section 4. We present a discussion of our findings in Section 5. 2 Related Work Despite its well-known shortcomings (Callison-Burch et al., 2006), BLEU continues to be the de-facto MT evaluation metric. Several studies have attempted to improve upon it by taking into account different aspects of linguistic structures including: (i) synonym dictionaries or paraphrase tables (Denkowski and Lavie, 2011; Snover et al., 2010); (ii) syntactic information (Liu and Gildea, 2005; Giménez and Màrquez, 2007; Liu et al., 2010; Chen and Kuhn, 2011); (iii) morphology (Tantug et al., 2008); (iv) semantics (Dahlmeier et al., 2011; Lo et al., 2012) and (v) discourse (Guzmán et al., 2014b; Joty et al., 2014). Generally, these metrics have been focused on translation into English. However, there has been little attention into their direct applicability to languages with rich morphology. Our work focuses on automatic evaluation of translation into morphologically rich languages, Arabic more specifically. In that sense, our work is related to AL-BLEU (Bouamor et al., 2014) which is an adaptation of BLEU that gives partial credits for stem and morphological matchings of hypothesis and reference words. Here, in addition to u"
C16-1132,W11-2107,0,0.514566,"s: from handling a complex and rich vocabulary, to designing adequate MT metrics that take morphology into account. While the first problem has widely explored (e.g. by using morphological analysis tools to reduce sparsity), the evaluation part has only been partly addressed. This is problematic since traditional MT metrics struggle to distinguish between (i) incorrect lexical choices; (ii) valid alternative lexical or syntactic variations; and (iii) differences in morphological inflection that are the result of incorrect case assignment or morphological agreement. While metrics like M ETEOR (Denkowski and Lavie, 2011) have made it possible to distinguish between (i) and (ii) by using paraphrases, (iii) is still an open problem. As a result, progress in SMT for MRL is hindered by the lack of adequate evaluation metrics. Since SMT metrics are used not only for evaluation but also for tuning system parameters, it is crucial that the MT metrics correctly handle morphology. Most recently, deep learning models have been used more heavily in different parts of the natural language processing (NLP) community, including MT and MT evaluation. One of the main advantages of such models is the use of distributed word r"
C16-1132,P14-1129,0,0.033517,"w that using morpho-syntactic representations can significantly improve the correlation with human judgments. Furthermore, we use a neural-network, which uses non-linearities to improve modeling. Over the past few years, neural network models have dramatically improved the state-of-the-art of different NLP applications (Goldberg, 2015). For instance, in SMT we have observed an increased use of neural nets for language modeling (Bengio et al., 2003; Mikolov et al., 2010), for improving answer ranking in community Question Answering (Guzmán et al., 2016), for improving the translation modeling (Devlin et al., 2014; Bahdanau et al., 2014; Cho et al., 2014) and for machine translation evaluation (Guzmán et al., 2015; Gupta et al., 2015). Our work is related to Guzmán et al. (2015), in several levels of lexical, syntactic and semantic are combined in a compact fashion using a pairwise neural framework. There are several differences between that work and ours: (i) we do not use syntactic embedding representations, (ii) we include additional pairwise features, namely the pairwise cosine similarity between embeddings; and (ii) we focus on an MRL language. While use of syntactic representations has proven a u"
C16-1132,W07-0738,0,0.0350979,"man judges. Next, we present related work in Section 2. We describe our approach in detail in Section 3; and we evaluate in Section 4. We present a discussion of our findings in Section 5. 2 Related Work Despite its well-known shortcomings (Callison-Burch et al., 2006), BLEU continues to be the de-facto MT evaluation metric. Several studies have attempted to improve upon it by taking into account different aspects of linguistic structures including: (i) synonym dictionaries or paraphrase tables (Denkowski and Lavie, 2011; Snover et al., 2010); (ii) syntactic information (Liu and Gildea, 2005; Giménez and Màrquez, 2007; Liu et al., 2010; Chen and Kuhn, 2011); (iii) morphology (Tantug et al., 2008); (iv) semantics (Dahlmeier et al., 2011; Lo et al., 2012) and (v) discourse (Guzmán et al., 2014b; Joty et al., 2014). Generally, these metrics have been focused on translation into English. However, there has been little attention into their direct applicability to languages with rich morphology. Our work focuses on automatic evaluation of translation into morphologically rich languages, Arabic more specifically. In that sense, our work is related to AL-BLEU (Bouamor et al., 2014) which is an adaptation of BLEU t"
C16-1132,D15-1124,0,0.0437833,"Missing"
C16-1132,D14-1027,1,0.917619,"on 5. 2 Related Work Despite its well-known shortcomings (Callison-Burch et al., 2006), BLEU continues to be the de-facto MT evaluation metric. Several studies have attempted to improve upon it by taking into account different aspects of linguistic structures including: (i) synonym dictionaries or paraphrase tables (Denkowski and Lavie, 2011; Snover et al., 2010); (ii) syntactic information (Liu and Gildea, 2005; Giménez and Màrquez, 2007; Liu et al., 2010; Chen and Kuhn, 2011); (iii) morphology (Tantug et al., 2008); (iv) semantics (Dahlmeier et al., 2011; Lo et al., 2012) and (v) discourse (Guzmán et al., 2014b; Joty et al., 2014). Generally, these metrics have been focused on translation into English. However, there has been little attention into their direct applicability to languages with rich morphology. Our work focuses on automatic evaluation of translation into morphologically rich languages, Arabic more specifically. In that sense, our work is related to AL-BLEU (Bouamor et al., 2014) which is an adaptation of BLEU that gives partial credits for stem and morphological matchings of hypothesis and reference words. Here, in addition to using lexical information captured by n-gram metrics, we s"
C16-1132,P14-1065,1,0.914549,"on 5. 2 Related Work Despite its well-known shortcomings (Callison-Burch et al., 2006), BLEU continues to be the de-facto MT evaluation metric. Several studies have attempted to improve upon it by taking into account different aspects of linguistic structures including: (i) synonym dictionaries or paraphrase tables (Denkowski and Lavie, 2011; Snover et al., 2010); (ii) syntactic information (Liu and Gildea, 2005; Giménez and Màrquez, 2007; Liu et al., 2010; Chen and Kuhn, 2011); (iii) morphology (Tantug et al., 2008); (iv) semantics (Dahlmeier et al., 2011; Lo et al., 2012) and (v) discourse (Guzmán et al., 2014b; Joty et al., 2014). Generally, these metrics have been focused on translation into English. However, there has been little attention into their direct applicability to languages with rich morphology. Our work focuses on automatic evaluation of translation into morphologically rich languages, Arabic more specifically. In that sense, our work is related to AL-BLEU (Bouamor et al., 2014) which is an adaptation of BLEU that gives partial credits for stem and morphological matchings of hypothesis and reference words. Here, in addition to using lexical information captured by n-gram metrics, we s"
C16-1132,P15-1078,1,0.842391,"ifferent parts of the natural language processing (NLP) community, including MT and MT evaluation. One of the main advantages of such models is the use of distributed word representations (embeddings). It has been shown that word embeddings are able to capture to certain semantic and syntactic aspects of words (Mikolov et al., 2013). Further refinements allow the inclusion of morphological information into distributed representations (Cotterell and Schütze, 2015). Word embeddings have been shown to help with modeling textual similarity well in the context of MT evaluation for MT into English (Guzmán et al., 2015), and community Question Answering (Guzmán et al., 2016). Nonetheless little exploration has been done on the use of embeddings for MT into MRL. In this paper, we investigate how embeddings obtained from different levels of lexical and morphosyntactic linguistic analysis can improve MT evaluation into a MRL. Specifically we report on Arabic, a language with complex and rich morphology paired with a high degree of ambiguity (Habash, 2010). Our results show that using a pairwise neural-network over different representations produces results This work is licensed under a Creative Commons Attribut"
C16-1132,P16-2075,1,0.862944,"community, including MT and MT evaluation. One of the main advantages of such models is the use of distributed word representations (embeddings). It has been shown that word embeddings are able to capture to certain semantic and syntactic aspects of words (Mikolov et al., 2013). Further refinements allow the inclusion of morphological information into distributed representations (Cotterell and Schütze, 2015). Word embeddings have been shown to help with modeling textual similarity well in the context of MT evaluation for MT into English (Guzmán et al., 2015), and community Question Answering (Guzmán et al., 2016). Nonetheless little exploration has been done on the use of embeddings for MT into MRL. In this paper, we investigate how embeddings obtained from different levels of lexical and morphosyntactic linguistic analysis can improve MT evaluation into a MRL. Specifically we report on Arabic, a language with complex and rich morphology paired with a high degree of ambiguity (Habash, 2010). Our results show that using a pairwise neural-network over different representations produces results This work is licensed under a Creative Commons Attribution 4.0 International License. //creativecommons.org/lic"
C16-1132,N06-2013,1,0.667533,"eatures representing different levels lexical and morphosyntactic information. As a baseline, we also used several MT metrics that are based on n-gram matches. Lexical units A distinguishing characteristic of Arabic morphology is the presence of concatenative morphemes, where words are formed via concatenations of stems, affixes and clitics. To allow our system to model how morphemes interact at a finer level, we split the morphemes. We used MADAMIRA (Pasha et al., 2014), the state-of-the-art morphological analyzer and disambiguator, to perform morphological tokenization following ATB scheme (Habash and Sadat, 2006). We extracted two forms of lexical features: NORM and TOKEN, which are tokens with and without Alef/Yaa normalization, respectively. We also extract the LEMMA feature; a morphological abstraction that represents words related by inflectional morphology. Morpho-Syntactic units We extracted part-of-speech (POS) tags according to different POS tagsets including: (i) CAT I BPOS(Habash et al., 2009), (ii) K ULICK POS1 (Kulick et al., 2006), (iii) B UCKWALTER POS (Buckwalter, 2004) and (iv) S TANFORD POS tagsets. These tagsets differ in their richness and complexity they capture. CAT I BPOS is the"
C16-1132,W14-3352,1,0.852249,"espite its well-known shortcomings (Callison-Burch et al., 2006), BLEU continues to be the de-facto MT evaluation metric. Several studies have attempted to improve upon it by taking into account different aspects of linguistic structures including: (i) synonym dictionaries or paraphrase tables (Denkowski and Lavie, 2011; Snover et al., 2010); (ii) syntactic information (Liu and Gildea, 2005; Giménez and Màrquez, 2007; Liu et al., 2010; Chen and Kuhn, 2011); (iii) morphology (Tantug et al., 2008); (iv) semantics (Dahlmeier et al., 2011; Lo et al., 2012) and (v) discourse (Guzmán et al., 2014b; Joty et al., 2014). Generally, these metrics have been focused on translation into English. However, there has been little attention into their direct applicability to languages with rich morphology. Our work focuses on automatic evaluation of translation into morphologically rich languages, Arabic more specifically. In that sense, our work is related to AL-BLEU (Bouamor et al., 2014) which is an adaptation of BLEU that gives partial credits for stem and morphological matchings of hypothesis and reference words. Here, in addition to using lexical information captured by n-gram metrics, we show that using morpho"
C16-1132,W05-0904,0,0.0469328,"the preferences of human judges. Next, we present related work in Section 2. We describe our approach in detail in Section 3; and we evaluate in Section 4. We present a discussion of our findings in Section 5. 2 Related Work Despite its well-known shortcomings (Callison-Burch et al., 2006), BLEU continues to be the de-facto MT evaluation metric. Several studies have attempted to improve upon it by taking into account different aspects of linguistic structures including: (i) synonym dictionaries or paraphrase tables (Denkowski and Lavie, 2011; Snover et al., 2010); (ii) syntactic information (Liu and Gildea, 2005; Giménez and Màrquez, 2007; Liu et al., 2010; Chen and Kuhn, 2011); (iii) morphology (Tantug et al., 2008); (iv) semantics (Dahlmeier et al., 2011; Lo et al., 2012) and (v) discourse (Guzmán et al., 2014b; Joty et al., 2014). Generally, these metrics have been focused on translation into English. However, there has been little attention into their direct applicability to languages with rich morphology. Our work focuses on automatic evaluation of translation into morphologically rich languages, Arabic more specifically. In that sense, our work is related to AL-BLEU (Bouamor et al., 2014) which"
C16-1132,W10-1754,0,0.0287716,"t related work in Section 2. We describe our approach in detail in Section 3; and we evaluate in Section 4. We present a discussion of our findings in Section 5. 2 Related Work Despite its well-known shortcomings (Callison-Burch et al., 2006), BLEU continues to be the de-facto MT evaluation metric. Several studies have attempted to improve upon it by taking into account different aspects of linguistic structures including: (i) synonym dictionaries or paraphrase tables (Denkowski and Lavie, 2011; Snover et al., 2010); (ii) syntactic information (Liu and Gildea, 2005; Giménez and Màrquez, 2007; Liu et al., 2010; Chen and Kuhn, 2011); (iii) morphology (Tantug et al., 2008); (iv) semantics (Dahlmeier et al., 2011; Lo et al., 2012) and (v) discourse (Guzmán et al., 2014b; Joty et al., 2014). Generally, these metrics have been focused on translation into English. However, there has been little attention into their direct applicability to languages with rich morphology. Our work focuses on automatic evaluation of translation into morphologically rich languages, Arabic more specifically. In that sense, our work is related to AL-BLEU (Bouamor et al., 2014) which is an adaptation of BLEU that gives partial"
C16-1132,W12-3129,0,0.0215102,"discussion of our findings in Section 5. 2 Related Work Despite its well-known shortcomings (Callison-Burch et al., 2006), BLEU continues to be the de-facto MT evaluation metric. Several studies have attempted to improve upon it by taking into account different aspects of linguistic structures including: (i) synonym dictionaries or paraphrase tables (Denkowski and Lavie, 2011; Snover et al., 2010); (ii) syntactic information (Liu and Gildea, 2005; Giménez and Màrquez, 2007; Liu et al., 2010; Chen and Kuhn, 2011); (iii) morphology (Tantug et al., 2008); (iv) semantics (Dahlmeier et al., 2011; Lo et al., 2012) and (v) discourse (Guzmán et al., 2014b; Joty et al., 2014). Generally, these metrics have been focused on translation into English. However, there has been little attention into their direct applicability to languages with rich morphology. Our work focuses on automatic evaluation of translation into morphologically rich languages, Arabic more specifically. In that sense, our work is related to AL-BLEU (Bouamor et al., 2014) which is an adaptation of BLEU that gives partial credits for stem and morphological matchings of hypothesis and reference words. Here, in addition to using lexical infor"
C16-1132,P14-5010,0,0.00285382,"xtracted part-of-speech (POS) tags according to different POS tagsets including: (i) CAT I BPOS(Habash et al., 2009), (ii) K ULICK POS1 (Kulick et al., 2006), (iii) B UCKWALTER POS (Buckwalter, 2004) and (iv) S TANFORD POS tagsets. These tagsets differ in their richness and complexity they capture. CAT I BPOS is the simplest with only 6 base tags2 , B UCKWALTER POS is the richest with 485 base tags, and K ULICK POS and S TANFORD POS come inbetween with 43 and 32 base tags, respectively. These tags were extracted using MADAMIRA, except for the Stanford tags, for which we used Stanford CoreNLP (Manning et al., 2014). Table 1 illustrates an example sentence with its lexical and morpho-syntactic features.3 ˇ bldhm − ςAd AlmSrywn Alðyn AxtTfwA Alý Sentence: TOKEN NORM Ñë+ +hm bld YÊK. ˇ Alý Ñë+ YÊK. ú Í@ Aly úÍ@ ˇ +hm bld YÊK . Ñë + LEMMA úÍ@ Jk@ @ñ®¢ AxtTfwA Jk@ @ñ®¢ AxtTfwA  ¢ Jk@ QåÖÏ@ XA« Jk@ áK YË@ ÑëYÊK. úÍ@ @ñ®¢ àñK àñK QåÖÏ@ áK YË@ XA« Alðyn AlmSrywn ςAd QåÖÏ@ áK YË@ àñK XA« Alðyn  ø Y Ë@ AlmSrywn ø Q åÓ XA« +hum balad Ailaý Aix.taTaf Al∼aðiy CAT I BPOS +NOM NOM PRT VRB-PASS NOM NOM VRB K ULICK POS +PRP$ NN IN VBN WP DT+NNS VBD S TANFORD POS PRP$ NN IN VBN WP DTNNS VBD +POSS _PRON _3MP NO"
C16-1132,C12-1121,1,0.84926,"¨ ¨ ¬   È Ð à è ð ø Â b t θ j H x d ð r z s š S D T Dˇ ς γ f q k l m n h w y, and 2 . .  w, ˇ @ A, ¯ ð' ˆ the additional symbols: Z ’, @ Â, @ A, Zø' yˆ , è ~, ø ý. Diacritics are represented as:  a,  u,  i,  .,  ã,  u˜ ,  ˜ı, and  ∼. 1401 obtain sentence-level representations for each of the translations and the references, we used additive composition (Mitchell and Lapata, 2010) with dropping unknown words. N-gram MT metrics We used the different n-gram based metrics to serve as a benchmark, and as additional features that capture lexical similarity. We used: BLEU+1 (Nakov et al., 2012),NIST (Doddington, 2002); M ETEOR (Denkowski and Lavie, 2011), 1-TER (Snover et al., 2006), and AL-BLEU (Bouamor et al., 2014), to compute scores at the sentence-level. For consistency with previous work, we report scores over words, and not over morphemes. 4 Experimental Setup In this section, we describe the experimental settings we used through our study. First, we introduce our evaluation criteria, then we elaborate on the dataset and various settings we used for our experiments. 4.1 Performance evaluation Automatic evaluation metrics are evaluated based on their correlation with human-per"
C16-1132,pasha-etal-2014-madamira,1,0.889937,"Missing"
C16-1132,2006.amta-papers.25,0,0.0619799,"nd 2 . .  w, ˇ @ A, ¯ ð' ˆ the additional symbols: Z ’, @ Â, @ A, Zø' yˆ , è ~, ø ý. Diacritics are represented as:  a,  u,  i,  .,  ã,  u˜ ,  ˜ı, and  ∼. 1401 obtain sentence-level representations for each of the translations and the references, we used additive composition (Mitchell and Lapata, 2010) with dropping unknown words. N-gram MT metrics We used the different n-gram based metrics to serve as a benchmark, and as additional features that capture lexical similarity. We used: BLEU+1 (Nakov et al., 2012),NIST (Doddington, 2002); M ETEOR (Denkowski and Lavie, 2011), 1-TER (Snover et al., 2006), and AL-BLEU (Bouamor et al., 2014), to compute scores at the sentence-level. For consistency with previous work, we report scores over words, and not over morphemes. 4 Experimental Setup In this section, we describe the experimental settings we used through our study. First, we introduce our evaluation criteria, then we elaborate on the dataset and various settings we used for our experiments. 4.1 Performance evaluation Automatic evaluation metrics are evaluated based on their correlation with human-performed evaluations (Soricut and Brill, 2004). In this work, we use Kendall’s τ , a coeffic"
C16-1132,P13-1045,0,0.0302945,"mán et al., 2015; Gupta et al., 2015). Our work is related to Guzmán et al. (2015), in several levels of lexical, syntactic and semantic are combined in a compact fashion using a pairwise neural framework. There are several differences between that work and ours: (i) we do not use syntactic embedding representations, (ii) we include additional pairwise features, namely the pairwise cosine similarity between embeddings; and (ii) we focus on an MRL language. While use of syntactic representations has proven a useful component to evaluate English, it relies heavily on an syntactic neural parser (Socher et al., 2013), which increases the complexity of the evaluation setup, and is not readily available for every language. Here, we instead use morpho-syntactic representations which capture both syntactic and morphological aspects of language. In our experiments, these simple representations are powerful enough to provide state-of-the-art performance. In this work, we use neural network models to improve MT evaluation into Arabic using representations that capture morphology. Morphological structure has been shown to improve the quality of word clusters (Clark, 2003), word vector representations (Cotterell a"
C16-1132,P04-1078,0,0.0560723,"002); M ETEOR (Denkowski and Lavie, 2011), 1-TER (Snover et al., 2006), and AL-BLEU (Bouamor et al., 2014), to compute scores at the sentence-level. For consistency with previous work, we report scores over words, and not over morphemes. 4 Experimental Setup In this section, we describe the experimental settings we used through our study. First, we introduce our evaluation criteria, then we elaborate on the dataset and various settings we used for our experiments. 4.1 Performance evaluation Automatic evaluation metrics are evaluated based on their correlation with human-performed evaluations (Soricut and Brill, 2004). In this work, we use Kendall’s τ , a coefficient that measures the agreement between rankings produced by human judgments and rankings produced by an automatic metric, at the sentence-level. We use the WMT’12 (workshop of machine translation) definition of Kendall’s τ that ignores ties, and is calculated as follows: [τ = (# concordant pairs − # discordant pairs) /total pairs], where the # concordant pairs is the number of times the human judgment and the automatic metric agree in the ranking of any two translations that belong to the same source sentence. The # discordant pairs is the opposi"
C16-1326,al-sabbagh-girju-2012-yadac,0,0.0609447,"Missing"
C16-1326,L16-1207,1,0.798443,"nalyzer for the new dialect. Because of the close relationship among the variants of Arabic, we also make use of an existing analyzer for MSA, and (in the case of Levantine), an existing Egyptian analyzer. The resulting analyzer is then used in a tagger, which uses the annotated corpus to learn classifiers that choose among all possible analyses. Crucially, we do not require the corpus to be fully annotated, allowing the annotator to concentrate on the most frequent words. We are currently annotating five more dialects with this sort of corpus, with initial corpora available for two dialects (Al-Shargi et al., 2016). The primary contribution of this paper is that we describe a methodology for creating morphological analyzers and taggers for any Arabic dialect. We show the effectiveness of our approach by measuring performance based on training corpora of different sizes. A secondary contribution of this paper is that we present new resources for Levantine Arabic (a morphological analyzer and a morphological tagger), which to our knowledge are the first of their kinds. While we restrict our attentions to Arabic and its dialects, we believe our approach may be relevant to other situations in which we face"
C16-1326,bouamor-etal-2014-multidialectal,1,0.927048,"Missing"
C16-1326,J95-4004,0,0.729663,"Missing"
C16-1326,E06-1047,1,0.913803,"Missing"
C16-1326,W05-0708,0,0.0946921,"Missing"
C16-1326,W13-2301,1,0.926411,"x∼ar be late PV+PVSUFF SUBJ:2MS verb VRB AtAxr HQ HQ  lhAlwqt waqt I»ñÊêË lhlwkt I ¯ñËAêË time PREP+DEM PRON+DET+NOUN noun NOM wqt ?? ?? ? ? PUNC punc PNX ?   k AK@   Ë èñK. @ ñË A sAlw ˆ Abwh lyˇs AtAxrt ˆ lhlwkt? Table 1: An example Levantine sentence ? I»ñÊêË HQ ‘His father asked him why he was late?’. The various columns are for the CODA spelling and different morphological features: lemma, gloss, Buckwalter POS tag, two reduced POS tags and stem. 3.2 Egyptian Data Corpus We use the Egyptian Arabic corpora developed by the Linguistic Data Consortium (LDC) (Maamouri et al., 2012; Eskander et al., 2013a). The corpora are morphologically annotated in a similar style to the annotations done at the LDC for MSA. Words are provided with contextually appropriate CODA form, lemmas, POS tags (Buckwalter, 2004), and English glosses. We ran the E GY corpus through our E GY morphological analyzer CALIMAEgy (Habash et al., 2012b) in order to generate morphological features similar to the ones described in MADAMIRA (Pasha et al., 2014). In this process, we replaced the human-annotated corpus analysis by the closest CALIMAEgy analysis when it does not match any of the CALIMAEgy analyses for a given word."
C16-1326,D13-1105,1,0.910991,"x∼ar be late PV+PVSUFF SUBJ:2MS verb VRB AtAxr HQ HQ  lhAlwqt waqt I»ñÊêË lhlwkt I ¯ñËAêË time PREP+DEM PRON+DET+NOUN noun NOM wqt ?? ?? ? ? PUNC punc PNX ?   k AK@   Ë èñK. @ ñË A sAlw ˆ Abwh lyˇs AtAxrt ˆ lhlwkt? Table 1: An example Levantine sentence ? I»ñÊêË HQ ‘His father asked him why he was late?’. The various columns are for the CODA spelling and different morphological features: lemma, gloss, Buckwalter POS tag, two reduced POS tags and stem. 3.2 Egyptian Data Corpus We use the Egyptian Arabic corpora developed by the Linguistic Data Consortium (LDC) (Maamouri et al., 2012; Eskander et al., 2013a). The corpora are morphologically annotated in a similar style to the annotations done at the LDC for MSA. Words are provided with contextually appropriate CODA form, lemmas, POS tags (Buckwalter, 2004), and English glosses. We ran the E GY corpus through our E GY morphological analyzer CALIMAEgy (Habash et al., 2012b) in order to generate morphological features similar to the ones described in MADAMIRA (Pasha et al., 2014). In this process, we replaced the human-annotated corpus analysis by the closest CALIMAEgy analysis when it does not match any of the CALIMAEgy analyses for a given word."
C16-1326,P05-1071,1,0.852418,"Missing"
C16-1326,habash-etal-2012-conventional,1,0.931467,"n be done with a small annotation effort. In both our previous work and our new one, we use an analyze-and-choose approach to morphological tagging, following the work of Hajiˇc (2000) (also used by Habash and Rambow (2005) for MSA). We also compare against our previous work in our evaluation. 3 3.1 Data Orthography Arabic dialects do not have a standard orthography. This is a big challenge to the annotation process as it allows the coexistence of uninteresting orthographic variations. To address this challenge, we previously developed the Conventional Orthography for Dialectal Arabic (CODA) (Habash et al., 2012a). The CODA choices aim at reducing differences between variants (DA and MSA) when possible while maintaining the distinctive morphological inventories of the different variants. The first CODA specifications were developed for Egyptian Arabic (henceforth E GY) and utilized in the E GY corpus which we also use (Maamouri et al., 2012). The E GY CODA guidelines were extended to Levantine Arabic (henceforth L EV) by the creators of the L EV corpus we use (Jarrar et al., 2014). Since the L EV corpus was annotated without diacritics, all diacritics were also stripped from the E GY corpus for the s"
C16-1326,W12-2301,1,0.920026,"Missing"
C16-1326,N13-1044,1,0.914769,"Missing"
C16-1326,A00-2013,0,0.238912,"Missing"
C16-1326,W14-3603,1,0.81476,"c variations. To address this challenge, we previously developed the Conventional Orthography for Dialectal Arabic (CODA) (Habash et al., 2012a). The CODA choices aim at reducing differences between variants (DA and MSA) when possible while maintaining the distinctive morphological inventories of the different variants. The first CODA specifications were developed for Egyptian Arabic (henceforth E GY) and utilized in the E GY corpus which we also use (Maamouri et al., 2012). The E GY CODA guidelines were extended to Levantine Arabic (henceforth L EV) by the creators of the L EV corpus we use (Jarrar et al., 2014). Since the L EV corpus was annotated without diacritics, all diacritics were also stripped from the E GY corpus for the study we present in this paper. The only exception is that lemmas are represented using diacritics in the corpora for both dialects so that fine-grained distinctions between different lexemes can be made. 3456 Word CODA Lemma Gloss BW Tag POS POS5 Stem ˆ ˆ ˆ ˆ ñË A sAlw éË A sAlh saAal ask PV+PVSUFF SUBJ:3MS+PVSUFF DO:3MS verb VRB sAl èñK. @ Abwh èñK. @ Abwh Ab father NOUN+POSS PRON 3MS noun NOM Ab  Ë lyˇs  Ë lyˇs layˇs why INTERROG ADV adv interrog PRT lyˇs    k A"
C16-1326,L16-1679,1,0.826526,"Missing"
C16-1326,maamouri-etal-2014-developing,1,0.870461,"Missing"
C16-1326,masmoudi-etal-2014-corpus,1,0.906692,"Missing"
C16-1326,mohamed-etal-2012-annotating,0,0.0504507,"Missing"
C16-1326,pasha-etal-2014-madamira,1,0.933304,"Missing"
C16-1326,W11-2602,1,0.914567,"Missing"
C16-1326,voss-etal-2014-finding,0,0.0978076,"Missing"
C16-1326,P06-1073,0,0.0789517,"Missing"
C16-2044,N13-1066,1,0.858896,"ialect, she recognizes common words and greetings in a number of other dialects. Orthographic Ambiguity and Inconsistency Arabic orthography represents short vowels and consonantal doubling using optional diacritical marks, which most commonly are not included in the text. This results in a high rate of ambiguity. Furthermore, Arabic writers make very common mistakes in spelling a number of problematic letters such as Alif-Hamza forms and Ta-Marbuta (Zaghouani et al., 2014). The issue of orthography is exacerbated for Arabic dialects where no standard orthographies exist (Habash et al., 2012; Eskander et al., 2013). Morphological Richness Arabic words are inflected for a large number of features such as gender, number, person, voices, aspect, etc., as well as accepting a number of attached clitics. In the context of a chatbot system this proves very challenging. Verbs, adjectives, and pronouns are all gender specific, which requires the chatbot to have two different systems of responses – one for male users and another for female users. 4 http://www.pandorabots.com/. 209 Idiomatic Dialogue Expressions As with any other language, Arabic has its own set of unique idiomatic dialogue expressions. One common"
C16-2044,habash-etal-2012-conventional,1,0.943174,"ene Egyptian Arabic dialect, she recognizes common words and greetings in a number of other dialects. Orthographic Ambiguity and Inconsistency Arabic orthography represents short vowels and consonantal doubling using optional diacritical marks, which most commonly are not included in the text. This results in a high rate of ambiguity. Furthermore, Arabic writers make very common mistakes in spelling a number of problematic letters such as Alif-Hamza forms and Ta-Marbuta (Zaghouani et al., 2014). The issue of orthography is exacerbated for Arabic dialects where no standard orthographies exist (Habash et al., 2012; Eskander et al., 2013). Morphological Richness Arabic words are inflected for a large number of features such as gender, number, person, voices, aspect, etc., as well as accepting a number of attached clitics. In the context of a chatbot system this proves very challenging. Verbs, adjectives, and pronouns are all gender specific, which requires the chatbot to have two different systems of responses – one for male users and another for female users. 4 http://www.pandorabots.com/. 209 Idiomatic Dialogue Expressions As with any other language, Arabic has its own set of unique idiomatic dialogue"
C16-2044,P16-1094,0,0.0157157,"to chat with it online.3 The rest of this paper is organized as follows. Next, we present related work in Section 2. We discuss the challenges for developing Arabic chatbots in Section 3. We then describe our approach and design decisions in some detail in Section 4 including presenting a conversation example and a preliminary user evaluation. 2 Related Work As in many other NLP areas, there are two types of approaches to developing chatbots: using manually written rules (Wallace, 2003) or automatically learning conversational patterns from data (Shawar and Atwell, 2003; Sordoni et al., 2015; Li et al., 2016). Both approaches have some advantages and disadvantages. While manual rules allow more control over the language and persona of the chatbot, they are 1 The name B OTTA (pronounced like but-ta) evokes the English word Bot as well as the Arabic friendly female nickname   ), which can be translated as ‘Ducky’. Batta ( é¢ . 2 To obtain the B OTTA database files, go to http://camel.abudhabi.nyu.edu/resources/. 3 To chat with B OTTA online, go to https://playground.pandorabots.com/en/clubhouse/ and search for ‘Botta’. The current version (1.0) is under BotID dana33/botta. 208 Proceedings of COLI"
C16-2044,pasha-etal-2014-madamira,1,0.891918,"Missing"
C16-2044,N15-1020,0,0.0362702,"or any users who want to chat with it online.3 The rest of this paper is organized as follows. Next, we present related work in Section 2. We discuss the challenges for developing Arabic chatbots in Section 3. We then describe our approach and design decisions in some detail in Section 4 including presenting a conversation example and a preliminary user evaluation. 2 Related Work As in many other NLP areas, there are two types of approaches to developing chatbots: using manually written rules (Wallace, 2003) or automatically learning conversational patterns from data (Shawar and Atwell, 2003; Sordoni et al., 2015; Li et al., 2016). Both approaches have some advantages and disadvantages. While manual rules allow more control over the language and persona of the chatbot, they are 1 The name B OTTA (pronounced like but-ta) evokes the English word Bot as well as the Arabic friendly female nickname   ), which can be translated as ‘Ducky’. Batta ( é¢ . 2 To obtain the B OTTA database files, go to http://camel.abudhabi.nyu.edu/resources/. 3 To chat with B OTTA online, go to https://playground.pandorabots.com/en/clubhouse/ and search for ‘Botta’. The current version (1.0) is under BotID dana33/botta. 208 P"
C16-2047,N16-3003,0,0.179523,"to http://camel.abudhabi.nyu.edu/resources/. 223 Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations, pages 223–227, Osaka, Japan, December 11-17 2016. more than 14 morphological and lexical features. It also provides different tokenization schemes. Additionally, MADAMIRA has two modes for MSA and Egyptian Arabic (EGY). The speed of MADAMIRA however is relatively slow (420 words/sec in stand-alone mode, and 1,013 words/sec in server mode) especially for NLP tasks where speed may be critical. Recently, Darwish and Mubarak (2016) and Abdelali et al. (2016) presented a new Arabic segmenter, FARASA. They reported much faster running times than MADAMIRA with similar accuracy on toekniztion. FARASA produces word segmentations only as opposed to MADAMIRA’s richer output; and it currently does not handle any Arabic dialect. Our system, YAMAMA, uses some components from MADAMIRA, in particular the morphological analyzers (out-of-context readings) but has its own disambiguation models. This allows YAMAMA to maintain the richness of MADAMIRA, but increase the speed. The disambiguation modeling components are inspired by FARASA’s design. In this paper, w"
C16-2047,W05-0909,0,0.0360927,"faster than YAMAMA. 4.2 Machine Translation Evaluation Experimental Setup We used the Moses With OOV Without OOV toolkit (Koehn et al., 2007) with default paramBLEU METEOR BLEU METEOR eters to develop the Statistical Machine TransYAMAMA 39.49 0.3618 38.00 0.3448 lation (SMT) systems. For alignment, we used MADAMIRA 39.52 0.3627 37.65 0.3435 FARASA 37.73 0.3301 37.76 0.3436 GIZA++ (Och and Ney, 2003). And for language modeling, we used KenLM (Heafield et Table 3: Machine translation results al., 2013) to build a 5-gram language model. We evaluate using BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005). We apply statistical significance tests using the paired bootstrapped resampling method (Koehn, 2004). We used the Arabic-English parallel component of the UN Corpus (Eisele and Chen, 2010), with about 9 million lines for the English language model (∼286 million words), 200 thousand parallel lines for training (∼5 million words), 2000 lines for tuning, and 3000 lines for testing. The English content was tokenized using the default English tokenizer at Moses, and the Arabic texts were tokenized through YAMAMA, MADAMIRA and FARASA into the same Arabic Treebank tokenization scheme. For YAMAMA,"
C16-2047,L16-1170,0,0.38741,"Habash, 2010). Table 1 presents an examphological analyzer of the word á  K. byn. The correct ple that showcases the aspect of morphological analysis is highlighted in gray. ambiguity which is shared across all varieties of Arabic.1 Previous efforts on morphological analysis and disambiguation have led to the creation of a number of state-of-the-art tools with high accuracy, such as MADAMIRA (Pasha et al., 2014). MADAMIRA produces a rich output (diacritization, tokenization, part-of-speech (POS), lemmatization, gloss, and all inflected features), but it is slow. Other systems such as FARASA (Darwish and Mubarak, 2016) are very fast but focus on specific types of output with high quality performance (tokenization). Clearly, there is always a tradeoff between speed, quality and richness. Our system, YAMAMA (Yet Another Multi Dialect Arabic Morphological Analyzer; Arabic éÓAÖß ‘Barbary Dove’), is an alternative to MADAMIRA and FARASA: it offers a faster performance than MADAMIRA but with all of MADAMIRA’s rich output at a reasonable tradeoff of quality that varies depending on the specific feature.2 2 Related Work There has been a considerable amount of work on MSA and DA morphological analysis, disambiguati"
C16-2047,eisele-chen-2010-multiun,0,0.0194817,"develop the Statistical Machine TransYAMAMA 39.49 0.3618 38.00 0.3448 lation (SMT) systems. For alignment, we used MADAMIRA 39.52 0.3627 37.65 0.3435 FARASA 37.73 0.3301 37.76 0.3436 GIZA++ (Och and Ney, 2003). And for language modeling, we used KenLM (Heafield et Table 3: Machine translation results al., 2013) to build a 5-gram language model. We evaluate using BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005). We apply statistical significance tests using the paired bootstrapped resampling method (Koehn, 2004). We used the Arabic-English parallel component of the UN Corpus (Eisele and Chen, 2010), with about 9 million lines for the English language model (∼286 million words), 200 thousand parallel lines for training (∼5 million words), 2000 lines for tuning, and 3000 lines for testing. The English content was tokenized using the default English tokenizer at Moses, and the Arabic texts were tokenized through YAMAMA, MADAMIRA and FARASA into the same Arabic Treebank tokenization scheme. For YAMAMA, we used the TOKAN tool (Habash et al., 2009) to do the tokenization. The Arabic dataset we used had English text segments covering UN resolutions numbers and named entities; so we applied Mos"
C16-2047,W12-2301,1,0.715028,"t al. (2013) for both treebanks. Maximum Likelihood Model We created the maximum likelihood model based on the ATB Train dataset by selecting the most frequent analysis for each word token in the dataset. The selected analyses are then stored in a dictionary that is loaded once the system starts running. The analyses include all the morphological and lexical features as in MADAMIRA. Analysis and Disambiguation For the OOV words, we run a morphological analyzer (same analyzer used in MADAMIRA). For MSA we used the SAMA database (Graff et al., 2009), and for EGY we used the CALIMA ARZ database (Habash et al., 2012). The analyses of each word are ranked using the multiplication of their lemma probability and their semi-lexicalized Buckwalter tag probability. Both probabilities are estimated using the training data. The highest ranking analysis is selected; and the word and analysis are added to the loaded analysis dictionary. Tokenization YAMAMA currently produces a detailed segmentation consisting of the undiacritized morphemes from the Buckwalter tag analysis (BWTagTok). For the analysis dictionary the BWTagTok segmentation is generated for each word ahead of time. Whereas for OOV words, the segmentati"
C16-2047,P13-2121,0,0.0343517,"Missing"
C16-2047,P07-2045,0,0.0149803,"Missing"
C16-2047,W04-3250,0,0.118343,"olkit (Koehn et al., 2007) with default paramBLEU METEOR BLEU METEOR eters to develop the Statistical Machine TransYAMAMA 39.49 0.3618 38.00 0.3448 lation (SMT) systems. For alignment, we used MADAMIRA 39.52 0.3627 37.65 0.3435 FARASA 37.73 0.3301 37.76 0.3436 GIZA++ (Och and Ney, 2003). And for language modeling, we used KenLM (Heafield et Table 3: Machine translation results al., 2013) to build a 5-gram language model. We evaluate using BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005). We apply statistical significance tests using the paired bootstrapped resampling method (Koehn, 2004). We used the Arabic-English parallel component of the UN Corpus (Eisele and Chen, 2010), with about 9 million lines for the English language model (∼286 million words), 200 thousand parallel lines for training (∼5 million words), 2000 lines for tuning, and 3000 lines for testing. The English content was tokenized using the default English tokenizer at Moses, and the Arabic texts were tokenized through YAMAMA, MADAMIRA and FARASA into the same Arabic Treebank tokenization scheme. For YAMAMA, we used the TOKAN tool (Habash et al., 2009) to do the tokenization. The Arabic dataset we used had Eng"
C16-2047,maamouri-etal-2014-developing,1,0.917963,"uses a pre-computed maximum likelihood model to assign an analysis to every word. For out-of-vocabulary words, YAMAMA ranks all of the analyses for such words using two unigram language models of the lemma and the Buckwalter POS tag. In both cases, YAMAMA reduces the text to types and makes decisions in type space, thus benefiting from the low type to token ratio.3 Datasets For the training and development of our system, we used the same settings as those used for MADAMIRA. For MSA, we used the Penn Arabic Treebank (PATB parts 1,2 and 3) (Maamouri et al., 2004), and for EGY, the ARZ Treebank (Maamouri et al., 2014) . We followed the data splits recommend by Diab et al. (2013) for both treebanks. Maximum Likelihood Model We created the maximum likelihood model based on the ATB Train dataset by selecting the most frequent analysis for each word token in the dataset. The selected analyses are then stored in a dictionary that is loaded once the system starts running. The analyses include all the morphological and lexical features as in MADAMIRA. Analysis and Disambiguation For the OOV words, we run a morphological analyzer (same analyzer used in MADAMIRA). For MSA we used the SAMA database (Graff et al., 20"
C16-2047,J03-1002,0,0.0106624,"Missing"
C16-2047,P02-1040,0,0.0972054,"n MADAMIRA and FARASA is four times faster than YAMAMA. 4.2 Machine Translation Evaluation Experimental Setup We used the Moses With OOV Without OOV toolkit (Koehn et al., 2007) with default paramBLEU METEOR BLEU METEOR eters to develop the Statistical Machine TransYAMAMA 39.49 0.3618 38.00 0.3448 lation (SMT) systems. For alignment, we used MADAMIRA 39.52 0.3627 37.65 0.3435 FARASA 37.73 0.3301 37.76 0.3436 GIZA++ (Och and Ney, 2003). And for language modeling, we used KenLM (Heafield et Table 3: Machine translation results al., 2013) to build a 5-gram language model. We evaluate using BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005). We apply statistical significance tests using the paired bootstrapped resampling method (Koehn, 2004). We used the Arabic-English parallel component of the UN Corpus (Eisele and Chen, 2010), with about 9 million lines for the English language model (∼286 million words), 200 thousand parallel lines for training (∼5 million words), 2000 lines for tuning, and 3000 lines for testing. The English content was tokenized using the default English tokenizer at Moses, and the Arabic texts were tokenized through YAMAMA, MADAMIRA and FARASA into the same Arabic Tree"
C16-2047,pasha-etal-2014-madamira,1,0.882058,"Missing"
C16-2048,N13-1049,1,0.890416,"biguator, MADAMIRA (Pasha et al., 2014), and improves its results using syntactically driven features. The system offers a number of output formats that include basic Columbia Arabic Treebank dependency (Habash and Roth, 2009) with morphological features, two tree visualization modes, and traditional Arabic grammatical analysis. CamelParser is publicly available for research purposes.1 2 Related Work In related work on modeling Arabic syntax and morphology, Habash et al. (2007a) demonstrated that given good syntactic representations, case prediction can be done with a high degree of accuracy. Alkuhlani et al. (2013) later extended this work to cover all morphological features. Marton et al. (2013) explored the contribution of different POS tag sets and several lexical and inflectional morphology features to dependency parsing of Arabic. Building on all of these previous efforts, Shahrour et al. (2015) presented an approach for improving the quality of several morphological features using syntax. They demonstrated that predicted syntax can significantly improve the full morphological analysis choice, particularly for case and state. Our system, CamelParser, further builds on their approach and improves on"
C16-2048,E12-2012,0,0.133263,"Missing"
C16-2048,P09-2056,1,0.91603,"e) construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the Idafa construction chain the noun heads. In this paper, we present CamelParser, a system for Arabic syntactic dependency analysis aligned with contextually disambiguated morphological features. CamelParser uses a state-of-the-art morphological disambiguator, MADAMIRA (Pasha et al., 2014), and improves its results using syntactically driven features. The system offers a number of output formats that include basic Columbia Arabic Treebank dependency (Habash and Roth, 2009) with morphological features, two tree visualization modes, and traditional Arabic grammatical analysis. CamelParser is publicly available for research purposes.1 2 Related Work In related work on modeling Arabic syntax and morphology, Habash et al. (2007a) demonstrated that given good syntactic representations, case prediction can be done with a high degree of accuracy. Alkuhlani et al. (2013) later extended this work to cover all morphological features. Marton et al. (2013) explored the contribution of different POS tag sets and several lexical and inflectional morphology features to depende"
C16-2048,D07-1116,1,0.817094,"ependency analysis aligned with contextually disambiguated morphological features. CamelParser uses a state-of-the-art morphological disambiguator, MADAMIRA (Pasha et al., 2014), and improves its results using syntactically driven features. The system offers a number of output formats that include basic Columbia Arabic Treebank dependency (Habash and Roth, 2009) with morphological features, two tree visualization modes, and traditional Arabic grammatical analysis. CamelParser is publicly available for research purposes.1 2 Related Work In related work on modeling Arabic syntax and morphology, Habash et al. (2007a) demonstrated that given good syntactic representations, case prediction can be done with a high degree of accuracy. Alkuhlani et al. (2013) later extended this work to cover all morphological features. Marton et al. (2013) explored the contribution of different POS tag sets and several lexical and inflectional morphology features to dependency parsing of Arabic. Building on all of these previous efforts, Shahrour et al. (2015) presented an approach for improving the quality of several morphological features using syntax. They demonstrated that predicted syntax can significantly improve the"
C16-2048,J13-1008,1,0.802813,"driven features. The system offers a number of output formats that include basic Columbia Arabic Treebank dependency (Habash and Roth, 2009) with morphological features, two tree visualization modes, and traditional Arabic grammatical analysis. CamelParser is publicly available for research purposes.1 2 Related Work In related work on modeling Arabic syntax and morphology, Habash et al. (2007a) demonstrated that given good syntactic representations, case prediction can be done with a high degree of accuracy. Alkuhlani et al. (2013) later extended this work to cover all morphological features. Marton et al. (2013) explored the contribution of different POS tag sets and several lexical and inflectional morphology features to dependency parsing of Arabic. Building on all of these previous efforts, Shahrour et al. (2015) presented an approach for improving the quality of several morphological features using syntax. They demonstrated that predicted syntax can significantly improve the full morphological analysis choice, particularly for case and state. Our system, CamelParser, further builds on their approach and improves on it by optimizing the syntactic parsing and by offering output in several formats i"
C16-2048,pasha-etal-2014-madamira,1,0.925657,"Missing"
C16-2048,D15-1152,1,0.841661,"aditional Arabic grammatical analysis. CamelParser is publicly available for research purposes.1 2 Related Work In related work on modeling Arabic syntax and morphology, Habash et al. (2007a) demonstrated that given good syntactic representations, case prediction can be done with a high degree of accuracy. Alkuhlani et al. (2013) later extended this work to cover all morphological features. Marton et al. (2013) explored the contribution of different POS tag sets and several lexical and inflectional morphology features to dependency parsing of Arabic. Building on all of these previous efforts, Shahrour et al. (2015) presented an approach for improving the quality of several morphological features using syntax. They demonstrated that predicted syntax can significantly improve the full morphological analysis choice, particularly for case and state. Our system, CamelParser, further builds on their approach and improves on it by optimizing the syntactic parsing and by offering output in several formats including aligned syntax 2 tree visualization, and tree ˇ and morphology, traditional Arabic grammatical analysis ( H . @Q«@ AiςrAb), annotation output compatible with the dependency annotation tool TrEd (Paja"
C18-1113,L18-1577,0,0.112743,"Missing"
C18-1113,C16-1115,0,0.035577,"and more advanced deep learning methods were submitted. High-order character n-grams extracted from speech or phonetic transcripts and i-vectors (a low-dimensional representation of audio recordings) were shown to be the most successful and efficient features (Butnaru and Ionescu, 2018), while deep learning approaches (Belinkov and Glass, 2016) did not perform well. Recently, there are more efforts to collect and annotate datasets for dialect identification. AbdulMageed et al. (2018) present a large dataset from Twitter domain covering dialects from 29 major Arab cities in 10 Arab countries. Al-Badrashiny and Diab (2016) present a system that detects points of codeswitching in sentences between MSA and dialectal Arabic. Most, if not all of the approaches, proposed in the literature have been exploring DID at the regional or country level. To the best of our knowledge, this is the first fine-grained DID system covering the dialects of 25 cities from several countries, including cities in the same country in the Arab World. Moreover, this is the first study pinpointing Arabic DID, discussing the difference between regional and city-level identification and redrawing the geographical map for Arabic DID. Furtherm"
C18-1113,W16-4819,0,0.171986,"main regions: Egyptian, Gulf, Levantine and North African, in addition to MSA. The dataset used in these tasks is different from the dataset we use in this work in its genre, size and the dialects covered. Several systems implementing a range of traditional supervised learning and more advanced deep learning methods were submitted. High-order character n-grams extracted from speech or phonetic transcripts and i-vectors (a low-dimensional representation of audio recordings) were shown to be the most successful and efficient features (Butnaru and Ionescu, 2018), while deep learning approaches (Belinkov and Glass, 2016) did not perform well. Recently, there are more efforts to collect and annotate datasets for dialect identification. AbdulMageed et al. (2018) present a large dataset from Twitter domain covering dialects from 29 major Arab cities in 10 Arab countries. Al-Badrashiny and Diab (2016) present a system that detects points of codeswitching in sentences between MSA and dialectal Arabic. Most, if not all of the approaches, proposed in the literature have been exploring DID at the regional or country level. To the best of our knowledge, this is the first fine-grained DID system covering the dialects o"
C18-1113,W14-3612,1,0.881669,"ptian and I.JºK AK An example of phonological differences is in the pronunciation of dialectal words whose MSA cognate  has the letter Qaf (  q). It is often observed that in Tunisian Arabic, this consonant appears as /q/ (similar to MSA), while in Egyptian and Levantine Arabic it is /P/ (glottal stop) and in Gulf Arabic it is /G/ (Haeri, 1991; Habash, 2010). It should be also noted that while MSA has an established standard orthography, the dialects do not. Often people write words reflecting the phonology or the history (etymology) of these words. DA is sometimes written in Roman script (Bies et al., 2014). In the context of NLP, a set of conventional orthography guidelines (CODA) has been proposed, but only for specific dialects (Habash et al., 2018). Despite these differences, distinguishing between dialects is a very challenging task because: (i) dialects use the same writing script (not in a conventionalized way) and share part of the vocabulary; and (ii) Arabic speakers usually resort to repeated code-switching between their dialect and MSA (AbuMelhim, 1991; Bassiouney, 2009), creating sentences with different levels/percentages of dialectness. More discussion on the similarity between dia"
C18-1113,W18-0519,0,0.0312111,"ranscripts along with acoustic features for dialects of four main regions: Egyptian, Gulf, Levantine and North African, in addition to MSA. The dataset used in these tasks is different from the dataset we use in this work in its genre, size and the dialects covered. Several systems implementing a range of traditional supervised learning and more advanced deep learning methods were submitted. High-order character n-grams extracted from speech or phonetic transcripts and i-vectors (a low-dimensional representation of audio recordings) were shown to be the most successful and efficient features (Butnaru and Ionescu, 2018), while deep learning approaches (Belinkov and Glass, 2016) did not perform well. Recently, there are more efforts to collect and annotate datasets for dialect identification. AbdulMageed et al. (2018) present a large dataset from Twitter domain covering dialects from 29 major Arab cities in 10 Arab countries. Al-Badrashiny and Diab (2016) present a system that detects points of codeswitching in sentences between MSA and dialectal Arabic. Most, if not all of the approaches, proposed in the literature have been exploring DID at the regional or country level. To the best of our knowledge, this i"
C18-1113,D14-1154,0,0.340509,"edicated to discriminating between language varieties (Malmasi et al., 2016; Zampieri et al., 2017). This is not surprising considering the importance of automatic DID for several NLP tasks, where prior knowledge about the dialect of an input text can be helpful, such as machine translation (Salloum et al., 2014), sentiment analysis (Al-Twairesh et al., 2016), or author profiling (Sadat et al., 2014). For Arabic DID, previous work typically targeted coarse-grained five dialect classes plus Standard Arabic at most (6-way classification) (Zaidan and Callison-Burch, 2014; Elfardy and Diab, 2013; Darwish et al., 2014). In this paper, we tackle a finer-grained dialect classification task, covering 25 cities from across the Arab World (from Rabat to Muscat), in addition to Standard Arabic. Table 1 shows the break up we follow in choosing these cities. The table relates the typical five-way regional break up of Arabic dialects (Habash, 2010) to a more refined ten-way sub-region division, and even further into 25 cities. This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ License details: http:// 1332 Proceedings of the 27th International C"
C18-1113,elfardy-diab-2012-simplified,0,0.0406909,"ntation and exploring different datasets has attracted increasing attention in recent years. Shoufan and Alameri (2015) and Al-Ayyoub et al. (2017) present a survey on NLP and deep learning methods for processing Arabic dialectal data with an overview on Arabic DID of text and speech. Biadsy and Hirschberg (2009) presented a system that identifies dialectal words in speech and their dialect of origin (on four regional Arabic dialects) from acoustic signals. In the same context, Bougrine et al. (2017) propose a hierarchical classification approach for spoken Arabic Algerian DID, using prosody. Diab and Elfardy (2012) presented a set of guidelines for token-level identification of dialectness. They later proposed a supervised approach for identifying whether a given sentence is prevalently MSA or Egyptian (Elfardy and Diab, 2013) using the Arabic online commentary dataset (AOC) (Zaidan and Callison-Burch, 2011). Their system (Elfardy and Diab, 2012) combines a token-level DID approach with other features to train a Naive-Bayes classifier. Similarly, Tillmann et al. (2014) use a linear SVM 1333 classifier to label the AOC dataset. Also, El-Haj et al. (2018) used grammatical, stylistic and Subtractive Bivale"
C18-1113,L18-1573,0,0.038802,"for spoken Arabic Algerian DID, using prosody. Diab and Elfardy (2012) presented a set of guidelines for token-level identification of dialectness. They later proposed a supervised approach for identifying whether a given sentence is prevalently MSA or Egyptian (Elfardy and Diab, 2013) using the Arabic online commentary dataset (AOC) (Zaidan and Callison-Burch, 2011). Their system (Elfardy and Diab, 2012) combines a token-level DID approach with other features to train a Naive-Bayes classifier. Similarly, Tillmann et al. (2014) use a linear SVM 1333 classifier to label the AOC dataset. Also, El-Haj et al. (2018) used grammatical, stylistic and Subtractive Bivalency Profiling features for dialect identification on the AOC dataset. Sadat et al. (2014) presented a bi-gram character-level model to identify the dialect of sentences in the social media context among dialects of 18 Arab countries. More recently, discriminating between Arabic Dialects has been the goal of a dedicated shared task (Zampieri et al., 2017; Malmasi et al., 2016), encouraging researchers to submit systems to recognize the dialect of speech transcripts along with acoustic features for dialects of four main regions: Egyptian, Gulf,"
C18-1113,C12-2029,0,0.027042,"identifies dialectal words in speech and their dialect of origin (on four regional Arabic dialects) from acoustic signals. In the same context, Bougrine et al. (2017) propose a hierarchical classification approach for spoken Arabic Algerian DID, using prosody. Diab and Elfardy (2012) presented a set of guidelines for token-level identification of dialectness. They later proposed a supervised approach for identifying whether a given sentence is prevalently MSA or Egyptian (Elfardy and Diab, 2013) using the Arabic online commentary dataset (AOC) (Zaidan and Callison-Burch, 2011). Their system (Elfardy and Diab, 2012) combines a token-level DID approach with other features to train a Naive-Bayes classifier. Similarly, Tillmann et al. (2014) use a linear SVM 1333 classifier to label the AOC dataset. Also, El-Haj et al. (2018) used grammatical, stylistic and Subtractive Bivalency Profiling features for dialect identification on the AOC dataset. Sadat et al. (2014) presented a bi-gram character-level model to identify the dialect of sentences in the social media context among dialects of 18 Arab countries. More recently, discriminating between Arabic Dialects has been the goal of a dedicated shared task (Zamp"
C18-1113,P13-2081,0,0.520396,"luation campaigns were dedicated to discriminating between language varieties (Malmasi et al., 2016; Zampieri et al., 2017). This is not surprising considering the importance of automatic DID for several NLP tasks, where prior knowledge about the dialect of an input text can be helpful, such as machine translation (Salloum et al., 2014), sentiment analysis (Al-Twairesh et al., 2016), or author profiling (Sadat et al., 2014). For Arabic DID, previous work typically targeted coarse-grained five dialect classes plus Standard Arabic at most (6-way classification) (Zaidan and Callison-Burch, 2014; Elfardy and Diab, 2013; Darwish et al., 2014). In this paper, we tackle a finer-grained dialect classification task, covering 25 cities from across the Arab World (from Rabat to Muscat), in addition to Standard Arabic. Table 1 shows the break up we follow in choosing these cities. The table relates the typical five-way regional break up of Arabic dialects (Habash, 2010) to a more refined ten-way sub-region division, and even further into 25 cities. This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ License details: http:// 1332 Proceedings of t"
C18-1113,P06-1086,1,0.779032,"l translations. An example of a 28-way parallel sentence (25 cities plus MSA, English and French) extracted from C ORPUS -26 is given in Figure 1. Data pre-processing and splitting In our experiments, we only tokenize the sentences in both C ORPUS -6 and C ORPUS -26 using punctuation marks. Morphological analysis has been shown to improve the performance of DID systems for a small number of dialects (Darwish et al., 2014). However, the number and sophistication of morphological analysis and segmentation tools for DA are very limited (Pasha et al., 2014), cover only a small number of dialects (Habash and Rambow, 2006; Habash et al., 2012b; Khalifa et al., 2017) and unavailable for most of the others. We split each corpus into Train, Development (Dev) and Test sets. The splits are balanced for each dialect and the distribution of each split is given in Table 2. We use TRAIN, DEVELOPMENT and TEST terms with C ORPUS -6 and C ORPUS -26 to refer to the training, development and test sets of the specified corpus. We use the term MODEL to refer to the trained system. Pairwise similarity between dialects In order to get a Train Dev Test Classes sense of the complexity of our task, we explore the deC ORPUS -6 9000"
C18-1113,habash-etal-2012-conventional,1,0.950925,"ic (which may include Sudan), North African Arabic (vaguely covering Morocco, Algeria, Tunisia, Libya and Mauritania), and Yemeni Arabic (Habash, 2010). However, within each of these regional groups, there is significant variation down to the village, town, and city levels. Arabic dialects differ from one another and from MSA on all levels of linguistic representation, from phonology and morphology to lexicon and syntax (Watson, 2007).1 The number of lexical differences is  @ ÂwD¯ « γrf¯h, Lybian P@X dAr and Tunisian ˇ h ‘room’ corresponds to MSA é¯Q significant i.e., Egyptian éð  K. byt (Habash et al., 2012a).2 Morphological differences are also quite common. One example is the I future marker particle which appears as +  sa+ or ¬ñ sawfa in MSA, + hHa+ or hP raH in Levantine  . bAš in Tunisian. This together with the variation in the templatic morphology make the AK   forms of some verbs rather different: e.g., ’I will write’ is I . J» A sa Âaktubu in MSA, I.J» Ag HaÂaktub dialects and 1 Comparative studies of several Arabic dialects suggest that the syntactic differences between the dialects are minor (Benmamoun, 2012). 2 Arabic transliteration is presented in the Habash-Soudi-Buckwalte"
C18-1113,W12-2301,1,0.925705,"ic (which may include Sudan), North African Arabic (vaguely covering Morocco, Algeria, Tunisia, Libya and Mauritania), and Yemeni Arabic (Habash, 2010). However, within each of these regional groups, there is significant variation down to the village, town, and city levels. Arabic dialects differ from one another and from MSA on all levels of linguistic representation, from phonology and morphology to lexicon and syntax (Watson, 2007).1 The number of lexical differences is  @ ÂwD¯ « γrf¯h, Lybian P@X dAr and Tunisian ˇ h ‘room’ corresponds to MSA é¯Q significant i.e., Egyptian éð  K. byt (Habash et al., 2012a).2 Morphological differences are also quite common. One example is the I future marker particle which appears as +  sa+ or ¬ñ sawfa in MSA, + hHa+ or hP raH in Levantine  . bAš in Tunisian. This together with the variation in the templatic morphology make the AK   forms of some verbs rather different: e.g., ’I will write’ is I . J» A sa Âaktubu in MSA, I.J» Ag HaÂaktub dialects and 1 Comparative studies of several Arabic dialects suggest that the syntactic differences between the dialects are minor (Benmamoun, 2012). 2 Arabic transliteration is presented in the Habash-Soudi-Buckwalte"
C18-1113,W11-2123,0,0.0254713,"g data. 1336 0.65 0.60 Token Dissimilarity 0.55 0.50 0.45 0.40 0.35 0.30 MO S BA G BA S BE N TR I SA N DO H JE D RIY TU N SF X AL G RA B FE S KH A MS A MU S AL X CA I AS W SA L AM M JE R BE I DA M AL E 0.25 Dialects Figure 2: Pairwise similarity between dialects in Corpus-26 word or character counts or representation for text classification) (Manning et al., 2008). Baseline We follow the approach described in Zaidan and Callison-Burch (2014) for dialect identification and adapt it to build our baseline model. For each dialect, we train a 5-gram character level language model (LM) using KenLM (Heafield, 2011) with default parameters and Kneser–Ney smoothing. Then, we use the LM to assign to each sentence S, the dialect Di that maximizes its conditional probability score argmaxi P (Di |S). Character-based LMs leverage subword information and are generally good for capturing particular peculiarities that are specific to certain dialects such as the use of certain cli tics, affixes or internal base word structure. For example, the word prefixes K X @ Âdy, JK. bt and ËAë hAl  X @ Âdyš btxdm hAlfyzA ? ‘How long is this depicted by the character n-gram LM in ? @Q ®ËAë ÐYjJK.  visa good for?’ are"
C18-1113,W16-4801,0,0.0610176,"Missing"
C18-1113,pasha-etal-2014-madamira,1,0.919885,"Missing"
C18-1113,W14-5904,0,0.54531,"g the dialect of a particular segment of speech or text of any size (i.e., word, sentence, or document). This task has attracted increasing attention in recent years. For instance, several evaluation campaigns were dedicated to discriminating between language varieties (Malmasi et al., 2016; Zampieri et al., 2017). This is not surprising considering the importance of automatic DID for several NLP tasks, where prior knowledge about the dialect of an input text can be helpful, such as machine translation (Salloum et al., 2014), sentiment analysis (Al-Twairesh et al., 2016), or author profiling (Sadat et al., 2014). For Arabic DID, previous work typically targeted coarse-grained five dialect classes plus Standard Arabic at most (6-way classification) (Zaidan and Callison-Burch, 2014; Elfardy and Diab, 2013; Darwish et al., 2014). In this paper, we tackle a finer-grained dialect classification task, covering 25 cities from across the Arab World (from Rabat to Muscat), in addition to Standard Arabic. Table 1 shows the break up we follow in choosing these cities. The table relates the typical five-way regional break up of Arabic dialects (Habash, 2010) to a more refined ten-way sub-region division, and eve"
C18-1113,P14-2125,1,0.87917,". Ë@ 1 Introduction Dialect identification (DID) is the task of automatically identifying the dialect of a particular segment of speech or text of any size (i.e., word, sentence, or document). This task has attracted increasing attention in recent years. For instance, several evaluation campaigns were dedicated to discriminating between language varieties (Malmasi et al., 2016; Zampieri et al., 2017). This is not surprising considering the importance of automatic DID for several NLP tasks, where prior knowledge about the dialect of an input text can be helpful, such as machine translation (Salloum et al., 2014), sentiment analysis (Al-Twairesh et al., 2016), or author profiling (Sadat et al., 2014). For Arabic DID, previous work typically targeted coarse-grained five dialect classes plus Standard Arabic at most (6-way classification) (Zaidan and Callison-Burch, 2014; Elfardy and Diab, 2013; Darwish et al., 2014). In this paper, we tackle a finer-grained dialect classification task, covering 25 cities from across the Arab World (from Rabat to Muscat), in addition to Standard Arabic. Table 1 shows the break up we follow in choosing these cities. The table relates the typical five-way regional break up"
C18-1113,W15-3205,0,0.0261751,"d analysis and discussion on dialect confusability, optimal classification and tweet dialect classification. Finally, we conclude and give our future directions in Section 6. 2 Related Work Working on DID is more challenging than just recognizing a specific language (Etman and Beex, 2015). Since Arabic dialects use the same script and share part of the vocabulary, it is quite arduous to distinguish between them. Hence, developing an automatic identification system working at different levels of representation and exploring different datasets has attracted increasing attention in recent years. Shoufan and Alameri (2015) and Al-Ayyoub et al. (2017) present a survey on NLP and deep learning methods for processing Arabic dialectal data with an overview on Arabic DID of text and speech. Biadsy and Hirschberg (2009) presented a system that identifies dialectal words in speech and their dialect of origin (on four regional Arabic dialects) from acoustic signals. In the same context, Bougrine et al. (2017) propose a hierarchical classification approach for spoken Arabic Algerian DID, using prosody. Diab and Elfardy (2012) presented a set of guidelines for token-level identification of dialectness. They later propose"
C18-1113,W14-5313,0,0.0251541,"the same context, Bougrine et al. (2017) propose a hierarchical classification approach for spoken Arabic Algerian DID, using prosody. Diab and Elfardy (2012) presented a set of guidelines for token-level identification of dialectness. They later proposed a supervised approach for identifying whether a given sentence is prevalently MSA or Egyptian (Elfardy and Diab, 2013) using the Arabic online commentary dataset (AOC) (Zaidan and Callison-Burch, 2011). Their system (Elfardy and Diab, 2012) combines a token-level DID approach with other features to train a Naive-Bayes classifier. Similarly, Tillmann et al. (2014) use a linear SVM 1333 classifier to label the AOC dataset. Also, El-Haj et al. (2018) used grammatical, stylistic and Subtractive Bivalency Profiling features for dialect identification on the AOC dataset. Sadat et al. (2014) presented a bi-gram character-level model to identify the dialect of sentences in the social media context among dialects of 18 Arab countries. More recently, discriminating between Arabic Dialects has been the goal of a dedicated shared task (Zampieri et al., 2017; Malmasi et al., 2016), encouraging researchers to submit systems to recognize the dialect of speech transc"
C18-1113,P11-1122,0,0.0544994,"sy and Hirschberg (2009) presented a system that identifies dialectal words in speech and their dialect of origin (on four regional Arabic dialects) from acoustic signals. In the same context, Bougrine et al. (2017) propose a hierarchical classification approach for spoken Arabic Algerian DID, using prosody. Diab and Elfardy (2012) presented a set of guidelines for token-level identification of dialectness. They later proposed a supervised approach for identifying whether a given sentence is prevalently MSA or Egyptian (Elfardy and Diab, 2013) using the Arabic online commentary dataset (AOC) (Zaidan and Callison-Burch, 2011). Their system (Elfardy and Diab, 2012) combines a token-level DID approach with other features to train a Naive-Bayes classifier. Similarly, Tillmann et al. (2014) use a linear SVM 1333 classifier to label the AOC dataset. Also, El-Haj et al. (2018) used grammatical, stylistic and Subtractive Bivalency Profiling features for dialect identification on the AOC dataset. Sadat et al. (2014) presented a bi-gram character-level model to identify the dialect of sentences in the social media context among dialects of 18 Arab countries. More recently, discriminating between Arabic Dialects has been th"
C18-1113,W17-1201,0,0.118119,"Missing"
C18-2033,L18-1151,0,0.0430407,"hrases refer to near-complete sentences with subject or object noun placeholders. An example template phrase is “I want *” which can have any noun phrases replace the asterisk, but not a verb phrase such as “buy apples.” To handle the latter case, we have another phrase “I want to buy *.” By allowing noun phrases but not verb phrases, we restrict the possibility of recursive sentence construction due to subordinate clauses and compound sentences. 3.3 Query to Phrase Mapping Dynamic parsing of user input to retrieve closely matching phrase suggestions is cardinal for guiding user conversation. Kumar et al. (2018) have demonstrated that the problem of composing well-formed natural 1 https://spacy.io/ 154 Figure 3: Sentence Generation Process language questions from user input queries has many useful applications, not only for web search engines, question answering systems and bot communication systems, but also for digital assistants where guiding users to their exact needs is paramount. While they reduce this query-to-question conversion to a translation problem, we utilize the same idea to navigate our users’ conversations through suggesting phrases from our database that match an input query. Ortega"
C18-2033,petrov-etal-2012-universal,0,0.012051,"ructure tag. The Concept ID is a 153 Figure 2: Sample English word trie to identify phrases from query words unique index that points to the iconic version of the phrase. Alternative phrases in some languages may exist and will point to the same unique index. This index is the only information that is passed between users’ interfaces when communicating. The non-iconic phrases (or paraphrases) are used to increase the possibility of matching a concept. The iconic version is the one that is presented to the user. The Phrase Structure Tag is inspired by the Universal Part-of-Speech (POS) Tagset (Petrov et al., 2012), but also includes phrase-level tags such as “sentence,” “noun phrase,” and “verb phrase,” in addition to POS tags such as “particle,” “adjective” and “adverb.” Having a large and accurate database of colloquial and alternative paraphrases in all three languages was key to improving the system’s usability and coverage. Since there was no existing corpus available for travel-specific paraphrases, we created our own by scraping translated phrases from a wide range of websites, such as Wikitravel and educational English as Second Language (ESL) resources. This approach came with challenges such"
D07-1116,N07-2014,1,0.898226,"Missing"
D07-1116,W05-0711,0,0.0816376,"Missing"
D07-1116,W04-1612,0,0.15119,"Missing"
D07-1116,P06-1073,0,0.324405,"Missing"
D07-1116,P97-1003,0,\N,Missing
D13-1105,brants-hansen-2002-developments,0,0.0447376,"Missing"
D13-1105,E12-1067,0,0.0121916,"articular lexeme. Both Forsberg et al. (2006) and Cl´ement et al. (2004) describe methods for automatically populating a lexicon from raw data given a set of morphological inflectional classes in a language. Our work differs in that we use annotated data, but do not start with a complete set of inflectional classes; thus, our work is exactly complementary to this work. 1033 The concept of a paradigm is also used in many published efforts on unsupervised learning of morphology, although not always in a way consistent with its use in linguistics. For instance, Snover et al. (2002) (and later on Can and Manandhar (2012)) define a paradigm as “a set of suffixes and the stems that attach to those suffixes and no others”. This definition is quite limited since it is not modeling the notion of lexeme. Chan (2006) defines a simpler concept of paradigms in his probabilistic paradigm model, which has many limitations, such as not handling syncretism or irregular morphology, nor distinguishing inflection and derivation. Dreyer and Eisner (2011) learn complete German verb paradigms from a small set of complete seed paradigms (50 or 100), which they choose randomly from all verbs in the language. They model stem chang"
D13-1105,W06-3209,0,0.0745043,". Our work differs in that we use annotated data, but do not start with a complete set of inflectional classes; thus, our work is exactly complementary to this work. 1033 The concept of a paradigm is also used in many published efforts on unsupervised learning of morphology, although not always in a way consistent with its use in linguistics. For instance, Snover et al. (2002) (and later on Can and Manandhar (2012)) define a paradigm as “a set of suffixes and the stems that attach to those suffixes and no others”. This definition is quite limited since it is not modeling the notion of lexeme. Chan (2006) defines a simpler concept of paradigms in his probabilistic paradigm model, which has many limitations, such as not handling syncretism or irregular morphology, nor distinguishing inflection and derivation. Dreyer and Eisner (2011) learn complete German verb paradigms from a small set of complete seed paradigms (50 or 100), which they choose randomly from all verbs in the language. They model stem changes using letter-based models, and use a large unannotated corpus in addition to the seed paradigms. Durrett and DeNero (2013) attack the same problem as Dreyer and Eisner (2011). Instead of usi"
D13-1105,clement-etal-2004-morphology,0,0.206172,"Missing"
D13-1105,W02-2006,0,0.173852,"systems painstakingly designed by hand (Koskenniemi, 1983; Buckwalter, 2004; Habash and Rambow, 2006; D´etrez and Ranta, 2012) to unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Hammarstr¨om and Borin, 2011; Dreyer and Eisner, 2011). There is a large continuum between these two approaches. Closer to one end, we find work on minimally supervised methods for morphology learning that make use of available resources such as parallel data, dictionaries or some additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). Closer to the other end, we find work that focuses on defining morphological models with limited lexicons that are then extended using raw text (Cl´ement et al., 2004; Forsberg et al., 2006). The work presented in this paper falls in the middle of this continuum: we are interested in learning complete morphological models using rich morphological annotations and, optionally, limited linguistic knowledge. We compare the value of different amounts of annotation and how they relate to additional linguistic knowledge. Morphological Paradigms Ma"
D13-1105,D11-1057,0,0.447036,"ings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1032–1043, c Seattle, Washington, USA, 18-21 October 2013. 2013 Association for Computational Linguistics 2 Related Work Approaches to Morphological Modeling Much work has been done in the area of computational morphology ranging from systems painstakingly designed by hand (Koskenniemi, 1983; Buckwalter, 2004; Habash and Rambow, 2006; D´etrez and Ranta, 2012) to unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Hammarstr¨om and Borin, 2011; Dreyer and Eisner, 2011). There is a large continuum between these two approaches. Closer to one end, we find work on minimally supervised methods for morphology learning that make use of available resources such as parallel data, dictionaries or some additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). Closer to the other end, we find work that focuses on defining morphological models with limited lexicons that are then extended using raw text (Cl´ement et al., 2004; Forsberg et al., 2006). The work presented in this pa"
D13-1105,N13-1138,0,0.206061,". This definition is quite limited since it is not modeling the notion of lexeme. Chan (2006) defines a simpler concept of paradigms in his probabilistic paradigm model, which has many limitations, such as not handling syncretism or irregular morphology, nor distinguishing inflection and derivation. Dreyer and Eisner (2011) learn complete German verb paradigms from a small set of complete seed paradigms (50 or 100), which they choose randomly from all verbs in the language. They model stem changes using letter-based models, and use a large unannotated corpus in addition to the seed paradigms. Durrett and DeNero (2013) attack the same problem as Dreyer and Eisner (2011). Instead of using unannotated text, they model explicit rules for affixes and stem changes. The major difference between these two efforts and our work is that the problem is defined differently: we assume that the training and test data is defined by a corpus, not by complete paradigms. Our methods therefore are more sensitive to frequency effects of tokens. We believe that our way of stating the problem is more relevant to actual computational challenges for languages with limited morphological resources. We empirically compare our approac"
D13-1105,W13-2301,1,0.894623,"Missing"
D13-1105,W02-0502,0,0.0467801,"interested in learning complete morphological models using rich morphological annotations and, optionally, limited linguistic knowledge. We compare the value of different amounts of annotation and how they relate to additional linguistic knowledge. Morphological Paradigms Many traditional and modern theories of inflectional morphology organize natural language morphology by paradigms (Stump, 2001; Walther, 2011; Camilleri, 2011). Within the continuum we discussed above, we find hierarchical representations of paradigm knowledge that have been used in manually constructed morphological models (Finkel and Stump, 2002; Habash et al., 2005). Furthermore, D´etrez and Ranta (2012) introduce an implementation of Smart Paradigms – heuristically organized paradigms minimizing the number of forms needed to predict the full paradigm of a particular lexeme. Both Forsberg et al. (2006) and Cl´ement et al. (2004) describe methods for automatically populating a lexicon from raw data given a set of morphological inflectional classes in a language. Our work differs in that we use annotated data, but do not start with a complete set of inflectional classes; thus, our work is exactly complementary to this work. 1033 The c"
D13-1105,P06-1086,1,0.883461,"introduce the key linguistic concepts we use (Section 3). We present our basic language-independent method in Section 4, and our language-specific modeling of stem variation in Section 5. 1032 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1032–1043, c Seattle, Washington, USA, 18-21 October 2013. 2013 Association for Computational Linguistics 2 Related Work Approaches to Morphological Modeling Much work has been done in the area of computational morphology ranging from systems painstakingly designed by hand (Koskenniemi, 1983; Buckwalter, 2004; Habash and Rambow, 2006; D´etrez and Ranta, 2012) to unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Hammarstr¨om and Borin, 2011; Dreyer and Eisner, 2011). There is a large continuum between these two approaches. Closer to one end, we find work on minimally supervised methods for morphology learning that make use of available resources such as parallel data, dictionaries or some additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). Closer to the other"
D13-1105,W05-0703,1,0.577033,"omplete morphological models using rich morphological annotations and, optionally, limited linguistic knowledge. We compare the value of different amounts of annotation and how they relate to additional linguistic knowledge. Morphological Paradigms Many traditional and modern theories of inflectional morphology organize natural language morphology by paradigms (Stump, 2001; Walther, 2011; Camilleri, 2011). Within the continuum we discussed above, we find hierarchical representations of paradigm knowledge that have been used in manually constructed morphological models (Finkel and Stump, 2002; Habash et al., 2005). Furthermore, D´etrez and Ranta (2012) introduce an implementation of Smart Paradigms – heuristically organized paradigms minimizing the number of forms needed to predict the full paradigm of a particular lexeme. Both Forsberg et al. (2006) and Cl´ement et al. (2004) describe methods for automatically populating a lexicon from raw data given a set of morphological inflectional classes in a language. Our work differs in that we use annotated data, but do not start with a complete set of inflectional classes; thus, our work is exactly complementary to this work. 1033 The concept of a paradigm i"
D13-1105,W12-2301,1,0.79686,"new word forms from morphosyntactic features and lemmas, unlike the largely unsupervised work. Our work also differs from most previous work in that we investigate how to model stem change explicitly. Whereas other approaches model stem syncretism through letterbased models (Yarowsky and Wicentowski, 2000; Neuvel and Fulop, 2002; Dreyer and Eisner, 2011), we explore the use of abstract stems. In our previous work on the EGY morphological analyzer CALIMA, we similarly used a lexicon of annotated morphological forms and extended it automatically using a simpler approach to paradigm completion (Habash et al., 2012). 3 Linguistic Terminology In this section, we review key concepts from morphology, and introduce the terminology we will use in this paper.2 We then introduce our own formalization of stems using vocalic templates. Morphology is the study of word forms and their decomposition into elementary morphemes, which are the smallest meaning-bearing units of a language. There are two types of morphological processes: inflectional and derivational morphology. In inflectional morphology, a core meaning is retained and different word forms reflect different types of morphosyntactic features such as perso"
D13-1105,J11-2002,0,0.09257,"Missing"
D13-1105,W02-0604,0,0.094647,"d by hand (Koskenniemi, 1983; Buckwalter, 2004; Habash and Rambow, 2006; D´etrez and Ranta, 2012) to unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Hammarstr¨om and Borin, 2011; Dreyer and Eisner, 2011). There is a large continuum between these two approaches. Closer to one end, we find work on minimally supervised methods for morphology learning that make use of available resources such as parallel data, dictionaries or some additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). Closer to the other end, we find work that focuses on defining morphological models with limited lexicons that are then extended using raw text (Cl´ement et al., 2004; Forsberg et al., 2006). The work presented in this paper falls in the middle of this continuum: we are interested in learning complete morphological models using rich morphological annotations and, optionally, limited linguistic knowledge. We compare the value of different amounts of annotation and how they relate to additional linguistic knowledge. Morphological Paradigms Many traditional and moder"
D13-1105,W02-0602,0,0.0332541,"to predict the full paradigm of a particular lexeme. Both Forsberg et al. (2006) and Cl´ement et al. (2004) describe methods for automatically populating a lexicon from raw data given a set of morphological inflectional classes in a language. Our work differs in that we use annotated data, but do not start with a complete set of inflectional classes; thus, our work is exactly complementary to this work. 1033 The concept of a paradigm is also used in many published efforts on unsupervised learning of morphology, although not always in a way consistent with its use in linguistics. For instance, Snover et al. (2002) (and later on Can and Manandhar (2012)) define a paradigm as “a set of suffixes and the stems that attach to those suffixes and no others”. This definition is quite limited since it is not modeling the notion of lexeme. Chan (2006) defines a simpler concept of paradigms in his probabilistic paradigm model, which has many limitations, such as not handling syncretism or irregular morphology, nor distinguishing inflection and derivation. Dreyer and Eisner (2011) learn complete German verb paradigms from a small set of complete seed paradigms (50 or 100), which they choose randomly from all verbs"
D13-1105,P08-1084,0,0.0864841,"1983; Buckwalter, 2004; Habash and Rambow, 2006; D´etrez and Ranta, 2012) to unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Hammarstr¨om and Borin, 2011; Dreyer and Eisner, 2011). There is a large continuum between these two approaches. Closer to one end, we find work on minimally supervised methods for morphology learning that make use of available resources such as parallel data, dictionaries or some additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). Closer to the other end, we find work that focuses on defining morphological models with limited lexicons that are then extended using raw text (Cl´ement et al., 2004; Forsberg et al., 2006). The work presented in this paper falls in the middle of this continuum: we are interested in learning complete morphological models using rich morphological annotations and, optionally, limited linguistic knowledge. We compare the value of different amounts of annotation and how they relate to additional linguistic knowledge. Morphological Paradigms Many traditional and modern theories of inflectional m"
D13-1105,P00-1027,0,0.825964,"ational morphology ranging from systems painstakingly designed by hand (Koskenniemi, 1983; Buckwalter, 2004; Habash and Rambow, 2006; D´etrez and Ranta, 2012) to unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Hammarstr¨om and Borin, 2011; Dreyer and Eisner, 2011). There is a large continuum between these two approaches. Closer to one end, we find work on minimally supervised methods for morphology learning that make use of available resources such as parallel data, dictionaries or some additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). Closer to the other end, we find work that focuses on defining morphological models with limited lexicons that are then extended using raw text (Cl´ement et al., 2004; Forsberg et al., 2006). The work presented in this paper falls in the middle of this continuum: we are interested in learning complete morphological models using rich morphological annotations and, optionally, limited linguistic knowledge. We compare the value of different amounts of annotation and how they relate to additional linguistic knowledg"
D13-1105,E12-1066,0,\N,Missing
D15-1090,N15-1122,0,0.015153,"pical text recipe consists of two parts: an ingredient list that declares the food items to process, and a set of instructions that mostly describe the transformations of the ingredients or the actions using the kitchen tools. The instructions relocate, process, combine, and separate ingredients, as well as heat or cool utensils in the recipes. For the most part, the output produced from one instruction feeds as input into another instruction. The list of ingredients can be generalized as special fetch instructions whose output feeds as input to one of the cooking instructions. Most recently, Abend et al. (2015) proposed an edge-factored model to determine the likely temporal order of events based solely on the identity of their predicates and arguments. They demonstrated their approach on recipe text, under the simplifying assumption that such text is also temporally ordered. 3.2 SIMMR Our proposed representation is SIMMR: Simplified Ingredient Merging Map in Recipes. SIMMR represents a recipe as a dependency tree whose leaves (terminal nodes) are the recipe ingredients, and whose internal nodes are the recipe instructions. Figure 1 exemplifies the SIMMR tree of a recipe for Surprise-inside French T"
D15-1090,de-marneffe-etal-2006-generating,0,0.0292519,"Missing"
D15-1090,W14-2407,0,0.214396,"SIMMR inst9 inst8 inst7 inst6 inst5 inst4 ing6 ing7 egg milk inst1 inst3 inst0 ing0 french bread inst2 ing4 sugar ing5 vanilla ing1 ing2 ing3 ricotta cottage cream cheese Figure 1: Example of a text recipe for Surprise-inside French Toast and its SIMMR representation. ing&lt;index> and inst&lt;index> refer to specific ingredients and instructions, respectively. 3 Mori et al. (2012) applied word segmentation, named entity recognition, and syntactic analysis to extract predicate-argument structures from Japanese recipe instructions as part of an effort to develop complete recipe flow representations. Malmaud et al. (2014) proposed a Markov Decision Process, in which the context of ingredients and tools is propagated along the temporal order of cooking instructions. 3.1 Recipe Representation Text Recipes The prototypical text recipe consists of two parts: an ingredient list that declares the food items to process, and a set of instructions that mostly describe the transformations of the ingredients or the actions using the kitchen tools. The instructions relocate, process, combine, and separate ingredients, as well as heat or cool utensils in the recipes. For the most part, the output produced from one instruct"
D15-1090,mori-etal-2014-flow,0,0.136123,"ractices of specific cultures. Nedovic (2013) examined underlying ingredient groupings from their recipe co-occurrences, using topic modeling techniques (latent Dirichlet allocation), and further improvised novel ingredient combinations using deep belief networks. Among the structured representation approaches, Tasse and Smith (2008) proposed MILK (Minimal Instruction Language for the Kitchen), a formal language to describe actions required in directive cooking instructions. They used MILK in developing CURD (Carnegie Mellon University Recipe Database), a corpus of manually annotated recipes. Mori et al. (2014) also manually annotated the procedural flow of Japanese cooking recipes using directed acyclic graphs (DAGs) where graph nodes correspond to food ingredients, cooking instruments, and actions. Tasse and Smith (2008) had limited success in parsing into MILK; and Mori et al. (2014) did not report on parsing experiments. Other studies explored different machine learning and NLP techniques to processing recipes. Introduction Cooking recipes are a specific genre of how-to instructions which have been gaining interest in recent years as they may allow us to discover insights into culinary and cultu"
D15-1152,N13-1049,1,0.789335,"l sentences with impressive results. We do not compare to their effort here but we note that they use an order of magnitude more diacritized data than we do, and they focus on diacritization only as opposed to full morphological analysis. In related work on modeling Arabic case and syntax, Habash et al. (2007a) compared rule-based and machine learning approaches to capture the complexity of Arabic case assignment and agreement. They demonstrated their results on gold syntactic analyses showing that given good syntactic representations, case prediction can be done at a high degree of accuracy. Alkuhlani et al. (2013) later extended this work to cover all morphological features, including state. Additionally, Marton et al. (2013) demonstrated that in the context of syntactic dependency parsing, case is the best feature to use in gold settings and is the worst feature to use in predicted settings. In this paper we use automatic (i.e. not gold) syntactic features to improve case prediction, which improves morphological analysis and word diacrtization. 4 Approach Motivation We are motivated by an error analysis we conducted of 1,200 words of the MADAMIRA system output. We found a large number of surprising sy"
D15-1152,N09-1045,1,0.67065,"Missing"
D15-1152,W15-3209,0,0.457686,"ct of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deeper morphological information; none to our knowledge make use of syntax. Habash and Rambow (2007) approach diacritization as a part of the morphological disambiguation problem, where they select the optimal full morphological tag for Arabic in context and use it to select from a list of possible analyses pro"
D15-1152,2007.mtsummit-papers.20,1,0.933313,"ar increases are shown on the full morphological analysis choice. 1 2 Introduction Modern Standard Arabic (MSA) orthography generally omits diacritical marks which encode lexical as well as syntactic (case) information. The task of Arabic automatic diacritization is about the automatic restoration of the missing diacritics. Diacritization improvement in Arabic has important implications for downstream processing for Arabic natural language processing, e.g. speech recognition (Ananthakrishnan et al., 2005; Biadsy et al., 2009), speech synthesis (Elshafei et al., 2002), and machine translation (Diab et al., 2007; Zbib et al., 2010). Previous efforts on diacritization utilized morphological tagging techniques to disambiguate word forms. Habash et al. (2007a) observe that while such techniques work relatively well on lexical diacritics (located on word stems), they are much worse for syntactic case diacritics (typically word final). They suggest that syntactic analysis may help with automatic diacrtization, but stop short of testing the idea, and instead demonstrate that complex linguistic features and rules are needed to model complex Arabic case using gold syntactic analyses. In this paper, we develo"
D15-1152,P05-1071,1,0.660522,"ion techniques. The results for these techniques are compared to our state-of-the-art baseline system, which has been compared to a number of other approaches. 5.1 Experimental Setup Data We used the Penn Arabic Treebank (PATB, parts 1, 2 and 3) (Maamouri et al., 2004; Maamouri et al., 2006; Maamouri et al., 2009) split into Train, Dev and (blind) Test along the recommendations of Diab et al. (2013) which were also used in the baseline system. The morphological feature representations we use are derived from the PATB analyses following the approach used in the MADA and later MADAMIRA systems (Habash and Rambow, 2005; Habash and Rambow, 2007; Pasha et al., 2014). We further divide Dev into two parts with equal number of sentences: DevTrain (30K words) for training our case-state classifiers, and DevTest (33K words) for development testing. The Test set has 63K words.5 Evaluation Metrics We report our accuracy in terms of two metrics: a. Diac, the percentage of correctly fully diacrtized words; and b. All, the percentage of words for which a full morphological analysis (lemma, POS, all inflectional and clitic features, and diacritization) is correctly predicted. We report the results on all words (All Word"
D15-1152,N07-2014,1,0.872544,"lex case/state assignment and agreement patterns that interact with the sentence’s syntax. For example, a noun may get its case by being subject of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deeper morphological information; none to our knowledge make use of syntax. Habash and Rambow (2007) approach diacritization as a part of the morphological disambiguation p"
D15-1152,P09-2056,1,0.779057,"Missing"
D15-1152,D07-1116,1,0.926859,"ritical marks which encode lexical as well as syntactic (case) information. The task of Arabic automatic diacritization is about the automatic restoration of the missing diacritics. Diacritization improvement in Arabic has important implications for downstream processing for Arabic natural language processing, e.g. speech recognition (Ananthakrishnan et al., 2005; Biadsy et al., 2009), speech synthesis (Elshafei et al., 2002), and machine translation (Diab et al., 2007; Zbib et al., 2010). Previous efforts on diacritization utilized morphological tagging techniques to disambiguate word forms. Habash et al. (2007a) observe that while such techniques work relatively well on lexical diacritics (located on word stems), they are much worse for syntactic case diacritics (typically word final). They suggest that syntactic analysis may help with automatic diacrtization, but stop short of testing the idea, and instead demonstrate that complex linguistic features and rules are needed to model complex Arabic case using gold syntactic analyses. In this paper, we develop an approach for improving the quality of automatic Arabic diacritization through the use of automatic syntactic analysis. Our approach combines"
D15-1152,2006.bcs-1.4,0,0.372531,"vTest experi1310 5 All Words System Diac All Oracle Topline 96.2 94.2 Baseline 87.4 85.0 Morphology Rules 88.0 85.5 Morphology Classifier 88.4 85.9 Syntax Rules 87.4 84.6 Syntax Classifier 89.1 86.6 Syntax Rules+Classifier 89.7 87.1 Experimental Results We present next our experimental results and compare five case-state prediction techniques. The results for these techniques are compared to our state-of-the-art baseline system, which has been compared to a number of other approaches. 5.1 Experimental Setup Data We used the Penn Arabic Treebank (PATB, parts 1, 2 and 3) (Maamouri et al., 2004; Maamouri et al., 2006; Maamouri et al., 2009) split into Train, Dev and (blind) Test along the recommendations of Diab et al. (2013) which were also used in the baseline system. The morphological feature representations we use are derived from the PATB analyses following the approach used in the MADA and later MADAMIRA systems (Habash and Rambow, 2005; Habash and Rambow, 2007; Pasha et al., 2014). We further divide Dev into two parts with equal number of sentences: DevTrain (30K words) for training our case-state classifiers, and DevTest (33K words) for development testing. The Test set has 63K words.5 Evaluation"
D15-1152,J13-1008,1,0.450092,"nitude more diacritized data than we do, and they focus on diacritization only as opposed to full morphological analysis. In related work on modeling Arabic case and syntax, Habash et al. (2007a) compared rule-based and machine learning approaches to capture the complexity of Arabic case assignment and agreement. They demonstrated their results on gold syntactic analyses showing that given good syntactic representations, case prediction can be done at a high degree of accuracy. Alkuhlani et al. (2013) later extended this work to cover all morphological features, including state. Additionally, Marton et al. (2013) demonstrated that in the context of syntactic dependency parsing, case is the best feature to use in gold settings and is the worst feature to use in predicted settings. In this paper we use automatic (i.e. not gold) syntactic features to improve case prediction, which improves morphological analysis and word diacrtization. 4 Approach Motivation We are motivated by an error analysis we conducted of 1,200 words of the MADAMIRA system output. We found a large number of surprising syntactically impossible case errors such as genitive nouns following verbs or construct nouns followed by non-genit"
D15-1152,W05-0711,0,0.043748,".]’ (different features). Third, Arabic has complex case/state assignment and agreement patterns that interact with the sentence’s syntax. For example, a noun may get its case by being subject of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deeper morphological information; none to our knowledge make use of syntax. Habash and Rambow (2007) approach diacritization"
D15-1152,pasha-etal-2014-madamira,1,0.720837,"Missing"
D15-1152,W04-1612,0,0.171602,"tt:c num:d) ‘two books of [...]’ (different features). Third, Arabic has complex case/state assignment and agreement patterns that interact with the sentence’s syntax. For example, a noun may get its case by being subject of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deeper morphological information; none to our knowledge make use of syntax. Habash and Rambow (2007"
D15-1152,W10-1763,0,0.0135376,"own on the full morphological analysis choice. 1 2 Introduction Modern Standard Arabic (MSA) orthography generally omits diacritical marks which encode lexical as well as syntactic (case) information. The task of Arabic automatic diacritization is about the automatic restoration of the missing diacritics. Diacritization improvement in Arabic has important implications for downstream processing for Arabic natural language processing, e.g. speech recognition (Ananthakrishnan et al., 2005; Biadsy et al., 2009), speech synthesis (Elshafei et al., 2002), and machine translation (Diab et al., 2007; Zbib et al., 2010). Previous efforts on diacritization utilized morphological tagging techniques to disambiguate word forms. Habash et al. (2007a) observe that while such techniques work relatively well on lexical diacritics (located on word stems), they are much worse for syntactic case diacritics (typically word final). They suggest that syntactic analysis may help with automatic diacrtization, but stop short of testing the idea, and instead demonstrate that complex linguistic features and rules are needed to model complex Arabic case using gold syntactic analyses. In this paper, we develop an approach for im"
D15-1152,P06-1073,0,0.851274,"Third, Arabic has complex case/state assignment and agreement patterns that interact with the sentence’s syntax. For example, a noun may get its case by being subject of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deeper morphological information; none to our knowledge make use of syntax. Habash and Rambow (2007) approach diacritization as a part of the morph"
D17-1073,N16-3003,0,0.091294,"s. Then they train a model to predict the optimal analysis of a word given the annotations within a context window. Shen et al. (2016), on the other hand, use a character-based Bi-LSTM model for morphological disambiguation of morphologically complex languages, without using a morphological analyzer. The LSTM cells have the advantage of capturing a longer sequence window than those of the fixed window and CNN approaches. Arabic morphological analysis and disambiguation have seen a considerable amount of work, spanning both MSA (Habash and Rambow, 2005; Diab et al., 2004; Khalifa et al., 2016; Abdelali et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). The current state-of-the-art system is MADAMIRA (Pasha et al., 2014); which uses SVMs to disambiguate among a target word’s various morphological analyses provided by a morphological dictionary. Neural-based contributions for Arabic, however, are also relatively scarce. Among the contributions that utilize morphological structures to enhance the neural models in different NLP tasks, we note Guzmán et al. (2016) for machine translation, and Abandah et al. (2015) for diacritization. Darwish et al."
D17-1073,D15-1274,0,0.0667946,"surface word level only, without considering any subword features. Several other contributions utilize somewhat similar approaches, with various neural architectures (Wang et al., 2015; Huang et al., 2015). Dos Santos and Zadrozny (2014), on the other hand, argue that subword information is useful for certain NLP tasks, like POS tagging. They propose a character-based embedding along with the word embeddings, to be able to capture internal morphemic structures. Character embeddings, capturing subword features, are well studied in other contributions too (Labeau et al., 2015; Rei et al., 2016; Belinkov and Glass, 2015). Morphological disambiguation, however, has Definition Diacratization Lemma Basic part-of-speech tags (34 tags) Gender Number Case State Person Aspect Mood Voice Proclitic 0, article proclitic Proclitic 1, preposition proclitic Proclitic 2, conjunction proclitic Proclitic 3, question proclitic Enclitic Table 1: The morphological features we use in the various models. The first two groups are lexical features; and the last two groups are inflectional and clitic features respectively, in addition to the part-of-speech tag. Furthermore, MRLs have a tendency towards a higher degree of ambiguity,"
D17-1073,W17-1316,0,0.0975835,"Missing"
D17-1073,N04-4038,0,0.139101,"oot along with a set of morphemic features. Then they train a model to predict the optimal analysis of a word given the annotations within a context window. Shen et al. (2016), on the other hand, use a character-based Bi-LSTM model for morphological disambiguation of morphologically complex languages, without using a morphological analyzer. The LSTM cells have the advantage of capturing a longer sequence window than those of the fixed window and CNN approaches. Arabic morphological analysis and disambiguation have seen a considerable amount of work, spanning both MSA (Habash and Rambow, 2005; Diab et al., 2004; Khalifa et al., 2016; Abdelali et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). The current state-of-the-art system is MADAMIRA (Pasha et al., 2014); which uses SVMs to disambiguate among a target word’s various morphological analyses provided by a morphological dictionary. Neural-based contributions for Arabic, however, are also relatively scarce. Among the contributions that utilize morphological structures to enhance the neural models in different NLP tasks, we note Guzmán et al. (2016) for machine translation, and Abandah et"
D17-1073,W05-0708,0,0.411618,"mal analysis of a word given the annotations within a context window. Shen et al. (2016), on the other hand, use a character-based Bi-LSTM model for morphological disambiguation of morphologically complex languages, without using a morphological analyzer. The LSTM cells have the advantage of capturing a longer sequence window than those of the fixed window and CNN approaches. Arabic morphological analysis and disambiguation have seen a considerable amount of work, spanning both MSA (Habash and Rambow, 2005; Diab et al., 2004; Khalifa et al., 2016; Abdelali et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). The current state-of-the-art system is MADAMIRA (Pasha et al., 2014); which uses SVMs to disambiguate among a target word’s various morphological analyses provided by a morphological dictionary. Neural-based contributions for Arabic, however, are also relatively scarce. Among the contributions that utilize morphological structures to enhance the neural models in different NLP tasks, we note Guzmán et al. (2016) for machine translation, and Abandah et al. (2015) for diacritization. Darwish et al. (2017) use Bi-LSTM models to train a 4 Approach"
D17-1073,C16-1132,1,0.818225,"spanning both MSA (Habash and Rambow, 2005; Diab et al., 2004; Khalifa et al., 2016; Abdelali et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). The current state-of-the-art system is MADAMIRA (Pasha et al., 2014); which uses SVMs to disambiguate among a target word’s various morphological analyses provided by a morphological dictionary. Neural-based contributions for Arabic, however, are also relatively scarce. Among the contributions that utilize morphological structures to enhance the neural models in different NLP tasks, we note Guzmán et al. (2016) for machine translation, and Abandah et al. (2015) for diacritization. Darwish et al. (2017) use Bi-LSTM models to train a 4 Approach The morphological disambiguation task involves choosing the correct morphological analysis from the set of potential analyses, obtained from the an706 alyzer. Towards that end, we train several models for the individual morphological features, and use their results to score and rank the different analyses and choose an optimal overall analysis. These features can be grouped into non-lexical features, where a tagger is used to obtain the relevant morphological t"
D17-1073,P05-1071,1,0.459729,"form of a word from the root along with a set of morphemic features. Then they train a model to predict the optimal analysis of a word given the annotations within a context window. Shen et al. (2016), on the other hand, use a character-based Bi-LSTM model for morphological disambiguation of morphologically complex languages, without using a morphological analyzer. The LSTM cells have the advantage of capturing a longer sequence window than those of the fixed window and CNN approaches. Arabic morphological analysis and disambiguation have seen a considerable amount of work, spanning both MSA (Habash and Rambow, 2005; Diab et al., 2004; Khalifa et al., 2016; Abdelali et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). The current state-of-the-art system is MADAMIRA (Pasha et al., 2014); which uses SVMs to disambiguate among a target word’s various morphological analyses provided by a morphological dictionary. Neural-based contributions for Arabic, however, are also relatively scarce. Among the contributions that utilize morphological structures to enhance the neural models in different NLP tasks, we note Guzmán et al. (2016) for machine translati"
D17-1073,E99-1010,0,0.0401471,"age Models 6.3 In addition to the morphological taggers for the non-lexical features, we use neural language models for the lemmatization and diacritization features. Lemmas and diacratized forms are lexical in nature, and cannot be modeled directly using a classifier. We use an LSTM-based neural language model (Enarvi and Kurimo, 2016), with class-based input rather than words. Using a class-based approach speeds convergence drastically and improves the overall perplexity, especially for the diac (diacritization) language model, which has a relatively large type count. We use the MKCLS tool (Och, 1999), through GIZA++ (Och and Ney, 2003), to train the word classes. We use two hidden layers of size 500 and input layer of size 300, and use Nesterov Momentum as the optimization algorithm. We encode the testing set in the HTK Standard Lattice Format (SLF), with a word mesh representation for the various options of each word. Table 7 shows the accuracy results of the language models for lex and diac for both MADAMIRA (which uses SRILM (Stolcke, 2002) for language modeling), and the LSTM model we use here. All models are trained on the same ATB training dataset used in the paper. The LSTM results"
D17-1073,N13-1044,1,0.324453,"context window. Shen et al. (2016), on the other hand, use a character-based Bi-LSTM model for morphological disambiguation of morphologically complex languages, without using a morphological analyzer. The LSTM cells have the advantage of capturing a longer sequence window than those of the fixed window and CNN approaches. Arabic morphological analysis and disambiguation have seen a considerable amount of work, spanning both MSA (Habash and Rambow, 2005; Diab et al., 2004; Khalifa et al., 2016; Abdelali et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). The current state-of-the-art system is MADAMIRA (Pasha et al., 2014); which uses SVMs to disambiguate among a target word’s various morphological analyses provided by a morphological dictionary. Neural-based contributions for Arabic, however, are also relatively scarce. Among the contributions that utilize morphological structures to enhance the neural models in different NLP tasks, we note Guzmán et al. (2016) for machine translation, and Abandah et al. (2015) for diacritization. Darwish et al. (2017) use Bi-LSTM models to train a 4 Approach The morphological disambiguation task involves ch"
D17-1073,J03-1002,0,0.0226446,"o the morphological taggers for the non-lexical features, we use neural language models for the lemmatization and diacritization features. Lemmas and diacratized forms are lexical in nature, and cannot be modeled directly using a classifier. We use an LSTM-based neural language model (Enarvi and Kurimo, 2016), with class-based input rather than words. Using a class-based approach speeds convergence drastically and improves the overall perplexity, especially for the diac (diacritization) language model, which has a relatively large type count. We use the MKCLS tool (Och, 1999), through GIZA++ (Och and Ney, 2003), to train the word classes. We use two hidden layers of size 500 and input layer of size 300, and use Nesterov Momentum as the optimization algorithm. We encode the testing set in the HTK Standard Lattice Format (SLF), with a word mesh representation for the various options of each word. Table 7 shows the accuracy results of the language models for lex and diac for both MADAMIRA (which uses SRILM (Stolcke, 2002) for language modeling), and the LSTM model we use here. All models are trained on the same ATB training dataset used in the paper. The LSTM results outperform MADAMIRA’s vastly, provi"
D17-1073,pasha-etal-2014-madamira,1,0.907607,"Missing"
D17-1073,C16-1030,0,0.0269866,"is applied on the surface word level only, without considering any subword features. Several other contributions utilize somewhat similar approaches, with various neural architectures (Wang et al., 2015; Huang et al., 2015). Dos Santos and Zadrozny (2014), on the other hand, argue that subword information is useful for certain NLP tasks, like POS tagging. They propose a character-based embedding along with the word embeddings, to be able to capture internal morphemic structures. Character embeddings, capturing subword features, are well studied in other contributions too (Labeau et al., 2015; Rei et al., 2016; Belinkov and Glass, 2015). Morphological disambiguation, however, has Definition Diacratization Lemma Basic part-of-speech tags (34 tags) Gender Number Case State Person Aspect Mood Voice Proclitic 0, article proclitic Proclitic 1, preposition proclitic Proclitic 2, conjunction proclitic Proclitic 3, question proclitic Enclitic Table 1: The morphological features we use in the various models. The first two groups are lexical features; and the last two groups are inflectional and clitic features respectively, in addition to the part-of-speech tag. Furthermore, MRLs have a tendency towards a h"
D17-1073,K17-1042,0,0.36325,"t analysis is bolded (4th from the bottom of the list). POS tagger, and compare it against SVM-based models. The SVM models in their system outperform the neural model, even with incorporating pre-trained embeddings. Heigold et al. (2016) developed character-based neural models for morphological tagging for 14 different languages, including Arabic, using the UD treebank. Most related to our work though is by Shen et al. (2016), who applied their Bi-LSTM morphological disambiguation model on MSA, but did not present any improvements over the state-of-the-art. Occurring in parallel to our work, Inoue et al. (2017) used multi-task learning to model finegrained POS tags, using the individual morphosyntactic features. They also use dictionary information concatenated to the word embeddings, similar to the approach we use in this paper, and use the same dataset. Our approach provides slightly higher accuracy scores for the individual features, but the joint features score in their system is higher. In this paper we study various architectures for neural based morphological tagging. We then use these architectures, along with neural language modeling systems, to train models for various Arabic morphological"
D17-1073,P08-2030,1,0.501607,"(2017) use Bi-LSTM models to train a 4 Approach The morphological disambiguation task involves choosing the correct morphological analysis from the set of potential analyses, obtained from the an706 alyzer. Towards that end, we train several models for the individual morphological features, and use their results to score and rank the different analyses and choose an optimal overall analysis. These features can be grouped into non-lexical features, where a tagger is used to obtain the relevant morphological tag, or morphological feature tagging, and lexical features that need a language model (Roth et al., 2008), or neural language models. Table 1 shows the set of morphological features we work with. The lexical features are handled with a language model, while the inflectional, clitic, and part-of-speech features are handled with a tagger. We use Bi-LSTM-based taggers for the morphological feature tagging tasks, with various embedding levels and morphological features. We investigate the different architectures and design options in detail in Section 5. We then use the best design to build 14 different taggers, each specific to an individual feature. We also use LSTM-based neural language models for"
D17-1073,D15-1152,1,0.548721,"Missing"
D17-1073,C16-2047,1,0.626969,"t of morphemic features. Then they train a model to predict the optimal analysis of a word given the annotations within a context window. Shen et al. (2016), on the other hand, use a character-based Bi-LSTM model for morphological disambiguation of morphologically complex languages, without using a morphological analyzer. The LSTM cells have the advantage of capturing a longer sequence window than those of the fixed window and CNN approaches. Arabic morphological analysis and disambiguation have seen a considerable amount of work, spanning both MSA (Habash and Rambow, 2005; Diab et al., 2004; Khalifa et al., 2016; Abdelali et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). The current state-of-the-art system is MADAMIRA (Pasha et al., 2014); which uses SVMs to disambiguate among a target word’s various morphological analyses provided by a morphological dictionary. Neural-based contributions for Arabic, however, are also relatively scarce. Among the contributions that utilize morphological structures to enhance the neural models in different NLP tasks, we note Guzmán et al. (2016) for machine translation, and Abandah et al. (2015) for diacrit"
D17-1073,C16-1018,0,0.144841,"matahA ‘its value’ has a specific analysis in the context of the sentence shown at the top of the AîDÒJ table; but it has many other analyses and diacritizations out of context. The correct analysis is bolded (4th from the bottom of the list). POS tagger, and compare it against SVM-based models. The SVM models in their system outperform the neural model, even with incorporating pre-trained embeddings. Heigold et al. (2016) developed character-based neural models for morphological tagging for 14 different languages, including Arabic, using the UD treebank. Most related to our work though is by Shen et al. (2016), who applied their Bi-LSTM morphological disambiguation model on MSA, but did not present any improvements over the state-of-the-art. Occurring in parallel to our work, Inoue et al. (2017) used multi-task learning to model finegrained POS tags, using the individual morphosyntactic features. They also use dictionary information concatenated to the word embeddings, similar to the approach we use in this paper, and use the same dataset. Our approach provides slightly higher accuracy scores for the individual features, but the joint features score in their system is higher. In this paper we study"
D17-1073,D15-1025,0,0.0271403,"Missing"
D18-1097,habash-etal-2012-conventional,1,0.906858,"Missing"
D18-1097,W16-3918,0,0.0180387,"models subword information. This provides the neural model with access to more linguistic information especially suitable for text normalization, without large parallel corpora. We show that providing the model with word-level features bridges the gap for the neural network approach to achieve a state-of-the-art F1 score on a standard Arabic language correction shared task dataset. 1 2 Related Work The encoder-decoder neural architecture (Sutskever et al., 2014; Cho et al., 2014) has shown promising results in text normalization tasks, particularly in character-level models (Xie et al., 2016; Ikeda et al., 2016). More recently, augmenting this neural architecture with the attention mechanism (Bahdanau et al., 2014; Luong et al., 2015) has dramatically increased the quality of results across most NLP tasks. However, in text normalization, state-of-the-art results involving attention (e.g., Xie et al. 2016) also rely on several other models during inference, such as language models and classifiers to filter suggested edits. Neural architectures at the word level inherently rely on multiple models to align and separately handle out-of-vocabulary (OOV) words (Yuan and Briscoe, 2016). In the context of Ar"
D18-1097,D15-1274,0,0.0399899,"2016) also rely on several other models during inference, such as language models and classifiers to filter suggested edits. Neural architectures at the word level inherently rely on multiple models to align and separately handle out-of-vocabulary (OOV) words (Yuan and Briscoe, 2016). In the context of Arabic, we are only aware of one attempt to use a neural model for end-to-end text normalization (Ahmadi, 2017), but it fails to beat all baselines reported later in this paper. Arabic diacritization, which can be considered forms of text normalization, has received a number of neural efforts (Belinkov and Glass, 2015; Abandah et al., 2015). However, state-of-the-art approaches for end-to-end text normalization rely on several additional models and rule-based approaches as hybrid models (Pasha et al., 2014; Rozovskaya et al., 2014; Nawar, 2015; Zalmout and Habash, 2017), which introduce direct human knowledge into the system, but are limited to correcting specific mistakes and rely on expert knowledge to be developed. Introduction Text normalization systems have many potential applications – from assisting native speakers and language learners with their writing, to supporting NLP applications with sparsit"
D18-1097,D15-1166,0,0.219286,"Missing"
D18-1097,W14-3605,1,0.879091,"being fed to the encoder-decoder model, where wj is the dwe dimensional word embedding for the word in which ci appears in. This effectively handles almost all cases except white spaces, in which we just always append a dwe -dimensional vector w_ initialized with a random uniform distribution of mean 0 and variance 1. For OOVs, we just append the whitespace embedding w_ to the word’s characters. 3.3 P 77.08 77.47 64.38 73.55 4.1 Evaluation Data We tested the proposed approach on the QALB dataset, a corpus for Arabic language correction and subject of two shared tasks (Zaghouani et al., 2014; Mohit et al., 2014; Rozovskaya et al., 2015). Following the guidelines of both shared tasks, we only used the training data of the QALB 2014 shared task corpus (19,411 sentences). Similarly, the validation dataset used is only that of the QALB 2014 shared task, consisting of 1,017 sentences. We use two blind tests, one from each year. During training, we only kept sentences of up to 400 characters in length, resulting in the loss of 172 sentences. 4.2 Metric Like in the QALB shared tasks, we use the MaxMatch scorer to compute the optimal word-level edits that map each source sentence to its respective corrected"
D18-1097,D14-1179,0,0.0232842,"Missing"
D18-1097,W15-3215,0,0.0959942,"ulary (OOV) words (Yuan and Briscoe, 2016). In the context of Arabic, we are only aware of one attempt to use a neural model for end-to-end text normalization (Ahmadi, 2017), but it fails to beat all baselines reported later in this paper. Arabic diacritization, which can be considered forms of text normalization, has received a number of neural efforts (Belinkov and Glass, 2015; Abandah et al., 2015). However, state-of-the-art approaches for end-to-end text normalization rely on several additional models and rule-based approaches as hybrid models (Pasha et al., 2014; Rozovskaya et al., 2014; Nawar, 2015; Zalmout and Habash, 2017), which introduce direct human knowledge into the system, but are limited to correcting specific mistakes and rely on expert knowledge to be developed. Introduction Text normalization systems have many potential applications – from assisting native speakers and language learners with their writing, to supporting NLP applications with sparsity reduction by cleaning large textual corpora. This can help improve benchmarks across many NLP tasks. In recent years, neural encoder-decoder models have shown promising results in language tasks like translation, part-of-speech"
D18-1097,D12-1052,0,0.0154405,"h character embedding. To learn these word representations, we use FastText (Bojanowski et al., 2016), which extends Word2Vec (Mikolov et al., 2013) by adding subword information to the word vector. This is very suitable for this task, not only because many mistakes occur at the character level, 838 wI w_ wrun wrun wrun cI c_ cr cu cn I r u Baseline MLE MADAMIRA MLE then MADAMIRA MADAMIRA then MLE R 41.56 32.10 38.42 44.61 F1 54.00 45.39 48.12 55.54 Table 1: Baselines scores on the QALB 2014 shared task development set. n and also helps avoid extreme running times for the NUS MaxMatch scorer (Dahlmeier and Ng, 2012), which we use for evaluation and comparison purposes. Figure 2: Illustration showing how the character embeddings are enriched with word-level features. 4 but also because FastText handles almost all OOVs by omitting the Word2Vec representation and simply using the subword-based representation. It is possible, yet extremely rare that FastText cannot handle a word– this can occur if the word contains an OOV n-gram or character that did not appear in the data used to train the embeddings. It should also be noted that these features are only fed to the encoder layer; the decoder layer only recei"
D18-1097,pasha-etal-2014-madamira,1,0.890919,"Missing"
D18-1097,P18-2089,1,0.734127,"0.74 79.81 – R 59.80 58.81 62.46 57.80 61.10 58.28 – F1 68.73 67.57 70.15 67.20 69.56 67.37 68.72 Model No word embeds Word2Vec FastText P 81.55 82.16 80.00 R 56.13 51.53 62.46 F1 66.49 63.33 70.15 Table 3: Ablation tests on the QALB 2014 shared task development dataset. All settings used no preprocessing and narrow word embeddings. Table 2: System scores on the QALB 2014 shared task development dataset for the different FastText embeddings. n-gram size, which was reduced from 3 to 2 to compensate for single-character prefixes and suffixes that appear in Arabic when omitting the short vowels (Erdmann et al., 2018). or kept as is, depending on the most common action in the training data. We found that, unlike Eskander et al. (2013) suggested, first using MADAMIRA and then MLE yields better results than composing these in the reverse order. The results are presented in Table 1. 4.5 4.4 Results Development set results are shown in Tables 2 and 3, test set results in Table 4. In all models, training without preprocessing consistently yielded better results than their analogues with the inputs pre-fed to MADAMIRA and then MLE. All the FastText embeddings setups with no preprocessing outperformed the previou"
D18-1097,N18-1202,0,0.0557573,"t, ordered by F1 score. on domain-specific knowledge to develop. Future directions include expanding the number of training pairs via synthetic data generation, where generative models can potentially add human-like errors to a large, unannotated corpus. Different sequence-to-sequence architectures, such as the Transformer module (Vaswani et al., 2017), could also be explored and researched more exhaustively. The word-level features provided by FastText could also be replaced by separately trained neural approaches that generate word embeddings from a word’s characters (e.g., ELMo embeddings, Peters et al. 2018), and could also be fine-tuned towards specific applications. Another interesting direction includes hybrid word-character architectures, where the encoder receives word-level features, while the decoder operates at the character level. We are also interested in applying our approach to other languages and dialects. Conclusion and Future Work We propose a novel approach to text normalization by enhancing character embeddings with word-level features that model subword information and model syntactic phenomena. This significantly improves the neural model’s recall, allowing the correction of mo"
D18-1097,N13-1066,1,0.803029,"Word2Vec FastText P 81.55 82.16 80.00 R 56.13 51.53 62.46 F1 66.49 63.33 70.15 Table 3: Ablation tests on the QALB 2014 shared task development dataset. All settings used no preprocessing and narrow word embeddings. Table 2: System scores on the QALB 2014 shared task development dataset for the different FastText embeddings. n-gram size, which was reduced from 3 to 2 to compensate for single-character prefixes and suffixes that appear in Arabic when omitting the short vowels (Erdmann et al., 2018). or kept as is, depending on the most common action in the training data. We found that, unlike Eskander et al. (2013) suggested, first using MADAMIRA and then MLE yields better results than composing these in the reverse order. The results are presented in Table 1. 4.5 4.4 Results Development set results are shown in Tables 2 and 3, test set results in Table 4. In all models, training without preprocessing consistently yielded better results than their analogues with the inputs pre-fed to MADAMIRA and then MLE. All the FastText embeddings setups with no preprocessing outperformed the previous state-of-the-art results in the development dataset. We hypothesize that this is occurs because the model has access"
D18-1097,W15-3204,1,0.873169,"coder-decoder model, where wj is the dwe dimensional word embedding for the word in which ci appears in. This effectively handles almost all cases except white spaces, in which we just always append a dwe -dimensional vector w_ initialized with a random uniform distribution of mean 0 and variance 1. For OOVs, we just append the whitespace embedding w_ to the word’s characters. 3.3 P 77.08 77.47 64.38 73.55 4.1 Evaluation Data We tested the proposed approach on the QALB dataset, a corpus for Arabic language correction and subject of two shared tasks (Zaghouani et al., 2014; Mohit et al., 2014; Rozovskaya et al., 2015). Following the guidelines of both shared tasks, we only used the training data of the QALB 2014 shared task corpus (19,411 sentences). Similarly, the validation dataset used is only that of the QALB 2014 shared task, consisting of 1,017 sentences. We use two blind tests, one from each year. During training, we only kept sentences of up to 400 characters in length, resulting in the loss of 172 sentences. 4.2 Metric Like in the QALB shared tasks, we use the MaxMatch scorer to compute the optimal word-level edits that map each source sentence to its respective corrected sentence. We report the F"
D18-1097,W14-3622,1,0.905315,"Missing"
D18-1097,D17-1073,1,0.643942,"ords (Yuan and Briscoe, 2016). In the context of Arabic, we are only aware of one attempt to use a neural model for end-to-end text normalization (Ahmadi, 2017), but it fails to beat all baselines reported later in this paper. Arabic diacritization, which can be considered forms of text normalization, has received a number of neural efforts (Belinkov and Glass, 2015; Abandah et al., 2015). However, state-of-the-art approaches for end-to-end text normalization rely on several additional models and rule-based approaches as hybrid models (Pasha et al., 2014; Rozovskaya et al., 2014; Nawar, 2015; Zalmout and Habash, 2017), which introduce direct human knowledge into the system, but are limited to correcting specific mistakes and rely on expert knowledge to be developed. Introduction Text normalization systems have many potential applications – from assisting native speakers and language learners with their writing, to supporting NLP applications with sparsity reduction by cleaning large textual corpora. This can help improve benchmarks across many NLP tasks. In recent years, neural encoder-decoder models have shown promising results in language tasks like translation, part-of-speech tagging, and text normaliza"
D18-1097,N16-1042,0,0.0263756,"models (Xie et al., 2016; Ikeda et al., 2016). More recently, augmenting this neural architecture with the attention mechanism (Bahdanau et al., 2014; Luong et al., 2015) has dramatically increased the quality of results across most NLP tasks. However, in text normalization, state-of-the-art results involving attention (e.g., Xie et al. 2016) also rely on several other models during inference, such as language models and classifiers to filter suggested edits. Neural architectures at the word level inherently rely on multiple models to align and separately handle out-of-vocabulary (OOV) words (Yuan and Briscoe, 2016). In the context of Arabic, we are only aware of one attempt to use a neural model for end-to-end text normalization (Ahmadi, 2017), but it fails to beat all baselines reported later in this paper. Arabic diacritization, which can be considered forms of text normalization, has received a number of neural efforts (Belinkov and Glass, 2015; Abandah et al., 2015). However, state-of-the-art approaches for end-to-end text normalization rely on several additional models and rule-based approaches as hybrid models (Pasha et al., 2014; Rozovskaya et al., 2014; Nawar, 2015; Zalmout and Habash, 2017), wh"
D18-1097,zaghouani-etal-2014-large,1,0.897442,"ated recurrent unit (GRU) layers (Cho et al., 2014), making only the first layer bidirectional following Wu et al. (2016). Like long short-term memory (Hochreiter and Schmidhuber, 1997), GRU layers are well-known to improve the performance of recurrent neural networks (RNN), but are slightly more computationally efficient than the former. For the decoder, we use two GRU layers along with the attention mechanism proposed by Luong et al. (2015) over the encoder outputs hi . The initial states for the decoder layers are learned with a fully-connected tanh layer in a similar fashion to Cho et al. (2014), but we do so from the first encoder output. During training, we use scheduled sampling (Bengio et al., 2015) and feed the dce -dimensional character embeddings at every time step, but using a constant sampling probability. While tuning scheduled sampling, we found that introducing a sampling probability provided better results than relying on the ground truth, i.e., teacher forcing (Williams and Zipser, 1989). However, introducing a schedule did not yield any improvement as opposed to keeping the sampling probability constant and unnecessarily complicates hyperparameter search. For both the"
D18-1097,N18-1087,1,0.666461,"are shown in Tables 2 and 3, test set results in Table 4. In all models, training without preprocessing consistently yielded better results than their analogues with the inputs pre-fed to MADAMIRA and then MLE. All the FastText embeddings setups with no preprocessing outperformed the previous state-of-the-art results in the development dataset. We hypothesize that this is occurs because the model has access to more examples of errors to normalize during training, thereby increasing performance. The best performing model was that with the narrow word embeddings; consistent with the results of Zalmout et al. (2018) showing the superior performance of narrow word embeddings over both wide embeddings and the concatenation of both. This is justified by Goldberg (2015) and Trask et al. (2015), who illustrate that wider word embeddings tend to capture more semantic information, while narrower word embeddings model more syntactic phenomena. In our ablation study, we compared the performance of the narrow FastText embeddings against narrow Word2Vec embeddings trained over the same Arabic Gigaword corpus with the same hyperparameters, as well as to no word-level embeddings at all. The results, displayed in Tabl"
diab-etal-2014-tharwa,C12-2029,1,\N,Missing
diab-etal-2014-tharwa,W11-2602,1,\N,Missing
diab-etal-2014-tharwa,2009.mtsummit-caasl.5,1,\N,Missing
diab-etal-2014-tharwa,P02-1040,0,\N,Missing
diab-etal-2014-tharwa,P11-2062,1,\N,Missing
diab-etal-2014-tharwa,N13-1036,1,\N,Missing
diab-etal-2014-tharwa,habash-etal-2012-conventional,1,\N,Missing
diab-etal-2014-tharwa,pasha-etal-2014-madamira,1,\N,Missing
diab-etal-2014-tharwa,P13-2081,1,\N,Missing
diab-etal-2014-tharwa,maamouri-etal-2006-developing,1,\N,Missing
diab-etal-2014-tharwa,W12-2301,1,\N,Missing
diab-etal-2014-tharwa,P00-1056,0,\N,Missing
dorr-etal-1998-thematic,W98-1426,0,\N,Missing
dorr-etal-1998-thematic,A97-1021,1,\N,Missing
dorr-etal-1998-thematic,P95-1034,0,\N,Missing
dorr-etal-1998-thematic,P98-1116,0,\N,Missing
dorr-etal-1998-thematic,C98-1112,0,\N,Missing
dorr-etal-2002-duster,han-etal-2000-handling,0,\N,Missing
dorr-etal-2002-duster,melamed-1998-empirical,0,\N,Missing
dorr-etal-2002-duster,A00-1009,0,\N,Missing
dorr-etal-2002-duster,J93-2003,0,\N,Missing
dorr-etal-2002-duster,W01-1406,0,\N,Missing
dorr-etal-2002-duster,2001.mtsummit-ebmt.4,0,\N,Missing
dorr-etal-2002-duster,W01-1403,0,\N,Missing
dorr-etal-2002-duster,C00-1078,0,\N,Missing
dorr-etal-2002-duster,C00-2131,0,\N,Missing
dorr-etal-2002-duster,W00-1306,1,\N,Missing
dorr-etal-2002-duster,N01-1026,0,\N,Missing
dorr-etal-2002-duster,J90-2002,0,\N,Missing
dorr-etal-2002-duster,P97-1062,0,\N,Missing
dorr-etal-2002-duster,P01-1067,0,\N,Missing
dorr-etal-2002-duster,P02-1050,1,\N,Missing
dorr-etal-2002-duster,J97-3002,0,\N,Missing
dorr-etal-2002-duster,P00-1056,0,\N,Missing
dukes-habash-2010-morphological,P05-1071,1,\N,Missing
dukes-habash-2010-morphological,P08-2030,1,\N,Missing
dukes-habash-2010-morphological,P09-2056,1,\N,Missing
dukes-habash-2010-morphological,dukes-etal-2010-syntactic,1,\N,Missing
E06-1047,N04-4038,1,0.632821,"biguous in MSA. For example, the LA words  mn ‘from’ and  myn ‘who’ both are translated into an orthographically ambiguous form in MSA  mn ‘from’ or ‘who’. 5.1 Implementation Each word in the LA sentence is translated into a bag of MSA words, producing a sausage lattice. The lattice is scored and decoded using the SRILM toolkit with a trigram language model trained on 54 million MSA words from Arabic Gigaword (Graff, 2003). The text used for language modeling was tokenized to match the tokenization of the Arabic used in the ATB and LATB. The tokenization was done using the ASVM Toolkit (Diab et al., 2004). The 1-best path in the lattice is passed on to the Bikel parser (Bikel, 2002), which was trained on the MSA training ATB. Finally, the terminal nodes in the resulting parse structure are replaced with the original LA words. 5.2 Experimental Results Table 1 describes the results of the sentence transduction path on the development corpus (DEV) in different settings: using no POS tags in the input versus using gold POS tags in the input, and using SLXUN versus BLXUN. The baseline results are obtained by parsing the LA sentence directly using the MSA parser (with and without gold POS tags). The"
E06-1047,A00-1002,0,0.0265605,"ency trees for the MSA and LA sentences (not shown here for space considerations) are isomorphic. They differ only in the node labels. 5 Sentence Transduction In this approach, we parse an MSA translation of the LA sentence and then link the LA sentence to the MSA parse. Machine translation (MT) is not easy, especially when there are no MT resources available such as naturally occurring parallel text or transfer lexicons. However, for this task we have three encouraging insights. First, for really close languages it is possible to obtain better translation quality by means of simpler methods (Hajic et al., 2000). Second, suboptimal MSA output can still be helpful for the parsing task without necessarily being fluent or accurate (since our goal is parsing LA, not translating it to MSA). And finally, translation from LA to MSA is easier than from MSA to LA. This is a result of the availability of abundant resources for MSA as compared to LA: for example, text corpora and tree banks for 4 Levantine also has other negation markers that precede the verb, as well as the circumfi x m- -$. language modeling and a morphological generation system (Habash, 2004). One disadvantage of this approach is the lack of"
E06-1047,maamouri-etal-2006-developing,1,0.666828,"Missing"
E06-1047,J01-1004,1,0.72461,"can be thought of as a variant of the treebank-transduction approach in which the syntactic transformations are localized to elementary trees. Moreover, because a parsed MSA translation is produced as a byproduct, we can also think of this approach as being related to the sentence-transduction approach. 7.1 Preliminaries The parsing model used is essentially that of Chiang (Chiang, 2000), which is based on a highly restricted version of tree-adjoining grammar. In its present form, the formalism is tree-substitution grammar (Schabes, 1990) with an additional operation called sister-adjunction (Rambow et al., 2001). Because of space constraints, we omit discussion of the sister-adjunction operation in this paper. A tree-substitution grammar is a set of elementary trees. A frontier node labeled with a nonterminal label is called a substitution site. If an elementary tree has exactly one terminal symbol, that symbol is called its lexical anchor. A derivation starts with an elementary tree and proceeds by a series of composition operations. In the substitution operation, a substitution site is rewritten with an elementary tree with a matching root label. The final product is a tree with no more substitutio"
E06-1047,P00-1008,0,0.0658914,"Missing"
E06-1047,W04-3207,0,0.0165264,"LA and MSA (Section 4). We then proceed to discuss three approaches: sentence transduction, in which the LA sentence to be parsed is turned into an MSA sentence and then parsed with an MSA parser (Section 5); treebank transduction, in which the MSA treebank is turned into an LA treebank (Section 6); and grammar transduction, in which an MSA grammar is turned into an LA grammar which is then used for parsing LA (Section 7). We summarize and discuss the results in Section 8. 2 Related Work There has been a fair amount of interest in parsing one language using another language, see for example (Smith and Smith, 2004; Hwa et al., 2004) for recent work. Much of this work uses synchronized formalisms as do we in the grammar transduction approach. However, these approaches rely on parallel corpora. For MSA and its dialects, there are no naturally occurring parallel corpora. It is this fact that has led us to investigate the use of explicit linguistic knowledge to complement machine learning. We refer to additional relevant work in the appropriate sections. aries. The resulting development data comprises 1928 sentences and 11151 tokens (DEV). The test data comprises 2051 sentences and 10,644 tokens (TEST). Fo"
E06-1047,W00-1307,0,0.0120082,"stic synchronous TSG, using a straightforward generalization of the CKY and Viterbi algorithms, we obtain the highestprobability paired derivation which includes a parse for S on one side, and a parsed translation of S on the other side. It is also straightforward to calculate inside and outside probabilities for reestimation by Expectation-Maximization (EM). 7.2 An MSA-dialect synchronous grammar We now describe how we build our MSA-dialect synchronous grammar. As mentioned above, the MSA side of the grammar is extracted from the ATB in a process described by Chiang and others (Chiang, 2000; Xia et al., 2000; Chen, 2001). This process also gives us MSA-only substitution probabilities P (α |η). We then apply various transformation rules (described below) to the MSA elementary trees to produce a dialect grammar, at the same time assigning probabilities P (α0 |α). The synchronoussubstitution probabilities can then be estimated as: P (α, α0 |η, η 0 ) ≈ P (α |η)P (α0 |α) ≈ P (α |η)P (w 0 , t0 |w, t) P (¯ α0 |α ¯ , w0 , t0 , w, t) where w and t are the lexical anchor of α and its POS tag, and α ¯ is the equivalence class of α modulo lexical anchors and their POS tags. P (w0 , t0 |w, t) is assigned as d"
E06-1047,P00-1058,1,0.647244,"andwritten rules into dialect elementary trees to yield an MSAdialect synchronous grammar. This synchronous grammar can be used to parse new dialect sentences using statistics gathered from the MSA data. Thus this approach can be thought of as a variant of the treebank-transduction approach in which the syntactic transformations are localized to elementary trees. Moreover, because a parsed MSA translation is produced as a byproduct, we can also think of this approach as being related to the sentence-transduction approach. 7.1 Preliminaries The parsing model used is essentially that of Chiang (Chiang, 2000), which is based on a highly restricted version of tree-adjoining grammar. In its present form, the formalism is tree-substitution grammar (Schabes, 1990) with an additional operation called sister-adjunction (Rambow et al., 2001). Because of space constraints, we omit discussion of the sister-adjunction operation in this paper. A tree-substitution grammar is a set of elementary trees. A frontier node labeled with a nonterminal label is called a substitution site. If an elementary tree has exactly one terminal symbol, that symbol is called its lexical anchor. A derivation starts with an elemen"
E06-1047,W97-0119,0,\N,Missing
E06-1047,H05-1107,0,\N,Missing
E06-1047,J03-3002,0,\N,Missing
E06-1047,W02-2026,0,\N,Missing
E06-1047,N01-1020,0,\N,Missing
E06-1047,J90-2002,0,\N,Missing
E06-1047,P99-1067,0,\N,Missing
E06-1047,P95-1032,0,\N,Missing
E06-1047,W01-0713,0,\N,Missing
E06-1047,J00-2004,0,\N,Missing
E06-1047,N04-1034,0,\N,Missing
E12-1069,P11-2062,1,0.767144,"ong  h (F S), others: QëAÓ mAhr (M S), èQëAÓ mAhr¯ 1 Arabic transliteration is presented in the Habash-SoudiBuckwalter (HSB) scheme (Habash et al., 2007): (in alphaˇ betical order) AbtθjHxdðrzsšSDTDςγfqklmnhwy and the ad ˇ ¯ ditional symbols: ’ Z, Â @, A @ , A @, wˆ ð', yˆ Zø', ¯h è, ý ø. àðQëAÓ  QëAÓ mAhrAt mAhrwn (M P ), and H@ (F P ). For a sizable minority of words, these features are expressed templatically, i.e., through pattern change, coupled with some singular suffix. A typical example of this phenomenon is the class of broken plurals, which accounts for over half of all plurals (Alkuhlani and Habash, 2011). In such cases, the form of the morphology (singular suffix) is inconsistent with the word’s functional number (plural). For example, the word I.KA¿ kAtb (M S) ‘writer’ has the broken plural: H. AJ» ktAb ( MMPS ).2 See the second word in the ex ample in Figure 1, which is the word H . AJ» ktAb ‘writers’ prefixed with the definite article Al+. In addition to broken plurals, Arabic has words with irregular gender, e.g., the feminine singular adS jective ‘red’ Z@QÔg HmrA’ ( M F S ), and the nouns é®J Êg xlyf¯h ( MF SS ) ‘caliph’ and ÉÓAg HAml ( MF SS ) ‘pregnant’. Verbs and nominal duals d"
E12-1069,altantawy-etal-2010-morphological,1,0.872104,"Missing"
E12-1069,N04-4038,0,0.0897145,"uch work has been done on Arabic morphological analysis, morphological disambiguation and part-of-speech (POS) tagging (Al-Sughaiyer and Al-Kharashi, 2004; Soudi et al., 2007; Habash, 2010). The bulk of this work does not address form-function discrepancy or morpho-syntactic agreement issues. This includes the most commonly used resources and tools for Arabic NLP: the Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2004) which is used in the Penn Arabic Tree Bank (PATB) (Maamouri et al., 2004), and the various POS tagging and morphological disambiguation tools trained using them (Diab et al., 2004; Habash and Rambow, 2005). There are some important exceptions (Goweder et al., 2004; Habash, 2004; Smrž, 2007b; Elghamry et al., 2008; Abbès et al., 2004; Attia, 2008; 3 We previously defined the rationality value N as notapplicable when we only considered nominals (Alkuhlani and Habash, 2011). In this work, we rename the rationality value N as not-specified without changing its meaning. We use the value N a (not-applicable) for parts-of-speech that do not have a meaningful value for any feature, e.g., prepositions have gender, number and rationality values of N a. Altantawy et al., 2010; Al"
E12-1069,N10-1115,0,0.140238,"Missing"
E12-1069,W04-3232,0,0.151491,"Missing"
E12-1069,P05-1071,1,0.966661,"one on Arabic morphological analysis, morphological disambiguation and part-of-speech (POS) tagging (Al-Sughaiyer and Al-Kharashi, 2004; Soudi et al., 2007; Habash, 2010). The bulk of this work does not address form-function discrepancy or morpho-syntactic agreement issues. This includes the most commonly used resources and tools for Arabic NLP: the Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2004) which is used in the Penn Arabic Tree Bank (PATB) (Maamouri et al., 2004), and the various POS tagging and morphological disambiguation tools trained using them (Diab et al., 2004; Habash and Rambow, 2005). There are some important exceptions (Goweder et al., 2004; Habash, 2004; Smrž, 2007b; Elghamry et al., 2008; Abbès et al., 2004; Attia, 2008; 3 We previously defined the rationality value N as notapplicable when we only considered nominals (Alkuhlani and Habash, 2011). In this work, we rename the rationality value N as not-specified without changing its meaning. We use the value N a (not-applicable) for parts-of-speech that do not have a meaningful value for any feature, e.g., prepositions have gender, number and rationality values of N a. Altantawy et al., 2010; Alkuhlani and Habash, 2011)."
E12-1069,P09-2056,1,0.907001,"JK YmÌ '@ àñ OBJ NOM ©ÒJj.ÖÏ@ MOD NOM MOD NOM  ú G. QªË@ Õç' Y®Ë@ Word ystlhm AlktAb AlHdyθwn qSSA jdyd¯ h mn Almjtmς Alςrby Alqdym Form MS MS MP MS FS NaNa MS MS MS Func MSN MPR MPN FPI FSN NaNaNa MSI MSN MSN Gloss be-inspired the-writers the-modern stories new from culture Arab ancient English ‘Modern writers are inspired by ancient Arab culture to write new stories .’ Figure 1: An example Arabic sentence showing its dependency representation together with the form-based and functional gender and number features and rationality. The dependency tree is in the CATiB treebank representation (Habash and Roth, 2009). The shown POS tags are VRB “verb”, NOM “nominal (noun/adjective)”, and PRT “particle”. The relations are SBJ “subject”, OBJ “object” and MOD “modifier”. The form-based features are only for gender and number. 2 Linguistic Facts Arabic has a rich and complex morphology. In addition to being both templatic (root/pattern) and concatenative (stems/affixes/clitics), Arabic’s optional diacritics add to the degree of word ambiguity. We focus on two problems of Arabic morphology: the discrepancy between morphological form and function; and the complexity of morphosyntactic agreement rules. 2.1 Form"
E12-1069,P03-1004,0,0.0262372,"aining set, the system backs off to a more general combination of features. For example, if an MLE system is using the features W2+LMM+BW, the system tries to match this combination. If it is not seen in training, the system backs off to the following set: LMM+BW, and tries to return the most common value for this POS tag and lemma combination. If again it fails to find a match, it backs off to BW, and returns the most common value for that particular POS tag. If no word is seen with this POS tag, the system returns the most common value across all words. Yamcha Sequence Tagger We use Yamcha (Kudo and Matsumoto, 2003), a support-vectormachine-based sequence tagger. We perform different experiments with the different sets of features presented above. After that, we apply a consistency filter that ensures that every wordlemma-pos combination always gets the same value for gender, number and rationality features. Yamcha in its default settings tags words using a window of two words before and two words after the word being tagged. This gives Yamcha an advantage over the MLE system which tags each word independently. Single vs Joint Classification In this paper, we only discuss systems trained for a single cla"
E12-1069,W10-1402,1,0.904154,"functional gender, number and rationality features. The learning features are explored in the following order: Orthographic Features These features are organized in two sets: W1 is the unnormalized form of the word, and W2 includes W1 plus letter ngrams. The n-grams used are the first letter, first two letters, last letter, and last two letters of the word form. We tried using the Alif/Ya normalized forms of the words (Habash, 2010), but these behaved consistently worse than the unnormalized forms. Morphological Features We explore the following morphological features inspired by the work of Marton et al. (2010): • POS tags. We experiment with different POS tag sets: CATiB-6 (6 tags) (Habash et al., 2009), CATiB-EX (44 tags), Kulick (34 tags) (Kulick et al., 2006), Buckwalter (BW) (Buckwalter, 2004), which is the tag used in the PATB (430 tags), and a reduced form of BW tag that ignores case and mood (BW-) (217 tags). These tags differ in their granularity and range from very specific tags (Buckwalter) to more general tags (CATiB). • Lemma. We use the diacritized lemma (Lemma), and the normalized and undiacritized form of the lemma, the LMM (LMM). • Form-based features. Form-based features (F) are ex"
E12-1069,P11-1159,1,0.860636,"Missing"
E12-1069,W07-0801,0,0.0163356,"(Al-Sughaiyer and Al-Kharashi, 2004; Soudi et al., 2007; Habash, 2010). The bulk of this work does not address form-function discrepancy or morpho-syntactic agreement issues. This includes the most commonly used resources and tools for Arabic NLP: the Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2004) which is used in the Penn Arabic Tree Bank (PATB) (Maamouri et al., 2004), and the various POS tagging and morphological disambiguation tools trained using them (Diab et al., 2004; Habash and Rambow, 2005). There are some important exceptions (Goweder et al., 2004; Habash, 2004; Smrž, 2007b; Elghamry et al., 2008; Abbès et al., 2004; Attia, 2008; 3 We previously defined the rationality value N as notapplicable when we only considered nominals (Alkuhlani and Habash, 2011). In this work, we rename the rationality value N as not-specified without changing its meaning. We use the value N a (not-applicable) for parts-of-speech that do not have a meaningful value for any feature, e.g., prepositions have gender, number and rationality values of N a. Altantawy et al., 2010; Alkuhlani and Habash, 2011). In terms of resources, Smrž (2007b)’s work contrasting illusory (form) features and"
E12-1069,W04-1604,0,\N,Missing
E12-1069,J13-1008,1,\N,Missing
E17-2038,2011.mtsummit-papers.55,0,0.0501892,"el evaluation datasets, which are not common. In some cases, researchers translated commonly used test sets to other languages to enrich the parallelism of the data, e.g., (Cettolo et al., 2011), while working on Arabic-Italian MT, translated a NIST MT eval dataset (Arabic to four English references) to French and Italian. For Arabic MT, the past 10 years have witnessed a lot of interest in translating from Arabic to English mostly due to large DARPA programs such as GALE and BOLT (Olive et al., 2011). There have been some limited efforts in comparison on translating into Arabic from English (Hamon and Choukri, 2011; Al-Haj and Lavie, 2012; El Kholy and Habash, 2012), but also between Arabic and other languages (Boudabous et al., 2013; Habash and Hu, 2009; Shilon et al., 2012; Cettolo et al., 2011). The JRC-Acquis collection, of which we translate a portion, is publicly available for research purposes and already exists in 22 languages (and others ongoing). As such, the Arab-Acquis dataset will open a pathway for researchers to work on MT from a large number of languages into Arabic and vice versa, covering pairs that have not been researched before. The dataset enables us to compare translation quality"
E17-2038,D08-1078,0,0.0583644,"Missing"
E17-2038,2009.mtsummit-papers.8,0,0.0235921,"679 5.1 JRC-Acquis MT Systems We built 21 MT systems for translating from English to X and 21 MT systems for translating from X to English, for X being all of the JRC-Acquis languages, other than English. We built these MT systems using the full JRC-Acquis corpus following the same data splits for training, tuning, and development used by Koehn et al. (2009), who reported their work on developing 462 machine translation systems based on the 22 languages of the JRC-Acquis corpus. Their paper included both direct and pivoting-based systems on multiple languages. We replicated the MT systems in (Koehn and Haddow, 2009), in an effort to pivot from/to Arabic through English. We present the MT results for the European languages with English in Table 2. Our results almost match those at (Koehn et al., 2009). Any minor differences in the scores are mainly attributed to the various upgrades in the toolkits used and tuning variations. We used the Moses toolkit (Koehn et al., 2007) with default parameters to develop the systems, Arab-Acquis Dataset In Table 1, we present the final dataset sizes for Arab-Acquis and the respective dataset sizes from the JRC-Acquis English and French portions used to translate it. In"
E17-2038,P07-2045,1,0.0101647,"reported their work on developing 462 machine translation systems based on the 22 languages of the JRC-Acquis corpus. Their paper included both direct and pivoting-based systems on multiple languages. We replicated the MT systems in (Koehn and Haddow, 2009), in an effort to pivot from/to Arabic through English. We present the MT results for the European languages with English in Table 2. Our results almost match those at (Koehn et al., 2009). Any minor differences in the scores are mainly attributed to the various upgrades in the toolkits used and tuning variations. We used the Moses toolkit (Koehn et al., 2007) with default parameters to develop the systems, Arab-Acquis Dataset In Table 1, we present the final dataset sizes for Arab-Acquis and the respective dataset sizes from the JRC-Acquis English and French portions used to translate it. In total, we created 687,344 translated words. 4 Machine Translation Results In this section we present the first results ever reported on benchmarking MT between Arabic and 22 European languages in both directions using the same datasets and conditions. Table 1: Arab-Acquis data set sizes, and the sizes of the corresponding sentences (4,108 sentences for Dev, 4,"
E17-2038,2011.eamt-1.34,0,0.0252348,"o translate from one language to another (Papineni et al., 2002). The number of language pairs that are fortunate to have large parallel data is limited. Researchers have explored ways to exploit existing resources by pivoting or bridging on a third language (Utiyama and Isahara, 2007; Habash and Hu, 2009; El Kholy et al., 2013). These techniques have shown promise but can obviously only be pursued for languages with parallel evaluation datasets, which are not common. In some cases, researchers translated commonly used test sets to other languages to enrich the parallelism of the data, e.g., (Cettolo et al., 2011), while working on Arabic-Italian MT, translated a NIST MT eval dataset (Arabic to four English references) to French and Italian. For Arabic MT, the past 10 years have witnessed a lot of interest in translating from Arabic to English mostly due to large DARPA programs such as GALE and BOLT (Olive et al., 2011). There have been some limited efforts in comparison on translating into Arabic from English (Hamon and Choukri, 2011; Al-Haj and Lavie, 2012; El Kholy and Habash, 2012), but also between Arabic and other languages (Boudabous et al., 2013; Habash and Hu, 2009; Shilon et al., 2012; Cettol"
E17-2038,2009.mtsummit-papers.7,0,0.361133,"luating Machine Translation between Arabic and European Languages Nizar Habash, Nasser Zalmout, Dima Taji, Hieu Hoang and Maverick Alzate Computational Approaches to Modeling Language Lab New York University Abu Dhabi, UAE {nizar.habash,nasser.zalmout,dima.taji,hh65,ma2835}@nyu.edu Abstract showcases the effort to create a dataset, which we dub Arab-Acquis, to support the development and evaluation of machine translation systems from Arabic to the languages of the European Union and vice versa. Our approach is simply to exploit the existence of the JRC-Acquis corpus (Steinberger et al., 2006; Koehn et al., 2009), which has 22 languages in parallel, and translate a portion of it to Standard Arabic. We include two translations in Arabic for each sentence in the set to support robust multi-reference evaluation metrics. This provides us with the largest (and first of its kind) set of multilingual translation for Standard Arabic to date. It allows us to evaluate the quality of translating into Arabic from a set of 22 languages, most of which have no large high quality datasets paired with Arabic. We present Arab-Acquis, a large publicly available dataset for evaluating machine translation between 22 Europ"
E17-2038,2005.mtsummit-papers.11,0,0.0743809,"research and MT evaluation resources are focused on translation from Arabic into English, with few additional resources pairing Arabic with a half dozen languages. This paper Related Work In the context of MT research in general, multilingual resources (or parallel corpora) are central. Some of these resources exist naturally such as the United Nations corpus (Arabic, Chinese, English, French, Russian and Spanish) (Rafalovitch et al., 2009), the Canadian Hansards (French and English) (Simard et al., 1993), the European Parliament proceedings, E URO PARL, (21 languages in its latest release) (Koehn, 2005), and the JRCAcquis (22 languages) (Steinberger et al., 2006; Koehn et al., 2009). Translations may also be commissioned to support MT research, as in the creation of an Arabic dialect to English translation corpus using crowdsourcing (Zbib et al., 2012). Such resources are necessary for the development of MT systems, and for the evaluation of MT systems in general. While training MT systems typically requires large collections in the order of millions of words, the automatic evaluation of MT requires less data; but evaluation data is expected to 1 The European Parliament has 24 official langu"
E17-2038,P13-2073,1,0.894443,"Missing"
E17-2038,P02-1040,0,0.103151,"expected to 1 The European Parliament has 24 official languages (European Parliament, 2016); however the corpus we used only contained 22, missing only Irish and Croatian (Steinberger et al., 2006; Koehn et al., 2009). 235 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 235–241, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics translations to maximize the parallelism. have more than one human reference since there are many ways to translate from one language to another (Papineni et al., 2002). The number of language pairs that are fortunate to have large parallel data is limited. Researchers have explored ways to exploit existing resources by pivoting or bridging on a third language (Utiyama and Isahara, 2007; Habash and Hu, 2009; El Kholy et al., 2013). These techniques have shown promise but can obviously only be pursued for languages with parallel evaluation datasets, which are not common. In some cases, researchers translated commonly used test sets to other languages to enrich the parallelism of the data, e.g., (Cettolo et al., 2011), while working on Arabic-Italian MT, trans"
E17-2038,W09-0431,1,0.891697,"h Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 235–241, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics translations to maximize the parallelism. have more than one human reference since there are many ways to translate from one language to another (Papineni et al., 2002). The number of language pairs that are fortunate to have large parallel data is limited. Researchers have explored ways to exploit existing resources by pivoting or bridging on a third language (Utiyama and Isahara, 2007; Habash and Hu, 2009; El Kholy et al., 2013). These techniques have shown promise but can obviously only be pursued for languages with parallel evaluation datasets, which are not common. In some cases, researchers translated commonly used test sets to other languages to enrich the parallelism of the data, e.g., (Cettolo et al., 2011), while working on Arabic-Italian MT, translated a NIST MT eval dataset (Arabic to four English references) to French and Italian. For Arabic MT, the past 10 years have witnessed a lot of interest in translating from Arabic to English mostly due to large DARPA programs such as GALE an"
E17-2038,pasha-etal-2014-madamira,1,0.860116,"Missing"
E17-2038,2009.mtsummit-posters.15,0,0.0643977,"Missing"
E17-2038,N07-1061,0,0.104176,"235 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 235–241, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics translations to maximize the parallelism. have more than one human reference since there are many ways to translate from one language to another (Papineni et al., 2002). The number of language pairs that are fortunate to have large parallel data is limited. Researchers have explored ways to exploit existing resources by pivoting or bridging on a third language (Utiyama and Isahara, 2007; Habash and Hu, 2009; El Kholy et al., 2013). These techniques have shown promise but can obviously only be pursued for languages with parallel evaluation datasets, which are not common. In some cases, researchers translated commonly used test sets to other languages to enrich the parallelism of the data, e.g., (Cettolo et al., 2011), while working on Arabic-Italian MT, translated a NIST MT eval dataset (Arabic to four English references) to French and Italian. For Arabic MT, the past 10 years have witnessed a lot of interest in translating from Arabic to English mostly due to large DARPA pro"
E17-2038,N12-1006,0,0.0276727,"urces (or parallel corpora) are central. Some of these resources exist naturally such as the United Nations corpus (Arabic, Chinese, English, French, Russian and Spanish) (Rafalovitch et al., 2009), the Canadian Hansards (French and English) (Simard et al., 1993), the European Parliament proceedings, E URO PARL, (21 languages in its latest release) (Koehn, 2005), and the JRCAcquis (22 languages) (Steinberger et al., 2006; Koehn et al., 2009). Translations may also be commissioned to support MT research, as in the creation of an Arabic dialect to English translation corpus using crowdsourcing (Zbib et al., 2012). Such resources are necessary for the development of MT systems, and for the evaluation of MT systems in general. While training MT systems typically requires large collections in the order of millions of words, the automatic evaluation of MT requires less data; but evaluation data is expected to 1 The European Parliament has 24 official languages (European Parliament, 2016); however the corpus we used only contained 22, missing only Irish and Croatian (Steinberger et al., 2006; Koehn et al., 2009). 235 Proceedings of the 15th Conference of the European Chapter of the Association for Computat"
F13-1029,P06-1086,1,0.854793,"Missing"
F13-1029,W05-0703,1,0.865443,"Missing"
F13-1029,J00-1006,0,0.0708705,"Missing"
F13-1029,W07-0801,0,0.0371678,"Missing"
farber-etal-2008-improving,N04-1043,0,\N,Missing
farber-etal-2008-improving,C02-1054,0,\N,Missing
farber-etal-2008-improving,W02-1001,0,\N,Missing
farber-etal-2008-improving,P05-1071,1,\N,Missing
farber-etal-2008-improving,W04-3234,1,\N,Missing
habash-2000-oxygen,W98-1426,0,\N,Missing
habash-2000-oxygen,W00-0207,1,\N,Missing
habash-2000-oxygen,P95-1034,0,\N,Missing
habash-2000-oxygen,P98-1116,0,\N,Missing
habash-2000-oxygen,C98-1112,0,\N,Missing
habash-2000-oxygen,dorr-etal-1998-thematic,1,\N,Missing
habash-dorr-2002-handling,W98-1426,0,\N,Missing
habash-dorr-2002-handling,han-etal-2000-handling,0,\N,Missing
habash-dorr-2002-handling,habash-2000-oxygen,1,\N,Missing
habash-dorr-2002-handling,A00-1009,0,\N,Missing
habash-dorr-2002-handling,W01-1403,0,\N,Missing
habash-dorr-2002-handling,W00-0207,1,\N,Missing
habash-dorr-2002-handling,C00-1007,0,\N,Missing
habash-dorr-2002-handling,C00-2131,0,\N,Missing
habash-dorr-2002-handling,P95-1034,0,\N,Missing
habash-dorr-2002-handling,1997.mtsummit-workshop.12,0,\N,Missing
habash-dorr-2002-handling,P98-1116,0,\N,Missing
habash-dorr-2002-handling,C98-1112,0,\N,Missing
habash-dorr-2002-handling,dorr-etal-2002-duster,1,\N,Missing
habash-etal-2006-design,N04-4038,0,\N,Missing
habash-etal-2006-design,J03-1002,0,\N,Missing
habash-etal-2006-design,W97-0801,0,\N,Missing
habash-etal-2012-conventional,I11-1036,1,\N,Missing
habash-etal-2012-conventional,P11-2007,0,\N,Missing
habash-etal-2012-conventional,N09-1045,1,\N,Missing
habash-etal-2012-conventional,elfardy-diab-2012-simplified,1,\N,Missing
habash-roth-2008-identification,C73-2031,0,\N,Missing
habash-roth-2008-identification,H01-1035,0,\N,Missing
habash-roth-2008-identification,N04-4038,0,\N,Missing
habash-roth-2008-identification,H05-1012,0,\N,Missing
habash-roth-2008-identification,X96-1047,0,\N,Missing
I13-1144,P10-2033,1,0.901021,"Missing"
I13-1144,P05-1033,0,0.160097,"Missing"
I13-1144,P13-1077,0,0.0576504,"Missing"
I13-1144,P05-1066,0,0.111759,"Missing"
I13-1144,P13-2073,1,0.899083,"Missing"
I13-1144,I13-1167,1,0.85267,"Missing"
I13-1144,W09-0809,1,0.929578,"Missing"
I13-1144,H05-1085,0,0.0202131,"ty. We address the orthographic challenge of inconsistent spacing with a supervised learning method which successfully recovers near all spacing errors. We also present a set of experiments for morphological segmentation to help improve Persian-to-English SMT. We show that the combination of orthographic cleanup and morphological segmentation for verbs in particular improves over a simple preprocessing baseline. Related Work Much work has been done to address data sparsity in SMT employing a variety of methods such as morphological and orthographic processing (Nießen and Ney, 2004; Lee, 2004; Goldwater and McClosky, 2005; Oflazer and Durgar El-Kahlout, 2007; Stymne, 2012; Singh and Habash, 2012; Habash and Sadat, 2012; El Kholy and Habash, 2012), targeting specific out-of-vocabulary phenomena with name transliteration or spelling expansion (Habash, 2008; Hermjakob et al., 2008) or using comparable corpora (Prochasson and Fung, 2011). Our approach falls in the class of orthographic and morphological preprocessing. Previous research on Persian SMT is rather limited despite some early efforts (Amtrup et al., 2000). A few parallel corpora have been released, such as (Pilevar et al., 2011; Farajian, 2011). We cond"
I13-1144,W12-5905,0,0.221008,"pora (Prochasson and Fung, 2011). Our approach falls in the class of orthographic and morphological preprocessing. Previous research on Persian SMT is rather limited despite some early efforts (Amtrup et al., 2000). A few parallel corpora have been released, such as (Pilevar et al., 2011; Farajian, 2011). We conduct our research on an unreleased PersianEnglish parallel corpus (El Kholy et al., 2013a; El Kholy et al., 2013b). In terms of preprocessing efforts, Kathol and Zheng (2008) use unsupervised Persian morpheme segmentation. Other attempts to improve Persian SMT use syntactic reordering (Gupta et al., 2012; Matusov and K¨opr¨u, 2010) and rule-based post editing (Mohaghegh et al., 2012). El Kholy et al. (2013a) and El Kholy et al. (2013b) also address resource limitation for Persian-Arabic SMT by pivoting on English. Our approach is similar to Kathol and Zheng (2008), except that we do not use unsupervised learning methods for segmenting morphemes and we explore POS-specific processing instead of segmenting all words. We make extensive use of available resources for Persian morphology such as the Persian dependency treebank (Rasooli et al., 2013), the Persian verb analyzer tool (Rasooli et al.,"
I13-1144,P08-2015,1,0.84792,"sh SMT. We show that the combination of orthographic cleanup and morphological segmentation for verbs in particular improves over a simple preprocessing baseline. Related Work Much work has been done to address data sparsity in SMT employing a variety of methods such as morphological and orthographic processing (Nießen and Ney, 2004; Lee, 2004; Goldwater and McClosky, 2005; Oflazer and Durgar El-Kahlout, 2007; Stymne, 2012; Singh and Habash, 2012; Habash and Sadat, 2012; El Kholy and Habash, 2012), targeting specific out-of-vocabulary phenomena with name transliteration or spelling expansion (Habash, 2008; Hermjakob et al., 2008) or using comparable corpora (Prochasson and Fung, 2011). Our approach falls in the class of orthographic and morphological preprocessing. Previous research on Persian SMT is rather limited despite some early efforts (Amtrup et al., 2000). A few parallel corpora have been released, such as (Pilevar et al., 2011; Farajian, 2011). We conduct our research on an unreleased PersianEnglish parallel corpus (El Kholy et al., 2013a; El Kholy et al., 2013b). In terms of preprocessing efforts, Kathol and Zheng (2008) use unsupervised Persian morpheme segmentation. Other attempts"
I13-1144,W11-2123,0,0.038576,"Missing"
I13-1144,P08-1045,0,0.0813802,"Missing"
I13-1144,P07-2045,0,0.00861315,"Missing"
I13-1144,W07-0734,0,0.0736058,"Missing"
I13-1144,N04-4015,0,0.0324765,"improves the translation quality of Persian-English by 1.9 BLEU points on a blind test set. 1 Introduction In the context of statistical machine translation (SMT), the severity of the data sparsity problem, typically a result of limited parallel data, increases for languages with rich morphology such as Arabic, Czech and Turkish. The most common solution, other than increasing the amount of parallel data, is to develop language-specific preprocessing and tokenization schemes that reduce the overall vocabulary and increase the symmetry between source and target languages (Nießen and Ney, 2004; Lee, 2004; Oflazer and Durgar El-Kahlout, 2007; Stymne, 2012; Singh and Habash, 2012; Habash and Sadat, 2012; El Kholy and Habash, 2012). In this paper, we work with Persian, a morphologically rich language with limited parallel data. Furthermore, Persian’s standard orthography makes use of a combination of spaces and semispaces (zero-width non-joiners), which are often ignored or confused, leading to orthographic inconstancies and added sparsity. We address the orthographic challenge of inconsistent spacing with a supervised learning method which successfully recovers near all spacing errors. We also"
I13-1144,2010.amta-papers.29,0,0.610636,"Missing"
I13-1144,C12-2085,0,0.131256,"aphic and morphological preprocessing. Previous research on Persian SMT is rather limited despite some early efforts (Amtrup et al., 2000). A few parallel corpora have been released, such as (Pilevar et al., 2011; Farajian, 2011). We conduct our research on an unreleased PersianEnglish parallel corpus (El Kholy et al., 2013a; El Kholy et al., 2013b). In terms of preprocessing efforts, Kathol and Zheng (2008) use unsupervised Persian morpheme segmentation. Other attempts to improve Persian SMT use syntactic reordering (Gupta et al., 2012; Matusov and K¨opr¨u, 2010) and rule-based post editing (Mohaghegh et al., 2012). El Kholy et al. (2013a) and El Kholy et al. (2013b) also address resource limitation for Persian-Arabic SMT by pivoting on English. Our approach is similar to Kathol and Zheng (2008), except that we do not use unsupervised learning methods for segmenting morphemes and we explore POS-specific processing instead of segmenting all words. We make extensive use of available resources for Persian morphology such as the Persian dependency treebank (Rasooli et al., 2013), the Persian verb analyzer tool (Rasooli et al., 2011a), the Persian verb valency lexicon (Rasooli et al., 2011c), and the PerStem"
I13-1144,J04-2003,0,0.0425997,"n verbs in particular improves the translation quality of Persian-English by 1.9 BLEU points on a blind test set. 1 Introduction In the context of statistical machine translation (SMT), the severity of the data sparsity problem, typically a result of limited parallel data, increases for languages with rich morphology such as Arabic, Czech and Turkish. The most common solution, other than increasing the amount of parallel data, is to develop language-specific preprocessing and tokenization schemes that reduce the overall vocabulary and increase the symmetry between source and target languages (Nießen and Ney, 2004; Lee, 2004; Oflazer and Durgar El-Kahlout, 2007; Stymne, 2012; Singh and Habash, 2012; Habash and Sadat, 2012; El Kholy and Habash, 2012). In this paper, we work with Persian, a morphologically rich language with limited parallel data. Furthermore, Persian’s standard orthography makes use of a combination of spaces and semispaces (zero-width non-joiners), which are often ignored or confused, leading to orthographic inconstancies and added sparsity. We address the orthographic challenge of inconsistent spacing with a supervised learning method which successfully recovers near all spacing error"
I13-1144,J03-1002,0,0.0101285,"Missing"
I13-1144,P02-1040,0,0.0882036,"Missing"
I13-1144,P11-1133,0,0.0246784,"rphological segmentation for verbs in particular improves over a simple preprocessing baseline. Related Work Much work has been done to address data sparsity in SMT employing a variety of methods such as morphological and orthographic processing (Nießen and Ney, 2004; Lee, 2004; Goldwater and McClosky, 2005; Oflazer and Durgar El-Kahlout, 2007; Stymne, 2012; Singh and Habash, 2012; Habash and Sadat, 2012; El Kholy and Habash, 2012), targeting specific out-of-vocabulary phenomena with name transliteration or spelling expansion (Habash, 2008; Hermjakob et al., 2008) or using comparable corpora (Prochasson and Fung, 2011). Our approach falls in the class of orthographic and morphological preprocessing. Previous research on Persian SMT is rather limited despite some early efforts (Amtrup et al., 2000). A few parallel corpora have been released, such as (Pilevar et al., 2011; Farajian, 2011). We conduct our research on an unreleased PersianEnglish parallel corpus (El Kholy et al., 2013a; El Kholy et al., 2013b). In terms of preprocessing efforts, Kathol and Zheng (2008) use unsupervised Persian morpheme segmentation. Other attempts to improve Persian SMT use syntactic reordering (Gupta et al., 2012; Matusov and"
I13-1144,N13-1031,1,0.862787,"Missing"
I13-1144,shamsfard-etal-2010-step,0,0.0712813,"Missing"
I13-1144,2012.eamt-1.8,1,0.841367,"U points on a blind test set. 1 Introduction In the context of statistical machine translation (SMT), the severity of the data sparsity problem, typically a result of limited parallel data, increases for languages with rich morphology such as Arabic, Czech and Turkish. The most common solution, other than increasing the amount of parallel data, is to develop language-specific preprocessing and tokenization schemes that reduce the overall vocabulary and increase the symmetry between source and target languages (Nießen and Ney, 2004; Lee, 2004; Oflazer and Durgar El-Kahlout, 2007; Stymne, 2012; Singh and Habash, 2012; Habash and Sadat, 2012; El Kholy and Habash, 2012). In this paper, we work with Persian, a morphologically rich language with limited parallel data. Furthermore, Persian’s standard orthography makes use of a combination of spaces and semispaces (zero-width non-joiners), which are often ignored or confused, leading to orthographic inconstancies and added sparsity. We address the orthographic challenge of inconsistent spacing with a supervised learning method which successfully recovers near all spacing errors. We also present a set of experiments for morphological segmentation to help improve"
I13-1144,2006.amta-papers.25,0,0.051887,"Missing"
I13-1144,W07-0704,0,\N,Missing
I13-1167,P08-2039,0,0.0175651,"i and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008; Shilon et al., 2010). Most of these efforts are focused on syntactic and morphological processing. There have been a growing number of publications that consider translation into Arabic. Sarikaya and Deng (2007) use joint morphological-lexical language models to re-rank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limited to few studies. For example, Kathol and Zheng (2008) use unsupervised morpheme segmentation for Persian. They show that hierarchical phrase-based models can improve Persian-English translation. There are also other attempts to improve Persian-English SMT by working on syntactic reordering (Gupta et al., 2012) and rule-based post editing (Mohaghegh et al., 2012). There is also some work done on showing the effect of different orthographic and morphological processing for Persian on Persian-English translation (Raso"
I13-1167,2008.iwslt-papers.1,0,0.233477,"eve a large reduction of pivot translation model size. This paper is organized as follows. Section 2 briefly discusses some related work. Section 3 presents linguistic challenges and differences between Arabic and Persian. In Section 4, we discuss our pivoting strategies. Then Section 5 discusses our approach for selective combination. In Section 6, we present our experimental results. 2 2.1 Related Work Pivoting Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The core idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivoting strategies have been presented in the literature. The following two are perhaps the most commonly used.1 1 Another notable strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing piv"
I13-1167,P07-1092,0,0.142752,"arget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). A new source-target model is built from the new corpus. 1174 International Joint Conference on Natural Language Processing, pages 1174–1180, Nagoya, Japan, 14-18 October 2013. The first strategy is sentence pivoting in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (Khalilov et al., 2008). The second strategy is phrase pivoting (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009). In phrase pivoting, a new source-target phrase table (translation model) is induced from source-pivot and pivot-target phrase tables. We compute the lexical weights and translation probabilities from the two phrase tables. In this paper, we utilize the phrase pivoting strategy as our baseline, which is shown to be better in performance compared to sentence pivoting (El Kholy et al., 2013). 2.2 Domain Adaptation We propose a selective combination approach of pivot and direct SMT models to improve the translation quality. Our approach is similar to domain adaptation techniq"
I13-1167,eck-etal-2004-language,0,0.04032,"to sentence pivoting (El Kholy et al., 2013). 2.2 Domain Adaptation We propose a selective combination approach of pivot and direct SMT models to improve the translation quality. Our approach is similar to domain adaptation techniques where training data from many diverse sources are combined to build a single translation model which is used to translate sentences in a new domain. Domain adaptation has been explored in the field through different methods. Some methods involve information retrieval (IR) techniques to retrieve sentence pairs related to the target domain from a training corpus (Eck et al., 2004; Hildebrand et al., 2005). Other domain adaptation methods are based on distinguishing between general and domain specific examples (Daum´e III and Marcu, 2006). In a similar approach, Koehn and Schroeder (2007) use multiple alternative decoding paths to combine different translation models and the weights are set with minimum error rate training (Och and Ney, 2003). In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and co"
I13-1167,2010.jeptalnrecital-long.29,1,0.859126,"Missing"
I13-1167,P13-2073,1,0.467086,"Missing"
I13-1167,W09-0809,1,0.887405,"ith minimum error rate training (Och and Ney, 2003). In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008; Shilon et al., 2010). Most of these efforts are focused on syntactic and morphological processing. There have been a growing number of publications that consider translation into Arabic. Sarikaya and Deng (2007) use joint morphological-lexical language models to re-rank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010"
I13-1167,W12-5905,0,0.229138,"ank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limited to few studies. For example, Kathol and Zheng (2008) use unsupervised morpheme segmentation for Persian. They show that hierarchical phrase-based models can improve Persian-English translation. There are also other attempts to improve Persian-English SMT by working on syntactic reordering (Gupta et al., 2012) and rule-based post editing (Mohaghegh et al., 2012). There is also some work done on showing the effect of different orthographic and morphological processing for Persian on Persian-English translation (Rasooli et al., 2013a). To our knowledge, there hasn’t been a lot of work on Persian and Arabic as a language pair. One example is an effort based on improving the reordering models for Persian-Arabic SMT (Matusov and K¨opr¨u, 2010). Another recent effort improved the quality of Persian-Arabic by pivoting through English and adding additional features to reflect the quality of projected align"
I13-1167,W09-0431,1,0.896525,"f pivot translation model size. This paper is organized as follows. Section 2 briefly discusses some related work. Section 3 presents linguistic challenges and differences between Arabic and Persian. In Section 4, we discuss our pivoting strategies. Then Section 5 discusses our approach for selective combination. In Section 6, we present our experimental results. 2 2.1 Related Work Pivoting Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The core idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivoting strategies have been presented in the literature. The following two are perhaps the most commonly used.1 1 Another notable strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Berto"
I13-1167,P05-1071,1,0.669182,"+ È@ Al+ ‘the’, and the class of pronominal enclitics, e.g., Ñë+ +hm ‘their/them’. Beyond these clitics, Arabic words inflect for person, gender, number, 1175 aspect, mood, voice, state and case.2 This morphological richness leads to thousands of inflected forms per lemma and a high degree of ambiguity: about 12 analyses per word, typically corresponding to two lemmas on average (Habash, 2010). We follow El Kholy and Habash (2010a) and use the PATB tokenization scheme (Maamouri et al., 2004) in our experiments which separates all clitics except for the determiner clitic Al+. We use MADA v3.1 (Habash and Rambow, 2005; Habash et al., 2009) to tokenize the Arabic text. We only evaluate on detokenized and orthographically correct (enriched) output following the work of El Kholy and Habash (2010b). 4 Persian on the other hand has a relatively simple nominal system. There is no case system and words do not inflect with gender except for a few animate Arabic loanwords. Unlike Arabic, Persian shows only two values for number, just singular and plural (no dual), which are usually marked by + +An, either the suffix Aë+ +hA and sometimes à@ or one of the Arabic plural markers. Persian also possess a closed set of f"
I13-1167,N06-2013,1,0.802285,"In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008; Shilon et al., 2010). Most of these efforts are focused on syntactic and morphological processing. There have been a growing number of publications that consider translation into Arabic. Sarikaya and Deng (2007) use joint morphological-lexical language models to re-rank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limite"
I13-1167,A00-1002,0,0.114119,"Missing"
I13-1167,W11-2123,0,0.0397642,"ic parallel corpus is about 2.8M sentences (≈60M words) available from LDC5 and GALE6 constrained data. We use an in-house Persian-English parallel corpus of about 170K sentences and 4M words. Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). For English language modeling, we use the English Gigaword Corpus with 5-gram LM using the KenLM toolkit (Heafield, 2011). All experiments are conducted using Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weights optimization. For Persian-English translation model, weights are optimized using a set 1000 sentences randomly sampled from the parallel corpus while the English-Arabic translation model weights are optimized using a set of 500 sentences from the 2004 NIST MT evaluation test set 5 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56, LDC2008G"
I13-1167,2005.eamt-1.19,0,0.0268703,"ing (El Kholy et al., 2013). 2.2 Domain Adaptation We propose a selective combination approach of pivot and direct SMT models to improve the translation quality. Our approach is similar to domain adaptation techniques where training data from many diverse sources are combined to build a single translation model which is used to translate sentences in a new domain. Domain adaptation has been explored in the field through different methods. Some methods involve information retrieval (IR) techniques to retrieve sentence pairs related to the target domain from a training corpus (Eck et al., 2004; Hildebrand et al., 2005). Other domain adaptation methods are based on distinguishing between general and domain specific examples (Daum´e III and Marcu, 2006). In a similar approach, Koehn and Schroeder (2007) use multiple alternative decoding paths to combine different translation models and the weights are set with minimum error rate training (Och and Ney, 2003). In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct t"
I13-1167,2008.iwslt-evaluation.17,0,0.0182215,"ve side effect, we achieve a large reduction of pivot translation model size. This paper is organized as follows. Section 2 briefly discusses some related work. Section 3 presents linguistic challenges and differences between Arabic and Persian. In Section 4, we discuss our pivoting strategies. Then Section 5 discusses our approach for selective combination. In Section 6, we present our experimental results. 2 2.1 Related Work Pivoting Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The core idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivoting strategies have been presented in the literature. The following two are perhaps the most commonly used.1 1 Another notable strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target languag"
I13-1167,W07-0733,0,0.662668,"r to domain adaptation techniques where training data from many diverse sources are combined to build a single translation model which is used to translate sentences in a new domain. Domain adaptation has been explored in the field through different methods. Some methods involve information retrieval (IR) techniques to retrieve sentence pairs related to the target domain from a training corpus (Eck et al., 2004; Hildebrand et al., 2005). Other domain adaptation methods are based on distinguishing between general and domain specific examples (Daum´e III and Marcu, 2006). In a similar approach, Koehn and Schroeder (2007) use multiple alternative decoding paths to combine different translation models and the weights are set with minimum error rate training (Och and Ney, 2003). In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has b"
I13-1167,P07-2045,0,0.0204444,"n Persian. Each verb has a past and present root and many verbs have attached prefix that is regarded part of the root. A verb in Persian inflects for 14 different tense, mood, aspect, person, number and voice combination values (Rasooli et al., 2013b). In phrase pivoting (sometimes called triangulation or phrase table multiplication), we train a Persianto-Arabic and an English-Arabic translation models, such as those used in the sentence pivoting technique. Based on these two models, we induce a new Persian-Arabic translation model. Since we build our models are based Moses phrase-based SMT (Koehn et al., 2007), we provide the basic set of phrase translation probability distributions.3 We follow Utiyama and Isahara (2007) in computing the probability distributions. The following are the set of equations used to compute the lexical probabilities (φ) and the phrase translation probabilities (pw ) P φ(f |a) = φ(f |e)φ(e|a) e P φ(a|f ) = φ(a|e)φ(e|f ) Pe pw (f |a) = pw (f |e)pw (e|a) e P pw (a|f ) = pw (a|e)pw (e|f ) We follow El Kholy et al. (2013) and tokenize Persian text using Perstem (Jadidinejad et al., 2010) which is a deterministic rule based approach for segmentation of Persian. English, our pi"
I13-1167,2009.mtsummit-papers.7,0,0.118623,"tion 5 discusses our approach for selective combination. In Section 6, we present our experimental results. 2 2.1 Related Work Pivoting Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The core idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivoting strategies have been presented in the literature. The following two are perhaps the most commonly used.1 1 Another notable strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). A new source-target model is built from the new corpus. 1174 International Joint Conference on Natural Language Processing, pages 1174–1180, Nagoya, Japan, 14-18 October 2013. The first strategy is sentence pivoting in which we first tra"
I13-1167,2010.amta-papers.29,1,0.9262,"Missing"
I13-1167,C12-2085,0,0.114063,"her efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limited to few studies. For example, Kathol and Zheng (2008) use unsupervised morpheme segmentation for Persian. They show that hierarchical phrase-based models can improve Persian-English translation. There are also other attempts to improve Persian-English SMT by working on syntactic reordering (Gupta et al., 2012) and rule-based post editing (Mohaghegh et al., 2012). There is also some work done on showing the effect of different orthographic and morphological processing for Persian on Persian-English translation (Rasooli et al., 2013a). To our knowledge, there hasn’t been a lot of work on Persian and Arabic as a language pair. One example is an effort based on improving the reordering models for Persian-Arabic SMT (Matusov and K¨opr¨u, 2010). Another recent effort improved the quality of Persian-Arabic by pivoting through English and adding additional features to reflect the quality of projected alignments between the source and target phrases in the pi"
I13-1167,J03-1002,0,0.0354178,"in a new domain. Domain adaptation has been explored in the field through different methods. Some methods involve information retrieval (IR) techniques to retrieve sentence pairs related to the target domain from a training corpus (Eck et al., 2004; Hildebrand et al., 2005). Other domain adaptation methods are based on distinguishing between general and domain specific examples (Daum´e III and Marcu, 2006). In a similar approach, Koehn and Schroeder (2007) use multiple alternative decoding paths to combine different translation models and the weights are set with minimum error rate training (Och and Ney, 2003). In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a"
I13-1167,P03-1021,0,0.0703291,"ouse Persian-English parallel corpus of about 170K sentences and 4M words. Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). For English language modeling, we use the English Gigaword Corpus with 5-gram LM using the KenLM toolkit (Heafield, 2011). All experiments are conducted using Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weights optimization. For Persian-English translation model, weights are optimized using a set 1000 sentences randomly sampled from the parallel corpus while the English-Arabic translation model weights are optimized using a set of 500 sentences from the 2004 NIST MT evaluation test set 5 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56, LDC2008G05, LDC2009E16, LDC2009G01. 6 Global Autonomous Language Exploitation, or GALE, is a DARPA-funded research projec"
I13-1167,P02-1040,0,0.0926472,"odel weights are optimized using a set of 500 sentences from the 2004 NIST MT evaluation test set 5 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56, LDC2008G05, LDC2009E16, LDC2009G01. 6 Global Autonomous Language Exploitation, or GALE, is a DARPA-funded research project. 1177 (MT04). We use a maximum phrase length of size 8 across all models. We report results on an inhouse Persian-Arabic evaluation set of 536 sentences with three references. We evaluate using BLEU-4 (Papineni et al., 2002). For the combination experiments, Moses allows the use of multiple translation tables (Koehn and Schroeder, 2007). Different combination techniques are available. We use the “Either” combination technique where the translation options are collected from one table, and additional options are collected from the other tables. If the same translation option (identical source and target phrases) is found in multiple tables, separate translation options are created for each occurrence, but with different scores. 6.2 Baseline Evaluation We compare the performance of sentence pivoting against phrase"
I13-1167,I13-1144,1,0.852517,"Missing"
I13-1167,N13-1031,0,0.116805,"2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limited to few studies. For example, Kathol and Zheng (2008) use unsupervised morpheme segmentation for Persian. They show that hierarchical phrase-based models can improve Persian-English translation. There are also other attempts to improve Persian-English SMT by working on syntactic reordering (Gupta et al., 2012) and rule-based post editing (Mohaghegh et al., 2012). There is also some work done on showing the effect of different orthographic and morphological processing for Persian on Persian-English translation (Rasooli et al., 2013a). To our knowledge, there hasn’t been a lot of work on Persian and Arabic as a language pair. One example is an effort based on improving the reordering models for Persian-Arabic SMT (Matusov and K¨opr¨u, 2010). Another recent effort improved the quality of Persian-Arabic by pivoting through English and adding additional features to reflect the quality of projected alignments between the source and target phrases in the pivot phrase table (El Kholy et al., 2013). 3 Arabic and Persian Linguistic Issues In this section we present our motivation and choice for preprocessing Arabic, Persian and"
I13-1167,N07-2037,0,0.0224418,"them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008; Shilon et al., 2010). Most of these efforts are focused on syntactic and morphological processing. There have been a growing number of publications that consider translation into Arabic. Sarikaya and Deng (2007) use joint morphological-lexical language models to re-rank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limited to few studies. For example, Kathol and Zheng (2008) use unsupervised morpheme segmentation for Persian. They show that hierarchical phrase-based models can improve Persian-English translation. There are also other attempts to improve"
I13-1167,2010.amta-srw.4,1,0.854875,"new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008; Shilon et al., 2010). Most of these efforts are focused on syntactic and morphological processing. There have been a growing number of publications that consider translation into Arabic. Sarikaya and Deng (2007) use joint morphological-lexical language models to re-rank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limited to few studies. For example, Kathol and Zhen"
I13-1167,N07-1061,0,0.718603,"ly when the source and target languages are morphologically rich. Morphological richness comes with many challenges and the severity of these challenges increases when the richness and morphological complexity are expressed differently in the source and target languages. A common SMT solution to the lack of parallel data is to pivot the translation through a third language (called pivot or bridge language) for which there exist abundant parallel corpora with the source and target languages. The literature covers many pivoting techniques. One of the best performing techniques, phrase pivoting (Utiyama and Isahara, 2007), builds an induced new phrase table between the source and target. One of the problems of this technique is that the size of the newly created pivot phrase table is very large (Utiyama and Isahara, 2007). Given a parallel corpus between the source and target language, combining a direct model based on this parallel corpus with a pivot model could lead to better coverage and overall translation quality. However, the combination approach needs to be optimized in order to maximize the information gain. In this paper, we propose a selective combination approach of pivot and direct SMT models. The"
I13-1167,P09-1018,0,0.198898,"sizes). As a positive side effect, we achieve a large reduction of pivot translation model size. This paper is organized as follows. Section 2 briefly discusses some related work. Section 3 presents linguistic challenges and differences between Arabic and Persian. In Section 4, we discuss our pivoting strategies. Then Section 5 discusses our approach for selective combination. In Section 6, we present our experimental results. 2 2.1 Related Work Pivoting Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The core idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivoting strategies have been presented in the literature. The following two are perhaps the most commonly used.1 1 Another notable strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpu"
I13-1167,P10-1047,0,0.0220506,"els and the weights are set with minimum error rate training (Och and Ney, 2003). In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008; Shilon et al., 2010). Most of these efforts are focused on syntactic and morphological processing. There have been a growing number of publications that consider translation into Arabic. Sarikaya and Deng (2007) use joint morphological-lexical language models to re-rank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008;"
I13-1167,H05-1021,0,\N,Missing
I13-2001,font-llitjos-carbonell-2004-translation,0,0.361837,"Missing"
I13-2001,P11-4010,0,0.0809888,", we show how our framework employs automatic annotators to correct basic Arabic spelling mistakes to speed up the annotation process. Our framework consists of two major interfaces: (a) an Admin interface, which enables the lead annotator to create, assign, monitor, evaluate and export annotation tasks in large scale; and (b) 1 2 Related Work Traditionally, manual text correction is performed under the context of post-editing machine translation (MT) output. The goal of post-editing is to evaluate MT systems rather than building corpora of edits. Tools like PET (Aziz et al., 2012) and BLAST (Stymne, 2011) provide annotators a text-editorlike interface to identify, record, and correct errors. Text-editor-like interfaces are very flexible and allow all forms of corrections to be performed, but, they are not capable of accurately tracking token alignment, if at all. Frameworks such as EXMARaLDA (Schmidt, 2010) and GATE (Cunningham et al., 2011) facilitate multi-layer and multi-round annotations. An example of such approach is the work of Dickinson and Ledbetter (2012) who annotated errors in Hungarian students essays using multiple annotation layers from phonology to syntax in different stages. T"
I13-2001,dickinson-ledbetter-2012-annotating,0,\N,Missing
I13-2001,aziz-etal-2012-pet,0,\N,Missing
I13-2001,2012.eamt-1.31,0,\N,Missing
I13-2001,2012.tc-1.5,0,\N,Missing
I13-2004,habash-etal-2006-design,1,0.651317,"h or h H. We address this problem in the context of natural language processing of Arabic dialect by proposing a conventional orthography for representing dialecIntroduction The Arabic language poses two problems for information retrieval (IR). First, Arabic is morphologically rich, which increases the likelihood of mismatch between words used in queries and words in documents. Much work has been done on addressing this issue in the context of Modern Standard Arabic (MSA), primarily using different methods of stemming and query reformulation (Al-Kharashi and Evens, 1999; Darwish et al., 2005; Habash et al., 2006; Larkey et al., 2007).1 Secondly, the Arabic-speaking world displays diglossia, meaning that a standard language, MSA, co-exists with dialects, such as Egyptian Arabic (EGY). The dialects differ from MSA in many dimensions, which limits the effectiveness of using MSA tools to handle the dialects. Relevant to IR are lexical and morphological differences. Lexically, different words may be used to 2 Arabic transliteration throughout the paper is presented in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007): (in alphabetical order) ˇ AbtθjHxdðrzsšSDTDςγfqklmnhwy and the additional ˇ ¯ sy"
I13-2004,W05-0704,0,0.0320462,"Y may be written as ë h or h H. We address this problem in the context of natural language processing of Arabic dialect by proposing a conventional orthography for representing dialecIntroduction The Arabic language poses two problems for information retrieval (IR). First, Arabic is morphologically rich, which increases the likelihood of mismatch between words used in queries and words in documents. Much work has been done on addressing this issue in the context of Modern Standard Arabic (MSA), primarily using different methods of stemming and query reformulation (Al-Kharashi and Evens, 1999; Darwish et al., 2005; Habash et al., 2006; Larkey et al., 2007).1 Secondly, the Arabic-speaking world displays diglossia, meaning that a standard language, MSA, co-exists with dialects, such as Egyptian Arabic (EGY). The dialects differ from MSA in many dimensions, which limits the effectiveness of using MSA tools to handle the dialects. Relevant to IR are lexical and morphological differences. Lexically, different words may be used to 2 Arabic transliteration throughout the paper is presented in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007): (in alphabetical order) ˇ AbtθjHxdðrzsšSDTDςγfqklmnhwy and t"
I13-2004,W12-2301,1,0.952931,"éËðA£  ð P zawja¯h ék . hawlA’ ZBñë ˆ Table 1: Four examples showing lexical variation among Arabic dialects and MSA. convey the same meaning in different dialects and MSA. Table 1 presents the same set of four words in English, MSA, Egyptian Arabic and Levantine Arabic.2 Morphologically, the dialects may use different forms from MSA, e.g., the short phrase ‘he writes’  JºJ K. appears as I in MSA , but as I . JºK yaktubu . JºK X dayiktib in Iraqi Arabic biyiktib in EGY, I .  and I . JºJ » kayiktib in Moroccan Arabic. The differences between MSA and dialect morphology can be rather large: Habash et al. (2012a) report that over one-third of EGY words cannot be analyzed using an MSA morphological analyzer; and Habash and Rambow (2006) report similar figures for Levantine verbs. Furthermore, while MSA has a standard orthography, the dialects are not orthographically standardized, which leads to the coexistence of multiple spellings for the same word, e.g., the future marker in EGY may be written as ë h or h H. We address this problem in the context of natural language processing of Arabic dialect by proposing a conventional orthography for representing dialecIntroduction The Arabic language poses tw"
I13-2004,habash-etal-2012-conventional,1,0.905655,"éËðA£  ð P zawja¯h ék . hawlA’ ZBñë ˆ Table 1: Four examples showing lexical variation among Arabic dialects and MSA. convey the same meaning in different dialects and MSA. Table 1 presents the same set of four words in English, MSA, Egyptian Arabic and Levantine Arabic.2 Morphologically, the dialects may use different forms from MSA, e.g., the short phrase ‘he writes’  JºJ K. appears as I in MSA , but as I . JºK yaktubu . JºK X dayiktib in Iraqi Arabic biyiktib in EGY, I .  and I . JºJ » kayiktib in Moroccan Arabic. The differences between MSA and dialect morphology can be rather large: Habash et al. (2012a) report that over one-third of EGY words cannot be analyzed using an MSA morphological analyzer; and Habash and Rambow (2006) report similar figures for Levantine verbs. Furthermore, while MSA has a standard orthography, the dialects are not orthographically standardized, which leads to the coexistence of multiple spellings for the same word, e.g., the future marker in EGY may be written as ë h or h H. We address this problem in the context of natural language processing of Arabic dialect by proposing a conventional orthography for representing dialecIntroduction The Arabic language poses tw"
I13-2004,P06-1086,1,0.880511,"vey the same meaning in different dialects and MSA. Table 1 presents the same set of four words in English, MSA, Egyptian Arabic and Levantine Arabic.2 Morphologically, the dialects may use different forms from MSA, e.g., the short phrase ‘he writes’  JºJ K. appears as I in MSA , but as I . JºK yaktubu . JºK X dayiktib in Iraqi Arabic biyiktib in EGY, I .  and I . JºJ » kayiktib in Moroccan Arabic. The differences between MSA and dialect morphology can be rather large: Habash et al. (2012a) report that over one-third of EGY words cannot be analyzed using an MSA morphological analyzer; and Habash and Rambow (2006) report similar figures for Levantine verbs. Furthermore, while MSA has a standard orthography, the dialects are not orthographically standardized, which leads to the coexistence of multiple spellings for the same word, e.g., the future marker in EGY may be written as ë h or h H. We address this problem in the context of natural language processing of Arabic dialect by proposing a conventional orthography for representing dialecIntroduction The Arabic language poses two problems for information retrieval (IR). First, Arabic is morphologically rich, which increases the likelihood of mismatch be"
J13-1008,E12-1069,1,0.937896,"th 2012). The Elixir-FM analyzer (Smrž 2007) readily provides the 4 PATB-tokenized words; see Section 2.5. 5 We ignore duals, which are regular in Arabic, and case/state variations in this discussion for simplicity. 6 Note that the functional and form-based feature values for verbs always coincide. 165 Computational Linguistics Volume 39, Number 1 functional inflectional number feature, but not full functional gender (only for adjectives and verbs but not for nouns), nor rationality. In this article, we use an in-house system which provides functional gender, number, and rationality features (Alkuhlani and Habash 2012). See Section 5.2 for more details. 2.4 Morpho-Syntactic Interactions Inflectional features and rationality interact with syntax in two ways. In agreement relations, two words in a specific syntactic configuration have coordinated values for specific sets of features. MSA has standard (i.e., matching value) agreement for subject– verb pairs on PERSON, GENDER, and NUMBER, and for noun–adjective pairs on NUMBER, GENDER, CASE , and DET . There are, however, three very common cases of exceptional agreement: Verbs preceding subjects are always singular, adjectives of irrational plural nouns are alw"
J13-1008,W06-2920,0,0.0791718,"Rambow Arabic Parsing with Lexical and Inflectional Features comparable to their work in terms of its systematic exploration of the space of morphological features. We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima’an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic (MSA), results have been reported on the PATB (Kulick, Gabbard, and Marcus 2006; Diab 2007; Green and Manning 2010), the Prague Dependency Treebank (PADT) (Buchholz and Marsi 2006; Nivre 2008) and the CATiB (Habash and Roth 2009). Recently, Green and Manning (2010) analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short idafa constructions and verbal or equational clauses. Nivre (2008) reports experiments on Arabic parsing using his MaltParser (Nivre et al. 2007), trained on the PADT. His results are not directly comparable to ours because of the different treebank representations, even though all the experiments reported here were performed using the MaltParser. Our results agree with previo"
J13-1008,P99-1065,0,0.172472,"ill be of little or no help for parsing, even if helpful when its gold values are provided. As we will see, the CASE feature is very relevant and not redundant, but it cannot be predicted with high accuracy and overall it is not useful. Different languages vary with respect to which features may be most helpful given various tradeoffs among these three factors. In the past, it has been shown that if we can recognize the relevant morphological features in assignment configurations well enough, then they contribute to parsing accuracy. For example, modeling CASE in Czech improves Czech parsing (Collins et al. 1999): CASE is relevant, not redundant, and can be predicted with sufficient accuracy. It has been more difficult showing that agreement morphology helps parsing, however, with negative results for dependency parsing in several languages (Eryigit, Nivre, and Oflazer 2008; Nivre, Boguslavsky, and Iomdin 2008; Nivre 2009). In this article we investigate morphological features for dependency parsing of Modern Standard Arabic (MSA). For MSA, the space of possible morphological features is fairly large. We determine which morphological features help and why. We further determine the upper bound for thei"
J13-1008,H05-1100,0,0.0777303,"Missing"
J13-1008,W07-0802,0,0.109652,"Missing"
J13-1008,N04-4038,0,0.0532459,"Missing"
J13-1008,J08-3003,0,0.160042,"Missing"
J13-1008,N10-1115,0,0.200839,"features, specifically CASE, are very helpful in MSA, though only under gold conditions: Because CASE is rarely explicit in the typically undiacritized written MSA, it has a dismal accuracy rate, which makes it useless when used in a machine-predicted (real, non-gold) condition. In contrast with previous results, we show agreement features are quite helpful in both gold and predicted conditions. This is likely a result of MSA having a rich agreement system, covering both verb–subject and noun–adjective relations. The result holds for both the MaltParser (Nivre 2008) and the Easy-First Parser (Goldberg and Elhadad 2010). Additionally, almost all work to date in MSA morphological analysis and part-ofspeech (POS) tagging has concentrated on the morphemic form of the words. Often, however, the functional morphology (which is relevant to agreement, and relates to the meaning of the word) is at odds with the “surface” (form-based) morphology; a well-known example of this are the “broken” (irregular) plurals of nominals. We show that by modeling the functional morphology rather than the form-based morphology, we obtain a further increase in parsing performance (again, both when using gold and when using predicted"
J13-1008,C10-1045,0,0.0169008,"orms other combinations. Our approach is 168 Marton, Habash, and Rambow Arabic Parsing with Lexical and Inflectional Features comparable to their work in terms of its systematic exploration of the space of morphological features. We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima’an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic (MSA), results have been reported on the PATB (Kulick, Gabbard, and Marcus 2006; Diab 2007; Green and Manning 2010), the Prague Dependency Treebank (PADT) (Buchholz and Marsi 2006; Nivre 2008) and the CATiB (Habash and Roth 2009). Recently, Green and Manning (2010) analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short idafa constructions and verbal or equational clauses. Nivre (2008) reports experiments on Arabic parsing using his MaltParser (Nivre et al. 2007), trained on the PADT. His results are not directly comparable to ours because of the different treebank representations, even though all the experiments reported here we"
J13-1008,D07-1116,1,0.910316,"Missing"
J13-1008,P05-1071,1,0.925477,"the correspondence between inflectional features and morphemes, and inspired by Smrž (2007), we distinguish between two types of inflectional features: formbased (a.k.a. surface, or illusory) features and functional features.6 Most available Arabic NLP tools and resources model morphology using formbased (“surface”) inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) (Maamouri et al. 2004), the Buckwalter morphological analyzer (Buckwalter 2004), and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow 2005; Habash, Rambow, and Roth 2012). The Elixir-FM analyzer (Smrž 2007) readily provides the 4 PATB-tokenized words; see Section 2.5. 5 We ignore duals, which are regular in Arabic, and case/state variations in this discussion for simplicity. 6 Note that the functional and form-based feature values for verbs always coincide. 165 Computational Linguistics Volume 39, Number 1 functional inflectional number feature, but not full functional gender (only for adjectives and verbs but not for nouns), nor rationality. In this article, we use an in-house system which provides functional gender, number, an"
J13-1008,P09-2056,1,0.477046,"in which both elements generally exhibit agreement in definiteness (and agreement in other features, too). Although only N-N may be followed by additional N elements in Idafa relation, both constructions may be followed by one or more adjectival modifiers. Lexical features do not constrain syntactic structure as inflectional features do. Instead, bilexical dependencies are used to model semantic relations that often are the only way to disambiguate among different possible syntactic structures. 2.5 Corpus, CATiB Format, and the CATIB 6 POS Tag Set We use the Columbia Arabic Treebank (CATiB) (Habash and Roth 2009). Specifically, we use the portion converted from Part 3 of the PATB to the CATiB format, which enriches the CATiB dependency trees with full PATB morphological information. CATiB’s dependency representation is based on traditional Arabic grammar and emphasizes syntactic case relations. It has a reduced POS tag set consisting of six tags only (henceforth CATIB 6). The tags are: NOM (non-proper nominals including nouns, pronouns, adjectives, and adverbs), PROP (proper nouns), VRB (active-voice verbs), VRB-PASS (passive-voice verbs), PRT (particles such as prepositions or conjunctions), and PNX"
J13-1008,P98-1080,0,0.174298,"Missing"
J13-1008,N12-1032,0,0.167008,"go beyond previous work, however, and explore additional lexical and inflectional features. Previous work with MaltParser in Russian, Turkish, and Hindi showed gains with CASE but not with agreement features (Eryigit, Nivre, and Oflazer 2008; Nivre, Boguslavsky, and Iomdin 2008; Nivre 2009). Our work is the first to show gains using agreement in MaltParser and in Arabic dependency parsing, and the first to use functional features for this task. Furthermore, we demonstrate that our results carry over successfully to another parser, the Easy-First Parser (Goldberg and Elhadad 2010) (Section 6). Hohensee and Bender (2012) have conducted a study on dependency parsing for 21 languages using features that encode whether the values for certain attributes are equal or not for a node and its governor. These features are potentially powerful, because they generalize to the very notion of agreement, away from the specific values of the attributes on which agreement occurs.9 We expect this kind of feature to yield lower gains for Arabic, unless: r one uses functional feature values (such as those used here for the first time in Arabic NLP), r one uses yet another representation level to account for the otherwise non-id"
J13-1008,W10-1402,1,0.636974,"Missing"
J13-1008,nilsson-nivre-2008-malteval,0,0.0121534,"ng the robustness of our findings across these frameworks. In Section 7 we explore alternative training methods, and their impact on key models. All results are reported mainly in terms of labeled attachment accuracy score (the parent word and the type of dependency relation to it, abbreviated as L AS), which is also used for greedy (hill-climbing) decisions for feature combination. Unlabeled attachment accuracy score (U AS) and label accuracy (dependency relation regardless of parent, L S) are also given. For statistical significance, we use McNemar’s test on non-gold L AS, as implemented by Nilsson and Nivre (2008). We denote p < 0.05 and p < 0.01 with + and ++ , respectively. 4.1 Data Sets and Parser For all the experiments reported in this article, we used the training portion of PATB Part 3 v3.1 (Maamouri et al. 2004), converted to the CATiB Treebank format, as mentioned in Section 2.5. We used the same training / devtest split as in Zitouni, Sorensen, and Sarikaya (2006); and we further split the devtest into two equal parts: a development (dev) set and a blind test set. For all experiments, unless specified otherwise, we used the dev set.10 We kept the test unseen (“blind”) during training and mode"
J13-1008,W03-3017,0,0.0314375,"rted to the CATiB Treebank format, as mentioned in Section 2.5. We used the same training / devtest split as in Zitouni, Sorensen, and Sarikaya (2006); and we further split the devtest into two equal parts: a development (dev) set and a blind test set. For all experiments, unless specified otherwise, we used the dev set.10 We kept the test unseen (“blind”) during training and model development. Statistics about this split (after conversion to the CATiB dependency format) are given in Table 1. For all experiments reported in this section we used the syntactic dependency parser MaltParser v1.3 (Nivre 2003, 2008; Kübler, McDonald, and Nivre 2009), a transition-based parser with an input buffer and a stack, which uses SVM classifiers 10 We use the term “dev set” to denote a non-blind test set, used for model development (feature selection and feature engineering). We do not perform further weight optimization (which, if done, is done on a separate “tuning set”). 170 Marton, Habash, and Rambow Arabic Parsing with Lexical and Inflectional Features Table 1 Penn Arabic Treebank part 3 v3.1 data split. split # tokens # sentences sentence length (avg. # tokens) training dev unseen test 341,094 31,208"
J13-1008,J08-4003,0,0.666889,"lectional Features results, assignment features, specifically CASE, are very helpful in MSA, though only under gold conditions: Because CASE is rarely explicit in the typically undiacritized written MSA, it has a dismal accuracy rate, which makes it useless when used in a machine-predicted (real, non-gold) condition. In contrast with previous results, we show agreement features are quite helpful in both gold and predicted conditions. This is likely a result of MSA having a rich agreement system, covering both verb–subject and noun–adjective relations. The result holds for both the MaltParser (Nivre 2008) and the Easy-First Parser (Goldberg and Elhadad 2010). Additionally, almost all work to date in MSA morphological analysis and part-ofspeech (POS) tagging has concentrated on the morphemic form of the words. Often, however, the functional morphology (which is relevant to agreement, and relates to the meaning of the word) is at odds with the “surface” (form-based) morphology; a well-known example of this are the “broken” (irregular) plurals of nominals. We show that by modeling the functional morphology rather than the form-based morphology, we obtain a further increase in parsing performance"
J13-1008,C08-1081,0,0.0584324,"Missing"
J13-1008,petrov-etal-2012-universal,0,0.0949504,"Missing"
J13-1008,W07-2219,0,0.0658174,"Missing"
J13-1008,P06-1073,0,0.121283,"Missing"
J13-1008,P11-2062,1,\N,Missing
J13-1008,P11-1159,1,\N,Missing
J13-1008,C98-1077,0,\N,Missing
J13-1008,J08-4010,0,\N,Missing
J13-1008,rambow-etal-2006-parallel,1,\N,Missing
J13-1008,N06-1020,0,\N,Missing
K17-3001,K17-3023,0,0.0375672,"Missing"
K17-3001,P16-1231,1,0.301678,"M Table 1: The supporting data overview: the number of words (M = million; K = thousand) for each language. http://commoncrawl.org/ Except for Ancient Greek, which was gathered from the Perseus Digital Library. 3 http://github.com/CLD2Owners/cld2 4 http://unicode.org/reports/tr15/ 3 verted to Unicode character NO-BREAK SPACE (U+00A0).5 The dimensionality of the word embeddings was chosen to be 100 after thorough discussion – more dimensions may yield better results and are commonly used, but even with just 100, the uncompressed word embeddings for the 45 languages take 135 GiB. Also note that Andor et al. (2016) achieved state-of-the-art results with 64 dimensions. The word embeddings were precomputed using word2vec (Mikolov et al., 2013) with the following options: word2vec -min-count 10 -size 100 -window 10 -negative 5 -iter 2 -threads 16 -cbow 0 -binary 0. The precomputed word embeddings are available on-line (Ginter et al., 2017). 2.3 this shared task, i.e., not included in any previous UD release. The PUD treebank consists of 1000 sentences currently in 18 languages (15 K to 27 K words, depending on the language), which were randomly picked from on-line newswire and Wikipedia;7 usually only a fe"
K17-3001,W06-2920,0,0.0145655,"categorization of the different approaches of the participating systems. Introduction Ten years ago, two CoNLL shared tasks were a major milestone for parsing research in general and dependency parsing in particular. For the first time dependency treebanks in more than ten languages were available for learning parsers. Many of them were used in follow-up work, evaluating parsers on multiple languages became standard, and multiple state-of-the-art, open-source parsers became available, facilitating production of dependency structures to be used in downstream applications. While the two tasks (Buchholz and Marsi, 2006; Nivre et al., 2007) were extremely important in setting the scene for the following years, there were also limitations that complicated application of their results: (1) gold-standard to1 Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, pages 1–19, c 2017 Association for Computational Linguistics Vancouver, Canada, August 3-4, 2017. kenization and part-of-speech tags in the test data moved the tasks away from real-world scenarios, and (2) incompatible annotation schemes made cross-linguistic comparison impossible. CoNLL 2017 has picked"
K17-3001,K17-3017,0,0.147208,"emains with participants, and since open sourcing the software underlying a paper is still the exception rather than the rule. To ensure both, TIRA supplies participants with a virtual machine, offering a range of commonly used operating systems in order not to limit the choice of technology stacks and development environments. Once deployed and tested, the virtual machines are archived to preserve the software within. Many participants agreed to share their code so that we decided to collect the respective projects in a kind of open source proceedings at GitHub.14 4.3 by Straka and Strakov´a (2017) as one of the competing systems. Straka and Strakov´a (2017) describe both these versions in more detail. The baseline models were released together with the UD 2.0 training data, one model for each treebank. Because only training and development data were available during baseline model training, we put aside a part of the training data for hyperparameter tuning, and evaluated the baseline model performance on development data. We called this data split baseline model split. The baseline models, the baseline model split, and also UD 2.0 training data with morphology predicted by 10-fold jack"
K17-3001,K17-3005,0,0.0752704,"Missing"
K17-3001,K17-3026,0,0.0310687,"E 90.88 82.31 82.46 LyS-FASTPARSE 90.88 82.31 79.14 NAIST SATO 90.88 82.31 82.46 Orange – Deski˜n 90.88 38.81 15.38 UALING 90.88 82.31 82.46 UParse 90.88 82.31 82.46 naistCL 90.88 82.31 82.46 Table 5: Universal POS tags, features and lemmas (ordered by UPOS F1 scores). duce suboptimal results when deployed on a machine different from the one where it was trained. Several teams used the library and may have been affected; for the Uppsala team (de Lhoneux et al., 2017) the issue led to official LAS = 65.11 (23rd place) instead of 69.66 (9th place). In the second case, the ParisNLP system (De La Clergerie et al., 2017) used a wrong method of recognizing the input language, which was not supported in the test data (but unfortunately it was possible to get along with it in development and trial data). Simply crashing could mean that the task moderator would show the team their diagnostic output and they would fix the bug; however, the parser was robust enough to switch to a languageagnostic mode and produced results that were not great, but also not so bad to alert the moderator and make him investigate. Thus the official LAS of the system is 60.02 (27th place) while without the bug it could have been 70.35 ("
K17-3001,K17-3021,0,0.0954088,"emains with participants, and since open sourcing the software underlying a paper is still the exception rather than the rule. To ensure both, TIRA supplies participants with a virtual machine, offering a range of commonly used operating systems in order not to limit the choice of technology stacks and development environments. Once deployed and tested, the virtual machines are archived to preserve the software within. Many participants agreed to share their code so that we decided to collect the respective projects in a kind of open source proceedings at GitHub.14 4.3 by Straka and Strakov´a (2017) as one of the competing systems. Straka and Strakov´a (2017) describe both these versions in more detail. The baseline models were released together with the UD 2.0 training data, one model for each treebank. Because only training and development data were available during baseline model training, we put aside a part of the training data for hyperparameter tuning, and evaluated the baseline model performance on development data. We called this data split baseline model split. The baseline models, the baseline model split, and also UD 2.0 training data with morphology predicted by 10-fold jack"
K17-3001,K17-3022,1,0.891655,"Missing"
K17-3001,K17-3025,0,0.0327614,"Missing"
K17-3001,K17-3024,0,0.050508,"Missing"
K17-3001,K17-3027,0,0.0537913,"Missing"
K17-3001,K17-3014,0,0.0756362,"Missing"
K17-3001,K17-3015,0,0.0745209,"Missing"
K17-3001,K17-3007,0,0.0511894,"Missing"
K17-3001,L16-1262,1,0.869327,"Missing"
K17-3001,W14-6111,0,0.0253686,"Missing"
K17-3001,W17-0411,1,0.831758,"ossible when the system run completed; before that, even the task moderator would not see whether the system was really producing output and not just sitting in an endless loop. Especially given the scale of operations this year, this turned out to be a major obstacle for some participants; TIRA needs to be improved by offering more finegrained process monitoring tools, both for organizers and participants. Content-word Labeled Attachment Score (CLAS) has been proposed as an alternative parsing metric that is tailored to the UD annotation style and more suitable for cross-language comparison (Nivre and Fang, 2017). It differs from LAS in that it only considers relations between content words. Attachment of function words is disregarded because it corresponds to morphological features in other languages (and morphology is not evaluated in this shared task). Furthermore, languages with many function words (e.g., English) have longer sentences than morphologically rich languages (e.g., Finnish), hence a single error in Finnish costs the parser significantly more than an error in English. CLAS also disregards attachment of punctuation. As CLAS is still experimental, we have designated full LAS as our main"
K17-3001,K17-3003,0,0.0845341,"Missing"
K17-3001,W17-0412,1,0.869806,"Missing"
K17-3001,L16-1680,1,0.0475333,"Missing"
K17-3001,K17-3009,1,0.104147,"Missing"
K17-3001,tiedemann-2012-parallel,0,0.0126153,"oses (so that follow-up research is not obstructed). We deliberately did not place upper bounds on data sizes (in contrast to e.g. Nivre et al. (2007)), despite the fact that processing large amounts of data may be difficult for some teams. Our primary objective was to determine the capability of current parsers with the data that is currently available. In practice, the task was formally closed, i.e., we listed the approved data resources so that all participants were aware of their options. However, the selection was rather broad, ranging from Wikipedia dumps over the OPUS parallel corpora (Tiedemann, 2012) to morphological transducers. Some of the resources were proposed by the participating teams. 2.2 Supporting Data To enable the induction of custom embeddings and the use of semi-supervised methods in general, the participants were provided with supporting resources primarily consisting of large text corpora for (nearly) all of the languages in the task, as well as embeddings pre-trained on these corpora. 1 Outside CoNLL, there were several other parsing tasks in the meantime, which naturally also explored previously unadressed aspects—for example SANCL (Petrov and McDonald, 2012) or SPMRL (S"
K17-3001,K17-3016,0,0.0605417,"Missing"
K17-3001,K17-3020,0,0.0375614,"Missing"
K17-3001,K17-3013,0,0.0456211,"Missing"
K17-3001,D07-1096,1,\N,Missing
K17-3001,K17-3002,1,\N,Missing
K17-3001,K17-3019,0,\N,Missing
K17-3001,K17-3012,1,\N,Missing
K17-3001,K17-3006,0,\N,Missing
K17-3001,K17-3010,0,\N,Missing
K17-3001,K17-3018,0,\N,Missing
K17-3001,K17-3028,1,\N,Missing
K17-3001,K17-3011,0,\N,Missing
L16-1175,W15-3206,0,0.0323242,"Missing"
L16-1175,bouamor-etal-2014-multidialectal,1,0.891026,"Missing"
L16-1175,diab-etal-2014-tharwa,1,0.89137,"Missing"
L16-1175,W14-3911,0,0.0305357,"Missing"
L16-1175,P06-1086,1,0.825282,"Missing"
L16-1175,W12-2301,1,0.906938,"Missing"
L16-1175,N13-1044,1,0.840128,"Missing"
L16-1175,D15-1254,0,0.0303772,"Missing"
L16-1175,L16-1679,1,0.805401,"Missing"
L16-1175,2006.bcs-1.4,0,0.122097,"Missing"
L16-1175,pasha-etal-2014-madamira,1,0.877273,"Missing"
L16-1175,W14-5904,0,0.0392074,"Missing"
L16-1175,P13-2001,0,0.0372105,"Missing"
L16-1175,salama-etal-2014-youdacc,1,0.889209,"Missing"
L16-1175,W11-2602,1,0.849481,"Missing"
L16-1175,W15-3205,0,0.0276656,"Missing"
L16-1175,P11-2007,0,0.0817413,"Missing"
L16-1175,N12-1006,0,0.0453082,"Missing"
L16-1207,W15-3206,1,0.79763,"There are few annotated corpora for dialectal Arabic. We note three corpora in particular: the Levantine Arabic Treebank (specifically Jordanian) (Maamouri et al., 2006), the Egyptian Arabic Treebank (Maamouri et al., 2014) and Curras, the Palestinian Arabic annotated corpus (Jarrar et al., 2014). Additionally, (Tratz et al., 2014) present a corpus of Moroccan dialect which has been annotated for language variety. Our work follows the work of Curras (Jarrar et al., 2014), which consists of around 43,000 words of a balanced genre corpus. The corpus was manually annotated using the DIWAN tool (Al-Shargi and Rambow, 2015), which we also use. The annotation in Curras is done by first using a morphological tagger for another Arabic dialect, namely MADAMIRA Egyptian (Pasha et al., 2014), to produce a base that was then corrected or accepted by a trained annotator. Since Arabic dialects do not have spelling standards, the team working on Curras followed previous efforts to create conventional orthographies (or CODA) for the dialect they worked on (Habash et al., 2012a; Zribi et al., 2014). We also follow this approach and define CODAs for MOR and YEMS. The effort to annotate corpora in context is a central step in"
L16-1207,bouamor-etal-2014-multidialectal,1,0.855928,"012a; Zribi et al., 2014). We also follow this approach and define CODAs for MOR and YEMS. The effort to annotate corpora in context is a central step in developing morphological analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). Other notable approaches and efforts have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multi-dialectal dictionary Tharwa (Diab et al., 2014), multi-dialectal corpora (Bouamor et al., 2014; Smaïli et al., 2014), the Gulf Arabic corpus (Khalifa et al., 2016) or extending MSA analyzers and resources (Salloum and Habash, 2014; Smaïli et al., 2014; Boujelbane et al., 2013). 1300 1 http://www.semarch.uni-hd.de 3. Linguistic Facts Dialectal Arabic poses many challenges for NLP. Arabic in general is a morphologically complex language which includes rich inflectional morphology, expressed both templatically and affixationally, and several classes of attachable clitics. For example, the Moroccan Arabic (MOR) word AëñJ.JºJ «ð w+γa+y-ktb-uw+hA2 ‘and they will write it’ has two proclitics"
L16-1207,I13-1048,0,0.0384164,"analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). Other notable approaches and efforts have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multi-dialectal dictionary Tharwa (Diab et al., 2014), multi-dialectal corpora (Bouamor et al., 2014; Smaïli et al., 2014), the Gulf Arabic corpus (Khalifa et al., 2016) or extending MSA analyzers and resources (Salloum and Habash, 2014; Smaïli et al., 2014; Boujelbane et al., 2013). 1300 1 http://www.semarch.uni-hd.de 3. Linguistic Facts Dialectal Arabic poses many challenges for NLP. Arabic in general is a morphologically complex language which includes rich inflectional morphology, expressed both templatically and affixationally, and several classes of attachable clitics. For example, the Moroccan Arabic (MOR) word AëñJ.JºJ «ð w+γa+y-ktb-uw+hA2 ‘and they will write it’ has two proclitics (+ ð w+ ‘and’ and +« ga+ ‘will’), one prefix -K y- ‘3rd person masculine imperfective’, one suffix ð- -uw ‘plural’ and one pronominal enclitic Aë+ +hA ‘it/her’. In Sanaani Yemeni Ara"
L16-1207,diab-etal-2014-tharwa,1,0.887158,"the dialect they worked on (Habash et al., 2012a; Zribi et al., 2014). We also follow this approach and define CODAs for MOR and YEMS. The effort to annotate corpora in context is a central step in developing morphological analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). Other notable approaches and efforts have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multi-dialectal dictionary Tharwa (Diab et al., 2014), multi-dialectal corpora (Bouamor et al., 2014; Smaïli et al., 2014), the Gulf Arabic corpus (Khalifa et al., 2016) or extending MSA analyzers and resources (Salloum and Habash, 2014; Smaïli et al., 2014; Boujelbane et al., 2013). 1300 1 http://www.semarch.uni-hd.de 3. Linguistic Facts Dialectal Arabic poses many challenges for NLP. Arabic in general is a morphologically complex language which includes rich inflectional morphology, expressed both templatically and affixationally, and several classes of attachable clitics. For example, the Moroccan Arabic (MOR) word AëñJ.JºJ «ð w+γa+y-ktb-uw+"
L16-1207,D13-1105,1,0.85685,"done by first using a morphological tagger for another Arabic dialect, namely MADAMIRA Egyptian (Pasha et al., 2014), to produce a base that was then corrected or accepted by a trained annotator. Since Arabic dialects do not have spelling standards, the team working on Curras followed previous efforts to create conventional orthographies (or CODA) for the dialect they worked on (Habash et al., 2012a; Zribi et al., 2014). We also follow this approach and define CODAs for MOR and YEMS. The effort to annotate corpora in context is a central step in developing morphological analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). Other notable approaches and efforts have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multi-dialectal dictionary Tharwa (Diab et al., 2014), multi-dialectal corpora (Bouamor et al., 2014; Smaïli et al., 2014), the Gulf Arabic corpus (Khalifa et al., 2016) or extending MSA analyzers and resources (Salloum and Habash, 2014; Smaïli et al., 2014; Boujelbane et al., 2013). 1300 1 http://www."
L16-1207,habash-etal-2012-conventional,1,0.910331,"rrar et al., 2014), which consists of around 43,000 words of a balanced genre corpus. The corpus was manually annotated using the DIWAN tool (Al-Shargi and Rambow, 2015), which we also use. The annotation in Curras is done by first using a morphological tagger for another Arabic dialect, namely MADAMIRA Egyptian (Pasha et al., 2014), to produce a base that was then corrected or accepted by a trained annotator. Since Arabic dialects do not have spelling standards, the team working on Curras followed previous efforts to create conventional orthographies (or CODA) for the dialect they worked on (Habash et al., 2012a; Zribi et al., 2014). We also follow this approach and define CODAs for MOR and YEMS. The effort to annotate corpora in context is a central step in developing morphological analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). Other notable approaches and efforts have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multi-dialectal dictionary Tharwa (Diab et al., 2014), multi-dialectal corpora (Bou"
L16-1207,W12-2301,1,0.945635,"rrar et al., 2014), which consists of around 43,000 words of a balanced genre corpus. The corpus was manually annotated using the DIWAN tool (Al-Shargi and Rambow, 2015), which we also use. The annotation in Curras is done by first using a morphological tagger for another Arabic dialect, namely MADAMIRA Egyptian (Pasha et al., 2014), to produce a base that was then corrected or accepted by a trained annotator. Since Arabic dialects do not have spelling standards, the team working on Curras followed previous efforts to create conventional orthographies (or CODA) for the dialect they worked on (Habash et al., 2012a; Zribi et al., 2014). We also follow this approach and define CODAs for MOR and YEMS. The effort to annotate corpora in context is a central step in developing morphological analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). Other notable approaches and efforts have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multi-dialectal dictionary Tharwa (Diab et al., 2014), multi-dialectal corpora (Bou"
L16-1207,N13-1044,1,0.843093,"orphological tagger for another Arabic dialect, namely MADAMIRA Egyptian (Pasha et al., 2014), to produce a base that was then corrected or accepted by a trained annotator. Since Arabic dialects do not have spelling standards, the team working on Curras followed previous efforts to create conventional orthographies (or CODA) for the dialect they worked on (Habash et al., 2012a; Zribi et al., 2014). We also follow this approach and define CODAs for MOR and YEMS. The effort to annotate corpora in context is a central step in developing morphological analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). Other notable approaches and efforts have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multi-dialectal dictionary Tharwa (Diab et al., 2014), multi-dialectal corpora (Bouamor et al., 2014; Smaïli et al., 2014), the Gulf Arabic corpus (Khalifa et al., 2016) or extending MSA analyzers and resources (Salloum and Habash, 2014; Smaïli et al., 2014; Boujelbane et al., 2013). 1300 1 http://www.semarch.uni-hd.de 3. L"
L16-1207,W14-3603,1,0.854216,"Missing"
L16-1207,L16-1679,1,0.503005,"ODAs for MOR and YEMS. The effort to annotate corpora in context is a central step in developing morphological analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). Other notable approaches and efforts have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multi-dialectal dictionary Tharwa (Diab et al., 2014), multi-dialectal corpora (Bouamor et al., 2014; Smaïli et al., 2014), the Gulf Arabic corpus (Khalifa et al., 2016) or extending MSA analyzers and resources (Salloum and Habash, 2014; Smaïli et al., 2014; Boujelbane et al., 2013). 1300 1 http://www.semarch.uni-hd.de 3. Linguistic Facts Dialectal Arabic poses many challenges for NLP. Arabic in general is a morphologically complex language which includes rich inflectional morphology, expressed both templatically and affixationally, and several classes of attachable clitics. For example, the Moroccan Arabic (MOR) word AëñJ.JºJ «ð w+γa+y-ktb-uw+hA2 ‘and they will write it’ has two proclitics (+ ð w+ ‘and’ and +« ga+ ‘will’), one prefix -K y- ‘3rd person mascu"
L16-1207,maamouri-etal-2006-developing,1,0.865078,"; Naïm-Sanbar, 1994; Al-Iryani, 1996; Behnstedt, 2006). There have been several data collections centered on Arabic dialects, specifically spoken Arabic. A very useful resource is the Semitisches Tonarchiv at the University of Heidelberg in Germany1 under the direction of Prof. Werner Arnold. We have included one Yemeni transcription from this resource in our Yemeni corpus (see Section 4.). Further data collections include (al Salam Al-Amri, 2000). There are few annotated corpora for dialectal Arabic. We note three corpora in particular: the Levantine Arabic Treebank (specifically Jordanian) (Maamouri et al., 2006), the Egyptian Arabic Treebank (Maamouri et al., 2014) and Curras, the Palestinian Arabic annotated corpus (Jarrar et al., 2014). Additionally, (Tratz et al., 2014) present a corpus of Moroccan dialect which has been annotated for language variety. Our work follows the work of Curras (Jarrar et al., 2014), which consists of around 43,000 words of a balanced genre corpus. The corpus was manually annotated using the DIWAN tool (Al-Shargi and Rambow, 2015), which we also use. The annotation in Curras is done by first using a morphological tagger for another Arabic dialect, namely MADAMIRA Egyptia"
L16-1207,maamouri-etal-2014-developing,1,0.879161,". There have been several data collections centered on Arabic dialects, specifically spoken Arabic. A very useful resource is the Semitisches Tonarchiv at the University of Heidelberg in Germany1 under the direction of Prof. Werner Arnold. We have included one Yemeni transcription from this resource in our Yemeni corpus (see Section 4.). Further data collections include (al Salam Al-Amri, 2000). There are few annotated corpora for dialectal Arabic. We note three corpora in particular: the Levantine Arabic Treebank (specifically Jordanian) (Maamouri et al., 2006), the Egyptian Arabic Treebank (Maamouri et al., 2014) and Curras, the Palestinian Arabic annotated corpus (Jarrar et al., 2014). Additionally, (Tratz et al., 2014) present a corpus of Moroccan dialect which has been annotated for language variety. Our work follows the work of Curras (Jarrar et al., 2014), which consists of around 43,000 words of a balanced genre corpus. The corpus was manually annotated using the DIWAN tool (Al-Shargi and Rambow, 2015), which we also use. The annotation in Curras is done by first using a morphological tagger for another Arabic dialect, namely MADAMIRA Egyptian (Pasha et al., 2014), to produce a base that was the"
L16-1207,pasha-etal-2014-madamira,1,0.929033,"Missing"
L16-1207,zribi-etal-2014-conventional,1,0.858671,"ich consists of around 43,000 words of a balanced genre corpus. The corpus was manually annotated using the DIWAN tool (Al-Shargi and Rambow, 2015), which we also use. The annotation in Curras is done by first using a morphological tagger for another Arabic dialect, namely MADAMIRA Egyptian (Pasha et al., 2014), to produce a base that was then corrected or accepted by a trained annotator. Since Arabic dialects do not have spelling standards, the team working on Curras followed previous efforts to create conventional orthographies (or CODA) for the dialect they worked on (Habash et al., 2012a; Zribi et al., 2014). We also follow this approach and define CODAs for MOR and YEMS. The effort to annotate corpora in context is a central step in developing morphological analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). Other notable approaches and efforts have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multi-dialectal dictionary Tharwa (Diab et al., 2014), multi-dialectal corpora (Bouamor et al., 2014; Sma"
L16-1295,avramidis-etal-2014-taraxu,0,0.0610864,"A portion of the corpus contains an analysis of the type of errors made by the MT system. Elming (2006) created a 265K-word English-Danish MT manually corrected corpus by a human professional translator. The full corpus covers the chemical patents domain. Simard et al. (2007) created a 500K-word corpus of manually edited FrenchEnglish and English-French MT from the Canadian Job Bank website. The corpus is a collection of blocks composed of the source language texts, the machine translation output of a rule-based MT system and the final post-edited version done by a human translator. Moreover, Avramidis et al. (2014) built a corpus of human-annotated machine translations which was evaluated by professional human translators for the following three language pairs: GermanEnglish, English-German and Spanish-German. Fishel et al. (2012) created a corpus of automatically produced translations with detailed manual translation error analysis of 576 sentences for four language pairs: EnglishCzech;French-German;German-English;English-Serbian. Popescu-belis et al. (2002) produced a small corpus of 50 texts translated by students and corrected by their professors and all translation errors are annotated with their c"
L16-1295,D14-1026,1,0.764023,"was evaluated by professional human translators for the following three language pairs: GermanEnglish, English-German and Spanish-German. Fishel et al. (2012) created a corpus of automatically produced translations with detailed manual translation error analysis of 576 sentences for four language pairs: EnglishCzech;French-German;German-English;English-Serbian. Popescu-belis et al. (2002) produced a small corpus of 50 texts translated by students and corrected by their professors and all translation errors are annotated with their corrections in this corpus. For Arabic, we cite the effort of Bouamor et al. (2014) who created a medium scale human judgment corpus of Arabic machine translation using the output of six MT systems and a total of 1892 sentences and 22K rankings. Our corpus is a part of the Qatar Arabic Language Bank (QALB) project, a large scale manually annotated annotation project (Zaghouani et al., 2014b; Zaghouani et al., 1869 2015). The project goal was to create an error corrected 2M-words corpus for online user comments on news websites, native speaker essays, non-native speaker essays and machine translation output. The 100K-word machine translation portion was selected from various"
L16-1295,W12-5611,0,0.0270103,"Missing"
L16-1295,2006.eamt-1.27,0,0.166044,"pair. Keywords: Post-Editing, Guidelines, Annotation 1. 2. Introduction In recent years, machine translation (MT) became widely used by translation companies to reduce their costs and improve their speed. Therefore, the demand for quick and accurate machine translations is growing. Machine translation (MT) systems often produce incorrect output with many grammatical and lexical choice errors. Correcting machine-produced translation errors, or MT Post-Editing (PE) can be done automatically or manually. Successful automatic post-editing approaches using manually corrected MT output were used by Elming (2006) and Simard et al. (2007). The availability of annotated resources is required for such approaches. When it comes to the Arabic language, to the best of our knowledge, there is no manually post-edited MT corpora available to build such systems. Therefore, there is a clear need to build such valuable resources for the Arabic language. In this paper, we present our guidelines and annotation procedure to create a human corrected MT corpus for the Modern Standard Arabic (MSA). The creation of any manually annotated corpus usually presents many challenges. In order to address these challenges, we c"
L16-1295,fishel-etal-2012-terra,0,0.104056,"ers the chemical patents domain. Simard et al. (2007) created a 500K-word corpus of manually edited FrenchEnglish and English-French MT from the Canadian Job Bank website. The corpus is a collection of blocks composed of the source language texts, the machine translation output of a rule-based MT system and the final post-edited version done by a human translator. Moreover, Avramidis et al. (2014) built a corpus of human-annotated machine translations which was evaluated by professional human translators for the following three language pairs: GermanEnglish, English-German and Spanish-German. Fishel et al. (2012) created a corpus of automatically produced translations with detailed manual translation error analysis of 576 sentences for four language pairs: EnglishCzech;French-German;German-English;English-Serbian. Popescu-belis et al. (2002) produced a small corpus of 50 texts translated by students and corrected by their professors and all translation errors are annotated with their corrections in this corpus. For Arabic, we cite the effort of Bouamor et al. (2014) who created a medium scale human judgment corpus of Arabic machine translation using the output of six MT systems and a total of 1892 sen"
L16-1295,W14-3605,1,0.85988,"one. 7. Conclusions We have presented in detail the methodology used to create a 100K-word English to Arabic MT manually post-edited corpus, including the development of the guidelines as well as the annotation procedure and the quality control procedure using frequent inter-annotator measures. The created guidelines will be made publicly available and we look forward to distribute the post-edited corpus in a planned shared task on automatic error correction and getting feedback from the community on its usefulness as it was in the previous shared tasks we organized for the L1 and L2 corpus (Mohit et al., 2014; Rozovskaya et al., 2015). We believe that this corpus will be valuable to advance research efforts in the machine translation area since manually annotated data is often needed by the MT community. We believe that our methodology for guideline development and annotation consistency checking can be applied in other projects and other languages as well. In the future, we plan to increase the size of the corpus and also to add other corpus domains. Acknowledgements We would like to thank the anonymous reviewers for their valuable comments and suggestions. We also thank all our dedicated annotat"
L16-1295,I13-2001,1,0.511808,"e was closely monitored during the initial period, before allowing the annotator to join the official post-editing production phase. Moreover, a dedicated online discussion group was frequently used by the annotation team to keep track of the MT post-editing questions and issues raised during the annotation process. This mechanism, proved to help the annotators and the lead annotator to have a better communication. The annotation itself is done using the QAWI annotation tool, an in house built web annotation framework designed originally for the manual correction of errors in L1 and L2 texts (Obeid et al., 2013). This framework includes two major components: The annotation management interface which is used to assist the lead annotator in the general work-flow process, it allows the annotation manager easily upload and organize files and projects, manage users, assign files in a batch or individually, export annotation tasks and monitor the current annotation progress by processing real time annotation progress statistics. Moreover inter-annotator agreement (IAA), evaluation metrics such as the Word Error Rate (WER) are integrated with the management interface to allow the scores to be computed and t"
L16-1295,pasha-etal-2014-madamira,1,0.825321,"Word Edit: to correct/modify a word. 2. Word Move: to move words to the right location in the sentence. 3. Add Word: insert missing words in the text. 4. Delete: delete unnecessary words. 5. Merge and Split: to merge or split words. All post-editing action history previously mentioned are recorded in a database and can be exported to an XML file. Figure 2 shows an example of how the annotation actions are stored in the XML annotation export file. Finally, and in order to increase the post-editing speed and prior to the first human pass, an automatic post-editing pass is done through MADAMIRA (Pasha et al., 2014), a tool that automatically corrects common spelling errors using a prediction model based on the words in-context. MADAMIRA uses a morphological analyzer to produce, for each input word, a list of analyses specifying every possible morphological interpretation of that word, covering all morphological features of the word. Most of the errors automatically corrected are related to Ya/AlifMaqsura, Ha/Ta-Marbuta and Hamzated Alif forms, which are common spelling errors in Arabic.6 6. 6.1. Evaluation Inter-Annotator Agreement We use Word error Rate (WER) as a proxy of the Inter annotator agreement"
L16-1295,W15-3204,1,0.858567,"We have presented in detail the methodology used to create a 100K-word English to Arabic MT manually post-edited corpus, including the development of the guidelines as well as the annotation procedure and the quality control procedure using frequent inter-annotator measures. The created guidelines will be made publicly available and we look forward to distribute the post-edited corpus in a planned shared task on automatic error correction and getting feedback from the community on its usefulness as it was in the previous shared tasks we organized for the L1 and L2 corpus (Mohit et al., 2014; Rozovskaya et al., 2015). We believe that this corpus will be valuable to advance research efforts in the machine translation area since manually annotated data is often needed by the MT community. We believe that our methodology for guideline development and annotation consistency checking can be applied in other projects and other languages as well. In the future, we plan to increase the size of the corpus and also to add other corpus domains. Acknowledgements We would like to thank the anonymous reviewers for their valuable comments and suggestions. We also thank all our dedicated annotators: Noor Alzeer, Hoda Fat"
L16-1295,N07-1064,0,0.122569,"st-Editing, Guidelines, Annotation 1. 2. Introduction In recent years, machine translation (MT) became widely used by translation companies to reduce their costs and improve their speed. Therefore, the demand for quick and accurate machine translations is growing. Machine translation (MT) systems often produce incorrect output with many grammatical and lexical choice errors. Correcting machine-produced translation errors, or MT Post-Editing (PE) can be done automatically or manually. Successful automatic post-editing approaches using manually corrected MT output were used by Elming (2006) and Simard et al. (2007). The availability of annotated resources is required for such approaches. When it comes to the Arabic language, to the best of our knowledge, there is no manually post-edited MT corpora available to build such systems. Therefore, there is a clear need to build such valuable resources for the Arabic language. In this paper, we present our guidelines and annotation procedure to create a human corrected MT corpus for the Modern Standard Arabic (MSA). The creation of any manually annotated corpus usually presents many challenges. In order to address these challenges, we created comprehensive and"
L16-1295,2006.amta-papers.25,0,0.111195,"Missing"
L16-1295,wisniewski-etal-2014-corpus,0,0.0305494,"ed to check the annotation quality. To the best of our knowledge, this is the first published machine translation manual post-editing annotation effort for Arabic of this scale. In the next sections, we review related work (Section 2), describe our corpus and the development of the guidelines (Sections 3-4), and present our annotation procedure (Section 5), than we present the annotation evaluation in Section 6, finally we conclude our work in Section 7. Related Work Large scale manually corrected MT corpora are not yet widely available due to the high cost related to building such resources. Wisniewski et al. (2014) created a corpus of machine translation errors extracted from several translation students taking part in a master program in specialized translations. The texts are translated from English to French. A portion of the corpus contains an analysis of the type of errors made by the MT system. Elming (2006) created a 265K-word English-Danish MT manually corrected corpus by a human professional translator. The full corpus covers the chemical patents domain. Simard et al. (2007) created a 500K-word corpus of manually edited FrenchEnglish and English-French MT from the Canadian Job Bank website. The"
L16-1295,zaghouani-etal-2014-large,1,0.889004,"glishCzech;French-German;German-English;English-Serbian. Popescu-belis et al. (2002) produced a small corpus of 50 texts translated by students and corrected by their professors and all translation errors are annotated with their corrections in this corpus. For Arabic, we cite the effort of Bouamor et al. (2014) who created a medium scale human judgment corpus of Arabic machine translation using the output of six MT systems and a total of 1892 sentences and 22K rankings. Our corpus is a part of the Qatar Arabic Language Bank (QALB) project, a large scale manually annotated annotation project (Zaghouani et al., 2014b; Zaghouani et al., 1869 2015). The project goal was to create an error corrected 2M-words corpus for online user comments on news websites, native speaker essays, non-native speaker essays and machine translation output. The 100K-word machine translation portion was selected from various Wikinews English articles translated to Arabic automatically using the Google Translate tool.1 3. Corpus Description We collected a 100K-word corpus of English news articles taken from the collaborative journalism Wikinews website.2 Since Wikinews is a free-content news source, we avoided any copyrights comp"
L16-1295,W15-1614,1,0.623101,"Missing"
L16-1578,avramidis-etal-2014-taraxu,0,0.0184159,"(Carl et al., 2011; Vieira, 2014; Stymne et al., 2012; Doherty and O’Brien, 2009; O’Brien, 2011). Furthermore, the approach is more objective than the approaches which rely on human scores for perceived post-editing effort (Specia, 2011; De Sousa et al., 2011; Koponen, 2012; Vieira, 2014). In its essence, it is similar to other error classification approaches, such as (Flanagan, 1994; Font-Llitj´os et al., 2005; 3644 Vilar et al., 2006; Farr´us Cabeceran et al., 2010; Blain et al., 2011; Stymne, 2011; Koponen, 2012; Koponen et al., 2012; Fishel et al., 2012; Stymne et al., 2012; Vieira, 2014; Avramidis et al., 2014). It is enriched, however by error ranking, based on information specifying which errors require more cognitive effort to be corrected, and which less. In this way, the approach only requires counting the number of errors of each type in the MT output. And thus it allows the comparison of the post-editing cost of different output texts of the same MT engine, the same text as an output of different MT engines, or for different language pairs. Temnikova (2010) tested her approach on two emergency instructions texts, one original (called “Complex”) and one manually simplified (called “Simplified”"
L16-1578,R11-1014,0,0.0530077,"Missing"
L16-1578,2009.mtsummit-posters.5,0,0.1322,"Missing"
L16-1578,2010.eamt-1.12,0,0.0241724,"cognitive evaluation approaches which are based on keystroke logging (Carl et al., 2011; Krings and Koby, 2001; Koponen et al., 2012) or eye-tracking (Carl et al., 2011; Vieira, 2014; Stymne et al., 2012; Doherty and O’Brien, 2009; O’Brien, 2011). Furthermore, the approach is more objective than the approaches which rely on human scores for perceived post-editing effort (Specia, 2011; De Sousa et al., 2011; Koponen, 2012; Vieira, 2014). In its essence, it is similar to other error classification approaches, such as (Flanagan, 1994; Font-Llitj´os et al., 2005; 3644 Vilar et al., 2006; Farr´us Cabeceran et al., 2010; Blain et al., 2011; Stymne, 2011; Koponen, 2012; Koponen et al., 2012; Fishel et al., 2012; Stymne et al., 2012; Vieira, 2014; Avramidis et al., 2014). It is enriched, however by error ranking, based on information specifying which errors require more cognitive effort to be corrected, and which less. In this way, the approach only requires counting the number of errors of each type in the MT output. And thus it allows the comparison of the post-editing cost of different output texts of the same MT engine, the same text as an output of different MT engines, or for different language pairs. Te"
L16-1578,fishel-etal-2012-terra,0,0.0135384,"s and Koby, 2001; Koponen et al., 2012) or eye-tracking (Carl et al., 2011; Vieira, 2014; Stymne et al., 2012; Doherty and O’Brien, 2009; O’Brien, 2011). Furthermore, the approach is more objective than the approaches which rely on human scores for perceived post-editing effort (Specia, 2011; De Sousa et al., 2011; Koponen, 2012; Vieira, 2014). In its essence, it is similar to other error classification approaches, such as (Flanagan, 1994; Font-Llitj´os et al., 2005; 3644 Vilar et al., 2006; Farr´us Cabeceran et al., 2010; Blain et al., 2011; Stymne, 2011; Koponen, 2012; Koponen et al., 2012; Fishel et al., 2012; Stymne et al., 2012; Vieira, 2014; Avramidis et al., 2014). It is enriched, however by error ranking, based on information specifying which errors require more cognitive effort to be corrected, and which less. In this way, the approach only requires counting the number of errors of each type in the MT output. And thus it allows the comparison of the post-editing cost of different output texts of the same MT engine, the same text as an output of different MT engines, or for different language pairs. Temnikova (2010) tested her approach on two emergency instructions texts, one original (called"
L16-1578,I13-2001,1,0.895716,"Missing"
L16-1578,P02-1040,0,0.106211,"6), from which the error classes were subsequently regrouped and ranked in an increasing order, so as to reflect the cognitive load post-editors experience while correcting the MT output. Error re-grouping and ranking was done on the basis of relevant psycholinguistic error correction litera1 https://translate.google.com ture (Harley, 2013; Larigauderie et al., 1998; Baddeley and Hitch, 1974). The aim of proposing such an approach was to create a better metric for the effort a post-editor faces while correcting MT texts, instead of relying on a nontransparent MT evaluation score such as BLEU (Papineni et al., 2002). Figure 1. shows the previous error ranking. The easiest errors to correct were considered those which required only a small change inside the word (CInF), followed by errors requiring replacing or adding a word (Styl, InW, etc.), while the hardest errors were considered those which required understanding of the whole sentence (e.g. InP, MissP, WoW and WoPh). Figure 1: Temnikova (2010)’s Error Ranking. The approach does not rely on using specific software, in contrast to PE cognitive evaluation approaches which are based on keystroke logging (Carl et al., 2011; Krings and Koby, 2001; Koponen"
L16-1578,pasha-etal-2014-madamira,1,0.803417,"Missing"
L16-1578,W15-3204,1,0.794797,"Missing"
L16-1578,2011.eamt-1.12,0,0.0234323,"rs were considered those which required understanding of the whole sentence (e.g. InP, MissP, WoW and WoPh). Figure 1: Temnikova (2010)’s Error Ranking. The approach does not rely on using specific software, in contrast to PE cognitive evaluation approaches which are based on keystroke logging (Carl et al., 2011; Krings and Koby, 2001; Koponen et al., 2012) or eye-tracking (Carl et al., 2011; Vieira, 2014; Stymne et al., 2012; Doherty and O’Brien, 2009; O’Brien, 2011). Furthermore, the approach is more objective than the approaches which rely on human scores for perceived post-editing effort (Specia, 2011; De Sousa et al., 2011; Koponen, 2012; Vieira, 2014). In its essence, it is similar to other error classification approaches, such as (Flanagan, 1994; Font-Llitj´os et al., 2005; 3644 Vilar et al., 2006; Farr´us Cabeceran et al., 2010; Blain et al., 2011; Stymne, 2011; Koponen, 2012; Koponen et al., 2012; Fishel et al., 2012; Stymne et al., 2012; Vieira, 2014; Avramidis et al., 2014). It is enriched, however by error ranking, based on information specifying which errors require more cognitive effort to be corrected, and which less. In this way, the approach only requires counting the number o"
L16-1578,stymne-etal-2012-eye,0,0.0214094,"to correct were considered those which required only a small change inside the word (CInF), followed by errors requiring replacing or adding a word (Styl, InW, etc.), while the hardest errors were considered those which required understanding of the whole sentence (e.g. InP, MissP, WoW and WoPh). Figure 1: Temnikova (2010)’s Error Ranking. The approach does not rely on using specific software, in contrast to PE cognitive evaluation approaches which are based on keystroke logging (Carl et al., 2011; Krings and Koby, 2001; Koponen et al., 2012) or eye-tracking (Carl et al., 2011; Vieira, 2014; Stymne et al., 2012; Doherty and O’Brien, 2009; O’Brien, 2011). Furthermore, the approach is more objective than the approaches which rely on human scores for perceived post-editing effort (Specia, 2011; De Sousa et al., 2011; Koponen, 2012; Vieira, 2014). In its essence, it is similar to other error classification approaches, such as (Flanagan, 1994; Font-Llitj´os et al., 2005; 3644 Vilar et al., 2006; Farr´us Cabeceran et al., 2010; Blain et al., 2011; Stymne, 2011; Koponen, 2012; Koponen et al., 2012; Fishel et al., 2012; Stymne et al., 2012; Vieira, 2014; Avramidis et al., 2014). It is enriched, however by e"
L16-1578,P11-4010,0,0.0197882,"ased on keystroke logging (Carl et al., 2011; Krings and Koby, 2001; Koponen et al., 2012) or eye-tracking (Carl et al., 2011; Vieira, 2014; Stymne et al., 2012; Doherty and O’Brien, 2009; O’Brien, 2011). Furthermore, the approach is more objective than the approaches which rely on human scores for perceived post-editing effort (Specia, 2011; De Sousa et al., 2011; Koponen, 2012; Vieira, 2014). In its essence, it is similar to other error classification approaches, such as (Flanagan, 1994; Font-Llitj´os et al., 2005; 3644 Vilar et al., 2006; Farr´us Cabeceran et al., 2010; Blain et al., 2011; Stymne, 2011; Koponen, 2012; Koponen et al., 2012; Fishel et al., 2012; Stymne et al., 2012; Vieira, 2014; Avramidis et al., 2014). It is enriched, however by error ranking, based on information specifying which errors require more cognitive effort to be corrected, and which less. In this way, the approach only requires counting the number of errors of each type in the MT output. And thus it allows the comparison of the post-editing cost of different output texts of the same MT engine, the same text as an output of different MT engines, or for different language pairs. Temnikova (2010) tested her approach"
L16-1578,temnikova-etal-2012-clcm,1,0.861661,"cifying which errors require more cognitive effort to be corrected, and which less. In this way, the approach only requires counting the number of errors of each type in the MT output. And thus it allows the comparison of the post-editing cost of different output texts of the same MT engine, the same text as an output of different MT engines, or for different language pairs. Temnikova (2010) tested her approach on two emergency instructions texts, one original (called “Complex”) and one manually simplified (called “Simplified”), according to Controlled Language (CL) text simplification rules (Temnikova et al., 2012). Both texts were translated using the web version of Google Translate into three languages: Russian, Spanish, and Bulgarian. The MT output was manually post-edited by 3-5 human translators per language and then the number of errors per category was manually counted by one annotator per language. Several researchers based their work on Temnikova (2010)’s cognitive evaluation approach. Among them, Koponen et al. (2012) have modified the error classification by adding one additional class: “Typographical, upper/lowercase or similar orthographical edits”, and splitting the “Incorrect Word” (InW)"
L16-1578,temnikova-2010-cognitive,1,0.356794,"f different difficulty to be corrected, fair compensation of post-editing should take into account the difficulty of the task, which should thus be measured in the most reliable way. The best solution for this would be to build an automatic classifier which (a) assigns each MT error into a specific correction class, (b) assigns an effort value which reflects the cognitive effort a post-editor needs to make in order to make such a correction, and (c) gives a post-editing effort score to a text. On our way of building such a classifier, we investigate whether an existing cognitive effort model (Temnikova, 2010) could provide a fairer compensation for the post-editor, by testing it on a new language which strongly differs from the previous languages on which this methodology was tested. The model made use of the Statistical Machine Translation (SMT) error classification schema proposed in Vilar et al. (2006), from which the error classes were subsequently regrouped and ranked in an increasing order, so as to reflect the cognitive load post-editors experience while correcting the MT output. Error re-grouping and ranking was done on the basis of relevant psycholinguistic error correction litera1 https:"
L16-1578,vilar-etal-2006-error,0,0.113944,"Missing"
L16-1578,zaghouani-etal-2014-large,1,0.906904,"Missing"
L16-1578,W15-1614,1,0.887222,"Missing"
L16-1578,L16-1295,1,0.826208,"Missing"
L16-1578,2012.amta-wptp.2,0,\N,Missing
L16-1578,W14-3605,1,\N,Missing
L16-1578,W12-3123,0,\N,Missing
L16-1640,K15-1005,1,0.473735,"and SeparatePunc commands. TagSounds detects sound patterns in an input String (e.g., hmmm, ahh, etc.). 5. Case Study As we are a specialized group in Arabic processing with many publicly available projects, the need for having a consistent preprocessing behavior across our projects is a must. Though, it is not necessary to have the same preprocessing pipeline for all projects, having the same implementation of the shared steps is crucial. Figures 5, 6, and 7 show the preprocessing pipelines of our publicly available tools for Arabic; AIDA for Arabic dialect identification and classification (Al-Badrashiny et al., 2015), MADAMIRA for morphological analysis and disambiguation of Egyptian and modern standard Arabic text (Pasha et al., 2014), and 3ARRIB, for converting dialectal Arabic written in Latin characters in social media to normalized Arabic orthography (Al-Badrashiny et al., 2014) and (Eskander et al., 2014). SPLIT has maintained the same system performance for these tools, but it significantly simplified the code by separating the text preprocessing part from the core engines. This enabled us to simply try different preprocessing schemes in a streamlined manner expediting the turn around for the exper"
L16-1640,althobaiti-etal-2014-aranlp,0,0.0202847,"nts to segment text into paragraphs, sentences, words and other kinds of tokens. GetItFull is a tool for downloading and preprocessing full-text journals. It performs various commonly used preprocessing steps and puts the output in a structured XML document for each article with tags identifying the various sections and journal information articles (Natarajan et al., 2006). AraNLP is a preprocessing tool developed specifically for preprocessing Arabic texts. It includes a sentence detector, tokenizer, light stemmer, root stemmer, part-of-speech tagger, and a punctuation and diacritic remover (Althobaiti et al., 2014). In this paper, we introduce SPLIT, the Smart Preprocessing (Quasi) Language Independent Tool. By language independence we mean that the tool is built in allows it to be as flexible as possible and not be restricted to a certain language. The tool consists of a list of commands. Where each of them performs only one task. The users can then build their own preprocessing pipeline using a simple configuration file. This list of commands can easily be expanded just by adding a file that contains the code of the new preprocessing task to the source directory of the tool. SPLIT is then able to use"
L16-1640,W14-3901,1,0.84161,"is not necessary to have the same preprocessing pipeline for all projects, having the same implementation of the shared steps is crucial. Figures 5, 6, and 7 show the preprocessing pipelines of our publicly available tools for Arabic; AIDA for Arabic dialect identification and classification (Al-Badrashiny et al., 2015), MADAMIRA for morphological analysis and disambiguation of Egyptian and modern standard Arabic text (Pasha et al., 2014), and 3ARRIB, for converting dialectal Arabic written in Latin characters in social media to normalized Arabic orthography (Al-Badrashiny et al., 2014) and (Eskander et al., 2014). SPLIT has maintained the same system performance for these tools, but it significantly simplified the code by separating the text preprocessing part from the core engines. This enabled us to simply try different preprocessing schemes in a streamlined manner expediting the turn around for the experimental investigations. 4058 Figure 7: 3ARRIB preprocessing pipeline Figure 5: AIDA preprocessing pipeline Figure 6: MADAMIRA preprocessing pipeline 6. Conclusions In this paper, we introduced version 1.01 of SPLIT. The tool provides the most preprocessing tasks that are needed to clean and prepare"
L16-1640,grover-etal-2000-lt,0,0.0782072,"tivate the need for a simple standard preprocessing framework that has a unified implementation of the most important preprocessing steps taking into consideration the different behaviors of various languages and genres. This enables the researcher to focus more on the research point. Some attempts toward this objective have been introduced. PRETO is a preprocessing tool developed specifically for preprocessing Turkish texts only (Tunali and Bilgin, 2012). JPreText is another tool that focuses on stemming, stopword removal, and term weighting (TF/IDF) for English text (Nogueira et al., 2008). Grover et al. (2000) introduced a tool called “A Flexible Tokenisation Tool” that includes ready-made components to segment text into paragraphs, sentences, words and other kinds of tokens. GetItFull is a tool for downloading and preprocessing full-text journals. It performs various commonly used preprocessing steps and puts the output in a structured XML document for each article with tags identifying the various sections and journal information articles (Natarajan et al., 2006). AraNLP is a preprocessing tool developed specifically for preprocessing Arabic texts. It includes a sentence detector, tokenizer, ligh"
L16-1640,pasha-etal-2014-madamira,1,0.830646,"specialized group in Arabic processing with many publicly available projects, the need for having a consistent preprocessing behavior across our projects is a must. Though, it is not necessary to have the same preprocessing pipeline for all projects, having the same implementation of the shared steps is crucial. Figures 5, 6, and 7 show the preprocessing pipelines of our publicly available tools for Arabic; AIDA for Arabic dialect identification and classification (Al-Badrashiny et al., 2015), MADAMIRA for morphological analysis and disambiguation of Egyptian and modern standard Arabic text (Pasha et al., 2014), and 3ARRIB, for converting dialectal Arabic written in Latin characters in social media to normalized Arabic orthography (Al-Badrashiny et al., 2014) and (Eskander et al., 2014). SPLIT has maintained the same system performance for these tools, but it significantly simplified the code by separating the text preprocessing part from the core engines. This enabled us to simply try different preprocessing schemes in a streamlined manner expediting the turn around for the experimental investigations. 4058 Figure 7: 3ARRIB preprocessing pipeline Figure 5: AIDA preprocessing pipeline Figure 6: MADA"
L16-1679,bouamor-etal-2014-multidialectal,1,0.81029,"e Levantine Arabic Treebank (LATB) of Jordanian Arabic (Maamouri et al., 2006) and the Curras corpus of Palestinian Arabic (Jarrar et al., 2014). Efforts on other dialects include corpora for Tunisian Arabic (Masmoudi et al., 2014) and Algerian Arabic (Smaïli et al., 2014). There are also some efforts that targeted multiple dialects such as the COLABA project (Diab et al., 2010) which annotated dialectal content resources for Egyptian, Iraqi, Levantine, and Moroccan dialects from online weblogs, the Tharwa multi-dialectal lexicon (Diab et al., 2014), the multidialectal parallel Arabic corpus (Bouamor et al., 2014), and the highly dialectal online commentary corpus (Zaidan and Callison-Burch, 2011). Most recently, in this conference proceedings, AlShargi et al. (2016) present two morphologically annotated corpora for Moroccan Arabic and Sanaani Yemeni Arabic. 4282 As far as Gulf Arabic is concerned, Halefom et al. (2013) created an Emirati Arabic Corpus (EAC) consisting of 2 million words of transcribed Emirati TV and radio shows. The corpus was transcribed in broad IPA and translated to English. Morphological and lexical annotations as well as Arabic script annotation was manually done for a small port"
L16-1679,diab-etal-2014-tharwa,1,0.847146,"abic received less attention, with notable efforts including the Levantine Arabic Treebank (LATB) of Jordanian Arabic (Maamouri et al., 2006) and the Curras corpus of Palestinian Arabic (Jarrar et al., 2014). Efforts on other dialects include corpora for Tunisian Arabic (Masmoudi et al., 2014) and Algerian Arabic (Smaïli et al., 2014). There are also some efforts that targeted multiple dialects such as the COLABA project (Diab et al., 2010) which annotated dialectal content resources for Egyptian, Iraqi, Levantine, and Moroccan dialects from online weblogs, the Tharwa multi-dialectal lexicon (Diab et al., 2014), the multidialectal parallel Arabic corpus (Bouamor et al., 2014), and the highly dialectal online commentary corpus (Zaidan and Callison-Burch, 2011). Most recently, in this conference proceedings, AlShargi et al. (2016) present two morphologically annotated corpora for Moroccan Arabic and Sanaani Yemeni Arabic. 4282 As far as Gulf Arabic is concerned, Halefom et al. (2013) created an Emirati Arabic Corpus (EAC) consisting of 2 million words of transcribed Emirati TV and radio shows. The corpus was transcribed in broad IPA and translated to English. Morphological and lexical annotations as w"
L16-1679,D13-1105,1,0.779384,"le MSA tools to cover DA characteristics, as in the work of Abo Bakr et al. (2008) and Salloum and Habash (2011), or modeling DAs directly, without relying on existing MSA contributions (Habash and Rambow, 2006). One of the notable recent contributions for Egyptian Arabic morphological analysis is CALIMA (Habash et al., 2012a). The CALIMA analyzer for EGY and the commonly used SAMA analyzer for MSA (Graff et al., 2009) are central in the functioning of the EGY morphological tagger MADA-ARZ (Habash et al., 2013), and its successor MADAMIRA (Pasha et al., 2014), which supports both MSA and EGY. Eskander et al. (2013) describe a technique for automatic extraction of morphological lexicons from morphologically annotated corpora and demonstrate it on EGY. Al-Shargi et al. (2016) apply the technique of Eskander et al. (2013) and build two morphological analyzers for Moroccan Arabic and Sanaani Yemeni Arabic. As for GA, we are aware of a single effort on a rule based stemmer (Abuata and Al-Omari, 2015) that works on sets of words collected online; they compare their results to other well known MSA stemmers. In this paper we use MADAMIRA-EGY as a starting point for the GA morphological annotation following the"
L16-1679,P06-1086,1,0.897461,"015) and Maghrebi Arabic (Turki et al., 2016) extended the original version of CODA. We extend CODA to cover Gulf Arabic. 2.3. Arabic Dialect Morphological Modeling Most of the work that explored morphology in Arabic focused on MSA (Al-Sughaiyer and Al-Kharashi, 2004; Buckwalter, 2004; Graff et al., 2009; Pasha et al., 2014). Contributions to DA morphology analysis are usually based on either extending available MSA tools to cover DA characteristics, as in the work of Abo Bakr et al. (2008) and Salloum and Habash (2011), or modeling DAs directly, without relying on existing MSA contributions (Habash and Rambow, 2006). One of the notable recent contributions for Egyptian Arabic morphological analysis is CALIMA (Habash et al., 2012a). The CALIMA analyzer for EGY and the commonly used SAMA analyzer for MSA (Graff et al., 2009) are central in the functioning of the EGY morphological tagger MADA-ARZ (Habash et al., 2013), and its successor MADAMIRA (Pasha et al., 2014), which supports both MSA and EGY. Eskander et al. (2013) describe a technique for automatic extraction of morphological lexicons from morphologically annotated corpora and demonstrate it on EGY. Al-Shargi et al. (2016) apply the technique of Esk"
L16-1679,P09-2056,1,0.918566,"related work in Dialectal Arabic NLP in Section 2. This is followed by a background discussion on GA in Section 3. We then discuss the collection of the corpus and describe its genre in Section 4. We present our preliminary annotation study and evaluate it in Section 5. Finally, we present the Gumar Corpus web interface in Section 6. 1  Gumar QÔ¯ /gumEr/ is the word for ‘moon’ in Gulf Arabic. 2.1. Related Work Dialectal Corpora There have been many notable efforts on the development of annotated Arabic language corpora (Maamouri and Cieri, 2002; Maamouri et al., 2004; Smrž and Hajiˇc, 2006; Habash and Roth, 2009; Zaghouani et al., 2014). Most contributions however targeted MSA, developing annotation guidelines and producing large-scale Arabic Treebanks. These resources were instrumental in pushing the state-of-the-art of Arabic NLP. Contributions that are specific to DA are limited in size, more scattered and more recent. Some of the earliest and relatively largest efforts have targeted Egyptian Arabic (EGY). They include CALLHOME Egyptian Arabic (CHE) corpus (Gadalla et al., 1997) and its associated Egyptian Colloquial Arabic Lexicon (ECAL) (Kilany et al., 2002). In addition, there is the YADAC corp"
L16-1679,W12-2301,1,0.895971,"Missing"
L16-1679,N13-1044,1,0.866818,"sha et al., 2014). Contributions to DA morphology analysis are usually based on either extending available MSA tools to cover DA characteristics, as in the work of Abo Bakr et al. (2008) and Salloum and Habash (2011), or modeling DAs directly, without relying on existing MSA contributions (Habash and Rambow, 2006). One of the notable recent contributions for Egyptian Arabic morphological analysis is CALIMA (Habash et al., 2012a). The CALIMA analyzer for EGY and the commonly used SAMA analyzer for MSA (Graff et al., 2009) are central in the functioning of the EGY morphological tagger MADA-ARZ (Habash et al., 2013), and its successor MADAMIRA (Pasha et al., 2014), which supports both MSA and EGY. Eskander et al. (2013) describe a technique for automatic extraction of morphological lexicons from morphologically annotated corpora and demonstrate it on EGY. Al-Shargi et al. (2016) apply the technique of Eskander et al. (2013) and build two morphological analyzers for Moroccan Arabic and Sanaani Yemeni Arabic. As for GA, we are aware of a single effort on a rule based stemmer (Abuata and Al-Omari, 2015) that works on sets of words collected online; they compare their results to other well known MSA stemmers"
L16-1679,W14-3603,1,0.794391,"its development. There is a lot of emphasis in the annotations of these corpora on the phonological and morphosyntactic phenomena of Emirati Arabic. Our Gumar Corpus is differently oriented and designed: text as opposed to speech is the starting point. And computational models of GA is our target. Our corpus only includes language created by adult speakers (unlike EMALAC) and that is a slightly conventionalized novellike form. Finally the Gumar Corpus includes texts from a number of the Gulf countries and is not limited to the UAE. For recent surveys of Arabic resources for NLP, see Zaghouani (2014) and Shoufan and Al-Ameri (2015). 2.2. Dialectal Orthography Due to the lack of standardized orthography guidelines for DA, along with the phonological differences from MSA, and dialectal variations within the dialects themselves, there are many orthographic variations for written DA content. Writers in DA, regardless of the context, are often inconsistent with others and even with themselves when it comes to the written form of a dialect, writing with MSA driven orthography, or phonologically driven orthography in Arabic script or even Latin script (Darwish, 2013; AlBadrashiny et al., 2014)."
L16-1679,maamouri-etal-2006-developing,1,0.83841,"rpus (Gadalla et al., 1997) and its associated Egyptian Colloquial Arabic Lexicon (ECAL) (Kilany et al., 2002). In addition, there is the YADAC corpus (AlSabbagh and Girju, 2012), which was based on dialectal content identification and web harvesting of blogs, micro blogs, and forums of EGY content. And most recently, the Linguistic Data Consortium collected and annotated a sizable EGY corpus (Maamouri et al., 2012b; Maamouri et al., 2012a; Maamouri et al., 2014). Levantine Arabic received less attention, with notable efforts including the Levantine Arabic Treebank (LATB) of Jordanian Arabic (Maamouri et al., 2006) and the Curras corpus of Palestinian Arabic (Jarrar et al., 2014). Efforts on other dialects include corpora for Tunisian Arabic (Masmoudi et al., 2014) and Algerian Arabic (Smaïli et al., 2014). There are also some efforts that targeted multiple dialects such as the COLABA project (Diab et al., 2010) which annotated dialectal content resources for Egyptian, Iraqi, Levantine, and Moroccan dialects from online weblogs, the Tharwa multi-dialectal lexicon (Diab et al., 2014), the multidialectal parallel Arabic corpus (Bouamor et al., 2014), and the highly dialectal online commentary corpus (Zaid"
L16-1679,maamouri-etal-2014-developing,1,0.854001,"ed and more recent. Some of the earliest and relatively largest efforts have targeted Egyptian Arabic (EGY). They include CALLHOME Egyptian Arabic (CHE) corpus (Gadalla et al., 1997) and its associated Egyptian Colloquial Arabic Lexicon (ECAL) (Kilany et al., 2002). In addition, there is the YADAC corpus (AlSabbagh and Girju, 2012), which was based on dialectal content identification and web harvesting of blogs, micro blogs, and forums of EGY content. And most recently, the Linguistic Data Consortium collected and annotated a sizable EGY corpus (Maamouri et al., 2012b; Maamouri et al., 2012a; Maamouri et al., 2014). Levantine Arabic received less attention, with notable efforts including the Levantine Arabic Treebank (LATB) of Jordanian Arabic (Maamouri et al., 2006) and the Curras corpus of Palestinian Arabic (Jarrar et al., 2014). Efforts on other dialects include corpora for Tunisian Arabic (Masmoudi et al., 2014) and Algerian Arabic (Smaïli et al., 2014). There are also some efforts that targeted multiple dialects such as the COLABA project (Diab et al., 2010) which annotated dialectal content resources for Egyptian, Iraqi, Levantine, and Moroccan dialects from online weblogs, the Tharwa multi-diale"
L16-1679,masmoudi-etal-2014-corpus,1,0.880078,"lSabbagh and Girju, 2012), which was based on dialectal content identification and web harvesting of blogs, micro blogs, and forums of EGY content. And most recently, the Linguistic Data Consortium collected and annotated a sizable EGY corpus (Maamouri et al., 2012b; Maamouri et al., 2012a; Maamouri et al., 2014). Levantine Arabic received less attention, with notable efforts including the Levantine Arabic Treebank (LATB) of Jordanian Arabic (Maamouri et al., 2006) and the Curras corpus of Palestinian Arabic (Jarrar et al., 2014). Efforts on other dialects include corpora for Tunisian Arabic (Masmoudi et al., 2014) and Algerian Arabic (Smaïli et al., 2014). There are also some efforts that targeted multiple dialects such as the COLABA project (Diab et al., 2010) which annotated dialectal content resources for Egyptian, Iraqi, Levantine, and Moroccan dialects from online weblogs, the Tharwa multi-dialectal lexicon (Diab et al., 2014), the multidialectal parallel Arabic corpus (Bouamor et al., 2014), and the highly dialectal online commentary corpus (Zaidan and Callison-Burch, 2011). Most recently, in this conference proceedings, AlShargi et al. (2016) present two morphologically annotated corpora for Mor"
L16-1679,pasha-etal-2014-madamira,1,0.956049,"c dialects in general which makes it easy to be extended to other dialects. Initially, the guidelines of CODA were mainly specific to EGY. Jarrar et al. (2014) extended the existing CODA to cover Palestinian Arabic. Recent work on Tunisian (Zribi et al., 2014), Algerian (Saadane and Habash, 2015) and Maghrebi Arabic (Turki et al., 2016) extended the original version of CODA. We extend CODA to cover Gulf Arabic. 2.3. Arabic Dialect Morphological Modeling Most of the work that explored morphology in Arabic focused on MSA (Al-Sughaiyer and Al-Kharashi, 2004; Buckwalter, 2004; Graff et al., 2009; Pasha et al., 2014). Contributions to DA morphology analysis are usually based on either extending available MSA tools to cover DA characteristics, as in the work of Abo Bakr et al. (2008) and Salloum and Habash (2011), or modeling DAs directly, without relying on existing MSA contributions (Habash and Rambow, 2006). One of the notable recent contributions for Egyptian Arabic morphological analysis is CALIMA (Habash et al., 2012a). The CALIMA analyzer for EGY and the commonly used SAMA analyzer for MSA (Graff et al., 2009) are central in the functioning of the EGY morphological tagger MADA-ARZ (Habash et al., 20"
L16-1679,W15-3208,1,0.814676,"identify and reason about the words of a given dialect (Habash et al., 2012b), hence, a conventional form for the orthographic notations is important. Habash et al. (2012b) proposed a Conventional Orthography for Dialectal Arabic (CODA). CODA is designed for the purpose of developing conventional computational models of Arabic dialects in general which makes it easy to be extended to other dialects. Initially, the guidelines of CODA were mainly specific to EGY. Jarrar et al. (2014) extended the existing CODA to cover Palestinian Arabic. Recent work on Tunisian (Zribi et al., 2014), Algerian (Saadane and Habash, 2015) and Maghrebi Arabic (Turki et al., 2016) extended the original version of CODA. We extend CODA to cover Gulf Arabic. 2.3. Arabic Dialect Morphological Modeling Most of the work that explored morphology in Arabic focused on MSA (Al-Sughaiyer and Al-Kharashi, 2004; Buckwalter, 2004; Graff et al., 2009; Pasha et al., 2014). Contributions to DA morphology analysis are usually based on either extending available MSA tools to cover DA characteristics, as in the work of Abo Bakr et al. (2008) and Salloum and Habash (2011), or modeling DAs directly, without relying on existing MSA contributions (Haba"
L16-1679,W11-2602,1,0.856726,"er Palestinian Arabic. Recent work on Tunisian (Zribi et al., 2014), Algerian (Saadane and Habash, 2015) and Maghrebi Arabic (Turki et al., 2016) extended the original version of CODA. We extend CODA to cover Gulf Arabic. 2.3. Arabic Dialect Morphological Modeling Most of the work that explored morphology in Arabic focused on MSA (Al-Sughaiyer and Al-Kharashi, 2004; Buckwalter, 2004; Graff et al., 2009; Pasha et al., 2014). Contributions to DA morphology analysis are usually based on either extending available MSA tools to cover DA characteristics, as in the work of Abo Bakr et al. (2008) and Salloum and Habash (2011), or modeling DAs directly, without relying on existing MSA contributions (Habash and Rambow, 2006). One of the notable recent contributions for Egyptian Arabic morphological analysis is CALIMA (Habash et al., 2012a). The CALIMA analyzer for EGY and the commonly used SAMA analyzer for MSA (Graff et al., 2009) are central in the functioning of the EGY morphological tagger MADA-ARZ (Habash et al., 2013), and its successor MADAMIRA (Pasha et al., 2014), which supports both MSA and EGY. Eskander et al. (2013) describe a technique for automatic extraction of morphological lexicons from morphologica"
L16-1679,W15-3205,0,0.217694,"ment. There is a lot of emphasis in the annotations of these corpora on the phonological and morphosyntactic phenomena of Emirati Arabic. Our Gumar Corpus is differently oriented and designed: text as opposed to speech is the starting point. And computational models of GA is our target. Our corpus only includes language created by adult speakers (unlike EMALAC) and that is a slightly conventionalized novellike form. Finally the Gumar Corpus includes texts from a number of the Gulf countries and is not limited to the UAE. For recent surveys of Arabic resources for NLP, see Zaghouani (2014) and Shoufan and Al-Ameri (2015). 2.2. Dialectal Orthography Due to the lack of standardized orthography guidelines for DA, along with the phonological differences from MSA, and dialectal variations within the dialects themselves, there are many orthographic variations for written DA content. Writers in DA, regardless of the context, are often inconsistent with others and even with themselves when it comes to the written form of a dialect, writing with MSA driven orthography, or phonologically driven orthography in Arabic script or even Latin script (Darwish, 2013; AlBadrashiny et al., 2014). These orthographic variations ma"
L16-1679,zaghouani-etal-2014-large,1,0.849967,"tal Arabic NLP in Section 2. This is followed by a background discussion on GA in Section 3. We then discuss the collection of the corpus and describe its genre in Section 4. We present our preliminary annotation study and evaluate it in Section 5. Finally, we present the Gumar Corpus web interface in Section 6. 1  Gumar QÔ¯ /gumEr/ is the word for ‘moon’ in Gulf Arabic. 2.1. Related Work Dialectal Corpora There have been many notable efforts on the development of annotated Arabic language corpora (Maamouri and Cieri, 2002; Maamouri et al., 2004; Smrž and Hajiˇc, 2006; Habash and Roth, 2009; Zaghouani et al., 2014). Most contributions however targeted MSA, developing annotation guidelines and producing large-scale Arabic Treebanks. These resources were instrumental in pushing the state-of-the-art of Arabic NLP. Contributions that are specific to DA are limited in size, more scattered and more recent. Some of the earliest and relatively largest efforts have targeted Egyptian Arabic (EGY). They include CALLHOME Egyptian Arabic (CHE) corpus (Gadalla et al., 1997) and its associated Egyptian Colloquial Arabic Lexicon (ECAL) (Kilany et al., 2002). In addition, there is the YADAC corpus (AlSabbagh and Girju,"
L16-1679,P11-2007,0,0.0737158,"006) and the Curras corpus of Palestinian Arabic (Jarrar et al., 2014). Efforts on other dialects include corpora for Tunisian Arabic (Masmoudi et al., 2014) and Algerian Arabic (Smaïli et al., 2014). There are also some efforts that targeted multiple dialects such as the COLABA project (Diab et al., 2010) which annotated dialectal content resources for Egyptian, Iraqi, Levantine, and Moroccan dialects from online weblogs, the Tharwa multi-dialectal lexicon (Diab et al., 2014), the multidialectal parallel Arabic corpus (Bouamor et al., 2014), and the highly dialectal online commentary corpus (Zaidan and Callison-Burch, 2011). Most recently, in this conference proceedings, AlShargi et al. (2016) present two morphologically annotated corpora for Moroccan Arabic and Sanaani Yemeni Arabic. 4282 As far as Gulf Arabic is concerned, Halefom et al. (2013) created an Emirati Arabic Corpus (EAC) consisting of 2 million words of transcribed Emirati TV and radio shows. The corpus was transcribed in broad IPA and translated to English. Morphological and lexical annotations as well as Arabic script annotation was manually done for a small portion of the corpus (around 15,000 words). Furthermore, Ntelitheos and Idrissi (Forthco"
L16-1679,zribi-etal-2014-conventional,1,0.846816,"omputational models to properly identify and reason about the words of a given dialect (Habash et al., 2012b), hence, a conventional form for the orthographic notations is important. Habash et al. (2012b) proposed a Conventional Orthography for Dialectal Arabic (CODA). CODA is designed for the purpose of developing conventional computational models of Arabic dialects in general which makes it easy to be extended to other dialects. Initially, the guidelines of CODA were mainly specific to EGY. Jarrar et al. (2014) extended the existing CODA to cover Palestinian Arabic. Recent work on Tunisian (Zribi et al., 2014), Algerian (Saadane and Habash, 2015) and Maghrebi Arabic (Turki et al., 2016) extended the original version of CODA. We extend CODA to cover Gulf Arabic. 2.3. Arabic Dialect Morphological Modeling Most of the work that explored morphology in Arabic focused on MSA (Al-Sughaiyer and Al-Kharashi, 2004; Buckwalter, 2004; Graff et al., 2009; Pasha et al., 2014). Contributions to DA morphology analysis are usually based on either extending available MSA tools to cover DA characteristics, as in the work of Abo Bakr et al. (2008) and Salloum and Habash (2011), or modeling DAs directly, without relyin"
L16-1679,habash-etal-2012-conventional,1,\N,Missing
L16-1681,W14-3602,0,0.0609341,"Missing"
L16-1681,N13-1049,1,0.829282,"abash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015; Shahrour et al., 2015; Belinkov and Glass, 2015). While previous approaches focused on improving the quality of automatic diacritization, sometimes through the use of improved morphological and syntactic feature predictions, this work utilizes diacritization to generate high quality predictions of morphological features. A method for automatic morphological enrichment of a morphologically underspecified treebank has was presented in Alkuhlani et al. (2013), extending previous efforts on case prediction over syntactic trees by (Habash et al., 2007a). Our work relates to their work by the virtue of using limited information from annotators (in our case, diacritizers) to automatically generate annotations for all morphological features. Building a treebank however is timeconsuming since it requires training annotators for specific tools and conventions, while typing diacritized text can be quickly done by an educated Arabic typist. 4. Approach Undiacritized Arabic words are highly ambiguous: in our training data, words had an average of 12.8 analy"
L16-1681,D15-1274,0,0.0624172,"for annotators. The effort to build the Penn Arabic Treebank at the Linguistic Data Consortium (Maamouri and Cieri, 2002; Maamouri et al., 2004), made active use of morphological analyzers (Buckwalter, 2004; Graff et al., 2009) to jointly select diacritizations and morphological tags. Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015; Shahrour et al., 2015; Belinkov and Glass, 2015). While previous approaches focused on improving the quality of automatic diacritization, sometimes through the use of improved morphological and syntactic feature predictions, this work utilizes diacritization to generate high quality predictions of morphological features. A method for automatic morphological enrichment of a morphologically underspecified treebank has was presented in Alkuhlani et al. (2013), extending previous efforts on case prediction over syntactic trees by (Habash et al., 2007a). Our work relates to their work by the virtue of using limited information from annotators (i"
L16-1681,W15-3209,0,0.131775,"uming process that requires lots of training for annotators. The effort to build the Penn Arabic Treebank at the Linguistic Data Consortium (Maamouri and Cieri, 2002; Maamouri et al., 2004), made active use of morphological analyzers (Buckwalter, 2004; Graff et al., 2009) to jointly select diacritizations and morphological tags. Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015; Shahrour et al., 2015; Belinkov and Glass, 2015). While previous approaches focused on improving the quality of automatic diacritization, sometimes through the use of improved morphological and syntactic feature predictions, this work utilizes diacritization to generate high quality predictions of morphological features. A method for automatic morphological enrichment of a morphologically underspecified treebank has was presented in Alkuhlani et al. (2013), extending previous efforts on case prediction over syntactic trees by (Habash et al., 2007a). Our work relates to their work by the virt"
L16-1681,N07-2014,1,0.855349,"ubling marker, and can be com2 Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007b): (in alphabetical order)   P     ¨ ¨ ¬   È Ð à è ð ø @ H. H H h. h p X XP ˇ ς γ f q k l m n hw y Â b t θ j H x dðr z s š S D T D ˇ ¯  and the additional symbols: ’ Z, Â @, A @, A @, wˆ ð', yˆ Zø', ¯h è, ý ø. 4298 bined with vowel or nunation diacritics, e.g., compare I . J» . J » kat∼aba /kattaba/ kataba (no Shadda) ‘he wrote’, with I (with Shadda) ‘he dictated’. Functionally, diacritics can be split into: lexemic diacritics and inflectional diacritics (Habash and Rambow, 2007; Habash, 2010). Lexemic diacritics distinguish between two lexemes. For example, the diacritization difference   between the lexemes I . K A¿ kAtib ‘writer’ and I.KA¿ kAtab ’he corresponded’ distinguish between the meanings of the word rather than their inflections. Inflectional diacritics distinguish different inflected forms (morpho-syntactic variants) of the same lexeme. For instance, the following three  forms of the word I . KA¿ kAtb ‘writer’ vary in terms of their I . K A¿ kAtibu ‘[nominative def. K A ¿ kAtib˜u ‘[nominative indefinite]’, I.K A ¿ kAtibi inite]’, I K A ¿ kAtib˜ı ’"
L16-1681,P09-2056,1,0.825324,"99.9 99.9 25.0 99.6 99.7 17.7 • POS: Errors in POS prediction: Nominals are nounadjective errors. Closed classes are errors in closed classes of POS, such as particles, pronouns and conjunctions. Other are types of POS errors other than the aforementioned ones. • Lemma: Errors in the prediction of the lemma. It is worth mentioning that we evaluate against a finegrained POS tag-set which includes 35 tags. Most of POS errors (nominals and closed classes) describe subtle differences within the same class of POS tags, and will disappear when evaluating against a coarser POS tag-set such as CATiB (Habash and Roth, 2009). 4301 Figure 1: System performance on partially diacritized text. Error Type No Analysis No Correct Analysis Input Error Inter-Word Diac POS: Nominals POS: Closed Classes POS: Other Lemma Newswire 31.3 0 0 0 37.5 6.3 6.3 18.8 Novel 5.8 26.9 5.8 3.8 28.8 23.1 3.8 1.9 Religious 15.7 21.4 2.9 0 28.6 20.0 4.3 7.1 Table 5: Percentage of errors by type among different genres of text. 5.3.3. Partial Diacritization In this section we study the effect of using partially diacritized text instead of fully diacritized text. We recognize that using less diacritics is bound to lower the overall quality of"
L16-1681,D07-1116,1,0.822469,"owels (/a/, /i/, /u/) and the absence of any vowel. The following is the same word with and without these four diacritics: ÕæJJ.Ó mbtsm2 / Õæ JJ. Ó mubtasim ‘smiling’. The three nunation diacritics can only occur in word final positions in nominals (nouns, adjectives and adverbs). They represent a short vowel followed by an /n/ sound, and indicate nominal indefiniteness, e.g., Õæ JJ. Ó mubtasimu˜ /mubtasimun/ ‘smiling [nominative indefinite]’. The Shadda diacritic is a consonant doubling marker, and can be com2 Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007b): (in alphabetical order)   P     ¨ ¨ ¬   È Ð à è ð ø @ H. H H h. h p X XP ˇ ς γ f q k l m n hw y Â b t θ j H x dðr z s š S D T D ˇ ¯  and the additional symbols: ’ Z, Â @, A @, A @, wˆ ð', yˆ Zø', ¯h è, ý ø. 4298 bined with vowel or nunation diacritics, e.g., compare I . J» . J » kat∼aba /kattaba/ kataba (no Shadda) ‘he wrote’, with I (with Shadda) ‘he dictated’. Functionally, diacritics can be split into: lexemic diacritics and inflectional diacritics (Habash and Rambow, 2007; Habash, 2010). Lexemic diacritics distinguish between two lexemes. For example, the diacritization"
L16-1681,2006.bcs-1.4,0,0.0554811,"x: Percentage of words where the chosen analysis has the correct lemma. Evaluation In this section, we present our experimental setup, evaluation metrics and experimental results. 5.1. • POS: Percentage of words where the chosen analysis has the correct part-of-speech. Experimental Setup • Tok: Percentage of words where the chosen analysis has the correct tokenization. Morphological tagger For our baseline system, we use the MADAMIRA morphological tagger (Pasha et al., 2014), which was trained on the training portion of the Penn Arabic Treebank (PATB, parts 1, 2 and 3) (Maamouri et al., 2004; Maamouri et al., 2006; Maamouri et al., 2009) along the recommendations of Diab et al. (2013). • Diac+Lex+POS+Tok: Percentage of words where the chosen analysis has the correct diacritization, lemma, part-of-speech, and tokenization combined. • Star: Percentage of words where the chosen analysis is perfectly correct (that is, all the morphological features such as gender, number, person, etc. match their gold values). This is the strictest possible metric and is only used for Newswire text. Used texts We selected three fully diacritized and morphologically annotated texts from three genres to report on. • A newswi"
L16-1681,maamouri-etal-2008-enhancing,0,0.079998,"Missing"
L16-1681,W05-0711,0,0.0114611,"i et al., 2004; Smrž and Hajiˇc, 2006; Habash and Roth, 2009; Alansary and Nagi, 2014). However, most contributions adopted manual annotation and morphological features, which is a time-consuming process that requires lots of training for annotators. The effort to build the Penn Arabic Treebank at the Linguistic Data Consortium (Maamouri and Cieri, 2002; Maamouri et al., 2004), made active use of morphological analyzers (Buckwalter, 2004; Graff et al., 2009) to jointly select diacritizations and morphological tags. Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015; Shahrour et al., 2015; Belinkov and Glass, 2015). While previous approaches focused on improving the quality of automatic diacritization, sometimes through the use of improved morphological and syntactic feature predictions, this work utilizes diacritization to generate high quality predictions of morphological features. A method for automatic morphological enrichment of a morphologically underspecified treeb"
L16-1681,pasha-etal-2014-madamira,1,0.947441,"possible morphological analyses for a specific word out of context. Each Analysis has a single diacritized form, part-of-speech, and other morphological features. Table 1 shows a list of analyses produced by the morphological analyzer for the word á  K. byn. Morphological tagging (aka morphological disambiguation) refers to the choosing of a morphological analysis in a specific context. Our approach is to generate high-quality automatic morphological tagging output by exploiting full diacritization information. Our baseline system is the state-of-the-art Arabic morphological tagger MADAMIRA (Pasha et al., 2014) which uses the Standard Arabic Morphological Analyzer (SAMA) (Graff et al., 2009). The morphological analyzer produces a list of possible analyses for each word, and the tagger ranks the mentioned list and selects the optimal full morphological tag for each word in context. MADAMIRA does not expect any diacritics as input and in fact it ignores any naturally occurring diacritics. In our approach, we use the original full diacritics of the words to filter the ranked choices. Each analysis gets a score based on the edit distance of its associated diacritization with the input diacritization. Th"
L16-1681,D15-1152,1,0.836411,"Missing"
L16-1681,W04-1612,0,0.0406688,"ouri and Cieri, 2002; Maamouri et al., 2004; Smrž and Hajiˇc, 2006; Habash and Roth, 2009; Alansary and Nagi, 2014). However, most contributions adopted manual annotation and morphological features, which is a time-consuming process that requires lots of training for annotators. The effort to build the Penn Arabic Treebank at the Linguistic Data Consortium (Maamouri and Cieri, 2002; Maamouri et al., 2004), made active use of morphological analyzers (Buckwalter, 2004; Graff et al., 2009) to jointly select diacritizations and morphological tags. Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015; Shahrour et al., 2015; Belinkov and Glass, 2015). While previous approaches focused on improving the quality of automatic diacritization, sometimes through the use of improved morphological and syntactic feature predictions, this work utilizes diacritization to generate high quality predictions of morphological features. A method for automatic morphological enrichment of a morphologi"
L16-1681,P06-1073,0,0.141704,"ajiˇc, 2006; Habash and Roth, 2009; Alansary and Nagi, 2014). However, most contributions adopted manual annotation and morphological features, which is a time-consuming process that requires lots of training for annotators. The effort to build the Penn Arabic Treebank at the Linguistic Data Consortium (Maamouri and Cieri, 2002; Maamouri et al., 2004), made active use of morphological analyzers (Buckwalter, 2004; Graff et al., 2009) to jointly select diacritizations and morphological tags. Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015; Shahrour et al., 2015; Belinkov and Glass, 2015). While previous approaches focused on improving the quality of automatic diacritization, sometimes through the use of improved morphological and syntactic feature predictions, this work utilizes diacritization to generate high quality predictions of morphological features. A method for automatic morphological enrichment of a morphologically underspecified treebank has was presented"
L16-1696,W14-3623,1,0.90176,"Missing"
L16-1696,pasha-etal-2014-madamira,1,0.813909,"nnotated tweet corpus and an exhaustive set of features to evaluate the effectiveness of the corpus for credibility classification. The chosen features are extracted from both, the tweet itself and its author. We extracted 22 user-based features extracted directly or indirectly from the author’s history (tweet timeline), for example, author expertise on the topic being discussed and rate of activity of the tweet author. In addition, 26 content-based features are extracted including sentiment, count of retweets, count of URLs etc. To extract the sentiment we tokenized the tweet using MADAMIRA (Pasha et al., 2014) to obtain the lemma for each word in the tweet. MADAMIRA is a morphological analysis and disambiguation tool for Arabic CAT Stratified Uniform Majority CAT Stratified Uniform Majority CAT Stratified Uniform Majority Table 4: CATs’ performance against baseline classifiers 6 For more information on the challenges of Arabic natural language processing, see (Habash, 2010). 4399 majority class baseline. Such a classifier predicts all tweets to belong to a single class and this class is the majority class in the training set. Hence, if the training set is mostly composed of credible tweets then eac"
L16-1696,stoyanov-cardie-2008-annotating,0,0.0599533,"Missing"
L18-1147,abdelali-etal-2014-amara,0,0.0352532,"Missing"
L18-1147,C10-2010,0,0.0673981,"Missing"
L18-1147,2012.eamt-1.60,0,0.0339438,"future work, we will explore sentence alignment methods to improve the quality of our corpus. We also plan to explore MT techniques for under-resourced language pairs such as pivoting, and domain adaptation from better resourced domains. 6. 4. Related Work Much work has been done on building multilingual parallel corpora which include the language pair of Arabic and Japanese. Table 8 summarizes the statistics of publicly available parallel corpora of this language pair. Lison and Tiedemann (2016) presents the largest corpus, in which they collected movie and TV subtitles from OpenSubtitles.11 Cettolo and Girardi (2012) constructed a parallel corpus that consists of transcribed and translated TED talks. Abdelali et al. (2014) developed the AMARA corpus 11 Acknowledgements This work has been partially funded by the Tobitate! (Leap for Tomorrow) Young Ambassador Program. Part of the work was done during the first author’s visit to New York University Abu Dhabi. The creation of translated articles has been carried out at Tokyo University of Foreign Studies. We are grateful to the contributors of the TUFS Media Project for providing translated articles. We thank the anonymous reviewers, Nasser Zalmout, Alexander"
L18-1147,W08-0509,0,0.0219614,"as approximately 3.4 million. This is much closer to the number of Japanese tokens, 3.7 million. Documents 4,253 1,854 811 608 330 280 244 194 48 15 10 5 8,652 Percentage 49.16 21.43 9.37 7.03 3.81 3.24 2.82 2.24 0.55 0.17 0.12 0.06 100.00 Table 4: Category distribution of our entire corpus. 3. Machine Translation Baselines In this section, we present the baseline results of phrasebased MT from Arabic to Japanese. 3.1. Experimental Settings Phrase-based MT Settings We use the Moses toolkit (Koehn et al., 2007) to build a standard phrasebased MT system. Word alignment was extracted by MGIZA++ (Gao and Vogel, 2008) with a maximum phrase size of 8. We use the grow-diag-final-and and msdbidirectional-fe options for symmetrization and reordering. We train a 5-gram language model on the target side of the training set using KenLM (Heafield, 2011). We use MERT (Och, 2003) for decoding weight optimization. Data and Preprocessing We use the manually aligned data described in Section 2.2.4. for tuning and testing, and the automatically aligned data using Gargantua described in Section 2.2.5. for training. We tokenize Arabic data using the MADAMIRA toolkit (Pasha et al., 2014) with six tokenization schemes (D0,"
L18-1147,W11-2123,0,0.0365625,"00 Table 4: Category distribution of our entire corpus. 3. Machine Translation Baselines In this section, we present the baseline results of phrasebased MT from Arabic to Japanese. 3.1. Experimental Settings Phrase-based MT Settings We use the Moses toolkit (Koehn et al., 2007) to build a standard phrasebased MT system. Word alignment was extracted by MGIZA++ (Gao and Vogel, 2008) with a maximum phrase size of 8. We use the grow-diag-final-and and msdbidirectional-fe options for symmetrization and reordering. We train a 5-gram language model on the target side of the training set using KenLM (Heafield, 2011). We use MERT (Och, 2003) for decoding weight optimization. Data and Preprocessing We use the manually aligned data described in Section 2.2.4. for tuning and testing, and the automatically aligned data using Gargantua described in Section 2.2.5. for training. We tokenize Arabic data using the MADAMIRA toolkit (Pasha et al., 2014) with six tokenization schemes (D0, D1, D2, D3, D3*, and ATB) following Zalmout and Habash (2017). Examples of the six tokenization schemes are shown in Table 1. We normalize Japanese texts using the NFKC normalization and tokenize them using the MeCab morphological a"
L18-1147,D10-1092,0,0.0227262,"e 1. We normalize Japanese texts using the NFKC normalization and tokenize them using the MeCab morphological analyzer (0.996) (Kudo, 2005) with IPAdic. We eliminate long sentences with more than 100 words using the script clean-corpus-n.perl before training translation models. Table 6 shows statistics of training data after cleaning. Evaluation Before evaluating, we de-tokenize the predicted output by deleting spaces between Japanese characters, and then re-tokenize them using MeCab with IPAdic. We calculate automatic evaluation scores for two metrics: BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010). We use the multi-bleu.perl script in the Moses toolkit to compute BLEU scores. We calculate RIBES scores using the RIBES.py (1.03.1.).10 10 http://www.kecl.ntt.co.jp/icl/lirg/ ribes/ 921 dev-tune dev-test blind-test train Total Documents 100 400 400 7,752 8,652 Sentences 621 2,393 2,236 59,238 64,488 Tokens (ar) 23,312 92,760 85,940 2,175,438 2,377,460 Tokens (ja) 36,595 147,536 144,358 3,403,244 3,731,733 Table 5: The basic statistics of our parallel corpus. Sentences in the training set are aligned using Gargantua. Tokenization D0 D1 D2 ATB D3 D3* Sentences 54,223 54,123 54,029 53,933 53,1"
L18-1147,P07-2045,0,0.00901545,"e to Japanese tokens. We ran MADAMIRA on our corpus to obtain the number of D3-tokenized tokens, which was approximately 3.4 million. This is much closer to the number of Japanese tokens, 3.7 million. Documents 4,253 1,854 811 608 330 280 244 194 48 15 10 5 8,652 Percentage 49.16 21.43 9.37 7.03 3.81 3.24 2.82 2.24 0.55 0.17 0.12 0.06 100.00 Table 4: Category distribution of our entire corpus. 3. Machine Translation Baselines In this section, we present the baseline results of phrasebased MT from Arabic to Japanese. 3.1. Experimental Settings Phrase-based MT Settings We use the Moses toolkit (Koehn et al., 2007) to build a standard phrasebased MT system. Word alignment was extracted by MGIZA++ (Gao and Vogel, 2008) with a maximum phrase size of 8. We use the grow-diag-final-and and msdbidirectional-fe options for symmetrization and reordering. We train a 5-gram language model on the target side of the training set using KenLM (Heafield, 2011). We use MERT (Och, 2003) for decoding weight optimization. Data and Preprocessing We use the manually aligned data described in Section 2.2.4. for tuning and testing, and the automatically aligned data using Gargantua described in Section 2.2.5. for training. We"
L18-1147,L16-1147,0,0.0198438,"3.7 million Japanese tokens. We also reported the first results of Arabic–Japanese phrase-based MT trained on our corpus. As future work, we will explore sentence alignment methods to improve the quality of our corpus. We also plan to explore MT techniques for under-resourced language pairs such as pivoting, and domain adaptation from better resourced domains. 6. 4. Related Work Much work has been done on building multilingual parallel corpora which include the language pair of Arabic and Japanese. Table 8 summarizes the statistics of publicly available parallel corpora of this language pair. Lison and Tiedemann (2016) presents the largest corpus, in which they collected movie and TV subtitles from OpenSubtitles.11 Cettolo and Girardi (2012) constructed a parallel corpus that consists of transcribed and translated TED talks. Abdelali et al. (2014) developed the AMARA corpus 11 Acknowledgements This work has been partially funded by the Tobitate! (Leap for Tomorrow) Young Ambassador Program. Part of the work was done during the first author’s visit to New York University Abu Dhabi. The creation of translated articles has been carried out at Tokyo University of Foreign Studies. We are grateful to the contribu"
L18-1147,P03-1021,0,0.0430365,"ion of our entire corpus. 3. Machine Translation Baselines In this section, we present the baseline results of phrasebased MT from Arabic to Japanese. 3.1. Experimental Settings Phrase-based MT Settings We use the Moses toolkit (Koehn et al., 2007) to build a standard phrasebased MT system. Word alignment was extracted by MGIZA++ (Gao and Vogel, 2008) with a maximum phrase size of 8. We use the grow-diag-final-and and msdbidirectional-fe options for symmetrization and reordering. We train a 5-gram language model on the target side of the training set using KenLM (Heafield, 2011). We use MERT (Och, 2003) for decoding weight optimization. Data and Preprocessing We use the manually aligned data described in Section 2.2.4. for tuning and testing, and the automatically aligned data using Gargantua described in Section 2.2.5. for training. We tokenize Arabic data using the MADAMIRA toolkit (Pasha et al., 2014) with six tokenization schemes (D0, D1, D2, D3, D3*, and ATB) following Zalmout and Habash (2017). Examples of the six tokenization schemes are shown in Table 1. We normalize Japanese texts using the NFKC normalization and tokenize them using the MeCab morphological analyzer (0.996) (Kudo, 20"
L18-1147,P02-1040,0,0.10982,"nization schemes are shown in Table 1. We normalize Japanese texts using the NFKC normalization and tokenize them using the MeCab morphological analyzer (0.996) (Kudo, 2005) with IPAdic. We eliminate long sentences with more than 100 words using the script clean-corpus-n.perl before training translation models. Table 6 shows statistics of training data after cleaning. Evaluation Before evaluating, we de-tokenize the predicted output by deleting spaces between Japanese characters, and then re-tokenize them using MeCab with IPAdic. We calculate automatic evaluation scores for two metrics: BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010). We use the multi-bleu.perl script in the Moses toolkit to compute BLEU scores. We calculate RIBES scores using the RIBES.py (1.03.1.).10 10 http://www.kecl.ntt.co.jp/icl/lirg/ ribes/ 921 dev-tune dev-test blind-test train Total Documents 100 400 400 7,752 8,652 Sentences 621 2,393 2,236 59,238 64,488 Tokens (ar) 23,312 92,760 85,940 2,175,438 2,377,460 Tokens (ja) 36,595 147,536 144,358 3,403,244 3,731,733 Table 5: The basic statistics of our parallel corpus. Sentences in the training set are aligned using Gargantua. Tokenization D0 D1 D2 ATB D3 D3* Sentences"
L18-1147,pasha-etal-2014-madamira,1,0.773483,"Missing"
L18-1147,L16-1144,0,0.0631373,"Missing"
L18-1147,C14-2019,0,0.0454772,"Missing"
L18-1147,tiedemann-2012-parallel,0,0.0405343,"t is understandable since Japanese also lacks the definite article. Tokenization D0 D1 D2 ATB D3 D3* dev-test BLEU RIBES 10.78 56.61 10.70 56.90 11.13 56.94 11.29 57.54 10.53 56.80 11.48 57.86 blind-test BLEU RIBES 8.76 55.71 8.83 55.63 9.34 56.08 9.24 56.41 8.56 55.77 9.38 56.63 Table 7: BLEU and RIBES scores of Arabic–Japanese PBMT systems with different tokenization schemes in the source side. that includes subtitles of educational video lectures on Massive Online Open Courses (MOOCs). Christodouloupoulos and Steedman (2015) presents a collection of Bible translations across 100 languages. Tiedemann (2012) provides a collection of Quran translations (Tanzil), localization files of technical manuals (GNOME, Ubuntu, and KDE4), as well as the collections of translations in the news domain (Global Voices, Tatoeba, News-Commentary 11). Prokopidis et al. (2016) constructed parallel corpora from Global Voices similar to Tiedemann (2012). Compared to the domains such as subtitles, religious texts, and technical manuals, the amount of data in the news domain is very limited. Our corpus aims to supplement the lack of parallel data in this domain by constructing a parallel corpus with over 64,000 sentence"
L18-1147,vondricka-2014-aligning,0,0.0393118,"Missing"
L18-1345,P09-2056,1,0.753922,"me great features but also lack key features which do not make them completely suitable for annotating MRLs. In particular, changing the tokenization of a word is not easy to do in these systems. We discuss these tools next to highlight their advantages and shortcomings. TrEd (Pajas and Štˇepánek, 2008) is a graph visualization and manipulation program written in Perl. It has been used as an annotation tool for several treebank projects, including the Prague Dependency Treebank (Böhmová et al., 2003), Prague Arabic Dependency Treebank (Hajic et al., 2004) and Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). It supports macros to automate frequently repeated operations and has a substantial number of features. It can be unintuitive at times and difficult to learn; thus, it may not be a good choice for less experienced annotators. A notable limitation of TrEd is that it is a standalone application and thus cannot be run through a webbrowser. PALMYRA is designed to run in web browsers, 2185 ID 1 2 3 4 making it simple to use and appropriate for web-based annotation tasks. TrEd does not provide any simple option for word tokenization. BRAT (Stenetorp et al., 2012) is a web-based annotation tool wit"
L18-1345,L16-1371,0,0.639757,"T is slow when processing documents of more than 100 sentences and has limited support for different file formats. It also does not allow for web-based configuration of tag sets. WebAnno (Yimam et al., 2013) is also another generalpurpose web-based annotation tool mainly meant for distributed teams. To visualize the text and annotations, it uses the JavaScript based annotation visualization from BRAT, thus facing the same display issues. WebAnno supports type specification through the import/export of tag sets. Similar to TrEd, WebAnno and BRAT have no support for word tokenization. EasyTree (Little and Tratz, 2016) is a light-weight tool designed for annotating dependency trees in browsers. It is limited to a front-end only and does not provide any interface to integrate parsers for pre-annotation. EasyTree has multiple intuitive features, such as color-coded part-ofspeech (POS) indicators and optional translation displays. EasyTree allows the customization of POS tags but does not maintain sentence order of nodes. It has no functionality for splitting or merging of words. PALMYRA’s design is highly influenced by EasyTree and uses some of its code. 4. PALMYRA Design Specifications Design and Implementat"
L18-1345,J93-2004,0,0.0650416,"ntactic annotation of morphologically rich languages, especially regarding easy change of morphological tokenization through edits, additions, deletions, splits and merges of words. PALMYRA uses an intuitive dragand-drop interface for editing tree structures, and provides pop-up boxes and keyboard shortcuts for part-of-speech and link label tagging. Keywords: Annotation, Interfaces, Syntax, Morphologically Rich Languages 1. Introduction 2. Producing high-quality natural language syntactic annotation is expensive. Well-known large-scale syntactic annotation projects, such as the Penn Treebank (Marcus et al., 1993) and the Prague Dependency Treebank (Böhmová et al., 2003), relied on expert linguists to produce carefully annotated data. This process is rather costly, and as a result, such annotation projects have been undertaken for only a handful of important languages. Efficient annotation tools play an important role in lowering treebank development costs and enabling the creation of larger, higher quality treebanks. The typical approach is to automatically create syntactic annotations, which are then manually corrected. In this scenario, a goal of the annotation tool is to lower the annotation burden"
L18-1345,C08-1085,0,0.0684579,"Missing"
L18-1345,C16-2048,1,0.862328,"tps://camel.abudhabi. nyu.edu/palmyra/. 5 6 7 8 9 Figure Word +ð ÕË ÕæK ÈA® J«@ Yg @ +H . I.k  Ë@ é£Qå . 1: POS PRT PRT VRB NOM Parent 3 3 0 3 Relation MOD MOD --SBJ NOM PRT NOM NOM PNX 4 3 6 7 3 IDF MOD OBJ IDF MOD The tree for the sentence wlm ytm AςtqAl ÂHd bHsb AlšrT¯h ‘and no one was arrested according to the police.”  Ë@ Im&apos; Yg @ ÈA® J«@ ÕæK ÕËð é£Qå . . are tokenized according to the Penn Arabic Treebank tokenization scheme (Maamouri et al., 2004), but other Arabic tokenization schemes can be used just the same (Habash, 2010). The format shown is produced by CamelParser (Shahrour et al., 2016). PALMYRA also accepts sentences for input when annotating from scratch. Every input line is considered as a separate tree. It tokenizes a sentence on spaces, and assumes all nodes are siblings under the root with default POS tag and link labels. Output Files PALMYRA has two output formats: the dependency format discussed above, and PNG image. Configuration File PALMYRA takes as input an optional configuration file, which specifies the various configuration and annotation options for the tool. The config files consist of key-value pairs, each specifying a property of the editor. The most impor"
L18-1345,E12-2021,0,0.223224,"Missing"
L18-1345,P13-4001,0,0.165724,"Missing"
L18-1366,abdul-mageed-diab-2012-awatif,0,0.0208954,"solve ambiguity from experience and context in readings where diacritics are often partial or omitted. Corpora in Arabic have predominantly been collected from news data to serve as general purpose text for NLP applications (Habash, 2010; Zaghouani, 2014). In recent years, the various dialects of Arabic began receiving more attention (Shoufan and Al-Ameri, 2015; Khalifa et al., 2016; Jarrar et al., 2016). Specialized corpora have also been released for various NLP applications such as machine translation (Ziemski et al., 2016), plagiarism detection (Bensalem et al., 2013), sentiment analysis (Abdul-Mageed and Diab, 2012), and error correction (Alfaifi et al., 2013; Zaghouani et al., 2014) to name a few. High-resource languages, on the other hand, have enjoyed a wider variety of specialized corpora, including data for pedagogical and educational applications (Pravec, 2002; Braun et al., 2006; Laufer and Ravenhorst-Kalovski, 2010). Also, recently reignited interest in text readability assessment as a computational task has encouraged more work in the creation of curricular and pedagogical corpora (Collins-Thompson, 2014; François, 2014; Volodina et al., 2014; Zalmout et al., 2016). Budding research in computati"
L18-1366,W14-3502,0,0.0294972,"giarism detection (Bensalem et al., 2013), sentiment analysis (Abdul-Mageed and Diab, 2012), and error correction (Alfaifi et al., 2013; Zaghouani et al., 2014) to name a few. High-resource languages, on the other hand, have enjoyed a wider variety of specialized corpora, including data for pedagogical and educational applications (Pravec, 2002; Braun et al., 2006; Laufer and Ravenhorst-Kalovski, 2010). Also, recently reignited interest in text readability assessment as a computational task has encouraged more work in the creation of curricular and pedagogical corpora (Collins-Thompson, 2014; François, 2014; Volodina et al., 2014; Zalmout et al., 2016). Budding research in computational readability for MSA has led to the creation of leveled corpora from curriculum texts. For instance, a corpus of 150 texts from the Saudi Arabian (KSA) curriculum labeled with [easy, intermediate, difficult] (Al-Khalifa and Al-Ajlan, 2010), and a corpus of 1196 texts totaling 400K words from the Jordanian curriculum (Al Tamimi et al., 2014). To the best of our knowledge, a corpus at the scale of the curricular data collected in our work (1.4M tokens) has yet to be released. 2317 Grade 2 Grade 7"
L18-1366,L16-1679,1,0.85805,"osition of clitics (Habash, 2010). Then, there is the challenge of resolving ambiguity due to its writing system with optional diacritics. While it is common to see fully diacritized texts for children, older readers are expected to resolve ambiguity from experience and context in readings where diacritics are often partial or omitted. Corpora in Arabic have predominantly been collected from news data to serve as general purpose text for NLP applications (Habash, 2010; Zaghouani, 2014). In recent years, the various dialects of Arabic began receiving more attention (Shoufan and Al-Ameri, 2015; Khalifa et al., 2016; Jarrar et al., 2016). Specialized corpora have also been released for various NLP applications such as machine translation (Ziemski et al., 2016), plagiarism detection (Bensalem et al., 2013), sentiment analysis (Abdul-Mageed and Diab, 2012), and error correction (Alfaifi et al., 2013; Zaghouani et al., 2014) to name a few. High-resource languages, on the other hand, have enjoyed a wider variety of specialized corpora, including data for pedagogical and educational applications (Pravec, 2002; Braun et al., 2006; Laufer and Ravenhorst-Kalovski, 2010). Also, recently reignited interest in text"
L18-1366,pasha-etal-2014-madamira,1,0.900514,"Missing"
L18-1366,W15-3205,0,0.016913,"ectional range and rich composition of clitics (Habash, 2010). Then, there is the challenge of resolving ambiguity due to its writing system with optional diacritics. While it is common to see fully diacritized texts for children, older readers are expected to resolve ambiguity from experience and context in readings where diacritics are often partial or omitted. Corpora in Arabic have predominantly been collected from news data to serve as general purpose text for NLP applications (Habash, 2010; Zaghouani, 2014). In recent years, the various dialects of Arabic began receiving more attention (Shoufan and Al-Ameri, 2015; Khalifa et al., 2016; Jarrar et al., 2016). Specialized corpora have also been released for various NLP applications such as machine translation (Ziemski et al., 2016), plagiarism detection (Bensalem et al., 2013), sentiment analysis (Abdul-Mageed and Diab, 2012), and error correction (Alfaifi et al., 2013; Zaghouani et al., 2014) to name a few. High-resource languages, on the other hand, have enjoyed a wider variety of specialized corpora, including data for pedagogical and educational applications (Pravec, 2002; Braun et al., 2006; Laufer and Ravenhorst-Kalovski, 2010). Also, recently reig"
L18-1366,volodina-etal-2014-flexible,0,0.029359,"n (Bensalem et al., 2013), sentiment analysis (Abdul-Mageed and Diab, 2012), and error correction (Alfaifi et al., 2013; Zaghouani et al., 2014) to name a few. High-resource languages, on the other hand, have enjoyed a wider variety of specialized corpora, including data for pedagogical and educational applications (Pravec, 2002; Braun et al., 2006; Laufer and Ravenhorst-Kalovski, 2010). Also, recently reignited interest in text readability assessment as a computational task has encouraged more work in the creation of curricular and pedagogical corpora (Collins-Thompson, 2014; François, 2014; Volodina et al., 2014; Zalmout et al., 2016). Budding research in computational readability for MSA has led to the creation of leveled corpora from curriculum texts. For instance, a corpus of 150 texts from the Saudi Arabian (KSA) curriculum labeled with [easy, intermediate, difficult] (Al-Khalifa and Al-Ajlan, 2010), and a corpus of 1196 texts totaling 400K words from the Jordanian curriculum (Al Tamimi et al., 2014). To the best of our knowledge, a corpus at the scale of the curricular data collected in our work (1.4M tokens) has yet to be released. 2317 Grade 2 Grade 7                , èQ ºJ"
L18-1366,zaghouani-etal-2014-large,1,0.952941,"data for natural language processing (NLP) applications. Continued efforts in creating such resources are instrumental in furthering research for all application domains of NLP, namely, parsing and part-of-speech (POS) tagging, speech recognition, machine translation, document classification, etc. Work in NLP for Modern Standard Arabic (MSA) is gaining momentum as more resources and tools are developed (Habash, 2010). Corpus data for MSA has been mostly sourced from the news genre (Zaghouani, 2014), while there are far fewer specialized resources, such as corpora for educational applications (Zaghouani et al., 2014; Alfaifi et al., 2013). As a particular type of educational resource, a level-annotated reading corpus can be leveraged for a multitude of applications: text simplification, automatic readability assessment, computer-assisted language learning, data-driven pedagogy, text genre and register profiling, and so on. Building a corpus of this nature contributes to the variety of resources at our disposal, allowing for research in Arabic NLP to progress in new directions. In this paper, we present a reading corpus in MSA collected from textbooks of the United Arab Emirates (UAE) curriculum and a col"
L18-1366,W16-4916,1,0.517987,"3), sentiment analysis (Abdul-Mageed and Diab, 2012), and error correction (Alfaifi et al., 2013; Zaghouani et al., 2014) to name a few. High-resource languages, on the other hand, have enjoyed a wider variety of specialized corpora, including data for pedagogical and educational applications (Pravec, 2002; Braun et al., 2006; Laufer and Ravenhorst-Kalovski, 2010). Also, recently reignited interest in text readability assessment as a computational task has encouraged more work in the creation of curricular and pedagogical corpora (Collins-Thompson, 2014; François, 2014; Volodina et al., 2014; Zalmout et al., 2016). Budding research in computational readability for MSA has led to the creation of leveled corpora from curriculum texts. For instance, a corpus of 150 texts from the Saudi Arabian (KSA) curriculum labeled with [easy, intermediate, difficult] (Al-Khalifa and Al-Ajlan, 2010), and a corpus of 1196 texts totaling 400K words from the Jordanian curriculum (Al Tamimi et al., 2014). To the best of our knowledge, a corpus at the scale of the curricular data collected in our work (1.4M tokens) has yet to be released. 2317 Grade 2 Grade 7                , èQ ºJ . Ó AêÓ ñ K áÓ ñj ,A"
L18-1366,L16-1561,0,0.0200388,"t is common to see fully diacritized texts for children, older readers are expected to resolve ambiguity from experience and context in readings where diacritics are often partial or omitted. Corpora in Arabic have predominantly been collected from news data to serve as general purpose text for NLP applications (Habash, 2010; Zaghouani, 2014). In recent years, the various dialects of Arabic began receiving more attention (Shoufan and Al-Ameri, 2015; Khalifa et al., 2016; Jarrar et al., 2016). Specialized corpora have also been released for various NLP applications such as machine translation (Ziemski et al., 2016), plagiarism detection (Bensalem et al., 2013), sentiment analysis (Abdul-Mageed and Diab, 2012), and error correction (Alfaifi et al., 2013; Zaghouani et al., 2014) to name a few. High-resource languages, on the other hand, have enjoyed a wider variety of specialized corpora, including data for pedagogical and educational applications (Pravec, 2002; Braun et al., 2006; Laufer and Ravenhorst-Kalovski, 2010). Also, recently reignited interest in text readability assessment as a computational task has encouraged more work in the creation of curricular and pedagogical corpora (Collins-Thompson, 2"
L18-1415,W15-3206,0,0.310868,"tactic annotation and morphological tokenization for Arabic. In general, many of these existing tools are not designed to handle the peculiarities of dialectal Arabic. They neither provide facilities for managing thousands of documents nor permit the distribution of tasks to tens of annotators, including managing inter-annotator agreement (IAA) tasks. Our interface borrows ideas from three other existing annotation tools: DIWAN, QAWI, and MANDIAC. Here we describe each of these tools and how they have influenced the design of our system. DIWAN is an annotation tool for Arabic dialectal texts (Al-Shargi and Rambow, 2015). It provides annotators with a set of tools for reducing duplicate effort including the use of morphological analyzers to pre-compute analyses, and the ability to apply analyses to multiple occurrences simultaneously. However, it requires installation on a Windows machine and the user interface is not very friendly to newcomers. QAWI (the QALB Annotation Web Interface) was used for token-based text editing to create raw and and text corrected parallel data for automatic text correction tasks (Obeid et al., 2013; Zaghouani et al., 2014; Zaghouani et al., 2015; Zaghouani et al., 2016). It suppo"
L18-1415,L16-1646,0,0.0160278,"al. (2012), Stymne (2011), Llitjós and Carbonell (2004), and Dickinson and Ledbetter (2012). For Arabic, there are several existing annotation tools, however, they are designed to handle specific NLP tasks and are not easy to adapt to our project. Examples include tools for semantic annotation such as the work of Saleh and Al-Khalifa (2009) and El-ghobashy et al. (2014), 2616 3 ¯⌦ P@Y” madAriy means ‘my orbit’ in Arabic. and the work on dialect annotation by Benajiba and Diab (2010) and Diab et al. (2010). Attia et al. (2009) built a morphological annotation tool. Recently, Al-Twairesh et al. (2016) introduced MADAD, a general-purpose online collaborative annotation tool for readability assessments project in Arabic. In the COLABA initiative (Diab et al., 2010), the authors built tools and resources to process Arabic social media data such as blogs, discussion forums, and chats. Javed et al. (2018) presented an online interface for joint syntactic annotation and morphological tokenization for Arabic. In general, many of these existing tools are not designed to handle the peculiarities of dialectal Arabic. They neither provide facilities for managing thousands of documents nor permit the"
L18-1415,aziz-etal-2012-pet,0,0.0188875,"Missing"
L18-1415,dickinson-ledbetter-2012-annotating,0,0.0264408,"of our annotation framework. In Section 4. and Section 5., we discuss the annotation and management interfaces, respectively. We finally describe a user study of working with MADARi in Section 6. 2. Related Work Several annotation tools and interfaces were proposed for many languages and to achieve various annotation tasks. Some are general purpose annotation tools, such as BRAT (Stenetorp et al., 2012) and WebAnno (Yimam et al., 2013). Task-specific annotation tools for post-editing and error correction include the work of Aziz et al. (2012), Stymne (2011), Llitjós and Carbonell (2004), and Dickinson and Ledbetter (2012). For Arabic, there are several existing annotation tools, however, they are designed to handle specific NLP tasks and are not easy to adapt to our project. Examples include tools for semantic annotation such as the work of Saleh and Al-Khalifa (2009) and El-ghobashy et al. (2014), 2616 3 ¯⌦ P@Y” madAriy means ‘my orbit’ in Arabic. and the work on dialect annotation by Benajiba and Diab (2010) and Diab et al. (2010). Attia et al. (2009) built a morphological annotation tool. Recently, Al-Twairesh et al. (2016) introduced MADAD, a general-purpose online collaborative annotation tool for readabi"
L18-1415,L18-1574,1,0.916519,"the word i.J⌦ mÃ '@AÎÒK. AK⌦  wyAbwhAAlxlyj1 involves two spelling errors2 (a word merge and character replacement) which can be corrected as i.J⌦ mÃ '@ AÎÒK. Ag.  wjAbwhA Alxlyj ‘and they brought it to the Gulf’. Furthermore, the first of the two corrected words includes two clitics that when segmented produce the form: AÎ+ @ÒK. Ag. +  w+ jAbwA +hA ‘and+ they-brought +it’. 1 Transliterations are in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007). 2 Since Arabic dialects do not have a standard orthography, spelling correction here means to conventionalize as per the CODA standard (Habash et al., 2018). Previous work on Arabic morphology annotation interfaces focused either on the problem of manual annotations for POS tagging (Maamouri et al., 2014), or diacritization (Obeid et al., 2016), or spelling correction (Obeid et al., 2013). In this paper we present a tool that allows doing all of these tasks together, eliminating the possibility of error propagation from one annotation level to another. Our tool is named MADARi3 after the project under which it was created: Multi-Arabic Dialect Annotations and Resources (Bouamor et al., 2018). The remainder of this paper is structured as follows:"
L18-1415,L18-1345,1,0.571093,"on such as the work of Saleh and Al-Khalifa (2009) and El-ghobashy et al. (2014), 2616 3 ¯⌦ P@Y” madAriy means ‘my orbit’ in Arabic. and the work on dialect annotation by Benajiba and Diab (2010) and Diab et al. (2010). Attia et al. (2009) built a morphological annotation tool. Recently, Al-Twairesh et al. (2016) introduced MADAD, a general-purpose online collaborative annotation tool for readability assessments project in Arabic. In the COLABA initiative (Diab et al., 2010), the authors built tools and resources to process Arabic social media data such as blogs, discussion forums, and chats. Javed et al. (2018) presented an online interface for joint syntactic annotation and morphological tokenization for Arabic. In general, many of these existing tools are not designed to handle the peculiarities of dialectal Arabic. They neither provide facilities for managing thousands of documents nor permit the distribution of tasks to tens of annotators, including managing inter-annotator agreement (IAA) tasks. Our interface borrows ideas from three other existing annotation tools: DIWAN, QAWI, and MANDIAC. Here we describe each of these tools and how they have influenced the design of our system. DIWAN is an"
L18-1415,L18-1607,1,0.939775,"al., 2018). MANDIAC utilized the token-based editor used in QAWI to perform text diacritization tasks (Obeid et al., 2016). More importantly, it introduced a flexible hybrid data storage system that allows for adding new features to the annotation front-end with little to no modifications to the back-end. MADARi utilizes this design to provide the same utility. 3. MADARi Design The MADARi interface is designed to be used by human annotators to create a morphologically annotated corpus of Arabic text. The text we work with comes from social media and is highly dialectal (Bouamor et al., 2018; Khalifa et al., 2018) and has numerous spelling errors. The annotators will carefully correct the spelling of the words and also annotate their morphology. The in-context morphology annotation includes tokenization, POS tagging, lemmatization and English glossing. 3.1. Desiderata In order to manage and process the annotation of the large scale dialectal Arabic corpus, we needed to create a tool to streamline the annotation process. The desiderata for developing the MADARi annotation tool include the following: • The tool must have very minimal requirements on the annotators. • The tool must allow off-site data man"
L18-1415,font-llitjos-carbonell-2004-translation,0,0.0249819,"iscuss the design and architecture of our annotation framework. In Section 4. and Section 5., we discuss the annotation and management interfaces, respectively. We finally describe a user study of working with MADARi in Section 6. 2. Related Work Several annotation tools and interfaces were proposed for many languages and to achieve various annotation tasks. Some are general purpose annotation tools, such as BRAT (Stenetorp et al., 2012) and WebAnno (Yimam et al., 2013). Task-specific annotation tools for post-editing and error correction include the work of Aziz et al. (2012), Stymne (2011), Llitjós and Carbonell (2004), and Dickinson and Ledbetter (2012). For Arabic, there are several existing annotation tools, however, they are designed to handle specific NLP tasks and are not easy to adapt to our project. Examples include tools for semantic annotation such as the work of Saleh and Al-Khalifa (2009) and El-ghobashy et al. (2014), 2616 3 ¯⌦ P@Y” madAriy means ‘my orbit’ in Arabic. and the work on dialect annotation by Benajiba and Diab (2010) and Diab et al. (2010). Attia et al. (2009) built a morphological annotation tool. Recently, Al-Twairesh et al. (2016) introduced MADAD, a general-purpose online colla"
L18-1415,maamouri-etal-2014-developing,1,0.844143,"mÃ '@ AÎÒK. Ag.  wjAbwhA Alxlyj ‘and they brought it to the Gulf’. Furthermore, the first of the two corrected words includes two clitics that when segmented produce the form: AÎ+ @ÒK. Ag. +  w+ jAbwA +hA ‘and+ they-brought +it’. 1 Transliterations are in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007). 2 Since Arabic dialects do not have a standard orthography, spelling correction here means to conventionalize as per the CODA standard (Habash et al., 2018). Previous work on Arabic morphology annotation interfaces focused either on the problem of manual annotations for POS tagging (Maamouri et al., 2014), or diacritization (Obeid et al., 2016), or spelling correction (Obeid et al., 2013). In this paper we present a tool that allows doing all of these tasks together, eliminating the possibility of error propagation from one annotation level to another. Our tool is named MADARi3 after the project under which it was created: Multi-Arabic Dialect Annotations and Resources (Bouamor et al., 2018). The remainder of this paper is structured as follows: we present work related to this effort in Section 2. In Section 3., we discuss the design and architecture of our annotation framework. In Section 4."
L18-1415,I13-2001,1,0.898118,"st of the two corrected words includes two clitics that when segmented produce the form: AÎ+ @ÒK. Ag. +  w+ jAbwA +hA ‘and+ they-brought +it’. 1 Transliterations are in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007). 2 Since Arabic dialects do not have a standard orthography, spelling correction here means to conventionalize as per the CODA standard (Habash et al., 2018). Previous work on Arabic morphology annotation interfaces focused either on the problem of manual annotations for POS tagging (Maamouri et al., 2014), or diacritization (Obeid et al., 2016), or spelling correction (Obeid et al., 2013). In this paper we present a tool that allows doing all of these tasks together, eliminating the possibility of error propagation from one annotation level to another. Our tool is named MADARi3 after the project under which it was created: Multi-Arabic Dialect Annotations and Resources (Bouamor et al., 2018). The remainder of this paper is structured as follows: we present work related to this effort in Section 2. In Section 3., we discuss the design and architecture of our annotation framework. In Section 4. and Section 5., we discuss the annotation and management interfaces, respectively. We"
L18-1415,pasha-etal-2014-madamira,1,0.866692,"al., 2016). In particular, we utilized the client-server architecture, as well as the flexible hybrid SQL/JSON storage system used by MANDIAC. This allows us to easily extend our annotation interface with minor changes, if any, to the back-end. Our system stores documents one sentence per row, unlike MANDIAC which stores one document per row. This modification allows the annotation interface to handle larger file sizes without affecting its performance by only overwriting the JSON of the modified sentences and not that of the entire document. Like, DIWAN and MANDIAC, we also utilize MADAMIRA (Pasha et al., 2014), a morphological analyzer and disambiguator for Arabic to pre-compute analyses. 4. Annotation Interface The annotation interface (illustrated in Figures 1 to 4) is where annotators perform the annotation tasks assigned to them. Here we describe the different components and utilities provided this interface. 4.1. Task Overview When starting an annotation session, annotators are first shown the “Task Overview” screen (Figure 1). Here annotators can see information on the size of the current task and their progress so far (Figure 1a). The sentence list can be filtered to contain sentences matchi"
L18-1415,E12-2021,0,0.168509,"Missing"
L18-1415,P11-4010,0,0.0125903,"ection 3., we discuss the design and architecture of our annotation framework. In Section 4. and Section 5., we discuss the annotation and management interfaces, respectively. We finally describe a user study of working with MADARi in Section 6. 2. Related Work Several annotation tools and interfaces were proposed for many languages and to achieve various annotation tasks. Some are general purpose annotation tools, such as BRAT (Stenetorp et al., 2012) and WebAnno (Yimam et al., 2013). Task-specific annotation tools for post-editing and error correction include the work of Aziz et al. (2012), Stymne (2011), Llitjós and Carbonell (2004), and Dickinson and Ledbetter (2012). For Arabic, there are several existing annotation tools, however, they are designed to handle specific NLP tasks and are not easy to adapt to our project. Examples include tools for semantic annotation such as the work of Saleh and Al-Khalifa (2009) and El-ghobashy et al. (2014), 2616 3 ¯⌦ P@Y” madAriy means ‘my orbit’ in Arabic. and the work on dialect annotation by Benajiba and Diab (2010) and Diab et al. (2010). Attia et al. (2009) built a morphological annotation tool. Recently, Al-Twairesh et al. (2016) introduced MADAD,"
L18-1415,P13-4001,0,0.0513893,"Missing"
L18-1415,zaghouani-etal-2014-large,1,0.850041,"WAN is an annotation tool for Arabic dialectal texts (Al-Shargi and Rambow, 2015). It provides annotators with a set of tools for reducing duplicate effort including the use of morphological analyzers to pre-compute analyses, and the ability to apply analyses to multiple occurrences simultaneously. However, it requires installation on a Windows machine and the user interface is not very friendly to newcomers. QAWI (the QALB Annotation Web Interface) was used for token-based text editing to create raw and and text corrected parallel data for automatic text correction tasks (Obeid et al., 2013; Zaghouani et al., 2014; Zaghouani et al., 2015; Zaghouani et al., 2016). It supported the exact recording of all modifications performed by the annotator which previous tools did not. We utilize this token-based editing system for minor text corrections that transform text of a given dialect into the appropriate CODA orthography (Habash et al., 2018). MANDIAC utilized the token-based editor used in QAWI to perform text diacritization tasks (Obeid et al., 2016). More importantly, it introduced a flexible hybrid data storage system that allows for adding new features to the annotation front-end with little to no modi"
L18-1415,W15-1614,1,0.860721,"l for Arabic dialectal texts (Al-Shargi and Rambow, 2015). It provides annotators with a set of tools for reducing duplicate effort including the use of morphological analyzers to pre-compute analyses, and the ability to apply analyses to multiple occurrences simultaneously. However, it requires installation on a Windows machine and the user interface is not very friendly to newcomers. QAWI (the QALB Annotation Web Interface) was used for token-based text editing to create raw and and text corrected parallel data for automatic text correction tasks (Obeid et al., 2013; Zaghouani et al., 2014; Zaghouani et al., 2015; Zaghouani et al., 2016). It supported the exact recording of all modifications performed by the annotator which previous tools did not. We utilize this token-based editing system for minor text corrections that transform text of a given dialect into the appropriate CODA orthography (Habash et al., 2018). MANDIAC utilized the token-based editor used in QAWI to perform text diacritization tasks (Obeid et al., 2016). More importantly, it introduced a flexible hybrid data storage system that allows for adding new features to the annotation front-end with little to no modifications to the back-en"
L18-1415,L16-1295,1,0.845639,"exts (Al-Shargi and Rambow, 2015). It provides annotators with a set of tools for reducing duplicate effort including the use of morphological analyzers to pre-compute analyses, and the ability to apply analyses to multiple occurrences simultaneously. However, it requires installation on a Windows machine and the user interface is not very friendly to newcomers. QAWI (the QALB Annotation Web Interface) was used for token-based text editing to create raw and and text corrected parallel data for automatic text correction tasks (Obeid et al., 2013; Zaghouani et al., 2014; Zaghouani et al., 2015; Zaghouani et al., 2016). It supported the exact recording of all modifications performed by the annotator which previous tools did not. We utilize this token-based editing system for minor text corrections that transform text of a given dialect into the appropriate CODA orthography (Habash et al., 2018). MANDIAC utilized the token-based editor used in QAWI to perform text diacritization tasks (Obeid et al., 2016). More importantly, it introduced a flexible hybrid data storage system that allows for adding new features to the annotation front-end with little to no modifications to the back-end. MADARi utilizes this d"
L18-1535,W14-1604,1,0.907171,"t. • Think of more than one translation into his/her dialect and carefully specify the city. • Use external informants to get more information for cities in his/her area if it is not his original city. • Enter the CODA and CAPHI versions of each entry, using the guidelines provided. Very recently, automatic DA processing has attracted a considerable amount of research in NLP (Shoufan and Alameri, 2015), facilitated by the newly developed monolingual and multilingual dialectal corpora and lexicons. Several mono-dialectal corpora covering different Arabic dialects were built and made available. Al-Badrashiny et al. (2014) compiled a large dialect-identified corpus of DA from several Egyptian sources, but with a large presence of MSA. In a related effort, McNeil and Faiza (2011) built a four-million-word corpus of Tunisian Spoken Arabic. Various other research work resulted in multidialectal non parallel corpora at different scales (Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Shargi et al., 2016; Zaghouani and Charfi, 2018). 10 The latest version of the lexicon is available for browsing online at http://nlp.qatar.cmu.edu/ma"
L18-1535,L16-1207,1,0.824624,"lectal corpora and lexicons. Several mono-dialectal corpora covering different Arabic dialects were built and made available. Al-Badrashiny et al. (2014) compiled a large dialect-identified corpus of DA from several Egyptian sources, but with a large presence of MSA. In a related effort, McNeil and Faiza (2011) built a four-million-word corpus of Tunisian Spoken Arabic. Various other research work resulted in multidialectal non parallel corpora at different scales (Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Shargi et al., 2016; Zaghouani and Charfi, 2018). 10 The latest version of the lexicon is available for browsing online at http://nlp.qatar.cmu.edu/madar/. 3393 As for dialect-to-dialect parallel corpora, Bouamor et al. (2014) presented the first small-scale 7-way parallel corpus covering several dialects in addition to MSA, and English, all translated from Egyptian sentences. The fact that Egyptian was chosen as a starting point affected the quality of the translation. The sentences produced were biased by the use of some Egyptian expressions that might be accepted in other dialects, but a native would not prod"
L18-1535,bouamor-etal-2014-multidialectal,1,0.953924,"cities has 12,000 sentences that are five-way parallel translations, and that could be used to build several Dialectal Arabic NLP applications such as machine translation. An example of a 28-way parallel sentences extracted from C ORPUS -25 is given in Figure 1.5 Translators, identified from each of the 25 cities specifically, were asked to read a set of sentences provided in English or French, and translate them into their dialects. The translators are all native speakers of the dialects of the cities they hail from. We did not choose MSA as a starting point to avoid biasing the translation (Bouamor et al., 2014). 6 4 The English, French and MSA versions we use are those provided in the IWSLT evaluation campaign (Eck and Hori, 2005). 5 The MADAR Corpus is available for browsing online at http://nlp.qatar.cmu.edu/madar/. 6 The translation was handled by Ramitechs (http://www. ramitechs.com/), a company that creates and annotates several types of corpora and lexicons using expert linguists. 3388 English French MSA Beirut Cairo Doha Rabat Tunis Aleppo Alexandria Algiers Amman Aswan Baghdad Basra Benghazi Damascus Fes Jeddah Jerusalem Khartoum Mosul Muscat This room is too small. Cette chambre est trop pe"
L18-1535,cotterell-callison-burch-2014-multi,0,0.122726,"ri, 2015), facilitated by the newly developed monolingual and multilingual dialectal corpora and lexicons. Several mono-dialectal corpora covering different Arabic dialects were built and made available. Al-Badrashiny et al. (2014) compiled a large dialect-identified corpus of DA from several Egyptian sources, but with a large presence of MSA. In a related effort, McNeil and Faiza (2011) built a four-million-word corpus of Tunisian Spoken Arabic. Various other research work resulted in multidialectal non parallel corpora at different scales (Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Shargi et al., 2016; Zaghouani and Charfi, 2018). 10 The latest version of the lexicon is available for browsing online at http://nlp.qatar.cmu.edu/madar/. 3393 As for dialect-to-dialect parallel corpora, Bouamor et al. (2014) presented the first small-scale 7-way parallel corpus covering several dialects in addition to MSA, and English, all translated from Egyptian sentences. The fact that Egyptian was chosen as a starting point affected the quality of the translation. The sentences produced were biased by the use of some Egyptian expressions tha"
L18-1535,W14-3629,0,0.0380058,"these differences. Phonology An example of phonological differences is in the pronunciation of dialectal words whose MSA cog nate has the letter Qaf (  q).2 It is often observed that in Tunisian Arabic, this consonant appears as /q/ (similar to MSA), while in Egyptian and Levantine Arabic it is /P/ (glottal stop) and in Gulf Arabic it is /g/ (Haeri, 1991; Habash, 2010). Orthography While MSA has a standard orthography, the dialects do not. Often people write words reflecting the phonology or the etymology of these words. DA is sometimes written in the so-called Arabizi Romanization script (Darwish, 2014). In the context of NLP, a set of conventional orthography guidelines (CODA) has been proposed for a number of dialects (Habash et al., 2012a; Jar2 Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007): (in alphabetical orˇ der) AbtθjHxdðrzsšSDTDςγfqklmnhwy and the additional sym   ˇ ¯ ˆ ð', yˆ ø , ¯ bols: ’ Z, Â @, A @, A @, w h è, ý ø. 3387 Region Maghreb Sub-region Morocco Algeria Tunisia Cities Rabat Algiers Tunis (RAB) (ALG) (TUN) Fes Sfax (FES) (SFX) Libya Tripoli (TRI) Benghazi (BEN) Nile Basin Egypt/Sudan Cairo (CAI) Alexandria (ALX) Aswan (AS"
L18-1535,diab-etal-2014-tharwa,1,0.957896,"itten language of informal communication online in the Arab World: in emails, blogs, discussion forums, chats, SMS, etc. There has been a rising interest in research on computational models of Arabic dialects in the last decade (Meftouh et al., 2015). There have been several efforts on creating different resources to allow building models for several Natural Language Processing (NLP) applications. However, these efforts have been disjoint from each other, and most of them have focused on a small number of dialects that represent vast regions of the Arab World (Zaidan and Callison-Burch, 2011; Diab et al., 2014; Sajjad et al., 2013). In this paper, we present two resources we created as part of the Multi Arabic Dialect Applications and Resources (MADAR) project.1 The goal of MADAR is to create, for a large number of dialects, a unified framework with common annotation guidelines and decisions, and targeting applications of Dialect Identification (DID) and Machine Translation (MT). The first resource is a large parallel corpus of 25 Arabic city dialects, in addition to the pre-existing parallel set for English, French and Modern Standard Arabic (MSA). The second resource is a 25-way lexicon of 1,045"
L18-1535,habash-etal-2012-conventional,1,0.901479,"the letter Qaf (  q).2 It is often observed that in Tunisian Arabic, this consonant appears as /q/ (similar to MSA), while in Egyptian and Levantine Arabic it is /P/ (glottal stop) and in Gulf Arabic it is /g/ (Haeri, 1991; Habash, 2010). Orthography While MSA has a standard orthography, the dialects do not. Often people write words reflecting the phonology or the etymology of these words. DA is sometimes written in the so-called Arabizi Romanization script (Darwish, 2014). In the context of NLP, a set of conventional orthography guidelines (CODA) has been proposed for a number of dialects (Habash et al., 2012a; Jar2 Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007): (in alphabetical orˇ der) AbtθjHxdðrzsšSDTDςγfqklmnhwy and the additional sym   ˇ ¯ ˆ ð', yˆ ø , ¯ bols: ’ Z, Â @, A @, A @, w h è, ý ø. 3387 Region Maghreb Sub-region Morocco Algeria Tunisia Cities Rabat Algiers Tunis (RAB) (ALG) (TUN) Fes Sfax (FES) (SFX) Libya Tripoli (TRI) Benghazi (BEN) Nile Basin Egypt/Sudan Cairo (CAI) Alexandria (ALX) Aswan (ASW) Khartoum (KHA) Levant South Levant North Levant Jerusalem Beirut (JER) (BEI) Amman Damascus (AMM) (DAM) Salt Aleppo (SAL) (ALE) Gulf Iraq"
L18-1535,W12-2301,1,0.897253,"the letter Qaf (  q).2 It is often observed that in Tunisian Arabic, this consonant appears as /q/ (similar to MSA), while in Egyptian and Levantine Arabic it is /P/ (glottal stop) and in Gulf Arabic it is /g/ (Haeri, 1991; Habash, 2010). Orthography While MSA has a standard orthography, the dialects do not. Often people write words reflecting the phonology or the etymology of these words. DA is sometimes written in the so-called Arabizi Romanization script (Darwish, 2014). In the context of NLP, a set of conventional orthography guidelines (CODA) has been proposed for a number of dialects (Habash et al., 2012a; Jar2 Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007): (in alphabetical orˇ der) AbtθjHxdðrzsšSDTDςγfqklmnhwy and the additional sym   ˇ ¯ ˆ ð', yˆ ø , ¯ bols: ’ Z, Â @, A @, A @, w h è, ý ø. 3387 Region Maghreb Sub-region Morocco Algeria Tunisia Cities Rabat Algiers Tunis (RAB) (ALG) (TUN) Fes Sfax (FES) (SFX) Libya Tripoli (TRI) Benghazi (BEN) Nile Basin Egypt/Sudan Cairo (CAI) Alexandria (ALX) Aswan (ASW) Khartoum (KHA) Levant South Levant North Levant Jerusalem Beirut (JER) (BEI) Amman Damascus (AMM) (DAM) Salt Aleppo (SAL) (ALE) Gulf Iraq"
L18-1535,L18-1574,1,0.896503,"I) Benghazi (BEN) Nile Basin Egypt/Sudan Cairo (CAI) Alexandria (ALX) Aswan (ASW) Khartoum (KHA) Levant South Levant North Levant Jerusalem Beirut (JER) (BEI) Amman Damascus (AMM) (DAM) Salt Aleppo (SAL) (ALE) Gulf Iraq Gulf Mosul Doha (MOS) (DOH) Baghdad Muscat (BAG) (MUS) Basra Riyadh (BAS) (RIY) Jeddah (JED) Yemen Yemen Sana’a (SAN) Table 1: Different region, sub-region, and city dialects considered in building the MADAR resources. rar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Turki et al., 2016; Khalifa et al., 2016), and has been recently unified under the CODA∗ effort (Habash et al., 2018). Morphology Morphological differences are quite common. One example is the future marker particle which appears as +  s+ or ¬ñ swf in MSA, + hH+ or hP  . bAš rH in Levantine dialects, +ë h+ in Egyptian and AK in Tunisian. This together with variation in the templatic morphology make the forms of some verbs rather different: J» A sÂktb (MSA), IJ» Ag HÂktub e.g., ’I will write’ is I . .   . bAš (Palestinian), I . Jºë hktb (Egyptian) and I.JºK AK nktb (Tunisian). Syntax Comparative studies of several Arabic dialects suggest that the syntactic differences between the dialects are relat"
L18-1535,W14-3603,1,0.936447,"Missing"
L18-1535,W14-3627,1,0.896251,"and multilingual dialectal corpora and lexicons. Several mono-dialectal corpora covering different Arabic dialects were built and made available. Al-Badrashiny et al. (2014) compiled a large dialect-identified corpus of DA from several Egyptian sources, but with a large presence of MSA. In a related effort, McNeil and Faiza (2011) built a four-million-word corpus of Tunisian Spoken Arabic. Various other research work resulted in multidialectal non parallel corpora at different scales (Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Shargi et al., 2016; Zaghouani and Charfi, 2018). 10 The latest version of the lexicon is available for browsing online at http://nlp.qatar.cmu.edu/madar/. 3393 As for dialect-to-dialect parallel corpora, Bouamor et al. (2014) presented the first small-scale 7-way parallel corpus covering several dialects in addition to MSA, and English, all translated from Egyptian sentences. The fact that Egyptian was chosen as a starting point affected the quality of the translation. The sentences produced were biased by the use of some Egyptian expressions that might be accepted in other dialects, but"
L18-1535,L16-1679,1,0.93096,"Rabat Algiers Tunis (RAB) (ALG) (TUN) Fes Sfax (FES) (SFX) Libya Tripoli (TRI) Benghazi (BEN) Nile Basin Egypt/Sudan Cairo (CAI) Alexandria (ALX) Aswan (ASW) Khartoum (KHA) Levant South Levant North Levant Jerusalem Beirut (JER) (BEI) Amman Damascus (AMM) (DAM) Salt Aleppo (SAL) (ALE) Gulf Iraq Gulf Mosul Doha (MOS) (DOH) Baghdad Muscat (BAG) (MUS) Basra Riyadh (BAS) (RIY) Jeddah (JED) Yemen Yemen Sana’a (SAN) Table 1: Different region, sub-region, and city dialects considered in building the MADAR resources. rar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Turki et al., 2016; Khalifa et al., 2016), and has been recently unified under the CODA∗ effort (Habash et al., 2018). Morphology Morphological differences are quite common. One example is the future marker particle which appears as +  s+ or ¬ñ swf in MSA, + hH+ or hP  . bAš rH in Levantine dialects, +ë h+ in Egyptian and AK in Tunisian. This together with variation in the templatic morphology make the forms of some verbs rather different: J» A sÂktb (MSA), IJ» Ag HÂktub e.g., ’I will write’ is I . .   . bAš (Palestinian), I . Jºë hktb (Egyptian) and I.JºK AK nktb (Tunisian). Syntax Comparative studies of several Arabic di"
L18-1535,Y15-1004,0,0.20582,"h of their coverage and the fine location granularity. The focus on cities, as opposed to regions in studying Arabic dialects, opens new avenues to many areas of research from dialectology to dialect identification and machine translation. Keywords: Arabic Dialects, Parallel Corpus, Lexicon 1. Introduction 2. Dialectal Arabic (DA) is emerging nowadays as the primary written language of informal communication online in the Arab World: in emails, blogs, discussion forums, chats, SMS, etc. There has been a rising interest in research on computational models of Arabic dialects in the last decade (Meftouh et al., 2015). There have been several efforts on creating different resources to allow building models for several Natural Language Processing (NLP) applications. However, these efforts have been disjoint from each other, and most of them have focused on a small number of dialects that represent vast regions of the Arab World (Zaidan and Callison-Burch, 2011; Diab et al., 2014; Sajjad et al., 2013). In this paper, we present two resources we created as part of the Multi Arabic Dialect Applications and Resources (MADAR) project.1 The goal of MADAR is to create, for a large number of dialects, a unified fra"
L18-1535,pasha-etal-2014-madamira,1,0.875164,"les from the BTEC parallel corpus. Tuples are then clustered based on their semantic similarity, such that each cluster represents a concept. The automatic process is followed by manual validation and fixing of errors resulting from the automatic process. 4.2.1. Automatic Extraction of Concept Keys Data Preprocessing Since the concept triplet words are represented in terms of lemmas, we pre-process the parallel data to map it into the lemma space. For English, we use the Stanford POS tagger (Toutanova et al., 2003) and for French, we use Treetagger (Schmid, 1994). For Arabic, we use MADAMIRA (Pasha et al., 2014) to tokenize words into the D3 scheme, which separates all clitics from the basewords. Arabic tokenization is required as the clitics attached to basewords in Arabic, are typically represented as separate words in English and French. The most common examples are the proclitic definite article + È@ Al+ ‘the’, and the enclitic possessive pronouns, such as è+ +h ‘his’. The goal here is to harmonize the forms of the three languages to encourage better word alignment and concept extraction. Triplet Extraction Our trilingual concept extraction approach focuses on collecting frequently used triplets."
L18-1535,W15-3208,1,0.95203,"hreb Sub-region Morocco Algeria Tunisia Cities Rabat Algiers Tunis (RAB) (ALG) (TUN) Fes Sfax (FES) (SFX) Libya Tripoli (TRI) Benghazi (BEN) Nile Basin Egypt/Sudan Cairo (CAI) Alexandria (ALX) Aswan (ASW) Khartoum (KHA) Levant South Levant North Levant Jerusalem Beirut (JER) (BEI) Amman Damascus (AMM) (DAM) Salt Aleppo (SAL) (ALE) Gulf Iraq Gulf Mosul Doha (MOS) (DOH) Baghdad Muscat (BAG) (MUS) Basra Riyadh (BAS) (RIY) Jeddah (JED) Yemen Yemen Sana’a (SAN) Table 1: Different region, sub-region, and city dialects considered in building the MADAR resources. rar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Turki et al., 2016; Khalifa et al., 2016), and has been recently unified under the CODA∗ effort (Habash et al., 2018). Morphology Morphological differences are quite common. One example is the future marker particle which appears as +  s+ or ¬ñ swf in MSA, + hH+ or hP  . bAš rH in Levantine dialects, +ë h+ in Egyptian and AK in Tunisian. This together with variation in the templatic morphology make the forms of some verbs rather different: J» A sÂktb (MSA), IJ» Ag HÂktub e.g., ’I will write’ is I . .   . bAš (Palestinian), I . Jºë hktb (Egyptian) and I.JºK AK nktb (Tunisian). Synt"
L18-1535,P13-2001,0,0.0207968,"nformal communication online in the Arab World: in emails, blogs, discussion forums, chats, SMS, etc. There has been a rising interest in research on computational models of Arabic dialects in the last decade (Meftouh et al., 2015). There have been several efforts on creating different resources to allow building models for several Natural Language Processing (NLP) applications. However, these efforts have been disjoint from each other, and most of them have focused on a small number of dialects that represent vast regions of the Arab World (Zaidan and Callison-Burch, 2011; Diab et al., 2014; Sajjad et al., 2013). In this paper, we present two resources we created as part of the Multi Arabic Dialect Applications and Resources (MADAR) project.1 The goal of MADAR is to create, for a large number of dialects, a unified framework with common annotation guidelines and decisions, and targeting applications of Dialect Identification (DID) and Machine Translation (MT). The first resource is a large parallel corpus of 25 Arabic city dialects, in addition to the pre-existing parallel set for English, French and Modern Standard Arabic (MSA). The second resource is a 25-way lexicon of 1,045 entries in each city’s"
L18-1535,salama-etal-2014-youdacc,1,0.898896,"developed monolingual and multilingual dialectal corpora and lexicons. Several mono-dialectal corpora covering different Arabic dialects were built and made available. Al-Badrashiny et al. (2014) compiled a large dialect-identified corpus of DA from several Egyptian sources, but with a large presence of MSA. In a related effort, McNeil and Faiza (2011) built a four-million-word corpus of Tunisian Spoken Arabic. Various other research work resulted in multidialectal non parallel corpora at different scales (Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Shargi et al., 2016; Zaghouani and Charfi, 2018). 10 The latest version of the lexicon is available for browsing online at http://nlp.qatar.cmu.edu/madar/. 3393 As for dialect-to-dialect parallel corpora, Bouamor et al. (2014) presented the first small-scale 7-way parallel corpus covering several dialects in addition to MSA, and English, all translated from Egyptian sentences. The fact that Egyptian was chosen as a starting point affected the quality of the translation. The sentences produced were biased by the use of some Egyptian expressions that might be accepted i"
L18-1535,W15-3205,0,0.305387,"ponsible for. • Delete all entries that are NOT relevant to the cities he/she is responsible for. • Apply the necessary changes for some entries that may need some minor fixes. • Add new words that are not on the AUTO list. • Think of more than one translation into his/her dialect and carefully specify the city. • Use external informants to get more information for cities in his/her area if it is not his original city. • Enter the CODA and CAPHI versions of each entry, using the guidelines provided. Very recently, automatic DA processing has attracted a considerable amount of research in NLP (Shoufan and Alameri, 2015), facilitated by the newly developed monolingual and multilingual dialectal corpora and lexicons. Several mono-dialectal corpora covering different Arabic dialects were built and made available. Al-Badrashiny et al. (2014) compiled a large dialect-identified corpus of DA from several Egyptian sources, but with a large presence of MSA. In a related effort, McNeil and Faiza (2011) built a four-million-word corpus of Tunisian Spoken Arabic. Various other research work resulted in multidialectal non parallel corpora at different scales (Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell"
L18-1535,N03-1033,0,0.0111141,"t key identification relies on an automatic process that extracts (English, French, Arabic) related tuples from the BTEC parallel corpus. Tuples are then clustered based on their semantic similarity, such that each cluster represents a concept. The automatic process is followed by manual validation and fixing of errors resulting from the automatic process. 4.2.1. Automatic Extraction of Concept Keys Data Preprocessing Since the concept triplet words are represented in terms of lemmas, we pre-process the parallel data to map it into the lemma space. For English, we use the Stanford POS tagger (Toutanova et al., 2003) and for French, we use Treetagger (Schmid, 1994). For Arabic, we use MADAMIRA (Pasha et al., 2014) to tokenize words into the D3 scheme, which separates all clitics from the basewords. Arabic tokenization is required as the clitics attached to basewords in Arabic, are typically represented as separate words in English and French. The most common examples are the proclitic definite article + È@ Al+ ‘the’, and the enclitic possessive pronouns, such as è+ +h ‘his’. The goal here is to harmonize the forms of the three languages to encourage better word alignment and concept extraction. Triplet Ex"
L18-1535,L18-1111,1,0.771723,"ons. Several mono-dialectal corpora covering different Arabic dialects were built and made available. Al-Badrashiny et al. (2014) compiled a large dialect-identified corpus of DA from several Egyptian sources, but with a large presence of MSA. In a related effort, McNeil and Faiza (2011) built a four-million-word corpus of Tunisian Spoken Arabic. Various other research work resulted in multidialectal non parallel corpora at different scales (Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Shargi et al., 2016; Zaghouani and Charfi, 2018). 10 The latest version of the lexicon is available for browsing online at http://nlp.qatar.cmu.edu/madar/. 3393 As for dialect-to-dialect parallel corpora, Bouamor et al. (2014) presented the first small-scale 7-way parallel corpus covering several dialects in addition to MSA, and English, all translated from Egyptian sentences. The fact that Egyptian was chosen as a starting point affected the quality of the translation. The sentences produced were biased by the use of some Egyptian expressions that might be accepted in other dialects, but a native would not produce naturally. The same conce"
L18-1535,P11-2007,0,0.621852,"erging nowadays as the primary written language of informal communication online in the Arab World: in emails, blogs, discussion forums, chats, SMS, etc. There has been a rising interest in research on computational models of Arabic dialects in the last decade (Meftouh et al., 2015). There have been several efforts on creating different resources to allow building models for several Natural Language Processing (NLP) applications. However, these efforts have been disjoint from each other, and most of them have focused on a small number of dialects that represent vast regions of the Arab World (Zaidan and Callison-Burch, 2011; Diab et al., 2014; Sajjad et al., 2013). In this paper, we present two resources we created as part of the Multi Arabic Dialect Applications and Resources (MADAR) project.1 The goal of MADAR is to create, for a large number of dialects, a unified framework with common annotation guidelines and decisions, and targeting applications of Dialect Identification (DID) and Machine Translation (MT). The first resource is a large parallel corpus of 25 Arabic city dialects, in addition to the pre-existing parallel set for English, French and Modern Standard Arabic (MSA). The second resource is a 25-wa"
L18-1535,N12-1006,0,0.0438526,"(Shoufan and Alameri, 2015), facilitated by the newly developed monolingual and multilingual dialectal corpora and lexicons. Several mono-dialectal corpora covering different Arabic dialects were built and made available. Al-Badrashiny et al. (2014) compiled a large dialect-identified corpus of DA from several Egyptian sources, but with a large presence of MSA. In a related effort, McNeil and Faiza (2011) built a four-million-word corpus of Tunisian Spoken Arabic. Various other research work resulted in multidialectal non parallel corpora at different scales (Zaidan and Callison-Burch, 2011; Zbib et al., 2012; Cotterell and Callison-Burch, 2014; Salama et al., 2014; Jeblee et al., 2014; Al-Shargi et al., 2016; Zaghouani and Charfi, 2018). 10 The latest version of the lexicon is available for browsing online at http://nlp.qatar.cmu.edu/madar/. 3393 As for dialect-to-dialect parallel corpora, Bouamor et al. (2014) presented the first small-scale 7-way parallel corpus covering several dialects in addition to MSA, and English, all translated from Egyptian sentences. The fact that Egyptian was chosen as a starting point affected the quality of the translation. The sentences produced were biased by the"
L18-1535,zribi-etal-2014-conventional,1,0.960805,"ý ø. 3387 Region Maghreb Sub-region Morocco Algeria Tunisia Cities Rabat Algiers Tunis (RAB) (ALG) (TUN) Fes Sfax (FES) (SFX) Libya Tripoli (TRI) Benghazi (BEN) Nile Basin Egypt/Sudan Cairo (CAI) Alexandria (ALX) Aswan (ASW) Khartoum (KHA) Levant South Levant North Levant Jerusalem Beirut (JER) (BEI) Amman Damascus (AMM) (DAM) Salt Aleppo (SAL) (ALE) Gulf Iraq Gulf Mosul Doha (MOS) (DOH) Baghdad Muscat (BAG) (MUS) Basra Riyadh (BAS) (RIY) Jeddah (JED) Yemen Yemen Sana’a (SAN) Table 1: Different region, sub-region, and city dialects considered in building the MADAR resources. rar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Turki et al., 2016; Khalifa et al., 2016), and has been recently unified under the CODA∗ effort (Habash et al., 2018). Morphology Morphological differences are quite common. One example is the future marker particle which appears as +  s+ or ¬ñ swf in MSA, + hH+ or hP  . bAš rH in Levantine dialects, +ë h+ in Egyptian and AK in Tunisian. This together with variation in the templatic morphology make the forms of some verbs rather different: J» A sÂktb (MSA), IJ» Ag HÂktub e.g., ’I will write’ is I . .   . bAš (Palestinian), I . Jºë hktb (Egyptian) and I.JºK"
L18-1574,C16-2044,1,0.881168,"Missing"
L18-1574,2014.iwslt-papers.1,0,0.119633,"Missing"
L18-1574,P11-2062,1,0.860318,"f MSA patterns will retain the spelling choice of the MSA pattern if the difference in pronunciation can be expressed using diacritics (for vowel change or absence), or if the pronunciation is a shortened form of the MSA pattern vowels. Alif Maqsura The MSA rules for spelling the AlifMaqsura ( ø ý), which are sometimes based on roots and sometimes on patterns, apply in CODA*. 6.4.2. The Ta-Marbuta  The Ta-Marbuta ( è ¯h) is a secondary letter of the Arabic alphabet used to represent a particular suffix morpheme that is often (but not exclusively) associated with the femininesingular feature (Alkuhlani and Habash, 2011). This morpheme has a number of allomorphs with differing pronunciations. Most notably, it appears as a vowel at the end of nominals, and changes to a ∼ /t/ when followed by possessive pronominal enclitics. The Ta-Marbuta should be writ ten as è ¯h in word-final positions, regardless of its pronunciation, and following general CODA rules in non-word-final positions. See Table 3 for example cases. 6.3.3. Clitic Spelling The general rule on phonological clitic spelling is that clitics that are mapped into single letters (with possible diacritics) will be spelled attached to the word, and will n"
L18-1574,W14-3612,1,0.893572,"1 which it can be confused by speakers of dialects which do not have the phoneme [p]. Thus, pQ is included in CAPHI as /p./ as it is useful in describing the dialectal differences between Iraqi and other dialects. The complete CAPHI inventory is listed in Figure 2. 6. CODA* General Rules and Specifications While the goals of the CODA* guidelines is to precisely define the CODA choices, it is unavoidable that different versions of the guidelines will need to be presented differently for specific annotators on specific tasks for specific dialects: e.g., conversion form Arabizi to Arabic script (Bies et al., 2014), or lexicon construction (Diab et al., 2014). In this paper, we summarize and highlight specific contributions of the effort; but the full set of CODA* guidelines is described on its online page (See Section 8.). We start with a description of the technical terminology we use; then we discuss the various rules and how to use them. The border between the general rules and the specification rules is broadly drawn along the lines that general rules do not refer to any specific lexical items (morphemes or words) and pertain to the meta-mechanics of CODA; while the specification rules are lexicall"
L18-1574,L18-1535,1,0.789785,"presented in previous work; (c) the introduction of the concept of a multidialectal Seed Lexicon that is used to allow users of CODA* to have access to previous decisions when identifying spellings for new words in new dialects; and finally, (d) a set of online pages that give users easy public access to all of these resources. The CODA* guidelines and their connected resources are being used by three large Arabic dialect processing projects in three universities: The Multi-Arabic Dialect Applications and Resources at Carnegie Mellon University Qatar and New York University Abu Dhabi (NYUAD) (Bouamor et al., 2018), The Gulf Arabic Annotated Corpus (NYUAD) (Khalifa et al., 2018), and The Columbia Arabic Dialect Annotation project (Columbia University and NYUAD). The CODA* effort is large and ongoing; the goal of this paper is to introduce the effort and some of its important contributions on how to conceptualize and address the question of orthographic decisions in dialectal Arabic computational processing. The rest of the paper is structured as follows. We present common challenges to Arabic processing in Section 2. This is followed by related work in Section 3. We introduce CODA* in Section 4., and di"
L18-1574,diab-etal-2014-tharwa,1,0.959854,"sals such as the Asaakir system (‘Asaakir, 1950) and Akl’s system (Arkadiusz, 2006), neither of which are broadly used today. Various DA dictionaries used Arabic, Latin or mixed script orthographies (Badawi and Hinds, 1986). In the context of NLP, the Linguistic Data Consortium (LDC) guidelines for transcribing Levantine Arabic (Maamouri et al., 2004) and the COLABA project at Columbia University (Diab et al., 2010) were precursors to the work of Habash et al. (2012). After the CODA-Egyptian guidelines were created and used for the creation of Egyptian Arabic resources (Maamouri et al., 2014; Diab et al., 2014; Pasha et al., 2014; Eskander et al., 2013; Al-Badrashiny et al., 2014), two additional sets of guidelines were created for CODATunisian (Zribi et al., 2014) and CODA-Palestinian (Jarrar et al., 2014). These were part of projects involving morphology annotation (Palestinian) or speech recognition (Tunisian). A variant on CODA was proposed for speech recognition by Ali et al. (2014) and was shown to reduce OOV and perplexity. Since then, four more dialects followed: CODA-Algerian (Saadane and Habash, 2015), CODA-Gulf (Khalifa et al., 2016), CODA-Moroccan and CODA-Yemeni (Al-Shargi et al., 2016"
L18-1574,N13-1066,1,0.885238,"Missing"
L18-1574,habash-etal-2012-conventional,1,0.57243,"vary from MSA and from each other in terms of phonology, morphology, lexicon and syntax (Watson, 2007), using MSA orthographic standards cannot fully address the needs of the dialects. As an example of the degree of variety in dialectal spelling, Figure 1. presents the 27 actually attested spellings of one Egyptian Arabic word online. The large number of possibilities results from independent decisions such as whether the proclitic /ma/ should be written attached or separated (+Ó m+1 or AÓ mA), or whether to write the stem in a way  w), ˆ or etymology (  q). that reflects its phonology (ð' Habash et al. (2012) introduced the concept of Conventional Orthography for Dialectal Arabic (CODA); and they proposed a set of guidelines and exception lists for Egyptian Arabic. Their conventions were used in the Linguistic Data Consortium for annotating Egyptian Arabic (Maamouri et al., 2014). Since then, a number of additional efforts followed suit for other dialects (Zribi et al., 2014; Saadane and Habash, 2015; Jarrar et al., 2016; Khalifa et al., 2016). While the original CODA guidelines aimed at being easy to adjust to new dialects and contained some 1 Arabic script transliteration is presented in the Hab"
L18-1574,W14-3603,1,0.933108,"Missing"
L18-1574,L16-1679,1,0.936174,"should be written attached or separated (+Ó m+1 or AÓ mA), or whether to write the stem in a way  w), ˆ or etymology (  q). that reflects its phonology (ð' Habash et al. (2012) introduced the concept of Conventional Orthography for Dialectal Arabic (CODA); and they proposed a set of guidelines and exception lists for Egyptian Arabic. Their conventions were used in the Linguistic Data Consortium for annotating Egyptian Arabic (Maamouri et al., 2014). Since then, a number of additional efforts followed suit for other dialects (Zribi et al., 2014; Saadane and Habash, 2015; Jarrar et al., 2016; Khalifa et al., 2016). While the original CODA guidelines aimed at being easy to adjust to new dialects and contained some 1 Arabic script transliteration is presented in the Habash-SoudiBuckwalter transliteration scheme (Habash et al., 2007):   P     ¨ ¨ ¬   È Ð à è ð ø @ H. H H h. h p X XP ˇ ς γ f q k l m n hw y Â b t θ j H x dðr z s š S D T D ˇ ¯  and the additional symbols: ’ Z, Â @, A @, A @, wˆ ð', yˆ Zø', ¯h è, ý ø. Phonological forms are presented in IPA or in the CAPHI scheme, which is discussed in Section 5. Frequency ≈ 26,000 ≈ 13,000 ≤ 10,000 ≤ 1,000 ≤ 100 ≤ 10 Figure 1: 27 encountered ways"
L18-1574,L18-1607,1,0.954641,"f a multidialectal Seed Lexicon that is used to allow users of CODA* to have access to previous decisions when identifying spellings for new words in new dialects; and finally, (d) a set of online pages that give users easy public access to all of these resources. The CODA* guidelines and their connected resources are being used by three large Arabic dialect processing projects in three universities: The Multi-Arabic Dialect Applications and Resources at Carnegie Mellon University Qatar and New York University Abu Dhabi (NYUAD) (Bouamor et al., 2018), The Gulf Arabic Annotated Corpus (NYUAD) (Khalifa et al., 2018), and The Columbia Arabic Dialect Annotation project (Columbia University and NYUAD). The CODA* effort is large and ongoing; the goal of this paper is to introduce the effort and some of its important contributions on how to conceptualize and address the question of orthographic decisions in dialectal Arabic computational processing. The rest of the paper is structured as follows. We present common challenges to Arabic processing in Section 2. This is followed by related work in Section 3. We introduce CODA* in Section 4., and discuss its components in Section 5. (CAPHI), Section 6. (General R"
L18-1574,maamouri-etal-2014-developing,1,0.931749,"actually attested spellings of one Egyptian Arabic word online. The large number of possibilities results from independent decisions such as whether the proclitic /ma/ should be written attached or separated (+Ó m+1 or AÓ mA), or whether to write the stem in a way  w), ˆ or etymology (  q). that reflects its phonology (ð' Habash et al. (2012) introduced the concept of Conventional Orthography for Dialectal Arabic (CODA); and they proposed a set of guidelines and exception lists for Egyptian Arabic. Their conventions were used in the Linguistic Data Consortium for annotating Egyptian Arabic (Maamouri et al., 2014). Since then, a number of additional efforts followed suit for other dialects (Zribi et al., 2014; Saadane and Habash, 2015; Jarrar et al., 2016; Khalifa et al., 2016). While the original CODA guidelines aimed at being easy to adjust to new dialects and contained some 1 Arabic script transliteration is presented in the Habash-SoudiBuckwalter transliteration scheme (Habash et al., 2007):   P     ¨ ¨ ¬   È Ð à è ð ø @ H. H H h. h p X XP ˇ ς γ f q k l m n hw y Â b t θ j H x dðr z s š S D T D ˇ ¯  and the additional symbols: ’ Z, Â @, A @, A @, wˆ ð', yˆ Zø', ¯h è, ý ø. Phonological fo"
L18-1574,Y15-1004,0,0.179652,"Missing"
L18-1574,pasha-etal-2014-madamira,1,0.908097,"Missing"
L18-1574,W15-3208,1,0.95202,"t decisions such as whether the proclitic /ma/ should be written attached or separated (+Ó m+1 or AÓ mA), or whether to write the stem in a way  w), ˆ or etymology (  q). that reflects its phonology (ð' Habash et al. (2012) introduced the concept of Conventional Orthography for Dialectal Arabic (CODA); and they proposed a set of guidelines and exception lists for Egyptian Arabic. Their conventions were used in the Linguistic Data Consortium for annotating Egyptian Arabic (Maamouri et al., 2014). Since then, a number of additional efforts followed suit for other dialects (Zribi et al., 2014; Saadane and Habash, 2015; Jarrar et al., 2016; Khalifa et al., 2016). While the original CODA guidelines aimed at being easy to adjust to new dialects and contained some 1 Arabic script transliteration is presented in the Habash-SoudiBuckwalter transliteration scheme (Habash et al., 2007):   P     ¨ ¨ ¬   È Ð à è ð ø @ H. H H h. h p X XP ˇ ς γ f q k l m n hw y Â b t θ j H x dðr z s š S D T D ˇ ¯  and the additional symbols: ’ Z, Â @, A @, A @, wˆ ð', yˆ Zø', ¯h è, ý ø. Phonological forms are presented in IPA or in the CAPHI scheme, which is discussed in Section 5. Frequency ≈ 26,000 ≈ 13,000 ≤ 10,000 ≤ 1,"
L18-1574,zaghouani-etal-2014-large,1,0.923929,"Missing"
L18-1574,N18-1087,1,0.880283,"Missing"
L18-1574,zribi-etal-2014-conventional,1,0.961603,"ults from independent decisions such as whether the proclitic /ma/ should be written attached or separated (+Ó m+1 or AÓ mA), or whether to write the stem in a way  w), ˆ or etymology (  q). that reflects its phonology (ð' Habash et al. (2012) introduced the concept of Conventional Orthography for Dialectal Arabic (CODA); and they proposed a set of guidelines and exception lists for Egyptian Arabic. Their conventions were used in the Linguistic Data Consortium for annotating Egyptian Arabic (Maamouri et al., 2014). Since then, a number of additional efforts followed suit for other dialects (Zribi et al., 2014; Saadane and Habash, 2015; Jarrar et al., 2016; Khalifa et al., 2016). While the original CODA guidelines aimed at being easy to adjust to new dialects and contained some 1 Arabic script transliteration is presented in the Habash-SoudiBuckwalter transliteration scheme (Habash et al., 2007):   P     ¨ ¨ ¬   È Ð à è ð ø @ H. H H h. h p X XP ˇ ς γ f q k l m n hw y Â b t θ j H x dðr z s š S D T D ˇ ¯  and the additional symbols: ’ Z, Â @, A @, A @, wˆ ð', yˆ Zø', ¯h è, ý ø. Phonological forms are presented in IPA or in the CAPHI scheme, which is discussed in Section 5. Frequency ≈ 26,"
L18-1607,P11-2062,1,0.692029,"a new POS tagset – C AMEL POS. C AMEL POS is inspired by the ARZATB tagset and guidelines (Maamouri et al., 2012b) which is based on the PATB guidelines (Maamouri et al., 2009). The C AMEL POS is designed as single tagset for both MSA and the dialects with the following goals in mind: (a) facilitating research on adaptation between MSA and the dialects, and among the dialects; (b) supporting backward compatibility with previously annotated resources; and (c) enforcing a functional morphology analysis that is deeper and more compatible with Arabic morphosyntactic rules than formbased analysis (Alkuhlani and Habash, 2011). The C AMEL POS tags and features are the union of those in MSA and the dialects. Features are available to use when needed. For example case and state features are used more often in MSA; but on the other hand, dialects tend to have many more clitics than MSA, including non-MSA ones. One of the main differences between C AMEL POS and ARZATB is that the morphological features of both gender and number of nominals are annotated functionally (Alkuhlani and Habash, 2011; Smrž, 2007). This decision allows us to assign the features to the baseword without the need to specify the surface form affix"
L18-1607,bouamor-etal-2014-multidialectal,1,0.8687,"al., 2014; Jarrar et al., 2016). ARZATB and Curras were used to create morphological analyzers and disambiguators (Eskander et al., 2016). Other dialects such as Yemeni and Moroccan Arabic followed the same approach (Al-Shargi et al., 2016). In addition to the dialects mentioned above, there were recent efforts on creating corpora for other dialects, namely Tunisian and Algerian (McNeil and Faiza, 2011; Masmoudi et al., 2014; Zribi et al., 2015; Smaïli et al., 2014). Other works targeted multi-dialect corpora (Diab et al., 2010; Zaidan and Callison-Burch, 2011; Diab et al., Forthcoming 2013; Bouamor et al., 2014; Cotterell and Callison-Burch, 2014), and, most recently, the ongoing Multi Arabic Dialect and Application Resources project (MADAR) (Bouamor et al., 2018) which includes corpora for 25 different city dialects. Gulf Arabic Resources As far as Gulf Arabic (GLF) is concerned, the only existing annotated corpora include the Emirati Arabic Corpus (EAC) (Halefom et al., 2013) and the Emirati Arabic Language Acquisition Corpus (EMALAC) (Ntelitheos and Idrissi, 2017) that were created by linguists with emphasis on the phonological and morphosyntactic phenomena of Emirati Arabic. We recently collecte"
L18-1607,L18-1535,1,0.688184,"such as Yemeni and Moroccan Arabic followed the same approach (Al-Shargi et al., 2016). In addition to the dialects mentioned above, there were recent efforts on creating corpora for other dialects, namely Tunisian and Algerian (McNeil and Faiza, 2011; Masmoudi et al., 2014; Zribi et al., 2015; Smaïli et al., 2014). Other works targeted multi-dialect corpora (Diab et al., 2010; Zaidan and Callison-Burch, 2011; Diab et al., Forthcoming 2013; Bouamor et al., 2014; Cotterell and Callison-Burch, 2014), and, most recently, the ongoing Multi Arabic Dialect and Application Resources project (MADAR) (Bouamor et al., 2018) which includes corpora for 25 different city dialects. Gulf Arabic Resources As far as Gulf Arabic (GLF) is concerned, the only existing annotated corpora include the Emirati Arabic Corpus (EAC) (Halefom et al., 2013) and the Emirati Arabic Language Acquisition Corpus (EMALAC) (Ntelitheos and Idrissi, 2017) that were created by linguists with emphasis on the phonological and morphosyntactic phenomena of Emirati Arabic. We recently collected a large-scale corpus of Gulf Arabic (Khalifa et al., 2016a) containing more than 100 million words covering six Gulf Arabic varieties. In regards to other"
L18-1607,cotterell-callison-burch-2014-multi,0,0.0245718,"al., 2016). ARZATB and Curras were used to create morphological analyzers and disambiguators (Eskander et al., 2016). Other dialects such as Yemeni and Moroccan Arabic followed the same approach (Al-Shargi et al., 2016). In addition to the dialects mentioned above, there were recent efforts on creating corpora for other dialects, namely Tunisian and Algerian (McNeil and Faiza, 2011; Masmoudi et al., 2014; Zribi et al., 2015; Smaïli et al., 2014). Other works targeted multi-dialect corpora (Diab et al., 2010; Zaidan and Callison-Burch, 2011; Diab et al., Forthcoming 2013; Bouamor et al., 2014; Cotterell and Callison-Burch, 2014), and, most recently, the ongoing Multi Arabic Dialect and Application Resources project (MADAR) (Bouamor et al., 2018) which includes corpora for 25 different city dialects. Gulf Arabic Resources As far as Gulf Arabic (GLF) is concerned, the only existing annotated corpora include the Emirati Arabic Corpus (EAC) (Halefom et al., 2013) and the Emirati Arabic Language Acquisition Corpus (EMALAC) (Ntelitheos and Idrissi, 2017) that were created by linguists with emphasis on the phonological and morphosyntactic phenomena of Emirati Arabic. We recently collected a large-scale corpus of Gulf Arabic"
L18-1607,C12-2029,0,0.0266838,"synonymous English glosses. For example Q J.» kbyr would have the following English glosses ‘large; great; important; major; senior’. 4.6. Word Level Dialect Identification Dialect identification is the task of tagging a certain context with a given dialect tag. Deciding the dialect tag depends on the context of the sentence and/or the document. This can be challenging since many words in their written form may be shared by many dialects and MSA. Additionally, it is not uncommon to find dialect code switching between MSA and a dialect, and even a dialect with another dialect (less commonly) (Elfardy and Diab, 2012). Hence we tag per word, but rely on the context of the sentence and even the document to identify the dialect. In Table 3 we show an example of a fully annotated sentence and the POS tag in ARZATB for comparison. For full description of each of the annotation tasks and examples, the full guidelines can be accessed online. 5. Annotation Process In this section, we discuss the annotation process details, the tool we used, and some annotation quality evaluation results. 5.1. MADARi Interface We used a newly developed interface for morphological annotation and spelling correction called MADARi (O"
L18-1607,C16-1326,1,0.761428,"agset and corpus with the intention to facilitate certain NLP applications like subjectivity and sentiment analysis. Levantine Arabic and and Other Dialectal Arabic Resources Levantine Arabic (LEV) received some notable efforts including the Levantine Arabic Treebank (LATB) of Jordanian Arabic (Maamouri et al., 2006) which contains around 27,000 annotated words in a similar fashion to ARZATB. A more recent resource is the annotated corpus of Palestinian Arabic (Curras) (Jarrar et al., 2014; Jarrar et al., 2016). ARZATB and Curras were used to create morphological analyzers and disambiguators (Eskander et al., 2016). Other dialects such as Yemeni and Moroccan Arabic followed the same approach (Al-Shargi et al., 2016). In addition to the dialects mentioned above, there were recent efforts on creating corpora for other dialects, namely Tunisian and Algerian (McNeil and Faiza, 2011; Masmoudi et al., 2014; Zribi et al., 2015; Smaïli et al., 2014). Other works targeted multi-dialect corpora (Diab et al., 2010; Zaidan and Callison-Burch, 2011; Diab et al., Forthcoming 2013; Bouamor et al., 2014; Cotterell and Callison-Burch, 2014), and, most recently, the ongoing Multi Arabic Dialect and Application Resources"
L18-1607,P06-1086,1,0.8782,"gical analysis and disambiguation are still lacking compared to those for Modern Standard Arabic (MSA). MSA is the official language in more than 20 countries, where it is used in official communications, news, and education. Yet, it is not the commonly spoken variety of Arabic; the dialectal varieties of Arabic are what is used in the day-to-day communication. Dialectal Arabic is also commonly used in written form on social media platforms, forums and blogs. Using available resources developed for MSA such as POS taggers and tokenizers gives limited performance when used on dialectal Arabic (Habash and Rambow, 2006; Jarrar et al., 2014; Khalifa et al., 2016a). Many researchers moved into the direction of creating tools and resources targeting the dialects specifically. Egyptian Arabic is one of the dialects that received earlier efforts for developing tools and resources. More resources are being developed for other dialects such as Levantine, Tunisian, Moroccan and Yemeni Arabic. Gulf Arabic, as we define it to be the native spoken variety in the Gulf Cooperation Council, is still lagging behind other Arabic dialects with respect to resource and tool creation, given the considerable amount of dialectal"
L18-1607,W12-2301,1,0.887414,"Missing"
L18-1607,habash-etal-2012-conventional,1,0.920065,"ic Resources In the scope of dialectal Arabic, there have been many recent contributions to the development and creation of resources. Below, we discuss the highlights of those contributions. Egyptian Arabic Resources Egyptian Arabic (EGY) was one of the first dialects that received the attention of the NLP community. The earliest effort, to the best of 3839 our knowledge, is the Egyptian Colloquial Arabic Lexicon (ECAL) (Kilany et al., 2002) which was developed as part of the CALLHOME Egypt corpus (Gadalla et al., 1997). The ECAL served as the seed to the EGY morphological analyzer (CALIMA) (Habash et al., 2012a). Later on, the Egyptian Arabic Treebank (ARZATB) (Maamouri et al., 2012a; Maamouri et al., 2014) was created by the LDC using CALIMA to provide analysis options for the annotation process. The ARZATB has currently 400,000 words in eight parts annotated in a similar fashion to the PATB. The annotation guidelines for the ARZATB (Maamouri et al., 2012b) followed that of the PATB with decisions specific to the dialect. Since the release, the ARZATB has been used extensively for developing EGY resources such as the EGY part of MADAMIRA, MADA and YAMAMA, in addition to a noise-robust morphologica"
L18-1607,L18-1574,1,0.93151,"s to other tools and resources, we recently developed a morphological analyzer for Gulf Arabic verbs (CALIMAGLF ) (Khalifa et al., 2017). We are also aware of the previously developed rule-based stemmer for Arabic Gulf dialect (Abuata and Al-Omari, 2015). In this work, we use about 200,000 words from the Emirati Arabic portion of the Gumar corpus to manually annotate for tokenization, POS tagging, lemma, English gloss and dialect identification. Additionally we conventionalize the spelling in accordance with the Conventional Orthography for Dialectal Arabic (CODA) rules (Habash et al., 2012b; Habash et al., 2018). For recent surveys on Arabic resources for NLP, see Zaghouani (2014), Shoufan and Al-Ameri (2015) and Zeroual and Lakhouaja (2018). 3. Annotating the Gumar Corpus We discuss next the Gumar Corpus and the portion of it we use to annotate in this effort. 3.1. Gumar Corpus The Gumar corpus is a large-scale corpus of Gulf Arabic containing more than 100 million words. The corpus consists mainly of documents of long conversational novels  JË@ HAK  @ð P ‘Internet Novels’. This type also known as I of literature is very popular among female teenagers in the Gulf area. These novels are written mos"
L18-1607,K17-1042,0,0.191588,"Missing"
L18-1607,W14-3603,1,0.792897,"ulf Arabic verbs (CALIMAGLF ) (Khalifa et al., 2017). We are also aware of the previously developed rule-based stemmer for Arabic Gulf dialect (Abuata and Al-Omari, 2015). In this work, we use about 200,000 words from the Emirati Arabic portion of the Gumar corpus to manually annotate for tokenization, POS tagging, lemma, English gloss and dialect identification. Additionally we conventionalize the spelling in accordance with the Conventional Orthography for Dialectal Arabic (CODA) rules (Habash et al., 2012b; Habash et al., 2018). For recent surveys on Arabic resources for NLP, see Zaghouani (2014), Shoufan and Al-Ameri (2015) and Zeroual and Lakhouaja (2018). 3. Annotating the Gumar Corpus We discuss next the Gumar Corpus and the portion of it we use to annotate in this effort. 3.1. Gumar Corpus The Gumar corpus is a large-scale corpus of Gulf Arabic containing more than 100 million words. The corpus consists mainly of documents of long conversational novels  JË@ HAK  @ð P ‘Internet Novels’. This type also known as I of literature is very popular among female teenagers in the Gulf area. These novels are written mostly in dialectal Arabic, where the lengthy conversations between the c"
L18-1607,L16-1679,1,0.92503,"cking compared to those for Modern Standard Arabic (MSA). MSA is the official language in more than 20 countries, where it is used in official communications, news, and education. Yet, it is not the commonly spoken variety of Arabic; the dialectal varieties of Arabic are what is used in the day-to-day communication. Dialectal Arabic is also commonly used in written form on social media platforms, forums and blogs. Using available resources developed for MSA such as POS taggers and tokenizers gives limited performance when used on dialectal Arabic (Habash and Rambow, 2006; Jarrar et al., 2014; Khalifa et al., 2016a). Many researchers moved into the direction of creating tools and resources targeting the dialects specifically. Egyptian Arabic is one of the dialects that received earlier efforts for developing tools and resources. More resources are being developed for other dialects such as Levantine, Tunisian, Moroccan and Yemeni Arabic. Gulf Arabic, as we define it to be the native spoken variety in the Gulf Cooperation Council, is still lagging behind other Arabic dialects with respect to resource and tool creation, given the considerable amount of dialectal content online. In this paper, we present"
L18-1607,C16-2047,1,0.938455,"cking compared to those for Modern Standard Arabic (MSA). MSA is the official language in more than 20 countries, where it is used in official communications, news, and education. Yet, it is not the commonly spoken variety of Arabic; the dialectal varieties of Arabic are what is used in the day-to-day communication. Dialectal Arabic is also commonly used in written form on social media platforms, forums and blogs. Using available resources developed for MSA such as POS taggers and tokenizers gives limited performance when used on dialectal Arabic (Habash and Rambow, 2006; Jarrar et al., 2014; Khalifa et al., 2016a). Many researchers moved into the direction of creating tools and resources targeting the dialects specifically. Egyptian Arabic is one of the dialects that received earlier efforts for developing tools and resources. More resources are being developed for other dialects such as Levantine, Tunisian, Moroccan and Yemeni Arabic. Gulf Arabic, as we define it to be the native spoken variety in the Gulf Cooperation Council, is still lagging behind other Arabic dialects with respect to resource and tool creation, given the considerable amount of dialectal content online. In this paper, we present"
L18-1607,W17-1305,1,0.838411,"is concerned, the only existing annotated corpora include the Emirati Arabic Corpus (EAC) (Halefom et al., 2013) and the Emirati Arabic Language Acquisition Corpus (EMALAC) (Ntelitheos and Idrissi, 2017) that were created by linguists with emphasis on the phonological and morphosyntactic phenomena of Emirati Arabic. We recently collected a large-scale corpus of Gulf Arabic (Khalifa et al., 2016a) containing more than 100 million words covering six Gulf Arabic varieties. In regards to other tools and resources, we recently developed a morphological analyzer for Gulf Arabic verbs (CALIMAGLF ) (Khalifa et al., 2017). We are also aware of the previously developed rule-based stemmer for Arabic Gulf dialect (Abuata and Al-Omari, 2015). In this work, we use about 200,000 words from the Emirati Arabic portion of the Gumar corpus to manually annotate for tokenization, POS tagging, lemma, English gloss and dialect identification. Additionally we conventionalize the spelling in accordance with the Conventional Orthography for Dialectal Arabic (CODA) rules (Habash et al., 2012b; Habash et al., 2018). For recent surveys on Arabic resources for NLP, see Zaghouani (2014), Shoufan and Al-Ameri (2015) and Zeroual and"
L18-1607,maamouri-etal-2006-developing,1,0.84165,"ely for developing EGY resources such as the EGY part of MADAMIRA, MADA and YAMAMA, in addition to a noise-robust morphological disambiguator for EGY (Zalmout et al., 2018). Other developed corpora and POS taggers for EGY include the work of Al-Sabbagh and Girju (2012) where they created their own POS tagset and corpus with the intention to facilitate certain NLP applications like subjectivity and sentiment analysis. Levantine Arabic and and Other Dialectal Arabic Resources Levantine Arabic (LEV) received some notable efforts including the Levantine Arabic Treebank (LATB) of Jordanian Arabic (Maamouri et al., 2006) which contains around 27,000 annotated words in a similar fashion to ARZATB. A more recent resource is the annotated corpus of Palestinian Arabic (Curras) (Jarrar et al., 2014; Jarrar et al., 2016). ARZATB and Curras were used to create morphological analyzers and disambiguators (Eskander et al., 2016). Other dialects such as Yemeni and Moroccan Arabic followed the same approach (Al-Shargi et al., 2016). In addition to the dialects mentioned above, there were recent efforts on creating corpora for other dialects, namely Tunisian and Algerian (McNeil and Faiza, 2011; Masmoudi et al., 2014; Zri"
L18-1607,maamouri-etal-2014-developing,1,0.815671,"development and creation of resources. Below, we discuss the highlights of those contributions. Egyptian Arabic Resources Egyptian Arabic (EGY) was one of the first dialects that received the attention of the NLP community. The earliest effort, to the best of 3839 our knowledge, is the Egyptian Colloquial Arabic Lexicon (ECAL) (Kilany et al., 2002) which was developed as part of the CALLHOME Egypt corpus (Gadalla et al., 1997). The ECAL served as the seed to the EGY morphological analyzer (CALIMA) (Habash et al., 2012a). Later on, the Egyptian Arabic Treebank (ARZATB) (Maamouri et al., 2012a; Maamouri et al., 2014) was created by the LDC using CALIMA to provide analysis options for the annotation process. The ARZATB has currently 400,000 words in eight parts annotated in a similar fashion to the PATB. The annotation guidelines for the ARZATB (Maamouri et al., 2012b) followed that of the PATB with decisions specific to the dialect. Since the release, the ARZATB has been used extensively for developing EGY resources such as the EGY part of MADAMIRA, MADA and YAMAMA, in addition to a noise-robust morphological disambiguator for EGY (Zalmout et al., 2018). Other developed corpora and POS taggers for EGY inc"
L18-1607,masmoudi-etal-2014-corpus,1,0.806091,"ic (Maamouri et al., 2006) which contains around 27,000 annotated words in a similar fashion to ARZATB. A more recent resource is the annotated corpus of Palestinian Arabic (Curras) (Jarrar et al., 2014; Jarrar et al., 2016). ARZATB and Curras were used to create morphological analyzers and disambiguators (Eskander et al., 2016). Other dialects such as Yemeni and Moroccan Arabic followed the same approach (Al-Shargi et al., 2016). In addition to the dialects mentioned above, there were recent efforts on creating corpora for other dialects, namely Tunisian and Algerian (McNeil and Faiza, 2011; Masmoudi et al., 2014; Zribi et al., 2015; Smaïli et al., 2014). Other works targeted multi-dialect corpora (Diab et al., 2010; Zaidan and Callison-Burch, 2011; Diab et al., Forthcoming 2013; Bouamor et al., 2014; Cotterell and Callison-Burch, 2014), and, most recently, the ongoing Multi Arabic Dialect and Application Resources project (MADAR) (Bouamor et al., 2018) which includes corpora for 25 different city dialects. Gulf Arabic Resources As far as Gulf Arabic (GLF) is concerned, the only existing annotated corpora include the Emirati Arabic Corpus (EAC) (Halefom et al., 2013) and the Emirati Arabic Language Ac"
L18-1607,L18-1415,1,0.812386,"). Hence we tag per word, but rely on the context of the sentence and even the document to identify the dialect. In Table 3 we show an example of a fully annotated sentence and the POS tag in ARZATB for comparison. For full description of each of the annotation tasks and examples, the full guidelines can be accessed online. 5. Annotation Process In this section, we discuss the annotation process details, the tool we used, and some annotation quality evaluation results. 5.1. MADARi Interface We used a newly developed interface for morphological annotation and spelling correction called MADARi (Obeid et al., 2018). MADARi is a web-based interface that supports joint morphological annotation (tokenization, POS tagging, lemmatization) and spelling correction at any point of the annotation process, which minimizes error propagation. English glossing and dialect identification are also supported in the interface. MADARi assigns initial answers to the new text using MADAMIRA in EGY mode, whose databases we extended with CALIMAGLF for more coverage. MADARi has many utilities to facilitate the annotation process that we utilize for more efficiency, of which examples are discussed in the next subsection. Figur"
L18-1607,pasha-etal-2014-madamira,1,0.901691,"Modern Standard Arabic Resources The Penn Arabic Treebank (PATB) (Maamouri et al., 2004) has been a central resource for developing MSA resources. It was developed at the Linguistic Data Consortium (LDC), and it mainly consists of newswire text from different news sources. The PATB corpus is annotated for tokenization, segmentation, POS tagging, lemmatization, diacritization, English gloss and syntactic structure. The PATB has 12 parts of more than 1.3 million words. The annotated data has been a backbone of many state-of-the-art tools such as analyzers and disambiguators including MADAMIRA (Pasha et al., 2014) and its predecessor MADA (Habash et al., 2009), in addition to YAMAMA (Khalifa et al., 2016b), and most recently a neural morphological disambiguatior (Zalmout and Habash, 2017) and a fine grained POS tagger (Inoue et al., 2017). In addition, the PATB guidelines (Maamouri et al., 2009) have inspired the creation of similar guidelines for the dialects including our own. 2.2. Dialectal Arabic Resources In the scope of dialectal Arabic, there have been many recent contributions to the development and creation of resources. Below, we discuss the highlights of those contributions. Egyptian Arabic"
L18-1607,W15-3205,0,0.0492324,"ic verbs (CALIMAGLF ) (Khalifa et al., 2017). We are also aware of the previously developed rule-based stemmer for Arabic Gulf dialect (Abuata and Al-Omari, 2015). In this work, we use about 200,000 words from the Emirati Arabic portion of the Gumar corpus to manually annotate for tokenization, POS tagging, lemma, English gloss and dialect identification. Additionally we conventionalize the spelling in accordance with the Conventional Orthography for Dialectal Arabic (CODA) rules (Habash et al., 2012b; Habash et al., 2018). For recent surveys on Arabic resources for NLP, see Zaghouani (2014), Shoufan and Al-Ameri (2015) and Zeroual and Lakhouaja (2018). 3. Annotating the Gumar Corpus We discuss next the Gumar Corpus and the portion of it we use to annotate in this effort. 3.1. Gumar Corpus The Gumar corpus is a large-scale corpus of Gulf Arabic containing more than 100 million words. The corpus consists mainly of documents of long conversational novels  JË@ HAK  @ð P ‘Internet Novels’. This type also known as I of literature is very popular among female teenagers in the Gulf area. These novels are written mostly in dialectal Arabic, where the lengthy conversations between the characters of the story are in"
L18-1607,W07-0801,0,0.0424616,"ysis that is deeper and more compatible with Arabic morphosyntactic rules than formbased analysis (Alkuhlani and Habash, 2011). The C AMEL POS tags and features are the union of those in MSA and the dialects. Features are available to use when needed. For example case and state features are used more often in MSA; but on the other hand, dialects tend to have many more clitics than MSA, including non-MSA ones. One of the main differences between C AMEL POS and ARZATB is that the morphological features of both gender and number of nominals are annotated functionally (Alkuhlani and Habash, 2011; Smrž, 2007). This decision allows us to assign the features to the baseword without the need to specify the surface form affixes that mark form gender and number. This is not the case in ARZATB, where broken plural nouns are tagged singular because they do not use the sound plural affixes. The other main difference is that we omit case and state features for nominals, and voice and mood for verbs as the dialects have almost lost them completely, except for some  high frequency fossilized MSA forms, such as AªJ . £ TabςAã ‘of course’ which retains an indefinite ending. The main part of the word, that is"
L18-1607,P11-2007,0,0.0231158,"s the annotated corpus of Palestinian Arabic (Curras) (Jarrar et al., 2014; Jarrar et al., 2016). ARZATB and Curras were used to create morphological analyzers and disambiguators (Eskander et al., 2016). Other dialects such as Yemeni and Moroccan Arabic followed the same approach (Al-Shargi et al., 2016). In addition to the dialects mentioned above, there were recent efforts on creating corpora for other dialects, namely Tunisian and Algerian (McNeil and Faiza, 2011; Masmoudi et al., 2014; Zribi et al., 2015; Smaïli et al., 2014). Other works targeted multi-dialect corpora (Diab et al., 2010; Zaidan and Callison-Burch, 2011; Diab et al., Forthcoming 2013; Bouamor et al., 2014; Cotterell and Callison-Burch, 2014), and, most recently, the ongoing Multi Arabic Dialect and Application Resources project (MADAR) (Bouamor et al., 2018) which includes corpora for 25 different city dialects. Gulf Arabic Resources As far as Gulf Arabic (GLF) is concerned, the only existing annotated corpora include the Emirati Arabic Corpus (EAC) (Halefom et al., 2013) and the Emirati Arabic Language Acquisition Corpus (EMALAC) (Ntelitheos and Idrissi, 2017) that were created by linguists with emphasis on the phonological and morphosyntac"
L18-1607,D17-1073,1,0.800272,"Linguistic Data Consortium (LDC), and it mainly consists of newswire text from different news sources. The PATB corpus is annotated for tokenization, segmentation, POS tagging, lemmatization, diacritization, English gloss and syntactic structure. The PATB has 12 parts of more than 1.3 million words. The annotated data has been a backbone of many state-of-the-art tools such as analyzers and disambiguators including MADAMIRA (Pasha et al., 2014) and its predecessor MADA (Habash et al., 2009), in addition to YAMAMA (Khalifa et al., 2016b), and most recently a neural morphological disambiguatior (Zalmout and Habash, 2017) and a fine grained POS tagger (Inoue et al., 2017). In addition, the PATB guidelines (Maamouri et al., 2009) have inspired the creation of similar guidelines for the dialects including our own. 2.2. Dialectal Arabic Resources In the scope of dialectal Arabic, there have been many recent contributions to the development and creation of resources. Below, we discuss the highlights of those contributions. Egyptian Arabic Resources Egyptian Arabic (EGY) was one of the first dialects that received the attention of the NLP community. The earliest effort, to the best of 3839 our knowledge, is the Egy"
L18-1607,N18-1087,1,0.716492,"n Arabic Treebank (ARZATB) (Maamouri et al., 2012a; Maamouri et al., 2014) was created by the LDC using CALIMA to provide analysis options for the annotation process. The ARZATB has currently 400,000 words in eight parts annotated in a similar fashion to the PATB. The annotation guidelines for the ARZATB (Maamouri et al., 2012b) followed that of the PATB with decisions specific to the dialect. Since the release, the ARZATB has been used extensively for developing EGY resources such as the EGY part of MADAMIRA, MADA and YAMAMA, in addition to a noise-robust morphological disambiguator for EGY (Zalmout et al., 2018). Other developed corpora and POS taggers for EGY include the work of Al-Sabbagh and Girju (2012) where they created their own POS tagset and corpus with the intention to facilitate certain NLP applications like subjectivity and sentiment analysis. Levantine Arabic and and Other Dialectal Arabic Resources Levantine Arabic (LEV) received some notable efforts including the Levantine Arabic Treebank (LATB) of Jordanian Arabic (Maamouri et al., 2006) which contains around 27,000 annotated words in a similar fashion to ARZATB. A more recent resource is the annotated corpus of Palestinian Arabic (Cu"
L18-1608,W06-2920,0,0.370592,"Missing"
L18-1608,W02-1503,0,0.157572,"tactic parsing, in both pipeline and joint settings, and presenting new opportunities in the development of UD resources for low-resource languages. Keywords: Morphology, Universal Dependencies, Morphological Analysis, Morphological Ambiguity 1. Introduction The development of the universal dependencies (UD) framework and its treebank collection (Nivre et al., 2016; Nivre et al., 2017) follows many shared tasks and multilingual evaluation campaigns in which the linguistic representation schemes across different languages vary (Buchholz and Marsi, 2006; Nivre et al., 2007; Seddah et al., 2013; Butt et al., 2002; Zeman et al., 2012). The UD treebanks collection, in contrast, obeys a single set of annotation guidelines, and respects the discrepancies between surface input tokens and the output nodes in the syntax trees (a.k.a., the two-level representation principle.)1 The UD initiative has paved the way to the development of cross-lingual models for word segmentation, part-of-speech tagging and dependency parsing (Straka and Strakov´a, 2017), as well as cross-linguistic typological investigations (Futrell et al., 2015). Recently, the CoNLL 2017 Shared Task on Multilingual UD Parsing (Zeman et al., 20"
L18-1608,coltekin-2010-freely,1,0.858208,"Missing"
L18-1608,C16-1033,1,0.861239,"4), which is built on top of the databases of SAMA (Maamouri et al., 2010) to output 5 morphology that adheres to the UD Arabic treebank (Taji et al., 2017).6 The Arabic UD treebank, as with other Arabic treebanks, uses the Penn Arabic treebank tokenization scheme (Maamouri et al., 2004) which segments all proclitics and enclitics except for the definite article. It is worth noting that the format we propose here is independent of the specifics of this tokenization scheme and it can be used with a number of other schemes (Habash, 2010). For Hebrew, we used the HEBLEX morphological analyzer of More and Tsarfaty (2016), based on the BGU Lexicon (Itai and Wintner, 2008), adapted to the UD Hebrew treebank.7 We only modified the HEBLEX SPMRL lattices format to follow the proposed CoNLL-UL format, as the HEBLEX annotations have already been adapted to the treebank counterpart (More and Tsarfaty, 2017). For Turkish, we developed a new morphological analyzer based on TRmorph (C¸o¨ ltekin, 2010).8 The analyzer follows the segmentation and morphological analysis scheme of the UD Turkish treebank v2.0 (Sulubacak et al., 2016) and Turkish-PUD treebank (Zeman et al., 2017). These treebanks have employed a different se"
L18-1608,K17-3027,1,0.780254,"004) which segments all proclitics and enclitics except for the definite article. It is worth noting that the format we propose here is independent of the specifics of this tokenization scheme and it can be used with a number of other schemes (Habash, 2010). For Hebrew, we used the HEBLEX morphological analyzer of More and Tsarfaty (2016), based on the BGU Lexicon (Itai and Wintner, 2008), adapted to the UD Hebrew treebank.7 We only modified the HEBLEX SPMRL lattices format to follow the proposed CoNLL-UL format, as the HEBLEX annotations have already been adapted to the treebank counterpart (More and Tsarfaty, 2017). For Turkish, we developed a new morphological analyzer based on TRmorph (C¸o¨ ltekin, 2010).8 The analyzer follows the segmentation and morphological analysis scheme of the UD Turkish treebank v2.0 (Sulubacak et al., 2016) and Turkish-PUD treebank (Zeman et al., 2017). These treebanks have employed a different segmentation approach compared to the METU-Sabancı Turkish Treebank (Oflazer et al., 2003). In addition, form and lemma representations, POS tags and morphological tag sets have changed. The existing morphological analyzers are not compatible with this new representation. Thus we intro"
L18-1608,L16-1262,1,0.908557,"Missing"
L18-1608,pasha-etal-2014-madamira,1,0.772852,"w, and Turkish. For these morphological analyzers, their pre-existing morphological analyses adhere to schemes that differ from those employed in the respective UD treebanks. These discrepancies are due to differences between the morphological theories adopted by the UD treebanks developers and those employed by the developers of the morphological analyzers. Therefore, the adapted resources we provide are non-trivial to obtain, and required careful alignment of the morphosyntactic analyses with their UD treebank counterparts. For Arabic, we adapted the morphological analyzer used in MADAMIRA (Pasha et al., 2014), which is built on top of the databases of SAMA (Maamouri et al., 2010) to output 5 morphology that adheres to the UD Arabic treebank (Taji et al., 2017).6 The Arabic UD treebank, as with other Arabic treebanks, uses the Penn Arabic treebank tokenization scheme (Maamouri et al., 2004) which segments all proclitics and enclitics except for the definite article. It is worth noting that the format we propose here is independent of the specifics of this tokenization scheme and it can be used with a number of other schemes (Habash, 2010). For Hebrew, we used the HEBLEX morphological analyzer of Mo"
L18-1608,L18-1292,1,0.841663,"L format. 3.2. Converted Morphological Lexicons As a complement to the CoNLL-UL-compatible analyzers described above, we have created a set of 53 CoNLL-ULcompatible morphological lexicons covering 38 languages, based on existing freely available resources.9 The source lexicons, the conversion processes and the resulting inventory of freely available CoNLL-UL lexicons are described https://conllul.github.io 3850 6 https://camel.abudhabi.nyu.edu/calima-star/ https://github.com/habeanf/yap 8 https://github.com/coltekin/TRmorph/tree/trmorph2 9 http://pauillac.inria.fr/˜sagot/udlexicons.html 7 in (Sagot, 2018).10 Here we only provide in Table 3 two examples converted from the Lefff , the Alexina lexicon for French. The first one illustrates the 1-to-1 case, with an entry converted from the following original entry: encodent encoder v P3p, which includes the wordform (i.e. the [source and tree] token) encodent ‘encode3pl.pres.ind ’, its lemma, its Lefff POS and its Lefff morphosyntactic tag. The other example illustrates the 1-to-m case with the source token auxquels, which is analyzable as reflecting the sequence of two tree tokens a` lesquels ‘to which’. 4. Related Work and Perspective Our work ov"
L18-1608,W13-4917,1,0.923267,"Missing"
L18-1608,Q15-1026,1,0.906774,"Missing"
L18-1608,K17-3009,0,0.0605054,"Missing"
L18-1608,C16-1325,1,0.883776,"Missing"
L18-1608,W17-1320,1,0.835643,"ctive UD treebanks. These discrepancies are due to differences between the morphological theories adopted by the UD treebanks developers and those employed by the developers of the morphological analyzers. Therefore, the adapted resources we provide are non-trivial to obtain, and required careful alignment of the morphosyntactic analyses with their UD treebank counterparts. For Arabic, we adapted the morphological analyzer used in MADAMIRA (Pasha et al., 2014), which is built on top of the databases of SAMA (Maamouri et al., 2010) to output 5 morphology that adheres to the UD Arabic treebank (Taji et al., 2017).6 The Arabic UD treebank, as with other Arabic treebanks, uses the Penn Arabic treebank tokenization scheme (Maamouri et al., 2004) which segments all proclitics and enclitics except for the definite article. It is worth noting that the format we propose here is independent of the specifics of this tokenization scheme and it can be used with a number of other schemes (Habash, 2010). For Hebrew, we used the HEBLEX morphological analyzer of More and Tsarfaty (2016), based on the BGU Lexicon (Itai and Wintner, 2008), adapted to the UD Hebrew treebank.7 We only modified the HEBLEX SPMRL lattices"
L18-1608,P12-2002,1,0.826771,"y. As a result of the latter, we can maintain a two-way compatibility promise: every morphological disambiguation in a UD v2 treebank can be represented as a CoNLLUL lattice, and every possible path in a CoNLL-UL lattice can serve as the syntactic words of a UD-annotated tree. Thus, we ease the burden on morphological and syntax parser research and development, such that they are relieved of adapting lexical resources (or their analyses) to UD-compliant morphology. The representation scheme for lattices used by the SPMRL shared task datasets (Seddah et al., 2013) and which were introduced by (Tsarfaty et al., 2012; Tsarfaty, 2013),12 allowed for annotating morphological ambiguity of these same languages. Seeker and C ¸ etino˘glu (2015) extended the SPMRL representation to accommodate marking the gold and optionally a predicted morphological analysis. Our proposal extends the latter with two additions: (i) we use the UD convention of specifying a surface token spanning multiple tree tokens; and (ii) we allow the specification of multiple anchors relating lattice arcs to tree tokens, for possibly grounding more than one syntactic tree (i.e., a forest) in the morphological lattice. Since we wanted to main"
L18-1608,P13-2103,1,0.786276,"atter, we can maintain a two-way compatibility promise: every morphological disambiguation in a UD v2 treebank can be represented as a CoNLLUL lattice, and every possible path in a CoNLL-UL lattice can serve as the syntactic words of a UD-annotated tree. Thus, we ease the burden on morphological and syntax parser research and development, such that they are relieved of adapting lexical resources (or their analyses) to UD-compliant morphology. The representation scheme for lattices used by the SPMRL shared task datasets (Seddah et al., 2013) and which were introduced by (Tsarfaty et al., 2012; Tsarfaty, 2013),12 allowed for annotating morphological ambiguity of these same languages. Seeker and C ¸ etino˘glu (2015) extended the SPMRL representation to accommodate marking the gold and optionally a predicted morphological analysis. Our proposal extends the latter with two additions: (i) we use the UD convention of specifying a surface token spanning multiple tree tokens; and (ii) we allow the specification of multiple anchors relating lattice arcs to tree tokens, for possibly grounding more than one syntactic tree (i.e., a forest) in the morphological lattice. Since we wanted to maintain compatibilit"
L18-1608,zeman-etal-2012-hamledt,0,0.319438,"Missing"
L18-1608,K17-3001,1,0.904845,"Missing"
maamouri-etal-2006-developing,E06-1047,1,\N,Missing
maamouri-etal-2006-developing,W04-1602,1,\N,Missing
maamouri-etal-2006-developing,N04-4038,1,\N,Missing
maamouri-etal-2006-developing,P05-1071,1,\N,Missing
maamouri-etal-2014-developing,C10-1045,0,\N,Missing
maamouri-etal-2014-developing,P06-1086,1,\N,Missing
maamouri-etal-2014-developing,habash-etal-2012-conventional,1,\N,Missing
maamouri-etal-2014-developing,N13-1044,1,\N,Missing
maamouri-etal-2014-developing,pasha-etal-2014-madamira,1,\N,Missing
maamouri-etal-2014-developing,W13-2301,1,\N,Missing
maamouri-etal-2014-developing,maamouri-etal-2006-developing,1,\N,Missing
maamouri-etal-2014-developing,W12-2301,1,\N,Missing
maamouri-etal-2014-developing,L06-1000,0,\N,Missing
masmoudi-etal-2014-corpus,N09-1045,1,\N,Missing
masmoudi-etal-2014-corpus,habash-etal-2012-conventional,1,\N,Missing
masmoudi-etal-2014-corpus,zribi-etal-2014-conventional,1,\N,Missing
N03-1013,dorr-etal-2000-building,1,0.923464,"Missing"
N03-1013,dorr-etal-2002-duster,1,0.810415,"standard, we asked 8 native speakers to evaluate 400 randomly-selected clusters. Each annotator was given a set of 100 clusters (with two annotators per set). Figure 3 shows a segment of the evaluation interface which was web-browseable. HeadGen with no CatVar filter: 0.1687 This quantitative distinction correlates with humanperceived differences, e.g., between the two headlines Washingtonians fight over drugs and In the nation’s capital (generated for the same story—with and without CatVar, respectively). 4.3 DUSTer DUSTer—Divergence Unraveling for Statistical Translation—was introduced in (Dorr et al., 2002). In this system, common divergence types are systematically identified and English sentences are transformed to bear a closer resemblance to that of another language using a mapping referred to as -to- . The objective is to enable more accurate alignment and projection of dependency trees in another language without requiring any training on dependency-tree data in that language. The CatVar database has been incorporated into two components of the DUSTer system: (1) In the -tomapping, e.g., the transformation from kick to LightVB kick (corresponding to the English/Spanish divergence"
N03-1013,P01-1032,1,0.877681,"Missing"
N03-1013,habash-dorr-2002-handling,1,0.845734,"to bear a closer resemblance to that of another language using a mapping referred to as -to- . The objective is to enable more accurate alignment and projection of dependency trees in another language without requiring any training on dependency-tree data in that language. The CatVar database has been incorporated into two components of the DUSTer system: (1) In the -tomapping, e.g., the transformation from kick to LightVB kick (corresponding to the English/Spanish divergence    6  The other conditions on conflatability and some detailed examples are discussed in (Habash, 2002) and (Habash and Dorr, 2002). 7 For details about the Bleu evaluation metric, see (Papineni et al., 2002). Figure 3: Evaluation The annotators were given detailed instructions and many examples to help them with the task. They were asked to classify each word in every cluster as belonging to one of the following categories: Perfect: This word definitely belongs in this cluster. Perfect (except for part of speech problem). Perfect (except for spelling problem). Not Sure: It is not clear whether a word that is derivationally correct belongs in a set or not. Doesn’t Belong: This word doesn’t belong in this cluster. May not"
N03-1013,W02-2125,1,0.902187,"o cluster. The database was inspired by pairs such as cross and across  which are used in Generation-Heavy MT. But since verb-preposition clusters are not typically morphologically related, they are 3 An English Verb-Noun list extracted from LDOCE was provided by Rebecca Green. 4 For example, in a headline generation system (HeadGen), higher Bleu scores were obtained when using the portions of the CatVar database that are most relevant to nominalized events (e.g., NOMLEX). 4.1 Generation-Heavy Machine Translation The Generation-Heavy Hybrid Machine Translation (GHMT) model was introduced in (Habash, 2002) to handle translation divergences between language pairs with asymmetrical (poor-source/rich-target) resources. The approach does not rely on a transfer lexicon or a common interlingual representation to map between divergent structural configurations from source to target language. Instead, different alternative structural configurations are over-generated and these are statistically ranked using a language model. 5 This supplementary database includes 242 clusters for more than 230 verbs and 29 prepositions. Other examples of verb-preposition clusters include: avoid and away from ; enter an"
N03-1013,C92-3145,0,0.0279957,"Missing"
N03-1013,P98-1116,0,0.0139513,"Missing"
N03-1013,P96-1004,0,0.0378019,"Missing"
N03-1013,J93-2004,0,0.0231914,"s in the search algorithm, might even appear in some of the top ranked choices. Given these issues, our goal is to build a database of categorial variations that can be used with both expansionist and reductionist approaches without the cost of over/under-stemming/generation. The research reported herein is relevant to MT, IR, and lexicon construction. 3 Building the CatVar The CatVar database was developed using a combination of resources and algorithms including the Lexical Conceptual Structure (LCS) Verb and Preposition Databases (Dorr, 2001), the Brown Corpus section of the Penn Treebank (Marcus et al., 1993), an English morphological analysis lexicon developed for PC-Kimmo (Englex) (Antworth, 1990), NOMLEX (Macleod et al., 1998), Longman Dictionary of Contemporary English 2 For a deeper discussion and classification of Porter stemmer’s errors, see (Krovetz, 1993). (LDOCE)3 (Procter, 1983), WordNet 1.6 (Fellbaum, 1998), and the Porter stemmer. The contribution of each of these sources is clearly labeled in the CatVar database, thus enabling the use of different cross-sections of the resource for different applications.4 Some of these resources were used to extract seed links between different word"
N03-1013,P02-1040,0,0.0778672,"Missing"
N03-1013,C00-1007,0,\N,Missing
N03-1013,C98-1112,0,\N,Missing
N06-2013,P05-1071,1,0.411395,"Missing"
N06-2013,koen-2004-pharaoh,0,0.0322123,"Missing"
N06-2013,W04-3250,0,0.121742,"Missing"
N06-2013,N04-4015,0,0.472245,"2004); Spanish, Catalan, and Serbian (Popovi´c and Ney, 2004); and Czech (Goldwater and McClosky, 2005). They all studied 2 We conducted several additional experiments that we do not report on here for lack of space but we reserve for a separate technical report. 49 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 49–52, c New York, June 2006. 2006 Association for Computational Linguistics the effects of various kinds of tokenization, lemmatization and POS tagging and show a positive effect on SMT quality. Specifically considering Arabic, Lee (2004) investigated the use of automatic alignment of POS tagged English and affix-stem segmented Arabic to determine appropriate tokenizations. Her results show that morphological preprocessing helps, but only for the smaller corpora. As size increases, the benefits diminish. Our results are comparable to hers in terms of BLEU score and consistent in terms of conclusions. We extend on previous work by experimenting with a wider range of preprocessing schemes for Arabic, by studying the effect of morphological disambiguation (beyond POS tagging) on preprocessing schemes over learning curves, and by"
N06-2013,P03-1021,0,0.0968139,"Missing"
N06-2013,2001.mtsummit-papers.68,0,0.0435829,"Missing"
N06-2013,popovic-ney-2004-towards,0,0.170018,"Missing"
N06-2013,J04-2003,0,0.0866808,"ackground on Arabic linguistics to motivate the schemes discussed in Section 4. Section 5 presents the tools and data sets used, along with the results of our experiments. Section 6 contains a discussion of the results. 2 Previous Work The anecdotal intuition in the field is that reduction of word sparsity often improves translation quality. This reduction can be achieved by increasing training data or via morphologically driven preprocessing (Goldwater and McClosky, 2005). Recent publications on the effect of morphology on SMT quality focused on morphologically rich languages such as German (Nießen and Ney, 2004); Spanish, Catalan, and Serbian (Popovi´c and Ney, 2004); and Czech (Goldwater and McClosky, 2005). They all studied 2 We conducted several additional experiments that we do not report on here for lack of space but we reserve for a separate technical report. 49 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 49–52, c New York, June 2006. 2006 Association for Computational Linguistics the effects of various kinds of tokenization, lemmatization and POS tagging and show a positive effect on SMT quality. Specifically considering Arabic, Lee ("
N06-2013,W05-0822,1,0.704448,"). D2 splits off the class of particles (l+, k+, b+ and s+) beyond D1. Finally D3 splits off what D2 does in addition to the definite article (Al+) and all pronominal clitics. MR: Morphemes. This scheme breaks up words into stem and affixival morphemes. EN: English-like. This scheme is intended to minimize differences between Arabic and English. It decliticizes similarly to D3; however, it uses lexeme and English-like POS tags instead of the regenerated word and it indicates the pro-dropped verb subject explicitly as a separate token. 5 Experiments We use the phrase-based SMT system, Portage (Sadat et al., 2005). For training, Portage uses IBM word alignment models (models 1 and 2) trained 51 bzyArp with visit AlY to trkyA. Turkey . bzyArp bzyArp b+ zyArp b+ zyArp b+ zyAr +p b+ zyArp  AlY  lY  lY  lY  lY  lY  trkyA trkyA trkyA trkyA trkyA trkyA   . . . . . . in both directions to extract phrase tables. Maximum phrase size used is 8. Trigram language models are implemented using the SRILM toolkit (Stolcke, 2002). Decoding weights are optimized using Och’s algorithm (Och, 2003) to set weights for the four components of the log-linear model: language model, phrase translation model, distortion"
N06-2013,P02-1040,0,\N,Missing
N06-2013,H05-1085,0,\N,Missing
N07-2007,P06-1097,0,0.022919,"ed in Section 6. 1 The second author was supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. HR0011-06-C-0023. Any opinions, findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. We thank Necip Ayan, Mona Diab, Bonnie Dorr, Abe Ittycheriah, Martin Jansche and Owen Rambow for helpful discussions. Recently, several successful attempts have been made at using supervised machine learning for word alignment (Liu et al., 2005; Taskar et al., 2005; Ittycheriah and Roukos, 2005; Fraser and Marcu, 2006). In contrast to generative models, this framework is easier to extend with new features. With the exception of Fraser and Marcu (2006), these previous publications do not entirely discard the generative models in that they integrate IBM model predictions as features. We extend on this approach by including alignment information based on multiple preprocessing schemes in the alignment process. In other related work, Tillmann et al. (1997) use several preprocessing strategies on both source and target language to make them more alike with regards to sentence length and word order. Lee (2004) on"
N07-2007,N06-1060,0,0.0502166,"Missing"
N07-2007,P05-1071,1,0.812019,"+ + w+ s+ yktbhA T B Arabic Treebank  + !      + w+ syktb +hA D3 split all clitics  + !     + + w+ s+ yktb +hA "" class of pronominal clitics, +PRON, (e.g., + +hA her/it/its). Next comes the class of particles (PART+), (e.g., + s+ will [future]). Most shallow is the class of conjunctions (CONJ+), (e.g., + w+ and). We use the following five schemes: AR, D1, D2, D3 and T B. Definitions and contrastive examples of these schemes are presented in Table 1. To create these schemes, we use M ADA, an off-the-shelf resource for Arabic morphological disambiguation (Habash and Rambow, 2005), and T OKAN, a general Arabic tokenizer (Habash and Sadat, 2006). 4 Preprocessing Schemes for Alignment Using a preprocessing scheme for word alignment breaks the process of applying Giza++ (Och and Ney, 2003) on some parallel text into three steps: preprocessing, alignment and remapping. In preprocessing, the words are tokenized into smaller units. Then, they are passed along to Giza++ for alignment (default settings). Finally, the Giza++ alignments are mapped back (remapped) to the original word form which is AR tokens in this work. For instance, take the first word in Table 1, wsyktbhA; if"
N07-2007,N06-2013,1,0.933929,"rabic) to induce morphological and syntactic symmetry between the parallel sentences. We differ from these two in that we do not decide on a certain scheme to make source and target sentences more symmetrical. Instead, it is left to the alignment algorithm to decide under which circumstances alignment information based on a specific scheme is more likely to be correct than information based on other schemes. 3 Arabic Preprocessing Schemes Arabic is a morphologically complex language with a large set of morphological features. As such, the set of possible preprocessing schemes is rather large (Habash and Sadat, 2006). We focus here on a subset of schemes pertaining to Arabic attachable clitics. There are three degrees of cliticization that apply to a word BASE: ([CONJ+ [PART+ [Al+ BASE +PRON]]]). At the deepest level, the BASE can have a definite article + (Al+ the)2 or a member of the 2 Arabic is transliterated in Buckwalter’s transliteration scheme. 25 Proceedings of NAACL HLT 2007, Companion Volume, pages 25–28, c Rochester, NY, April 2007. 2007 Association for Computational Linguistics Table 1: Arabic preprocessing scheme variants for     ’and he will write it’  Preprocessing Scheme Exampl"
N07-2007,H05-1012,0,0.419394,"pectively. Results are presented in Section 6. 1 The second author was supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. HR0011-06-C-0023. Any opinions, findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. We thank Necip Ayan, Mona Diab, Bonnie Dorr, Abe Ittycheriah, Martin Jansche and Owen Rambow for helpful discussions. Recently, several successful attempts have been made at using supervised machine learning for word alignment (Liu et al., 2005; Taskar et al., 2005; Ittycheriah and Roukos, 2005; Fraser and Marcu, 2006). In contrast to generative models, this framework is easier to extend with new features. With the exception of Fraser and Marcu (2006), these previous publications do not entirely discard the generative models in that they integrate IBM model predictions as features. We extend on this approach by including alignment information based on multiple preprocessing schemes in the alignment process. In other related work, Tillmann et al. (1997) use several preprocessing strategies on both source and target language to make them more alike with regards to sentence length and"
N07-2007,N03-1017,0,0.0161906,"Missing"
N07-2007,N04-4015,0,0.0929163,"Marcu, 2006). In contrast to generative models, this framework is easier to extend with new features. With the exception of Fraser and Marcu (2006), these previous publications do not entirely discard the generative models in that they integrate IBM model predictions as features. We extend on this approach by including alignment information based on multiple preprocessing schemes in the alignment process. In other related work, Tillmann et al. (1997) use several preprocessing strategies on both source and target language to make them more alike with regards to sentence length and word order. Lee (2004) only changes the word segmentation of the morphologically complex language (Arabic) to induce morphological and syntactic symmetry between the parallel sentences. We differ from these two in that we do not decide on a certain scheme to make source and target sentences more symmetrical. Instead, it is left to the alignment algorithm to decide under which circumstances alignment information based on a specific scheme is more likely to be correct than information based on other schemes. 3 Arabic Preprocessing Schemes Arabic is a morphologically complex language with a large set of morphological"
N07-2007,P05-1057,0,0.0639148,"ment preprocessing and combination, respectively. Results are presented in Section 6. 1 The second author was supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. HR0011-06-C-0023. Any opinions, findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. We thank Necip Ayan, Mona Diab, Bonnie Dorr, Abe Ittycheriah, Martin Jansche and Owen Rambow for helpful discussions. Recently, several successful attempts have been made at using supervised machine learning for word alignment (Liu et al., 2005; Taskar et al., 2005; Ittycheriah and Roukos, 2005; Fraser and Marcu, 2006). In contrast to generative models, this framework is easier to extend with new features. With the exception of Fraser and Marcu (2006), these previous publications do not entirely discard the generative models in that they integrate IBM model predictions as features. We extend on this approach by including alignment information based on multiple preprocessing schemes in the alignment process. In other related work, Tillmann et al. (1997) use several preprocessing strategies on both source and target language to make t"
N07-2007,2006.amta-papers.11,0,0.119402,"Missing"
N07-2007,P00-1056,0,0.0434476,"al 2003 (663 Arabic sentences each human aligned to four English references). To get initial Giza++ alignments, we use a larger parallel corpus together with the annotated set. The Arabic-English parallel corpus has about 5 million words.5 The Arabic text in IBMAC is preprocessed in the AR preprocessing scheme with some additional character normalizations. We match the preprocessing and normalizations on our additional data to that of IBMAC’s Arabic and English preprocessing (Ittycheriah and Roukos, 2005). The standard evaluation metric within word alignment is the Alignment Error Rate (AER) (Och and Ney, 2000), which requires gold alignments that are marked as ’sure’ or ’probable’. Since the IBMAC gold alignments we use are not marked as such, AER reduces to 1 - F-score (Ittycheriah and Roukos, 2005): Pr = |A∩S| |A| Rc = |A∩S| |S| AER = 1 − 2P rRc P r+Rc where A links are proposed and S links are gold. 3 We use the AER on the development data normalized so all weights sum to one. See Section 6.2. 4 We thank IBM for making their hand aligned data available to the research community. 5 All of the training data we use is available from the Linguistic Data Consortium (LDC). The parallel text includes A"
N07-2007,J03-1002,0,0.0284435,"ext comes the class of particles (PART+), (e.g., + s+ will [future]). Most shallow is the class of conjunctions (CONJ+), (e.g., + w+ and). We use the following five schemes: AR, D1, D2, D3 and T B. Definitions and contrastive examples of these schemes are presented in Table 1. To create these schemes, we use M ADA, an off-the-shelf resource for Arabic morphological disambiguation (Habash and Rambow, 2005), and T OKAN, a general Arabic tokenizer (Habash and Sadat, 2006). 4 Preprocessing Schemes for Alignment Using a preprocessing scheme for word alignment breaks the process of applying Giza++ (Och and Ney, 2003) on some parallel text into three steps: preprocessing, alignment and remapping. In preprocessing, the words are tokenized into smaller units. Then, they are passed along to Giza++ for alignment (default settings). Finally, the Giza++ alignments are mapped back (remapped) to the original word form which is AR tokens in this work. For instance, take the first word in Table 1, wsyktbhA; if the D3 preprocesssing scheme is applied to it before alignment, it is turned into four tokens (w+ s+ yktb +hA). Giza++ will link these tokens to different words on the English side. In the remapping step, the"
N07-2007,P06-1001,1,0.865906,"machine translation (SMT).1 Although phrasebased approaches to SMT tend to be robust to wordalignment errors (Lopez and Resnik, 2006), improving word-alignment is still useful for other NLP research that is more sensitive to alignment quality, e.g., projection of information across parallel corpora (Yarowsky et al., 2001). In this paper, we present a novel approach to using and combining multiple preprocessing (tokenization) schemes to improve word alignment. The intuition here is similar to the combination of different preprocessing schemes for a morphologically rich language as part of SMT (Sadat and Habash, 2006) except that the focus is on improving the alignment quality. The language pair we work with is Arabic-English. In the following two sections, we present related work and Arabic preprocessing schemes. Section 4 and 5 present our approach to alignment preprocessing and combination, respectively. Results are presented in Section 6. 1 The second author was supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. HR0011-06-C-0023. Any opinions, findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect th"
N07-2007,H05-1010,0,0.0407494,"and combination, respectively. Results are presented in Section 6. 1 The second author was supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. HR0011-06-C-0023. Any opinions, findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. We thank Necip Ayan, Mona Diab, Bonnie Dorr, Abe Ittycheriah, Martin Jansche and Owen Rambow for helpful discussions. Recently, several successful attempts have been made at using supervised machine learning for word alignment (Liu et al., 2005; Taskar et al., 2005; Ittycheriah and Roukos, 2005; Fraser and Marcu, 2006). In contrast to generative models, this framework is easier to extend with new features. With the exception of Fraser and Marcu (2006), these previous publications do not entirely discard the generative models in that they integrate IBM model predictions as features. We extend on this approach by including alignment information based on multiple preprocessing schemes in the alignment process. In other related work, Tillmann et al. (1997) use several preprocessing strategies on both source and target language to make them more alike with r"
N07-2007,P97-1037,0,0.111988,"essful attempts have been made at using supervised machine learning for word alignment (Liu et al., 2005; Taskar et al., 2005; Ittycheriah and Roukos, 2005; Fraser and Marcu, 2006). In contrast to generative models, this framework is easier to extend with new features. With the exception of Fraser and Marcu (2006), these previous publications do not entirely discard the generative models in that they integrate IBM model predictions as features. We extend on this approach by including alignment information based on multiple preprocessing schemes in the alignment process. In other related work, Tillmann et al. (1997) use several preprocessing strategies on both source and target language to make them more alike with regards to sentence length and word order. Lee (2004) only changes the word segmentation of the morphologically complex language (Arabic) to induce morphological and syntactic symmetry between the parallel sentences. We differ from these two in that we do not decide on a certain scheme to make source and target sentences more symmetrical. Instead, it is left to the alignment algorithm to decide under which circumstances alignment information based on a specific scheme is more likely to be corr"
N07-2007,H01-1035,0,0.123484,"Missing"
N07-2014,A00-2013,0,\N,Missing
N07-2014,H05-1060,0,\N,Missing
N07-2014,W04-1612,0,\N,Missing
N07-2014,P05-1071,1,\N,Missing
N07-2014,P06-1073,0,\N,Missing
N07-2014,P03-1004,0,\N,Missing
N07-2014,gimenez-marquez-2004-svmtool,0,\N,Missing
N09-1045,W09-0807,1,0.835986,"Missing"
N09-1045,P05-1071,1,0.75991,"ages with complex letter-to-sound mappings, such dictionaries are typically written by hand. However, for morphologically rich languages, such as MSA,1 pronunciation dictionaries are difficult to create by hand, because of the large number of word forms, each of which has a large number of possible pronunciations. Fortunately, the relationship between orthography and pronunciation is relatively regular and well understood for MSA. Moreover, recent automatic techniques for morphological analysis and disambiguation (MADA) can also be useful in automating part of the dictionary creation process (Habash and Rambow, 2005; Habash and Rambow, 2007) Nonetheless, most documented Arabic ASR systems appear to handle only a subset of Arabic phonetic phenomena; very few use morphological disambiguation tools. In Section 2, we briefly describe related work, including the baseline system we use. In Section 3, we outline the linguistic phenomena we believe are critical to improving MSA pronunciation dictionaries. In Section 4, we describe the pronunciation rules we have developed based upon these linguistic phenomena. In Section 5, we describe how these rules are used, together with MADA, to build our pronunciation dict"
N09-1045,P06-1086,1,0.645739,"Missing"
N09-1045,N07-2014,1,0.474331,"to-sound mappings, such dictionaries are typically written by hand. However, for morphologically rich languages, such as MSA,1 pronunciation dictionaries are difficult to create by hand, because of the large number of word forms, each of which has a large number of possible pronunciations. Fortunately, the relationship between orthography and pronunciation is relatively regular and well understood for MSA. Moreover, recent automatic techniques for morphological analysis and disambiguation (MADA) can also be useful in automating part of the dictionary creation process (Habash and Rambow, 2005; Habash and Rambow, 2007) Nonetheless, most documented Arabic ASR systems appear to handle only a subset of Arabic phonetic phenomena; very few use morphological disambiguation tools. In Section 2, we briefly describe related work, including the baseline system we use. In Section 3, we outline the linguistic phenomena we believe are critical to improving MSA pronunciation dictionaries. In Section 4, we describe the pronunciation rules we have developed based upon these linguistic phenomena. In Section 5, we describe how these rules are used, together with MADA, to build our pronunciation dictionaries for training and"
N09-1045,W04-1612,0,0.17158,"Missing"
N09-1045,P06-1073,0,0.0614355,"Missing"
N13-1036,al-sabbagh-girju-2010-mining,0,0.095797,"(Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA or other methods to collect word-pair lists have been explored. For example, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. This hybrid system consisted of a statistical system for tokenizing and tagging, and a rule-based system for constructing diacritized MSA sentences. Moreover, Al-Sabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. In the context of DA-to-English SMT, Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut the OOV words by half. Machine Translation for Closely Related Languages. Using closely related languages has been shown to improve MT quality when resources are limited. Hajiˇc et al. (2000) argued that for very close languages, e.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based"
N13-1036,N06-1003,0,0.0501077,"Missing"
N13-1036,E06-1047,1,0.259214,"d sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA or other methods to collect word-pair lists have been explored. For example, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. This hybrid system consisted of a statistical system for tokenizing and tagging, and a rule-based system for constructing diacritized MSA sentences. Moreover, Al-Sabbagh and Girju ("
N13-1036,D10-1041,0,0.0274909,"Missing"
N13-1036,W05-0708,0,0.0751909,"itized forms: Levantine wHayikitbuwhA and MSA wasayaktubuwnahA. All of the NLP challenges of MSA (e.g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or tran"
N13-1036,P05-1071,1,0.765405,"words and construct a lattice of possible sentences. E LISSA uses a language model to rank and select the generated sentences. E LISSA supports untokenized (raw) input only. E LISSA supports three types of output: top-1 choice, an n-best list or a map file that maps source words/phrases to target phrases. The top-1 and nbest lists are determined using an untokenized MSA language model to rank the paths in the MSA translation output lattice. This variety of output types makes it easy to plug E LISSA with other systems and to use it as a DA preprocessing tool for other MSA systems, e.g., MADA (Habash and Rambow, 2005) or AMIRA (Diab et al., 2007). E LISSA’s approach consists of three major steps preceded by a preprocessing and normalization step, that prepares the input text to be handled (e.g., UTF8 cleaning, Alif/Ya normalization, word-lengthening normalization), and followed by a post-processing step, that produces the output in the desired form (e.g., encoding choice). The three major steps are Selection, Translation, and Language Modeling. 5.1 Selection In the first step, E LISSA identifies which words or phrases to paraphrase and which words or phrases to leave as is. E LISSA provides different metho"
N13-1036,P06-1086,1,0.130438,"HayikitbuwhA and MSA wasayaktubuwnahA. All of the NLP challenges of MSA (e.g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA a"
N13-1036,W12-2301,1,0.241697,"diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translat"
N13-1036,N13-1044,1,0.698026,"ng inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA or other m"
N13-1036,A00-1002,0,0.0764371,"Missing"
N13-1036,P07-2045,0,0.00524198,"opied from Table 1 for convenience. The second part shows E LISSA’s output on the dialectal sentence and its Google Translate translation. The produced MSA is not perfect, but is clearly an improvement over doing nothing as far as usability for MT into English. 6 Evaluation In this section, we present two evaluations of E LISSA. The first is an extrinsic evaluation of E LISSA as part of MSA-pivoting for DA-to-English SMT. And the second is an intrinsic evaluation of the quality of E LISSA’s MSA output. 6.1 DA-English MT Evaluation 6.1.1 Experimental Setup We use the open-source Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system trained on mostly MSA data (64M words on the Arabic side) obtained from several LDC corpora including some limited DA data. Our system uses 353 a standard phrase-based architecture. The parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003). Phrase translations of up to 10 words are extracted in the Moses phrase table. The language model for our system is trained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to m"
N13-1036,W04-3250,0,0.191227,"Missing"
N13-1036,D07-1005,0,0.0229654,"2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual 350 paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-toEnglish SMT system. Pivoting on MSA or acquiring more DA-English data? Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data. They used Amazon’s Mechanical Turk (MTurk) to create a DAEnglish parallel corpus"
N13-1036,P11-1130,0,0.0276512,"Missing"
N13-1036,J03-1002,0,0.00280414,"ion, we present two evaluations of E LISSA. The first is an extrinsic evaluation of E LISSA as part of MSA-pivoting for DA-to-English SMT. And the second is an intrinsic evaluation of the quality of E LISSA’s MSA output. 6.1 DA-English MT Evaluation 6.1.1 Experimental Setup We use the open-source Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system trained on mostly MSA data (64M words on the Arabic side) obtained from several LDC corpora including some limited DA data. Our system uses 353 a standard phrase-based architecture. The parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003). Phrase translations of up to 10 words are extracted in the Moses phrase table. The language model for our system is trained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization s"
N13-1036,P03-1021,0,0.00284424,"Arabic side) obtained from several LDC corpora including some limited DA data. Our system uses 353 a standard phrase-based architecture. The parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003). Phrase translations of up to 10 words are extracted in the Moses phrase table. The language model for our system is trained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are used for word alignment. We use the same development (dev) and test sets used by Salloum and Habash (2011) (we will call them speech-dev and speech-test, respectively) and we compare to them"
N13-1036,P02-1040,0,0.115427,"h-test set has 1,568 sentences with 32,492 untokenized Arabic words. The web-levtest set has 2,728 sentences with 21,179 untokenized Arabic words. The web-egy-test set has 1,553 sentences with 21,495 untokenized Arabic words. The two speech test sets contain multi-dialect (e.g., Iraqi, Levantine, Gulf, and Egyptian) broadcast conversational (BC) segments (with three reference translations), and broadcast news (BN) segments (with only one reference, replicated three times). The web-egy-test has two references while the web-levtest has only one reference. Results are presented in terms of BLEU (Papineni et al., 2002). All evaluation results are case insensitive. 6.1.2 Results on the Development Set We experimented with different method combinations in the selection and translation components in E LISSA. We use the term selection mode and translation mode to denote a certain combination of methods in selection or translation, respectively. Due to limited space, we only present the best selection mode variation experiments. Other selection modes were tried but they proved to be consistently lower than the rest. The ‘F2F+L2L; S2S’ wordbased translation mode (using morphological transfer of features and lemma"
N13-1036,2006.amta-papers.21,0,0.783834,"anslations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA or other methods to collect word-pair lists have been explored. For example, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. This hybrid system consisted of a statistical system for tokenizing and tagging, and a rule-based system for constructing diacritized MSA sentences. Moreover, Al-Sabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. In the context of DA-to-English SMT, Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut the OOV words by half. Machine Translation for Closely Related Languages. Using closely related languages has been shown to improve MT quality when resources are limited. Hajiˇc et al. (2000) argued that for very close languages, e.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of"
N13-1036,P08-2030,1,0.0693574,"rained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are used for word alignment. We use the same development (dev) and test sets used by Salloum and Habash (2011) (we will call them speech-dev and speech-test, respectively) and we compare to them in the next sections. We also evaluate on two web-crawled blind test sets: the Levantine test set presented in Zbib et al. (2012) (we will call it web-lev-test) and the Egyptian Dev-MTv2 development data of the DARPA BOLT program (we will call it web-egy-test). The speech-dev set has 1,496 sentences with 32,047 untokenized Arabic"
N13-1036,W11-2602,1,0.0985788,"es of MSA (e.g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-base"
N13-1036,C12-3048,1,0.41933,"is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual 350 paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich l"
N13-1036,2010.amta-papers.5,0,0.480498,"rithm for online morpheme segmentation on DA that cut the OOV words by half. Machine Translation for Closely Related Languages. Using closely related languages has been shown to improve MT quality when resources are limited. Hajiˇc et al. (2000) argued that for very close languages, e.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar"
N13-1036,N07-1061,0,0.012301,"ialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual 350 paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-toEnglish SMT system. Pivoting on MSA or acquiring more DA-English data? Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data. They used Amazon’s Mechanical Turk (MTurk) to create a DAEng"
N13-1036,N12-1006,0,0.299482,"The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are used for word alignment. We use the same development (dev) and test sets used by Salloum and Habash (2011) (we will call them speech-dev and speech-test, respectively) and we compare to them in the next sections. We also evaluate on two web-crawled blind test sets: the Levantine test set presented in Zbib et al. (2012) (we will call it web-lev-test) and the Egyptian Dev-MTv2 development data of the DARPA BOLT program (we will call it web-egy-test). The speech-dev set has 1,496 sentences with 32,047 untokenized Arabic words. The speech-test set has 1,568 sentences with 32,492 untokenized Arabic words. The web-levtest set has 2,728 sentences with 21,179 untokenized Arabic words. The web-egy-test set has 1,553 sentences with 21,495 untokenized Arabic words. The two speech test sets contain multi-dialect (e.g., Iraqi, Levantine, Gulf, and Egyptian) broadcast conversational (BC) segments (with three reference tr"
N13-1036,P98-2238,0,0.101284,"mining the web to build a DA-to-MSA lexicon. In the context of DA-to-English SMT, Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut the OOV words by half. Machine Translation for Closely Related Languages. Using closely related languages has been shown to improve MT quality when resources are limited. Hajiˇc et al. (2000) argued that for very close languages, e.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich"
N13-1036,P11-2062,1,\N,Missing
N13-1036,C98-2233,0,\N,Missing
N13-1036,D08-1076,0,\N,Missing
N13-1044,J95-4004,0,0.652028,"Missing"
N13-1044,E06-1047,1,0.883658,"Missing"
N13-1044,W07-0812,0,0.0536773,"Missing"
N13-1044,W05-0708,0,0.22811,"Missing"
N13-1044,N13-1066,1,0.6732,"ture proclitic +  sa+ appears in ARZ as +ë ha+. There are some morphemes in ARZ that do not exist in MSA such as the negation circum-clitic + . . . + AÓ mA+ . . . +š. And there are MSA features that are absent from ARZ, most notably case and mood. Since there are no orthographic standards, ARZ words may be written in a variety of ways reflecting different writing rules, e.g., phonologically or etymologically. A conventional orthography for Dialectal Arabic (CODA) has been proposed and used for writing ARZ in the context of NLP applications (Habash et al., 2012a; Al-Sabbagh and Girju, 2012; Eskander et al., 2013). Finally, MSA and ARZ coexist and are often used interchangeably, especially in more formal settings. The CALIMA morphological analyzer we use addresses several of these issues by modeling both ARZ and MSA together, including a limited set of inter-dialect morphology phenomena, and by mapping ARZ words into CODA orthography internally while accepting a wide range of spelling variants. 4 4.1 Approach The MADA Approach MADA is a method for Arabic morphological analysis and disambiguation (Habash and Rambow, 2005; Roth et al., 2008). MADA uses a morphological analyzer to produce, for each input"
N13-1044,W08-0509,0,0.033935,"Missing"
N13-1044,P05-1071,1,0.827859,"n the context of NLP applications (Habash et al., 2012a; Al-Sabbagh and Girju, 2012; Eskander et al., 2013). Finally, MSA and ARZ coexist and are often used interchangeably, especially in more formal settings. The CALIMA morphological analyzer we use addresses several of these issues by modeling both ARZ and MSA together, including a limited set of inter-dialect morphology phenomena, and by mapping ARZ words into CODA orthography internally while accepting a wide range of spelling variants. 4 4.1 Approach The MADA Approach MADA is a method for Arabic morphological analysis and disambiguation (Habash and Rambow, 2005; Roth et al., 2008). MADA uses a morphological analyzer to produce, for each input word, a list of analyses specifying every possible morphological interpretation of that word, covering all morphological features of the word (diacritization, POS, lemma, and 13 inflectional and clitic features). MADA then applies a set of models (support vector machines and N-gram language models) to produce a prediction, per word in-context, for different morphological features, such as POS, lemma, gender, number or person. A ranking component scores the analyses produced by the morphological analyzer using a"
N13-1044,P06-1086,1,0.693833,"Missing"
N13-1044,N06-2013,1,0.877369,"Missing"
N13-1044,habash-etal-2012-conventional,1,0.598422,"of Arabic (Habash and Rambow, 2005). The approach used in MADA, which was inspired by earlier work by Hajiˇc (2000), disambiguates in context for every aspect of Arabic morphology, thus solving all tasks in “one fell swoop”. The disadvantage of the MADA approach is its dependence on two complex resources: a morphological analyzer for the language and a large collection of manually annotated words for all morphological features in the same representation used by the analyzer. For ARZ, such resources have recently become available, with the development of the CALIMA ARZ morphological analyzer (Habash et al., 2012b) and the release by the Linguistic Data Consortium (LDC) of a large ARZ corpus annotated morphologically in a manner compatible with CALIMA (Maamouri et al., 2012a). In the work presented here, we utilize these new resources within the paradigm of MADA, transforming MADA into MADA-ARZ. The elegance of the MADA solution makes this conceptually a simple extension. Our evaluation demonstrates that our Egyptian DA version of MADA, henceforth MADA-ARZ, outperforms MADA for MSA on ARZ morphological tagging and improves the quality of ARZ to English statistical machine translation (MT). The rest of"
N13-1044,W12-2301,1,0.811988,"of Arabic (Habash and Rambow, 2005). The approach used in MADA, which was inspired by earlier work by Hajiˇc (2000), disambiguates in context for every aspect of Arabic morphology, thus solving all tasks in “one fell swoop”. The disadvantage of the MADA approach is its dependence on two complex resources: a morphological analyzer for the language and a large collection of manually annotated words for all morphological features in the same representation used by the analyzer. For ARZ, such resources have recently become available, with the development of the CALIMA ARZ morphological analyzer (Habash et al., 2012b) and the release by the Linguistic Data Consortium (LDC) of a large ARZ corpus annotated morphologically in a manner compatible with CALIMA (Maamouri et al., 2012a). In the work presented here, we utilize these new resources within the paradigm of MADA, transforming MADA into MADA-ARZ. The elegance of the MADA solution makes this conceptually a simple extension. Our evaluation demonstrates that our Egyptian DA version of MADA, henceforth MADA-ARZ, outperforms MADA for MSA on ARZ morphological tagging and improves the quality of ARZ to English statistical machine translation (MT). The rest of"
N13-1044,A00-2013,0,0.167854,"Missing"
N13-1044,P07-2045,0,0.0056658,"Missing"
N13-1044,maamouri-etal-2006-developing,1,0.918685,"Missing"
N13-1044,mohamed-etal-2012-annotating,0,0.102356,"Missing"
N13-1044,P03-1021,0,0.0143296,"English MT MT Experimental Settings We use the opensource Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system. We use MGIZA++ for word alignment (Gao and Vogel, 2008). Phrase translations of up to 8 words are extracted in the phrase table. We use SRILM (Stolcke, 2002) with modified Kneser-Ney smoothing to build two 4gram language models. The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data. Feature weights are tuned to maximize BLEU (Papineni et al., 2002) on a development set using Minimum Error Rate Training (Och, 2003). We perform caseinsensitive evaluation in terms of BLEU , METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006) metrics. Data We trained on DA-English parallel data (Egyptian and Levantine) obtained from several LDC corpora. The training data amounts to 3.8M untokenized words on the Arabic side. The dev set, used for tuning the parameters of the MT system, has 15,585 untokenized Arabic words. The test set has 12,116 untokenized Arabic words. Both dev and test data contain two sets of reference translations. The English data is lower-cased and tokenized using simple punctuation-based"
N13-1044,P02-1040,0,0.105292,"Missing"
N13-1044,P08-2030,1,0.554215,"ications (Habash et al., 2012a; Al-Sabbagh and Girju, 2012; Eskander et al., 2013). Finally, MSA and ARZ coexist and are often used interchangeably, especially in more formal settings. The CALIMA morphological analyzer we use addresses several of these issues by modeling both ARZ and MSA together, including a limited set of inter-dialect morphology phenomena, and by mapping ARZ words into CODA orthography internally while accepting a wide range of spelling variants. 4 4.1 Approach The MADA Approach MADA is a method for Arabic morphological analysis and disambiguation (Habash and Rambow, 2005; Roth et al., 2008). MADA uses a morphological analyzer to produce, for each input word, a list of analyses specifying every possible morphological interpretation of that word, covering all morphological features of the word (diacritization, POS, lemma, and 13 inflectional and clitic features). MADA then applies a set of models (support vector machines and N-gram language models) to produce a prediction, per word in-context, for different morphological features, such as POS, lemma, gender, number or person. A ranking component scores the analyses produced by the morphological analyzer using a tuned weighted sum"
N13-1044,W11-2602,1,0.571602,"Missing"
N13-1044,N13-1036,1,0.795899,"Missing"
N13-1044,2006.amta-papers.25,0,0.0321823,"ased SMT system. We use MGIZA++ for word alignment (Gao and Vogel, 2008). Phrase translations of up to 8 words are extracted in the phrase table. We use SRILM (Stolcke, 2002) with modified Kneser-Ney smoothing to build two 4gram language models. The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data. Feature weights are tuned to maximize BLEU (Papineni et al., 2002) on a development set using Minimum Error Rate Training (Och, 2003). We perform caseinsensitive evaluation in terms of BLEU , METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006) metrics. Data We trained on DA-English parallel data (Egyptian and Levantine) obtained from several LDC corpora. The training data amounts to 3.8M untokenized words on the Arabic side. The dev set, used for tuning the parameters of the MT system, has 15,585 untokenized Arabic words. The test set has 12,116 untokenized Arabic words. Both dev and test data contain two sets of reference translations. The English data is lower-cased and tokenized using simple punctuation-based rules. Systems We build three translation systems which vary in tokenization of the Arabic text. The first system applies"
N13-1044,P12-2063,0,0.0558195,"Missing"
N13-1044,N12-1006,0,0.416831,"Missing"
N13-1044,P06-1073,0,0.1305,"Missing"
N13-1044,W05-0909,0,\N,Missing
N13-1044,D08-1076,0,\N,Missing
N13-1049,abdul-mageed-diab-2012-awatif,0,0.0253265,"ebank enrichment for many languages, such Danish, English, German, Italian and Spanish (Oepen et al., 2002; Hinrichs et al., 2004; Müller, 2010). Additionally, there has been some work on Arabic treebank enrichment that built on the PATB by manually extending its already rich annotations or automatically converting them to new formalisms. The Arabic Propbank (Propositional Bank) (Palmer et al., 2008) and the OntoNotes project (Hovy et al., 2006) both annotate for Arabic semantic information. Alkuhlani and Habash (2011) add annotations marking functional gender and number, and rationality; and Abdul-Mageed and Diab (2012) annotate the sentence level with sentiment labels. Tounsi et al. (2009) automatically converted the PATB to a lexical functional grammar (LFG) representation. Similarly, Habash and Roth (2009) used a similar technique to build an initial version of CATiB. We use this CATiB version of PATB to evaluate our approach in this paper. Also related to this is the work on automatic enrichment of specific features, e.g., Habash et al. (2007a) demonstrated that nominal case, can be determined for gold syntactic analyses at high accuracy. We replicate their results and improve upon them. And unlike them,"
N13-1049,P11-2062,1,0.879631,"ichment There has been a number of efforts on developing treebanks with rich representations and on treebank enrichment for many languages, such Danish, English, German, Italian and Spanish (Oepen et al., 2002; Hinrichs et al., 2004; Müller, 2010). Additionally, there has been some work on Arabic treebank enrichment that built on the PATB by manually extending its already rich annotations or automatically converting them to new formalisms. The Arabic Propbank (Propositional Bank) (Palmer et al., 2008) and the OntoNotes project (Hovy et al., 2006) both annotate for Arabic semantic information. Alkuhlani and Habash (2011) add annotations marking functional gender and number, and rationality; and Abdul-Mageed and Diab (2012) annotate the sentence level with sentiment labels. Tounsi et al. (2009) automatically converted the PATB to a lexical functional grammar (LFG) representation. Similarly, Habash and Roth (2009) used a similar technique to build an initial version of CATiB. We use this CATiB version of PATB to evaluate our approach in this paper. Also related to this is the work on automatic enrichment of specific features, e.g., Habash et al. (2007a) demonstrated that nominal case, can be determined for gold"
N13-1049,N04-4038,0,0.0450407,"2009) used a similar technique to build an initial version of CATiB. We use this CATiB version of PATB to evaluate our approach in this paper. Also related to this is the work on automatic enrichment of specific features, e.g., Habash et al. (2007a) demonstrated that nominal case, can be determined for gold syntactic analyses at high accuracy. We replicate their results and improve upon them. And unlike them, we handle all the morphological features in the PATB, not just case. 461 Morphological Disambiguation There has been a lot of work on Arabic POS tagging and morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Smith et al., 2005; Hajiˇc et al., 2005; Roth et al., 2008; Habash et al., 2013). These approaches are intended to apply to raw text and determine the appropriate in-context morphological reading for each word. In contrast, in this paper, we are starting from a partially disambiguated and relatively rich representation: we have tokenization, general POS tags and syntactic dependency information. Finally, morphological information (beyond tokenization) has been shown to be useful for many NLP applications. Marton et al. (2011) demonstrated that morphology helps Arabic"
N13-1049,P05-1071,1,0.960177,"r technique to build an initial version of CATiB. We use this CATiB version of PATB to evaluate our approach in this paper. Also related to this is the work on automatic enrichment of specific features, e.g., Habash et al. (2007a) demonstrated that nominal case, can be determined for gold syntactic analyses at high accuracy. We replicate their results and improve upon them. And unlike them, we handle all the morphological features in the PATB, not just case. 461 Morphological Disambiguation There has been a lot of work on Arabic POS tagging and morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Smith et al., 2005; Hajiˇc et al., 2005; Roth et al., 2008; Habash et al., 2013). These approaches are intended to apply to raw text and determine the appropriate in-context morphological reading for each word. In contrast, in this paper, we are starting from a partially disambiguated and relatively rich representation: we have tokenization, general POS tags and syntactic dependency information. Finally, morphological information (beyond tokenization) has been shown to be useful for many NLP applications. Marton et al. (2011) demonstrated that morphology helps Arabic parsing. Using morpholog"
N13-1049,P09-2056,1,0.868301,"kground facts about Arabic and its treebanking; Section 4 explains our approach; and Section 5 presents and discusses our results. 2 Related Work Arabic Treebanking There has been a lot work on building treebanks for different languages. In the case of Modern Standard Arabic (MSA), there are three efforts that vary in terms of richness and representation choice. The Penn Arabic Treebank (PATB) (Maamouri et al., 2004; Maamouri et al., 2009b; Maamouri et al., 2009a), the Prague Arabic Dependency Treebank (PADT) (Smrž and Hajiˇc, 2006; Smrž et al., 2008) and the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009; Habash et al., 2009) . The PATB uses phrase structure representation, while the other two use two 460 Proceedings of NAACL-HLT 2013, pages 460–470, c Atlanta, Georgia, 9–14 June 2013. 2013 Association for Computational Linguistics different dependency representations. The PATB and PADT representations are quite detailed. The PATB not only provides tokenization, complex POS tags (485 tags in our data set), and syntactic structure; it also provides empty categories, diacritization, lemma choices, glosses and some semantic tags. In comparison CATiB only provides tokenization, six POS tags and e"
N13-1049,D07-1116,1,0.341658,"2006) both annotate for Arabic semantic information. Alkuhlani and Habash (2011) add annotations marking functional gender and number, and rationality; and Abdul-Mageed and Diab (2012) annotate the sentence level with sentiment labels. Tounsi et al. (2009) automatically converted the PATB to a lexical functional grammar (LFG) representation. Similarly, Habash and Roth (2009) used a similar technique to build an initial version of CATiB. We use this CATiB version of PATB to evaluate our approach in this paper. Also related to this is the work on automatic enrichment of specific features, e.g., Habash et al. (2007a) demonstrated that nominal case, can be determined for gold syntactic analyses at high accuracy. We replicate their results and improve upon them. And unlike them, we handle all the morphological features in the PATB, not just case. 461 Morphological Disambiguation There has been a lot of work on Arabic POS tagging and morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Smith et al., 2005; Hajiˇc et al., 2005; Roth et al., 2008; Habash et al., 2013). These approaches are intended to apply to raw text and determine the appropriate in-context morphological reading for eac"
N13-1049,N13-1044,1,0.827718,"o evaluate our approach in this paper. Also related to this is the work on automatic enrichment of specific features, e.g., Habash et al. (2007a) demonstrated that nominal case, can be determined for gold syntactic analyses at high accuracy. We replicate their results and improve upon them. And unlike them, we handle all the morphological features in the PATB, not just case. 461 Morphological Disambiguation There has been a lot of work on Arabic POS tagging and morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Smith et al., 2005; Hajiˇc et al., 2005; Roth et al., 2008; Habash et al., 2013). These approaches are intended to apply to raw text and determine the appropriate in-context morphological reading for each word. In contrast, in this paper, we are starting from a partially disambiguated and relatively rich representation: we have tokenization, general POS tags and syntactic dependency information. Finally, morphological information (beyond tokenization) has been shown to be useful for many NLP applications. Marton et al. (2011) demonstrated that morphology helps Arabic parsing. Using morphological features such as case has also improved parsing for Russian, Turkish and Hind"
N13-1049,N06-2015,0,0.0509622,"e of the Quran, not MSA (Dukes and Buckwalter, 2010). Treebank Enrichment There has been a number of efforts on developing treebanks with rich representations and on treebank enrichment for many languages, such Danish, English, German, Italian and Spanish (Oepen et al., 2002; Hinrichs et al., 2004; Müller, 2010). Additionally, there has been some work on Arabic treebank enrichment that built on the PATB by manually extending its already rich annotations or automatically converting them to new formalisms. The Arabic Propbank (Propositional Bank) (Palmer et al., 2008) and the OntoNotes project (Hovy et al., 2006) both annotate for Arabic semantic information. Alkuhlani and Habash (2011) add annotations marking functional gender and number, and rationality; and Abdul-Mageed and Diab (2012) annotate the sentence level with sentiment labels. Tounsi et al. (2009) automatically converted the PATB to a lexical functional grammar (LFG) representation. Similarly, Habash and Roth (2009) used a similar technique to build an initial version of CATiB. We use this CATiB version of PATB to evaluate our approach in this paper. Also related to this is the work on automatic enrichment of specific features, e.g., Habas"
N13-1049,P03-1004,0,0.0281084,"Missing"
N13-1049,W10-1402,1,0.884974,"Missing"
N13-1049,P11-1159,1,0.784703,"OS tagging and morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Smith et al., 2005; Hajiˇc et al., 2005; Roth et al., 2008; Habash et al., 2013). These approaches are intended to apply to raw text and determine the appropriate in-context morphological reading for each word. In contrast, in this paper, we are starting from a partially disambiguated and relatively rich representation: we have tokenization, general POS tags and syntactic dependency information. Finally, morphological information (beyond tokenization) has been shown to be useful for many NLP applications. Marton et al. (2011) demonstrated that morphology helps Arabic parsing. Using morphological features such as case has also improved parsing for Russian, Turkish and Hindi (Nivre et al., 2008; Eryigit et al., 2008; Nivre, 2009). Other work has shown value for morphology in the context of Arabic named entity recognition (Benajiba et al., 2009). These results support the value of our goal of enriching resources with morphological information, which then can be used to improve different NLP applications. 3 Linguistic Background In this section, we present some relevant general linguistic facts about Arabic and then d"
N13-1049,C08-1081,0,0.0566305,"Missing"
N13-1049,palmer-etal-2008-pilot,0,0.0438052,"bank, which targets the Classical Arabic language of the Quran, not MSA (Dukes and Buckwalter, 2010). Treebank Enrichment There has been a number of efforts on developing treebanks with rich representations and on treebank enrichment for many languages, such Danish, English, German, Italian and Spanish (Oepen et al., 2002; Hinrichs et al., 2004; Müller, 2010). Additionally, there has been some work on Arabic treebank enrichment that built on the PATB by manually extending its already rich annotations or automatically converting them to new formalisms. The Arabic Propbank (Propositional Bank) (Palmer et al., 2008) and the OntoNotes project (Hovy et al., 2006) both annotate for Arabic semantic information. Alkuhlani and Habash (2011) add annotations marking functional gender and number, and rationality; and Abdul-Mageed and Diab (2012) annotate the sentence level with sentiment labels. Tounsi et al. (2009) automatically converted the PATB to a lexical functional grammar (LFG) representation. Similarly, Habash and Roth (2009) used a similar technique to build an initial version of CATiB. We use this CATiB version of PATB to evaluate our approach in this paper. Also related to this is the work on automati"
N13-1049,P08-2030,1,0.831321,"B version of PATB to evaluate our approach in this paper. Also related to this is the work on automatic enrichment of specific features, e.g., Habash et al. (2007a) demonstrated that nominal case, can be determined for gold syntactic analyses at high accuracy. We replicate their results and improve upon them. And unlike them, we handle all the morphological features in the PATB, not just case. 461 Morphological Disambiguation There has been a lot of work on Arabic POS tagging and morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Smith et al., 2005; Hajiˇc et al., 2005; Roth et al., 2008; Habash et al., 2013). These approaches are intended to apply to raw text and determine the appropriate in-context morphological reading for each word. In contrast, in this paper, we are starting from a partially disambiguated and relatively rich representation: we have tokenization, general POS tags and syntactic dependency information. Finally, morphological information (beyond tokenization) has been shown to be useful for many NLP applications. Marton et al. (2011) demonstrated that morphology helps Arabic parsing. Using morphological features such as case has also improved parsing for Rus"
N13-1049,H05-1060,0,0.108253,"Missing"
N13-1049,W09-0806,0,0.0672281,"Missing"
N13-1049,J08-4010,0,\N,Missing
N13-1049,J08-3003,0,\N,Missing
N13-1066,abuhakema-etal-2008-annotating,0,0.133349,"NLP tools, resources, and heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach to transform from EGY to MSA. Similarly, both Sawaf (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of morphological analysis and morphosyntactic transformatio"
N13-1066,I11-1036,0,0.0614695,"EGY to MSA. Similarly, both Sawaf (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of morphological analysis and morphosyntactic transformation rules (for example, Al-Gaphari and Al-Yadoumi (2010)). While all this work is similar to ours in that dialectal input is processed, our output is still dialectal, while the work on conversion aims for a transformation into MSA. The work most closely related to ours is that of Dasigi and Diab (2011). They identify the spelling variants in a given document and normalize them. However, they do not present a system that converts spontaneous spelling to a pre-existing convention such as CODA, and thus their results cannot be directly related to ours. Furthermore, their technique is different. First, similarity metrics based on string difference are used to identify if two strings are similar. Also, a contextual string similarity is used based on the fact that if two words are orthographic variants of each other, then they are bound to appear in similar contexts. After identifying the similar"
N13-1066,W08-0509,0,0.0133854,"Missing"
N13-1066,P05-1071,1,0.114663,"Missing"
N13-1066,P11-1088,1,0.874123,"nd heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach to transform from EGY to MSA. Similarly, both Sawaf (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of morphological analysis and morphosyntactic transformation rules (for example, Al"
N13-1066,habash-etal-2012-conventional,1,0.319733,"ears in EGY as /ha/+ or /Ha/+. The two forms appear in free variation, and we have not been able to find a variable that predicts which form is used when. This variation is not a general phonological variation between /h/ and /H/, we find it only in this morpheme. Predictably, this leads to two spellings in EGY: + h H+ and + ë h+. Negation in EGY is realized as the circum-clitic /m¯a/+ . . . +/š/. The principal orthographic question is whether the prefix is a separate word or is part of the main word; both variants are found. 3 CODA CODA is a conventionalized orthography for Arabic dialects (Habash et al., 2012). In this section, we summarize CODA so that the reader can understand the goals of this paper. CODA has five key properties. 1. CODA is an internally consistent and coherent convention for writing DA: every word has a  always written as è h ¯ in CODA, e.g., /’arbaςa/ ‘four’ single orthographic rendering. 2. CODA is created for computational purposes. 3. CODA uses the Arabic script as used for MSA, with no extra symbols from, for example, Persian or Urdu. 4. CODA is intended as a unified framework for writing all dialects. In this paper, we only discuss the instantiation of CODA for EGY. 5. C"
N13-1066,N13-1044,1,0.65939,"rm as seen in the training data. This assumes that the underlying word exists in the training corpus. For unseen words, the technique keeps them with no change. The MLE approach chooses the correct CODA form for most of the words seen in training, making this approach highly dependent on the training data. It is efficient at correcting common misspellings in frequent words, especially those that are from closed classes. 6.4 Morphological Tagger In addition to the approaches discussed above, we use a morphological tagger, MADAARZ (Morphological Analysis and Disambiguation for Egyptian Arabic) (Habash et al., 2013). Although MADAARZ is originally developed to work as a morphological tagger, it still can help the codafication process, since the choice of a full morphological analysis for a word in context determines its CODA spelling. Therefore, MADAARZ is able to correct many word misspellings that are common in spontaneous orthography. These corrections include  ˇ A), ¯ ø/ ø y/ý and è/ è h/¯ ( @/ @/ @/ @ A/Â/A/ h transforma tions. However, MADAARZ , as a codafication technique, uses the context of the word, which makes it a contextual modeling approach unlike CEC and MLE. It is much slower than they"
N13-1066,I08-2131,0,0.0278911,"Missing"
N13-1066,P07-2045,0,0.00829527,"Missing"
N13-1066,W06-1648,0,0.0265451,"of-vocabulary words using NLP tools, resources, and heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach to transform from EGY to MSA. Similarly, both Sawaf (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of morphological analysis and morph"
N13-1066,P03-1021,0,0.0135224,"Missing"
N13-1066,J96-1003,0,0.0368266,"ome similarity to automatic spelling correction (ASC) and related tasks such as post editing for optical character recognition (OCR). Our task is different from ASC since ASC work assumes a standard orthography that the writer is also assumed to aim for. Both supervised and unsupervised approaches to this task have been explored. Unsupervised approaches rely on improving the fluency of the text and reducing the percentage of out-of-vocabulary words using NLP tools, resources, and heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introdu"
N13-1066,P02-1040,0,0.104397,"Missing"
N13-1066,W11-2602,1,0.250709,"correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach to transform from EGY to MSA. Similarly, both Sawaf (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of morphological analysis and morphosyntactic transformation rules (for example, Al-Gaphari and Al-Yadoumi (2010)). While all this work is similar to ours in that dialectal input is processed, our output is still dialectal, while the work on conversion aims for a transformation into MSA. The work most closely related to ours is that of Dasigi and Diab (2011). They identify the spelling variants in a given"
N13-1066,2010.amta-papers.5,0,0.109513,"s learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach to transform from EGY to MSA. Similarly, both Sawaf (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of morphological analysis and morphosyntactic transformation rules (for example, Al-Gaphari and Al-Yadoumi (2010)). While all this work is similar to ours in that dialectal input is processed, our output is still dialectal, while the work on conversion aims for a transformation into MSA. The work most closely related to ours is that of Dasigi and Diab (2011). They identify the"
N13-1066,D08-1076,0,\N,Missing
N18-1087,N16-3003,0,0.0881088,"on spelling/lexical variations, whereas dialectal content is further characterized with morphosyntactic and phonetic variations that make automatic processing more challenging (Jørgensen et al., 2015). In addition to the issues of morphological complexity, ambiguity, and lack of standard orthography for MSA and DA. There has been several contributions covering various NLP tasks including morphological analysis, disambiguation, POS tagging, tokenization, lemmatization and diacritization, addressing both MSA and DA (Al-Sabbagh and Girju, 2010; Mohamed et al., 2012; Habash et al., 2012b, 2013a; Abdelali et al., 2016; Khalifa et al., 2016b). Notable contributions for both MSA and EGY include MADAMIRA (Pasha et al., 2014), a morphological disambiguation tool that uses morphological analyzers to handle complexity and ambiguity. MADAMIRA can automatically correct common spelling errors as a side effect of disambiguation, but does not include explicit processing steps for noisy content. A neural version of MADAMIRA for MSA is presented by Zalmout and Habash (2017), who use Bi-LSTMs and morphological tag embeddings. Their system shows significant improvement over MADAMIRA, but does not use any explicit charact"
N18-1087,W17-4419,0,0.0163676,"lude the ARK tagger (Owoputi et al., 2013), which is targeted for online conversational text. ARK tagger uses conditional random fields with word clusters as features, obtained via Brown clustering (Brown et al., 1992), along with various lexical features. Gimpel et al. (2011) also use conditional random fields for POS tagging, trained on annotated Twitter content. Derczynski et al. (2013) use manually curated lists to map low frequency and out of vocabulary terms to more frequent terms. Noisy content has also been addressed for named entity recognition (Liu et al., 2011; Ritter et al., 2011; Aguilar et al., 2017), and syntactic parsing (Foster et al., 2011; Petrov and McDonald, 2012). Most relevant to our work is the paper by van der Goot et al. (2017), where they use Word2vec (Mikolov et al., 2013) to find potential normalization candidates for non-canonical words on the lexical level, and rank them using a classifier. They experiment with various normalization and embedding settings, and they find that both normalization and pre-trained embeddings are helpful for the task of POS tagging. • Lexicalized features: lemma, diacritization. • Non-lexicalized features: aspect, case, gender, person, part-of-"
N18-1087,al-sabbagh-girju-2010-mining,0,0.0338816,"text processing is exacerbated for dialectal content. Most contributions focus on spelling/lexical variations, whereas dialectal content is further characterized with morphosyntactic and phonetic variations that make automatic processing more challenging (Jørgensen et al., 2015). In addition to the issues of morphological complexity, ambiguity, and lack of standard orthography for MSA and DA. There has been several contributions covering various NLP tasks including morphological analysis, disambiguation, POS tagging, tokenization, lemmatization and diacritization, addressing both MSA and DA (Al-Sabbagh and Girju, 2010; Mohamed et al., 2012; Habash et al., 2012b, 2013a; Abdelali et al., 2016; Khalifa et al., 2016b). Notable contributions for both MSA and EGY include MADAMIRA (Pasha et al., 2014), a morphological disambiguation tool that uses morphological analyzers to handle complexity and ambiguity. MADAMIRA can automatically correct common spelling errors as a side effect of disambiguation, but does not include explicit processing steps for noisy content. A neural version of MADAMIRA for MSA is presented by Zalmout and Habash (2017), who use Bi-LSTMs and morphological tag embeddings. Their system shows si"
N18-1087,J92-4003,0,0.316774,"(richness), covering all related features. The best analysis is then chosen through morphological disambiguation. The set of morphological features that we model for EGY morphological disambiguation includes: 3 Background and Related Work Explicit handling of noisy content in NLP has recently gained momentum with the increasing use of social media outlets. Notable contributions for POS tagging include the ARK tagger (Owoputi et al., 2013), which is targeted for online conversational text. ARK tagger uses conditional random fields with word clusters as features, obtained via Brown clustering (Brown et al., 1992), along with various lexical features. Gimpel et al. (2011) also use conditional random fields for POS tagging, trained on annotated Twitter content. Derczynski et al. (2013) use manually curated lists to map low frequency and out of vocabulary terms to more frequent terms. Noisy content has also been addressed for named entity recognition (Liu et al., 2011; Ritter et al., 2011; Aguilar et al., 2017), and syntactic parsing (Foster et al., 2011; Petrov and McDonald, 2012). Most relevant to our work is the paper by van der Goot et al. (2017), where they use Word2vec (Mikolov et al., 2013) to fin"
N18-1087,I11-1036,0,0.203556,"Missing"
N18-1087,R13-1026,0,0.0289084,"Y morphological disambiguation includes: 3 Background and Related Work Explicit handling of noisy content in NLP has recently gained momentum with the increasing use of social media outlets. Notable contributions for POS tagging include the ARK tagger (Owoputi et al., 2013), which is targeted for online conversational text. ARK tagger uses conditional random fields with word clusters as features, obtained via Brown clustering (Brown et al., 1992), along with various lexical features. Gimpel et al. (2011) also use conditional random fields for POS tagging, trained on annotated Twitter content. Derczynski et al. (2013) use manually curated lists to map low frequency and out of vocabulary terms to more frequent terms. Noisy content has also been addressed for named entity recognition (Liu et al., 2011; Ritter et al., 2011; Aguilar et al., 2017), and syntactic parsing (Foster et al., 2011; Petrov and McDonald, 2012). Most relevant to our work is the paper by van der Goot et al. (2017), where they use Word2vec (Mikolov et al., 2013) to find potential normalization candidates for non-canonical words on the lexical level, and rank them using a classifier. They experiment with various normalization and embedding"
N18-1087,N13-1066,1,0.895696,"rd cold noun 0 0 0 0 na asp na i na i na vox mod gen num stt na na m s c na na m s i na na m s c a i m s na na na m s c cas u u u na u enc0 2ms:poss 0 2fs:poss 2ms:dobj 2ms:poss Table 1: An example highlighting the effect of non-standard and ambiguous orthography, along with rich mor . barDak ‘still’ is provided in the example with phology, on EGY morphological disambiguation. The word QK the non-standard (non-CODA compliant) orthography XQK. bardak, which can lead to different morphological analyses than the one intended in context. treated DA content should be less sparse and less noisy. Eskander et al. (2013) presented a tool to normalize raw texts into a CODA compliant version using the K-nearest neighbor algorithm. Scaling this tool to other dialects, however, is challenging due to the lack of training data. Our morphological tagging architecture is similar to the work of Inoue et al. (2017) and Zalmout and Habash (2017), but we further experiment with CNN-based character embeddings, and pre-train the word embeddings. The architecture is also similar to the work of Heigold et al. (2017) and Plank et al. (2016) in terms of the character embeddings, both LSTM and CNN-based systems. Our architectur"
N18-1087,P81-1022,0,0.282095,"Missing"
N18-1087,W12-2301,1,0.924809,"plications on orthography as  /θ/ in MSA, well. These include the consonant H  /t/ or  /s/ in which can be mapped to either H EGY. These variations make the written EGY content more susceptible to noise and inconsistency. Table 1 shows an EGY sentence example, along with the set of potential analyses for a given word. Linguistic Issues Dialectal Arabic, including EGY among other dialects, is the primarily spoken language used by native Arabic speakers in daily exchanges. The outbreak of social media platforms expanded the use of DA as a written language. The lack of a standard orthography (Habash et al., 2012a), combined with the fact that user-generated content in social media is prone to noise, increase sparsity and reduce performance. EGY, similar to MSA, is also a morphologically complex language, having a number of morphological features, e.g., gender, number, person, mood, and attachable clitics. Moreover, the diacritization-optional orthography for Arabic (both DA and MSA) results in orthographic ambiguity, leading to several interpretations of the same surface forms. Richness of form increases model sparsity, and ambiguity makes disambiguation harder. One approach to model complexity, rich"
N18-1087,P05-1071,1,0.808723,"architecture for morphological tagging and language modeling for the various morphological features in EGY. We also experiment with several embedding models for words and characters, and present several approaches for noise-robust modeling on the raw form and vector levels. We present the overall tagging and disambiguation architecture, in addition to the character embedding model, in 4.1. We then present the noise handling approaches in 4.2 and 4.3. 4.1 Morphological Tagging and Disambiguation Architecture We use a similar disambiguation approach as in previous contributions for MSA and EGY (Habash and Rambow, 2005; Habash et al., 2009, 2013b). 955 4.1.1 ? $ ?# The morphological disambiguation task is intended to choose the correct morphological analysis from the set of potential analyses, obtained from the morphological analyzer. The analyzer provides a set of morphological features for each given word. These features can be grouped into non-lexical features, where a tagger is used to predict the relevant morphological tag, handled through morphological feature tagging, and lexical features that need a language model (Roth et al., 2008), handled through lexicalized feature language models. The inflec"
N18-1087,N07-2014,1,0.786756,"on for the individual insertion, deletion, and substitution operations, then use these weights to score the candidates. Embedding the morphological tags using the analyzer does not constitute a hard constraint in the system, and the vti vector can be discarded or substituted with less resource-demanding options for other languages or dialects. 4.1.2 Lexicalized Feature Language Models We use LSTM-based neural language models (Enarvi and Kurimo, 2016) for the lexical features (lemma and diacritization). Lemmas and diacritized forms are lexical and cannot be modeled directly using a classifier (Habash and Rambow, 2007), since the target space is big (around 13K for lemmas, and 33K for the diacritized forms, in Train). We therefore use a language model to choose among the candidate lemmas and diacritized forms obtained from the analyzer. We encode the runtime dataset in the HTK Standard Lattice Format (SLF), with a word mesh representation for the various options of each word. 4.2 Embedding Space Mapping Edit Distance Weights The spelling variants are first identified based on narrow window and wide window embeddings, to capture both semantic and syntactic based relationships. For each word in each embedding"
N18-1087,N13-1044,1,0.920888,"in noise-robust NLP tools recently, motivated by the sheer magnitude of user-generated content in social media platforms. The noisy nature of user-generated content makes its processing very challenging for NLP tools. Noisy content is non-canonical in nature, with lexical, orthographic, and phonetic variations that increase the perplexity and sparsity of NLP models. Several contributions show considerable drop in performance for a number of tasks, where simply retraining existing models with social media data does not provide substantial improvement (Gimpel et al., 2011; Ritter et al., 2011; Habash et al., 2013a). Morphological disambiguation for noisy content is further complicated for dialectal content, with additional morpho-syntactic variations. Morphological disambiguation is also more challenging for morphologically rich and ambiguous languages, like Arabic and Dialectal Arabic (DA). 953 Proceedings of NAACL-HLT 2018, pages 953–964 c New Orleans, Louisiana, June 1 - 6, 2018. 2018 Association for Computational Linguistics Despite the similarities, EGY and MSA have many differences that prevent MSA tools from being effectively utilized for EGY text. These include lexical, phonological, and morph"
N18-1087,E17-1048,0,0.0530642,"Missing"
N18-1087,mohamed-etal-2012-annotating,0,0.0272158,"ted for dialectal content. Most contributions focus on spelling/lexical variations, whereas dialectal content is further characterized with morphosyntactic and phonetic variations that make automatic processing more challenging (Jørgensen et al., 2015). In addition to the issues of morphological complexity, ambiguity, and lack of standard orthography for MSA and DA. There has been several contributions covering various NLP tasks including morphological analysis, disambiguation, POS tagging, tokenization, lemmatization and diacritization, addressing both MSA and DA (Al-Sabbagh and Girju, 2010; Mohamed et al., 2012; Habash et al., 2012b, 2013a; Abdelali et al., 2016; Khalifa et al., 2016b). Notable contributions for both MSA and EGY include MADAMIRA (Pasha et al., 2014), a morphological disambiguation tool that uses morphological analyzers to handle complexity and ambiguity. MADAMIRA can automatically correct common spelling errors as a side effect of disambiguation, but does not include explicit processing steps for noisy content. A neural version of MADAMIRA for MSA is presented by Zalmout and Habash (2017), who use Bi-LSTMs and morphological tag embeddings. Their system shows significant improvement"
N18-1087,K17-1042,0,0.302504,"‘still’ is provided in the example with phology, on EGY morphological disambiguation. The word QK the non-standard (non-CODA compliant) orthography XQK. bardak, which can lead to different morphological analyses than the one intended in context. treated DA content should be less sparse and less noisy. Eskander et al. (2013) presented a tool to normalize raw texts into a CODA compliant version using the K-nearest neighbor algorithm. Scaling this tool to other dialects, however, is challenging due to the lack of training data. Our morphological tagging architecture is similar to the work of Inoue et al. (2017) and Zalmout and Habash (2017), but we further experiment with CNN-based character embeddings, and pre-train the word embeddings. The architecture is also similar to the work of Heigold et al. (2017) and Plank et al. (2016) in terms of the character embeddings, both LSTM and CNN-based systems. Our architecture, however, uses neural language models for modeling lemmas and diacritized forms, and utilizes the word-level embeddings in various configurations to combat noise, as explained throughout the rest of the paper. The issue of noisy text processing is exacerbated for dialectal content. Most"
N18-1087,N13-1039,0,0.103253,"Missing"
N18-1087,pasha-etal-2014-madamira,1,0.953538,"Missing"
N18-1087,W15-4302,0,0.0286889,"7) and Plank et al. (2016) in terms of the character embeddings, both LSTM and CNN-based systems. Our architecture, however, uses neural language models for modeling lemmas and diacritized forms, and utilizes the word-level embeddings in various configurations to combat noise, as explained throughout the rest of the paper. The issue of noisy text processing is exacerbated for dialectal content. Most contributions focus on spelling/lexical variations, whereas dialectal content is further characterized with morphosyntactic and phonetic variations that make automatic processing more challenging (Jørgensen et al., 2015). In addition to the issues of morphological complexity, ambiguity, and lack of standard orthography for MSA and DA. There has been several contributions covering various NLP tasks including morphological analysis, disambiguation, POS tagging, tokenization, lemmatization and diacritization, addressing both MSA and DA (Al-Sabbagh and Girju, 2010; Mohamed et al., 2012; Habash et al., 2012b, 2013a; Abdelali et al., 2016; Khalifa et al., 2016b). Notable contributions for both MSA and EGY include MADAMIRA (Pasha et al., 2014), a morphological disambiguation tool that uses morphological analyzers to"
N18-1087,L16-1679,1,0.827262,"riations, whereas dialectal content is further characterized with morphosyntactic and phonetic variations that make automatic processing more challenging (Jørgensen et al., 2015). In addition to the issues of morphological complexity, ambiguity, and lack of standard orthography for MSA and DA. There has been several contributions covering various NLP tasks including morphological analysis, disambiguation, POS tagging, tokenization, lemmatization and diacritization, addressing both MSA and DA (Al-Sabbagh and Girju, 2010; Mohamed et al., 2012; Habash et al., 2012b, 2013a; Abdelali et al., 2016; Khalifa et al., 2016b). Notable contributions for both MSA and EGY include MADAMIRA (Pasha et al., 2014), a morphological disambiguation tool that uses morphological analyzers to handle complexity and ambiguity. MADAMIRA can automatically correct common spelling errors as a side effect of disambiguation, but does not include explicit processing steps for noisy content. A neural version of MADAMIRA for MSA is presented by Zalmout and Habash (2017), who use Bi-LSTMs and morphological tag embeddings. Their system shows significant improvement over MADAMIRA, but does not use any explicit character embeddings nor nois"
N18-1087,C16-2047,1,0.622588,"riations, whereas dialectal content is further characterized with morphosyntactic and phonetic variations that make automatic processing more challenging (Jørgensen et al., 2015). In addition to the issues of morphological complexity, ambiguity, and lack of standard orthography for MSA and DA. There has been several contributions covering various NLP tasks including morphological analysis, disambiguation, POS tagging, tokenization, lemmatization and diacritization, addressing both MSA and DA (Al-Sabbagh and Girju, 2010; Mohamed et al., 2012; Habash et al., 2012b, 2013a; Abdelali et al., 2016; Khalifa et al., 2016b). Notable contributions for both MSA and EGY include MADAMIRA (Pasha et al., 2014), a morphological disambiguation tool that uses morphological analyzers to handle complexity and ambiguity. MADAMIRA can automatically correct common spelling errors as a side effect of disambiguation, but does not include explicit processing steps for noisy content. A neural version of MADAMIRA for MSA is presented by Zalmout and Habash (2017), who use Bi-LSTMs and morphological tag embeddings. Their system shows significant improvement over MADAMIRA, but does not use any explicit character embeddings nor nois"
N18-1087,P16-2067,0,0.0303634,"e one intended in context. treated DA content should be less sparse and less noisy. Eskander et al. (2013) presented a tool to normalize raw texts into a CODA compliant version using the K-nearest neighbor algorithm. Scaling this tool to other dialects, however, is challenging due to the lack of training data. Our morphological tagging architecture is similar to the work of Inoue et al. (2017) and Zalmout and Habash (2017), but we further experiment with CNN-based character embeddings, and pre-train the word embeddings. The architecture is also similar to the work of Heigold et al. (2017) and Plank et al. (2016) in terms of the character embeddings, both LSTM and CNN-based systems. Our architecture, however, uses neural language models for modeling lemmas and diacritized forms, and utilizes the word-level embeddings in various configurations to combat noise, as explained throughout the rest of the paper. The issue of noisy text processing is exacerbated for dialectal content. Most contributions focus on spelling/lexical variations, whereas dialectal content is further characterized with morphosyntactic and phonetic variations that make automatic processing more challenging (Jørgensen et al., 2015). I"
N18-1087,P11-1037,0,0.0424583,"table contributions for POS tagging include the ARK tagger (Owoputi et al., 2013), which is targeted for online conversational text. ARK tagger uses conditional random fields with word clusters as features, obtained via Brown clustering (Brown et al., 1992), along with various lexical features. Gimpel et al. (2011) also use conditional random fields for POS tagging, trained on annotated Twitter content. Derczynski et al. (2013) use manually curated lists to map low frequency and out of vocabulary terms to more frequent terms. Noisy content has also been addressed for named entity recognition (Liu et al., 2011; Ritter et al., 2011; Aguilar et al., 2017), and syntactic parsing (Foster et al., 2011; Petrov and McDonald, 2012). Most relevant to our work is the paper by van der Goot et al. (2017), where they use Word2vec (Mikolov et al., 2013) to find potential normalization candidates for non-canonical words on the lexical level, and rank them using a classifier. They experiment with various normalization and embedding settings, and they find that both normalization and pre-trained embeddings are helpful for the task of POS tagging. • Lexicalized features: lemma, diacritization. • Non-lexicalized feat"
N18-1087,D11-1141,0,0.424717,"en a growing interest in noise-robust NLP tools recently, motivated by the sheer magnitude of user-generated content in social media platforms. The noisy nature of user-generated content makes its processing very challenging for NLP tools. Noisy content is non-canonical in nature, with lexical, orthographic, and phonetic variations that increase the perplexity and sparsity of NLP models. Several contributions show considerable drop in performance for a number of tasks, where simply retraining existing models with social media data does not provide substantial improvement (Gimpel et al., 2011; Ritter et al., 2011; Habash et al., 2013a). Morphological disambiguation for noisy content is further complicated for dialectal content, with additional morpho-syntactic variations. Morphological disambiguation is also more challenging for morphologically rich and ambiguous languages, like Arabic and Dialectal Arabic (DA). 953 Proceedings of NAACL-HLT 2018, pages 953–964 c New Orleans, Louisiana, June 1 - 6, 2018. 2018 Association for Computational Linguistics Despite the similarities, EGY and MSA have many differences that prevent MSA tools from being effectively utilized for EGY text. These include lexical, ph"
N18-1087,P08-2030,1,0.818218,"tion approach as in previous contributions for MSA and EGY (Habash and Rambow, 2005; Habash et al., 2009, 2013b). 955 4.1.1 ? $ ?# The morphological disambiguation task is intended to choose the correct morphological analysis from the set of potential analyses, obtained from the morphological analyzer. The analyzer provides a set of morphological features for each given word. These features can be grouped into non-lexical features, where a tagger is used to predict the relevant morphological tag, handled through morphological feature tagging, and lexical features that need a language model (Roth et al., 2008), handled through lexicalized feature language models. The inflectional, clitic, and partof-speech features are handled with a tagger, while the lexical features are handled with a language model. ? + argmax •••• argmax •••• argmax softmax •••• softmax •••• softmax ● ● ●● •••• ● ● ●● •••• ● ● ●● Bi-LSTM ●● ●● ●● ?# ?*- ?z&apos;- ?)- ●● ●● ●● •••• ?$ ?*, ?z&apos;, ?), ●● ●● ●● •••• ?+ ?*( ?z&apos;( ?)( Figure 1: The overall tagging architecture, with the input vector as the concatenation of the word, characters, and candidate tag embeddings. Morphological Feature Tagging embedding in POS tagging (Heigold et"
N18-1087,W15-3208,1,0.891493,"or MSA is presented by Zalmout and Habash (2017), who use Bi-LSTMs and morphological tag embeddings. Their system shows significant improvement over MADAMIRA, but does not use any explicit character embeddings nor noise reduction techniques. To address the lack of standardized orthography for DA, Habash et al. (2012a) proposed CODA, a Conventional Orthography for Dialectal Arabic. CODA presents a detailed description of orthographic guidelines, mainly for the purpose of developing DA computational models, applied to EGY, and later extended to several other Arabic dialects (Zribi et al., 2014; Saadane and Habash, 2015; Turki et al., 2016; Khalifa et al., 2016a; Jarrar et al., 2016; Habash et al., 2018). CODA4 Approach We present a morphological disambiguation model for EGY. We use an LSTM-based architecture for morphological tagging and language modeling for the various morphological features in EGY. We also experiment with several embedding models for words and characters, and present several approaches for noise-robust modeling on the raw form and vector levels. We present the overall tagging and disambiguation architecture, in addition to the character embedding model, in 4.1. We then present the noise"
N18-1087,W15-1502,0,0.04878,"Missing"
N18-1087,W17-2632,0,0.165162,"Missing"
N18-1087,W17-4404,0,0.0424711,"Missing"
N18-1087,D17-1073,1,0.760973,"the example with phology, on EGY morphological disambiguation. The word QK the non-standard (non-CODA compliant) orthography XQK. bardak, which can lead to different morphological analyses than the one intended in context. treated DA content should be less sparse and less noisy. Eskander et al. (2013) presented a tool to normalize raw texts into a CODA compliant version using the K-nearest neighbor algorithm. Scaling this tool to other dialects, however, is challenging due to the lack of training data. Our morphological tagging architecture is similar to the work of Inoue et al. (2017) and Zalmout and Habash (2017), but we further experiment with CNN-based character embeddings, and pre-train the word embeddings. The architecture is also similar to the work of Heigold et al. (2017) and Plank et al. (2016) in terms of the character embeddings, both LSTM and CNN-based systems. Our architecture, however, uses neural language models for modeling lemmas and diacritized forms, and utilizes the word-level embeddings in various configurations to combat noise, as explained throughout the rest of the paper. The issue of noisy text processing is exacerbated for dialectal content. Most contributions focus on spellin"
N18-1087,zribi-etal-2014-conventional,1,0.890436,"ersion of MADAMIRA for MSA is presented by Zalmout and Habash (2017), who use Bi-LSTMs and morphological tag embeddings. Their system shows significant improvement over MADAMIRA, but does not use any explicit character embeddings nor noise reduction techniques. To address the lack of standardized orthography for DA, Habash et al. (2012a) proposed CODA, a Conventional Orthography for Dialectal Arabic. CODA presents a detailed description of orthographic guidelines, mainly for the purpose of developing DA computational models, applied to EGY, and later extended to several other Arabic dialects (Zribi et al., 2014; Saadane and Habash, 2015; Turki et al., 2016; Khalifa et al., 2016a; Jarrar et al., 2016; Habash et al., 2018). CODA4 Approach We present a morphological disambiguation model for EGY. We use an LSTM-based architecture for morphological tagging and language modeling for the various morphological features in EGY. We also experiment with several embedding models for words and characters, and present several approaches for noise-robust modeling on the raw form and vector levels. We present the overall tagging and disambiguation architecture, in addition to the character embedding model, in 4.1."
N19-4002,W15-3206,0,0.0282561,"tandard Arabic (MSA). ADIDA displays the results with either a point map or a heat map overlaid on top of a geographical map of the Arab World. 2 3 Related Work 3.1 Arabic Dialect Processing While automatic processing of DA is relatively recent compared to MSA, it has attracted a considerable amount of research in NLP (Shoufan and Al-Ameri, 2015). Most of it focuses on (i) collecting datasets from various sources and at different levels (Zaidan and Callison-Burch, 2011; Khalifa et al., 2016; Abdul-Mageed et al., 2018; Bouamor et al., 2018), (ii) creating processing tools (Habash et al., 2013; Al-Shargi and Rambow, 2015; Obeid et al., 2018) (iii) developing DA to English maArabic and its Dialects Although MSA is the official language across the Arab World, it is not the native language of any speakers of Arabic. Dialectal Arabic (DA), on the other hand, is the daily informal spoken variety. 1 https://adida.abudhabi.nyu.edu/  The Arabic word èYK Y« /ςadida/ means ‘numerous’. 2 https://camel.abudhabi.nyu.edu/madar/ 6 Proceedings of NAACL-HLT 2019: Demonstrations, pages 6–11 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics Region Maghreb Sub-region Morocco Algeria"
N19-4002,W16-4819,0,0.0196803,"ence, developing an automatic identification system working at different levels of representation and exploring different datasets has attracted increasing attention in recent years. For instance, DID has been the goal of a dedicated shared task (Malmasi et al., 2016; Zampieri et al., 2017, 2018), encouraging researchers to submit systems to recognize the dialect of speech transcripts for dialects of four main regions: Egyptian, Gulf, Levantine and North African, and MSA. Several systems implementing a range of traditional supervised learning (Tillmann et al., 2014) and deep learning methods (Belinkov and Glass, 2016; Michon et al., 2018) were proposed. In the literature, a number of studies have been exploring DID using several datasets, ranging from user-generated content (i.e., blogs, social media posts) (Sadat et al., 2014), speech transcripts (Biadsy et al., 2009; Bougrine et al., 2017), and other corpora (Elfardy and Diab, 2012, 2013; Zaidan and Callison-Burch, 2014; Salameh et al., 2018; Dinu et al., 2018; Goldman et al., 2018). Shoufan and Al-Ameri (2015) and Al-Ayyoub et al. (2017) present a survey on NLP and deep learning methods for processing Arabic dialectal data with an overview on Arabic DI"
N19-4002,W09-0807,1,0.731291,", 2016; Zampieri et al., 2017, 2018), encouraging researchers to submit systems to recognize the dialect of speech transcripts for dialects of four main regions: Egyptian, Gulf, Levantine and North African, and MSA. Several systems implementing a range of traditional supervised learning (Tillmann et al., 2014) and deep learning methods (Belinkov and Glass, 2016; Michon et al., 2018) were proposed. In the literature, a number of studies have been exploring DID using several datasets, ranging from user-generated content (i.e., blogs, social media posts) (Sadat et al., 2014), speech transcripts (Biadsy et al., 2009; Bougrine et al., 2017), and other corpora (Elfardy and Diab, 2012, 2013; Zaidan and Callison-Burch, 2014; Salameh et al., 2018; Dinu et al., 2018; Goldman et al., 2018). Shoufan and Al-Ameri (2015) and Al-Ayyoub et al. (2017) present a survey on NLP and deep learning methods for processing Arabic dialectal data with an overview on Arabic DID of text and speech. While most of the proposed approaches targeted regional or country level DID, Salameh et al. (2018) introduced a fine-grained DID system covering the dialects of 25 cities from several countries across the Arab world (from Rabat to Mu"
N19-4002,W14-5313,0,0.0297096,"it is quite arduous to distinguish between them. Hence, developing an automatic identification system working at different levels of representation and exploring different datasets has attracted increasing attention in recent years. For instance, DID has been the goal of a dedicated shared task (Malmasi et al., 2016; Zampieri et al., 2017, 2018), encouraging researchers to submit systems to recognize the dialect of speech transcripts for dialects of four main regions: Egyptian, Gulf, Levantine and North African, and MSA. Several systems implementing a range of traditional supervised learning (Tillmann et al., 2014) and deep learning methods (Belinkov and Glass, 2016; Michon et al., 2018) were proposed. In the literature, a number of studies have been exploring DID using several datasets, ranging from user-generated content (i.e., blogs, social media posts) (Sadat et al., 2014), speech transcripts (Biadsy et al., 2009; Bougrine et al., 2017), and other corpora (Elfardy and Diab, 2012, 2013; Zaidan and Callison-Burch, 2014; Salameh et al., 2018; Dinu et al., 2018; Goldman et al., 2018). Shoufan and Al-Ameri (2015) and Al-Ayyoub et al. (2017) present a survey on NLP and deep learning methods for processing"
N19-4002,J14-1006,0,0.1236,"Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics Region Maghreb Sub-region Morocco Algeria Tunisia Libya Cities Rabat Algiers Tunis Tripoli Fes Sfax Benghazi Nile Basin Egypt/Sudan Cairo Alexandria Aswan Khartoum Levant Gulf South Levant North Levant Iraq Gulf Jerusalem Beirut Mosul Doha Amman Damascus Baghdad Muscat Salt Aleppo Basra Riyadh Jeddah Yemen Yemen Sana’a Table 1: Different city dialects covered in ADIDA and the regions they belong to. 3.3 chine translation systems (Zbib et al., 2012; Sajjad et al., 2013), (iv) or performing dialect identification (Zaidan and Callison-Burch, 2014; Huang, 2015; Salameh et al., 2018). 3.2 Visualization Map visualizations are used in multiple fields of study including linguistics, socio-linguistics, and political science to display geographical relations of non-geographic data. Geographical visualizations may include point maps to display individual data points, choropleths and Voronoi tessalation maps that cluster data points by region, and heat maps and surface maps that interpolate data over some geographical area. In the general context of visualization of language data, one example is the Visualizing Medieval Places project (Wrisley"
N19-4002,P11-2007,0,0.409839,"18). The dialect identification system produces a vector of probabilities indicating the likelihood an input sentence is from 25 cities (Table 1) and Modern Standard Arabic (MSA). ADIDA displays the results with either a point map or a heat map overlaid on top of a geographical map of the Arab World. 2 3 Related Work 3.1 Arabic Dialect Processing While automatic processing of DA is relatively recent compared to MSA, it has attracted a considerable amount of research in NLP (Shoufan and Al-Ameri, 2015). Most of it focuses on (i) collecting datasets from various sources and at different levels (Zaidan and Callison-Burch, 2011; Khalifa et al., 2016; Abdul-Mageed et al., 2018; Bouamor et al., 2018), (ii) creating processing tools (Habash et al., 2013; Al-Shargi and Rambow, 2015; Obeid et al., 2018) (iii) developing DA to English maArabic and its Dialects Although MSA is the official language across the Arab World, it is not the native language of any speakers of Arabic. Dialectal Arabic (DA), on the other hand, is the daily informal spoken variety. 1 https://adida.abudhabi.nyu.edu/  The Arabic word èYK Y« /ςadida/ means ‘numerous’. 2 https://camel.abudhabi.nyu.edu/madar/ 6 Proceedings of NAACL-HLT 2019: Demonstrati"
N19-4002,W17-1201,0,0.190799,"Missing"
N19-4002,W18-3901,0,0.102306,"Missing"
N19-4002,N12-1006,0,0.0279204,"du/madar/ 6 Proceedings of NAACL-HLT 2019: Demonstrations, pages 6–11 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics Region Maghreb Sub-region Morocco Algeria Tunisia Libya Cities Rabat Algiers Tunis Tripoli Fes Sfax Benghazi Nile Basin Egypt/Sudan Cairo Alexandria Aswan Khartoum Levant Gulf South Levant North Levant Iraq Gulf Jerusalem Beirut Mosul Doha Amman Damascus Baghdad Muscat Salt Aleppo Basra Riyadh Jeddah Yemen Yemen Sana’a Table 1: Different city dialects covered in ADIDA and the regions they belong to. 3.3 chine translation systems (Zbib et al., 2012; Sajjad et al., 2013), (iv) or performing dialect identification (Zaidan and Callison-Burch, 2014; Huang, 2015; Salameh et al., 2018). 3.2 Visualization Map visualizations are used in multiple fields of study including linguistics, socio-linguistics, and political science to display geographical relations of non-geographic data. Geographical visualizations may include point maps to display individual data points, choropleths and Voronoi tessalation maps that cluster data points by region, and heat maps and surface maps that interpolate data over some geographical area. In the general context"
N19-4002,D15-1254,0,0.0167688,". 2019 Association for Computational Linguistics Region Maghreb Sub-region Morocco Algeria Tunisia Libya Cities Rabat Algiers Tunis Tripoli Fes Sfax Benghazi Nile Basin Egypt/Sudan Cairo Alexandria Aswan Khartoum Levant Gulf South Levant North Levant Iraq Gulf Jerusalem Beirut Mosul Doha Amman Damascus Baghdad Muscat Salt Aleppo Basra Riyadh Jeddah Yemen Yemen Sana’a Table 1: Different city dialects covered in ADIDA and the regions they belong to. 3.3 chine translation systems (Zbib et al., 2012; Sajjad et al., 2013), (iv) or performing dialect identification (Zaidan and Callison-Burch, 2014; Huang, 2015; Salameh et al., 2018). 3.2 Visualization Map visualizations are used in multiple fields of study including linguistics, socio-linguistics, and political science to display geographical relations of non-geographic data. Geographical visualizations may include point maps to display individual data points, choropleths and Voronoi tessalation maps that cluster data points by region, and heat maps and surface maps that interpolate data over some geographical area. In the general context of visualization of language data, one example is the Visualizing Medieval Places project (Wrisley, 2017, 2019)"
N19-4002,L16-1679,1,0.732632,"ystem produces a vector of probabilities indicating the likelihood an input sentence is from 25 cities (Table 1) and Modern Standard Arabic (MSA). ADIDA displays the results with either a point map or a heat map overlaid on top of a geographical map of the Arab World. 2 3 Related Work 3.1 Arabic Dialect Processing While automatic processing of DA is relatively recent compared to MSA, it has attracted a considerable amount of research in NLP (Shoufan and Al-Ameri, 2015). Most of it focuses on (i) collecting datasets from various sources and at different levels (Zaidan and Callison-Burch, 2011; Khalifa et al., 2016; Abdul-Mageed et al., 2018; Bouamor et al., 2018), (ii) creating processing tools (Habash et al., 2013; Al-Shargi and Rambow, 2015; Obeid et al., 2018) (iii) developing DA to English maArabic and its Dialects Although MSA is the official language across the Arab World, it is not the native language of any speakers of Arabic. Dialectal Arabic (DA), on the other hand, is the daily informal spoken variety. 1 https://adida.abudhabi.nyu.edu/  The Arabic word èYK Y« /ςadida/ means ‘numerous’. 2 https://camel.abudhabi.nyu.edu/madar/ 6 Proceedings of NAACL-HLT 2019: Demonstrations, pages 6–11 c Minn"
N19-4002,W16-4801,0,0.0485913,"Missing"
N19-4002,W18-3914,0,0.0141618,"tic identification system working at different levels of representation and exploring different datasets has attracted increasing attention in recent years. For instance, DID has been the goal of a dedicated shared task (Malmasi et al., 2016; Zampieri et al., 2017, 2018), encouraging researchers to submit systems to recognize the dialect of speech transcripts for dialects of four main regions: Egyptian, Gulf, Levantine and North African, and MSA. Several systems implementing a range of traditional supervised learning (Tillmann et al., 2014) and deep learning methods (Belinkov and Glass, 2016; Michon et al., 2018) were proposed. In the literature, a number of studies have been exploring DID using several datasets, ranging from user-generated content (i.e., blogs, social media posts) (Sadat et al., 2014), speech transcripts (Biadsy et al., 2009; Bougrine et al., 2017), and other corpora (Elfardy and Diab, 2012, 2013; Zaidan and Callison-Burch, 2014; Salameh et al., 2018; Dinu et al., 2018; Goldman et al., 2018). Shoufan and Al-Ameri (2015) and Al-Ayyoub et al. (2017) present a survey on NLP and deep learning methods for processing Arabic dialectal data with an overview on Arabic DID of text and speech."
N19-4002,L18-1415,1,0.849481,"displays the results with either a point map or a heat map overlaid on top of a geographical map of the Arab World. 2 3 Related Work 3.1 Arabic Dialect Processing While automatic processing of DA is relatively recent compared to MSA, it has attracted a considerable amount of research in NLP (Shoufan and Al-Ameri, 2015). Most of it focuses on (i) collecting datasets from various sources and at different levels (Zaidan and Callison-Burch, 2011; Khalifa et al., 2016; Abdul-Mageed et al., 2018; Bouamor et al., 2018), (ii) creating processing tools (Habash et al., 2013; Al-Shargi and Rambow, 2015; Obeid et al., 2018) (iii) developing DA to English maArabic and its Dialects Although MSA is the official language across the Arab World, it is not the native language of any speakers of Arabic. Dialectal Arabic (DA), on the other hand, is the daily informal spoken variety. 1 https://adida.abudhabi.nyu.edu/  The Arabic word èYK Y« /ςadida/ means ‘numerous’. 2 https://camel.abudhabi.nyu.edu/madar/ 6 Proceedings of NAACL-HLT 2019: Demonstrations, pages 6–11 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics Region Maghreb Sub-region Morocco Algeria Tunisia Libya Cities"
N19-4002,W14-5904,0,0.23213,"f a dedicated shared task (Malmasi et al., 2016; Zampieri et al., 2017, 2018), encouraging researchers to submit systems to recognize the dialect of speech transcripts for dialects of four main regions: Egyptian, Gulf, Levantine and North African, and MSA. Several systems implementing a range of traditional supervised learning (Tillmann et al., 2014) and deep learning methods (Belinkov and Glass, 2016; Michon et al., 2018) were proposed. In the literature, a number of studies have been exploring DID using several datasets, ranging from user-generated content (i.e., blogs, social media posts) (Sadat et al., 2014), speech transcripts (Biadsy et al., 2009; Bougrine et al., 2017), and other corpora (Elfardy and Diab, 2012, 2013; Zaidan and Callison-Burch, 2014; Salameh et al., 2018; Dinu et al., 2018; Goldman et al., 2018). Shoufan and Al-Ameri (2015) and Al-Ayyoub et al. (2017) present a survey on NLP and deep learning methods for processing Arabic dialectal data with an overview on Arabic DID of text and speech. While most of the proposed approaches targeted regional or country level DID, Salameh et al. (2018) introduced a fine-grained DID system covering the dialects of 25 cities from several countrie"
N19-4002,P13-2001,0,0.0233764,"ings of NAACL-HLT 2019: Demonstrations, pages 6–11 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics Region Maghreb Sub-region Morocco Algeria Tunisia Libya Cities Rabat Algiers Tunis Tripoli Fes Sfax Benghazi Nile Basin Egypt/Sudan Cairo Alexandria Aswan Khartoum Levant Gulf South Levant North Levant Iraq Gulf Jerusalem Beirut Mosul Doha Amman Damascus Baghdad Muscat Salt Aleppo Basra Riyadh Jeddah Yemen Yemen Sana’a Table 1: Different city dialects covered in ADIDA and the regions they belong to. 3.3 chine translation systems (Zbib et al., 2012; Sajjad et al., 2013), (iv) or performing dialect identification (Zaidan and Callison-Burch, 2014; Huang, 2015; Salameh et al., 2018). 3.2 Visualization Map visualizations are used in multiple fields of study including linguistics, socio-linguistics, and political science to display geographical relations of non-geographic data. Geographical visualizations may include point maps to display individual data points, choropleths and Voronoi tessalation maps that cluster data points by region, and heat maps and surface maps that interpolate data over some geographical area. In the general context of visualization of la"
N19-4002,C18-1113,1,0.873594,"ar Habash New York University Abu Dhabi, UAE † Carnegie Mellon University in Qatar, Qatar {oobeid,nizar.habash}@nyu.edu {msalameh,hbouamor}@cmu.edu Abstract DA is nowadays emerging as the primary language of communication – not just spoken, but also written, particularly in social media. Arabic dialects are often classified in terms of geographical regions, such as Levantine Arabic, Gulf Arabic and Egyptian Arabic (Habash, 2010). However, within each of these regional groups, there is significant variation down to the village, town, and city levels. The demo we present is based on the work of Salameh et al. (2018), who utilize the MADAR Project parallel corpus of 25 Arab cities plus MSA (Table 1) (Bouamor et al., 2018).2 Arabic dialects differ in various ways from MSA and from each other. These include phonological, morphological, lexical, and syntactic differences (Haeri, 1991; Holes, 2004; Watson, 2007; Bassiouney, 2009). Despite these differences, distinguishing between Arabic dialects in written form is an arduous task because: (i) dialects use the same writing script and share part of the vocabulary; and (ii) Arabic speakers usually resort to repeated code-switching between their dialect and MSA ("
P05-1071,N04-4038,0,0.774426,"in One Fell Swoop Nizar Habash and Owen Rambow Center for Computational Learning Systems Columbia University New York, NY 10115, USA {habash,rambow}@cs.columbia.edu Abstract morphological tag, cannot be done successfully using methods developed for English because of data sparseness. Hajiˇc (2000) demonstrates convincingly that morphological disambiguation can be aided by a morphological analyzer, which, given a word without any context, gives us the set of all possible morphological tags. The only work on Arabic tagging that uses a corpus for training and evaluation (that we are aware of), (Diab et al., 2004), does not use a morphological analyzer. In this paper, we show that the use of a morphological analyzer outperforms other tagging methods for Arabic; to our knowledge, we present the best-performing wide-coverage tokenizer on naturally occurring input and the bestperforming morphological tagger for Arabic. We present an approach to using a morphological analyzer for tokenizing and morphologically tagging (including partof-speech tagging) Arabic words in one process. We learn classifiers for individual morphological features, as well as ways of using these classifiers to choose among entries f"
P05-1071,A00-2013,0,0.425099,"Missing"
P05-1071,P03-1004,0,0.0361062,"on (but not from training). In contrast, Diab et al. (2004) treat NO FUNC like any other POS tag, but it is unclear whether this is meaningful. Thus, when comparing results from different approaches which make different choices about the data (for example, the NO FUNC cases), one should bear in mind that small differences in performance are probably not meaningful. Method Test POS Conj Part Pron Det Gen Num Per Voice Asp 5 Classifiers for Linguistic Features We now describe how we train classifiers for the morphological features in Figure 2. We train one classifier per feature. We use Yamcha (Kudo and Matsumoto, 2003), an implementation of support vector machines which includes Viterbi decoding. 6 As training features, we use two sets. These sets are based on the ten morphological features in Figure 2, plus four other “hidden” morphological features, for which we do not train classifiers, but which are represented in the analyses returned by the morphological analyzer. The reason we do not train classifiers for the hidden features is that they are only returned by the morphological analyzer when they are marked overtly in orthography, but they are not disambiguated in case they are not overtly marked. The"
P05-1071,P03-1051,0,0.0576065,"Missing"
P05-1071,P03-1050,0,0.0152138,"Missing"
P05-1071,W02-0506,0,\N,Missing
P06-1001,P05-3026,0,0.00927356,"sions. Other research on preprocessing Arabic suggests that minimal preprocessing, such as splitting off the conjunction + w+ ’and’, produces best results with very large training data (Och, 2005). System combination for MT has also been investigated by different researchers. Approaches to combination generally either select one of the hypotheses produced by the different systems combined (Nomoto, 2004; Paul et al., 2005; Lee, 2005) or combine lattices/n-best lists from the different systems with different degrees of synthesis or mixing (Frederking and Nirenburg, 1994; Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006). These different approaches use various translation and language models in addition to other models such as word matching, sentence and document alignment, system translation confidence, phrase translation lexicons, etc. We extend on previous work by experimenting with a wider range of preprocessing schemes for Arabic and exploring their combination to produce better results. derivational morphology (such as using roots as tokens) in this paper.  Orthographic Ambiguity: The form of certain letters in Arabic script allows suboptimal orthographic variants of the same wor"
P06-1001,koen-2004-pharaoh,0,0.0605115,"Missing"
P06-1001,W04-3250,0,0.155401,"Missing"
P06-1001,N04-4015,0,0.631891,"publications on the effect of morphology on SMT quality focused on morphologically rich languages such as German (Nießen and Ney, 2004); Spanish, Catalan, and Serbian (Popovi´c 1 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1–8, c Sydney, July 2006. 2006 Association for Computational Linguistics and Ney, 2004); and Czech (Goldwater and McClosky, 2005). They all studied the effects of various kinds of tokenization, lemmatization and POS tagging and show a positive effect on SMT quality. Specifically considering Arabic, Lee (2004) investigated the use of automatic alignment of POS tagged English and affix-stem segmented Arabic to determine appropriate tokenizations. Her results show that morphological preprocessing helps, but only for the smaller corpora. As size increases, the benefits diminish. Our results are comparable to hers in terms of BLEU score and consistent in terms of conclusions. Other research on preprocessing Arabic suggests that minimal preprocessing, such as splitting off the conjunction + w+ ’and’, produces best results with very large training data (Och, 2005). System combination for MT has also been"
P06-1001,2005.iwslt-1.9,0,0.0122647,"helps, but only for the smaller corpora. As size increases, the benefits diminish. Our results are comparable to hers in terms of BLEU score and consistent in terms of conclusions. Other research on preprocessing Arabic suggests that minimal preprocessing, such as splitting off the conjunction + w+ ’and’, produces best results with very large training data (Och, 2005). System combination for MT has also been investigated by different researchers. Approaches to combination generally either select one of the hypotheses produced by the different systems combined (Nomoto, 2004; Paul et al., 2005; Lee, 2005) or combine lattices/n-best lists from the different systems with different degrees of synthesis or mixing (Frederking and Nirenburg, 1994; Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006). These different approaches use various translation and language models in addition to other models such as word matching, sentence and document alignment, system translation confidence, phrase translation lexicons, etc. We extend on previous work by experimenting with a wider range of preprocessing schemes for Arabic and exploring their combination to produce better results. derivati"
P06-1001,E06-1005,0,0.00637967,"eprocessing Arabic suggests that minimal preprocessing, such as splitting off the conjunction + w+ ’and’, produces best results with very large training data (Och, 2005). System combination for MT has also been investigated by different researchers. Approaches to combination generally either select one of the hypotheses produced by the different systems combined (Nomoto, 2004; Paul et al., 2005; Lee, 2005) or combine lattices/n-best lists from the different systems with different degrees of synthesis or mixing (Frederking and Nirenburg, 1994; Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006). These different approaches use various translation and language models in addition to other models such as word matching, sentence and document alignment, system translation confidence, phrase translation lexicons, etc. We extend on previous work by experimenting with a wider range of preprocessing schemes for Arabic and exploring their combination to produce better results. derivational morphology (such as using roots as tokens) in this paper.  Orthographic Ambiguity: The form of certain letters in Arabic script allows suboptimal orthographic variants of the same word to coexist in the sam"
P06-1001,J04-2003,0,0.149101,"Missing"
P06-1001,P04-1063,0,0.0161291,"that morphological preprocessing helps, but only for the smaller corpora. As size increases, the benefits diminish. Our results are comparable to hers in terms of BLEU score and consistent in terms of conclusions. Other research on preprocessing Arabic suggests that minimal preprocessing, such as splitting off the conjunction + w+ ’and’, produces best results with very large training data (Och, 2005). System combination for MT has also been investigated by different researchers. Approaches to combination generally either select one of the hypotheses produced by the different systems combined (Nomoto, 2004; Paul et al., 2005; Lee, 2005) or combine lattices/n-best lists from the different systems with different degrees of synthesis or mixing (Frederking and Nirenburg, 1994; Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006). These different approaches use various translation and language models in addition to other models such as word matching, sentence and document alignment, system translation confidence, phrase translation lexicons, etc. We extend on previous work by experimenting with a wider range of preprocessing schemes for Arabic and exploring their combination to p"
P06-1001,P03-1021,0,0.0649375,"Missing"
P06-1001,2001.mtsummit-papers.68,0,0.13432,"sing, separating punctuation from words and splitting off “’s”. The same preprocessing was used on the English data for all experiments. Only Arabic preprocessing was varied. Decoding weight optimization was done using a set of 200 sentences from the 2003 NIST MT evaluation test set (M T 03). We report results on the 2004 NIST MT evaluation test set (M T 04) The experiment design and choices of schemes and techniques were done independently of the test set. The data sets, M T 03 and M T 04, include one Arabic source and four English reference translations. We use the evaluation metric BLEU-4 (Papineni et al., 2001) although we are aware of its caveats (CallisonBurch et al., 2006). Table 2: Scheme Statistics Scheme Tokens OOVs Perplexity ST ON D1 D2 D3 WA TB MR L1 L2 EN 36000 36000 38817 40934 52085 38635 42880 62410 36000 36000 55525 1345 1212 1016 835 575 1044 662 409 392 432 432 1164 944 582 422 137 596 338 69 401 460 103 with the number of OOVs and perplexity. The only exceptions are L1 and L2, whose low OOV rate is the result of the reductionist nature of the scheme, which does not preserve morphological information. 5 Basic Scheme Experiments We now describe the system and the data sets we used to"
P06-1001,2005.iwslt-1.5,0,0.0186921,"ical preprocessing helps, but only for the smaller corpora. As size increases, the benefits diminish. Our results are comparable to hers in terms of BLEU score and consistent in terms of conclusions. Other research on preprocessing Arabic suggests that minimal preprocessing, such as splitting off the conjunction + w+ ’and’, produces best results with very large training data (Och, 2005). System combination for MT has also been investigated by different researchers. Approaches to combination generally either select one of the hypotheses produced by the different systems combined (Nomoto, 2004; Paul et al., 2005; Lee, 2005) or combine lattices/n-best lists from the different systems with different degrees of synthesis or mixing (Frederking and Nirenburg, 1994; Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006). These different approaches use various translation and language models in addition to other models such as word matching, sentence and document alignment, system translation confidence, phrase translation lexicons, etc. We extend on previous work by experimenting with a wider range of preprocessing schemes for Arabic and exploring their combination to produce better resul"
P06-1001,popovic-ney-2004-towards,0,0.294964,"Missing"
P06-1001,W05-0822,1,0.8478,"Missing"
P06-1001,E06-1032,0,0.00868398,"Missing"
P06-1001,N04-4038,0,0.0527738,"hemes. It is identical to the initial tokenization used by Lee (2004).  L1 and L2: Lexeme and POS. These reduce a word to its lexeme and a POS. L1 and L2 differ in the set of POS tags they use. L1 uses the simple POS tags advocated by Habash and RambzyArp with visit AlY to trkyA. Turkey . bzyArp bzyArp bzyArp b+ zyArp b+ zyArp bzyArp b+ zyArp b+ zyAr +p zyArp zyArp  b+ zyArp  AlY  lY  lY  lY  lY  lY  lY  lY  lY  lY   lY  trkyA trkyA trkyA trkyA trkyA trkyA trkyA trkyA trkyA trkyA   trkyA   . . . . . . . . . . . bow (2005) (15 tags); while L2 uses the reduced tag set used by Diab et al. (2004) (24 tags). The latter is modeled after the English Penn POS tag set. For example, Arabic nouns are differentiated for being singular (NN) or Plural/Dual (NNS), but adjectives are not even though, in Arabic, they inflect exactly the same way nouns do.  EN: English-like. This scheme is intended to minimize differences between Arabic and English. It decliticizes similarly to D3, but uses Lexeme and POS tags instead of the regenerated word. The POS tag set used is the reduced Arabic Treebank tag set (24 tags) (Maamouri et al., 2004; Diab et al., 2004). Additionally, the subject inflection is ind"
P06-1001,H05-1085,0,0.091081,"g, part-of-speech (POS) tagging and lemmatization. The ultimate goal of preprocessing is to improve the quality of the SMT output by addressing issues such as sparsity in training data. We refer to a specific kind of preprocessing as a “scheme” and differentiate it from the “technique” used to obtain it. In a previous publication, we presented results describing six pre2 Previous Work The anecdotal intuition in the field is that reduction of word sparsity often improves translation quality. This reduction can be achieved by increasing training data or via morphologically driven preprocessing (Goldwater and McClosky, 2005). Recent publications on the effect of morphology on SMT quality focused on morphologically rich languages such as German (Nießen and Ney, 2004); Spanish, Catalan, and Serbian (Popovi´c 1 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1–8, c Sydney, July 2006. 2006 Association for Computational Linguistics and Ney, 2004); and Czech (Goldwater and McClosky, 2005). They all studied the effects of various kinds of tokenization, lemmatization and POS tagging and show a positive effect on SMT quality. Specifically considering"
P06-1001,P05-1071,1,0.763811,"not always an easy task and often requires the use of a morphological analyzer. One common example in Arabic nouns is Broken Plurals. For example, one of the plukAtb ‘writer’ ral forms of the Arabic word is   ktbp ‘writers’. An alternative non-broken plural (concatenatively derived) is  kAtbwn ‘writers’.     4.1 We use the Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2002) to obtain possible word analyses. To select among these analyses, we use the Morphological Analysis and Disambiguation for Arabic (M ADA) tool,2 an off-theshelf resource for Arabic disambiguation (Habash and Rambow, 2005). Being a disambiguation system of morphology, not word sense, M ADA sometimes produces ties for analyses with the same inflectional features but different lexemes (resolving such ties require word-sense disambiguation). We resolve these ties in a consistent arbitrary manner: first in a sorted list of analyses. Producing a preprocessing scheme involves removing features from the word analysis and regenerating the word without the split-off features. The regeneration ensures that the generated form is appropriately normalized by addressing various morphotactics described in Section 3. The gener"
P06-1001,N06-2013,1,0.429835,"). These schemes were evaluated against three different techniques that vary in linguistic complexity; and across a learning curve of training sizes. Additionally, we reported on the effect of scheme/technique combination on genre variation between training and testing. In this paper, we shift our attention to exploring and contrasting additional preprocessing schemes for Arabic and describing and evaluating different methods for combining them. We use a single technique throughout the experiments reported here. We show an improved MT performance when combining different schemes. Similarly to Habash and Sadat (2006), the set of schemes we explore are all word-level. As such, we do not utilize any syntactic information. We define the word to be limited to written Modern Standard Arabic (MSA) strings separated by white space, punctuation and numbers. Section 2 presents previous relevant research. Section 3 presents some relevant background on Arabic linguistics to motivate the schemes discussed in Section 4. Section 5 presents the tools and data sets used, along with the results of basic scheme experiments. Section 6 presents combination techniques and their results. Statistical machine translation is quit"
P06-1001,A94-1016,0,\N,Missing
P06-1001,P02-1040,0,\N,Missing
P06-1001,2005.eamt-1.20,0,\N,Missing
P06-1086,J94-1003,0,\N,Missing
P06-1086,C88-1064,0,\N,Missing
P06-1086,E87-1002,0,\N,Missing
P06-1086,J00-1006,0,\N,Missing
P06-1086,W05-0703,1,\N,Missing
P06-1086,W02-0506,0,\N,Missing
P06-1086,W98-1007,0,\N,Missing
P06-1086,maamouri-etal-2006-developing,1,\N,Missing
P08-2015,N06-1060,0,0.0402106,"nd the phrase table with entries from a manually created dictionary – the English glosses of the Buckwalter Arabic morphological analyzer (Buckwalter, 2004). For each analysis of an OOV word, we expand the English lemma gloss to all its possible surface forms. The newly generated pairs are equally assigned very low translation probabilities that do not interfere with the rest of the phrase table. T RANS E X We produce English transliteration hypotheses that assume the OOV is a proper name. Our transliteration system is rather simple: it uses the transliteration similarity measure described by Freeman et al. (2006) to select a best match from a large list of possible names in English.3 The list was collected from a large collection of English corpora primarily using capitalization statistics. For each OOV word, we produce a list of possible transliterations that are used to add translation pair entries in the phrase table. The newly generated pairs are assigned very low translation probabilities that do not interfere with the rest of the phrase table. Weights of entries were modulated by the degree of similarity indicated by the metric we used. Given the large number of possible matches, we only pass th"
P08-2015,P08-2015,1,0.106339,"tering, S PELL E X may contribute too. 4 OOV-Handling Techniques word is replaced with the OOV word. The translation weights of the INV phrase are used as is in the new phrase. We limit the added phrases to sourcelanguage unigrams and bigrams (determined empirically). In D ICT E X and T RANS E X techniques, we add completely new entries to the phrase table. All the techniques could be used with other approaches, such as input-text lattice extension with INV variants of OOVs or their target translations. We briefly describe the techniques next. More details are available in a technical report (Habash, 2008). M ORPH E X We match the OOV word with an INV word that is a possible morphological variant of the OOV word. For this to work, we need to be able to morphologically analyze the OOV word (into lexeme and features). OOV words that fail morphological analysis cannot be helped by this technique. The morphological matching assumes the words to be matched agree in their lexeme but have different inflectional features. We collect information on possible inflectional variations from the original phrase table itself: in an off-line process, we cluster all the analyses of single-word Arabic entries in"
P08-2015,P05-1071,1,0.391159,"Missing"
P08-2015,W05-0712,0,0.058084,"erbian (Popovi´c and Ney, 2004) and Arabic (Sadat and Habash, 2006). We are interested in the specific task of online OOV handling. We will not consider solutions that game precision-based evaluation metrics by deleting OOVs. Some previous approaches anticipate OOV words that are potentially morphologically related to in-vocabulary (INV) words (Yang and Kirchhoff, 2006). Vilar et al. (2007) address spelling-variant OOVs in MT through online retokenization into letters and combination with a word-based system. There is much work on name transliteration and its integration in larger MT systems (Hassan and Sorensen, 2005). Okuma et al. (2007) describe a dictionary-based technique for translating OOV words in SMT. We differ from previous work on OOV handling in that we address spelling and name-transliteration OOVs in addition to morphological OOVs. We compare these different techniques and study their combination. Our morphology expansion technique is novel in that we automatically learn which source language morphological features are irrelevant to the target language. 3 Out-of-Vocabulary Words in Arabic-English Machine Translation Arabic Linguistic Issues Orthographically, we distinguish three major challeng"
P08-2015,koen-2004-pharaoh,0,0.0173501,"Missing"
P08-2015,J03-1002,0,0.00561331,"Missing"
P08-2015,P03-1021,0,0.0107888,"Missing"
P08-2015,2007.mtsummit-papers.48,0,0.0771109,"04) and Arabic (Sadat and Habash, 2006). We are interested in the specific task of online OOV handling. We will not consider solutions that game precision-based evaluation metrics by deleting OOVs. Some previous approaches anticipate OOV words that are potentially morphologically related to in-vocabulary (INV) words (Yang and Kirchhoff, 2006). Vilar et al. (2007) address spelling-variant OOVs in MT through online retokenization into letters and combination with a word-based system. There is much work on name transliteration and its integration in larger MT systems (Hassan and Sorensen, 2005). Okuma et al. (2007) describe a dictionary-based technique for translating OOV words in SMT. We differ from previous work on OOV handling in that we address spelling and name-transliteration OOVs in addition to morphological OOVs. We compare these different techniques and study their combination. Our morphology expansion technique is novel in that we automatically learn which source language morphological features are irrelevant to the target language. 3 Out-of-Vocabulary Words in Arabic-English Machine Translation Arabic Linguistic Issues Orthographically, we distinguish three major challenges for Arabic process"
P08-2015,P02-1040,0,0.0853093,"Missing"
P08-2015,popovic-ney-2004-towards,0,0.116261,"Missing"
P08-2015,P06-1001,1,0.721011,"Missing"
P08-2015,W07-0705,0,0.0323469,"in MT has shown that orthographic and morpho-syntactic preprocessing of the training and test data reduces data sparsity and OOV rates. This is especially true for languages with rich morphology such as Spanish, Catalan, and Serbian (Popovi´c and Ney, 2004) and Arabic (Sadat and Habash, 2006). We are interested in the specific task of online OOV handling. We will not consider solutions that game precision-based evaluation metrics by deleting OOVs. Some previous approaches anticipate OOV words that are potentially morphologically related to in-vocabulary (INV) words (Yang and Kirchhoff, 2006). Vilar et al. (2007) address spelling-variant OOVs in MT through online retokenization into letters and combination with a word-based system. There is much work on name transliteration and its integration in larger MT systems (Hassan and Sorensen, 2005). Okuma et al. (2007) describe a dictionary-based technique for translating OOV words in SMT. We differ from previous work on OOV handling in that we address spelling and name-transliteration OOVs in addition to morphological OOVs. We compare these different techniques and study their combination. Our morphology expansion technique is novel in that we automatically"
P08-2015,E06-1006,0,0.131548,"R0011-06-C-0023. Much work in MT has shown that orthographic and morpho-syntactic preprocessing of the training and test data reduces data sparsity and OOV rates. This is especially true for languages with rich morphology such as Spanish, Catalan, and Serbian (Popovi´c and Ney, 2004) and Arabic (Sadat and Habash, 2006). We are interested in the specific task of online OOV handling. We will not consider solutions that game precision-based evaluation metrics by deleting OOVs. Some previous approaches anticipate OOV words that are potentially morphologically related to in-vocabulary (INV) words (Yang and Kirchhoff, 2006). Vilar et al. (2007) address spelling-variant OOVs in MT through online retokenization into letters and combination with a word-based system. There is much work on name transliteration and its integration in larger MT systems (Hassan and Sorensen, 2005). Okuma et al. (2007) describe a dictionary-based technique for translating OOV words in SMT. We differ from previous work on OOV handling in that we address spelling and name-transliteration OOVs in addition to morphological OOVs. We compare these different techniques and study their combination. Our morphology expansion technique is novel in"
P08-2015,D08-1076,0,\N,Missing
P08-2030,N07-2014,1,0.69545,"Missing"
P08-2030,A00-2013,0,0.302047,"Missing"
P08-2030,P06-1073,0,0.106827,"Missing"
P08-2030,P05-1071,1,\N,Missing
P09-2056,P05-1071,1,0.603708,"Missing"
P09-2056,D07-1116,1,0.667198,"ic syntax. We describe CATiB’s representation and annotation procedure, and report on interannotator agreement and speed. 1 Introduction and Motivation CATiB contrasts with PATB and PADT in putting an emphasis on annotation speed for the specific task of parser training. Two basic ideas inspire the CATiB approach. First, CATiB avoids annotation of redundant linguistic information or information not targeted in current parsing research. For example, nominal case markers in Arabic have been shown to be automatically determinable from syntax and word morphology and needn’t be manually annotated (Habash et al., 2007a). Also, phrasal co-indexation, empty pronouns, and full lemma disambiguation are not currently used in parsing research so we do not include them in CATiB. Second, CATiB uses a simple intuitive dependency representation and terminology inspired by Arabic’s long tradition of syntactic studies. For example, CATiB relation labels include tamyiz (specification) and idafa (possessive construction) in addition to universal predicate-argument structure labels such as subject, object and modifier. These representation choices make it easier to train annotators without being restricted to hire people"
P09-2056,maamouri-etal-2008-enhancing,0,0.0705742,"annotation for the sentence àñÔ g Ï @ PñÖ ß ú¯ àA JJ . Ë @ð P@P l&apos; A Ë@ ú æAÖ xmswn Alf sAˆyH zArwA lbnAn fy tmwz AlmADy ‘50 thousand tourists visited Lebanon last July.’ 3 Annotation Procedure Although CATiB is independent of previous annotation projects, it builds on existing resources and lessons learned. For instance, CATiB’s pipeline uses PATB-trained tools for tokenization, POStagging and parsing. We also use the TrEd annotation interface developed in coordination with the PADT. Similarly, our annotation manual is guided by the wonderfully detailed manual of the PATB for coverage (Maamouri et al., 2008). Annotators Our five annotators and their supervisor are all educated native Arabic speakers. Annotators are hired on a part-time basis and are not required to be on-site. The annotation files are exchanged electronically. This arrangement allows more annotators to participate, and reduces logistical problems. However, having no full-time annotators limits the overall weekly annotation rate. Annotator training took about two months (150 hrs/annotator on average). This training time is much shorter than the PATB’s six-month training period.4 Below, we describe our pipeline in some detail inclu"
P09-2056,J93-2004,0,\N,Missing
P10-2033,2010.jeptalnrecital-long.30,1,0.424339,"Missing"
P10-2033,2009.mtsummit-papers.2,0,0.0112858,"le. We apply statistical significance tests to prune unreliable phrase-pairs Based on these analyses, we propose a new method to help phrase-based SMT systems deal with Arabic-English word order differences due to VS constructions. As in related work on syntactic reordering by preprocessing, our method attempts to make Arabic and English word order closer to each other by reordering Arabic VS constructions into SV. However, unlike in previous work, the reordered Arabic sentences are used only for word alignment. Phrase translation extraction and de180 and score remaining phrase-table entries (Chen et al., 2009). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MT06 test set. For all systems, the English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (PATB3) tokenization scheme (Maamouri et al., 2009) using the MADA+TOKAN morphological analyzer and tokenizer (Habash and Rambow, 2005). MADA-produced Arabic lemmas are used for word alignment. 6 Table 3: Evaluation on all test sets: on the total of 4432 test sentences, improvements are statistically significant"
P10-2033,P08-1009,0,0.0320597,"has been more successful on language pairs other than Arabic-English, perhaps due to more accurate parsers and less ambiguous reordering patterns than for Arabic VS. For instance, Collins et al. (2005) apply six manually defined transformations to German parse trees which improve German-English translation by 0.4 BLEU on the Europarl task. Xia and McCord (2004) learn reordering rules for French to English translations, which arguably presents less syntactic distortion than Arabic-English. Zhang et al. (2007) limit reordering to decoding for Chinese-English SMT using a lattice representation. Cherry (2008) uses dependency parses as cohesion constraints in decoding for French-English SMT. For Arabic-English phrase-based SMT, the impact of syntactic reordering as preprocessing is less clear. Habash (2007) proposes to learn syntactic reordering rules targeting Arabic-English word order differences and integrates them as deterministic preprocessing. He reports improvements in BLEU compared to phrase-based SMT limited to monotonic decoding, but these improvements do not hold with distortion. Instead of applying reordering rules deterministically, Crego and Habash (2008) use a lattice input to repres"
P10-2033,P05-1066,0,0.241763,"parallel treebank. Our analysis shows that VS reordering rules are not straightforward and that SMT should therefore benefit from direct modeling of Arabic verb subject translation. In order to detect VS constructions, we use our state-of-the-art Arabic dependency parser, which is essentially the CATIB E X baseline in our subsequent parsing work in Marton et al. (2010), and is further described there. We show that VS subjects and their exact boundaries are hard to identify accurately. Given the noise in VS detection, existing strategies for source-side reordering (e.g., Xia and McCord (2004), Collins et al. (2005), Wang et al. (2007)) or using deWe study the challenges raised by Arabic verb and subject detection and reordering in Statistical Machine Translation (SMT). We show that post-verbal subject (VS) constructions are hard to translate because they have highly ambiguous reordering patterns when translated to English. In addition, implementing reordering is difficult because the boundaries of VS constructions are hard to detect accurately, even with a state-of-the-art Arabic dependency parser. We therefore propose to reorder VS constructions into SV order for SMT word alignment only. This strategy"
P10-2033,W08-0307,1,0.945077,"es, even on a strong large-scale baseline and despite noisy parses. 1 Introduction Modern Standard Arabic (MSA) is a morphosyntactically complex language, with different phenomena from English, a fact that raises many interesting issues for natural language processing and Arabic-to-English statistical machine translation (SMT). While comprehensive Arabic preprocessing schemes have been widely adopted for handling Arabic morphology in SMT (e.g., Sadat and Habash (2006), Zollmann et al. (2006), Lee (2004)), syntactic issues have not received as much attention by comparison (Green et al. (2009), Crego and Habash (2008), Habash (2007)). Arabic verbal constructions are particularly challenging since subjects can occur in pre-verbal (SV), post-verbal (VS) or pro-dropped (“null subject”) constructions. As a result, training data for learning verbal construction translations is split between the different constructions and their patterns; and complex reordering schemas are needed in order to translate them into primarily 1 http://www.itl.nist.gov/iad/ mig/tests/mt/2009/ResultsRelease/ currentArabic.html 178 Proceedings of the ACL 2010 Conference Short Papers, pages 178–183, c Uppsala, Sweden, 11-16 July 2010. 20"
P10-2033,W08-0306,0,0.0382337,"Missing"
P10-2033,W03-3017,0,0.0495428,"Missing"
P10-2033,P05-1071,1,0.216532,"Missing"
P10-2033,J08-4003,0,0.0138759,"Missing"
P10-2033,J03-1002,0,0.00389424,"5 65.75 74.23 83.31 65.50 • medium-scale the bitext consists of 12M words on the Arabic side (LDC2007E103). The language model is trained on the English side of the large bitext. • large-scale the bitext consists of several newswire LDC corpora, and has 64M words on the Arabic side. The language model is trained on the English side of the bitext augmented with Gigaword data. Reordering Arabic VS for SMT word alignment Except from this difference in training data, the two systems are identical. They use a standard phrase-based architecture. The parallel corpus is word-aligned using the GIZA++ (Och and Ney, 2003), which sequentially learns word alignments for the IBM1, HMM, IBM3 and IBM4 models. The resulting alignments in both translation directions are intersected and augmented using the grow-diag-final-and heuristic (Koehn et al., 2007). Phrase translations of up to 10 words are extracted in the Moses phrase-table. We apply statistical significance tests to prune unreliable phrase-pairs Based on these analyses, we propose a new method to help phrase-based SMT systems deal with Arabic-English word order differences due to VS constructions. As in related work on syntactic reordering by preprocessing,"
P10-2033,P09-2056,1,0.562753,"Missing"
P10-2033,P02-1040,0,0.108224,"Missing"
P10-2033,2007.mtsummit-papers.29,1,0.951896,"e-scale baseline and despite noisy parses. 1 Introduction Modern Standard Arabic (MSA) is a morphosyntactically complex language, with different phenomena from English, a fact that raises many interesting issues for natural language processing and Arabic-to-English statistical machine translation (SMT). While comprehensive Arabic preprocessing schemes have been widely adopted for handling Arabic morphology in SMT (e.g., Sadat and Habash (2006), Zollmann et al. (2006), Lee (2004)), syntactic issues have not received as much attention by comparison (Green et al. (2009), Crego and Habash (2008), Habash (2007)). Arabic verbal constructions are particularly challenging since subjects can occur in pre-verbal (SV), post-verbal (VS) or pro-dropped (“null subject”) constructions. As a result, training data for learning verbal construction translations is split between the different constructions and their patterns; and complex reordering schemas are needed in order to translate them into primarily 1 http://www.itl.nist.gov/iad/ mig/tests/mt/2009/ResultsRelease/ currentArabic.html 178 Proceedings of the ACL 2010 Conference Short Papers, pages 178–183, c Uppsala, Sweden, 11-16 July 2010. 2010 Association"
P10-2033,P06-1001,1,0.829926,"ser. We therefore propose to reorder VS constructions into SV order for SMT word alignment only. This strategy significantly improves BLEU and TER scores, even on a strong large-scale baseline and despite noisy parses. 1 Introduction Modern Standard Arabic (MSA) is a morphosyntactically complex language, with different phenomena from English, a fact that raises many interesting issues for natural language processing and Arabic-to-English statistical machine translation (SMT). While comprehensive Arabic preprocessing schemes have been widely adopted for handling Arabic morphology in SMT (e.g., Sadat and Habash (2006), Zollmann et al. (2006), Lee (2004)), syntactic issues have not received as much attention by comparison (Green et al. (2009), Crego and Habash (2008), Habash (2007)). Arabic verbal constructions are particularly challenging since subjects can occur in pre-verbal (SV), post-verbal (VS) or pro-dropped (“null subject”) constructions. As a result, training data for learning verbal construction translations is split between the different constructions and their patterns; and complex reordering schemas are needed in order to translate them into primarily 1 http://www.itl.nist.gov/iad/ mig/tests/mt"
P10-2033,D09-1024,0,0.023611,"Missing"
P10-2033,N03-1017,0,0.005535,"Missing"
P10-2033,2006.amta-papers.25,0,0.0496745,"Missing"
P10-2033,D07-1077,0,0.028413,"analysis shows that VS reordering rules are not straightforward and that SMT should therefore benefit from direct modeling of Arabic verb subject translation. In order to detect VS constructions, we use our state-of-the-art Arabic dependency parser, which is essentially the CATIB E X baseline in our subsequent parsing work in Marton et al. (2010), and is further described there. We show that VS subjects and their exact boundaries are hard to identify accurately. Given the noise in VS detection, existing strategies for source-side reordering (e.g., Xia and McCord (2004), Collins et al. (2005), Wang et al. (2007)) or using deWe study the challenges raised by Arabic verb and subject detection and reordering in Statistical Machine Translation (SMT). We show that post-verbal subject (VS) constructions are hard to translate because they have highly ambiguous reordering patterns when translated to English. In addition, implementing reordering is difficult because the boundaries of VS constructions are hard to detect accurately, even with a state-of-the-art Arabic dependency parser. We therefore propose to reorder VS constructions into SV order for SMT word alignment only. This strategy significantly improv"
P10-2033,C04-1073,0,0.253143,"aligned Arabic-English parallel treebank. Our analysis shows that VS reordering rules are not straightforward and that SMT should therefore benefit from direct modeling of Arabic verb subject translation. In order to detect VS constructions, we use our state-of-the-art Arabic dependency parser, which is essentially the CATIB E X baseline in our subsequent parsing work in Marton et al. (2010), and is further described there. We show that VS subjects and their exact boundaries are hard to identify accurately. Given the noise in VS detection, existing strategies for source-side reordering (e.g., Xia and McCord (2004), Collins et al. (2005), Wang et al. (2007)) or using deWe study the challenges raised by Arabic verb and subject detection and reordering in Statistical Machine Translation (SMT). We show that post-verbal subject (VS) constructions are hard to translate because they have highly ambiguous reordering patterns when translated to English. In addition, implementing reordering is difficult because the boundaries of VS constructions are hard to detect accurately, even with a state-of-the-art Arabic dependency parser. We therefore propose to reorder VS constructions into SV order for SMT word alignme"
P10-2033,W04-3250,0,0.0118151,"Missing"
P10-2033,W07-0401,0,0.048109,"translations that do not break subject boundaries. Syntactically motivated reordering for phrasebased SMT has been more successful on language pairs other than Arabic-English, perhaps due to more accurate parsers and less ambiguous reordering patterns than for Arabic VS. For instance, Collins et al. (2005) apply six manually defined transformations to German parse trees which improve German-English translation by 0.4 BLEU on the Europarl task. Xia and McCord (2004) learn reordering rules for French to English translations, which arguably presents less syntactic distortion than Arabic-English. Zhang et al. (2007) limit reordering to decoding for Chinese-English SMT using a lattice representation. Cherry (2008) uses dependency parses as cohesion constraints in decoding for French-English SMT. For Arabic-English phrase-based SMT, the impact of syntactic reordering as preprocessing is less clear. Habash (2007) proposes to learn syntactic reordering rules targeting Arabic-English word order differences and integrates them as deterministic preprocessing. He reports improvements in BLEU compared to phrase-based SMT limited to monotonic decoding, but these improvements do not hold with distortion. Instead of"
P10-2033,N04-4015,0,0.0894678,"ions into SV order for SMT word alignment only. This strategy significantly improves BLEU and TER scores, even on a strong large-scale baseline and despite noisy parses. 1 Introduction Modern Standard Arabic (MSA) is a morphosyntactically complex language, with different phenomena from English, a fact that raises many interesting issues for natural language processing and Arabic-to-English statistical machine translation (SMT). While comprehensive Arabic preprocessing schemes have been widely adopted for handling Arabic morphology in SMT (e.g., Sadat and Habash (2006), Zollmann et al. (2006), Lee (2004)), syntactic issues have not received as much attention by comparison (Green et al. (2009), Crego and Habash (2008), Habash (2007)). Arabic verbal constructions are particularly challenging since subjects can occur in pre-verbal (SV), post-verbal (VS) or pro-dropped (“null subject”) constructions. As a result, training data for learning verbal construction translations is split between the different constructions and their patterns; and complex reordering schemas are needed in order to translate them into primarily 1 http://www.itl.nist.gov/iad/ mig/tests/mt/2009/ResultsRelease/ currentArabic."
P10-2033,maamouri-etal-2008-enhancing,0,0.0848332,"Missing"
P10-2033,P06-1073,0,0.0210988,"Missing"
P10-2033,N06-2051,0,0.0191457,"to reorder VS constructions into SV order for SMT word alignment only. This strategy significantly improves BLEU and TER scores, even on a strong large-scale baseline and despite noisy parses. 1 Introduction Modern Standard Arabic (MSA) is a morphosyntactically complex language, with different phenomena from English, a fact that raises many interesting issues for natural language processing and Arabic-to-English statistical machine translation (SMT). While comprehensive Arabic preprocessing schemes have been widely adopted for handling Arabic morphology in SMT (e.g., Sadat and Habash (2006), Zollmann et al. (2006), Lee (2004)), syntactic issues have not received as much attention by comparison (Green et al. (2009), Crego and Habash (2008), Habash (2007)). Arabic verbal constructions are particularly challenging since subjects can occur in pre-verbal (SV), post-verbal (VS) or pro-dropped (“null subject”) constructions. As a result, training data for learning verbal construction translations is split between the different constructions and their patterns; and complex reordering schemas are needed in order to translate them into primarily 1 http://www.itl.nist.gov/iad/ mig/tests/mt/2009/ResultsRelease/ cu"
P10-2033,W10-1402,1,0.41613,"modeling should further improve SMT. We attempt to get a better understanding of translation patterns for Arabic verb constructions, particularly VS constructions, by studying their occurrence and reordering patterns in a handaligned Arabic-English parallel treebank. Our analysis shows that VS reordering rules are not straightforward and that SMT should therefore benefit from direct modeling of Arabic verb subject translation. In order to detect VS constructions, we use our state-of-the-art Arabic dependency parser, which is essentially the CATIB E X baseline in our subsequent parsing work in Marton et al. (2010), and is further described there. We show that VS subjects and their exact boundaries are hard to identify accurately. Given the noise in VS detection, existing strategies for source-side reordering (e.g., Xia and McCord (2004), Collins et al. (2005), Wang et al. (2007)) or using deWe study the challenges raised by Arabic verb and subject detection and reordering in Statistical Machine Translation (SMT). We show that post-verbal subject (VS) constructions are hard to translate because they have highly ambiguous reordering patterns when translated to English. In addition, implementing reorderin"
P10-2033,nivre-etal-2006-maltparser,0,0.0108731,"Missing"
P10-2033,D07-1103,0,\N,Missing
P10-2033,W11-2127,1,\N,Missing
P10-2033,J04-4004,0,\N,Missing
P10-2033,J93-2003,0,\N,Missing
P10-2033,C96-2141,0,\N,Missing
P10-2033,N09-2001,0,\N,Missing
P10-2033,W10-1735,0,\N,Missing
P10-2033,P07-2045,0,\N,Missing
P10-2033,P08-2030,1,\N,Missing
P10-2033,N06-2013,1,\N,Missing
P10-2033,P11-2067,0,\N,Missing
P10-2033,C10-1045,0,\N,Missing
P10-2033,P08-1114,1,\N,Missing
P10-2033,2006.amta-papers.11,0,\N,Missing
P11-1088,P05-1071,1,0.881269,": the ratio of the number of hypotheses in the N-best list that contain the word over the total number of hypotheses Table 2: PZD model features. Simple features are used directly by the PZD SVM models, whereas Binned features’ (numerical) values are reduced to a small, labeled category set whose labels are used as model features. combinations of features were considered. Table 2 shows the individual feature definitions. In order to obtain the morphological features, all of the training and test data is passed through MADA 3.0, a software tool for Arabic morphological analysis disambiguation (Habash and Rambow, 2005; Roth et al., 2008; Habash et al., 2010). For these experiments, MADA provides the pos (using MADA’s native 34-tag set) and the lemma for each word. Occasionally MADA will not be able to produce any interpretations (analyses) for a word; since this is often a sign that the word is misspelled or uncommon, we define a binary na feature to indicate when MADA fails to generate analyses. In addition to using the MADA features directly, we also develop a set of nine N-gram models (where N=1, 2, and 3) for the nw, pos, and lem features defined in Table 2. We train these models using 220M words from"
P11-1088,P03-1004,0,0.0189905,"Missing"
P11-1088,W06-1648,0,0.683308,"kground on the difficulties of the Arabic HR task. Section 3 presents an analysis of HR errors and defines what is considered a problem zone to be tagged. The experimental features, data and other variables are outlined in Section 4. The experiments are presented and discussed in Section 5. We discuss and compare to some related work in detail in Section 6. Conclusions and suggested avenues of for future progress are presented in Section 7. 2 Arabic Handwriting Recognition Challenges Arabic has several orthographic and morphological properties that make HR challenging (Darwish and Oard, 2002; Magdy and Darwish, 2006; Märgner and Abed, 2009). Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 875–884, c Portland, Oregon, June 19-24, 2011. 2011 Association for Computational Linguistics 2.1 Arabic Orthography Challenges The use of cursive, connected script creates problems in that it becomes more difficult for a machine to distinguish between individual characters. This is certainly not a property unique to Arabic; methods developed for other cursive script languages (such as Hidden Markov Models) can be applied successfully to Arabic (Natarajan et al., 2008; Sale"
P11-1088,J96-1003,0,0.536846,"Missing"
P11-1088,P08-2030,1,0.848236,"of hypotheses in the N-best list that contain the word over the total number of hypotheses Table 2: PZD model features. Simple features are used directly by the PZD SVM models, whereas Binned features’ (numerical) values are reduced to a small, labeled category set whose labels are used as model features. combinations of features were considered. Table 2 shows the individual feature definitions. In order to obtain the morphological features, all of the training and test data is passed through MADA 3.0, a software tool for Arabic morphological analysis disambiguation (Habash and Rambow, 2005; Roth et al., 2008; Habash et al., 2010). For these experiments, MADA provides the pos (using MADA’s native 34-tag set) and the lemma for each word. Occasionally MADA will not be able to produce any interpretations (analyses) for a word; since this is often a sign that the word is misspelled or uncommon, we define a binary na feature to indicate when MADA fails to generate analyses. In addition to using the MADA features directly, we also develop a set of nine N-gram models (where N=1, 2, and 3) for the nw, pos, and lem features defined in Table 2. We train these models using 220M words from the Arabic Gigaword"
P11-1159,P11-2062,1,0.748432,"Missing"
P11-1159,W06-2920,0,0.0813362,"Missing"
P11-1159,P99-1065,0,0.379153,"Missing"
P11-1159,H05-1100,0,0.374859,"Missing"
P11-1159,W07-0802,0,0.34456,"Missing"
P11-1159,J08-3003,0,0.14088,"Missing"
P11-1159,C10-1045,0,0.0649513,"Missing"
P11-1159,P05-1071,1,0.924217,"Missing"
P11-1159,P09-2056,1,0.715528,"s on syntactic structure, such as agreement, which often plays an important role in morphologically rich languages. In this paper, we explore the role of morphological features in parsing Modern Standard Arabic (MSA). For MSA, the space of possible morphological features is fairly large. We determine which morphological features help and why. We also explore going beyond the easily detectable, regular form-based (“surface”) features, by representing functional values for some morphological features. We expect that representing lexical abstracCorpus We use the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). Specifically, we use the portion converted automatically from part 3 of the Penn Arabic Treebank (PATB) (Maamouri et al., 2004) to the CATiB format, which enriches the CATiB dependency trees with full PATB morphological information. CATiB’s dependency representation is based on traditional Arabic grammar and emphasizes syntactic case relations. It has a reduced POS tagset (with six tags only – henceforth CATIB 6), but a standard set of eight dependency relations: SBJ and OBJ for subject and (direct or indirect) object, respectively, (whether they appear preor post-verbally); IDF for the idaf"
P11-1159,P98-1080,0,0.260714,"Missing"
P11-1159,W10-1402,1,0.467971,"h are extremely rare (in our training corpus of about 300,000 words, we encounter only 430 of such POS tags with complete morphology). Therefore, researchers have proposed tagsets for MSA whose size is similar to that of the English PTB tagset, as this has proven to be a useful size computationally. These tagsets are hybrids in the sense that they are neither simply the core POS, nor the complete morphologically enriched tagset, but instead they selectively enrich the core POS tagset with only certain morphological features. A full dicussion of how these tagsets affect parsing is presented in Marton et al. (2010); we summarize the main points here. The following are the various tagsets we use in this paper: (a) the core POS tagset CORE 12; (b) the CATiB treebank tagset CATIB E X, a newly introduced extension of CATIB 6 (Habash and Roth, 2009) by simple regular expressions of the word form, indicating particular morphemes such as the +wn; this tagset prefix È@ Al+ or the suffix àð is the best-performing tagset for Arabic on predicted values. (c) the PATB full tagset (BW), size ≈2000+ (Buckwalter, 2004); We only discuss here the best performing tagsets (on predicted values), and BW for comparison. 1589"
P11-1159,nilsson-nivre-2008-malteval,0,0.0616297,"bination of lexical and inflectional features (Section 5.3); an extension of the DET feature (Section 5.4); using functional NUMBER and GENDER feature values, as well as the RATIONALITY feature (Section 5.5); finally, putting best feature combinations to test with the best-performing POS tagset, and on an unseen test set (Section 5.6). All results are reported mainly in terms of labeled attachment accuracy score (parent word and the dependency relation to it, a.k.a. L AS). Unlabeled attachment accuracy score (UAS) is also given. We use McNemar’s statistical significance test as implemented by Nilsson and Nivre (2008), and denote p &lt; 0.05 and p &lt; 0.01 with + and ++ , respectively. 5.1 Parser For all experiments reported here we used the syntactic dependency parser MaltParser v1.3 (Nivre, 2003; Nivre, 2008; Kübler et al., 2009) – a transition-based parser with an input buffer and a stack, using SVM classifiers to predict the next state in the parse derivation. All experiments were done using the Nivre &quot;eager&quot; algorithm.6 For training, de5 In this paper, we do not examine the contribution of different POS tagsets, see Marton et al. (2010) for details. 6 Nivre (2008) reports that non-projective and pseudoproj"
P11-1159,C08-1081,0,0.57356,"Missing"
P11-1159,W03-3017,0,0.0771246,"re (Section 5.5); finally, putting best feature combinations to test with the best-performing POS tagset, and on an unseen test set (Section 5.6). All results are reported mainly in terms of labeled attachment accuracy score (parent word and the dependency relation to it, a.k.a. L AS). Unlabeled attachment accuracy score (UAS) is also given. We use McNemar’s statistical significance test as implemented by Nilsson and Nivre (2008), and denote p &lt; 0.05 and p &lt; 0.01 with + and ++ , respectively. 5.1 Parser For all experiments reported here we used the syntactic dependency parser MaltParser v1.3 (Nivre, 2003; Nivre, 2008; Kübler et al., 2009) – a transition-based parser with an input buffer and a stack, using SVM classifiers to predict the next state in the parse derivation. All experiments were done using the Nivre &quot;eager&quot; algorithm.6 For training, de5 In this paper, we do not examine the contribution of different POS tagsets, see Marton et al. (2010) for details. 6 Nivre (2008) reports that non-projective and pseudoprojective algorithms outperform the &quot;eager&quot; projective algorithm in MaltParser, but our training data did not contain any non-projective dependencies. The Nivre &quot;standard&quot; algorithm"
P11-1159,J08-4003,0,0.548223,"r verbs) outperforms other combinations. Our approach is comparable to their work in terms of its systematic exploration of the space of morphological features. We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima’an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic, results have been reported on PATB (Kulick et al., 2006; Diab, 2007; Green and Manning, 2010), the Prague Dependency Treebank (PADT) (Buchholz and Marsi, 2006; Nivre, 2008) and the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). Recently, Green and Manning (2010) analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short Idafa constructions and verbal or equational clauses. Nivre (2008) reports experiments on Arabic parsing using his MaltParser (Nivre et al., 2007), trained on the PADT. His results are not directly comparable to ours because of the different treebanks’ representations, even though all the experiments reported here were performed using MaltParser. Our results agr"
P11-1159,P08-2030,1,0.896384,"Missing"
P11-1159,W07-2219,0,0.17495,"Missing"
P11-1159,C98-1077,0,\N,Missing
P11-1159,J08-4010,0,\N,Missing
P11-2062,altantawy-etal-2010-morphological,1,0.728944,"Missing"
P11-2062,W07-0802,0,0.180943,"I), and not-applicable (N ). N is assigned to verbs, adjectives, numbers and quantifiers.   6 Rationality (‘humanness’ ‘ É¯A« Q «/ É¯A«’) is narrower than animacy. English expresses it mainly in pronouns (he/she vs. it) and relativizers (men who... vs. cars/cows which...). 5 358 additionally, verbs in verb-subject (VSO) order only agree in gender and default to singular number. For example, the sentence ‘the men traveled’ can appear as @ð Q¯A ÈAg. QË@ AlrjAl ( MMPSR ) sAfrwA ( MMPPN ) or as sAfr ( M S ) AlrjAl ( M S ). ÈAg. QË@ Q¯A M SN MP R Third, number quantification has unique rules (Dada, 2007), e.g., numbers over 10 always take a singular noun, while numbers 3 to 10 take a plural noun and inversely agree with the noun’s func . ËA£ Ôg tional gender.7 Compare, for instance, HAJ S xms ( MMSN ) TAlbAt ( FFPPR ) ‘five [female] students’  S with H ) TlAb ( MMPSR ) ‘five . C£ éÔg xms¯h ( FFSN  g xmswn ( M P ) [male] students’ and éJ.ËA£ àñÔ BP N S TAlb¯h ( FFSR ) ‘lit. fifty [female] student[s]’. Figure 1 presents one example that combines the three phenomena mentioned above. The example is in a dependency representation based on the Columbia Arabic Treebank (C ATIB) (Habash and Rot"
P11-2062,W04-3232,0,0.299389,"Missing"
P11-2062,P09-2056,1,0.674082,"s (Dada, 2007), e.g., numbers over 10 always take a singular noun, while numbers 3 to 10 take a plural noun and inversely agree with the noun’s func . ËA£ Ôg tional gender.7 Compare, for instance, HAJ S xms ( MMSN ) TAlbAt ( FFPPR ) ‘five [female] students’  S with H ) TlAb ( MMPSR ) ‘five . C£ éÔg xms¯h ( FFSN  g xmswn ( M P ) [male] students’ and éJ.ËA£ àñÔ BP N S TAlb¯h ( FFSR ) ‘lit. fifty [female] student[s]’. Figure 1 presents one example that combines the three phenomena mentioned above. The example is in a dependency representation based on the Columbia Arabic Treebank (C ATIB) (Habash and Roth, 2009). Finally, although the rules described above are generally followed, there are numerous exceptions that can typically be explained as some form of figure of speech involving elision or overridden ratio k. jyš nality/irrationality. For example, the word  MS (M SI ) ‘army’ can take the rational M P agreement in an elided reference to its members. 7 Reverse gender agreement can be modeled as a formfunction discrepancy, although it is typically not discussed as such in Arabic grammar. 3 Related Work Much work has been done on Arabic computational morphology (Al-Sughaiyer and Al-Kharashi, 2004;"
P11-2062,P11-1159,1,0.674739,"rationality and functional gender and number. In this paper, we present an enriched version of the Penn Arabic Treebank (PATB, part 3) (Maamouri et al., 2004) that we manually annotated for these features.1 We describe a process for how to do the annotation efficiently; and furthermore, present the first quantitative analysis of morpho-syntactic phenomena in Arabic. This resource is important for building computational models of Arabic morphology and syntax that account for morpho-syntactic agreement patterns. It has already been used to demonstrate added value for Arabic dependency parsing (Marton et al., 2011). This paper is structured as follows: Sections 2 and 3 present relevant linguistic facts and related work, respectively. Section 4 describes our annotation process and Section 5 presents an analysis of the annotated corpus. 1 The annotations are publicly available for research purposes. Please contact authors. The PATB must be acquired through the Linguistic Data Consortium (LDC): http:// www.ldc.upenn.edu/. 2.1 Form and Function Arabic nominals (i.e. nouns, proper nouns and adjectives) and verbs inflect for gender: masculine (M ) and feminine (F ), and for number: singular (S), dual (D) and"
P11-2062,W07-0801,0,0.051121,"Missing"
P11-2062,W04-1604,0,\N,Missing
P13-2073,2008.iwslt-papers.1,0,0.666324,"determine the quality of the pivot phrase pairs between source and target. We show positive results (0.6 BLEU points) on Persian-Arabic SMT. Next, we briefly discuss some related work. We then review two common pivoting strategies and how we use them in Section 3. This is followed by our approach to using connectivity strength features in Section 4. We present our experimental results in Section 5. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to"
P13-2073,P07-1092,0,0.588006,"t-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (Khalilov et al., 2008). The second strategy is based on phrase pivoting (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009). In phrase pivoting, a new source-target phrase table (translation model) is induced from source-pivot and pivottarget phrase tables. Lexical weights and translation probabilities are computed from the two translation models. The third strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). In this paper, we build on the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007). We e"
P13-2073,2010.jeptalnrecital-long.29,1,0.887227,"Missing"
P13-2073,W09-0809,1,0.77596,"e a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). In this paper, we build on the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007). We extend phrase table scores with two other features that are language independent. Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve the quality of translation. To our knowledge, there hasn’t been a lot of work on Persian and Arabic as a language pair. The only effort that we are aware of is based on improving the reordering models for PersianArabic SMT (Matusov and K¨opr¨u, 2010). 3 Pivoting Strategies In this section, we review the two pivoting strategies that are our baselines. We also discuss how we overcome the large expansion of source-totarget phrase pai"
P13-2073,W09-0431,1,0.571964,"f the pivot phrase pairs between source and target. We show positive results (0.6 BLEU points) on Persian-Arabic SMT. Next, we briefly discuss some related work. We then review two common pivoting strategies and how we use them in Section 3. This is followed by our approach to using connectivity strength features in Section 4. We present our experimental results in Section 5. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (K"
P13-2073,P05-1071,1,0.76893,"e.g., Ñë+ +hm ‘their/them’. Beyond these clitics, Arabic words inflect for person (P ER), gender (G EN), number (N UM), aspect (A SP), mood (M OD), voice (VOX), state (S TT) and case (C AS). This morphological richness leads to thousands of inflected forms per lemma and a high degree of ambiguity: about 12 analyses per word, typically corresponding to two lemmas on average (Habash, 2010) We follow El Kholy and Habash (2010a) and use the PATB tokenization scheme (Maamouri et al., 2004) in our experiments. which separates all clitics except for the determiner clitic Al+(D ET) We use MADA v3.1 (Habash and Rambow, 2005; Habash et al., 2009) to tokenize the Arabic text. We only evaluate on detokenized and orthographically correct (enriched) output following the work of El Kholy and Habash (2010b). Persian on the other hand has a relatively simple nominal system. There is no case system and words do not inflect with gender except for a few animate Arabic loanwords. Unlike Arabic, Persian shows only two values for number, just singular and plural (no dual), which are usually marked by + +An, either the suffix Aë+ +hA and sometimes à@ or one of the Arabic plural markers. Persian also possess a closed set of few"
P13-2073,N06-2013,1,0.877582,"pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). In this paper, we build on the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007). We extend phrase table scores with two other features that are language independent. Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve the quality of translation. To our knowledge, there hasn’t been a lot of work on Persian and Arabic as a language pair. The only effort that we are aware of is based on improving the reordering models for PersianArabic SMT (Matusov and K¨opr¨u, 2010). 3 Pivoting Strategies In this section, we review the two pivoting strategies that are our baselines. We also discuss how we overcome the large expansion of source-totarget phrase pairs in the process of creating a pivot phrase table."
P13-2073,A00-1002,0,0.293724,"Missing"
P13-2073,W11-2123,0,0.0150908,"Arabic parallel corpus is about 2.8M sentences (≈60M words) available from LDC4 and GALE5 constrained data. We use an in-house Persian-English parallel corpus of about 170K sentences and 4M words. Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). For English language modeling, we use English Gigaword Corpus with 5-gram LM using the KenLM toolkit (Heafield, 2011). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight 4 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56, LDC2008G05, LDC2009E16, LDC2009G01. 5 Global Autonomous Language Exploitation, or GALE, is a DARPA-funded research project. optimization. For Persian-English translation model, weights are optimized using a set 1000 sentences randomly sampled from the parallel corpus while the English"
P13-2073,2008.iwslt-evaluation.17,0,0.361269,"ndependent features to determine the quality of the pivot phrase pairs between source and target. We show positive results (0.6 BLEU points) on Persian-Arabic SMT. Next, we briefly discuss some related work. We then review two common pivoting strategies and how we use them in Section 3. This is followed by our approach to using connectivity strength features in Section 4. We present our experimental results in Section 5. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivo"
P13-2073,P07-2045,0,0.0309558,"between two separate phrase-based MT systems; Persian-English direct system and EnglishArabic direct system. Given a Persian sentence, we first translate the Persian sentence from Persian to English, and then from English to Arabic. 3.2 Phrase Pivoting In phrase pivoting (sometimes called triangulation or phrase table multiplication), we train a Persianto-Arabic and an English-Arabic translation models, such as those used in the sentence pivoting technique. Based on these two models, we induce a new Persian-Arabic translation model. Since we build our models on top of Moses phrase-based SMT (Koehn et al., 2007), we need to provide the same set of phrase translation probability distributions.1 We follow Utiyama and Isahara (2007) in computing the probability distributions. The following are the set of equations used to compute the lexical probabilities (φ) and the phrase probabilities (pw ) P φ(f |a) = φ(f |e)φ(e|a) e P φ(a|f ) = φ(a|e)φ(e|f ) Pe pw (f |a) = pw (f |e)pw (e|a) e P pw (a|f ) = pw (a|e)pw (e|f ) e where f is the Persian source phrase. e is the English pivot phrase that is common in both Persian-English translation model and EnglishArabic translation model. a is the Arabic target phrase."
P13-2073,2009.mtsummit-papers.7,0,0.0443296,"by our approach to using connectivity strength features in Section 4. We present our experimental results in Section 5. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (Khalilov et al., 2008). The second strategy is based on phrase pivoting (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009). In phrase pivoting, a new source-target phrase table (translation model) is induced from source-pivot and pivottar"
P13-2073,W04-3250,0,0.221711,"Missing"
P13-2073,W07-0734,0,0.0565513,"ct. optimization. For Persian-English translation model, weights are optimized using a set 1000 sentences randomly sampled from the parallel corpus while the English-Arabic translation model weights are optimized using a set of 500 sentences from the 2004 NIST MT evaluation test set (MT04). The optimized weights are used for ranking and filtering (discussed in Section 3.3). We use a maximum phrase length of size 8 across all models. We report results on an inhouse Persian-Arabic evaluation set of 536 sentences with three references. We evaluate using BLEU-4 (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007). 5.2 Linguistic Preprocessing In this section we present our motivation and choice for preprocessing Arabic, Persian, English data. Both Arabic and Persian are morphologically complex languages but they belong to two different language families. They both express richness and linguistic complexities in different ways. One aspect of Arabic’s complexity is its various attachable clitics and numerous morphological features (Habash, 2010). which include conjunction proclitics, e.g., +ð w+ ‘and’, particle proclitics, e.g., + È l+ ‘to/for’, the definite article + È@ Al+ ‘the’, and the class of pron"
P13-2073,2010.amta-papers.29,1,0.90408,"Missing"
P13-2073,J03-1002,0,0.0163657,"he&quot;country’&quot; Figure 2: An example of weakly connected Persian-Arabic phrase pairs through English. Only one Persian word is connected to an Arabic word. SCS=0.25 and TCS=0.2. 5.1 Experimental Setup In our pivoting experiments, we build two SMT models. One model to translate from Persian to English and another model to translate from English to Arabic. The English-Arabic parallel corpus is about 2.8M sentences (≈60M words) available from LDC4 and GALE5 constrained data. We use an in-house Persian-English parallel corpus of about 170K sentences and 4M words. Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). For English language modeling, we use English Gigaword Corpus with 5-gram LM using the KenLM toolkit (Heafield, 2011). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight 4 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E"
P13-2073,P03-1021,0,0.0355814,"ouse Persian-English parallel corpus of about 170K sentences and 4M words. Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). For English language modeling, we use English Gigaword Corpus with 5-gram LM using the KenLM toolkit (Heafield, 2011). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight 4 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56, LDC2008G05, LDC2009E16, LDC2009G01. 5 Global Autonomous Language Exploitation, or GALE, is a DARPA-funded research project. optimization. For Persian-English translation model, weights are optimized using a set 1000 sentences randomly sampled from the parallel corpus while the English-Arabic translation model weights are optimized using a set of 500 sentences from the 2004 NIST MT evaluation test se"
P13-2073,P02-1040,0,0.0995031,"E, is a DARPA-funded research project. optimization. For Persian-English translation model, weights are optimized using a set 1000 sentences randomly sampled from the parallel corpus while the English-Arabic translation model weights are optimized using a set of 500 sentences from the 2004 NIST MT evaluation test set (MT04). The optimized weights are used for ranking and filtering (discussed in Section 3.3). We use a maximum phrase length of size 8 across all models. We report results on an inhouse Persian-Arabic evaluation set of 536 sentences with three references. We evaluate using BLEU-4 (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007). 5.2 Linguistic Preprocessing In this section we present our motivation and choice for preprocessing Arabic, Persian, English data. Both Arabic and Persian are morphologically complex languages but they belong to two different language families. They both express richness and linguistic complexities in different ways. One aspect of Arabic’s complexity is its various attachable clitics and numerous morphological features (Habash, 2010). which include conjunction proclitics, e.g., +ð w+ ‘and’, particle proclitics, e.g., + È l+ ‘to/for’, the definite article"
P13-2073,N13-1031,0,0.0210977,"n’t have separate forms for singular and plural. When a noun is modified by one or more adjective, the indefinite article is attached to the last adjective. Persian adjectives are similar to English in expressing comparative and superlative constructions just by adding suffixes QK+ +tar QK+ +taryn ‘+est’ respectively. Verbal ‘+er’ and áK morphology is very complex in Persian. Each verb has a past and present root and many verbs have attached prefix that is regarded part of the root. A verb in Persian inflects for 14 different tense, mood, aspect, person, number and voice combination values (Rasooli et al., 2013). We use Perstem (Jadidinejad et al., 2010) for segmenting Persian text. English, our pivot language, is quite different from both Arabic and Persian. English is poor in morphology and barely inflects for number and tense, and for person in a limited context. English preprocessing simply includes down-casing, separating punctuation and splitting off “’s”. 5.3 Baseline Evaluation We compare the performance of sentence pivoting against phrase pivoting with different filtering thresholds. The results are presented in Table 2. In general, the phrase pivoting outperforms the sentence pivoting even"
P13-2073,N07-1061,0,0.900714,"ults (0.6 BLEU points) on Persian-Arabic SMT as a case study. 1 Introduction One of the main issues in statistical machine translation (SMT) is the scarcity of parallel data for many language pairs especially when the source and target languages are morphologically rich. A common SMT solution to the lack of parallel data is to pivot the translation through a third language (called pivot or bridge language) for which there exist abundant parallel corpora with the source and target languages. The literature covers many pivoting techniques. One of the best performing techniques, phrase pivoting (Utiyama and Isahara, 2007), builds an induced new phrase table between the source and target. One of the main issues of this technique is that the size of the newly created pivot phrase table is very large (Utiyama and Isahara, 2007). Moreover, many of the produced phrase pairs are of low quality which affects the translation choices during decoding and the overall translation quality. In this paper, we introduce language independent features to determine the quality of the pivot phrase pairs between source and target. We show positive results (0.6 BLEU points) on Persian-Arabic SMT. Next, we briefly discuss some relat"
P13-2073,P09-1018,0,0.190156,"ntroduce language independent features to determine the quality of the pivot phrase pairs between source and target. We show positive results (0.6 BLEU points) on Persian-Arabic SMT. Next, we briefly discuss some related work. We then review two common pivoting strategies and how we use them in Section 3. This is followed by our approach to using connectivity strength features in Section 4. We present our experimental results in Section 5. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and"
P13-2073,P10-1047,0,0.02119,"he third strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). In this paper, we build on the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007). We extend phrase table scores with two other features that are language independent. Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve the quality of translation. To our knowledge, there hasn’t been a lot of work on Persian and Arabic as a language pair. The only effort that we are aware of is based on improving the reordering models for PersianArabic SMT (Matusov and K¨opr¨u, 2010). 3 Pivoting Strategies In this section, we review the two pivoting strategies that are our baselines. We also discuss how we overcome the large expansion of s"
P13-2073,H05-1021,0,\N,Missing
P13-2098,W09-4613,0,0.0166207,"ome form of relation between w1 and w2 . Whereas Lin (1997) and Lin (1998) used dependency relation between words, we use distance. Given a sentence, the distance between w1 and w2 is one plus the number of words that are seen after w1 and before w2 in that sentence. Hence, f (w1 , d, w2 ) is the number of times w1 occurs before w2 at a distance d in all the sentences in a corpus. ∗ is a placeholder for any word, i.e., f (∗, d, ∗) is the frequency of all word pairs occurring at distance d. The distances are directional and not absolute values. A similar measure of relatedness was also used by Kolb (2009). We estimate the frequencies from the Arabic Gigaword. We set the window size to 3 and calculate IC values of all pairs of words occurring at distance within the window size. Since the distances are directional, it has to be noted that given a word, its relations with three words before it and three words after it are modeled. During testing, for each phrase in our test set, we measure semantic relatedness of pairs of words using the IC values estimated from the Arabic Gigaword, and normalize their sum by the number of pairs in the phrase to obtain a measure of Semantic Coherence (SC) of the"
P13-2098,P97-1009,0,0.0657713,"training data for the meta-ranker. We choose RankSVM4 as the metaranker since it performed well as a base-ranker. 2.3 lexical semantic information, simple bag-of-words models usually have a lot of noise; while more sophisticated models considering positional information have sparsity issues. To strike a balance between these two extremes, we introduce a novel model of semantic coherence that is based on a measure of semantic relatedness between pairs of words. We model semantic relatedness between two words using the Information Content (IC) of the pair in a method similar to the one used by Lin (1997) and Lin (1998). Features Our features fall into five families. Base features include the HMM and LM scores produced by the OCR system. These features are used by the baseline system5 as well as by the various reranking methods. Simple features (“simple”) include the baseline rank of the hypothesis and a 0-to-1 range normalized version of it. We also use a hypothesis confidence feature which corresponds to the average of the confidence of individual words in the hypothesis; “confidence” for a given word is computed as the fraction of hypotheses in the n-best list that contain the word (Habash"
P13-2098,P98-2127,0,0.313254,"for the meta-ranker. We choose RankSVM4 as the metaranker since it performed well as a base-ranker. 2.3 lexical semantic information, simple bag-of-words models usually have a lot of noise; while more sophisticated models considering positional information have sparsity issues. To strike a balance between these two extremes, we introduce a novel model of semantic coherence that is based on a measure of semantic relatedness between pairs of words. We model semantic relatedness between two words using the Information Content (IC) of the pair in a method similar to the one used by Lin (1997) and Lin (1998). Features Our features fall into five families. Base features include the HMM and LM scores produced by the OCR system. These features are used by the baseline system5 as well as by the various reranking methods. Simple features (“simple”) include the baseline rank of the hypothesis and a 0-to-1 range normalized version of it. We also use a hypothesis confidence feature which corresponds to the average of the confidence of individual words in the hypothesis; “confidence” for a given word is computed as the fraction of hypotheses in the n-best list that contain the word (Habash and Roth, 2011)"
P13-2098,P06-2034,0,0.0673404,"Missing"
P13-2098,P05-1071,1,0.82405,"Missing"
P13-2098,P11-1088,1,0.849138,"ave been developed (M¨argner and Abed, 2009). The BBN Byblos OCR system (Natajan et al., 2002; Prasad et al., 2008; Saleem et al., 2009), which we use in this paper, relies on a hidden Markov model (HMM) to recover the sequence of characters from the image, and uses an n-gram language model (LM) to emphasize the fluency of the output. For an input image, the OCR decoder generates an nbest list of hypotheses each of which is associated with HMM and LM scores. In addition to fluency as evaluated by LMs, other information potentially helps in discriminating good from bad hypotheses. For example, Habash and Roth (2011) use a variety of linguistic (morphological and syntactic) and non-linguistic features to automatically identify errors in OCR 2 Discriminative Reranking for OCR Each hypothesis in an n-best list {hi }ni=1 is represented by a d-dimensional feature vector xi ∈ Rd . Each xi is associated with a loss li to generate a labeled n-best list H = {(xi , li )}ni=1 . The loss is computed as the Word Error Rate (WER) of the 549 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 549–555, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Lingu"
P13-2098,N04-1023,0,0.352104,"Missing"
P13-2098,J05-1003,0,\N,Missing
P13-2098,W12-3412,0,\N,Missing
P13-2098,C98-2122,0,\N,Missing
P14-1127,P01-1005,0,0.0882182,"Missing"
P14-1127,D10-1056,0,0.0224652,"The size of the languages (|L|) suggests that we are suffering from vast overgeneration; we overgenerate because in our model any affix can attach to any stem, which is not in general true. Thus there is a lack of linguistic knowledge such as paradigm information (Stump, 2001) for each word category in our model. In other words, all morphemes are treated the same in our model which is not true in natural languages. One way to tackle this problem is through an unsupervised POS tagger. The challenge here is that fully unsupervised POS taggers (without any tag dictionary) are not very accurate (Christodoulopoulos et al., 2010). Another way is through using joint mor1355 Figure 3: Trends for token-based OOV reduction with different sizes for the Fixed Affix model with trigraph reranking. phology and tagging models such as Frank et al. (2013). Language |pr ||stm ||sf| |L| |If| Assamese 4 4791 564 10.8M 1.8 Bengali 3 6496 378 7.4M 1.5 Pashto 1 5395 271 1.5M 1.3 Persian 49 6998 538 184M 2.0 Tagalog 179 4259 299 228M 1.5 Turkish 45 5266 1801 427M 2.3 Zulu 2254 5680 427 5.5B 2.8 Persian-N 3 6121 268 4.9M 1.5 Persian-V 43 788 44 1.5M 3.4 Table 4: Information about the number of unique morphemes in the Fixed Affix model fo"
P14-1127,clement-etal-2004-morphology,0,0.276789,"Missing"
P14-1127,W02-2006,0,0.208519,"um, we find work that focuses on defining morphological models with limited lexica that are then extended using raw text (Cl´ement et al., 2004; Forsberg et al., 2006). In the middle of this continuum, we find efforts to learn complete paradigms using fully supervised methods relying on completely annotated data points with rich morphological information (Durrett and DeNero, 2013; Eskander et al., 2013). Next, there is work on minimally supervised methods that use available resources such as dictionaries, bitexts, and other additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). At the other extreme, we find unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Dreyer and Eisner, 2011; Sirts and Goldwater, 2013). The work we present in this paper makes no use of any morphological annotations whatsoever, yet we are quite distinct from the approaches cited above. We compare our work to two efforts specifically. First, consider work in automatic morphological segmentation learning from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008). Unlike"
P14-1127,E12-1066,0,0.0832502,"Missing"
P14-1127,D11-1057,0,0.0467994,"mplete paradigms using fully supervised methods relying on completely annotated data points with rich morphological information (Durrett and DeNero, 2013; Eskander et al., 2013). Next, there is work on minimally supervised methods that use available resources such as dictionaries, bitexts, and other additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). At the other extreme, we find unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Dreyer and Eisner, 2011; Sirts and Goldwater, 2013). The work we present in this paper makes no use of any morphological annotations whatsoever, yet we are quite distinct from the approaches cited above. We compare our work to two efforts specifically. First, consider work in automatic morphological segmentation learning from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008). Unlike these approaches which provide segmentations for training data and produce models that can be used to segment unseen words, our approach can generate words that have not been seen in the training data. The focus of efforts i"
P14-1127,N13-1138,0,0.0197157,"eeded, and the amount of machine learning used. At one extreme, we find systems that are painstakingly and carefully designed by hand (Koskenniemi, 1983; Buckwalter, 2004; Habash and Rambow, 2006; D´etrez and Ranta, 2012). Next on the continuum, we find work that focuses on defining morphological models with limited lexica that are then extended using raw text (Cl´ement et al., 2004; Forsberg et al., 2006). In the middle of this continuum, we find efforts to learn complete paradigms using fully supervised methods relying on completely annotated data points with rich morphological information (Durrett and DeNero, 2013; Eskander et al., 2013). Next, there is work on minimally supervised methods that use available resources such as dictionaries, bitexts, and other additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). At the other extreme, we find unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Dreyer and Eisner, 2011; Sirts and Goldwater, 2013). The work we present in this paper makes no use of any morphological annotations whatsoever, yet we a"
P14-1127,D13-1105,1,0.820969,"achine learning used. At one extreme, we find systems that are painstakingly and carefully designed by hand (Koskenniemi, 1983; Buckwalter, 2004; Habash and Rambow, 2006; D´etrez and Ranta, 2012). Next on the continuum, we find work that focuses on defining morphological models with limited lexica that are then extended using raw text (Cl´ement et al., 2004; Forsberg et al., 2006). In the middle of this continuum, we find efforts to learn complete paradigms using fully supervised methods relying on completely annotated data points with rich morphological information (Durrett and DeNero, 2013; Eskander et al., 2013). Next, there is work on minimally supervised methods that use available resources such as dictionaries, bitexts, and other additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). At the other extreme, we find unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Dreyer and Eisner, 2011; Sirts and Goldwater, 2013). The work we present in this paper makes no use of any morphological annotations whatsoever, yet we are quite distinct from t"
P14-1127,D13-1004,0,0.0573526,"Missing"
P14-1127,P06-1086,1,0.870002,"aining data. The paper is structured as follows. We first discuss related work in Section 2. We then present our method in Section 3, and present experimental results in Section 4. We conclude with a discussion of future work in Section 5. 2 Related Work Approaches to Morphological Modeling Computational morphology is a very active area of research with a multitude of approaches that vary in the degree of manual annotation needed, and the amount of machine learning used. At one extreme, we find systems that are painstakingly and carefully designed by hand (Koskenniemi, 1983; Buckwalter, 2004; Habash and Rambow, 2006; D´etrez and Ranta, 2012). Next on the continuum, we find work that focuses on defining morphological models with limited lexica that are then extended using raw text (Cl´ement et al., 2004; Forsberg et al., 2006). In the middle of this continuum, we find efforts to learn complete paradigms using fully supervised methods relying on completely annotated data points with rich morphological information (Durrett and DeNero, 2013; Eskander et al., 2013). Next, there is work on minimally supervised methods that use available resources such as dictionaries, bitexts, and other additional morphologica"
P14-1127,P08-2015,1,0.78393,"e pronunciation lexicon via generating all possible pronunciations for a word before lattice generation and indexation. There are also other methods for generating abbreviations in voice search systems such as Yang et al. (2012). While all of these approaches involve lexicon expansion, they do not employ any morphological information. In the context of MT, several researchers have addressed the problem of OOV words by relating them to known in-vocabulary (INV) words. Yang and Kirchhoff (2006) anticipated OOV words that are potentially morphologically related using phrase-based backoff models. Habash (2008) considered different techniques for vocabulary expansion online. One of their techniques learned models of morphological mapping between morphologically rich source words in Arabic that produce the same English translation. This was used to relate an OOV word to a morphologically related INV word. Another technique expanded the MT phrase tables with possible transliterations and spelling alternatives. 3 segmented stems and affixes. We explore two different techniques for morphology-based vocabulary expansion that we discuss below. The output of these models is represented as a weighted finite"
P14-1127,W02-0604,0,0.0542663,"on defining morphological models with limited lexica that are then extended using raw text (Cl´ement et al., 2004; Forsberg et al., 2006). In the middle of this continuum, we find efforts to learn complete paradigms using fully supervised methods relying on completely annotated data points with rich morphological information (Durrett and DeNero, 2013; Eskander et al., 2013). Next, there is work on minimally supervised methods that use available resources such as dictionaries, bitexts, and other additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). At the other extreme, we find unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Dreyer and Eisner, 2011; Sirts and Goldwater, 2013). The work we present in this paper makes no use of any morphological annotations whatsoever, yet we are quite distinct from the approaches cited above. We compare our work to two efforts specifically. First, consider work in automatic morphological segmentation learning from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008). Unlike these approaches which"
P14-1127,J96-1003,0,0.148277,"le 4: Information about the number of unique morphemes in the Fixed Affix model for each dataset including empty affixes. |L |shows the upper bound of the number of possible unique words that can be generated from the word generation model. |If |is the average number of unique prefix-suffix pairs (including empty pairs) for each stem. Error Analysis on Turkish Unfortunately for most languages we could not find an available rule-based or supervised morphological analyzer to verify the words generated by our model. The only available tool for us is a Turkish finite-state morphological analyzer (Oflazer, 1996) implemented with the Xerox FST toolkit (Beesley and Karttunen, 2003). As we can see in Table 5, the system with the largest proportion of correct generated words reranks the expansion with trigraph probabilities using a Fixed Affix model. Results also show that we are overgenerating many nonsense words that we ought to be pruning from our results. Another observation is that the recognition percentage of the morphological analyzer on INV words is much higher than on OOVs, which shows that OOVs in Turkish dataset are much harder to analyze. 1356 Tr. WFST Model Fixed Affix Model Bigram Affix Mo"
P14-1127,N13-1031,1,0.785358,"-babel103bv0.4b), Pashto (IARPA-babel104b-v0.4bY), Tagalog (IARPA-babel106-v0.2g), Turkish (IARPAbabel105b-v0.4) and Zulu (IARPA-babel206bv0.1e). Speech annotation such as silences and hesitations are removed from transcription and all words are turned into lower-case (for languages using the Roman script – Tagalog, Turkish and Zulu). Moreover, in order to be able to perform a manual error analysis, we include a language that has rich morphology and of which the first author is a native speaker: Persian. We sampled data from the training and development set of the Persian dependency treebank (Rasooli et al., 2013) to create a comparable seventh dataset in Persian. Statistics about the datasets are shown in Table 1. We also conduct further experiments on just verbs and nouns in the data set for Persian (Persian-N and Persian V). As shown in Table 1, the training data is very small and the OOV rate is high especially in terms of types. For some languages that have richer morphology such as Turkish and Zulu, the OOV rate is much higher than other languages. Word Generation Tools and Settings For unsupervised learning of morphology, we use Morfessor CAT-MAP (v. 0.9.2) which was shown to be a very accurate"
P14-1127,N09-4005,0,0.0633433,"Missing"
P14-1127,Q13-1021,0,0.0255187,"lly supervised methods relying on completely annotated data points with rich morphological information (Durrett and DeNero, 2013; Eskander et al., 2013). Next, there is work on minimally supervised methods that use available resources such as dictionaries, bitexts, and other additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). At the other extreme, we find unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Dreyer and Eisner, 2011; Sirts and Goldwater, 2013). The work we present in this paper makes no use of any morphological annotations whatsoever, yet we are quite distinct from the approaches cited above. We compare our work to two efforts specifically. First, consider work in automatic morphological segmentation learning from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008). Unlike these approaches which provide segmentations for training data and produce models that can be used to segment unseen words, our approach can generate words that have not been seen in the training data. The focus of efforts is rather complementary: we a"
P14-1127,P08-1084,0,0.0566489,"al models with limited lexica that are then extended using raw text (Cl´ement et al., 2004; Forsberg et al., 2006). In the middle of this continuum, we find efforts to learn complete paradigms using fully supervised methods relying on completely annotated data points with rich morphological information (Durrett and DeNero, 2013; Eskander et al., 2013). Next, there is work on minimally supervised methods that use available resources such as dictionaries, bitexts, and other additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). At the other extreme, we find unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Dreyer and Eisner, 2011; Sirts and Goldwater, 2013). The work we present in this paper makes no use of any morphological annotations whatsoever, yet we are quite distinct from the approaches cited above. We compare our work to two efforts specifically. First, consider work in automatic morphological segmentation learning from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008). Unlike these approaches which provide segmentations for tr"
P14-1127,E06-1006,0,0.0347412,"ary to build an expanded lexicon. Word recognition is done in the second run based on the lexicon. Lei et al. (2009) expanded the pronunciation lexicon via generating all possible pronunciations for a word before lattice generation and indexation. There are also other methods for generating abbreviations in voice search systems such as Yang et al. (2012). While all of these approaches involve lexicon expansion, they do not employ any morphological information. In the context of MT, several researchers have addressed the problem of OOV words by relating them to known in-vocabulary (INV) words. Yang and Kirchhoff (2006) anticipated OOV words that are potentially morphologically related using phrase-based backoff models. Habash (2008) considered different techniques for vocabulary expansion online. One of their techniques learned models of morphological mapping between morphologically rich source words in Arabic that produce the same English translation. This was used to relate an OOV word to a morphologically related INV word. Another technique expanded the MT phrase tables with possible transliterations and spelling alternatives. 3 segmented stems and affixes. We explore two different techniques for morphol"
P14-1127,P00-1027,0,0.0999458,"anta, 2012). Next on the continuum, we find work that focuses on defining morphological models with limited lexica that are then extended using raw text (Cl´ement et al., 2004; Forsberg et al., 2006). In the middle of this continuum, we find efforts to learn complete paradigms using fully supervised methods relying on completely annotated data points with rich morphological information (Durrett and DeNero, 2013; Eskander et al., 2013). Next, there is work on minimally supervised methods that use available resources such as dictionaries, bitexts, and other additional morphological annotations (Yarowsky and Wicentowski, 2000; Cucerzan and Yarowsky, 2002; Neuvel and Fulop, 2002; Snyder and Barzilay, 2008). At the other extreme, we find unsupervised methods that learn morphology models from unannotated data (Creutz and Lagus, 2007; Monson et al., 2008; Dreyer and Eisner, 2011; Sirts and Goldwater, 2013). The work we present in this paper makes no use of any morphological annotations whatsoever, yet we are quite distinct from the approaches cited above. We compare our work to two efforts specifically. First, consider work in automatic morphological segmentation learning from unannotated data (Creutz and Lagus, 2007;"
P14-2027,P01-1005,0,0.0263224,"Spelling Error Correction model, which uses supervised learning to map input characters into output characters in context. The approach has the following characteristics: Character-level Corrections are learned at the character-level1 using a supervised sequence labeling approach. Generalized The input space consists of all characters, and a single classifier is used to learn 2 Related Work Most earlier work on automatic error correction addressed spelling errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 1 We use the term ‘character’ strictly in the alphabetic sense, not the logographic sense (as in the Chinese s"
P14-2027,habash-etal-2012-conventional,1,0.900559,"Missing"
P14-2027,N13-1044,1,0.906303,"Missing"
P14-2027,D12-1052,0,0.0226669,"models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 1 We use the term ‘character’ strictly in the alphabetic sense, not the logographic sense (as in the Chinese script). 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics Input k o r e c t d Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of"
P14-2027,D12-1138,0,0.028716,"e recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 1 We use the term ‘character’ strictly in the alphabetic sense, not the logographic sense (as in the Chinese script). 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics Input k o r e c t d Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al., 2013; Subramaniam et al., 2009; Ling et al., 2013). The work of Eskander et al. (2013) is the most relevant to the present study: it presents a character-edit classification model (CEC) using the same dataset we use in this paper.2 Eskander et al. (2013) analyzed the data to identify the seven most common types of errors. They developed seven classifiers and appli"
P14-2027,P11-1038,0,0.0363372,"phic sense (as in the Chinese script). 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics Input k o r e c t d Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al., 2013; Subramaniam et al., 2009; Ling et al., 2013). The work of Eskander et al. (2013) is the most relevant to the present study: it presents a character-edit classification model (CEC) using the same dataset we use in this paper.2 Eskander et al. (2013) analyzed the data to identify the seven most common types of errors. They developed seven classifiers and applied them to the data in succession. This makes the approach tailored to the specific data set in use and limited to a specific set of errors. In this work, a single model is considered for all types of errors. The model c"
P14-2027,N13-1066,1,0.860407,"acter-level1 using a supervised sequence labeling approach. Generalized The input space consists of all characters, and a single classifier is used to learn 2 Related Work Most earlier work on automatic error correction addressed spelling errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 1 We use the term ‘character’ strictly in the alphabetic sense, not the logographic sense (as in the Chinese script). 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistic"
P14-2027,I08-2131,0,0.0314932,"aracteristics: Character-level Corrections are learned at the character-level1 using a supervised sequence labeling approach. Generalized The input space consists of all characters, and a single classifier is used to learn 2 Related Work Most earlier work on automatic error correction addressed spelling errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 1 We use the term ‘character’ strictly in the alphabetic sense, not the logographic sense (as in the Chinese script). 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, c Baltimore, Maryland,"
P14-2027,N10-1019,0,0.0255857,"ish and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 1 We use the term ‘character’ strictly in the alphabetic sense, not the logographic sense (as in the Chinese script). 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics Input k o r e c t d Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on"
P14-2027,N01-1025,0,0.246898,"Missing"
P14-2027,P11-1088,1,0.832313,"sh correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 1 We use the term ‘character’ strictly in the alphabetic sense, not the logographic sense (as in the Chinese script). 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics Input k o r e c t d Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al., 2013; Subramaniam et al., 2009; Ling et al., 2013). The work of Eskander et al. (2013) is the most relevant to the present study: it presents a character-edit classification model (CEC) using the same dataset we use in this paper.2 Eskander et al. (2013) analyzed the data to identify the seven most common types of errors. They developed seven classifiers and applied them to the data in succession. This makes th"
P14-2027,D13-1008,0,0.0226538,"Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics Input k o r e c t d Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al., 2013; Subramaniam et al., 2009; Ling et al., 2013). The work of Eskander et al. (2013) is the most relevant to the present study: it presents a character-edit classification model (CEC) using the same dataset we use in this paper.2 Eskander et al. (2013) analyzed the data to identify the seven most common types of errors. They developed seven classifiers and applied them to the data in succession. This makes the approach tailored to the specific data set in use and limited to a specific set of errors. In this work, a single model is considered for all types of errors. The model considers every character in the input text for a possible spelli"
P14-2027,P11-1093,1,0.871573,"14). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 1 We use the term ‘character’ strictly in the alphabetic sense, not the logographic sense (as in the Chinese script). 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics Input k o r e c t d Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al., 2013; Subramaniam et al., 2009; Ling et al., 2013). The work of Eskander et al. (2013) is the most relevant to the present study: it presents a character-edit classification model (CEC) using the same dataset we use in this paper.2 Eskander et al. (2013) analyzed t"
P14-2027,zaghouani-etal-2014-large,1,\N,Missing
P14-2125,P07-2045,0,0.0127241,"mental setup and the four baseline systems we built, and we evaluate their performance and the potential of their combination. In the next section we present and evaluate the system selection approach. MT Systems. We build four MT systems. (1) DA-Only. This system is trained on the DAEnglish data and tuned on EgyDevV3. (2) MSA-Only. This system is trained on the MSA-English data and tuned on MT08. (3) DA+MSA. This system is trained on the combination of both corpora (resulting in 62M tokenized2 words on the Arabic side) and tuned on MT Tools and Settings. We use the open-source Moses toolkit (Koehn et al., 2007) to build four Arabic-English phrase-based statistical machine translation systems (SMT). Our systems use a standard phrase-based architecture. The parallel corpora are word-aligned using GIZA++ (Och and Ney, 2003). The language model for our systems is trained on English Gigaword (Graff and Cieri, 2003). We use SRILM Toolkit (Stolcke, 2002) to build a 5-gram language model with modified 2 Since the DA+MSA system is intended for DA data and DA morphology, as far as tokenization is concerned, is more complex, we tokenized the training data with dialect awareness (DA with M ADA -A RZ and MSA wit"
P14-2125,W09-0807,1,0.834439,"lect identification together with various linguistic features in optimizing the selection of outputs of four different MT systems on input text that includes a mix of dialects. We test our approach on Arabic, a prototypical diglossic language (Ferguson, 1959) where the standard form of the language, Modern Standard Arabic (MSA) and the regional dialects (DA) live side-by-side and are closely related. MSA is the language used in education, scripted speech and official settings while DA is the primarily spoken Dialect Identification. There has been a number of efforts on dialect identification (Biadsy et al., 2009; Zaidan and Callison-Burch, 2011; Akbacak et al., 2011; Elfardy et al., 2013; Elfardy and Diab, 2013). Elfardy et al. (2013) performed token-level dialect ID by casting the problem as a code-switching problem and treating MSA and Egyptian as two different languages. They later 1 This paper presents work supported by the Defense Advanced Research Projects Agency (DARPA) contract No. HR0011-12-C-0014. Any opinions, findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 772 Proceedings of the 52nd Annual Mee"
P14-2125,W04-3250,0,0.425605,"Missing"
P14-2125,P13-2081,1,0.908394,"ts of four different MT systems on input text that includes a mix of dialects. We test our approach on Arabic, a prototypical diglossic language (Ferguson, 1959) where the standard form of the language, Modern Standard Arabic (MSA) and the regional dialects (DA) live side-by-side and are closely related. MSA is the language used in education, scripted speech and official settings while DA is the primarily spoken Dialect Identification. There has been a number of efforts on dialect identification (Biadsy et al., 2009; Zaidan and Callison-Burch, 2011; Akbacak et al., 2011; Elfardy et al., 2013; Elfardy and Diab, 2013). Elfardy et al. (2013) performed token-level dialect ID by casting the problem as a code-switching problem and treating MSA and Egyptian as two different languages. They later 1 This paper presents work supported by the Defense Advanced Research Projects Agency (DARPA) contract No. HR0011-12-C-0014. Any opinions, findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 772 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 772–778, c Baltimore, Mary"
P14-2125,N13-1045,0,0.0117847,"(Habash et al., 2013). The Arabic text is also Alif/Ya normalized. For more details on processing Arabic, see (Habash, 2010). System Selection and Combination in Machine Translation. The most popular approach to MT system combination involves building confusion networks from the outputs of different MT systems and decoding them to generate new translations (Rosti et al., 2007; Karakos et al., 2008; He et al., 2008; Xu et al., 2011). Other researchers explored the idea of re-ranking the n-best output of MT systems using different types of syntactic models (Och et al., 2004; Hasan et al., 2006; Ma and McKeown, 2013). While most researchers use target language features in training their rerankers, others considered source language features (Ma and McKeown, 2013). Most MT system combination work uses MT systems employing different techniques to train on the same data. However, in this paper, we use the same MT algorithms for training, tuning, and testing, but vary the training data, specifically in terms of the degree of source language dialectness. Our approach runs a classifier trained only on source language features to decide which system should translate each sentence in the test set, which means that"
P14-2125,J03-1002,0,0.00634686,"Missing"
P14-2125,N13-1044,1,0.910277,"eser-Ney smoothing. Feature weights are tuned to maximize BLEU on tuning sets using Minimum Error Rate Training (Och, 2003). Results are presented in terms of BLEU (Papineni et al., 2002). All evaluation results are case insensitive. The English data is tokenized using simple punctuation-based rules. The MSA portion of the Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004; Sadat and Habash, 2006) using the M ADA +T OKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008), while the DA portion is ATB-tokenized with M ADA -A RZ (Habash et al., 2013). The Arabic text is also Alif/Ya normalized. For more details on processing Arabic, see (Habash, 2010). System Selection and Combination in Machine Translation. The most popular approach to MT system combination involves building confusion networks from the outputs of different MT systems and decoding them to generate new translations (Rosti et al., 2007; Karakos et al., 2008; He et al., 2008; Xu et al., 2011). Other researchers explored the idea of re-ranking the n-best output of MT systems using different types of syntactic models (Och et al., 2004; Hasan et al., 2006; Ma and McKeown, 2013)"
P14-2125,P03-1021,0,0.0147561,"Linguistics (Short Papers), pages 772–778, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics used features from their token-level system to train a classifier that performs sentence-level dialect ID (Elfardy and Diab, 2013). In this paper, we use A IDA, the system of Elfardy and Diab (2013), to provide a variety of dialect ID features to train classifiers that select, for a given sentence, the MT system that produces the best translation. Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on tuning sets using Minimum Error Rate Training (Och, 2003). Results are presented in terms of BLEU (Papineni et al., 2002). All evaluation results are case insensitive. The English data is tokenized using simple punctuation-based rules. The MSA portion of the Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004; Sadat and Habash, 2006) using the M ADA +T OKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008), while the DA portion is ATB-tokenized with M ADA -A RZ (Habash et al., 2013). The Arabic text is also Alif/Ya normalized. For more details on processing Arabic, see (Habash, 2010)"
P14-2125,P02-1040,0,0.0896015,"re, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics used features from their token-level system to train a classifier that performs sentence-level dialect ID (Elfardy and Diab, 2013). In this paper, we use A IDA, the system of Elfardy and Diab (2013), to provide a variety of dialect ID features to train classifiers that select, for a given sentence, the MT system that produces the best translation. Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on tuning sets using Minimum Error Rate Training (Och, 2003). Results are presented in terms of BLEU (Papineni et al., 2002). All evaluation results are case insensitive. The English data is tokenized using simple punctuation-based rules. The MSA portion of the Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004; Sadat and Habash, 2006) using the M ADA +T OKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008), while the DA portion is ATB-tokenized with M ADA -A RZ (Habash et al., 2013). The Arabic text is also Alif/Ya normalized. For more details on processing Arabic, see (Habash, 2010). System Selection and Combination in Machine Translation. The m"
P14-2125,W06-2606,0,0.0138725,"ed with M ADA -A RZ (Habash et al., 2013). The Arabic text is also Alif/Ya normalized. For more details on processing Arabic, see (Habash, 2010). System Selection and Combination in Machine Translation. The most popular approach to MT system combination involves building confusion networks from the outputs of different MT systems and decoding them to generate new translations (Rosti et al., 2007; Karakos et al., 2008; He et al., 2008; Xu et al., 2011). Other researchers explored the idea of re-ranking the n-best output of MT systems using different types of syntactic models (Och et al., 2004; Hasan et al., 2006; Ma and McKeown, 2013). While most researchers use target language features in training their rerankers, others considered source language features (Ma and McKeown, 2013). Most MT system combination work uses MT systems employing different techniques to train on the same data. However, in this paper, we use the same MT algorithms for training, tuning, and testing, but vary the training data, specifically in terms of the degree of source language dialectness. Our approach runs a classifier trained only on source language features to decide which system should translate each sentence in the tes"
P14-2125,P07-1040,0,0.0245416,"to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004; Sadat and Habash, 2006) using the M ADA +T OKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008), while the DA portion is ATB-tokenized with M ADA -A RZ (Habash et al., 2013). The Arabic text is also Alif/Ya normalized. For more details on processing Arabic, see (Habash, 2010). System Selection and Combination in Machine Translation. The most popular approach to MT system combination involves building confusion networks from the outputs of different MT systems and decoding them to generate new translations (Rosti et al., 2007; Karakos et al., 2008; He et al., 2008; Xu et al., 2011). Other researchers explored the idea of re-ranking the n-best output of MT systems using different types of syntactic models (Och et al., 2004; Hasan et al., 2006; Ma and McKeown, 2013). While most researchers use target language features in training their rerankers, others considered source language features (Ma and McKeown, 2013). Most MT system combination work uses MT systems employing different techniques to train on the same data. However, in this paper, we use the same MT algorithms for training, tuning, and testing, but vary the"
P14-2125,D08-1011,0,0.0160327,"scheme (Maamouri et al., 2004; Sadat and Habash, 2006) using the M ADA +T OKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008), while the DA portion is ATB-tokenized with M ADA -A RZ (Habash et al., 2013). The Arabic text is also Alif/Ya normalized. For more details on processing Arabic, see (Habash, 2010). System Selection and Combination in Machine Translation. The most popular approach to MT system combination involves building confusion networks from the outputs of different MT systems and decoding them to generate new translations (Rosti et al., 2007; Karakos et al., 2008; He et al., 2008; Xu et al., 2011). Other researchers explored the idea of re-ranking the n-best output of MT systems using different types of syntactic models (Och et al., 2004; Hasan et al., 2006; Ma and McKeown, 2013). While most researchers use target language features in training their rerankers, others considered source language features (Ma and McKeown, 2013). Most MT system combination work uses MT systems employing different techniques to train on the same data. However, in this paper, we use the same MT algorithms for training, tuning, and testing, but vary the training data, specifically in terms o"
P14-2125,P08-2030,1,0.805052,", for a given sentence, the MT system that produces the best translation. Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on tuning sets using Minimum Error Rate Training (Och, 2003). Results are presented in terms of BLEU (Papineni et al., 2002). All evaluation results are case insensitive. The English data is tokenized using simple punctuation-based rules. The MSA portion of the Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004; Sadat and Habash, 2006) using the M ADA +T OKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008), while the DA portion is ATB-tokenized with M ADA -A RZ (Habash et al., 2013). The Arabic text is also Alif/Ya normalized. For more details on processing Arabic, see (Habash, 2010). System Selection and Combination in Machine Translation. The most popular approach to MT system combination involves building confusion networks from the outputs of different MT systems and decoding them to generate new translations (Rosti et al., 2007; Karakos et al., 2008; He et al., 2008; Xu et al., 2011). Other researchers explored the idea of re-ranking the n-best output of MT systems using different types of"
P14-2125,P08-2021,0,0.0247599,"ank (ATB) tokenization scheme (Maamouri et al., 2004; Sadat and Habash, 2006) using the M ADA +T OKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008), while the DA portion is ATB-tokenized with M ADA -A RZ (Habash et al., 2013). The Arabic text is also Alif/Ya normalized. For more details on processing Arabic, see (Habash, 2010). System Selection and Combination in Machine Translation. The most popular approach to MT system combination involves building confusion networks from the outputs of different MT systems and decoding them to generate new translations (Rosti et al., 2007; Karakos et al., 2008; He et al., 2008; Xu et al., 2011). Other researchers explored the idea of re-ranking the n-best output of MT systems using different types of syntactic models (Och et al., 2004; Hasan et al., 2006; Ma and McKeown, 2013). While most researchers use target language features in training their rerankers, others considered source language features (Ma and McKeown, 2013). Most MT system combination work uses MT systems employing different techniques to train on the same data. However, in this paper, we use the same MT algorithms for training, tuning, and testing, but vary the training data, specif"
P14-2125,P06-1001,1,0.782279,"d Diab (2013), to provide a variety of dialect ID features to train classifiers that select, for a given sentence, the MT system that produces the best translation. Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on tuning sets using Minimum Error Rate Training (Och, 2003). Results are presented in terms of BLEU (Papineni et al., 2002). All evaluation results are case insensitive. The English data is tokenized using simple punctuation-based rules. The MSA portion of the Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004; Sadat and Habash, 2006) using the M ADA +T OKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008), while the DA portion is ATB-tokenized with M ADA -A RZ (Habash et al., 2013). The Arabic text is also Alif/Ya normalized. For more details on processing Arabic, see (Habash, 2010). System Selection and Combination in Machine Translation. The most popular approach to MT system combination involves building confusion networks from the outputs of different MT systems and decoding them to generate new translations (Rosti et al., 2007; Karakos et al., 2008; He et al., 2008; Xu et al., 2011). Other researchers ex"
P14-2125,P13-2001,0,0.122008,"Missing"
P14-2125,W11-2602,1,0.874594,"Missing"
P14-2125,N13-1036,1,0.902589,"aword (Graff and Cieri, 2003). We use SRILM Toolkit (Stolcke, 2002) to build a 5-gram language model with modified 2 Since the DA+MSA system is intended for DA data and DA morphology, as far as tokenization is concerned, is more complex, we tokenized the training data with dialect awareness (DA with M ADA -A RZ and MSA with M ADA) since M ADA -A RZ does a lot better than M ADA on DA (Habash et al., 2013). Tuning and Test data, however, are tokenized by M ADA -A RZ since we do not assume any knowledge of the dialect of a test sentence. 773 EgyDevV3. (4) MSA-Pivot. This MSA-pivoting system uses Salloum and Habash (2013)’s DA-MSA MT system followed by an Arabic-English SMT system which is trained on both corpora augmented with the DA-English where the DA side is preprocessed with the same DA-MSA MT system then tokenized with M ADA -A RZ. The result is 67M tokenized words on the Arabic side. EgyDevV3 was similarly preprocessed with the DA-MSA MT system and M ADA -A RZ and used for tuning the system parameters. Test sets are similarly preprocessed before decoding with the SMT system. is that these systems complement each other in interesting ways where the combination of their selections could lead to better ov"
P14-2125,2010.amta-papers.5,0,0.358145,"Missing"
P14-2125,W11-2121,0,0.0486787,"Missing"
P14-2125,P11-2007,0,0.0759012,"ogether with various linguistic features in optimizing the selection of outputs of four different MT systems on input text that includes a mix of dialects. We test our approach on Arabic, a prototypical diglossic language (Ferguson, 1959) where the standard form of the language, Modern Standard Arabic (MSA) and the regional dialects (DA) live side-by-side and are closely related. MSA is the language used in education, scripted speech and official settings while DA is the primarily spoken Dialect Identification. There has been a number of efforts on dialect identification (Biadsy et al., 2009; Zaidan and Callison-Burch, 2011; Akbacak et al., 2011; Elfardy et al., 2013; Elfardy and Diab, 2013). Elfardy et al. (2013) performed token-level dialect ID by casting the problem as a code-switching problem and treating MSA and Egyptian as two different languages. They later 1 This paper presents work supported by the Defense Advanced Research Projects Agency (DARPA) contract No. HR0011-12-C-0014. Any opinions, findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 772 Proceedings of the 52nd Annual Meeting of the Association for Compu"
P14-2125,N12-1006,0,0.066245,"o avoid confusion. 3 MT Train/Tune/Test Data. We have two parallel corpora. The first is a DA-English corpus of 5M tokenized words of Egyptian (∼3.5M) and Levantine (∼1.5M). This corpus is part of BOLT data. The second is an MSA-English corpus of 57M tokenized words obtained from several LDC corpora (10 times the size of the DAEnglish data). We work with eight standard MT test sets: three MSA sets from NIST MTEval with four references (MT06, MT08, and MT09), four Egyptian sets from LDC BOLT data with two references (EgyDevV1, EgyDevV2, EgyDevV3, and EgyTestV2), and one Levantine set from BBN (Zbib et al., 2012) with one reference which we split into LevDev and LevTest. We used MT08 and EgyDevV3 to tune SMT systems while we divided the remaining sets among classifier training data (5,562 sentences), dev (1,802 sentences) and blind test (1,804 sentences) sets to ensure each of these new sets has a variety of dialects and genres (weblog and newswire). Machine Translation Experiments In this section, we present our MT experimental setup and the four baseline systems we built, and we evaluate their performance and the potential of their combination. In the next section we present and evaluate the system"
P14-2125,N04-1021,0,\N,Missing
P14-2125,D08-1076,0,\N,Missing
P18-2089,E06-1047,1,0.721003,"pes is three times greater in DA. Many previous works ignore inter-dialect variation, training dialect agnostic embeddings, yet we show that modeling dialects individually yields Introduction Many natural language processing tasks require word embeddings as inputs, yet quality embeddings require large, non-noisy corpora. Dialectal Arabic (DA), the low register of highly diglossic Arabic (Ferguson, 1959), is problematically noisy. While the high register, Modern Standard Arabic (MSA), is uniform across educated circles in the Arab World, many varieties of DA are not even mutually intelligible (Chiang et al., 2006). The lexical correspondences across four Arab city di1 Examples are drawn from the MADAR lexicon (Bouamor et al., 2018). Arabic script follows CODA guidelines (Habash et al., 2018) and transliteration is presented in the HSB scheme (Habash et al., 2007). 2 Our DA corpora are described in Section 3 whereas the MSA and English sentences are randomly drawn from the parallel corpus described in Almahairi et al. (2016). 558 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 558–565 c Melbourne, Australia, July 15 - 20, 2018. 2018 Associati"
P18-2089,L18-1133,0,0.0263376,"d resources: V ECMAP (Artetxe et al., 2016, 2017a) and MUSE (Conneau et al., 2017). Both are equipped to learn either via supervision or by iteratively mapping with little or no supervision. Recently, another unsupervised approach leveraging local neighborhood structures was evaluated on French, English, and MSA (Aldarmaki et al., 2017). Such approaches address seed data scarcity, but have not previously been applied to sparse corpora lacking standardized spelling. While we address unstandardized spelling indirectly by learning better embeddings for low frequency types, Zalmout et al. (2018), Abidi and Smaïli (2018), and Dasigi and Diab (2011) attempt to map DA spelling variants to each other. We are the first to use embeddings for multiple specific DA dialects, though DA embeddings are often used for sentiment analysis (Al Sallab et al., 2015; Altowayan and Tao, 2016). One such work, Dahou et al. (2016), uses pre-built dictionaries to deterministically identify phrases in mixed MSADA data before training embeddings. In MSA, embeddings have been used in additional tasks like morphological analysis (Zalmout and Habash, 2017) and POS tagging (Darwish et al., 2017). Table 2: Token and type based comparisons"
P18-2089,W16-1808,0,0.0283122,"word given the context (Continuous Bag of Words) or elements of the context given the target (SkipGram) (Mikolov et al., 2013a). These have been adapted to incorporate word order (Trask et al., 2015) or subword information (Bojanowski et al., 2016) to model syntax, morphology, etc. Bilingual embeddings are vector representations of two languages mapped into shared space, such that translated word pairs have similar vectors (Gouws et al., 2015; Luong et al., 2015). They facilitate applications from parallel sentence extraction (Grover and Mitra, 2017) to machine translation (Zou et al., 2013; Cholakov and Kordoni, 2016; Artetxe et al., 2017b) and can be used to improve monolingual embeddings (Faruqui and Dyer, 2014). Bilingual embeddings are learned via one of three methods: mapping both spaces into a shared space (Mikolov et al., 2013b), monolingual adaptation of one language’s embedding space into another’s (Zou et al., 2013), or bilingually training both embeddings simultaneously (AP et al., 2014; Pham et al., 2015). We compare implementations of two state-of-the-art mod3 Data We adopt Zaidan and Callison-Burch (2011)’s 4-way coarse-grained dialect distinction of Gulf (GLF), Maghrebi (MAG), Egyptian (EGY"
P18-2089,C16-1228,0,0.0267453,"nglish, and MSA (Aldarmaki et al., 2017). Such approaches address seed data scarcity, but have not previously been applied to sparse corpora lacking standardized spelling. While we address unstandardized spelling indirectly by learning better embeddings for low frequency types, Zalmout et al. (2018), Abidi and Smaïli (2018), and Dasigi and Diab (2011) attempt to map DA spelling variants to each other. We are the first to use embeddings for multiple specific DA dialects, though DA embeddings are often used for sentiment analysis (Al Sallab et al., 2015; Altowayan and Tao, 2016). One such work, Dahou et al. (2016), uses pre-built dictionaries to deterministically identify phrases in mixed MSADA data before training embeddings. In MSA, embeddings have been used in additional tasks like morphological analysis (Zalmout and Habash, 2017) and POS tagging (Darwish et al., 2017). Table 2: Token and type based comparisons between two dialects of Arabic, MSA, and English in corpora of 13 million words each. strong performances in a dictionary induction task when noise is systematically addressed. To that end, we make three contributions. First, we describe simple but effective adaptations to word embedding tool"
P18-2089,W17-1316,0,0.0210424,"frequency types, Zalmout et al. (2018), Abidi and Smaïli (2018), and Dasigi and Diab (2011) attempt to map DA spelling variants to each other. We are the first to use embeddings for multiple specific DA dialects, though DA embeddings are often used for sentiment analysis (Al Sallab et al., 2015; Altowayan and Tao, 2016). One such work, Dahou et al. (2016), uses pre-built dictionaries to deterministically identify phrases in mixed MSADA data before training embeddings. In MSA, embeddings have been used in additional tasks like morphological analysis (Zalmout and Habash, 2017) and POS tagging (Darwish et al., 2017). Table 2: Token and type based comparisons between two dialects of Arabic, MSA, and English in corpora of 13 million words each. strong performances in a dictionary induction task when noise is systematically addressed. To that end, we make three contributions. First, we describe simple but effective adaptations to word embedding tools to maximize the informative content leveraged in each training sentence. Second, we compare methods for representing disparate dialects in one embedding space, by mapping individual dialects into shared space or learning a joint model of all dialects. Finally,"
P18-2089,I11-1036,0,0.029043,"et al., 2016, 2017a) and MUSE (Conneau et al., 2017). Both are equipped to learn either via supervision or by iteratively mapping with little or no supervision. Recently, another unsupervised approach leveraging local neighborhood structures was evaluated on French, English, and MSA (Aldarmaki et al., 2017). Such approaches address seed data scarcity, but have not previously been applied to sparse corpora lacking standardized spelling. While we address unstandardized spelling indirectly by learning better embeddings for low frequency types, Zalmout et al. (2018), Abidi and Smaïli (2018), and Dasigi and Diab (2011) attempt to map DA spelling variants to each other. We are the first to use embeddings for multiple specific DA dialects, though DA embeddings are often used for sentiment analysis (Al Sallab et al., 2015; Altowayan and Tao, 2016). One such work, Dahou et al. (2016), uses pre-built dictionaries to deterministically identify phrases in mixed MSADA data before training embeddings. In MSA, embeddings have been used in additional tasks like morphological analysis (Zalmout and Habash, 2017) and POS tagging (Darwish et al., 2017). Table 2: Token and type based comparisons between two dialects of Ara"
P18-2089,E14-1049,0,0.0383955,"m) (Mikolov et al., 2013a). These have been adapted to incorporate word order (Trask et al., 2015) or subword information (Bojanowski et al., 2016) to model syntax, morphology, etc. Bilingual embeddings are vector representations of two languages mapped into shared space, such that translated word pairs have similar vectors (Gouws et al., 2015; Luong et al., 2015). They facilitate applications from parallel sentence extraction (Grover and Mitra, 2017) to machine translation (Zou et al., 2013; Cholakov and Kordoni, 2016; Artetxe et al., 2017b) and can be used to improve monolingual embeddings (Faruqui and Dyer, 2014). Bilingual embeddings are learned via one of three methods: mapping both spaces into a shared space (Mikolov et al., 2013b), monolingual adaptation of one language’s embedding space into another’s (Zou et al., 2013), or bilingually training both embeddings simultaneously (AP et al., 2014; Pham et al., 2015). We compare implementations of two state-of-the-art mod3 Data We adopt Zaidan and Callison-Burch (2011)’s 4-way coarse-grained dialect distinction of Gulf (GLF), Maghrebi (MAG), Egyptian (EGY), and Levantine (LEV). We collect corpora for each dialect by concatenating the relevant dialect i"
P18-2089,D16-1250,0,0.0281904,"emantics, and probabilistic phrase identification increases the number of meaningful contexts used for training. These enable the model to learn better representations for noisy, low frequency forms without requiring additional data. 5 6 Experiments and Results To evaluate the quality of our DA word embeddings, we use the task of dictionary induction. Given source dialect words from the evaluation dictionary, we attempt to recall appropriate translations in the target dialect based on cosine distance in multidialectal embedding space. The standard metric for this task is precision@k=1 (P @1) (Artetxe et al., 2016, 2017a; Conneau et al., 2017), measuring the fraction of source words in the evaluation dictionary for which the nearest target dialect neighbor matches any of the possible translations in the evaluation dictionary. We, however, are also concerned with how well multiple translations are recalled, as many words become polysemous in DA with short vowels omitted and spelling not standardized. For this reason, many words appearing both in the seed and evaluation dictionaries do not map to the exact same set of possible translations in each. Thus, many precision errors may be forgiveable, so we fo"
P18-2089,P17-1042,0,0.0255322,"tinuous Bag of Words) or elements of the context given the target (SkipGram) (Mikolov et al., 2013a). These have been adapted to incorporate word order (Trask et al., 2015) or subword information (Bojanowski et al., 2016) to model syntax, morphology, etc. Bilingual embeddings are vector representations of two languages mapped into shared space, such that translated word pairs have similar vectors (Gouws et al., 2015; Luong et al., 2015). They facilitate applications from parallel sentence extraction (Grover and Mitra, 2017) to machine translation (Zou et al., 2013; Cholakov and Kordoni, 2016; Artetxe et al., 2017b) and can be used to improve monolingual embeddings (Faruqui and Dyer, 2014). Bilingual embeddings are learned via one of three methods: mapping both spaces into a shared space (Mikolov et al., 2013b), monolingual adaptation of one language’s embedding space into another’s (Zou et al., 2013), or bilingually training both embeddings simultaneously (AP et al., 2014; Pham et al., 2015). We compare implementations of two state-of-the-art mod3 Data We adopt Zaidan and Callison-Burch (2011)’s 4-way coarse-grained dialect distinction of Gulf (GLF), Maghrebi (MAG), Egyptian (EGY), and Levantine (LEV)"
P18-2089,P17-3003,0,0.0158713,"olingual embedding models are trained to predict either the target word given the context (Continuous Bag of Words) or elements of the context given the target (SkipGram) (Mikolov et al., 2013a). These have been adapted to incorporate word order (Trask et al., 2015) or subword information (Bojanowski et al., 2016) to model syntax, morphology, etc. Bilingual embeddings are vector representations of two languages mapped into shared space, such that translated word pairs have similar vectors (Gouws et al., 2015; Luong et al., 2015). They facilitate applications from parallel sentence extraction (Grover and Mitra, 2017) to machine translation (Zou et al., 2013; Cholakov and Kordoni, 2016; Artetxe et al., 2017b) and can be used to improve monolingual embeddings (Faruqui and Dyer, 2014). Bilingual embeddings are learned via one of three methods: mapping both spaces into a shared space (Mikolov et al., 2013b), monolingual adaptation of one language’s embedding space into another’s (Zou et al., 2013), or bilingually training both embeddings simultaneously (AP et al., 2014; Pham et al., 2015). We compare implementations of two state-of-the-art mod3 Data We adopt Zaidan and Callison-Burch (2011)’s 4-way coarse-gra"
P18-2089,J82-2005,0,0.621711,"Missing"
P18-2089,1983.tc-1.13,0,0.1283,"Missing"
P18-2089,L18-1577,0,0.116754,"Missing"
P18-2089,D14-1162,0,0.103769,"Missing"
P18-2089,W15-1512,0,0.0248294,"lar vectors (Gouws et al., 2015; Luong et al., 2015). They facilitate applications from parallel sentence extraction (Grover and Mitra, 2017) to machine translation (Zou et al., 2013; Cholakov and Kordoni, 2016; Artetxe et al., 2017b) and can be used to improve monolingual embeddings (Faruqui and Dyer, 2014). Bilingual embeddings are learned via one of three methods: mapping both spaces into a shared space (Mikolov et al., 2013b), monolingual adaptation of one language’s embedding space into another’s (Zou et al., 2013), or bilingually training both embeddings simultaneously (AP et al., 2014; Pham et al., 2015). We compare implementations of two state-of-the-art mod3 Data We adopt Zaidan and Callison-Burch (2011)’s 4-way coarse-grained dialect distinction of Gulf (GLF), Maghrebi (MAG), Egyptian (EGY), and Levantine (LEV). We collect corpora for each dialect by concatenating the relevant dialect identified portion of the following corpora: Almeman and Lee (2013)’s web crawl of forums, comments and blogs, Khalifa et al. (2016)’s Gumar corpus of internet novels,3 the Broad Operational Language Translation corpus of primarily blogs described in Zbib et al. (2012), the dialectal Arabic travel corpus of B"
P18-2089,W17-2632,0,0.203288,"Missing"
P18-2089,P11-2007,0,0.0343403,"rallel sentence extraction (Grover and Mitra, 2017) to machine translation (Zou et al., 2013; Cholakov and Kordoni, 2016; Artetxe et al., 2017b) and can be used to improve monolingual embeddings (Faruqui and Dyer, 2014). Bilingual embeddings are learned via one of three methods: mapping both spaces into a shared space (Mikolov et al., 2013b), monolingual adaptation of one language’s embedding space into another’s (Zou et al., 2013), or bilingually training both embeddings simultaneously (AP et al., 2014; Pham et al., 2015). We compare implementations of two state-of-the-art mod3 Data We adopt Zaidan and Callison-Burch (2011)’s 4-way coarse-grained dialect distinction of Gulf (GLF), Maghrebi (MAG), Egyptian (EGY), and Levantine (LEV). We collect corpora for each dialect by concatenating the relevant dialect identified portion of the following corpora: Almeman and Lee (2013)’s web crawl of forums, comments and blogs, Khalifa et al. (2016)’s Gumar corpus of internet novels,3 the Broad Operational Language Translation corpus of primarily blogs described in Zbib et al. (2012), the dialectal Arabic travel corpus of Bouamor et al. (2018), Zaidan and CallisonBurch (2011)’s online news commentary corpus, and Jarrar et al."
P18-2089,N18-1087,1,0.538494,"best suited our data and resources: V ECMAP (Artetxe et al., 2016, 2017a) and MUSE (Conneau et al., 2017). Both are equipped to learn either via supervision or by iteratively mapping with little or no supervision. Recently, another unsupervised approach leveraging local neighborhood structures was evaluated on French, English, and MSA (Aldarmaki et al., 2017). Such approaches address seed data scarcity, but have not previously been applied to sparse corpora lacking standardized spelling. While we address unstandardized spelling indirectly by learning better embeddings for low frequency types, Zalmout et al. (2018), Abidi and Smaïli (2018), and Dasigi and Diab (2011) attempt to map DA spelling variants to each other. We are the first to use embeddings for multiple specific DA dialects, though DA embeddings are often used for sentiment analysis (Al Sallab et al., 2015; Altowayan and Tao, 2016). One such work, Dahou et al. (2016), uses pre-built dictionaries to deterministically identify phrases in mixed MSADA data before training embeddings. In MSA, embeddings have been used in additional tasks like morphological analysis (Zalmout and Habash, 2017) and POS tagging (Darwish et al., 2017). Table 2: Token a"
P18-2089,D17-1073,1,0.568594,"ectly by learning better embeddings for low frequency types, Zalmout et al. (2018), Abidi and Smaïli (2018), and Dasigi and Diab (2011) attempt to map DA spelling variants to each other. We are the first to use embeddings for multiple specific DA dialects, though DA embeddings are often used for sentiment analysis (Al Sallab et al., 2015; Altowayan and Tao, 2016). One such work, Dahou et al. (2016), uses pre-built dictionaries to deterministically identify phrases in mixed MSADA data before training embeddings. In MSA, embeddings have been used in additional tasks like morphological analysis (Zalmout and Habash, 2017) and POS tagging (Darwish et al., 2017). Table 2: Token and type based comparisons between two dialects of Arabic, MSA, and English in corpora of 13 million words each. strong performances in a dictionary induction task when noise is systematically addressed. To that end, we make three contributions. First, we describe simple but effective adaptations to word embedding tools to maximize the informative content leveraged in each training sentence. Second, we compare methods for representing disparate dialects in one embedding space, by mapping individual dialects into shared space or learning a"
P18-2089,W14-3603,1,0.856262,"-Burch (2011)’s 4-way coarse-grained dialect distinction of Gulf (GLF), Maghrebi (MAG), Egyptian (EGY), and Levantine (LEV). We collect corpora for each dialect by concatenating the relevant dialect identified portion of the following corpora: Almeman and Lee (2013)’s web crawl of forums, comments and blogs, Khalifa et al. (2016)’s Gumar corpus of internet novels,3 the Broad Operational Language Translation corpus of primarily blogs described in Zbib et al. (2012), the dialectal Arabic travel corpus of Bouamor et al. (2018), Zaidan and CallisonBurch (2011)’s online news commentary corpus, and Jarrar et al. (2014)’s corpus of subtitles and tweets. This results in 1.7 million sentences of EGY , 1.5 million GLF , 1.3 million LEV , and 1.1 million MAG. These corpora are each about 200 times smaller than MSA’s single-domain Gigaword (Parker et al., 2011), with lack of standard3 Gumar’s GLF portion is huge, making the GLF corpus less comparable to other dialects. Thus, we removed GLF Gumar as its inclusion did not help performance. 559 tors are concatenated to build a 400 dimensional model. Given much work demonstrating that narrow context windows capture more syntactic information and wide windows, semanti"
P18-2089,L16-1679,1,0.85445,"et al., 2013b), monolingual adaptation of one language’s embedding space into another’s (Zou et al., 2013), or bilingually training both embeddings simultaneously (AP et al., 2014; Pham et al., 2015). We compare implementations of two state-of-the-art mod3 Data We adopt Zaidan and Callison-Burch (2011)’s 4-way coarse-grained dialect distinction of Gulf (GLF), Maghrebi (MAG), Egyptian (EGY), and Levantine (LEV). We collect corpora for each dialect by concatenating the relevant dialect identified portion of the following corpora: Almeman and Lee (2013)’s web crawl of forums, comments and blogs, Khalifa et al. (2016)’s Gumar corpus of internet novels,3 the Broad Operational Language Translation corpus of primarily blogs described in Zbib et al. (2012), the dialectal Arabic travel corpus of Bouamor et al. (2018), Zaidan and CallisonBurch (2011)’s online news commentary corpus, and Jarrar et al. (2014)’s corpus of subtitles and tweets. This results in 1.7 million sentences of EGY , 1.5 million GLF , 1.3 million LEV , and 1.1 million MAG. These corpora are each about 200 times smaller than MSA’s single-domain Gigaword (Parker et al., 2011), with lack of standard3 Gumar’s GLF portion is huge, making the GLF c"
P18-2089,P07-2045,0,0.0080732,"Missing"
P18-2089,W15-1521,0,0.02407,"orms without compromising accuracy on high frequency forms. 2 Related Work Common monolingual embedding models are trained to predict either the target word given the context (Continuous Bag of Words) or elements of the context given the target (SkipGram) (Mikolov et al., 2013a). These have been adapted to incorporate word order (Trask et al., 2015) or subword information (Bojanowski et al., 2016) to model syntax, morphology, etc. Bilingual embeddings are vector representations of two languages mapped into shared space, such that translated word pairs have similar vectors (Gouws et al., 2015; Luong et al., 2015). They facilitate applications from parallel sentence extraction (Grover and Mitra, 2017) to machine translation (Zou et al., 2013; Cholakov and Kordoni, 2016; Artetxe et al., 2017b) and can be used to improve monolingual embeddings (Faruqui and Dyer, 2014). Bilingual embeddings are learned via one of three methods: mapping both spaces into a shared space (Mikolov et al., 2013b), monolingual adaptation of one language’s embedding space into another’s (Zou et al., 2013), or bilingually training both embeddings simultaneously (AP et al., 2014; Pham et al., 2015). We compare implementations of tw"
P18-2089,N12-1006,0,0.0527939,"eddings simultaneously (AP et al., 2014; Pham et al., 2015). We compare implementations of two state-of-the-art mod3 Data We adopt Zaidan and Callison-Burch (2011)’s 4-way coarse-grained dialect distinction of Gulf (GLF), Maghrebi (MAG), Egyptian (EGY), and Levantine (LEV). We collect corpora for each dialect by concatenating the relevant dialect identified portion of the following corpora: Almeman and Lee (2013)’s web crawl of forums, comments and blogs, Khalifa et al. (2016)’s Gumar corpus of internet novels,3 the Broad Operational Language Translation corpus of primarily blogs described in Zbib et al. (2012), the dialectal Arabic travel corpus of Bouamor et al. (2018), Zaidan and CallisonBurch (2011)’s online news commentary corpus, and Jarrar et al. (2014)’s corpus of subtitles and tweets. This results in 1.7 million sentences of EGY , 1.5 million GLF , 1.3 million LEV , and 1.1 million MAG. These corpora are each about 200 times smaller than MSA’s single-domain Gigaword (Parker et al., 2011), with lack of standard3 Gumar’s GLF portion is huge, making the GLF corpus less comparable to other dialects. Thus, we removed GLF Gumar as its inclusion did not help performance. 559 tors are concatenated"
P18-2089,D13-1141,0,0.039157,"either the target word given the context (Continuous Bag of Words) or elements of the context given the target (SkipGram) (Mikolov et al., 2013a). These have been adapted to incorporate word order (Trask et al., 2015) or subword information (Bojanowski et al., 2016) to model syntax, morphology, etc. Bilingual embeddings are vector representations of two languages mapped into shared space, such that translated word pairs have similar vectors (Gouws et al., 2015; Luong et al., 2015). They facilitate applications from parallel sentence extraction (Grover and Mitra, 2017) to machine translation (Zou et al., 2013; Cholakov and Kordoni, 2016; Artetxe et al., 2017b) and can be used to improve monolingual embeddings (Faruqui and Dyer, 2014). Bilingual embeddings are learned via one of three methods: mapping both spaces into a shared space (Mikolov et al., 2013b), monolingual adaptation of one language’s embedding space into another’s (Zou et al., 2013), or bilingually training both embeddings simultaneously (AP et al., 2014; Pham et al., 2015). We compare implementations of two state-of-the-art mod3 Data We adopt Zaidan and Callison-Burch (2011)’s 4-way coarse-grained dialect distinction of Gulf (GLF), M"
P19-1173,N16-3003,0,0.072978,". This enables the model to learn shared domain features. Adversarial domain adaptation has been used in several NLP applications, including sentiment analysis (Chen et al., 2016), POS tagging for Twitter (Gui et al., 2017), relation extraction (Fu et al., 2017; Wang et al., 2018), among other applications. As far as we know, we are the first to apply adversarial domain adaptation in the context of dialectal morphological modeling. Arabic Morphological Modeling Morphological modeling for Arabic has many contributions in both MSA (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout and Habash, 2017; Zalmout et al., 2018). These contributions use separate models for each morphological feature, then apply a disambiguation step, similar to several previous models for Arabic (Habash and Rambow, 2005; Pasha et al., 2014). Shen et al. (2016) use LSTMs with word/character embeddings for Arabic tagging. Darwish et al. (2018) use a CRF model for a multi-dialect POS tagging, using a"
P19-1173,W16-2007,0,0.0238069,"11; Søgaard and Goldberg, 2016; Alonso and Plank, 2017; Bingel and Søgaard, 2017; Hashimoto et al., 2017). Inoue et al. (2017) used multitask learning for fine-grained POS tagging in MSA. We extend their work by doing cross-dialectal modeling and various contributions for low-resource dialects. 2 Although E GY, like DA in general, does not have a standardized orthography like MSA (Habash et al., 2018). 1776 Cross-Lingual Transfer Cross-lingual morphology and syntax modeling has also been a very active NLP research area, with contributions in morphological reinflection and paradigm completion (Aharoni et al., 2016; Faruqui et al., 2016; Kann et al., 2017), morphological tagging (Buys and Botha, 2016; Cotterell and Heigold, 2017), parsing (Guo et al., 2015; Ammar et al., 2016), among others. Cotterell and Heigold (2017) used multitask learning for multi-lingual POS tagging, similar in spirit to our approach. Their architecture, however, models the morphological features in each language in a single task, where each target value represents all morphological features combined. This architecture is not suitable for MRLs, with large target spaces. Adversarial Domain Adaptation Inspired by the work of Goodfe"
P19-1173,L18-1620,0,0.0168391,"ectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout and Habash, 2017; Zalmout et al., 2018). These contributions use separate models for each morphological feature, then apply a disambiguation step, similar to several previous models for Arabic (Habash and Rambow, 2005; Pasha et al., 2014). Shen et al. (2016) use LSTMs with word/character embeddings for Arabic tagging. Darwish et al. (2018) use a CRF model for a multi-dialect POS tagging, using a small annotated Twitter corpus. Alharbi et al. (2018) also use neural models for Gulf Arabic, with good results. 4 Baseline Tagging and Disambiguation Architecture In this section we present our baseline tagging and disambiguation architectures. We extend this architecture for joint modeling in the section that follows. 4.1 Morphological Feature Tagging We use a similar tagging architecture to Zalmout et al. (2018), based on a Bi-LSTM tagging model, for the closed-set morphological features. Given a sentence of length L {w1 , w2 , ..., wL }, every word wj is represented by vector vj . We use two LSTM layers to model the relevant context for each"
P19-1173,E17-1005,0,0.025872,"proclitics, conjunction proclitics, question proclitics. Morphological disambiguation involves predicting the values for each of these features, then using these predictions to rank the different analyses from the morphological analyzer. 3 Background and Related Work Joint Modeling in NLP Joint NLP modeling in general has been an active area of research throughout the past several years, supported by recent updates in deep learning architectures. Multitask learning models have been proven very useful for several NLP tasks and applications, (Collobert et al., 2011; Søgaard and Goldberg, 2016; Alonso and Plank, 2017; Bingel and Søgaard, 2017; Hashimoto et al., 2017). Inoue et al. (2017) used multitask learning for fine-grained POS tagging in MSA. We extend their work by doing cross-dialectal modeling and various contributions for low-resource dialects. 2 Although E GY, like DA in general, does not have a standardized orthography like MSA (Habash et al., 2018). 1776 Cross-Lingual Transfer Cross-lingual morphology and syntax modeling has also been a very active NLP research area, with contributions in morphological reinflection and paradigm completion (Aharoni et al., 2016; Faruqui et al., 2016; Kann et al"
P19-1173,D16-1250,0,0.0334859,"We introduce various extensions to the multitask learning architecture for cross-dialectal modeling. These include sharing the embeddings for the pretrained word embeddings and character embeddings, sharing the output layers for the different features, and adversarial training as a form of dialect adaptation. The decisions of shared vs joint modeling throughout the various architecture choices will also affect the size of the model and number of parameters. 6.1 • Mapped embedding spaces, by training separate models for each dialect, then mapping the embedding spaces together. We use V ECMAP (Artetxe et al., 2016, 2017) to map the embedding spaces of the different variants (MSA and DA). V ECMAP uses a seed dictionary to learn a mapping function that minimizes the distances between seed dictionary unigram pairs. In addition to shared word embeddings, the character-level embeddings can also be learned separately or jointly. We do not use pretrained embeddings for the characters, and the embeddings are learnt as part of the end-to-end system. 6.2 In the multitask learning architecture, each of the different morphological features needs a separate output layer. In our experiments with Arabic, we are model"
P19-1173,P17-1042,0,0.0526869,"Missing"
P19-1173,E17-2026,0,0.0235136,"proclitics, question proclitics. Morphological disambiguation involves predicting the values for each of these features, then using these predictions to rank the different analyses from the morphological analyzer. 3 Background and Related Work Joint Modeling in NLP Joint NLP modeling in general has been an active area of research throughout the past several years, supported by recent updates in deep learning architectures. Multitask learning models have been proven very useful for several NLP tasks and applications, (Collobert et al., 2011; Søgaard and Goldberg, 2016; Alonso and Plank, 2017; Bingel and Søgaard, 2017; Hashimoto et al., 2017). Inoue et al. (2017) used multitask learning for fine-grained POS tagging in MSA. We extend their work by doing cross-dialectal modeling and various contributions for low-resource dialects. 2 Although E GY, like DA in general, does not have a standardized orthography like MSA (Habash et al., 2018). 1776 Cross-Lingual Transfer Cross-lingual morphology and syntax modeling has also been a very active NLP research area, with contributions in morphological reinflection and paradigm completion (Aharoni et al., 2016; Faruqui et al., 2016; Kann et al., 2017), morphological ta"
P19-1173,P16-1184,0,0.0313187,"moto et al., 2017). Inoue et al. (2017) used multitask learning for fine-grained POS tagging in MSA. We extend their work by doing cross-dialectal modeling and various contributions for low-resource dialects. 2 Although E GY, like DA in general, does not have a standardized orthography like MSA (Habash et al., 2018). 1776 Cross-Lingual Transfer Cross-lingual morphology and syntax modeling has also been a very active NLP research area, with contributions in morphological reinflection and paradigm completion (Aharoni et al., 2016; Faruqui et al., 2016; Kann et al., 2017), morphological tagging (Buys and Botha, 2016; Cotterell and Heigold, 2017), parsing (Guo et al., 2015; Ammar et al., 2016), among others. Cotterell and Heigold (2017) used multitask learning for multi-lingual POS tagging, similar in spirit to our approach. Their architecture, however, models the morphological features in each language in a single task, where each target value represents all morphological features combined. This architecture is not suitable for MRLs, with large target spaces. Adversarial Domain Adaptation Inspired by the work of Goodfellow et al. (2014), adversarial networks have been used to learn domain invariant featu"
P19-1173,D17-1078,0,0.0209073,"oue et al. (2017) used multitask learning for fine-grained POS tagging in MSA. We extend their work by doing cross-dialectal modeling and various contributions for low-resource dialects. 2 Although E GY, like DA in general, does not have a standardized orthography like MSA (Habash et al., 2018). 1776 Cross-Lingual Transfer Cross-lingual morphology and syntax modeling has also been a very active NLP research area, with contributions in morphological reinflection and paradigm completion (Aharoni et al., 2016; Faruqui et al., 2016; Kann et al., 2017), morphological tagging (Buys and Botha, 2016; Cotterell and Heigold, 2017), parsing (Guo et al., 2015; Ammar et al., 2016), among others. Cotterell and Heigold (2017) used multitask learning for multi-lingual POS tagging, similar in spirit to our approach. Their architecture, however, models the morphological features in each language in a single task, where each target value represents all morphological features combined. This architecture is not suitable for MRLs, with large target spaces. Adversarial Domain Adaptation Inspired by the work of Goodfellow et al. (2014), adversarial networks have been used to learn domain invariant features in models involving multip"
P19-1173,L18-1015,0,0.0681829,"al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout and Habash, 2017; Zalmout et al., 2018). These contributions use separate models for each morphological feature, then apply a disambiguation step, similar to several previous models for Arabic (Habash and Rambow, 2005; Pasha et al., 2014). Shen et al. (2016) use LSTMs with word/character embeddings for Arabic tagging. Darwish et al. (2018) use a CRF model for a multi-dialect POS tagging, using a small annotated Twitter corpus. Alharbi et al. (2018) also use neural models for Gulf Arabic, with good results. 4 Baseline Tagging and Disambiguation Architecture In this section we present our baseline tagging and disambiguation architectures. We extend this architecture for joint modeling in the section that follows. 4.1 Morphological Feature Tagging We use a similar tagging architecture to Zalmout et al. (2018), based on a Bi-LSTM tagging model, for the closed-set morphological features. Given a sentence of length L {w1 , w2 , ...,"
P19-1173,N04-4038,0,0.115382,"backpropagates the negative gradients in the backward direction. This enables the model to learn shared domain features. Adversarial domain adaptation has been used in several NLP applications, including sentiment analysis (Chen et al., 2016), POS tagging for Twitter (Gui et al., 2017), relation extraction (Fu et al., 2017; Wang et al., 2018), among other applications. As far as we know, we are the first to apply adversarial domain adaptation in the context of dialectal morphological modeling. Arabic Morphological Modeling Morphological modeling for Arabic has many contributions in both MSA (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout and Habash, 2017; Zalmout et al., 2018). These contributions use separate models for each morphological feature, then apply a disambiguation step, similar to several previous models for Arabic (Habash and Rambow, 2005; Pasha et al., 2014). Shen et al. (2016) use LSTMs with word/character embeddings for Arabic tagging. Darwish et"
P19-1173,W05-0708,0,0.186108,"l domain adaptation has been used in several NLP applications, including sentiment analysis (Chen et al., 2016), POS tagging for Twitter (Gui et al., 2017), relation extraction (Fu et al., 2017; Wang et al., 2018), among other applications. As far as we know, we are the first to apply adversarial domain adaptation in the context of dialectal morphological modeling. Arabic Morphological Modeling Morphological modeling for Arabic has many contributions in both MSA (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout and Habash, 2017; Zalmout et al., 2018). These contributions use separate models for each morphological feature, then apply a disambiguation step, similar to several previous models for Arabic (Habash and Rambow, 2005; Pasha et al., 2014). Shen et al. (2016) use LSTMs with word/character embeddings for Arabic tagging. Darwish et al. (2018) use a CRF model for a multi-dialect POS tagging, using a small annotated Twitter corpus. Alharbi et al. (2018) also use neural"
P19-1173,P18-2089,1,0.901928,"Missing"
P19-1173,N16-1077,0,0.0309076,"rg, 2016; Alonso and Plank, 2017; Bingel and Søgaard, 2017; Hashimoto et al., 2017). Inoue et al. (2017) used multitask learning for fine-grained POS tagging in MSA. We extend their work by doing cross-dialectal modeling and various contributions for low-resource dialects. 2 Although E GY, like DA in general, does not have a standardized orthography like MSA (Habash et al., 2018). 1776 Cross-Lingual Transfer Cross-lingual morphology and syntax modeling has also been a very active NLP research area, with contributions in morphological reinflection and paradigm completion (Aharoni et al., 2016; Faruqui et al., 2016; Kann et al., 2017), morphological tagging (Buys and Botha, 2016; Cotterell and Heigold, 2017), parsing (Guo et al., 2015; Ammar et al., 2016), among others. Cotterell and Heigold (2017) used multitask learning for multi-lingual POS tagging, similar in spirit to our approach. Their architecture, however, models the morphological features in each language in a single task, where each target value represents all morphological features combined. This architecture is not suitable for MRLs, with large target spaces. Adversarial Domain Adaptation Inspired by the work of Goodfellow et al. (2014), ad"
P19-1173,I17-2072,0,0.0191928,"training (Ganin and Lempitsky, 2015; Ganin et al., 2016). Adversarial training facilitates domain-adaptation schemes, especially in high-resource to low-resource adaptation scenarios. The approach is based on an adversarial discriminator, which tries to identify the domain of the data, and backpropagates the negative gradients in the backward direction. This enables the model to learn shared domain features. Adversarial domain adaptation has been used in several NLP applications, including sentiment analysis (Chen et al., 2016), POS tagging for Twitter (Gui et al., 2017), relation extraction (Fu et al., 2017; Wang et al., 2018), among other applications. As far as we know, we are the first to apply adversarial domain adaptation in the context of dialectal morphological modeling. Arabic Morphological Modeling Morphological modeling for Arabic has many contributions in both MSA (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout and Habash, 2017; Zalmout et al., 2018"
P19-1173,D17-1256,0,0.0274328,"ple domains, through domain adversarial training (Ganin and Lempitsky, 2015; Ganin et al., 2016). Adversarial training facilitates domain-adaptation schemes, especially in high-resource to low-resource adaptation scenarios. The approach is based on an adversarial discriminator, which tries to identify the domain of the data, and backpropagates the negative gradients in the backward direction. This enables the model to learn shared domain features. Adversarial domain adaptation has been used in several NLP applications, including sentiment analysis (Chen et al., 2016), POS tagging for Twitter (Gui et al., 2017), relation extraction (Fu et al., 2017; Wang et al., 2018), among other applications. As far as we know, we are the first to apply adversarial domain adaptation in the context of dialectal morphological modeling. Arabic Morphological Modeling Morphological modeling for Arabic has many contributions in both MSA (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout"
P19-1173,P15-1119,0,0.0337005,"ng for fine-grained POS tagging in MSA. We extend their work by doing cross-dialectal modeling and various contributions for low-resource dialects. 2 Although E GY, like DA in general, does not have a standardized orthography like MSA (Habash et al., 2018). 1776 Cross-Lingual Transfer Cross-lingual morphology and syntax modeling has also been a very active NLP research area, with contributions in morphological reinflection and paradigm completion (Aharoni et al., 2016; Faruqui et al., 2016; Kann et al., 2017), morphological tagging (Buys and Botha, 2016; Cotterell and Heigold, 2017), parsing (Guo et al., 2015; Ammar et al., 2016), among others. Cotterell and Heigold (2017) used multitask learning for multi-lingual POS tagging, similar in spirit to our approach. Their architecture, however, models the morphological features in each language in a single task, where each target value represents all morphological features combined. This architecture is not suitable for MRLs, with large target spaces. Adversarial Domain Adaptation Inspired by the work of Goodfellow et al. (2014), adversarial networks have been used to learn domain invariant features in models involving multiple domains, through domain"
P19-1173,W12-2301,1,0.892038,"Figure 3: The adversarial adaptation architecture, with a discriminator task that backpropagates negative gradients using the Gradient Reversal Layer (GRL). Training Process For each of the training batches, we populate half of the batch with samples from the morphologically labeled data, and the other half with the unlabeled data. The model calculates the morphological tagging loss for the first half, and the discriminator loss with the other, and optimizes for both jointly. The morphological analyzers that we use include SAMA (Graff et al., 2009) for MSA, and a combination of SAMA, CALIMA (Habash et al., 2012), and ADAM (Salloum and Habash, 2014) for E GY, as used in the MADAMIRA (Pasha et al., 2014) system. Unlabeled Data The pretrained word embeddings for MSA are trained using the LDC’s Gigaword corpus (Parker et al., 2011). For E GY we use about 410 million words of the Broad Operational Language Translation (BOLT) Arabic Forum Discussions (Tracey et al., 2018). We use the MADAR corpus (Bouamor et al., 2018) as the seed dictionary for embedding space mapping. We use the E GY data from the work by Zbib et al. (2012) as the unlabeled corpus for E GY. 1780 7.2 Experimental Setup Tagging Architectur"
P19-1173,P05-1071,1,0.818118,"negative gradients in the backward direction. This enables the model to learn shared domain features. Adversarial domain adaptation has been used in several NLP applications, including sentiment analysis (Chen et al., 2016), POS tagging for Twitter (Gui et al., 2017), relation extraction (Fu et al., 2017; Wang et al., 2018), among other applications. As far as we know, we are the first to apply adversarial domain adaptation in the context of dialectal morphological modeling. Arabic Morphological Modeling Morphological modeling for Arabic has many contributions in both MSA (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout and Habash, 2017; Zalmout et al., 2018). These contributions use separate models for each morphological feature, then apply a disambiguation step, similar to several previous models for Arabic (Habash and Rambow, 2005; Pasha et al., 2014). Shen et al. (2016) use LSTMs with word/character embeddings for Arabic tagging. Darwish et al. (2018) use a CRF mod"
P19-1173,N13-1044,1,0.94607,"ications, including sentiment analysis (Chen et al., 2016), POS tagging for Twitter (Gui et al., 2017), relation extraction (Fu et al., 2017; Wang et al., 2018), among other applications. As far as we know, we are the first to apply adversarial domain adaptation in the context of dialectal morphological modeling. Arabic Morphological Modeling Morphological modeling for Arabic has many contributions in both MSA (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout and Habash, 2017; Zalmout et al., 2018). These contributions use separate models for each morphological feature, then apply a disambiguation step, similar to several previous models for Arabic (Habash and Rambow, 2005; Pasha et al., 2014). Shen et al. (2016) use LSTMs with word/character embeddings for Arabic tagging. Darwish et al. (2018) use a CRF model for a multi-dialect POS tagging, using a small annotated Twitter corpus. Alharbi et al. (2018) also use neural models for Gulf Arabic, with good results. 4 Base"
P19-1173,D17-1206,0,0.0314965,"litics. Morphological disambiguation involves predicting the values for each of these features, then using these predictions to rank the different analyses from the morphological analyzer. 3 Background and Related Work Joint Modeling in NLP Joint NLP modeling in general has been an active area of research throughout the past several years, supported by recent updates in deep learning architectures. Multitask learning models have been proven very useful for several NLP tasks and applications, (Collobert et al., 2011; Søgaard and Goldberg, 2016; Alonso and Plank, 2017; Bingel and Søgaard, 2017; Hashimoto et al., 2017). Inoue et al. (2017) used multitask learning for fine-grained POS tagging in MSA. We extend their work by doing cross-dialectal modeling and various contributions for low-resource dialects. 2 Although E GY, like DA in general, does not have a standardized orthography like MSA (Habash et al., 2018). 1776 Cross-Lingual Transfer Cross-lingual morphology and syntax modeling has also been a very active NLP research area, with contributions in morphological reinflection and paradigm completion (Aharoni et al., 2016; Faruqui et al., 2016; Kann et al., 2017), morphological tagging (Buys and Botha, 20"
P19-1173,K17-1042,0,0.0669967,"ambiguation involves predicting the values for each of these features, then using these predictions to rank the different analyses from the morphological analyzer. 3 Background and Related Work Joint Modeling in NLP Joint NLP modeling in general has been an active area of research throughout the past several years, supported by recent updates in deep learning architectures. Multitask learning models have been proven very useful for several NLP tasks and applications, (Collobert et al., 2011; Søgaard and Goldberg, 2016; Alonso and Plank, 2017; Bingel and Søgaard, 2017; Hashimoto et al., 2017). Inoue et al. (2017) used multitask learning for fine-grained POS tagging in MSA. We extend their work by doing cross-dialectal modeling and various contributions for low-resource dialects. 2 Although E GY, like DA in general, does not have a standardized orthography like MSA (Habash et al., 2018). 1776 Cross-Lingual Transfer Cross-lingual morphology and syntax modeling has also been a very active NLP research area, with contributions in morphological reinflection and paradigm completion (Aharoni et al., 2016; Faruqui et al., 2016; Kann et al., 2017), morphological tagging (Buys and Botha, 2016; Cotterell and Hei"
P19-1173,P17-1182,0,0.0231468,"lank, 2017; Bingel and Søgaard, 2017; Hashimoto et al., 2017). Inoue et al. (2017) used multitask learning for fine-grained POS tagging in MSA. We extend their work by doing cross-dialectal modeling and various contributions for low-resource dialects. 2 Although E GY, like DA in general, does not have a standardized orthography like MSA (Habash et al., 2018). 1776 Cross-Lingual Transfer Cross-lingual morphology and syntax modeling has also been a very active NLP research area, with contributions in morphological reinflection and paradigm completion (Aharoni et al., 2016; Faruqui et al., 2016; Kann et al., 2017), morphological tagging (Buys and Botha, 2016; Cotterell and Heigold, 2017), parsing (Guo et al., 2015; Ammar et al., 2016), among others. Cotterell and Heigold (2017) used multitask learning for multi-lingual POS tagging, similar in spirit to our approach. Their architecture, however, models the morphological features in each language in a single task, where each target value represents all morphological features combined. This architecture is not suitable for MRLs, with large target spaces. Adversarial Domain Adaptation Inspired by the work of Goodfellow et al. (2014), adversarial networks h"
P19-1173,C16-2047,1,0.840418,"l to learn shared domain features. Adversarial domain adaptation has been used in several NLP applications, including sentiment analysis (Chen et al., 2016), POS tagging for Twitter (Gui et al., 2017), relation extraction (Fu et al., 2017; Wang et al., 2018), among other applications. As far as we know, we are the first to apply adversarial domain adaptation in the context of dialectal morphological modeling. Arabic Morphological Modeling Morphological modeling for Arabic has many contributions in both MSA (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout and Habash, 2017; Zalmout et al., 2018). These contributions use separate models for each morphological feature, then apply a disambiguation step, similar to several previous models for Arabic (Habash and Rambow, 2005; Pasha et al., 2014). Shen et al. (2016) use LSTMs with word/character embeddings for Arabic tagging. Darwish et al. (2018) use a CRF model for a multi-dialect POS tagging, using a small annotated Twitte"
P19-1173,pasha-etal-2014-madamira,1,0.934583,"Missing"
P19-1173,C16-1018,0,0.0651418,"ng Morphological modeling for Arabic has many contributions in both MSA (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout and Habash, 2017; Zalmout et al., 2018). These contributions use separate models for each morphological feature, then apply a disambiguation step, similar to several previous models for Arabic (Habash and Rambow, 2005; Pasha et al., 2014). Shen et al. (2016) use LSTMs with word/character embeddings for Arabic tagging. Darwish et al. (2018) use a CRF model for a multi-dialect POS tagging, using a small annotated Twitter corpus. Alharbi et al. (2018) also use neural models for Gulf Arabic, with good results. 4 Baseline Tagging and Disambiguation Architecture In this section we present our baseline tagging and disambiguation architectures. We extend this architecture for joint modeling in the section that follows. 4.1 Morphological Feature Tagging We use a similar tagging architecture to Zalmout et al. (2018), based on a Bi-LSTM tagging model, for t"
P19-1173,P16-2038,0,0.0356114,"ticle proclitic, preposition proclitics, conjunction proclitics, question proclitics. Morphological disambiguation involves predicting the values for each of these features, then using these predictions to rank the different analyses from the morphological analyzer. 3 Background and Related Work Joint Modeling in NLP Joint NLP modeling in general has been an active area of research throughout the past several years, supported by recent updates in deep learning architectures. Multitask learning models have been proven very useful for several NLP tasks and applications, (Collobert et al., 2011; Søgaard and Goldberg, 2016; Alonso and Plank, 2017; Bingel and Søgaard, 2017; Hashimoto et al., 2017). Inoue et al. (2017) used multitask learning for fine-grained POS tagging in MSA. We extend their work by doing cross-dialectal modeling and various contributions for low-resource dialects. 2 Although E GY, like DA in general, does not have a standardized orthography like MSA (Habash et al., 2018). 1776 Cross-Lingual Transfer Cross-lingual morphology and syntax modeling has also been a very active NLP research area, with contributions in morphological reinflection and paradigm completion (Aharoni et al., 2016; Faruqui"
P19-1173,C18-1099,0,0.0253659,"nd Lempitsky, 2015; Ganin et al., 2016). Adversarial training facilitates domain-adaptation schemes, especially in high-resource to low-resource adaptation scenarios. The approach is based on an adversarial discriminator, which tries to identify the domain of the data, and backpropagates the negative gradients in the backward direction. This enables the model to learn shared domain features. Adversarial domain adaptation has been used in several NLP applications, including sentiment analysis (Chen et al., 2016), POS tagging for Twitter (Gui et al., 2017), relation extraction (Fu et al., 2017; Wang et al., 2018), among other applications. As far as we know, we are the first to apply adversarial domain adaptation in the context of dialectal morphological modeling. Arabic Morphological Modeling Morphological modeling for Arabic has many contributions in both MSA (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout and Habash, 2017; Zalmout et al., 2018). These contributio"
P19-1173,D18-1097,1,0.687787,"Missing"
P19-1173,N18-1087,1,0.772559,"ion (Fu et al., 2017; Wang et al., 2018), among other applications. As far as we know, we are the first to apply adversarial domain adaptation in the context of dialectal morphological modeling. Arabic Morphological Modeling Morphological modeling for Arabic has many contributions in both MSA (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout and Habash, 2017; Zalmout et al., 2018). These contributions use separate models for each morphological feature, then apply a disambiguation step, similar to several previous models for Arabic (Habash and Rambow, 2005; Pasha et al., 2014). Shen et al. (2016) use LSTMs with word/character embeddings for Arabic tagging. Darwish et al. (2018) use a CRF model for a multi-dialect POS tagging, using a small annotated Twitter corpus. Alharbi et al. (2018) also use neural models for Gulf Arabic, with good results. 4 Baseline Tagging and Disambiguation Architecture In this section we present our baseline tagging and disambiguation architect"
P19-1173,D17-1073,1,0.509195,"., 2017), relation extraction (Fu et al., 2017; Wang et al., 2018), among other applications. As far as we know, we are the first to apply adversarial domain adaptation in the context of dialectal morphological modeling. Arabic Morphological Modeling Morphological modeling for Arabic has many contributions in both MSA (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016), and Dialectal Arabic (Duh and Kirchhoff, 2005; Al-Sabbagh and Girju, 2012; Habash et al., 2013). There were also several neural extensions that show impressive results (Zalmout and Habash, 2017; Zalmout et al., 2018). These contributions use separate models for each morphological feature, then apply a disambiguation step, similar to several previous models for Arabic (Habash and Rambow, 2005; Pasha et al., 2014). Shen et al. (2016) use LSTMs with word/character embeddings for Arabic tagging. Darwish et al. (2018) use a CRF model for a multi-dialect POS tagging, using a small annotated Twitter corpus. Alharbi et al. (2018) also use neural models for Gulf Arabic, with good results. 4 Baseline Tagging and Disambiguation Architecture In this section we present our baseline tagging and d"
P19-1173,N12-1006,0,0.0292597,"e include SAMA (Graff et al., 2009) for MSA, and a combination of SAMA, CALIMA (Habash et al., 2012), and ADAM (Salloum and Habash, 2014) for E GY, as used in the MADAMIRA (Pasha et al., 2014) system. Unlabeled Data The pretrained word embeddings for MSA are trained using the LDC’s Gigaword corpus (Parker et al., 2011). For E GY we use about 410 million words of the Broad Operational Language Translation (BOLT) Arabic Forum Discussions (Tracey et al., 2018). We use the MADAR corpus (Bouamor et al., 2018) as the seed dictionary for embedding space mapping. We use the E GY data from the work by Zbib et al. (2012) as the unlabeled corpus for E GY. 1780 7.2 Experimental Setup Tagging Architecture We use two hidden layers of size 800 for the Bi-LSTM network (two for each direction), and a dropout wrapper with keep probability of 0.7, and peephole connections. We use Adam optimizer (Kingma and Ba, 2014) with a learning rate of 0.0005, and cross-entropy cost function. We run the various models for 70 epochs (fixed number of epoch since we use dropout). The LSTM character embedding architecture uses two LSTM layers of size 100, and embedding size 50. We use Word2Vec (Mikolov et al., 2013) to train the word"
P19-1327,S18-1152,0,0.0560476,"Missing"
P19-1327,S18-1116,0,0.167416,"Missing"
P19-1327,P99-1016,0,0.0111565,"orms the backbone of word-level taxonomies, most notably WordNet (Fellbaum, 1998). Early works on the modeling of this relationship focused on the practical task of discovering new instances of the hypernymy relationship given a vocabulary and an existing resource with labeled data about hypernymy, described as hypernym discovery by Camacho-Collados (2017). For the purposes of discovery, Hearst (1992) developed a landmark set of lexico-syntactic patterns which indicated hypernymy. There have been many follow-ups on this concept of identifying and utilizing patterns to identify hypernym pairs (Caraballo, 1999; Mann, 2002; Snow et al., 2005, 2006). However, by restricting the sentences of interest to only those which match patterns, even very large datasets with very loose pattern matching will often return Recently, hybrid models of hypernymy, in both discovery and detection, have surpassed the performance of either paradigm individually. Similarly, the current state-of-the-art in hypernymy detection was set by a classifier which integrated information from both pattern data and distributional word embeddings (Shwartz et al., 2016). In hypernym discovery, where purely distributional methods have s"
P19-1327,D16-1041,0,0.107838,"dataset is used to tune our cutoff points for Hearst Pattern frequency and minimum similarity for the nearest neighbor hypernyms approach. For each query word, we propose 15 candidates ranked as described in Section 4. For the three English sub-tasks, we evaluate our model using the evaluation script from the SemEval task, and compare our results on Mean Average Precision, Mean Reciprocal Rank, and Precision at 5, the metrics primarily discussed in the original task. We compare our system to the CRIM (Bernier-Colborne and Barriere, 2018), 300-sparsans (Berend et al., 2018), vanilla Taxoembed (Espinosa-Anke et al., 2016), and most frequent hypernym systems. The first two were the only systems to achieve state-of-the-art results on the above metrics for the three English subtasks, while the latter two represent the best baselines from the shared task. The comparison against these models on all three sub-tasks can be found in Table 2. 3364 Model Hybrid of SVD & NN(Our Model) CRIM (Bernier-Colborne and Barriere, 2018) vTE∗ (Espinosa-Anke et al., 2016) 300-sparsans (Berend et al., 2018) Most Frequent Hypernym∗ MAP 15.97 19.78 10.60 8.95 8.77 General MRR 34.07 36.10 23.83 19.44 21.39 P@5 15.00 19.03 9.91 8.63 7.81"
P19-1327,L16-1056,0,0.0147126,"support using the degrees of hypernymy each paradigm captures effectively. 3362 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3362–3367 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics 2 Pattern-Based Model In order to make our pattern-based approach return a reasonable number of candidate hypernyms, we apply two separate methods to increase the number of candidate hypernyms presented by the pattern based model. Extended Pattern Use First, we utilize a set of 47 extended Hearst Patterns as collected in Seitner et al. (2016). Additionally, we consider ngram terms from our vocabulary to inherently contain a pattern co-occurrence with their sub-terms, e.g., nuclear physics →hyponym physics. In English, this construction is common and accounts for a high number of “co-occurrences” between hyponyms and hypernyms. All input sentences are tested by regular expression representations of these 47 patterns, yielding a table of candidates for the hypernymy relationship, in the form of xhypo , yhyper , and the number of times the pairs co-occurred in any of the extended Hearst Patterns. This stage is fully unsupervised but"
P19-1327,P16-1226,0,0.0419475,"oncept of identifying and utilizing patterns to identify hypernym pairs (Caraballo, 1999; Mann, 2002; Snow et al., 2005, 2006). However, by restricting the sentences of interest to only those which match patterns, even very large datasets with very loose pattern matching will often return Recently, hybrid models of hypernymy, in both discovery and detection, have surpassed the performance of either paradigm individually. Similarly, the current state-of-the-art in hypernymy detection was set by a classifier which integrated information from both pattern data and distributional word embeddings (Shwartz et al., 2016). In hypernym discovery, where purely distributional methods have struggled, a model which utilized a hybrid approach of patterns and distributional representations far and away led the results of a recent SemEval Task (Camacho-Collados et al., 2018; Bernier-Colborne and Barriere, 2018). In this paper, we study the benefits of hybrid strategies of hypernymy via a hybrid of extremely simple models of pattern-based and distributional hypernym discovery. We evaluate this model on the English sub-tasks of SemEval 2018 Task 9 for Hypernym Discovery. Overall, our results show that these paradigms ha"
P19-1327,E17-1007,0,0.176722,"hybrid approach establishes new stateof-the-art results on two domain-specific English hypernym discovery tasks and outperforms all non-hybrid approaches in a general English hypernym discovery task. 1 To tackle the sparsity of pattern-based approaches, recent focus has turned to distributional models of hypernymy. Distributional models are attractive since they use signals drawn from every sentence of training data. Distributional approaches have focused on discovering spatial properties of embedding space which capture the hypernymy relationship (Kotlerman et al., 2010; Yamane et al., 2016; Shwartz et al., 2017; Nickel and Kiela, 2017; Vulic and Mrksic, 2017). The performance of distributional approaches in hypernymy detection shows promise to create a more broad picture of the hypernymy relationship space. Introduction Discovering word-level hierarchies has long been an important step in constructing language taxonomies. The most important of these hierarchical relationships is hypernymy or the ISArelationship, i.e. ‘chihuahua’ is a ‘dog’, which forms the backbone of word-level taxonomies, most notably WordNet (Fellbaum, 1998). Early works on the modeling of this relationship focused on the practic"
P19-1327,P06-1101,0,0.0976866,"data that we have. For words which never occur in any patterns, we still lack the ability to generate any reasonable candidates which causes this approach to still suffer from low total recall due to query terms never seen in patterns. 3 Distributional Modeling with Hypernyms from Nearest Neighbor For our distributional methodology, we choose the simplest possible supervised approach to hypernym discovery - a single nearest neighbor approach - in which the hypernyms for each query term are transferred from their nearest neighbor in the training data. This approach is motivated by the work of Snow et al. (2006) where linking a new hyponym to a similar known hyponym was shown to effectively encode an enormous amount of signal about correct hypernyms. Our method is as follows. Suppose we have a training set H consisting of a number of hyponyms and their corresponding hypernyms. H : {Hypoi : Hyperi1 ...Hyperij } For a given query term Q, we find the nearest neighbor Hyponn from the training set by the cosine similarity of vector representations of the words. The hypernyms of the nearest neighbor are then sorted by descending frequency in the training set, such that the words which served as hypernyms t"
P19-1327,N18-1103,0,0.0268596,"Missing"
P19-1327,C16-1176,0,0.184055,"system, utilizing a hybrid approach establishes new stateof-the-art results on two domain-specific English hypernym discovery tasks and outperforms all non-hybrid approaches in a general English hypernym discovery task. 1 To tackle the sparsity of pattern-based approaches, recent focus has turned to distributional models of hypernymy. Distributional models are attractive since they use signals drawn from every sentence of training data. Distributional approaches have focused on discovering spatial properties of embedding space which capture the hypernymy relationship (Kotlerman et al., 2010; Yamane et al., 2016; Shwartz et al., 2017; Nickel and Kiela, 2017; Vulic and Mrksic, 2017). The performance of distributional approaches in hypernymy detection shows promise to create a more broad picture of the hypernymy relationship space. Introduction Discovering word-level hierarchies has long been an important step in constructing language taxonomies. The most important of these hierarchical relationships is hypernymy or the ISArelationship, i.e. ‘chihuahua’ is a ‘dog’, which forms the backbone of word-level taxonomies, most notably WordNet (Fellbaum, 1998). Early works on the modeling of this relationship"
P19-1327,C92-2082,0,0.402812,"hierarchies has long been an important step in constructing language taxonomies. The most important of these hierarchical relationships is hypernymy or the ISArelationship, i.e. ‘chihuahua’ is a ‘dog’, which forms the backbone of word-level taxonomies, most notably WordNet (Fellbaum, 1998). Early works on the modeling of this relationship focused on the practical task of discovering new instances of the hypernymy relationship given a vocabulary and an existing resource with labeled data about hypernymy, described as hypernym discovery by Camacho-Collados (2017). For the purposes of discovery, Hearst (1992) developed a landmark set of lexico-syntactic patterns which indicated hypernymy. There have been many follow-ups on this concept of identifying and utilizing patterns to identify hypernym pairs (Caraballo, 1999; Mann, 2002; Snow et al., 2005, 2006). However, by restricting the sentences of interest to only those which match patterns, even very large datasets with very loose pattern matching will often return Recently, hybrid models of hypernymy, in both discovery and detection, have surpassed the performance of either paradigm individually. Similarly, the current state-of-the-art in hypernymy"
P19-1327,W02-1111,0,0.038853,"of word-level taxonomies, most notably WordNet (Fellbaum, 1998). Early works on the modeling of this relationship focused on the practical task of discovering new instances of the hypernymy relationship given a vocabulary and an existing resource with labeled data about hypernymy, described as hypernym discovery by Camacho-Collados (2017). For the purposes of discovery, Hearst (1992) developed a landmark set of lexico-syntactic patterns which indicated hypernymy. There have been many follow-ups on this concept of identifying and utilizing patterns to identify hypernym pairs (Caraballo, 1999; Mann, 2002; Snow et al., 2005, 2006). However, by restricting the sentences of interest to only those which match patterns, even very large datasets with very loose pattern matching will often return Recently, hybrid models of hypernymy, in both discovery and detection, have surpassed the performance of either paradigm individually. Similarly, the current state-of-the-art in hypernymy detection was set by a classifier which integrated information from both pattern data and distributional word embeddings (Shwartz et al., 2016). In hypernym discovery, where purely distributional methods have struggled, a"
P19-1327,P18-2057,0,0.2617,"he hypernymy relationship, in the form of xhypo , yhyper , and the number of times the pairs co-occurred in any of the extended Hearst Patterns. This stage is fully unsupervised but aims to extract lexico-syntactic information which indicates direct hypernymy. This raw co-occurrence table can be used to discover hypernym terms, with hypernym candidates scored based on their raw counts. Hearst Matrix Singular Value Decomposition While this raw co-occurrence table can be used to discover candidate hypernyms, it still suffers from a high amount of sparsity even for terms which occur in patterns. Roller et al. (2018) showed exactly that performing singular value decomposition on co-occurrence tables can yield recall improvements, oftentimes outperforming state-ofthe-art distributional methods for the hypernym detection task. To modify this method for the hypernym discovery task, we simply sort all vocabulary terms that occur in Hearst Patterns according to the following metric: sp(x, y) = UxT Σr Vy where U , Σ, and V are taken from the singular value decomposition of the Hearst Pattern cooccurrence matrix and Ux , Vy are the row vector and the column vector for the hyponym and the hypernym respectively. T"
pasha-etal-2014-madamira,P05-1071,1,\N,Missing
pasha-etal-2014-madamira,P08-2030,1,\N,Missing
pasha-etal-2014-madamira,P09-2056,1,\N,Missing
pasha-etal-2014-madamira,P06-1086,1,\N,Missing
pasha-etal-2014-madamira,mohamed-etal-2012-annotating,0,\N,Missing
pasha-etal-2014-madamira,N13-1044,1,\N,Missing
pasha-etal-2014-madamira,W12-2301,1,\N,Missing
passonneau-etal-2006-inter,W98-1507,0,\N,Missing
passonneau-etal-2006-inter,W04-2709,1,\N,Missing
passonneau-etal-2006-inter,W04-3254,0,\N,Missing
passonneau-etal-2006-inter,passonneau-2006-measuring,1,\N,Missing
passonneau-etal-2006-inter,passonneau-2004-computing,1,\N,Missing
passonneau-etal-2006-inter,di-eugenio-2000-usage,0,\N,Missing
rambow-etal-2006-parallel,W04-2709,1,\N,Missing
rambow-etal-2006-parallel,passonneau-etal-2006-inter,1,\N,Missing
rambow-etal-2006-parallel,J93-2004,0,\N,Missing
rambow-etal-2006-parallel,W00-0204,0,\N,Missing
rambow-etal-2006-parallel,W02-1503,0,\N,Missing
rambow-etal-2006-parallel,rambow-etal-2002-dependency,1,\N,Missing
reeder-etal-2004-interlingual,W04-2709,1,\N,Missing
reeder-etal-2004-interlingual,W03-1601,0,\N,Missing
reeder-etal-2004-interlingual,W03-1604,0,\N,Missing
reeder-etal-2004-interlingual,P98-1013,0,\N,Missing
reeder-etal-2004-interlingual,C98-1013,0,\N,Missing
reeder-etal-2004-interlingual,1991.mtsummit-papers.9,1,\N,Missing
reeder-etal-2004-interlingual,J96-2004,0,\N,Missing
reeder-etal-2004-interlingual,A97-1011,0,\N,Missing
S17-2099,P11-2103,0,0.0363133,"train Support Vector Machines (SVM) (RushdiSaleh et al., 2011; Aly and Atiya, 2013; Shoukry and Rafea, 2012), Na¨ıve Bayes (Mountassir et al., 2012; Elawady et al., 2014) and ensemble classifiers (Omar et al., 2013). Word n-grams were also used with syntactic features (root and part-ofspeech n-grams) and stylistic features (digit and letter n-grams, word length, etc.) and achieved good performances after applying the EntropyWeighted Genetic Algorithm for feature reduction (Abbasi et al., 2008). Sentiment lexicons also provided an additional source of features that proved useful for the task (Abdul-Mageed et al., 2011; Badaro et al., 2014, 2015) A framework was developed for tweets written in Modern Standard Arabic (MSA) and containing 3 OMAM Systems In this section, we present the four OMAM systems that we investigated to perform the different subtasks of SemEval-2017 Task 4. These systems were explored during the development phase, and those that achieved best performances for each subtask were then used to submit the test results. 3.1 System 1: English State-of-the-Art SA The state-of-the-art system selected from English was the winner of SemEval-2016 Subtask C “Fivepoint scale Tweet classification” in"
S17-2099,C10-1045,0,0.0345272,"s of training different sentiment classifiers for different clusters. Also, the inferior performance produced by System 3 can be due to its reliance on Arabic NLP tools, such as the syntactic parser, that are trained on MSA data, whereas the evaluation data are tweets that are likely to be noisy in terms of containing significant amounts of misspellings and grammatical errors. For the RAE approach (System 3), tweets are processed similar to System 1. We used MADAMIRA v2.1 to perform morphological tokenization following the ATB scheme (Habash and Sadat, 2006). We also used the Stanford parser (Green and Manning, 2010) to generate the syntactic parse trees. Since the resulting trees are not necessarily binary, and hence cannot be used to train recursive models, we used left-factoring to transform the trees to the Chomsky Normal Form (CNF) grammar that only contains unary and binary production rules. Model Avg-R Avg-F1 Acc. D EV Sys 1 Sys 2 Sys 3 0.458 0.455 0.424 0.434 0.401 0.394 0.453 0.477 0.410 T EST Sys 1 0.438 0.422 0.430 Table 3: Results for subtask A (rank: #5/8). For the topic-based approach (System 4), tweets are preprocessed by applying normalization and stemming using the NLTK ISRI stemmer (Tagh"
S17-2099,N06-2013,1,0.695645,"and higher accuracy, which indicates the potential benefits of training different sentiment classifiers for different clusters. Also, the inferior performance produced by System 3 can be due to its reliance on Arabic NLP tools, such as the syntactic parser, that are trained on MSA data, whereas the evaluation data are tweets that are likely to be noisy in terms of containing significant amounts of misspellings and grammatical errors. For the RAE approach (System 3), tweets are processed similar to System 1. We used MADAMIRA v2.1 to perform morphological tokenization following the ATB scheme (Habash and Sadat, 2006). We also used the Stanford parser (Green and Manning, 2010) to generate the syntactic parse trees. Since the resulting trees are not necessarily binary, and hence cannot be used to train recursive models, we used left-factoring to transform the trees to the Chomsky Normal Form (CNF) grammar that only contains unary and binary production rules. Model Avg-R Avg-F1 Acc. D EV Sys 1 Sys 2 Sys 3 0.458 0.455 0.424 0.434 0.401 0.394 0.453 0.477 0.410 T EST Sys 1 0.438 0.422 0.430 Table 3: Results for subtask A (rank: #5/8). For the topic-based approach (System 4), tweets are preprocessed by applying"
S17-2099,P13-2088,0,0.0236904,"in subtask D and 1st in subtasks C and E. The rest of this paper is organized as follows. Section 2 describes previous efforts on the given task. Section 3 presents the details of the Arabic OMAM systems. Section 4 illustrates the performances achieved for each subtask. We conclude in Section 5 with remarks on future work. 2 Related Work SA models for Arabic are generally developed by training machine learning classifiers using different choices of features. The most common features are the word n-grams features that were used to train Support Vector Machines (SVM) (RushdiSaleh et al., 2011; Aly and Atiya, 2013; Shoukry and Rafea, 2012), Na¨ıve Bayes (Mountassir et al., 2012; Elawady et al., 2014) and ensemble classifiers (Omar et al., 2013). Word n-grams were also used with syntactic features (root and part-ofspeech n-grams) and stylistic features (digit and letter n-grams, word length, etc.) and achieved good performances after applying the EntropyWeighted Genetic Algorithm for feature reduction (Abbasi et al., 2008). Sentiment lexicons also provided an additional source of features that proved useful for the task (Abdul-Mageed et al., 2011; Badaro et al., 2014, 2015) A framework was developed for"
S17-2099,W14-3623,1,0.899976,"nes (SVM) (RushdiSaleh et al., 2011; Aly and Atiya, 2013; Shoukry and Rafea, 2012), Na¨ıve Bayes (Mountassir et al., 2012; Elawady et al., 2014) and ensemble classifiers (Omar et al., 2013). Word n-grams were also used with syntactic features (root and part-ofspeech n-grams) and stylistic features (digit and letter n-grams, word length, etc.) and achieved good performances after applying the EntropyWeighted Genetic Algorithm for feature reduction (Abbasi et al., 2008). Sentiment lexicons also provided an additional source of features that proved useful for the task (Abdul-Mageed et al., 2011; Badaro et al., 2014, 2015) A framework was developed for tweets written in Modern Standard Arabic (MSA) and containing 3 OMAM Systems In this section, we present the four OMAM systems that we investigated to perform the different subtasks of SemEval-2017 Task 4. These systems were explored during the development phase, and those that achieved best performances for each subtask were then used to submit the test results. 3.1 System 1: English State-of-the-Art SA The state-of-the-art system selected from English was the winner of SemEval-2016 Subtask C “Fivepoint scale Tweet classification” in English (Ba604 Bayes"
S17-2099,S16-1010,0,0.0654565,"Missing"
S17-2099,S17-2088,0,0.0704868,"Missing"
S17-2099,D15-1299,0,0.0180159,"ñJ . . . . . ÐCB@ , àAÓP  H. AëPB@ , «@X . Y B@ ,I.Êg , éK Pñ , AK Pñ , à@ Q K @ , àA «ðXP@ ,PA   ú æJ  , éK XñªË@ , @QªË@ , àñ JJÊ¿ ø PCJ ë AÓAK. ð@ ,AÓAK. ð @ @P AK. , I.Ó@QK YËAKðX Table 2: The list of 8 generalized domains corresponding to the 34 topics in the training dataset. For the cluster-based SA approach (System 2), we trained the skip-gram word embedding model using a collection of datasets including the T RAIN and the D EV tweets provided by the organizers, the Qatar Arabic Language Bank (QALB) (Zaghouani et al., 2014) and several Arabic Twitter corpora from (Nabil et al., 2015; Refaee and Rieser, 2014b). We also used the k-means algorithm to cluster the embedding space into k clusters, with k ranging between 1 (no clustering) and 12. Best results during development were obtained using k = 4 and 5. 4.2 Message Polarity Classification (A) For this subtask, we evaluated the English state-ofthe-art approach (System 1), the cluster-based SA approach (System 2) and RAE (System 3). The development and test results are illustrated in Table 3. It can be observed that System 1 achieved the best development results, and hence was used at the test phase. System 2 achieved slig"
S17-2099,D11-1014,0,0.413812,"). Machine translation was used to apply existing state-of-the-art models for English to translations of Arabic tweets. Despite slight accuracy drop caused by translation errors, these models are still considered efficient and effective, especially for low-resource languages (Refaee and Rieser, 2014b; Mohammad et al., 2016). We briefly mention the state-of-the-art performances achieved in English SA. A new class of machine learning models based on deep learning have recently emerged. These models achieved high performances in both Arabic and English, such as the Recursive Auto Encoders (RAE) (Socher et al., 2011; Al Sallab et al., 2015), the Recursive Neural Tensor Networks (Socher et al., 2013), the Gated Recurrent Neural Networks (Tang et al., 2015) and the Dynamic Memory Networks (Kumar et al., 2015). These models were only evaluated on reviews documents, and were never tested against the irregularities and noise that exist in Twitter data. A framework to automate the human reading process improved the performance of several state-of-the-art models (Baly et al., 2016; Hobeica et al., 2011). The first system extends English state-of-theart feature engineering methods, and is based on training senti"
S17-2099,D13-1170,0,0.00665394,"h to translations of Arabic tweets. Despite slight accuracy drop caused by translation errors, these models are still considered efficient and effective, especially for low-resource languages (Refaee and Rieser, 2014b; Mohammad et al., 2016). We briefly mention the state-of-the-art performances achieved in English SA. A new class of machine learning models based on deep learning have recently emerged. These models achieved high performances in both Arabic and English, such as the Recursive Auto Encoders (RAE) (Socher et al., 2011; Al Sallab et al., 2015), the Recursive Neural Tensor Networks (Socher et al., 2013), the Gated Recurrent Neural Networks (Tang et al., 2015) and the Dynamic Memory Networks (Kumar et al., 2015). These models were only evaluated on reviews documents, and were never tested against the irregularities and noise that exist in Twitter data. A framework to automate the human reading process improved the performance of several state-of-the-art models (Baly et al., 2016; Hobeica et al., 2011). The first system extends English state-of-theart feature engineering methods, and is based on training sentiment classifiers with different choices of surface, syntactic and semantic features."
S17-2099,S17-2111,1,0.860884,"Missing"
S17-2099,pasha-etal-2014-madamira,1,0.871303,"Missing"
S17-2099,D15-1167,0,0.0331422,"drop caused by translation errors, these models are still considered efficient and effective, especially for low-resource languages (Refaee and Rieser, 2014b; Mohammad et al., 2016). We briefly mention the state-of-the-art performances achieved in English SA. A new class of machine learning models based on deep learning have recently emerged. These models achieved high performances in both Arabic and English, such as the Recursive Auto Encoders (RAE) (Socher et al., 2011; Al Sallab et al., 2015), the Recursive Neural Tensor Networks (Socher et al., 2013), the Gated Recurrent Neural Networks (Tang et al., 2015) and the Dynamic Memory Networks (Kumar et al., 2015). These models were only evaluated on reviews documents, and were never tested against the irregularities and noise that exist in Twitter data. A framework to automate the human reading process improved the performance of several state-of-the-art models (Baly et al., 2016; Hobeica et al., 2011). The first system extends English state-of-theart feature engineering methods, and is based on training sentiment classifiers with different choices of surface, syntactic and semantic features. The second is based on clustering the data into groups of"
S17-2099,P02-1053,0,0.0119198,"sk A. As for the remaining subtasks, we introduce a topicbased approach that accounts for topic specificities by predicting topics or domains of upcoming tweets, and then using this information to predict their sentiment. Results indicate that applying the English state-of-the-art method to Arabic has achieved solid results without significant enhancements. Furthermore, the topic-based method ranked 1st in subtasks C and E, and 2nd in subtask D. 1 Introduction Sentiment Analysis (SA) is a fundamental problem aiming to allow machines to automatically extract subjectivity information from text (Turney, 2002), whether at the sentence or the document level (Farra et al., 2010). This field has been 603 Proceedings of the 11th International Workshop on Semantic Evaluations (SemEval-2017), pages 603–610, c Vancouver, Canada, August 3 - 4, 2017. 2017 Association for Computational Linguistics Jordanian dialects, Arabizi (Arabic words written using Latin characters) and emoticons. This framework was realized by training different classifiers using features that capture the different linguistic phenomena (Duwairi et al., 2014). A distant-based approach showed improvement over existing fully-supervised mod"
S17-2099,zaghouani-etal-2014-large,1,0.902981,"Missing"
S17-2099,refaee-rieser-2014-arabic,0,0.0594774,"ment level (Farra et al., 2010). This field has been 603 Proceedings of the 11th International Workshop on Semantic Evaluations (SemEval-2017), pages 603–610, c Vancouver, Canada, August 3 - 4, 2017. 2017 Association for Computational Linguistics Jordanian dialects, Arabizi (Arabic words written using Latin characters) and emoticons. This framework was realized by training different classifiers using features that capture the different linguistic phenomena (Duwairi et al., 2014). A distant-based approach showed improvement over existing fully-supervised models for subjectivity classification (Refaee and Rieser, 2014a). A subjectivity and sentiment analysis system for Arabic tweets used a feature set that includes different forms of the word (lexemes and lemmas), POS tags, presence of polar adjectives, writing style (MSA or DA), and genre-specific features including the user’s gender and ID (Abdul-Mageed et al., 2014). Machine translation was used to apply existing state-of-the-art models for English to translations of Arabic tweets. Despite slight accuracy drop caused by translation errors, these models are still considered efficient and effective, especially for low-resource languages (Refaee and Rieser"
S17-2111,W11-1701,0,0.0364546,"ached to the text is derived using natural language processing tools (Pang et al., 2008; Cambria et al., 2013). Sentiment analysis could be approached in two ways. General sentiment analysis, often termed sentence-level sentiment analysis, extracts the general sentiment of the text based solely on its contents. The sentiment is not related or based on any external entity. On the other hand, topic-level sentiment analysis infers the sentiment of the given text based on a specific topic. This branch of sentiment analysis has been further explored under the term Stance Detection (Faulkner, 2014; Anand et al., 2011). With the rapid increase in different forms of online expression like reviews, political criticism, ratings and punditry, social media has become an invaluable source of data for research in sentiment analysis. With data from social media, sentiment analysis can show the public sentiment towards current topics of public discourse. Twitter is one of the largest of such social media platforms and a prominent source of data for sentiment research (Pak and Paroubek, 2010; Wang et al., 2011; Rajadesingan and Liu, 2014). In this paper, we describe the components and results of a system for English"
S17-2111,S16-1010,0,0.174975,"Missing"
S17-2111,S16-1001,0,0.0580891,"classification where tweets are classified on sentiment towards a given topic on a twoway scale: Negative and Positive (henceforth, −1, +1). Subtask C is the same topic-based task as B, except that it uses a five-point sentiment scale (−2, −1, 0, +1, +2), where −2 is very negative and +2 is very positive. Both subtasks D and E are tweet quantification tasks based on subtasks B and C, respectively. In both D and E, given the same datasets from B and C, the distribution of the tweets for each topic across each label of the given scales is estimated. This task is a rerun of SemEval-2016 Task 4 (Nakov et al., 2016), with some changes. For this task, user profile information of the author of each tweet were made available. Also, this task included an Arabic language version. Our system works on English but is submitted as part of the OMAM (Opinion Mining for Arabic and More) team that also submitted a system that analyzes sentiment in Arabic (Baly et al., 2017). We describe a supervised system that uses optimized Conditional Random Fields and lexical features to predict the sentiment of a tweet. The system was submitted to the English version of all subtasks in SemEval-2017 Task 4. 1 Shared Task Descript"
S17-2111,pak-paroubek-2010-twitter,0,0.0592368,"on a specific topic. This branch of sentiment analysis has been further explored under the term Stance Detection (Faulkner, 2014; Anand et al., 2011). With the rapid increase in different forms of online expression like reviews, political criticism, ratings and punditry, social media has become an invaluable source of data for research in sentiment analysis. With data from social media, sentiment analysis can show the public sentiment towards current topics of public discourse. Twitter is one of the largest of such social media platforms and a prominent source of data for sentiment research (Pak and Paroubek, 2010; Wang et al., 2011; Rajadesingan and Liu, 2014). In this paper, we describe the components and results of a system for English sentiment analysis with which participated in an international shared task on sentiment analysis for Twitter data. 3 Approach For all subtasks, we used the same setup (process and system). We used CRF++ (Kudo, 2005), which is an implementation of Conditional Random Fields (CRF), as the underlying machine learning component. We were inspired by the work of Yang et al. (2007) who used CRFs to determine sentiment of web blogs, training at the sentence level and classifyi"
S17-2111,S17-2088,0,0.100801,"Missing"
W00-0207,dorr-etal-1998-thematic,1,0.387978,"Missing"
W00-0207,A97-1021,0,0.017779,": Lexical Conceptual Structure (LCS), and the Abstract Meaning Representations used at USC/ISI (Langkilde and Knight, 1998a). 2 (1) (act_on l o c (* t h i n g 1) (* t h i n g 2) ((* [on] 23) l o c (*head*) ( t h i n g 24)) ( c u t + i n g l y 26) (down+/m)) Lexical Conceptual Structure Lexical Conceptual Structure is a compositional abstraction with language-independent properties that transcend structural idiosyncrasies (Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996). This representation has been used as the interlingua of several projects such as UNITRAN (Dorr et al., 1993) and MILT (Dorr, 1997). An LCS is adirected graph with a root. Each node is associated with certain information, including a type, a primitive and a field. The type of an LCS node is one of Event, State, Path, Manner, Property or Thing, loosely correlated with verbs prepositions, adverbs, adjectives and nouns. Within each of these The top node in the. RLCS has the structural primitive ACT_ON in the locational field. Its subject is a star-marked LCS, meaning a subordinate RLCS needs to be filled in here to form a complete event. It also has the restriction that the filler LCS be of the type thing. The number &quot;1&quot; in"
W00-0207,P98-1116,0,0.644006,"e translation and cross-language processing. Such representations are becoming fairly popular, yet there are widely different views about what these languages should be composed of, varying from purely conceptual knowledge-representations, having little to do with the structure of language, to very syntactic representations, maintaining most of the idiosyncrasies of the source languages. In our generation system we make use of resources associated with two different (kinds of) interlingua structures: Lexical Conceptual Structure (LCS), and the Abstract Meaning Representations used at USC/ISI (Langkilde and Knight, 1998a). 2 (1) (act_on l o c (* t h i n g 1) (* t h i n g 2) ((* [on] 23) l o c (*head*) ( t h i n g 24)) ( c u t + i n g l y 26) (down+/m)) Lexical Conceptual Structure Lexical Conceptual Structure is a compositional abstraction with language-independent properties that transcend structural idiosyncrasies (Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996). This representation has been used as the interlingua of several projects such as UNITRAN (Dorr et al., 1993) and MILT (Dorr, 1997). An LCS is adirected graph with a root. Each node is associated with certain information, including a type, a"
W00-0207,W98-1426,0,0.532831,"e translation and cross-language processing. Such representations are becoming fairly popular, yet there are widely different views about what these languages should be composed of, varying from purely conceptual knowledge-representations, having little to do with the structure of language, to very syntactic representations, maintaining most of the idiosyncrasies of the source languages. In our generation system we make use of resources associated with two different (kinds of) interlingua structures: Lexical Conceptual Structure (LCS), and the Abstract Meaning Representations used at USC/ISI (Langkilde and Knight, 1998a). 2 (1) (act_on l o c (* t h i n g 1) (* t h i n g 2) ((* [on] 23) l o c (*head*) ( t h i n g 24)) ( c u t + i n g l y 26) (down+/m)) Lexical Conceptual Structure Lexical Conceptual Structure is a compositional abstraction with language-independent properties that transcend structural idiosyncrasies (Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996). This representation has been used as the interlingua of several projects such as UNITRAN (Dorr et al., 1993) and MILT (Dorr, 1997). An LCS is adirected graph with a root. Each node is associated with certain information, including a type, a"
W00-0207,C98-1112,0,\N,Missing
W04-2709,P98-1013,0,0.473703,"dependency parser (details in section 6) and is a useful starting point for semantic annotation at IL1, since it allows annotators to see how textual units relate syntactically when making semantic judgments. 4.1.3 IL2 IL2 is intended to be an interlingua, a representation of meaning that is reasonably independent of language. IL2 is intended to capture similarities in meaning across languages and across different lexical/syntactic realizations within a language. For example, IL2 is expected to normalize over conversives (e.g. X bought a book from Y vs. Y sold a book to X) (as does FrameNet (Baker et al 1998)) and non-literal language usage (e.g. X started its business vs. X opened its doors to customers). The exact definition of IL2 will be the major research contribution of this project. 4.2 The Omega Ontology In progressing from IL0 to IL1, annotators have to select semantic terms (concepts) to represent the nouns, verbs, adjectives, and adverbs present in each sentence. These terms are represented in the 110,000-node ontology Omega (Philpot et al., 2003), under construction at ISI. Omega has been built semi-automatically from a variety of sources, including Princeton's WordNet (Fellbaum, 1998)"
W04-2709,J96-2004,0,0.0756983,"Missing"
W04-2709,2003.mtsummit-eval.3,1,0.726095,"al content, modality, speech acts, etc. At the same time, while incorporating these items, vagueness and redundancy must be eliminated from the annotation language. Many inter-event relations would need to be captured such as entity reference, time reference, place reference, causal relationships, associative relationships, etc. Finally, to incorporate these, crosssentence phenomena remain a challenge. From an MT perspective, issues include evaluating the consistency in the use of an annotation language given that any source text can result in multiple, different, legitimate translations (see Farwell and Helmreich, 2003) for discussion of evaluation in this light. Along these lines, there is the problem of annotating texts for translation without including in the annotations inferences from the source text. 9 Conclusions This is a radically different annotation project from those that have focused on morphology, syntax or even certain types of semantic content (e.g., for word sense disambiguation competitions). It is most similar to PropBank (Kingsbury et al 2002) and FrameNet (Baker et al 1998). However, it is novel in its emphasis on: (1) a more abstract level of mark-up (interpretation); (2) the assignment"
W04-2709,P03-1001,1,0.790541,"sentence. These terms are represented in the 110,000-node ontology Omega (Philpot et al., 2003), under construction at ISI. Omega has been built semi-automatically from a variety of sources, including Princeton's WordNet (Fellbaum, 1998), NMSU’s Mikrokosmos (Mahesh and Nirenburg, 1995), ISI's Upper Model (Bateman et al., 1989) and ISI's SENSUS (Knight and Luk, 1994). After the uppermost region of Omega was created by hand, these various resources’ contents were incorporated and, to some extent, reconciled. After that, several million instances of people, locations, and other facts were added (Fleischman et al., 2003). The ontology, which has been used in several projects in recent years (Hovy et al., 2001), can be browsed using the DINO browser at http://blombos.isi.edu:8000/dino; this browser forms a part of the annotation environment. Omega remains under continued development and extension. 4.1.2 IL1 IL1 is an intermediate semantic representation. It associates semantic concepts with lexical units like nouns, adjectives, adverbs and verbs (details of the ontology in section 4.2). It also replaces the syntactic relations in IL0, like subject and object, with thematic roles, like agent, theme and goal (de"
W04-2709,C18-2019,0,0.0664532,"Missing"
W04-2709,A97-1011,0,0.0452745,"first present the annotation process and tools used with it as well as the annotation manuals. Finally, setup issues relating to negotiating multi-site annotations are discussed. 6.1 Annotation process The annotation process was identical for each text. For the initial testing period, only English texts were annotated, and the process described here is for English text. The process for non-English texts will be, mutatis mutandis, the same. Each sentence of the text is parsed into a dependency tree structure. For English texts, these trees were first provided by the Connexor parser at UMIACS (Tapanainen and Jarvinen, 1997), and then corrected by one of the team PIs. For the initial testing period, annotators were not permitted to alter these structures. Already at this stage, some of the lexical items are replaced by features (e.g., tense), morphological forms are replaced by features on the citation form, and certain constructions are regularized (e.g., passive) and empty arguments inserted. It is this dependency structure that is loaded into the annotation tool and which each annotator then marks up. The annotator was instructed to annotate all nouns, verbs, adjectives, and adverbs. This involves annotating e"
W04-2709,1994.amta-1.25,0,0.0933693,"Missing"
W04-2709,C98-1013,0,\N,Missing
W05-0703,J94-1003,0,\N,Missing
W05-0703,C88-1064,0,\N,Missing
W05-0703,E87-1002,0,\N,Missing
W05-0703,J00-1006,1,\N,Missing
W05-0703,W98-1007,0,\N,Missing
W08-0307,W05-0909,0,0.0607395,"alls out of the projection of chunk c1 ([t4 , t4 ]). A further refinement can be done using the chunks of the target side. The same technique is applied by switching the role of source and target words/chunks in the algorithm described above and using the output of the basic source-based refinement (described above) as the high-recall alignment set, i.e., instead of Union. We use the standard four-reference NIST MTEval data sets for the years 2003, 2004 and 2005 (henceforth MT03, MT04 and MT05, respectively) for testing and the 2002 data set for tuning.6 BLEU4 (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and multiple-reference Word Error Rate scores are reported. SMT decoding is done using MARIE,7 a freely available N -gram-based decoder implementing a beam search strategy with distortion/reordering capabilities (Crego and Mari˜no, 2007a). Optimization is done with an in-house implementation of the SIMPLEX (Nelder and Mead, 1965) algorithm. 7 Evaluation 7.2 7.1 In this section we assess the accuracy results of the techniques introduced in this paper for alignment refinement and word reordering. Experimental Framework All of the training data used here is available from the Linguistic Data Con"
W08-0307,J93-2003,0,0.0122549,"h precision and high recall alignment sets, respectively. We will study the effect of various initial alignment sets (such as grow-diag-final instead of Union) in the future. The method is based on the fact that linguistic phrases (chunks), like raw words, have translation correspondences and can therefore be aligned. We use chunk information to reduce the number of allowed alignments for a given word. The simple idea that words in a source chunk are typically aligned to words in a single possible target chunk is used to discard alignments which link words from 2 We use IBM-1 to IBM-5 models (Brown et al., 1993) implemented with GIZA++ (Och and Ney, 2003). 57 Figure 4: Chunk projection: solid link are Intersection links and all links (solid and dashed) are Union links. We outline the algorithm next. The method can be decomposed in two steps. In the first step, using the Intersection set of alignments and source-side chunks, each chunk is projected into the target side. Figure 4 shows an example of word alignment refinement. The projection c′k of the chunk ck is composed of the sequence of consecutive target words [tlef t , tright ] which can be determined as follows: • All target words tj contained i"
W08-0307,P05-1066,0,0.215248,"ferent language pairs. Structural information offers a greater potential to learn generalizations about relationships between languages than flat-structure models. The need for these ‘mappings’ is specially relevant when handling language pairs with very different word order, such as Arabic-English or Chinese-English. Many alternatives have been proposed on using syntactic information in SMT systems. They range from those aiming at harmonizing (monotonizing) the word order of the considered language pairs by means of a set of linguistically-motivated reordering patterns (Xia and McCord, 2004; Collins et al., 2005) to others considering translation a synchronous parsing process where reorderings introduced in the overall search are syntactically motivated (Galley et al., 2004; Quirk et al., 2005). The work presented here follows the word order harmonization strategy. 53 Proceedings of the Third Workshop on Statistical Machine Translation, pages 53–61, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics Collins et al. (2005) describe a technique for preprocessing German to look more like English syntactically. They used six transformations that are applied on German parsed te"
W08-0307,W06-1609,0,0.107022,"Missing"
W08-0307,P07-2054,1,0.891682,"Missing"
W08-0307,2007.mtsummit-papers.16,1,0.859517,"Missing"
W08-0307,2005.mtsummit-papers.37,1,0.84332,"Missing"
W08-0307,N04-4038,0,0.506991,"hologically complex containing clitics whose translations are represented separately in English and sometimes in a different order. For instance, possessive pronominal enclitics are attached to the noun they modify in Arabic but their translation precedes the English translation of the noun: kitAbu+hu1 ‘book+his → his book’. Other clitics include the definite article Al+ ‘the’, the conjunction w+ ‘and’ and the preposition l+ ‘of/for’, among others. We use the Penn Arabic Treebank tokenization scheme which splits three classes of clitics only. This scheme is compatible with the chunker we use (Diab et al., 2004). Secondly, Arabic verb subjects may be: prodropped (verb conjugated), pre-verbal (SVO), or post-verbal (VSO). The VSO order is quite challenging in the context of translation to English. For small noun phrases (NP), small phrase pairs in a phrase table and some degree of distortion can easily move the verb to follow the NP. But this becomes much less likely with very long NPs that exceed the size of phrases in a phrase table. Finally, Arabic adjectival modifiers typically follow their nouns (with a small exception of some superlative adjectives). For example, rajul Tawiyl (lit. man tall) tran"
W08-0307,N04-1035,0,0.0344264,"e need for these ‘mappings’ is specially relevant when handling language pairs with very different word order, such as Arabic-English or Chinese-English. Many alternatives have been proposed on using syntactic information in SMT systems. They range from those aiming at harmonizing (monotonizing) the word order of the considered language pairs by means of a set of linguistically-motivated reordering patterns (Xia and McCord, 2004; Collins et al., 2005) to others considering translation a synchronous parsing process where reorderings introduced in the overall search are syntactically motivated (Galley et al., 2004; Quirk et al., 2005). The work presented here follows the word order harmonization strategy. 53 Proceedings of the Third Workshop on Statistical Machine Translation, pages 53–61, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics Collins et al. (2005) describe a technique for preprocessing German to look more like English syntactically. They used six transformations that are applied on German parsed text to reorder it before passing it on to a phrase-based system. They show a moderate statistically significant improvement. Our work differs from theirs crucially i"
W08-0307,P05-1071,1,0.806277,"sh newswire text from the English Gigaword corpus (LDC2003T05). Additionally, we use a 5-gram language model computed over the POS tagged English side of the training corpus. Language models are implemented using the SRILM toolkit (Stolcke, 2002). For Arabic tokenization, we use the Arabic TreeBank tokenization scheme: 4-way normalized segments into conjunction, particle, word and pronominal clitic. For POS tagging, we use the collapsed tagset for PATB (24 tags). Tokenization and POS tagging are done using the publicly available Morphological Analysis and Disambiguation of Arabic (MADA) tool (Habash and Rambow, 2005). For chunking Arabic, we use the AMIRA (ASVMT) toolkit (Diab et al., 2004). English preprocessing simply included down-casing, separating punctuation from words and splitting off “’s”. The English side is POS-tagged with TNT(Brants, 2000) and chunked with the freely available OpenNlp5 tools. 3 http://www.ldc.upenn.edu The parallel text includes Arabic News (LDC2004T17), eTIRR (LDC2004E72), English translation of Arabic Treebank (LDC2005E46), and Ummah (LDC2004T18). 5 http://opennlp.sourceforge.net/ 4 58 Results Alignment Refinement Experiment We contrast three systems built from different wor"
W08-0307,J06-4004,1,0.85668,"Missing"
W08-0307,P00-1056,0,0.0539878,"typically producing a large number of noisy (wrong) alignments. The N -gram-based SMT approach suffers highly from the presence of noisy alignments since translation units are extracted out of single alignment-based segmentations of training sentences. Noisy alignments lead to large translation units, which cause a loss of translation information and add to sparseness problems. We propose an alignment refinement method to reduce the number of wrong alignments. The method employs two initial alignment sets: one with high precision, the other with high recall. We use the Intersection and Union (Och and Ney, 2000) of both alignment directions2 as the high precision and high recall alignment sets, respectively. We will study the effect of various initial alignment sets (such as grow-diag-final instead of Union) in the future. The method is based on the fact that linguistic phrases (chunks), like raw words, have translation correspondences and can therefore be aligned. We use chunk information to reduce the number of allowed alignments for a given word. The simple idea that words in a source chunk are typically aligned to words in a single possible target chunk is used to discard alignments which link wo"
W08-0307,J03-1002,0,0.0367108,"espectively. We will study the effect of various initial alignment sets (such as grow-diag-final instead of Union) in the future. The method is based on the fact that linguistic phrases (chunks), like raw words, have translation correspondences and can therefore be aligned. We use chunk information to reduce the number of allowed alignments for a given word. The simple idea that words in a source chunk are typically aligned to words in a single possible target chunk is used to discard alignments which link words from 2 We use IBM-1 to IBM-5 models (Brown et al., 1993) implemented with GIZA++ (Och and Ney, 2003). 57 Figure 4: Chunk projection: solid link are Intersection links and all links (solid and dashed) are Union links. We outline the algorithm next. The method can be decomposed in two steps. In the first step, using the Intersection set of alignments and source-side chunks, each chunk is projected into the target side. Figure 4 shows an example of word alignment refinement. The projection c′k of the chunk ck is composed of the sequence of consecutive target words [tlef t , tright ] which can be determined as follows: • All target words tj contained in Intersection links (si , tj ) with source"
W08-0307,C04-1073,0,0.148179,"word order between different language pairs. Structural information offers a greater potential to learn generalizations about relationships between languages than flat-structure models. The need for these ‘mappings’ is specially relevant when handling language pairs with very different word order, such as Arabic-English or Chinese-English. Many alternatives have been proposed on using syntactic information in SMT systems. They range from those aiming at harmonizing (monotonizing) the word order of the considered language pairs by means of a set of linguistically-motivated reordering patterns (Xia and McCord, 2004; Collins et al., 2005) to others considering translation a synchronous parsing process where reorderings introduced in the overall search are syntactically motivated (Galley et al., 2004; Quirk et al., 2005). The work presented here follows the word order harmonization strategy. 53 Proceedings of the Third Workshop on Statistical Machine Translation, pages 53–61, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics Collins et al. (2005) describe a technique for preprocessing German to look more like English syntactically. They used six transformations that are appl"
W08-0307,W07-0401,0,0.149171,"itional distortion-based reordering). The value of reordering is diminished if the decoder is run in a non-monotonic way. Recently, Crego and Mari˜no (2007b) employ POS tags to automatically learn reorderings in training. They allow all possible learned reorderings to be used to create a lattice that is input to the decoder, which further improves translation accuracy. Similarly, Costa-juss`a and Fonollosa (2006) use statistical word classes to generalize reorderings, which are learned/introduced in a translation process that transforms the source language into the target language word order. Zhang et al. (2007) describe a similar approach using unlexicalized context-free chunk tags (XPs) to learn reordering rules for Chinese-English SMT. Crego and Mari˜no (2007c) extend their previous work using syntax trees (dependency parsing) to learn reorderings on a Chinese-English task. Habash (2007) applies automatically-learned syntactic reordering rules (for Arabic-English SMT) to preprocess the input before passing it to a phrase-based SMT decoder. As in (Zhang et al., 2007), (Costa-juss`a and Fonollosa, 2006) and (Crego and Mari˜no, 2007b), we employ a word graph for a tight coupling between reordering an"
W08-0307,P02-1040,0,\N,Missing
W08-0307,A00-1031,0,\N,Missing
W08-0307,P05-1034,0,\N,Missing
W09-0431,P03-1021,0,0.0347292,"ese LM in our parallel corpus. We use 210M English words in total. 4.4 S Lines 32500 Words (Arabic) 1 Million M L XL 65000 130000 260000 2 Million 4 Million 8 Million Table 3: Training Data Size We use two other data sets (1K lines each) for tuning and testing. Each sentence in these sets has only one reference. Tuning and testing data sets are the same across all experiments and systems. In all our experiments, we decode using Pharaoh (Koehn, 2004) with a distortion limit of 4 and a maximum phrase length of 7. Tuning is done for each experimental condition using Och’s Minimum Error Training (Och, 2003). Phrase Pivoting MT System The phrase pivoting system (A-p-C) extracts a new Arabic to Chinese phrase table using the Arabic-English phrase table and the EnglishChinese phrase table. We consider a Chinese phrase a translation of an Arabic phrase only if some English phrase can bridge the two. We use the following formulae to compute the lexical and phrase probabilities in the new phrase table in a similar manner to Utiyama and Isahara (2007). Here, φ is the lexical probability and Note that for each set of experiments with the same data size, we draw Chinese, Arabic and English from the same"
W09-0431,P06-1001,1,0.758945,"vot language: sentence pivoting and phrase-table pivoting. Our results show that using English as a pivot in either approach outperforms direct translation from Arabic to Chinese. Our best result is the phrase-pivot system which scores higher than direct translation by 1.1 BLEU points. An error analysis of our best system shows that we successfully handle many complex Arabic-Chinese syntactic variations. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 1 Introduction Arabic and Chinese are two languages with a very large global presence; however, there has not been, to our knowledge, any work on MT for this pair. Given the cost involved in creating parallel corpora for Arabic and Ch"
W09-0431,P02-1040,0,0.0798234,", we draw Chinese, Arabic and English from the same chunk of three way parallel corpus. For example, in S size experiments, the two phrase tables used to build a new table in the phrase-pivoting approach are extracted respectively from the A-E and E-C systems built in the sentence-pivoting approach with size S corpora. pw is the phrase probability. 5.1 φ &apos;(a |c) = ∑ φ (a |e)φ (e |c) Direct System Results Table 4 shows the results of the direct translation system A-C. It also includes the result for A-E and E-C direct translation. As expected, as we double the size of the data, the BLEU score (Papineni et al., 2002) increases. However, the rate of increase is not always consistent. In particular, the M and L conditions vary highly in A-E compared to A-C. This is odd especially given that we are comparing the same set of data from the three parallel corpora. We speculate that this may have to do with an oddity in that portion of the data set that may have a different quality than the rest. We see the effect of this drop in A-E in the next section. BLEU is measured on English case-insensitively. BLEU is measured on Chinese using segmented words not characters. e φ &apos;(c |a) = ∑ φ (c |e)φ (e |a ) e pw &apos;(a |c)"
W09-0431,W02-2026,0,0.0492515,"rget) are very different and from completely unrelated families. We focus our experiments on a trilingual parallel corpus to keep all conditions experimentally clean. Our results show that using English as a pivot language for translating Arabic to Chinese actually outperforms direct translation. We believe this may be a result of English being a sort of middle ground between Arabic and Chinese in terms of different linguistic features and, in particular, word order. Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word alignment. Schafer and Yarowsky (2002) induced translation lexicons for languages without common parallel corpora using a bridge language that is related to the target languages. Simard (1999) described a sentence aligner that makes simultaneous decisions in a trilingual parallel text. Kumar et al. (2007) improved Arabic-English MT by using available parallel data in other languages. Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. Filali and Bilmes (2005) improved word alignment by leveraging multilingual parallel translations. Most related to our work on p"
W09-0431,W99-0602,0,0.04298,"ur results show that using English as a pivot language for translating Arabic to Chinese actually outperforms direct translation. We believe this may be a result of English being a sort of middle ground between Arabic and Chinese in terms of different linguistic features and, in particular, word order. Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word alignment. Schafer and Yarowsky (2002) induced translation lexicons for languages without common parallel corpora using a bridge language that is related to the target languages. Simard (1999) described a sentence aligner that makes simultaneous decisions in a trilingual parallel text. Kumar et al. (2007) improved Arabic-English MT by using available parallel data in other languages. Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. Filali and Bilmes (2005) improved word alignment by leveraging multilingual parallel translations. Most related to our work on pivoting are the following: Utiyama and Isahara (2007) studied 1 http://www.nist.gov/speech/tests/mt/2008/doc/ Proceedings of the Fourth Workshop on Statis"
W09-0431,W07-0728,0,0.0696421,"Missing"
W09-0431,N07-1061,0,0.680816,"ns for languages without common parallel corpora using a bridge language that is related to the target languages. Simard (1999) described a sentence aligner that makes simultaneous decisions in a trilingual parallel text. Kumar et al. (2007) improved Arabic-English MT by using available parallel data in other languages. Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. Filali and Bilmes (2005) improved word alignment by leveraging multilingual parallel translations. Most related to our work on pivoting are the following: Utiyama and Isahara (2007) studied 1 http://www.nist.gov/speech/tests/mt/2008/doc/ Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 173–181, c Athens, Greece, 30 March – 31 March 2009. 2009 Association for Computational Linguistics 173 can be made out of one, two or more characters. However, words are written without separating spaces. Word segmentation is a major challenge for processing Chinese (Wu, 1998). sentence and phrase pivoting strategies using three European languages (Spanish, French and German). Their results showed that pivoting does not work as well as direct translation. Wu a"
W09-0431,D07-1077,0,0.0121247,"ract We present a comparison of two approaches for Arabic-Chinese machine translation using English as a pivot language: sentence pivoting and phrase-table pivoting. Our results show that using English as a pivot in either approach outperforms direct translation from Arabic to Chinese. Our best result is the phrase-pivot system which scores higher than direct translation by 1.1 BLEU points. An error analysis of our best system shows that we successfully handle many complex Arabic-Chinese syntactic variations. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 1 Introduction Arabic and Chinese are two languages with a very large global presence; however, there has not been, to our"
W09-0431,P07-1108,0,0.225407,"007) studied 1 http://www.nist.gov/speech/tests/mt/2008/doc/ Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 173–181, c Athens, Greece, 30 March – 31 March 2009. 2009 Association for Computational Linguistics 173 can be made out of one, two or more characters. However, words are written without separating spaces. Word segmentation is a major challenge for processing Chinese (Wu, 1998). sentence and phrase pivoting strategies using three European languages (Spanish, French and German). Their results showed that pivoting does not work as well as direct translation. Wu and Wang (2007) focused on phrase pivoting. They proposed an interpolated scheme that employs two phrase tables: one extracted from a small amount of direct parallel data; and the other extracted from large amounts of indirect data with a third pivoting language. They compared results for different European language as well as Chinese-Japanese translation using English as a pivoting language. Their results show that simple pivoting does not improve over direct MT; however, extending the direct MT system with phrases learned through pivoting helps. Babych et al. (2007) compared two methods for translating int"
W09-0431,2007.mtsummit-papers.69,0,0.0329212,"-pivot system which scores higher than direct translation by 1.1 BLEU points. An error analysis of our best system shows that we successfully handle many complex Arabic-Chinese syntactic variations. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 1 Introduction Arabic and Chinese are two languages with a very large global presence; however, there has not been, to our knowledge, any work on MT for this pair. Given the cost involved in creating parallel corpora for Arabic and Chinese and given that there are lots of available resources (in particular parallel corpora) for Arabic and English and for Chinese and English, we are interested in exploring the role English might serv"
W09-0431,P06-1067,0,0.0103709,"ivoting and phrase-table pivoting. Our results show that using English as a pivot in either approach outperforms direct translation from Arabic to Chinese. Our best result is the phrase-pivot system which scores higher than direct translation by 1.1 BLEU points. An error analysis of our best system shows that we successfully handle many complex Arabic-Chinese syntactic variations. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 1 Introduction Arabic and Chinese are two languages with a very large global presence; however, there has not been, to our knowledge, any work on MT for this pair. Given the cost involved in creating parallel corpora for Arabic and Chinese and given that there are"
W09-0431,2007.mtsummit-papers.5,0,0.0334066,"es not work as well as direct translation. Wu and Wang (2007) focused on phrase pivoting. They proposed an interpolated scheme that employs two phrase tables: one extracted from a small amount of direct parallel data; and the other extracted from large amounts of indirect data with a third pivoting language. They compared results for different European language as well as Chinese-Japanese translation using English as a pivoting language. Their results show that simple pivoting does not improve over direct MT; however, extending the direct MT system with phrases learned through pivoting helps. Babych et al. (2007) compared two methods for translating into English from Ukrainian: direct Ukrainian-English MT versus translation via a cognate language, Russian. Their comparison showed that it is possible to achieve better translation quality via pivoting. English uses the Roman alphabet and its words are written with separating white spaces. English orthography is much closer to Arabic than it is to Chinese. 3.2 Arabic is a morphologically rich language with a large set of morphological features such person, number, gender, voice, aspect, mood, case, and state. Arabic features are realized using both conca"
W09-0431,2007.mtsummit-papers.11,0,0.0126301,"hes for Arabic-Chinese machine translation using English as a pivot language: sentence pivoting and phrase-table pivoting. Our results show that using English as a pivot in either approach outperforms direct translation from Arabic to Chinese. Our best result is the phrase-pivot system which scores higher than direct translation by 1.1 BLEU points. An error analysis of our best system shows that we successfully handle many complex Arabic-Chinese syntactic variations. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 1 Introduction Arabic and Chinese are two languages with a very large global presence; however, there has not been, to our knowledge, any work on MT for this pair. Give"
W09-0431,2007.mtsummit-papers.16,0,0.0378068,"omparison of two approaches for Arabic-Chinese machine translation using English as a pivot language: sentence pivoting and phrase-table pivoting. Our results show that using English as a pivot in either approach outperforms direct translation from Arabic to Chinese. Our best result is the phrase-pivot system which scores higher than direct translation by 1.1 BLEU points. An error analysis of our best system shows that we successfully handle many complex Arabic-Chinese syntactic variations. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 1 Introduction Arabic and Chinese are two languages with a very large global presence; however, there has not been, to our knowledge, any work on"
W09-0431,2007.mtsummit-papers.29,1,0.863376,"Missing"
W09-0431,2007.mtsummit-papers.35,0,0.0356172,"o Chinese. Our best result is the phrase-pivot system which scores higher than direct translation by 1.1 BLEU points. An error analysis of our best system shows that we successfully handle many complex Arabic-Chinese syntactic variations. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 1 Introduction Arabic and Chinese are two languages with a very large global presence; however, there has not been, to our knowledge, any work on MT for this pair. Given the cost involved in creating parallel corpora for Arabic and Chinese and given that there are lots of available resources (in particular parallel corpora) for Arabic and English and for Chinese and English, we are interested in ex"
W09-0431,koen-2004-pharaoh,0,0.184924,"pect, mood, case, and state. Arabic features are realized using both concatenative (affixes and stems) and templatic (root and patterns) morphology with a variety of morphological, phonological and orthographic adjustments. In addition, Arabic has a set of very common clitics that are written attached to the word, e.g., the conjunction + وw+ ‘and’, the preposition + بb+2 ‘with/in’, the definite article + الAl+ ‘the’ and a range of pronominal clitics that can attach to nouns (as possessives) or verbs and prepositions (as objects). In this paper we use a standard phrase-based MT approach (Koehn, 2004) that is in the same spirit of most statistical MT nowadays. We believe that we are the first to explore the ArabicChinese language pair in MT. We differ from previous pivoting research in showing that pivoting can outperform direct translation even when the source, target and pivot languages are all linguistically unrelated. In stark contrast to Arabic, Chinese is an isolating language with no morphology to talk of. However, what Chinese lacks in morphology it replaces with a complex system of nominal quantifiers and verbal aspects. For example, in Figure 1 (at the end of this paper), Chinese"
W09-0431,D07-1005,0,0.0179225,"s direct translation. We believe this may be a result of English being a sort of middle ground between Arabic and Chinese in terms of different linguistic features and, in particular, word order. Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word alignment. Schafer and Yarowsky (2002) induced translation lexicons for languages without common parallel corpora using a bridge language that is related to the target languages. Simard (1999) described a sentence aligner that makes simultaneous decisions in a trilingual parallel text. Kumar et al. (2007) improved Arabic-English MT by using available parallel data in other languages. Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. Filali and Bilmes (2005) improved word alignment by leveraging multilingual parallel translations. Most related to our work on pivoting are the following: Utiyama and Isahara (2007) studied 1 http://www.nist.gov/speech/tests/mt/2008/doc/ Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 173–181, c Athens, Greece, 30 March – 31 March 2009. 2009 Association for Comput"
W09-0431,N04-4015,0,0.0203407,"Missing"
W09-0431,N06-1003,0,\N,Missing
W09-0431,J03-1002,0,\N,Missing
W09-0431,zhang-etal-2004-interpreting,0,\N,Missing
W09-0431,D08-1076,0,\N,Missing
W09-0807,N09-1045,1,0.812703,"Missing"
W09-0809,N03-1017,0,0.353778,"evaluate and discuss the results of our English-Arabic MT system. We investigate syntactic reordering within an English to Arabic translation task. We extend a pre-translation syntactic reordering approach developed on a close language pair (English-Danish) to the distant language pair, English-Arabic. We achieve significant improvements in translation quality over related approaches, measured by manual as well as automatic evaluations. These results prove the viability of this approach for distant languages. 1 Introduction The emergence of phrase-based statistical machine translation (PSMT) (Koehn et al., 2003a) has been one of the major developments in statistical approaches to translation. Allowing translation of word sequences (phrases) instead of single words provides PSMT with a high degree of robustness in word selection and in local-word reordering. Recent developments have shown that improvements in PSMT quality are possible using syntax. One such development is the pretranslation reordering approach, which adjusts the source sentence to resemble target-language word order prior to translation. This is typically done using rules that are either manually created or automatically learned from"
W09-0809,2005.iwslt-1.8,0,0.0127947,"rdering rules from the IBM Arabic-English aligned corpus (IBMAC) (Ittycheriah and Roukos, 2005). Of its total 13.9K sentence pairs, we only use 8.8K sentences because the rest of the corpus uses different normalizations for numerals that make the two sets incompatible. 6.6K of the sentences (179K English and 146K Arabic words) are used to learn rule, while the rest are used for development purposes. In addition to the manual alignment supplied with these data, we create an automatic word alignment for them using GIZA++ (Och and Ney, 2003) and the grow-diagfinal (GDF) symmetrization algorithm (Koehn et al., 2005). This was done together with the data used to train the MT system. The English side is parsed using a state-of-the-art statistical English parser (Charniak, 2000). Two rule sets are learned based on the manual alignments (MAN) and the automatic alignments (GDF). The MT system is trained on a corpus consisting of 126K sentences with 4.2M English and 3.3M Arabic words in simple tokenization scheme. The domain is newswire (LDCNEWS) taken from Arabic News (LDC2004T17), eTIRR (LDC2004E72), English translation of Arabic Treebank (LDC2005E46), and Ummah (LDC2004T18). Although there are additional co"
W09-0809,koen-2004-pharaoh,0,0.0212448,"inear PSMT model as an additional parameter by simple addition. 5 5.1 The reordering approach Similar to Elming (2008), the integration of the rule-based reordering in our PSMT system is carried out in two separate stages: 1. Reordering the source sentence to assimilate the word order of the target language. The PSMT system 2. Weighting of the target word order according to the rules. Our baseline is the PSMT system used for the 2006 NAACL SMT workshop (Koehn and Monz, 2006) with phrase length 3 and a trigram language model (Stolcke, 2002). The decoder used for the baseline system is Pharaoh (Koehn, 2004) with its distance-penalizing reordering model. Since Pharaoh does not support word lattice input, we use our own decoder for the experiments. Except for the reordering model, it uses the same knowledge sources as Pharaoh, i.e. a bidirectional phrase translation model, a lexical weight model, phrase and word penalties, and a target language model. Its behavior is comparable to Pharaoh when doing monotone decoding. The search algorithm of our decoder is similar to the RG graph decoder of (Zens et al., 2002). It expects a word lattice as input. Figure 3 shows the word lattice for the example in"
W09-0809,N04-4015,0,0.131631,"ish to Arabic and we are discouraged by recent results indicating Arabic parsing is not at a stage that makes it usable in MT (Habash et al., 2006). While several recent authors using a pre-translation (sourceside) reordering approach have achieved positive results, it has been difficult to integrate syntactic Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages, pages 69–77, c Athens, Greece, 31 March, 2009. 2009 Association for Computational Linguistics 69 gest that some degree of tokenization is helpful when translating from Arabic (Habash and Sadat, 2006; Lee, 2004). However, when translating into a morphologically rich language, target tokenization means that the translation process is broken into multiple steps (Badr et al., 2008). For our experiments, Arabic was not segmented apart from simple punctuation tokenization. This low level of segmentation was maintained in order to agree with the segmentation provided in the manually aligned corpus we used to learn our rules (section 6.1). We found no simple means for transferring the manual alignments to more segmented language. We expect that better performance would be achieved by introducing more Arabic"
W09-0809,P07-1091,0,0.0729467,"ves phrases follow (or precede while hyphenated). For example, a tall man translates as ÉK ñ£ Ég. P rjl information while retaining the strengths of the statistical approach. In some studies, reordering decisions are done “deterministically” by supplying the decoder with a canonical word order (Xia and McCord, 2004; Collins et al., 2005; Wang et al., 2007; Habash, 2007). These reordering rules are either manually specified or automatically learned from alignments; and they are always placed outside the actual PSMT system. By contrast, other studies (Crego and Mariño, 2007; Zhang et al., 2007; Li et al., 2007; Elming, 2008) are more in the spirit of PSMT, in that multiple reorderings are presented to the PSMT system as (possibly weighted) options that are allowed to contribute alongside other parameters. Specifically, we follow the pre-translation reordering approach of Elming (2008). This approach has been proven to remedy shortcomings of other pre-translation reordering approaches by reordering the input word sequence, but scoring the output word sequence. Elming (2008) only examined the approach within English – Danish, a language pair that displays little reordering. By contrast, in this paper"
W09-0809,2006.amta-papers.11,0,0.0572048,"Missing"
W09-0809,J03-1002,0,0.00287452,"rase translation it prefers without reordering cost. Data We learn the reordering rules from the IBM Arabic-English aligned corpus (IBMAC) (Ittycheriah and Roukos, 2005). Of its total 13.9K sentence pairs, we only use 8.8K sentences because the rest of the corpus uses different normalizations for numerals that make the two sets incompatible. 6.6K of the sentences (179K English and 146K Arabic words) are used to learn rule, while the rest are used for development purposes. In addition to the manual alignment supplied with these data, we create an automatic word alignment for them using GIZA++ (Och and Ney, 2003) and the grow-diagfinal (GDF) symmetrization algorithm (Koehn et al., 2005). This was done together with the data used to train the MT system. The English side is parsed using a state-of-the-art statistical English parser (Charniak, 2000). Two rule sets are learned based on the manual alignments (MAN) and the automatic alignments (GDF). The MT system is trained on a corpus consisting of 126K sentences with 4.2M English and 3.3M Arabic words in simple tokenization scheme. The domain is newswire (LDCNEWS) taken from Arabic News (LDC2004T17), eTIRR (LDC2004E72), English translation of Arabic Tree"
W09-0809,N07-2037,0,0.163126,"scoring the output word sequence. Elming (2008) only examined the approach within English – Danish, a language pair that displays little reordering. By contrast, in this paper, we target the more demanding reordering task of translating between two distant languages, English and Arabic. While much work has been done on Arabic to English MT (Habash and Sadat, 2006; Lee, 2004) mostly focusing on addressing the problems caused by the rich morphology of Arabic, we handle the less described translation direction: English to Arabic. Recently, there are some new publications on English to Arabic MT. Sarikaya and Deng (2007) use joint morphological-lexical language models to re-rank the output of English dialectal-Arabic MT, and Badr et al. (2008) report results on the value of the morphological decomposition of Arabic during training and describe different techniques for re-composition of Arabic in the output. We differ from the previous efforts targeting Arabic in that (1) we do not address morphology issues through segmentation (more on this in section 3) and (2) we focus on utilizing syntactic knowledge to address the reordering challenges of this translation direction. 3 Arabic Syntactic Issues Arabic is a m"
W09-0809,D07-1077,0,0.0490336,"ifiers typically follow their nouns with the exception of some superlative adjectives. However, English adjectival modifiers can follow or precede their nouns depending on the size of the adjectival phrase: single word adjectives precede but multi-word adjectives phrases follow (or precede while hyphenated). For example, a tall man translates as ÉK ñ£ Ég. P rjl information while retaining the strengths of the statistical approach. In some studies, reordering decisions are done “deterministically” by supplying the decoder with a canonical word order (Xia and McCord, 2004; Collins et al., 2005; Wang et al., 2007; Habash, 2007). These reordering rules are either manually specified or automatically learned from alignments; and they are always placed outside the actual PSMT system. By contrast, other studies (Crego and Mariño, 2007; Zhang et al., 2007; Li et al., 2007; Elming, 2008) are more in the spirit of PSMT, in that multiple reorderings are presented to the PSMT system as (possibly weighted) options that are allowed to contribute alongside other parameters. Specifically, we follow the pre-translation reordering approach of Elming (2008). This approach has been proven to remedy shortcomings of othe"
W09-0809,C04-1073,0,0.0742509,"spectively.2 Secondly, Arabic adjectival modifiers typically follow their nouns with the exception of some superlative adjectives. However, English adjectival modifiers can follow or precede their nouns depending on the size of the adjectival phrase: single word adjectives precede but multi-word adjectives phrases follow (or precede while hyphenated). For example, a tall man translates as ÉK ñ£ Ég. P rjl information while retaining the strengths of the statistical approach. In some studies, reordering decisions are done “deterministically” by supplying the decoder with a canonical word order (Xia and McCord, 2004; Collins et al., 2005; Wang et al., 2007; Habash, 2007). These reordering rules are either manually specified or automatically learned from alignments; and they are always placed outside the actual PSMT system. By contrast, other studies (Crego and Mariño, 2007; Zhang et al., 2007; Li et al., 2007; Elming, 2008) are more in the spirit of PSMT, in that multiple reorderings are presented to the PSMT system as (possibly weighted) options that are allowed to contribute alongside other parameters. Specifically, we follow the pre-translation reordering approach of Elming (2008). This approach has b"
W09-0809,P01-1067,0,0.0452818,"lar variety of this approach, proposed by Elming (2008), uses a large set of linguistic features to automatically learn reordering rules. The rules are applied nondeterministically; however, phrase-internal wordalignments are used to ensure that the intended reordering does not come undone because of phrase internal reordering (Elming, 2008). This approach 2 Related Work Much work has been done in syntactic reordering for SMT, focusing on both source and targetlanguage syntax. In this paper, we adapt an approach that utilizes source-syntax information as opposed to target-side syntax systems (Yamada and Knight, 2001; Galley et al., 2004). This is because we are translating from English to Arabic and we are discouraged by recent results indicating Arabic parsing is not at a stage that makes it usable in MT (Habash et al., 2006). While several recent authors using a pre-translation (sourceside) reordering approach have achieved positive results, it has been difficult to integrate syntactic Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages, pages 69–77, c Athens, Greece, 31 March, 2009. 2009 Association for Computational Linguistics 69 gest that some degree of tokenizati"
W09-0809,2002.tmi-tutorials.2,0,0.129078,"a trigram language model (Stolcke, 2002). The decoder used for the baseline system is Pharaoh (Koehn, 2004) with its distance-penalizing reordering model. Since Pharaoh does not support word lattice input, we use our own decoder for the experiments. Except for the reordering model, it uses the same knowledge sources as Pharaoh, i.e. a bidirectional phrase translation model, a lexical weight model, phrase and word penalties, and a target language model. Its behavior is comparable to Pharaoh when doing monotone decoding. The search algorithm of our decoder is similar to the RG graph decoder of (Zens et al., 2002). It expects a word lattice as input. Figure 3 shows the word lattice for the example in table 2. In the example used here, we choose to focus on the reordering of adjective and noun. For readability, we do not describe the possibility of reordering the Stage (1) is done in a non-deterministic fashion by generating a word lattice as input. This way, the system has both the original word order, and the reorderings predicted by the rule set. The different paths of the word lattice are merely given as equal suggestions to the decoder. They are in no way individually weighted. Separating stage (2)"
W09-0809,zhang-etal-2004-interpreting,0,0.0753631,"Missing"
W09-0809,2007.iwslt-1.3,0,0.0541018,"t multi-word adjectives phrases follow (or precede while hyphenated). For example, a tall man translates as ÉK ñ£ Ég. P rjl information while retaining the strengths of the statistical approach. In some studies, reordering decisions are done “deterministically” by supplying the decoder with a canonical word order (Xia and McCord, 2004; Collins et al., 2005; Wang et al., 2007; Habash, 2007). These reordering rules are either manually specified or automatically learned from alignments; and they are always placed outside the actual PSMT system. By contrast, other studies (Crego and Mariño, 2007; Zhang et al., 2007; Li et al., 2007; Elming, 2008) are more in the spirit of PSMT, in that multiple reorderings are presented to the PSMT system as (possibly weighted) options that are allowed to contribute alongside other parameters. Specifically, we follow the pre-translation reordering approach of Elming (2008). This approach has been proven to remedy shortcomings of other pre-translation reordering approaches by reordering the input word sequence, but scoring the output word sequence. Elming (2008) only examined the approach within English – Danish, a language pair that displays little reordering. By contra"
W09-0809,P08-2039,0,0.186338,"recent authors using a pre-translation (sourceside) reordering approach have achieved positive results, it has been difficult to integrate syntactic Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages, pages 69–77, c Athens, Greece, 31 March, 2009. 2009 Association for Computational Linguistics 69 gest that some degree of tokenization is helpful when translating from Arabic (Habash and Sadat, 2006; Lee, 2004). However, when translating into a morphologically rich language, target tokenization means that the translation process is broken into multiple steps (Badr et al., 2008). For our experiments, Arabic was not segmented apart from simple punctuation tokenization. This low level of segmentation was maintained in order to agree with the segmentation provided in the manually aligned corpus we used to learn our rules (section 6.1). We found no simple means for transferring the manual alignments to more segmented language. We expect that better performance would be achieved by introducing more Arabic segmentation as reported by Badr et al. (2008).1 As such, and unlike previous work in PSMT translating into Arabic, we focus here on syntax. We plan to investigate diffe"
W09-0809,W07-0718,0,0.0127554,"Results are listed in table 3 along with results on the development set. We report on (a) Pharaoh with no restriction on reordering (Pharaoh Free), (b) Pharaoh with distortion limit 4 (Pharaoh DL4), (c) Pharaoh with monotone decoding (Pharaoh Monotone), and (d) a system provided with a rule reordered word lattice but no (NO) weighting in the spirit of (Crego and Mariño, 2007), (e) the same system but with a source order Diff Set Overall the TO approach seems to be a superior reordering method. To back this observation, 50 sentences of MT04 are manually evaluated by a native speaker of Arabic. Callison-Burch et al. (2007) show that ranking sentences gives higher inter-annotator agreement than scoring adequacy and fluency. We therefore employ this evaluation method, asking the evaluator to rank sentences from four of the systems given the input sentence. Ties are allowed. Table 4 shows the average rat74 MT04 MT05 Decoder choice Phrase internal Phrase external Reject Phrase internal Phrase external Reject NO 20.7 30.1 49.2 21.3 29.5 49.2 SO 0.6 43.0 56.5 0.7 42.9 56.4 TO 21.2 33.1 45.7 21.6 31.8 46.5 are also manually analyzed with regards to reordering. For each reordering in these sentences, the four systems a"
W09-0809,A00-2018,0,0.0610087,"the rest of the corpus uses different normalizations for numerals that make the two sets incompatible. 6.6K of the sentences (179K English and 146K Arabic words) are used to learn rule, while the rest are used for development purposes. In addition to the manual alignment supplied with these data, we create an automatic word alignment for them using GIZA++ (Och and Ney, 2003) and the grow-diagfinal (GDF) symmetrization algorithm (Koehn et al., 2005). This was done together with the data used to train the MT system. The English side is parsed using a state-of-the-art statistical English parser (Charniak, 2000). Two rule sets are learned based on the manual alignments (MAN) and the automatic alignments (GDF). The MT system is trained on a corpus consisting of 126K sentences with 4.2M English and 3.3M Arabic words in simple tokenization scheme. The domain is newswire (LDCNEWS) taken from Arabic News (LDC2004T17), eTIRR (LDC2004E72), English translation of Arabic Treebank (LDC2005E46), and Ummah (LDC2004T18). Although there are additional corpora available, we restricted ourselves to this set to allow for a fast development cycle. We plan to extend the data size in the future. The Arabic language mode"
W09-0809,P05-1033,0,0.230505,"eorderings should be promoted regardless of whether they owe their existence to a syntactic rule or a phrase table entry. This is accomplished by letting the actual scoring of the reordering focus on the target string. 72 Source: Rule: Hypothesis H1 H2 he1 bought2 new3 books4 today5 34→43 Target string Alignment Aštrý jdyd~ ktbA 1+2 3 4 Aštrý ktbA jdyd~ 1+2 4 3 Separating the scoring from the source language reordering also has the advantage that the approach in essence is compatible with other approaches such as a traditional PSMT system (Koehn et al., 2003b) or a hierarchical phrase system (Chiang, 2005). We will, however, not examine this possibility further in the present paper. Table 2: Example of the scoring approach during decoding at source word 4. 6 Evaluation 6.1 The decoder is informed of where a rule has predicted a reordering, how much it costs to do the reordering, and how much it costs to avoid it. This is then checked for each hypothesized target string via a word alignment. The word alignment keeps track of which source position the word in each target position originates from. In order to access this information, each phrase table entry is annotated with its internal word alig"
W09-0809,P05-1066,0,0.135486,"Arabic adjectival modifiers typically follow their nouns with the exception of some superlative adjectives. However, English adjectival modifiers can follow or precede their nouns depending on the size of the adjectival phrase: single word adjectives precede but multi-word adjectives phrases follow (or precede while hyphenated). For example, a tall man translates as ÉK ñ£ Ég. P rjl information while retaining the strengths of the statistical approach. In some studies, reordering decisions are done “deterministically” by supplying the decoder with a canonical word order (Xia and McCord, 2004; Collins et al., 2005; Wang et al., 2007; Habash, 2007). These reordering rules are either manually specified or automatically learned from alignments; and they are always placed outside the actual PSMT system. By contrast, other studies (Crego and Mariño, 2007; Zhang et al., 2007; Li et al., 2007; Elming, 2008) are more in the spirit of PSMT, in that multiple reorderings are presented to the PSMT system as (possibly weighted) options that are allowed to contribute alongside other parameters. Specifically, we follow the pre-translation reordering approach of Elming (2008). This approach has been proven to remedy s"
W09-0809,2007.mtsummit-papers.16,0,0.167609,"rd adjectives precede but multi-word adjectives phrases follow (or precede while hyphenated). For example, a tall man translates as ÉK ñ£ Ég. P rjl information while retaining the strengths of the statistical approach. In some studies, reordering decisions are done “deterministically” by supplying the decoder with a canonical word order (Xia and McCord, 2004; Collins et al., 2005; Wang et al., 2007; Habash, 2007). These reordering rules are either manually specified or automatically learned from alignments; and they are always placed outside the actual PSMT system. By contrast, other studies (Crego and Mariño, 2007; Zhang et al., 2007; Li et al., 2007; Elming, 2008) are more in the spirit of PSMT, in that multiple reorderings are presented to the PSMT system as (possibly weighted) options that are allowed to contribute alongside other parameters. Specifically, we follow the pre-translation reordering approach of Elming (2008). This approach has been proven to remedy shortcomings of other pre-translation reordering approaches by reordering the input word sequence, but scoring the output word sequence. Elming (2008) only examined the approach within English – Danish, a language pair that displays little r"
W09-0809,W08-0406,1,0.895601,"llowing translation of word sequences (phrases) instead of single words provides PSMT with a high degree of robustness in word selection and in local-word reordering. Recent developments have shown that improvements in PSMT quality are possible using syntax. One such development is the pretranslation reordering approach, which adjusts the source sentence to resemble target-language word order prior to translation. This is typically done using rules that are either manually created or automatically learned from word-aligned parallel corpora. One particular variety of this approach, proposed by Elming (2008), uses a large set of linguistic features to automatically learn reordering rules. The rules are applied nondeterministically; however, phrase-internal wordalignments are used to ensure that the intended reordering does not come undone because of phrase internal reordering (Elming, 2008). This approach 2 Related Work Much work has been done in syntactic reordering for SMT, focusing on both source and targetlanguage syntax. In this paper, we adapt an approach that utilizes source-syntax information as opposed to target-side syntax systems (Yamada and Knight, 2001; Galley et al., 2004). This is"
W09-0809,N04-1035,0,0.0271649,"ach, proposed by Elming (2008), uses a large set of linguistic features to automatically learn reordering rules. The rules are applied nondeterministically; however, phrase-internal wordalignments are used to ensure that the intended reordering does not come undone because of phrase internal reordering (Elming, 2008). This approach 2 Related Work Much work has been done in syntactic reordering for SMT, focusing on both source and targetlanguage syntax. In this paper, we adapt an approach that utilizes source-syntax information as opposed to target-side syntax systems (Yamada and Knight, 2001; Galley et al., 2004). This is because we are translating from English to Arabic and we are discouraged by recent results indicating Arabic parsing is not at a stage that makes it usable in MT (Habash et al., 2006). While several recent authors using a pre-translation (sourceside) reordering approach have achieved positive results, it has been difficult to integrate syntactic Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages, pages 69–77, c Athens, Greece, 31 March, 2009. 2009 Association for Computational Linguistics 69 gest that some degree of tokenization is helpful when tra"
W09-0809,N06-2013,1,0.857022,"re translating from English to Arabic and we are discouraged by recent results indicating Arabic parsing is not at a stage that makes it usable in MT (Habash et al., 2006). While several recent authors using a pre-translation (sourceside) reordering approach have achieved positive results, it has been difficult to integrate syntactic Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages, pages 69–77, c Athens, Greece, 31 March, 2009. 2009 Association for Computational Linguistics 69 gest that some degree of tokenization is helpful when translating from Arabic (Habash and Sadat, 2006; Lee, 2004). However, when translating into a morphologically rich language, target tokenization means that the translation process is broken into multiple steps (Badr et al., 2008). For our experiments, Arabic was not segmented apart from simple punctuation tokenization. This low level of segmentation was maintained in order to agree with the segmentation provided in the manually aligned corpus we used to learn our rules (section 6.1). We found no simple means for transferring the manual alignments to more segmented language. We expect that better performance would be achieved by introducing"
W09-0809,2007.mtsummit-papers.29,1,0.889041,"llow their nouns with the exception of some superlative adjectives. However, English adjectival modifiers can follow or precede their nouns depending on the size of the adjectival phrase: single word adjectives precede but multi-word adjectives phrases follow (or precede while hyphenated). For example, a tall man translates as ÉK ñ£ Ég. P rjl information while retaining the strengths of the statistical approach. In some studies, reordering decisions are done “deterministically” by supplying the decoder with a canonical word order (Xia and McCord, 2004; Collins et al., 2005; Wang et al., 2007; Habash, 2007). These reordering rules are either manually specified or automatically learned from alignments; and they are always placed outside the actual PSMT system. By contrast, other studies (Crego and Mariño, 2007; Zhang et al., 2007; Li et al., 2007; Elming, 2008) are more in the spirit of PSMT, in that multiple reorderings are presented to the PSMT system as (possibly weighted) options that are allowed to contribute alongside other parameters. Specifically, we follow the pre-translation reordering approach of Elming (2008). This approach has been proven to remedy shortcomings of other pre-translati"
W09-0809,H05-1012,0,0.019589,"er the reordering is internal (due to a phrase table entry) or external (due to a syntactic rule). Phrase internal reorderings at other points of the sentence, i.e. points that are not covered by a rule, are not judged by the reordering model. Our rule extraction does not learn every possible reordering between the two languages, but only the most general ones. If no rule has an opinion at a certain point in a sentence, the decoder is free to choose the phrase translation it prefers without reordering cost. Data We learn the reordering rules from the IBM Arabic-English aligned corpus (IBMAC) (Ittycheriah and Roukos, 2005). Of its total 13.9K sentence pairs, we only use 8.8K sentences because the rest of the corpus uses different normalizations for numerals that make the two sets incompatible. 6.6K of the sentences (179K English and 146K Arabic words) are used to learn rule, while the rest are used for development purposes. In addition to the manual alignment supplied with these data, we create an automatic word alignment for them using GIZA++ (Och and Ney, 2003) and the grow-diagfinal (GDF) symmetrization algorithm (Koehn et al., 2005). This was done together with the data used to train the MT system. The Engl"
W09-0809,W06-3114,0,0.0256082,"y Ripper on the performance of the individual rules on the training data. These logarithmic probabilities are easily integratable in the log-linear PSMT model as an additional parameter by simple addition. 5 5.1 The reordering approach Similar to Elming (2008), the integration of the rule-based reordering in our PSMT system is carried out in two separate stages: 1. Reordering the source sentence to assimilate the word order of the target language. The PSMT system 2. Weighting of the target word order according to the rules. Our baseline is the PSMT system used for the 2006 NAACL SMT workshop (Koehn and Monz, 2006) with phrase length 3 and a trigram language model (Stolcke, 2002). The decoder used for the baseline system is Pharaoh (Koehn, 2004) with its distance-penalizing reordering model. Since Pharaoh does not support word lattice input, we use our own decoder for the experiments. Except for the reordering model, it uses the same knowledge sources as Pharaoh, i.e. a bidirectional phrase translation model, a lexical weight model, phrase and word penalties, and a target language model. Its behavior is comparable to Pharaoh when doing monotone decoding. The search algorithm of our decoder is similar to"
W09-0809,C08-1027,1,\N,Missing
W09-0809,2006.amta-papers.7,1,\N,Missing
W10-1402,W06-2920,0,0.166177,"Missing"
W10-1402,P99-1065,0,0.536202,"Missing"
W10-1402,H05-1100,0,0.287657,"Missing"
W10-1402,J08-3003,0,0.384489,"Missing"
W10-1402,P05-1071,1,0.203632,"Missing"
W10-1402,P09-2056,1,0.575385,"aspect of syntax, which is often not explicitly modeled in parsing, involves morphological constraints on syntactic structure, such as agreement. In this paper, we explore the role of morphological features in parsing Modern Standard Arabic (MSA). For MSA, the space of possible morphological features is fairly large. We determine which morphological features help and why, and we determine the upper bound for their contribution to parsing quality. We first present the corpus we use (§2), then relevant Arabic linguistic facts (§3); we survey related We use the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). Specifically, we use the portion converted from part 3 of the Penn Arabic Treebank (PATB) (Maamouri et al., 2004) to the CATiB format, which enriches the CATiB dependency trees with full PATB morphological information. CATiB’s dependency representation is based on traditional Arabic grammar and emphasizes syntactic case relations. It has a reduced POS tagset (with six tags only), but a standard set of eight dependency relations: SBJ and OBJ for subject and (direct or indirect) object, respectively, (whether they appear pre- or post-verbally); IDF for the idafa (possessive) relation; MOD for"
W10-1402,P98-1080,0,0.306207,"Missing"
W10-1402,E06-1011,0,0.0595554,"Missing"
W10-1402,C08-1081,0,0.370938,"Missing"
W10-1402,W03-3017,0,0.0667882,"ld vs. predicted POS and morphological feature values for all models; (c) prediction accuracy of each POS tagset and morphological feature; (d) the contribution of numerous morphological features in a controlled fashion; and (e) the contribution of certain feature and POS tagset combinations. All results are reported mainly in terms of labeled attachment accuracy (parent word and the dependency relation to it). Unlabeled attachment accuracy and label accuracy are also given, space permitting. 5.2 Parser For all experiments reported here we used the syntactic dependency parser MaltParser v1.3 (Nivre, 2003; Nivre, 2008; Kübler et al., 2009) – a transition-based parser with an input buffer and a stack, using SVM classifiers to predict the next state in the parse derivation. All experiments were done using the Nivre &quot;eager&quot; algorithm.7 We trained the parser on the training portion of PATB part 3 (Maamouri et al., 2004). We used the same split as in Zitouni et al. (2006) for dev/test, and kept the test unseen during training. There are five default attributes, in the MaltParser terminology, for each token in the text: word ID (ordinal position in the sentence), word form, POS 7 Nivre (2008) report"
W10-1402,J08-4003,0,0.173037,"s, and verbs; and mode for verbs) outperforms other combinations. Our approach is comparable to their work in terms of its systematic exploration of the space of morphological features. We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima’an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic, results have been reported on PATB (Kulick et al., 2006; Diab, 2007), the Prague Dependency Treebank (PADT) (Buchholz and Marsi, 2006; Nivre, 2008) and the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). Besides the work we describe in §3, Nivre (2008) reports experiments on Arabic parsing using his MaltParser (Nivre et al., 2007), trained on the PADT. His results are not directly comparable to ours because of the different treebanks representations and tokenization used, even though all our experiments reported here were performed using the MaltParser. Our results agree with previous published work on Arabic and Hebrew in that marking the definite article is helpful for parsing. However, we go beyond previous work in that we a"
W10-1402,W07-2219,0,0.303941,"Missing"
W10-1402,P06-1073,0,0.233763,"curacy (parent word and the dependency relation to it). Unlabeled attachment accuracy and label accuracy are also given, space permitting. 5.2 Parser For all experiments reported here we used the syntactic dependency parser MaltParser v1.3 (Nivre, 2003; Nivre, 2008; Kübler et al., 2009) – a transition-based parser with an input buffer and a stack, using SVM classifiers to predict the next state in the parse derivation. All experiments were done using the Nivre &quot;eager&quot; algorithm.7 We trained the parser on the training portion of PATB part 3 (Maamouri et al., 2004). We used the same split as in Zitouni et al. (2006) for dev/test, and kept the test unseen during training. There are five default attributes, in the MaltParser terminology, for each token in the text: word ID (ordinal position in the sentence), word form, POS 7 Nivre (2008) reports that non-projective and pseudoprojective algorithms outperform the &quot;eager&quot; projective algorithm in MaltParser; however, our training data did not contain any non-projective dependencies, so there was no point in using these algorithms. The Nivre &quot;standard&quot; algorithm is also reported to do better on Arabic, but in a preliminary experimentation, it did slightly worse"
W10-1402,C98-1077,0,\N,Missing
W10-1402,J08-4010,0,\N,Missing
W11-2127,W05-0909,0,0.828278,"ses), and a corresponding improvement in the percentage of syntactically wellformed subjects under a manual evaluation. The rest of the paper is structured as follows. Section 2 gives a review of research on this topic. Section 3 motivates the approach discussed in Section 4. 227 Proceedings of the 6th Workshop on Statistical Machine Translation, pages 227–236, c Edinburgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics Section 5 presents the results of a set of machine translation experiments using the automatic metrics BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005), and a manual-evaluation of subject integrity. Section 6 discusses our conclusions and future plans. 2 Related Work The general approach pursued in this paper—that of using pre-ordering to improve translation output– has been explored by many researchers. Most work has focused on automatically learning reordering rules (Xia and McCord, 2004; Habash, 2007b; Elming, 2008; Elming and Habash, 2009; Dyer and Resnik, 2010). Xia and McCord (2004) describe an approach for translation from French to English, where context-free constituency reordering rules are acquired automatically using source and t"
W11-2127,W10-1735,0,0.313793,"es is still quite poor. Collins et al. (2005), for example, assume that the parse trees they use are correct. While the state-of-the-art in English parsing is fairly good (though far from perfect), this is not the case in other languages, where parsing shows substantial error rates. Moreover, when attempting to reorder so as to bring the source text more grammatically in line with the target language, a bad parse can be disastrous: moving parts of the sentence that shouldn’t be moved, and introducing more distortion error than it is able to correct. To address the problem of noisy parse data, Bisazza and Federico (2010) identify the subject using a chunker, then fuzzify it, creating a lattice in which the translation system has a choice of several different paths, corresponding to re-orderings of different subject spans. In investigating syntax-based reordering for Arabic specifically, Carpuat et al. (2010) show that a syntax-driven reordering of the training data only for the purpose of alignment improvement leads to a substantial improvement in translation quality, but do not report a corresponding improvement when reordering test data in a similar fashion. Interestingly, Bisazza and Federico (2010) report"
W11-2127,P10-2033,1,0.907361,"attempting to reorder so as to bring the source text more grammatically in line with the target language, a bad parse can be disastrous: moving parts of the sentence that shouldn’t be moved, and introducing more distortion error than it is able to correct. To address the problem of noisy parse data, Bisazza and Federico (2010) identify the subject using a chunker, then fuzzify it, creating a lattice in which the translation system has a choice of several different paths, corresponding to re-orderings of different subject spans. In investigating syntax-based reordering for Arabic specifically, Carpuat et al. (2010) show that a syntax-driven reordering of the training data only for the purpose of alignment improvement leads to a substantial improvement in translation quality, but do not report a corresponding improvement when reordering test data in a similar fashion. Interestingly, Bisazza and Federico (2010) report that fuzzy reordering the test data improves MT output, suggesting that fuzzification may be the mechanism necessary to render reordering on test data useful. To the best of our knowledge, nobody has yet used fuzzification to correct the identified subject span of complete Arabic dependency"
W11-2127,P11-2031,0,0.017868,"and left-attachment cases), it is guaranteed to appear as one path through the lattice. 5 5.1 Evaluation 5-gram language model with modified Kneser-Ney smoothing implemented using the SRILM toolkit (Stolcke, 2002). Feature weights were tuned with MERT (Och, 2003) to maximize BLEU on the NIST MT06 corpus. MERT was done only for the baseline system; these same weights were used for all experiments to control for the effect of MERT instability. In the future, we plan to experiment with approachspecific optimization and to use recent published suggestions on controlling for optimizer instability (Clark et al., 2011). English data was tokenized using simple punctuation-based rules. Arabic data was segmented with to the Arabic Treebank tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological disambiguator and tokenizer (Habash and Rambow, 2005; Habash, 2007a; Roth et al., 2008). The Arabic text was also Alif/Ya normalized (Habash, 2010). MADAproduced Arabic lemmas were used for word alignment. We compare four settings with predicted parses (as opposed to the gold parse experiments discussed in Section 3): • BASE An un-reordered test set; • FORCE A test set which forced reordering on m"
W11-2127,P05-1066,0,0.388507,"Missing"
W11-2127,N10-1128,0,0.0734522,"Missing"
W11-2127,P08-1115,0,0.0186757,"nslations of up to 10 words are extracted in the Moses phrase table. The same baseline phrase table was used in all experiments. The system’s language model was trained both on the English portion of the training corpus and English Gigaword (Graff and Cieri, 2003). We used a 5 All data is available from the Linguistic Data Consortium: http://www.ldc.upenn.edu. 232 • SPAN A test set with fuzzification through optional reordering on matrix verbs and through fuzzification of the subject span according to the algorithm shown in Section 4.2. Each reordering corpus used Moses’ lattice input format (Dyer et al., 2008) (including the baselines, which had only one path). Results are presented in terms of the standard BLEU metric (Papineni et al., 2002), METEOR metric (Banerjee and Lavie, 2005) and a manual evaluation targeting subject span translation correctness. 5.2 Automatic Evaluation Results Table 2 presents the results for the experiments discussed above. Columns three and Four (Prec-1g and Prec-4g) indicate the corresponding 1-gram and 4-gram (sub-BLEU) precision scores, respectively. System BASE FORCE OPT SPAN BLEU Prec-1g Prec-4g METEOR 47.13 81.91 29.52 53.09 47.03 81.78 29.52 53.11 47.42 81.88 30."
W11-2127,W09-0809,1,0.888195,"Missing"
W11-2127,W08-0406,0,0.0449602,"Missing"
W11-2127,2009.mtsummit-caasl.4,0,0.174897,"eeebank (CATiB) (Habash and Roth, 2009). To answer this question, we examined more servation that even VS-ordered matrix verbs in Arabic are sometimes translated monotonically into English (as, for example, in passive constructions). An alternative explanation may be that since the training data itself is not re-ordered, it is plausible that some re-ordering may cause otherwise good possible matches in the phrase table to not match any more. 3.2 Parser Error The problem of finding correct subject span boundaries for reordering, however, is a particularly difficult one. Both Habash (2007b) and Green et al. (2009) have noted previously that even state-ofthe-art Arabic dependency parsers tend to perform poorly, and we would expect that incorrect boundaries would do more harm than good for translation. In order to determine how to “fix” these spans, it is first necessary to understand the kinds of errors that the parser makes. A set of predicted parses of the NIST MT05 data was compared to the gold parses of the same data set. There are three categories of error the parser can make in identifying subjects: labeling errors, attachment errors and span errors. In labeling errors, the parser either incorrect"
W11-2127,P05-1071,1,0.770901,"ERT (Och, 2003) to maximize BLEU on the NIST MT06 corpus. MERT was done only for the baseline system; these same weights were used for all experiments to control for the effect of MERT instability. In the future, we plan to experiment with approachspecific optimization and to use recent published suggestions on controlling for optimizer instability (Clark et al., 2011). English data was tokenized using simple punctuation-based rules. Arabic data was segmented with to the Arabic Treebank tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological disambiguator and tokenizer (Habash and Rambow, 2005; Habash, 2007a; Roth et al., 2008). The Arabic text was also Alif/Ya normalized (Habash, 2010). MADAproduced Arabic lemmas were used for word alignment. We compare four settings with predicted parses (as opposed to the gold parse experiments discussed in Section 3): • BASE An un-reordered test set; • FORCE A test set which forced reordering on matrix verbs; • OPT A test set with fuzzification through optional reordering on matrix verbs; and Experimental Setup We used the open-source Moses PSMT toolkit (Koehn et al., 2007). Training data was a newswire (MSA-English) parallel text with 12M word"
W11-2127,P09-2056,1,0.914406,"Missing"
W11-2127,2007.mtsummit-papers.29,1,0.976961,"burgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics Section 5 presents the results of a set of machine translation experiments using the automatic metrics BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005), and a manual-evaluation of subject integrity. Section 6 discusses our conclusions and future plans. 2 Related Work The general approach pursued in this paper—that of using pre-ordering to improve translation output– has been explored by many researchers. Most work has focused on automatically learning reordering rules (Xia and McCord, 2004; Habash, 2007b; Elming, 2008; Elming and Habash, 2009; Dyer and Resnik, 2010). Xia and McCord (2004) describe an approach for translation from French to English, where context-free constituency reordering rules are acquired automatically using source and target parses and word alignment. Elming (2008) and Elming and Habash (2009) use a large set of linguistic features to automatically learn reordering rules for English-Danish and English-Arabic; the rules are used to pre-order the input into a lattice of variant orders. Habash (2007b) learns syntactic reordering rules targeting Arabic-English word order di"
W11-2127,P07-2045,0,0.0216307,"04) using the MADA+TOKAN morphological disambiguator and tokenizer (Habash and Rambow, 2005; Habash, 2007a; Roth et al., 2008). The Arabic text was also Alif/Ya normalized (Habash, 2010). MADAproduced Arabic lemmas were used for word alignment. We compare four settings with predicted parses (as opposed to the gold parse experiments discussed in Section 3): • BASE An un-reordered test set; • FORCE A test set which forced reordering on matrix verbs; • OPT A test set with fuzzification through optional reordering on matrix verbs; and Experimental Setup We used the open-source Moses PSMT toolkit (Koehn et al., 2007). Training data was a newswire (MSA-English) parallel text with 12M words on the Arabic side (LDC2007E103)5 Sentences were reordered only for alignment, following the approach of Carpuat et al. (2010). Parses were obtained using a publicly available parser for Arabic (Marton et al., 2010). GIZA++ was used for word alignment (Och and Ney, 2003) and phrase translations of up to 10 words are extracted in the Moses phrase table. The same baseline phrase table was used in all experiments. The system’s language model was trained both on the English portion of the training corpus and English Gigaword"
W11-2127,W04-3250,0,0.204998,"Missing"
W11-2127,W10-1402,1,0.910449,"Missing"
W11-2127,J03-1002,0,0.00412204,"Section 3): • BASE An un-reordered test set; • FORCE A test set which forced reordering on matrix verbs; • OPT A test set with fuzzification through optional reordering on matrix verbs; and Experimental Setup We used the open-source Moses PSMT toolkit (Koehn et al., 2007). Training data was a newswire (MSA-English) parallel text with 12M words on the Arabic side (LDC2007E103)5 Sentences were reordered only for alignment, following the approach of Carpuat et al. (2010). Parses were obtained using a publicly available parser for Arabic (Marton et al., 2010). GIZA++ was used for word alignment (Och and Ney, 2003) and phrase translations of up to 10 words are extracted in the Moses phrase table. The same baseline phrase table was used in all experiments. The system’s language model was trained both on the English portion of the training corpus and English Gigaword (Graff and Cieri, 2003). We used a 5 All data is available from the Linguistic Data Consortium: http://www.ldc.upenn.edu. 232 • SPAN A test set with fuzzification through optional reordering on matrix verbs and through fuzzification of the subject span according to the algorithm shown in Section 4.2. Each reordering corpus used Moses’ lattice"
W11-2127,P03-1021,0,0.0247076,"ists of tuples, where each tuple defines a single reordering, and each list of tuples defines a set of spans that must be moved to the left of the matrix verb for one reordering. These re-orderings are then joined together to form the final lattice. If a single-constituent correction to the span exists (except in the aforementioned pathological and left-attachment cases), it is guaranteed to appear as one path through the lattice. 5 5.1 Evaluation 5-gram language model with modified Kneser-Ney smoothing implemented using the SRILM toolkit (Stolcke, 2002). Feature weights were tuned with MERT (Och, 2003) to maximize BLEU on the NIST MT06 corpus. MERT was done only for the baseline system; these same weights were used for all experiments to control for the effect of MERT instability. In the future, we plan to experiment with approachspecific optimization and to use recent published suggestions on controlling for optimizer instability (Clark et al., 2011). English data was tokenized using simple punctuation-based rules. Arabic data was segmented with to the Arabic Treebank tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological disambiguator and tokenizer (Habash and Ramb"
W11-2127,P02-1040,0,0.087095,"the maximum possible using gold parses), and a corresponding improvement in the percentage of syntactically wellformed subjects under a manual evaluation. The rest of the paper is structured as follows. Section 2 gives a review of research on this topic. Section 3 motivates the approach discussed in Section 4. 227 Proceedings of the 6th Workshop on Statistical Machine Translation, pages 227–236, c Edinburgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics Section 5 presents the results of a set of machine translation experiments using the automatic metrics BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005), and a manual-evaluation of subject integrity. Section 6 discusses our conclusions and future plans. 2 Related Work The general approach pursued in this paper—that of using pre-ordering to improve translation output– has been explored by many researchers. Most work has focused on automatically learning reordering rules (Xia and McCord, 2004; Habash, 2007b; Elming, 2008; Elming and Habash, 2009; Dyer and Resnik, 2010). Xia and McCord (2004) describe an approach for translation from French to English, where context-free constituency reordering rules are acq"
W11-2127,P08-2030,1,0.810201,"NIST MT06 corpus. MERT was done only for the baseline system; these same weights were used for all experiments to control for the effect of MERT instability. In the future, we plan to experiment with approachspecific optimization and to use recent published suggestions on controlling for optimizer instability (Clark et al., 2011). English data was tokenized using simple punctuation-based rules. Arabic data was segmented with to the Arabic Treebank tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological disambiguator and tokenizer (Habash and Rambow, 2005; Habash, 2007a; Roth et al., 2008). The Arabic text was also Alif/Ya normalized (Habash, 2010). MADAproduced Arabic lemmas were used for word alignment. We compare four settings with predicted parses (as opposed to the gold parse experiments discussed in Section 3): • BASE An un-reordered test set; • FORCE A test set which forced reordering on matrix verbs; • OPT A test set with fuzzification through optional reordering on matrix verbs; and Experimental Setup We used the open-source Moses PSMT toolkit (Koehn et al., 2007). Training data was a newswire (MSA-English) parallel text with 12M words on the Arabic side (LDC2007E103)5"
W11-2127,C04-1073,0,0.306764,"Missing"
W11-2127,C08-1027,0,\N,Missing
W11-2127,D08-1076,0,\N,Missing
W11-2128,P01-1008,0,0.111227,"s by lexical and morphological expansion of known phrases and dictionary terms – and transliteration of proper names. Bond et al. (2008) also pivot for paraphrasing. They improve SMT coverage by using a manually crafted monolingual HPSG grammar for generating meaning and grammar-preserving paraphrases. This grammar allows for certain word reordering, lexical substitutions, contractions, and “typo” corrections. Onishi et al. (2010), Du et al. (2010), and others, pivot-paraphrase the input, and represent the paraphrases in a lattice format, decoding it with Moses. Work on paraphrase generation: Barzilay and McKeown (2001) extract paraphrases from a monolingual parallel corpus, containing multiple translations of the same source. However, monolingual parallel corpora are extremely rare and small. Dolan et al. (2004) use edit distance for paraphrasing. Max (2009) and others take the context of the paraphrased word’s occurrence into account. Zhao et al. (2008) apply SMT-style decoding for paraphrasing, using several log linear weighted resources while Zhao et al. (2009) filter out paraphrase candidates and weight paraphrase features according to the desired NLP task. Chevelu et al. (2009) introduce a new paraphra"
W11-2128,2008.iwslt-papers.2,0,0.0193067,"ifference being the filtering of the resulting paraphrases for antonymity. Other work on augmentating SMT: Habash and Hu (2009) show, pivoting via a trilingual parallel text, that using English as a pivot language between Chinese and Arabic outperforms translation 245 using a direct Chinese-Arabic bilingual parallel text. Other attempts to reduce the OOV rate by augmenting the phrase table’s source side include Habash (2009), providing an online tool for paraphrasing OOV phrases by lexical and morphological expansion of known phrases and dictionary terms – and transliteration of proper names. Bond et al. (2008) also pivot for paraphrasing. They improve SMT coverage by using a manually crafted monolingual HPSG grammar for generating meaning and grammar-preserving paraphrases. This grammar allows for certain word reordering, lexical substitutions, contractions, and “typo” corrections. Onishi et al. (2010), Du et al. (2010), and others, pivot-paraphrase the input, and represent the paraphrases in a lattice format, decoding it with Moses. Work on paraphrase generation: Barzilay and McKeown (2001) extract paraphrases from a monolingual parallel corpus, containing multiple translations of the same source."
W11-2128,N06-1003,0,0.389187,"recognition and generation has proven useful for various natural language processing (NLP) tasks, including statistical machine translation (SMT), information retrieval, query expansion, document summarization, and natural language generation. We concentrate here on phrase-level (as opposed to sentence-level) paraphrasing for SMT. Paraphrasing is useful for SMT as it increases translation coverage – a persistent problem, even in largescale systems. Two common approaches are “pivot” and distributional paraphrasing. Pivot paraphrasing translates phrases of interest to other languages and back (Callison-Burch et al., 2006; Callison-Burch, 2008). It relies on parallel texts (or translation phrase tables) in various languages, which are typically scarce, and hence limit its applicability. Distributional paraphrasing (Marton et al., 2009) generates paraphrases using a distributional semantic distance measure computed over a large monolingual corpus.1 Monolingual corpora are relatively easy and inexpensive to collect, but distributional semantic distance measures are known to rank antonymous and polarity-dissimilar phrasal candidates high. We therefore attempt to identify and filter out such illsuited paraphrase c"
W11-2128,D08-1021,0,0.482614,"as proven useful for various natural language processing (NLP) tasks, including statistical machine translation (SMT), information retrieval, query expansion, document summarization, and natural language generation. We concentrate here on phrase-level (as opposed to sentence-level) paraphrasing for SMT. Paraphrasing is useful for SMT as it increases translation coverage – a persistent problem, even in largescale systems. Two common approaches are “pivot” and distributional paraphrasing. Pivot paraphrasing translates phrases of interest to other languages and back (Callison-Burch et al., 2006; Callison-Burch, 2008). It relies on parallel texts (or translation phrase tables) in various languages, which are typically scarce, and hence limit its applicability. Distributional paraphrasing (Marton et al., 2009) generates paraphrases using a distributional semantic distance measure computed over a large monolingual corpus.1 Monolingual corpora are relatively easy and inexpensive to collect, but distributional semantic distance measures are known to rank antonymous and polarity-dissimilar phrasal candidates high. We therefore attempt to identify and filter out such illsuited paraphrase candidates. A phrase pai"
W11-2128,P09-2063,0,0.0188916,"phrase generation: Barzilay and McKeown (2001) extract paraphrases from a monolingual parallel corpus, containing multiple translations of the same source. However, monolingual parallel corpora are extremely rare and small. Dolan et al. (2004) use edit distance for paraphrasing. Max (2009) and others take the context of the paraphrased word’s occurrence into account. Zhao et al. (2008) apply SMT-style decoding for paraphrasing, using several log linear weighted resources while Zhao et al. (2009) filter out paraphrase candidates and weight paraphrase features according to the desired NLP task. Chevelu et al. (2009) introduce a new paraphrase generation tool based on MonteCarlo sampling. Mirkin et al. (2009), inter alia, frame paraphrasing as a special, symmetrical case of (WordNet-based) textual entailment. See Madnani and Dorr (2010) for a good paraphrasing survey. Work on measuring distributional semantic distance: For one survey of this rich topic, see Weeds et al. (2004) and Turney and Pantel (2010). We use here cosine of log-likelihood ratios (McDonald, 2000). A recent paper (Kazama et al., 2010) advocates a Bayesian approach, making rare terms have lower strength of association, as a by-product of"
W11-2128,D08-1083,0,0.051072,"Missing"
W11-2128,C04-1051,0,0.0898422,"nually crafted monolingual HPSG grammar for generating meaning and grammar-preserving paraphrases. This grammar allows for certain word reordering, lexical substitutions, contractions, and “typo” corrections. Onishi et al. (2010), Du et al. (2010), and others, pivot-paraphrase the input, and represent the paraphrases in a lattice format, decoding it with Moses. Work on paraphrase generation: Barzilay and McKeown (2001) extract paraphrases from a monolingual parallel corpus, containing multiple translations of the same source. However, monolingual parallel corpora are extremely rare and small. Dolan et al. (2004) use edit distance for paraphrasing. Max (2009) and others take the context of the paraphrased word’s occurrence into account. Zhao et al. (2008) apply SMT-style decoding for paraphrasing, using several log linear weighted resources while Zhao et al. (2009) filter out paraphrase candidates and weight paraphrase features according to the desired NLP task. Chevelu et al. (2009) introduce a new paraphrase generation tool based on MonteCarlo sampling. Mirkin et al. (2009), inter alia, frame paraphrasing as a special, symmetrical case of (WordNet-based) textual entailment. See Madnani and Dorr (201"
W11-2128,D10-1041,0,0.0535489,"text. Other attempts to reduce the OOV rate by augmenting the phrase table’s source side include Habash (2009), providing an online tool for paraphrasing OOV phrases by lexical and morphological expansion of known phrases and dictionary terms – and transliteration of proper names. Bond et al. (2008) also pivot for paraphrasing. They improve SMT coverage by using a manually crafted monolingual HPSG grammar for generating meaning and grammar-preserving paraphrases. This grammar allows for certain word reordering, lexical substitutions, contractions, and “typo” corrections. Onishi et al. (2010), Du et al. (2010), and others, pivot-paraphrase the input, and represent the paraphrases in a lattice format, decoding it with Moses. Work on paraphrase generation: Barzilay and McKeown (2001) extract paraphrases from a monolingual parallel corpus, containing multiple translations of the same source. However, monolingual parallel corpora are extremely rare and small. Dolan et al. (2004) use edit distance for paraphrasing. Max (2009) and others take the context of the paraphrased word’s occurrence into account. Zhao et al. (2008) apply SMT-style decoding for paraphrasing, using several log linear weighted resou"
W11-2128,2010.jeptalnrecital-long.29,1,0.849452,"Missing"
W11-2128,W09-0431,1,0.849446,"; Callison-Burch (2008) filters such paraphrases using syntactic parsing information; Marton et al. (2009) use distributional paraphrasing technique that applies distributional semantic distance measure for the paraphrase score; Marton (2010) applies a lexical resource / corpus-based hybrid semantic distance measure for the paraphrase score instead, approximating word senses; here, we apply a distributional semantic distance measure that is similar to Marton et al. (2009), with the main difference being the filtering of the resulting paraphrases for antonymity. Other work on augmentating SMT: Habash and Hu (2009) show, pivoting via a trilingual parallel text, that using English as a pivot language between Chinese and Arabic outperforms translation 245 using a direct Chinese-Arabic bilingual parallel text. Other attempts to reduce the OOV rate by augmenting the phrase table’s source side include Habash (2009), providing an online tool for paraphrasing OOV phrases by lexical and morphological expansion of known phrases and dictionary terms – and transliteration of proper names. Bond et al. (2008) also pivot for paraphrasing. They improve SMT coverage by using a manually crafted monolingual HPSG grammar"
W11-2128,P05-1071,1,0.683791,"s four reference translations. English-Arabic: We use an English-Arabic parallel corpus of about 135k sentences (4 million words) and a subset of 30K sentences (one million words) for the translation models’ training data. The sentences were extracted from Arabic News (LDC2004T17), eTIRR (LDC2004E72), English translation of Arabic Treebank (LDC2005E46), and Ummah (LDC2004T18).4 For Arabic preprocessing, we follow previously reported best tokenization scheme (TB)5 and orthographic word normalization condition (Reduced) when translating from English to Arabic (El Kholy and Habash, 2010b). MADA (Habash and Rambow, 2005) is used to pre-process the Arabic text for the translation model and 5-gram language model (LM). As a postprocessing step, we jointly denormalize and detokenize the text to produce the final Arabic output. Following El Kholy and Habash (2010a), we use their best detokenization technique, T+R+LM. The technique crucially utilizes a lookup table (T), mapping tokenized forms to detokenized forms, based on our MADA-fied LM. Alternatives are given conditional probabilities, P (detokenized|tokenized). Tokenized words absent from the tables are detokenized using deterministic rules (R), as a backoff"
W11-2128,P10-1026,0,0.060719,"Missing"
W11-2128,W04-3250,0,0.45526,"uage model (LM) probability. We used Giza++ (Och and Ney, 2000) for word alignment. All features were weighted in a log-linear framework (Och and Ney, 2002). Feature weights were set with minimum error rate training (Och, 2003) on a tuning set using B LEU (Papineni et al., 2002) as the objective function. Test results were evaluated using B LEU and TER (Snover et al., 2006): The higher the B LEU score, the better the result; the lower the TER score, the better the result. This is denoted with B LEU↑ and TER↓ in Table 1. Statistical significance of model output differences was determined using Koehn (2004)’s test on the objective function (B LEU). The paraphrase-augmented models were created as described in Section 4. We used the same data and parameter settings as in Marton (2010).3 We used cosine distance over DPs of log-likelihood ratios (McDonald, 2000), built with a sliding win3 Data preprocessing and paraphrasing code slightly differ from those used in Marton et al. (2009) and Marton (2010), and hence scores are not exactly the same across these publications. dow of size ±6, a sampling threshold of 10000 occurrences, and a maximal paraphrase length of 6 tokens. We applied a paraphrase sco"
W11-2128,J10-3003,0,0.038695,". Dolan et al. (2004) use edit distance for paraphrasing. Max (2009) and others take the context of the paraphrased word’s occurrence into account. Zhao et al. (2008) apply SMT-style decoding for paraphrasing, using several log linear weighted resources while Zhao et al. (2009) filter out paraphrase candidates and weight paraphrase features according to the desired NLP task. Chevelu et al. (2009) introduce a new paraphrase generation tool based on MonteCarlo sampling. Mirkin et al. (2009), inter alia, frame paraphrasing as a special, symmetrical case of (WordNet-based) textual entailment. See Madnani and Dorr (2010) for a good paraphrasing survey. Work on measuring distributional semantic distance: For one survey of this rich topic, see Weeds et al. (2004) and Turney and Pantel (2010). We use here cosine of log-likelihood ratios (McDonald, 2000). A recent paper (Kazama et al., 2010) advocates a Bayesian approach, making rare terms have lower strength of association, as a by-product of relying on their probabilistic Expectation. Work on detecting antonyms: Our work with antonyms can be thought of as an application-based extension of the (Mohammad et al., 2008) method. Some of the earliest computational wo"
W11-2128,P08-1118,0,0.251552,"Missing"
W11-2128,D09-1040,1,0.69469,"anguage generation. We concentrate here on phrase-level (as opposed to sentence-level) paraphrasing for SMT. Paraphrasing is useful for SMT as it increases translation coverage – a persistent problem, even in largescale systems. Two common approaches are “pivot” and distributional paraphrasing. Pivot paraphrasing translates phrases of interest to other languages and back (Callison-Burch et al., 2006; Callison-Burch, 2008). It relies on parallel texts (or translation phrase tables) in various languages, which are typically scarce, and hence limit its applicability. Distributional paraphrasing (Marton et al., 2009) generates paraphrases using a distributional semantic distance measure computed over a large monolingual corpus.1 Monolingual corpora are relatively easy and inexpensive to collect, but distributional semantic distance measures are known to rank antonymous and polarity-dissimilar phrasal candidates high. We therefore attempt to identify and filter out such illsuited paraphrase candidates. A phrase pair may have a varying degree of antonymy, beyond the better-known complete opposites (hot / cold) and contradictions (did / did not), e.g., weaker contrasts (hot / cool), contrasting trends (cover"
W11-2128,W09-2503,0,0.0188174,"eaning and grammar-preserving paraphrases. This grammar allows for certain word reordering, lexical substitutions, contractions, and “typo” corrections. Onishi et al. (2010), Du et al. (2010), and others, pivot-paraphrase the input, and represent the paraphrases in a lattice format, decoding it with Moses. Work on paraphrase generation: Barzilay and McKeown (2001) extract paraphrases from a monolingual parallel corpus, containing multiple translations of the same source. However, monolingual parallel corpora are extremely rare and small. Dolan et al. (2004) use edit distance for paraphrasing. Max (2009) and others take the context of the paraphrased word’s occurrence into account. Zhao et al. (2008) apply SMT-style decoding for paraphrasing, using several log linear weighted resources while Zhao et al. (2009) filter out paraphrase candidates and weight paraphrase features according to the desired NLP task. Chevelu et al. (2009) introduce a new paraphrase generation tool based on MonteCarlo sampling. Mirkin et al. (2009), inter alia, frame paraphrasing as a special, symmetrical case of (WordNet-based) textual entailment. See Madnani and Dorr (2010) for a good paraphrasing survey. Work on meas"
W11-2128,H05-1067,0,0.0827201,"lion) and detecting contradictions (Marneffe et al., 2008; Voorhees, 2008) (The inhabitants of Peru are well off / the inhabitants of Peru are poor). Of course, such “contradictions” may be a result of differing sentiment, new information, non-coreferent mentions, or genuinely contradictory statements. Identifying paraphrases and contradictions are in turn useful in effectively re-ranking target language hypotheses in machine translation, and for re-ranking query responses in information retrieval. Identifying contrasting word pairs (or short phrase pairs) is also useful for detecting humor (Mihalcea and Strapparava, 2005), as satire and jokes tend to have contradictions and oxymorons. Lastly, it is useful to know which words contrast a focal word, even if only to filter them out. For example, in the automatic creation of a thesaurus it is necessary to distinguish near-synonyms from contrasting word pairs. Distributional similarity measures typically fail to do so. Instances of strong contrast are recorded to some extent in manually created dictionaries, but hundreds of thousands of other contrasting pairs are not. Further, antonyms can be of many kinds such as those described in Section 3.1 below. We use the M"
W11-2128,P09-1089,0,0.0733884,"et al., 2008; Voorhees, 2008). We transfer some of the insights, data and techniques to the area of paraphrasing and SMT. We distributionally expand a small seed set of antonyms in an unsupervised manner, following Mohammad et al. (2008). We then present a method for filtering antonymous and polarity-dissimilar distributional paraphrases using the expanded antonymous list and a list of negators (e.g., cannot) and trenddecreasing words (reduced). We evaluate the impact of our approach in a SMT setting, where non1 Other variants use a lexical resource in conjunction with the monolingual corpus (Mirkin et al., 2009; Marton, 2010). 237 Proceedings of the 6th Workshop on Statistical Machine Translation, pages 237–249, c Edinburgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics baseline translation models are augmented with distributional paraphrases. We show gains of up to 1 B LEU relative to non-filtered models (1.6 B LEU from non-augmented baselines) in English-Chinese models trained on small and medium-large size data, but lower to no gains in English-Arabic. The small training size simulates resource-poor languages. The rest of this paper is organized as follows: We des"
W11-2128,D08-1103,0,0.514223,"id not), e.g., weaker contrasts (hot / cool), contrasting trends (covered / reduced coverage), or sentiment polarity (happy / sad). Information extraction, opinion mining and sentiment analysis literature has been grappling with identifying such pairs (Pang and Lee, 2008), e.g., in order to distinguish positive and negative reviews or comments, or to detect contradictions (Marneffe et al., 2008; Voorhees, 2008). We transfer some of the insights, data and techniques to the area of paraphrasing and SMT. We distributionally expand a small seed set of antonyms in an unsupervised manner, following Mohammad et al. (2008). We then present a method for filtering antonymous and polarity-dissimilar distributional paraphrases using the expanded antonymous list and a list of negators (e.g., cannot) and trenddecreasing words (reduced). We evaluate the impact of our approach in a SMT setting, where non1 Other variants use a lexical resource in conjunction with the monolingual corpus (Mirkin et al., 2009; Marton, 2010). 237 Proceedings of the 6th Workshop on Statistical Machine Translation, pages 237–249, c Edinburgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics baseline translation m"
W11-2128,P00-1056,0,0.0609184,"se and English-to-Arabic translation, augmenting the models with translation rules for unknown English phrases. We also contrasted these models with non-augmented baseline models. For baseline we used the phrase-based SMT system Moses (Koehn et al., 2007), with the default model features: 1. phrase translation probability, 2. reverse phrase translation probability, 3. lexical translation probability, 4. reverse lexical translation probability, 5. word penalty, 6. phrase penalty, 7. six lexicalized reordering features, 8. distortion cost, and 9. language model (LM) probability. We used Giza++ (Och and Ney, 2000) for word alignment. All features were weighted in a log-linear framework (Och and Ney, 2002). Feature weights were set with minimum error rate training (Och, 2003) on a tuning set using B LEU (Papineni et al., 2002) as the objective function. Test results were evaluated using B LEU and TER (Snover et al., 2006): The higher the B LEU score, the better the result; the lower the TER score, the better the result. This is denoted with B LEU↑ and TER↓ in Table 1. Statistical significance of model output differences was determined using Koehn (2004)’s test on the objective function (B LEU). The para"
W11-2128,P02-1038,0,0.031655,"n English phrases. We also contrasted these models with non-augmented baseline models. For baseline we used the phrase-based SMT system Moses (Koehn et al., 2007), with the default model features: 1. phrase translation probability, 2. reverse phrase translation probability, 3. lexical translation probability, 4. reverse lexical translation probability, 5. word penalty, 6. phrase penalty, 7. six lexicalized reordering features, 8. distortion cost, and 9. language model (LM) probability. We used Giza++ (Och and Ney, 2000) for word alignment. All features were weighted in a log-linear framework (Och and Ney, 2002). Feature weights were set with minimum error rate training (Och, 2003) on a tuning set using B LEU (Papineni et al., 2002) as the objective function. Test results were evaluated using B LEU and TER (Snover et al., 2006): The higher the B LEU score, the better the result; the lower the TER score, the better the result. This is denoted with B LEU↑ and TER↓ in Table 1. Statistical significance of model output differences was determined using Koehn (2004)’s test on the objective function (B LEU). The paraphrase-augmented models were created as described in Section 4. We used the same data and par"
W11-2128,P03-1021,0,0.0153041,"models. For baseline we used the phrase-based SMT system Moses (Koehn et al., 2007), with the default model features: 1. phrase translation probability, 2. reverse phrase translation probability, 3. lexical translation probability, 4. reverse lexical translation probability, 5. word penalty, 6. phrase penalty, 7. six lexicalized reordering features, 8. distortion cost, and 9. language model (LM) probability. We used Giza++ (Och and Ney, 2000) for word alignment. All features were weighted in a log-linear framework (Och and Ney, 2002). Feature weights were set with minimum error rate training (Och, 2003) on a tuning set using B LEU (Papineni et al., 2002) as the objective function. Test results were evaluated using B LEU and TER (Snover et al., 2006): The higher the B LEU score, the better the result; the lower the TER score, the better the result. This is denoted with B LEU↑ and TER↓ in Table 1. Statistical significance of model output differences was determined using Koehn (2004)’s test on the objective function (B LEU). The paraphrase-augmented models were created as described in Section 4. We used the same data and parameter settings as in Marton (2010).3 We used cosine distance over DPs"
W11-2128,P10-2001,0,0.0184454,"ic bilingual parallel text. Other attempts to reduce the OOV rate by augmenting the phrase table’s source side include Habash (2009), providing an online tool for paraphrasing OOV phrases by lexical and morphological expansion of known phrases and dictionary terms – and transliteration of proper names. Bond et al. (2008) also pivot for paraphrasing. They improve SMT coverage by using a manually crafted monolingual HPSG grammar for generating meaning and grammar-preserving paraphrases. This grammar allows for certain word reordering, lexical substitutions, contractions, and “typo” corrections. Onishi et al. (2010), Du et al. (2010), and others, pivot-paraphrase the input, and represent the paraphrases in a lattice format, decoding it with Moses. Work on paraphrase generation: Barzilay and McKeown (2001) extract paraphrases from a monolingual parallel corpus, containing multiple translations of the same source. However, monolingual parallel corpora are extremely rare and small. Dolan et al. (2004) use edit distance for paraphrasing. Max (2009) and others take the context of the paraphrased word’s occurrence into account. Zhao et al. (2008) apply SMT-style decoding for paraphrasing, using several log lin"
W11-2128,2006.amta-papers.25,0,0.0193977,"probability, 2. reverse phrase translation probability, 3. lexical translation probability, 4. reverse lexical translation probability, 5. word penalty, 6. phrase penalty, 7. six lexicalized reordering features, 8. distortion cost, and 9. language model (LM) probability. We used Giza++ (Och and Ney, 2000) for word alignment. All features were weighted in a log-linear framework (Och and Ney, 2002). Feature weights were set with minimum error rate training (Och, 2003) on a tuning set using B LEU (Papineni et al., 2002) as the objective function. Test results were evaluated using B LEU and TER (Snover et al., 2006): The higher the B LEU score, the better the result; the lower the TER score, the better the result. This is denoted with B LEU↑ and TER↓ in Table 1. Statistical significance of model output differences was determined using Koehn (2004)’s test on the objective function (B LEU). The paraphrase-augmented models were created as described in Section 4. We used the same data and parameter settings as in Marton (2010).3 We used cosine distance over DPs of log-likelihood ratios (McDonald, 2000), built with a sliding win3 Data preprocessing and paraphrasing code slightly differ from those used in Mart"
W11-2128,C08-1114,0,0.128524,"Missing"
W11-2128,P08-1008,0,0.391516,"to identify and filter out such illsuited paraphrase candidates. A phrase pair may have a varying degree of antonymy, beyond the better-known complete opposites (hot / cold) and contradictions (did / did not), e.g., weaker contrasts (hot / cool), contrasting trends (covered / reduced coverage), or sentiment polarity (happy / sad). Information extraction, opinion mining and sentiment analysis literature has been grappling with identifying such pairs (Pang and Lee, 2008), e.g., in order to distinguish positive and negative reviews or comments, or to detect contradictions (Marneffe et al., 2008; Voorhees, 2008). We transfer some of the insights, data and techniques to the area of paraphrasing and SMT. We distributionally expand a small seed set of antonyms in an unsupervised manner, following Mohammad et al. (2008). We then present a method for filtering antonymous and polarity-dissimilar distributional paraphrases using the expanded antonymous list and a list of negators (e.g., cannot) and trenddecreasing words (reduced). We evaluate the impact of our approach in a SMT setting, where non1 Other variants use a lexical resource in conjunction with the monolingual corpus (Mirkin et al., 2009; Marton,"
W11-2128,C04-1146,0,0.0903803,"Missing"
W11-2128,P08-1116,0,0.0198643,", lexical substitutions, contractions, and “typo” corrections. Onishi et al. (2010), Du et al. (2010), and others, pivot-paraphrase the input, and represent the paraphrases in a lattice format, decoding it with Moses. Work on paraphrase generation: Barzilay and McKeown (2001) extract paraphrases from a monolingual parallel corpus, containing multiple translations of the same source. However, monolingual parallel corpora are extremely rare and small. Dolan et al. (2004) use edit distance for paraphrasing. Max (2009) and others take the context of the paraphrased word’s occurrence into account. Zhao et al. (2008) apply SMT-style decoding for paraphrasing, using several log linear weighted resources while Zhao et al. (2009) filter out paraphrase candidates and weight paraphrase features according to the desired NLP task. Chevelu et al. (2009) introduce a new paraphrase generation tool based on MonteCarlo sampling. Mirkin et al. (2009), inter alia, frame paraphrasing as a special, symmetrical case of (WordNet-based) textual entailment. See Madnani and Dorr (2010) for a good paraphrasing survey. Work on measuring distributional semantic distance: For one survey of this rich topic, see Weeds et al. (2004)"
W11-2128,P09-1094,0,0.025951,"s, pivot-paraphrase the input, and represent the paraphrases in a lattice format, decoding it with Moses. Work on paraphrase generation: Barzilay and McKeown (2001) extract paraphrases from a monolingual parallel corpus, containing multiple translations of the same source. However, monolingual parallel corpora are extremely rare and small. Dolan et al. (2004) use edit distance for paraphrasing. Max (2009) and others take the context of the paraphrased word’s occurrence into account. Zhao et al. (2008) apply SMT-style decoding for paraphrasing, using several log linear weighted resources while Zhao et al. (2009) filter out paraphrase candidates and weight paraphrase features according to the desired NLP task. Chevelu et al. (2009) introduce a new paraphrase generation tool based on MonteCarlo sampling. Mirkin et al. (2009), inter alia, frame paraphrasing as a special, symmetrical case of (WordNet-based) textual entailment. See Madnani and Dorr (2010) for a good paraphrasing survey. Work on measuring distributional semantic distance: For one survey of this rich topic, see Weeds et al. (2004) and Turney and Pantel (2010). We use here cosine of log-likelihood ratios (McDonald, 2000). A recent paper (Kaz"
W11-2128,P07-2045,0,\N,Missing
W11-2128,I05-3027,0,\N,Missing
W11-2602,al-sabbagh-girju-2010-mining,0,0.131144,"f parallel corpora, rule-based methods to translate DA-to-MSA Proceedings of EMNLP 2011, Conference on Empirical Methods in Natural Language Processing, pages 10–21, c Edinburgh, Scotland, UK, July 27–31, 2011. 2011 Association for Computational Linguistics or other methods to collect word-pair lists have been explored. For example, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. This hybrid system consisted of a statistical system for tokenizing and tagging, and a rule-based system for constructing diacritized MSA sentences. Moreover, Al-Sabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. In the context of DA-to-English SMT, Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut the OOVs by half. Machine Translation for Closely Related Languages Using closely related languages has been shown to improve MT quality when resources are limited. Hajiˇc et al. (2000) argued that for very close languages, e.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and"
W11-2602,W11-4416,1,0.678103,"Rambow, 2006; Abo Bakr et al., 2008). In this section, we present a new dialectal morphological analyzer, A DAM, built as an extension to an already existing MSA analyzer. We only focus on extensions that address dialectal affixes and clitics, as opposed to stems, which we plan to address in future work. This approach to extending an MSA analyzer is similar to work done by Abo Bakr et al. (2008) and it contrasts as rather a shallow/quick-and-dirty solution compared to other more demanding efforts on building dialectal analyzers from scratch, such as the MAGEAD system (Habash and Rambow, 2006; Altantawy et al., 2011). 2. Analysis. Produce a set of alternative analyses for each word. 4.2.1 3. Transfer. Map each analysis into one or more target analyses. A DAM is built on the top of BAMA database (Buckwalter, 2004) as used in the A LMOR morphological analyzer/generator (Habash, 2007), which is the rule-based component of the M ADA system for morphological analysis and disambiguation of Arabic (Habash and Rambow, 2005; Roth et al., 2008). The A LMOR system presents analyses as lemma and feature-value pairs including clitics. The BAMA databases contain three tables of Arabic stems, complex prefixes and comple"
W11-2602,W05-0909,0,0.0214876,"imum Error Rate Training (Och, 2003). This is only done on the baseline systems. For all systems, the English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer (Habash and Rambow, 2005) – v3.1 (Roth et al., 2008). The Arabic text is also Alif/Ya normalized (Habash, 2010). MADA-produced Arabic lemmas are used for word alignment. Results are presented in terms of BLEU (Papineni et al., 2002), NIST (Doddington, 2002) and METEOR (Banerjee and Lavie, 2005) metrics.4 However, all optimizations were done against the BLEU metric. All evaluation results are case insensitive. All of the systems we present use the lattice input format to Moses (Dyer et al., 2008), including the baselines which do not need them. We do not report on the non-lattice baselines, but in initial experiments we conducted, they did not perform as well as the degenerate lattice version. The Devtest Set Our devtest set consists of sentences containing at least one non-MSA segment (as annotated by LDC)5 in the Dev10 audio development data under the DARPA GALE program. The data c"
W11-2602,N06-1003,0,0.0406266,"e-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rulebased approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. This use of “resourcerich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Habash, 2008; Du et al., 2010). This paper presents results on a rule-based system to generate alternative paraphrases for DA OOV words and low frequency words to help improve SMT from highly dialectal Arabic to English. Our work is most similar to Sawaf (2010)’s approach to DA normalization into MSA, although we shy away from the term in our work since we do not produce a single MSA version of the input to pass on to MSAEnglish MT. Instead we pass multiple paraphrases (or alternative normalizations) as a lattice to an SMT system, in a manner similar to Du et al. (2010). Certain aspects of o"
W11-2602,E06-1047,1,0.421033,"challenges and motivation, Section 4 details our approach and Section 5 presents results evaluating our approach under a variety of conditions. 2 Related Work Dialectal Arabic NLP Much work has been done in the context of MSA NLP (Habash, 2010). Specifically for Arabic-to-English SMT, the importance of tokenization using morphological analysis has been shown by many researchers (Lee, 2004; Zollmann et al., 2006; Habash and Sadat, 2006). In contrast, research on DA NLP is still in its early stages: (Kilany et al., 2002; Kirchhoff et al., 2003; Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Chiang et al., 2006). Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP, e.g., Chiang et al. (2006) built syntactic parsers for DA trained on MSA treebanks. Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA Proceedings of EMNLP 2011, Conference on Empirical Methods in Natural Language Processing, pages 10–21, c Edinburgh, Scotland, UK, July 27–31, 2011. 2011 Association fo"
W11-2602,D10-1041,0,0.0237743,"ammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rulebased approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. This use of “resourcerich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Habash, 2008; Du et al., 2010). This paper presents results on a rule-based system to generate alternative paraphrases for DA OOV words and low frequency words to help improve SMT from highly dialectal Arabic to English. Our work is most similar to Sawaf (2010)’s approach to DA normalization into MSA, although we shy away from the term in our work since we do not produce a single MSA version of the input to pass on to MSAEnglish MT. Instead we pass multiple paraphrases (or alternative normalizations) as a lattice to an SMT system, in a manner similar to Du et al. (2010). Certain aspects of our approach are similar to Riesa"
W11-2602,W05-0708,0,0.468239,"n 2 is related work, Section 3 presents linguistic challenges and motivation, Section 4 details our approach and Section 5 presents results evaluating our approach under a variety of conditions. 2 Related Work Dialectal Arabic NLP Much work has been done in the context of MSA NLP (Habash, 2010). Specifically for Arabic-to-English SMT, the importance of tokenization using morphological analysis has been shown by many researchers (Lee, 2004; Zollmann et al., 2006; Habash and Sadat, 2006). In contrast, research on DA NLP is still in its early stages: (Kilany et al., 2002; Kirchhoff et al., 2003; Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Chiang et al., 2006). Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP, e.g., Chiang et al. (2006) built syntactic parsers for DA trained on MSA treebanks. Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA Proceedings of EMNLP 2011, Conference on Empirical Methods in Natural Language Processing, pages 10–21, c Edinburgh, Scot"
W11-2602,P08-1115,0,0.0159136,"Arabic Treebank tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer (Habash and Rambow, 2005) – v3.1 (Roth et al., 2008). The Arabic text is also Alif/Ya normalized (Habash, 2010). MADA-produced Arabic lemmas are used for word alignment. Results are presented in terms of BLEU (Papineni et al., 2002), NIST (Doddington, 2002) and METEOR (Banerjee and Lavie, 2005) metrics.4 However, all optimizations were done against the BLEU metric. All evaluation results are case insensitive. All of the systems we present use the lattice input format to Moses (Dyer et al., 2008), including the baselines which do not need them. We do not report on the non-lattice baselines, but in initial experiments we conducted, they did not perform as well as the degenerate lattice version. The Devtest Set Our devtest set consists of sentences containing at least one non-MSA segment (as annotated by LDC)5 in the Dev10 audio development data under the DARPA GALE program. The data contains broadcast conversational (BC) segments (with three reference translations), and broadcast news (BN) segments (with only one reference, replicated three times). The data set contained a mix of Arabi"
W11-2602,P05-1071,1,0.949698,", produces an average of 12 analyses per word. Moreover, some letters in Arabic are often spelled inconsistently which leads to an increase in both sparsity (multiple forms of the same word) and ambiguity (same form corresponding to multiple words), e.g., variants of Hamzated ˇ are often written without their Alif, @ Â or @ A, Hamza ( Z ’): @ A; and the Alif-Maqsura (or dotless Ya) ø ý and the regular dotted Ya ø y are often used interchangeably in word final position (Kholy and Habash, 2010). Arabic complex morphology and ambiguity are handled using tools for disambiguation and tokenization (Habash and Rambow, 2005; Diab et al., 2007). For our SMT system, we preprocess the Arabic text so that it is tokenized in the Penn Arabic Treebank tokenization (Maamouri et al., 2004), Alif/Ya normalized and undiacritized. These measures have an important effect on reducing overall OOV rate (Habash, 2008). 3.2 Dialectal Arabic Challenges Contemporary Arabic is in fact a collection of varieties: MSA, which has a standard orthography and is used in formal settings, and DAs, which are commonly used informally and with increasing presence on the web, but which do not have standard orthographies. There are several variet"
W11-2602,P06-1086,1,0.59302,"ion 3 presents linguistic challenges and motivation, Section 4 details our approach and Section 5 presents results evaluating our approach under a variety of conditions. 2 Related Work Dialectal Arabic NLP Much work has been done in the context of MSA NLP (Habash, 2010). Specifically for Arabic-to-English SMT, the importance of tokenization using morphological analysis has been shown by many researchers (Lee, 2004; Zollmann et al., 2006; Habash and Sadat, 2006). In contrast, research on DA NLP is still in its early stages: (Kilany et al., 2002; Kirchhoff et al., 2003; Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Chiang et al., 2006). Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP, e.g., Chiang et al. (2006) built syntactic parsers for DA trained on MSA treebanks. Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA Proceedings of EMNLP 2011, Conference on Empirical Methods in Natural Language Processing, pages 10–21, c Edinburgh, Scotland, UK, July 27–31, 201"
W11-2602,N06-2013,1,0.924171,"Missing"
W11-2602,P08-2015,1,0.926115,"formational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rulebased approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. This use of “resourcerich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Habash, 2008; Du et al., 2010). This paper presents results on a rule-based system to generate alternative paraphrases for DA OOV words and low frequency words to help improve SMT from highly dialectal Arabic to English. Our work is most similar to Sawaf (2010)’s approach to DA normalization into MSA, although we shy away from the term in our work since we do not produce a single MSA version of the input to pass on to MSAEnglish MT. Instead we pass multiple paraphrases (or alternative normalizations) as a lattice to an SMT system, in a manner similar to Du et al. (2010). Certain aspects of our approach ar"
W11-2602,A00-1002,0,0.657439,"Missing"
W11-2602,P07-2045,0,0.00502363,"clitics as an option. 4.4 Generation In this step, we generate Arabic words from all analyses produced by the previous steps. The generation is done using the general tokenizer TOKAN (Habash, 2007) to produce Arabic Treebank (ATB) scheme tokenizations. TOKAN is used in the baseline system to generate tokenizations for MSA from morphologically disambiguated input in the same ATB scheme (see Section 5.1). The various generated forms are added in the lattices, which are then input to the SMT system. 5 5.1 Evaluation on Machine Translation Experimental Setup We use the open-source Moses toolkit (Koehn et al., 2007) to build two phrase-based SMT systems trained on two different data conditions: a mediumscale MSA-only system trained using a newswire (MSA-English) parallel text with 12M words on the Arabic side (LDC2007E103) and a large-scale MSA/DA-mixed system (64M words on the Arabic side) trained using several LDC corpora including some limited DA data. Both systems use a standard phrase-based architecture. The parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003). Phrase translations of up to 10 words are extracted in the Moses phrase table. The language model for both systems is trained on"
W11-2602,W04-3250,0,0.102708,"Missing"
W11-2602,D07-1005,0,0.0484701,"quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rulebased approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. This use of “resourcerich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Habash, 2008; Du et al., 2010). This paper presents results on a rule-based system to generate alternative paraphrases for DA OOV words and low frequency words to help improve SMT from highly dialectal Arabic to English. Our work is most similar to Sawaf (2010)’s approach to DA normalization into MSA, although we shy away from the term in our work since we do not produce a single MSA version of the input to pass on to MSAEnglish MT. Instead"
W11-2602,N04-4015,0,0.0845531,"Missing"
W11-2602,P11-1130,0,0.0478177,"similar to Sawaf (2010), we use a rule-based approach to model DA morphology. Our morphological analysis implementation is quite similar to the approach taken by Abo Bakr et al. (2008), which extend existing MSA analyzers through rules; however, unlike them, we are not interested in generating MSA per se, but rather to use it as a bridge to English MT. Our interest in OOV words is similar to Habash (2008), who compared multiple techniques for handling MSA OOVs; however, unlike him, we target dialectal phenomena and we use lattices as input to the SMT system. Also related is the recent work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-to-English SMT system. 3 Challenge and Motivation We are primarily interested in improving ArabicEnglish SMT on highly dialectal text. This particular type of text has many challenges. We discuss these challenges and motivate our research approach with an analysis of DA OOV terms in a state-of-theart SMT system. 3.1 Arabic Linguistic Challenges The Arabic language poses many challenges for NLP. Arabic is a morphologically complex language which includes ri"
W11-2602,J03-1002,0,0.00242943,"e then input to the SMT system. 5 5.1 Evaluation on Machine Translation Experimental Setup We use the open-source Moses toolkit (Koehn et al., 2007) to build two phrase-based SMT systems trained on two different data conditions: a mediumscale MSA-only system trained using a newswire (MSA-English) parallel text with 12M words on the Arabic side (LDC2007E103) and a large-scale MSA/DA-mixed system (64M words on the Arabic side) trained using several LDC corpora including some limited DA data. Both systems use a standard phrase-based architecture. The parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003). Phrase translations of up to 10 words are extracted in the Moses phrase table. The language model for both systems is trained on the English may be complicated to explain given the allotted space, as such we present only the functional description of the TRs. 15 side of the large bitext augmented with English Gigaword data. We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. For all systems, the English data is to"
W11-2602,P03-1021,0,0.00541515,"hrase-based architecture. The parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003). Phrase translations of up to 10 words are extracted in the Moses phrase table. The language model for both systems is trained on the English may be complicated to explain given the allotted space, as such we present only the functional description of the TRs. 15 side of the large bitext augmented with English Gigaword data. We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. For all systems, the English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer (Habash and Rambow, 2005) – v3.1 (Roth et al., 2008). The Arabic text is also Alif/Ya normalized (Habash, 2010). MADA-produced Arabic lemmas are used for word alignment. Results are presented in terms of BLEU (Papineni et al., 2002), NIST (Doddington, 2002) and METEOR (Banerjee and Lavie, 2005) metrics.4"
W11-2602,P02-1040,0,0.102281,"to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. For all systems, the English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer (Habash and Rambow, 2005) – v3.1 (Roth et al., 2008). The Arabic text is also Alif/Ya normalized (Habash, 2010). MADA-produced Arabic lemmas are used for word alignment. Results are presented in terms of BLEU (Papineni et al., 2002), NIST (Doddington, 2002) and METEOR (Banerjee and Lavie, 2005) metrics.4 However, all optimizations were done against the BLEU metric. All evaluation results are case insensitive. All of the systems we present use the lattice input format to Moses (Dyer et al., 2008), including the baselines which do not need them. We do not report on the non-lattice baselines, but in initial experiments we conducted, they did not perform as well as the degenerate lattice version. The Devtest Set Our devtest set consists of sentences containing at least one non-MSA segment (as annotated by LDC)5 in the Dev10"
W11-2602,2006.amta-papers.21,0,0.526982,"guage Processing, pages 10–21, c Edinburgh, Scotland, UK, July 27–31, 2011. 2011 Association for Computational Linguistics or other methods to collect word-pair lists have been explored. For example, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. This hybrid system consisted of a statistical system for tokenizing and tagging, and a rule-based system for constructing diacritized MSA sentences. Moreover, Al-Sabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. In the context of DA-to-English SMT, Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut the OOVs by half. Machine Translation for Closely Related Languages Using closely related languages has been shown to improve MT quality when resources are limited. Hajiˇc et al. (2000) argued that for very close languages, e.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic"
W11-2602,P08-2030,1,0.586591,"llow/quick-and-dirty solution compared to other more demanding efforts on building dialectal analyzers from scratch, such as the MAGEAD system (Habash and Rambow, 2006; Altantawy et al., 2011). 2. Analysis. Produce a set of alternative analyses for each word. 4.2.1 3. Transfer. Map each analysis into one or more target analyses. A DAM is built on the top of BAMA database (Buckwalter, 2004) as used in the A LMOR morphological analyzer/generator (Habash, 2007), which is the rule-based component of the M ADA system for morphological analysis and disambiguation of Arabic (Habash and Rambow, 2005; Roth et al., 2008). The A LMOR system presents analyses as lemma and feature-value pairs including clitics. The BAMA databases contain three tables of Arabic stems, complex prefixes and complex suffixes2 and three additional tables with constraints on matching them. MSA, according to the BAMA databases, has 1,208 complex prefixes and 940 complex suffixes, which correspond to 49 simple prefixes/proclitics and 177 simple suffixes/enclitics, respectively. The number of combinations in prefixes is a lot bigger than in suffixes, which explains the different proportions of complex affixes to simple affixes. We extend"
W11-2602,2010.amta-papers.5,0,0.240393,"d algorithm for online morpheme segmentation on DA that cut the OOVs by half. Machine Translation for Closely Related Languages Using closely related languages has been shown to improve MT quality when resources are limited. Hajiˇc et al. (2000) argued that for very close languages, e.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rulebased approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. This use of “resourcerich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Habash, 2008; Du et al., 2010). This paper presents results on a rule-based system to"
W11-2602,W07-0728,0,0.0193589,"mplex suffixes, which correspond to 49 simple prefixes/proclitics and 177 simple suffixes/enclitics, respectively. The number of combinations in prefixes is a lot bigger than in suffixes, which explains the different proportions of complex affixes to simple affixes. We extended the BAMA database through a 4. Generation. Generate properly tokenized forms of the target analyses. The core steps of analysis-transfer-generation are similar to generic transfer-based MT (Dorr et al., 1999). In essence our approach can be thought of as a mini-rule-based system that is used to hybridize an SMT system (Simard et al., 2007; Sawaf, 2010). 4.1 Selection The most obvious set of words to select for paraphrasing is the phrase-table OOV words. We identify them by comparing each word in the source text against all phrase-table singletons. Another set of words to consider includes low frequency words (DA or MSA), which are less likely to be associated with good phrase-table translations. We compute the frequency of such words against the original training data. We further extend the idea of frequency-based selection to typed-frequency selection in which we consider different frequency cut-offs for different 13 2 A DAM:"
W11-2602,N07-1061,0,0.0492477,"obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rulebased approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. This use of “resourcerich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Habash, 2008; Du et al., 2010). This paper presents results on a rule-based system to generate alternative paraphrases for DA OOV words and low frequency words to help improve SMT from highly dialectal Arabic to English. Our work is most similar to Sawaf (2010)’s approach to DA normalization into MSA, although we shy away from the term in our work since we do not produce a single MSA version of the input to pass on to MS"
W11-2602,P98-2238,0,0.376921,"ach of mining the web to build a DA-to-MSA lexicon. In the context of DA-to-English SMT, Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut the OOVs by half. Machine Translation for Closely Related Languages Using closely related languages has been shown to improve MT quality when resources are limited. Hajiˇc et al. (2000) argued that for very close languages, e.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rulebased approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. This use of “resourcerich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as mon"
W11-2602,N06-2051,0,0.0661983,"Missing"
W11-2602,C98-2233,0,\N,Missing
W11-2602,D08-1076,0,\N,Missing
W11-2912,W10-1404,0,0.0294327,"Missing"
W11-2912,W09-3036,0,0.0729375,"Missing"
W11-2912,H91-1060,0,0.224491,"Missing"
W11-2912,A00-2018,0,0.367551,"Missing"
W11-2912,dukes-habash-2010-morphological,1,0.839866,"nominal sentence, headed by the demonstrative pronoun, acts as the object of the verb ‘said’. The example sentence shown in Figures 1 and 2 illustrates several linguistic aspects of the Quranic Treebank which make it challenging for statistical parsing: rich morphology, phrase structure, and elision. We discuss various aspects of the Treebank next. 93 the basic unit instead of words improves parsing accuracy. However, in contrast to other Arabic treebanks that define their own segmentation schemes, morphological annotation in the Quranic Treebank closely follows segmentation rules from i’rāb (Dukes and Habash, 2010). In addition to part-of-speech, the grammar describes multiple features for each morpheme, including person, gender, number, verb mood, noun case and state. The treebank also includes roots and lemmas. A root is a sequence of three or four radicals that are used to group words with related derivational morphology. The lemma is a further subdivision that groups forms varying only in inflectional morphology (Habash, 2010). In our experiments, we consider how different combinations of these rich morphological features affect the accuracy of statistical parsing. Phrases: Most dependencies in the"
W11-2912,N06-1024,0,0.140175,"Missing"
W11-2912,W10-1412,0,0.046737,"Missing"
W11-2912,P08-1043,0,0.166517,"e treebank creators used a hybrid representation that supports relations between morphemes, as well as between phrases, clauses and sentences. The treebank also includes empty nodes for prodrop and for semantic elision. This representation presents several challenges to statistical parsing. Possible pipeline approaches include converting to pure constituency or to pure dependency as a preprocessing step. The alternative we pursue is using an integrated model to parse the hybrid representation. For other parsing tasks, integrated models have been shown to out-perform pipeline approaches, e.g., Goldberg and Tsarfaty (2008) integrate morphological and syntactic disambiguation for Hebrew, and report improved parsing performance. In the next section, we review the Treebank. In Section 3, we survey related work. Section 4 describes our parsing algorithm. We present our parsing approaches and evaluate in Sections 5 and 6, respectively. Abstract In this paper, we describe and compare two statistical parsing approaches for the hybrid dependency-constituency syntactic representation used in the Quranic Arabic Treebank (Dukes and Buckwalter, 2010). In our first approach, we apply a multi-step process in which we use a s"
W11-2912,P09-2056,1,0.822568,"ough traditional Arabic grammar developed independently from modern European linguistics, it uses the concepts of heads (āmil) and dependents (ma’mūl fī-hi). Along with Panini’s grammar for Classical Sanskrit, it is considered to be one of the origins of modern dependency grammar (Owens, 1988; Bohas et al., 1990). Morphemes: The basic unit of analysis in traditional Arabic grammar is the morphological segment. Compound word-forms in Classical Arabic are tokenized into independent grammatical units. This agrees with other recent treebanking efforts for MSA such as the Columbia Arabic Treebank (Habash and Roth, 2009), the Prague Arabic Dependency Treebank (Smrž, et al., 2008), and the Penn Arabic Treebank (Maamouri et al., 2004). This also compares with recent parsing work for other morphological rich languages. For example, Eryiğit et al. (2008) show that for Turkish using groups of morphemes as In this verse, ‘said’ is a perfective verb, whose subject is an elided pronoun of the form ‘he’. The noun ‘lord’ is in the nominative case and is the predicate of the demonstrative pronoun ‘this’. The suffixed pronoun ‘my’ attached to the noun is a possessive clitic. The nominal sentence, headed by the demonstrat"
W11-2912,D07-1097,0,0.0213956,"pure dependency parsing: SHIFT, REDUCE, LEFT and RIGHT. 3. The parser’s output is pure dependency. We recover the hybrid representation by reversing the transformations in step 1. The size of the unconverted dataset is 50,955 tokens, including 3,775 empty categories. The dependency graphs in the treebank contain 9,847 phrase nodes and 38,642 edges. After conversion, all phrase nodes and empty categories were removed, resulting in 47,220 tokens and a total of 34,849 edges. The number of edges dropped due to collapsing edges between empty categories. For conversion, we use a similar process to Hall et al. (2007, 2008)'s approach for German and Swedish, but adapt this to the representation used for traditional Arabic grammar. During the conversion process, we apply graph transformations to encode information about phrase structure and elision: Phrases: Let p = (ti, tj) be a phrase node in the hybrid graph covering the terminal nodes from ti to tj inclusively. The conversion for the phrase node p is based on the observation that the phrase covers a subgraph with root ω0. If p is a dependent node with edge E, head h, and dependency relation r, we remove E and p and add a new edge E' with dependent ω0,"
W11-2912,W08-1007,0,0.0181815,"o predict the next operation, given the feature vector associated with the first few nodes at the top of the queue and stack. Feature selection is described in more detail in the next section. We apply the standard technique of binarization of input features in the training data, so that a single symbolic feature is represented using many binary predicates (Yamada and Matsumoto, 2003). To reduce learning time, the training set is partitioned using the part-of-speech at the top of the stack, and one statistical classifier is trained for each part-of-speech. We use the same LIBSVM settings that Hall and Nivre (2008) use for parsing the German TIGER and TüBa-D/Z treebanks: γ = 0.2 and r = 0 for kernel parameters, C = 0.5 for penalty and ε = 1 for termination. We also use the same quadratic kernel: 1. SHIFT reads the next token from the queue and moves this to the top of the stack: Q' = (q2, …, qA) and S' = (q1, s1, …, sB). 2. REDUCE pops the stack: S' = (s2, …, sB). 3. LEFT adds an edge to the graph, with s1 as the head node and s2 as the dependent node. 4. RIGHT adds an edge to the graph, with s2 as the head node and s1 as the dependent node. 5. REDUCE2 pops the second node on the stack: S' = (s1, s3, …,"
W11-2912,W07-2444,0,0.0174035,"pure dependency parsing: SHIFT, REDUCE, LEFT and RIGHT. 3. The parser’s output is pure dependency. We recover the hybrid representation by reversing the transformations in step 1. The size of the unconverted dataset is 50,955 tokens, including 3,775 empty categories. The dependency graphs in the treebank contain 9,847 phrase nodes and 38,642 edges. After conversion, all phrase nodes and empty categories were removed, resulting in 47,220 tokens and a total of 34,849 edges. The number of edges dropped due to collapsing edges between empty categories. For conversion, we use a similar process to Hall et al. (2007, 2008)'s approach for German and Swedish, but adapt this to the representation used for traditional Arabic grammar. During the conversion process, we apply graph transformations to encode information about phrase structure and elision: Phrases: Let p = (ti, tj) be a phrase node in the hybrid graph covering the terminal nodes from ti to tj inclusively. The conversion for the phrase node p is based on the observation that the phrase covers a subgraph with root ω0. If p is a dependent node with edge E, head h, and dependency relation r, we remove E and p and add a new edge E' with dependent ω0,"
W11-2912,J93-2004,0,0.0379825,"Missing"
W11-2912,W10-1402,1,0.921395,"two approaches lead to different machine learning problems. In the first experiment, the parser has to learn more complex edge labels. In the second experiment, there are fewer classes for classification, and phrase structure and elision are integrated directly into the parsing process. 5.3 POS MORPH6 MORPH9 POS Y Y Y Y Y PHRASE Y Y Y Y Y VOICE - Y Y Y Y MOOD - Y Y Y Y CASE - Y Y Y Y STATE - Y Y Y Y PRONTYPE - - Y Y Y SEGTYPE - - Y Y Y COPULA - - Y Y Y LEMMA - - - Y Y PERSON - - - - Y GENDER - - - - Y NUMBER - - - - Y LEMMA PHI Figure 6: Morphological features used for parsing. In comparison, Marton et al. (2010) show that for modern Arabic using predicted features or gold-standard morphological features for parsing achieves similar results. Our different feature sets are described below: POS: This baseline feature set includes the part-of-speech and phrase tags for the selected nodes. MORPH6: This set adds the core morphological features that might help with parsing, based on domain knowledge of traditional Arabic grammar: VOICE, MOOD, CASE and STATE. State is either not-specified, definite (for the Arabic definite article al- prefix) or indefinite (for tanween). MORPH9: Adds a further three morpholo"
W11-2912,W06-2932,0,0.0872835,"Missing"
W11-2912,W03-3023,0,0.0580634,"f actions required to construct the graph. For machine learning, we use support vector machines, implemented by the Java version of LIBSVM (Chang and Lin, 2001). For each step in the parsing programs, a collection of SVM classifiers learn to predict the next operation, given the feature vector associated with the first few nodes at the top of the queue and stack. Feature selection is described in more detail in the next section. We apply the standard technique of binarization of input features in the training data, so that a single symbolic feature is represented using many binary predicates (Yamada and Matsumoto, 2003). To reduce learning time, the training set is partitioned using the part-of-speech at the top of the stack, and one statistical classifier is trained for each part-of-speech. We use the same LIBSVM settings that Hall and Nivre (2008) use for parsing the German TIGER and TüBa-D/Z treebanks: γ = 0.2 and r = 0 for kernel parameters, C = 0.5 for penalty and ε = 1 for termination. We also use the same quadratic kernel: 1. SHIFT reads the next token from the queue and moves this to the top of the stack: Q' = (q2, …, qA) and S' = (q1, s1, …, sB). 2. REDUCE pops the stack: S' = (s2, …, sB). 3. LEFT a"
W11-2912,J03-4003,0,\N,Missing
W11-2912,J08-4010,0,\N,Missing
W11-2912,J08-3003,0,\N,Missing
W11-2912,D07-1096,0,\N,Missing
W11-2912,dukes-etal-2010-syntactic,1,\N,Missing
W11-4416,altantawy-etal-2010-morphological,1,0.906756,"logy, the finite-state transducers (FSTs) tend to become extremely large, causing a significant deterioration in response time. Proceedings of the 9th International Workshop on Finite State Methods and Natural Language Processing, pages 116–124, c Blois (France), July 12-15, 2011. 2011 Association for Computational Linguistics In this paper, we present a solution to the modeling of rich morphologies that combines the best of these two approaches. In previous work, we presented M AGEAD, a multi-tier finite-state implementation of Arabic morphology (Habash et al., 2005; Habash and Rambow, 2006; Altantawy et al., 2010). We improve the speed by automatically converting our FST-based M AGEAD system to a precompiled tabular implementation that preserves all of the rich linguistic information used in M AGEAD’s design. The new system, M AGEAD -E XPRESS is not only much faster and smaller in size, but it also still allows linguistically based abstract changes and updates in its model. Furthermore, M AGEAD E XPRESS produces complete linguistic analyses that include intermediate levels of representation, an advantage M AGEAD does not have readily in its output. The only disadvantage of M AGEAD -E XPRESS is its inab"
W11-4416,W00-1801,0,0.0388487,"hat it has particle proclitic l ‘for/that’; and that it has a pronominal 4.1 M AGEAD’s Representation of Linguistic enclitic that is 3rd person masculine singular. Knowledge 3 Related Work There has been a considerable amount of work on Arabic morphological analysis; for an overview, see (Al-Sughaiyer and Al-Kharashi, 2004). The first large-scale implementation of Arabic morphology within the constraints of finite-state methods is that of Beesley et al. (1989) (the “Xerox system”) with a ‘detouring’ mechanism for access to multiple lexica, which gives rise to other works by Beesley (1998) and Beesley and Karttunen (2000) and, independently, by Buckwalter (2004). Unlike the Xerox system, the Buckwalter Arabic Morphological Analyzer (BAMA) uses a hard-coded tabular approach with a focus on analysis into surface morphemes (discussed above). Buckwalter’s work has been since extended to handle generation as well as the lexeme-and-features representation (A L MORGEANA , (Habash, 2007)) and functional morphology in Arabic (ELIXIR, (Smrž, 2007)). Finite-state handling of templatic morphology has been demonstrated using a variety of techniques for several Semitic languages other than Arabic including Akkadian (Kataja"
W11-4416,E09-1036,0,0.0191382,"ard-coded tabular approach with a focus on analysis into surface morphemes (discussed above). Buckwalter’s work has been since extended to handle generation as well as the lexeme-and-features representation (A L MORGEANA , (Habash, 2007)) and functional morphology in Arabic (ELIXIR, (Smrž, 2007)). Finite-state handling of templatic morphology has been demonstrated using a variety of techniques for several Semitic languages other than Arabic including Akkadian (Kataja and Koskenniemi, 1988), Syriac (Kiraz, 2000), Hebrew (Yona and Wintner, 2005), Amharic (Amsalu and Gibbon, 2005), and Tigrinya (Gasser, 2009). Kay (1987) proposes a framework for handling templatic morphology in which each templatic morpheme is assigned a tape in a multi-tape finite state machine, with an additional tape for the surface form. Kiraz (2000) extends Kay’s approach and implements a multi-tape system for Modern Standard Arabic (MSA) and Syriac. The M AGEAD system (Habash et al., 2005; Habash and Rambow, 2006) extended Kiraz’s work 118 M AGEAD relates (bidirectionally) a lexeme and a set of feature-value pairs to a surface word form through a sequence of transformations. In a generation perspective, the features are tran"
W11-4416,P06-1086,1,0.948957,"its two poles: on one end, very abstract and linguistically rich representations and rules (often based on particular theories of morphology) are used to derive surface forms; while on the other end, simple and shallow techniques focus on efficient search in a space of precompiled (tabulated) 116 solutions. The first type is typically implemented using finite-state technology and can be at many different degrees of sophistication and detail. An example of this type of implementation is the M AGEAD (Morphological Analysis and GEneration for Arabic and its Dialects) system (Habash et al., 2005; Habash and Rambow, 2006). This system, which we use as starting point in this paper, compiles abstract high-level linguistic information of different types to finite state machinery. The second type is typically not implemented in finite-state technology. Examples include the Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2004) and its extension A LMORGEANA (Habash, 2007). These systems do not represent the morphemic, phonological and orthographic rules directly at all, and instead compile their effect into the lexicon itself. Numerous intermediate points exist between these two extremes (e.g., (Smrž, 2"
W11-4416,W05-0703,1,0.937932,"is characterized by its two poles: on one end, very abstract and linguistically rich representations and rules (often based on particular theories of morphology) are used to derive surface forms; while on the other end, simple and shallow techniques focus on efficient search in a space of precompiled (tabulated) 116 solutions. The first type is typically implemented using finite-state technology and can be at many different degrees of sophistication and detail. An example of this type of implementation is the M AGEAD (Morphological Analysis and GEneration for Arabic and its Dialects) system (Habash et al., 2005; Habash and Rambow, 2006). This system, which we use as starting point in this paper, compiles abstract high-level linguistic information of different types to finite state machinery. The second type is typically not implemented in finite-state technology. Examples include the Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2004) and its extension A LMORGEANA (Habash, 2007). These systems do not represent the morphemic, phonological and orthographic rules directly at all, and instead compile their effect into the lexicon itself. Numerous intermediate points exist between these tw"
W11-4416,E87-1002,0,0.537265,"ar approach with a focus on analysis into surface morphemes (discussed above). Buckwalter’s work has been since extended to handle generation as well as the lexeme-and-features representation (A L MORGEANA , (Habash, 2007)) and functional morphology in Arabic (ELIXIR, (Smrž, 2007)). Finite-state handling of templatic morphology has been demonstrated using a variety of techniques for several Semitic languages other than Arabic including Akkadian (Kataja and Koskenniemi, 1988), Syriac (Kiraz, 2000), Hebrew (Yona and Wintner, 2005), Amharic (Amsalu and Gibbon, 2005), and Tigrinya (Gasser, 2009). Kay (1987) proposes a framework for handling templatic morphology in which each templatic morpheme is assigned a tape in a multi-tape finite state machine, with an additional tape for the surface form. Kiraz (2000) extends Kay’s approach and implements a multi-tape system for Modern Standard Arabic (MSA) and Syriac. The M AGEAD system (Habash et al., 2005; Habash and Rambow, 2006) extended Kiraz’s work 118 M AGEAD relates (bidirectionally) a lexeme and a set of feature-value pairs to a surface word form through a sequence of transformations. In a generation perspective, the features are translated to ab"
W11-4416,2010.jeptalnrecital-long.29,1,0.832216,"Missing"
W11-4416,J00-1006,0,0.913933,"er (2004). Unlike the Xerox system, the Buckwalter Arabic Morphological Analyzer (BAMA) uses a hard-coded tabular approach with a focus on analysis into surface morphemes (discussed above). Buckwalter’s work has been since extended to handle generation as well as the lexeme-and-features representation (A L MORGEANA , (Habash, 2007)) and functional morphology in Arabic (ELIXIR, (Smrž, 2007)). Finite-state handling of templatic morphology has been demonstrated using a variety of techniques for several Semitic languages other than Arabic including Akkadian (Kataja and Koskenniemi, 1988), Syriac (Kiraz, 2000), Hebrew (Yona and Wintner, 2005), Amharic (Amsalu and Gibbon, 2005), and Tigrinya (Gasser, 2009). Kay (1987) proposes a framework for handling templatic morphology in which each templatic morpheme is assigned a tape in a multi-tape finite state machine, with an additional tape for the surface form. Kiraz (2000) extends Kay’s approach and implements a multi-tape system for Modern Standard Arabic (MSA) and Syriac. The M AGEAD system (Habash et al., 2005; Habash and Rambow, 2006) extended Kiraz’s work 118 M AGEAD relates (bidirectionally) a lexeme and a set of feature-value pairs to a surface wo"
W11-4416,W05-0702,0,0.0179376,"Xerox system, the Buckwalter Arabic Morphological Analyzer (BAMA) uses a hard-coded tabular approach with a focus on analysis into surface morphemes (discussed above). Buckwalter’s work has been since extended to handle generation as well as the lexeme-and-features representation (A L MORGEANA , (Habash, 2007)) and functional morphology in Arabic (ELIXIR, (Smrž, 2007)). Finite-state handling of templatic morphology has been demonstrated using a variety of techniques for several Semitic languages other than Arabic including Akkadian (Kataja and Koskenniemi, 1988), Syriac (Kiraz, 2000), Hebrew (Yona and Wintner, 2005), Amharic (Amsalu and Gibbon, 2005), and Tigrinya (Gasser, 2009). Kay (1987) proposes a framework for handling templatic morphology in which each templatic morpheme is assigned a tape in a multi-tape finite state machine, with an additional tape for the surface form. Kiraz (2000) extends Kay’s approach and implements a multi-tape system for Modern Standard Arabic (MSA) and Syriac. The M AGEAD system (Habash et al., 2005; Habash and Rambow, 2006) extended Kiraz’s work 118 M AGEAD relates (bidirectionally) a lexeme and a set of feature-value pairs to a surface word form through a sequence of tra"
W11-4416,C88-1064,0,\N,Missing
W11-4416,P00-1025,0,\N,Missing
W11-4416,W98-1007,0,\N,Missing
W12-1514,P11-2062,1,0.830101,"average (Habash, 2010). The Penn Arabic Treebank (PATB) tokenization scheme (Maamouri et al., 2004), which we use in all our experiments, separates all clitics except for the determiner clitic Al+ (D ET). As such we consider the D ET as an additional morphological feature. Arabic has complex morpho-syntactic agreement rules in terms of G EN, N UM and definiteness. Adjectives agree with nouns in G EN and N UM but plural irrational nouns exceptionally take feminine singular adjectives. Moreover, verbs agree with subjects in G EN only in VSO order while they agree in G EN and N UM in SVO order (Alkuhlani and Habash, 2011). The D ET in Arabic is used to distinguish different syntactic constructions such as the possessive or adjectival modification. These agreement rules make the generation of correctly inflected forms in context a challenging task. 4 Approach In this section, we discuss our approach in generating Arabic words from Arabic lemmas (L EMMA) using a pipeline of three steps. 1. (Optional) Morphology Prediction of linguistic features to inflect L EMMAs. 2 The Arabic NLP tools we use in this paper do not model all templatic inflectional realizations. 91 Tokens w+ s+ yktbwn +hA POS conj fut part verb pr"
W12-1514,E12-1069,1,0.883286,"Missing"
W12-1514,P08-2039,0,0.348034,"tion of inflected Arabic tokens from L EMMAs and any subset of Arabic linguistic features. 3. Detokenization of inflected Arabic tokens into surface Arabic words. Morphology generation is the main contribution of this paper which in addition to detokenization represents an end-to-end inflection generator. The morphology prediction step is an optional step that complements the whole process by enriching the input of the morphology generation step with one or more predicted morphological features. We follow numerous previously published efforts on the value of tokenization for Arabic NLP tasks (Badr et al., 2008; El Kholy and Habash, 2010). We use the best performing tokenization scheme (PATB) in machine translation in all our experiments and focus on the question of how to generate Arabic inflected words from L EMMAs and features. Figure 1 shows an example of a tokenized word and its decomposition into a L EMMA and morphological features. Morphology Prediction This optional step takes a sequence of L EMMAs and tries to enrich them by predicting one or more morphological features. It is implemented using a supervised discriminative learning model, namely Conditional Random Fields (CRF) (Lafferty et a"
W12-1514,P11-1004,0,0.141391,"d. Related Work In the context of morphological generation for MT, the state-of-the-art factored machine translation approach models morphology using generation factors in the translation process (Koehn et al., 2007). One of the limitations of factored models is that generation is based on the word level not the phrase level and the context is only captured through a language model. Minkov et al. (2007) and Toutanova et al. (2008) model translation and morphology independently for English-Arabic and English-Russian MT. They use a maximum entropy model to predict inflected word forms directly. Clifton and Sarkar (2011) use a similar approach for English-Finnish MT where they predict morpheme sequences. Unlike both approaches, we generate the word forms from the deeper representation of lemmas and features. As for using SMT in generation, there are many previous efforts. Wong and Mooney (2007) use SMT methods for tactical NLG. They learn through SMT to map meaning representations to natural language. Quirk et al. (2004) apply SMT tools to generate paraphrases of input sentences in the same language. Both of these efforts target English, a morphologically poor language. Our work is conceptually closer to Wong"
W12-1514,2010.jeptalnrecital-long.29,1,0.933026,"Missing"
W12-1514,2012.eamt-1.6,1,0.824803,"Missing"
W12-1514,P05-1071,1,0.851635,"Missing"
W12-1514,P07-2045,0,0.00464741,"tion Evaluation Setup All of the training data we use is available from the Linguistic Data Consortium (LDC).3 For SMT training and language modeling (LM), we use 200M words from the Arabic Gigaword corpus (LDC2007T40). We use 5-grams for all LMs implemented using the SRILM toolkit (Stolcke, 2002). MADA+TOKAN (Habash and Rambow, 2005; Habash et al., 2009) is used to preprocess the Arabic text for generation and language modeling. MADA+TOKAN tokenizes, lemmatizes and selects all morphological features in context. All generation experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). The decoding weight optimization is done using a set of 300 Arabic sentences from the 2004 NIST MT evaluation test set (MT04). The tuning is based on tokenized Arabic without detokenization. We use a maximum phrase length of size 4. We report results on the Arabic side of the 2005 NIST MT evaluation set (MT05), our development set. We use the Arabic side of MT06 NIST data set for blind test. We evaluate using BLEU-1 and BLEU-4 (Papineni et al., 2002). BLEU is a precision-based evaluation metric commonly used in MT research. Given the way we define our generation task to exclude reordering an"
W12-1514,P07-1017,0,0.178537,"Missing"
W12-1514,P02-1040,0,0.0840057,"s, lemmatizes and selects all morphological features in context. All generation experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). The decoding weight optimization is done using a set of 300 Arabic sentences from the 2004 NIST MT evaluation test set (MT04). The tuning is based on tokenized Arabic without detokenization. We use a maximum phrase length of size 4. We report results on the Arabic side of the 2005 NIST MT evaluation set (MT05), our development set. We use the Arabic side of MT06 NIST data set for blind test. We evaluate using BLEU-1 and BLEU-4 (Papineni et al., 2002). BLEU is a precision-based evaluation metric commonly used in MT research. Given the way we define our generation task to exclude reordering and word deletion/addition, BLEU1 can be interpreted as a measure of word accuracy. BLEU-4 is the geometric mean of unigram, bigram, trigram and 4-gram precision.4 Since Arabic text 3 http://www.ldc.upenn.edu n-gram precision is the number of test n-word sequences that appear in the reference divided by the number of all possible n-word sequences in the test. 4 is generally written without diacritics, we evaluate on undiacritized text only. In the future"
W12-1514,W04-3219,0,0.038731,"tanova et al. (2008) model translation and morphology independently for English-Arabic and English-Russian MT. They use a maximum entropy model to predict inflected word forms directly. Clifton and Sarkar (2011) use a similar approach for English-Finnish MT where they predict morpheme sequences. Unlike both approaches, we generate the word forms from the deeper representation of lemmas and features. As for using SMT in generation, there are many previous efforts. Wong and Mooney (2007) use SMT methods for tactical NLG. They learn through SMT to map meaning representations to natural language. Quirk et al. (2004) apply SMT tools to generate paraphrases of input sentences in the same language. Both of these efforts target English, a morphologically poor language. Our work is conceptually closer to Wong and Mooney (2007), except that we focus on the question of morphological generation and our approach includes an optional feature prediction component. In a related publication, we integrate our generation model as part of end-to-end English-Arabic SMT (El Kholy and Habash, 2012). In that work, we make use of English features in the Arabic morphology prediction component, e.g., English POS and parse tree"
W12-1514,P08-1059,0,0.127041,"Missing"
W12-1514,N07-1022,0,0.0289725,"based on the word level not the phrase level and the context is only captured through a language model. Minkov et al. (2007) and Toutanova et al. (2008) model translation and morphology independently for English-Arabic and English-Russian MT. They use a maximum entropy model to predict inflected word forms directly. Clifton and Sarkar (2011) use a similar approach for English-Finnish MT where they predict morpheme sequences. Unlike both approaches, we generate the word forms from the deeper representation of lemmas and features. As for using SMT in generation, there are many previous efforts. Wong and Mooney (2007) use SMT methods for tactical NLG. They learn through SMT to map meaning representations to natural language. Quirk et al. (2004) apply SMT tools to generate paraphrases of input sentences in the same language. Both of these efforts target English, a morphologically poor language. Our work is conceptually closer to Wong and Mooney (2007), except that we focus on the question of morphological generation and our approach includes an optional feature prediction component. In a related publication, we integrate our generation model as part of end-to-end English-Arabic SMT (El Kholy and Habash, 201"
W12-2301,W11-4416,1,0.847621,"ological and orthographic rules directly, and instead compile their effect into the lexicon itself, which consists of three tables for prefixes, stems and suffixes and their compatibilities. A prefix or suffix in this approach is a string consisting of all the word’s prefixes and suffixes, respectively, as a single unit (including null affix sequences). During analysis, all possible splits of a word into compatible prefix-stem-suffix combination are explored. More details are discussed in Section 4.5. Numerous intermediate points exist between these two extremes (e.g., ElixirFM (Smrž, 2007)). Altantawy et al. (2011) describe a method for converting a linguistically complex and abstract implementation of Arabic verbs in finite-state machinery into a simple precompiled tabular representation. The approach we follow in this paper is closer to the second type. We start with a lexicon of inflected forms and derive from it a tabular representation compatible with the SAMA system for MSA. However, as we do this, we design the tables and extend them in ways that capture generalizations and extend orthographic coverage. 3.2 Approaches to Arabic Morphology There has been a considerable amount of work on Arabic mor"
W12-2301,P05-1071,1,0.876139,"ces an average of 12 analyses per MSA word. Moreover, some letters in Arabic are often spelled inconsistently which leads to an increase in both sparsity (multiple forms of the same word) and ambiguity (same form corresponding to multiple words), e.g., variants of the Hamzated Alif, @ Â or ˇ are often written without their Hamza ( Z ’): @ A. @ A, and the Alif-Maqsura (or dot-less Ya) ø ý and the regular dotted Ya ø y are often used interchangeably in the word-final position (Buckwalter, 2007). Arabic complex morphology and ambiguity are handled using tools for disambiguation and tokenization (Habash and Rambow, 2005; Diab et al., 2007). 2 Arabic orthographic transliteration is presented in the HSB scheme (Habash et al., 2007): (in alphabetical order) P     ¨ ¨ ¬   È Ð à è ð ø @ H. H H h. h p X XP ˇ ς γ f q k l m n hw y A b t θ j H x dðr z s š S D T D ˇ ¯  and the additional letters: ’ Z, Â @, A @, A @, wˆ ð&apos;, yˆ Zø&apos;, ~ è, ý ø. 2 We distinguish between morphological analysis, whose target is to produce all possible morphological/POS readings of a word out of context, and morphological disambiguation, which attempts to tag the word in context (Habash and Rambow, 2005). The work presented in thi"
W12-2301,P06-1086,1,0.81929,": words can be spelled as pronounced or etymologically in their related MSA form, e.g., H . Y» kidb or H. Y» kiðb. Some clitics have multiple common forms, e.g., the future particle h Ha appears as a separate word or as a proclitic + h/+ë Ha+/ha+, reflecting different pronunciations. The different spellings may add some confusion, e.g., ñJ.J» ktbw may be @ñJ.J» katabuwA ‘they wrote’ or éJ.J» katabuh ‘he wrote it’. Finally, shortened long vowels can be spelled long or short, e.g., Aê¯A/ Aê® šAf+hA/šf+hA ‘he saw her’. 3 3.1 Related Work tion and detail (Beesley et al., 1989; Kiraz, 2000; Habash and Rambow, 2006). The second type is typically implemented using hash-tables with a simple search algorithm. Examples include the Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2004), its Standard Arabic Morphological Analyzer (SAMA) (Graff et al., 2009) incarnation, and their generation-oriented extension, ALMOR (Habash, 2007). These systems do not represent the morphemic, phonological and orthographic rules directly, and instead compile their effect into the lexicon itself, which consists of three tables for prefixes, stems and suffixes and their compatibilities. A prefix or suffix in this app"
W12-2301,habash-etal-2012-conventional,1,0.500363,"processing, e.g., phonological lexicons (Kilany et al., 2002). In this paper we present the Columbia Arabic Language and dIalect Morphological Analyzer (CALIMA) for EGY.1 We built this tool by extending an existing resource for EGY, the Egyptian Colloquial Arabic Lexicon (ECAL) (Kilany et al., 2002). CALIMA is a linguistically accurate, largescale morphological analyzer. It follows the part-ofspeech (POS) guidelines used by the Linguistic Data Consortium for EGY (Maamouri et al., 2012b). It accepts multiple orthographic variants and normalizes them to CODA, a conventional orthography for DA (Habash et al., 2012). The rest of the paper is structured as follows: Section 2 presents relevant motivating linguistic facts. Section 3 discusses related work. Section 4 details the steps taken to create CALIMA starting with ECAL. Section 5 presents a preliminary evaluation and statistics about the coverage of CALIMA. Finally, Section 6 outlines future plans and directions. 1 Although we focus on Egyptian Arabic in this paper, the CALIMA name will be used in the future to cover a variety of dialects. 1 Proceedings of the Twelfth Meeting of the Special Interest Group on Computational Morphology and Phonology (SIG"
W12-2301,J00-1006,0,0.0641071,"n responsible: words can be spelled as pronounced or etymologically in their related MSA form, e.g., H . Y» kidb or H. Y» kiðb. Some clitics have multiple common forms, e.g., the future particle h Ha appears as a separate word or as a proclitic + h/+ë Ha+/ha+, reflecting different pronunciations. The different spellings may add some confusion, e.g., ñJ.J» ktbw may be @ñJ.J» katabuwA ‘they wrote’ or éJ.J» katabuh ‘he wrote it’. Finally, shortened long vowels can be spelled long or short, e.g., Aê¯A/ Aê® šAf+hA/šf+hA ‘he saw her’. 3 3.1 Related Work tion and detail (Beesley et al., 1989; Kiraz, 2000; Habash and Rambow, 2006). The second type is typically implemented using hash-tables with a simple search algorithm. Examples include the Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2004), its Standard Arabic Morphological Analyzer (SAMA) (Graff et al., 2009) incarnation, and their generation-oriented extension, ALMOR (Habash, 2007). These systems do not represent the morphemic, phonological and orthographic rules directly, and instead compile their effect into the lexicon itself, which consists of three tables for prefixes, stems and suffixes and their compatibilities. A pr"
W12-2301,maamouri-etal-2006-developing,1,0.66763,"hamed et al. (2012) annotated a collection of EGY for morpheme boundaries and used this data to develop an EGY tokenizer. Although these efforts model DA directly, they remain at a shallow level of representation (undiacritized surface morph segmentation). We use the ECAL lexicon as a base for CALIMA and extend it further. Some of the expansion techniques we used are inspired by previous solutions (Abo Bakr et al., 2008; Salloum and Habash, 2011). For the morphological representation, we follow the Linguistic Data Consortium guidelines which extend the MSA POS guidelines to multiple dialects (Maamouri et al., 2006; Maamouri et al., 2012b). To address the problem of orthographic 4 variations, we follow the proposal by Habash et al. (2012) who designed a conventional orthography for DA (or CODA) for NLP applications in the CALIMA databases. However, to handle input in a variety of spellings, we extend our analyzer to accept non-CODA-compliant word forms but map them only to CODA-compliant forms as part of the analysis. 4 Approach We describe next the various steps for creating CALIMA starting with ECAL. The details of the approach are to some degree dependent on this unique resource; however, some aspect"
W12-2301,mohamed-etal-2012-annotating,0,0.315184,"tically rich representations and morphological rules are used to derive surface forms; while on the other end, simple and shallow techniques focus on efficient search in a space of precompiled (tabulated) solutions. The first type is typically implemented using finite-state technology and can be at many different degrees of sophistica3 Arabic Dialect Morphology The majority of the work discussed above has focused on MSA, while only a few efforts have targeted DA morphology (Kilany et al., 2002; Riesa and Yarowsky, 2006; Habash and Rambow, 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Mohamed et al., 2012). These efforts generally fall in two camps. First are solutions that focus on extending MSA tools to cover DA phenomena. For example, both Abo Bakr et al. (2008) and Salloum and Habash (2011) extended the BAMA/SAMA databases (Buckwalter, 2004; Graff et al., 2009) to accept DA prefixes and suffixes. Both of these efforts were interested in mapping DA text to some MSA-like form; as such they did not model DA linguistic phenomena, e.g., the ADAM system (Salloum and Habash, 2011) outputs only MSA diacritics that are discarded in later processing. The second camp is interested in modeling DA direc"
W12-2301,2006.amta-papers.21,0,0.737202,"mputational morphology as being on a continuum with two poles: on one end, very abstract and linguistically rich representations and morphological rules are used to derive surface forms; while on the other end, simple and shallow techniques focus on efficient search in a space of precompiled (tabulated) solutions. The first type is typically implemented using finite-state technology and can be at many different degrees of sophistica3 Arabic Dialect Morphology The majority of the work discussed above has focused on MSA, while only a few efforts have targeted DA morphology (Kilany et al., 2002; Riesa and Yarowsky, 2006; Habash and Rambow, 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Mohamed et al., 2012). These efforts generally fall in two camps. First are solutions that focus on extending MSA tools to cover DA phenomena. For example, both Abo Bakr et al. (2008) and Salloum and Habash (2011) extended the BAMA/SAMA databases (Buckwalter, 2004; Graff et al., 2009) to accept DA prefixes and suffixes. Both of these efforts were interested in mapping DA text to some MSA-like form; as such they did not model DA linguistic phenomena, e.g., the ADAM system (Salloum and Habash, 2011) outputs only MSA diac"
W12-2301,W11-2602,1,0.702117,"very abstract and linguistically rich representations and morphological rules are used to derive surface forms; while on the other end, simple and shallow techniques focus on efficient search in a space of precompiled (tabulated) solutions. The first type is typically implemented using finite-state technology and can be at many different degrees of sophistica3 Arabic Dialect Morphology The majority of the work discussed above has focused on MSA, while only a few efforts have targeted DA morphology (Kilany et al., 2002; Riesa and Yarowsky, 2006; Habash and Rambow, 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Mohamed et al., 2012). These efforts generally fall in two camps. First are solutions that focus on extending MSA tools to cover DA phenomena. For example, both Abo Bakr et al. (2008) and Salloum and Habash (2011) extended the BAMA/SAMA databases (Buckwalter, 2004; Graff et al., 2009) to accept DA prefixes and suffixes. Both of these efforts were interested in mapping DA text to some MSA-like form; as such they did not model DA linguistic phenomena, e.g., the ADAM system (Salloum and Habash, 2011) outputs only MSA diacritics that are discarded in later processing. The second camp is interest"
W13-2301,P11-2062,1,0.825864,"s, resources, and heuristics, e.g., morphological analyzers, language models, annotated data and edit-distance measures, respectively (Kukich, 1992; Oflazer, 1996; Shaalan et al., 2003; Hassan et al., 2008; Kolak and Resnik, 2002; Magdy and Darwish, 2006). Our work is different from these approaches in that it extends beyond spelling of word forms to deeper annotations. However, we use some of these techniques to correct not just the words, but also malformed POS tags. A number of efforts exist on treebank enrichment for many languages including Arabic (Palmer et al., 2008; Hovy et al., 2006; Alkuhlani and Habash, 2011; Alkuhlani et al., 2013). Our morphological extension effort is similar to Alkuhlani et al. (2013)’s work except that they start with tokenizations, reduced POS tags and dependency trees and extend them to full morphological information. There has been a lot of work on Arabic POS tagging and morphological disambiguation (Habash and Rambow, 2005; Smith et al., 2005; Hajiˇc et al., 2005; Habash, 2010; Habash et al., 2013). The work by Habash et al. (2013) uses one of the resources we improve on in this paper. In their work, they simply attempt to “synchronize” unknown/malformed annotations with"
W13-2301,N13-1049,1,0.895093,"Missing"
W13-2301,N13-1066,1,0.784259,"currently considers words out of context, such a correction is not preferred because it requires more character edits (see Figure 2). We acknowledge this to be a limitation and plan to address it in the future. 11 The Levenshtein edit distance is defined as the minimum number of single-character edits (insertion, deletion and substitution) required to change one string into the other. For Arabic words and morphemes, we modify the cost of substitutions involving two phonologically or orthographically similar letters to count as half edits. We acquire the list of such letter substitutions from Eskander et al. (2013), who report them as the most frequent source of errors in Egyptian Arabic orthography. We map all diacritic-only morphemes to empty morphemes in both ways at a cost of half edit also. For POS tag edit distance, we use the standard definition of Levenshtein edit distance. Edit cost is an area where a lot of tuning could be done and we plan to explore it in the future. R AW Analysis D IAC M ORPH POS L EM Incorrect Annotation hayiÂaj∼iluh ha+yi+Âaj∼il+uh ñÊg. AJ ë hyAjlw Correct Annotation HayiÂaj∼iluwA Ha+yi+Âaj∼il+uwA FUT_PART+IV3MS+IV+IVSUFF_SUBJ:P FUT_PART+IV3P+IV+IVSUFF_SUBJ:P Âaj∼ill1 Âaj∼"
W13-2301,P05-1071,1,0.660451,"to deeper annotations. However, we use some of these techniques to correct not just the words, but also malformed POS tags. A number of efforts exist on treebank enrichment for many languages including Arabic (Palmer et al., 2008; Hovy et al., 2006; Alkuhlani and Habash, 2011; Alkuhlani et al., 2013). Our morphological extension effort is similar to Alkuhlani et al. (2013)’s work except that they start with tokenizations, reduced POS tags and dependency trees and extend them to full morphological information. There has been a lot of work on Arabic POS tagging and morphological disambiguation (Habash and Rambow, 2005; Smith et al., 2005; Hajiˇc et al., 2005; Habash, 2010; Habash et al., 2013). The work by Habash et al. (2013) uses one of the resources we improve on in this paper. In their work, they simply attempt to “synchronize” unknown/malformed annotations with the morphological analyzer they use, thus forcing a reading on the word to make the unknown/malformed annotation usable. In our work, we address the cleaning issue directly. We intend to make these automatic corrections and extensions available in the future so that they can be used in future disambiguation tools. Maamouri et al. (2009) describ"
W13-2301,P06-1086,1,0.865193,"Missing"
W13-2301,habash-etal-2012-conventional,1,0.831293,"y and affixationally, and several classes of attachable clitics. For example, the Egyptian Arabic word AëñJ.JºJ ëð wi+ha+yi-ktib-uw+hA3 ‘and they will write it’ has two proclitics (+ ð wi+ ‘and’ and + è ha+ ‘will’), one prefix - ø yi- ‘3rd person’, one suffix ð- -uw ‘masculine plural’ and one pronominal enclitic Aë+ +hA ‘it/her’. The word is considered an inflected form of the lemma katab ‘write [lit. he wrote]’. An important challenge for NLP work on dialectal Arabic in general is the lack of an orthographic standard. Egyptian Arabic writers are often inconsistent even in their own writing (Habash et al., 2012a), e.g., the future particle h Ha appears as a separate word or as a proclitic + h/+ë Ha+/ha+, reflecting different pronunciations. Arabic orthography in general drops diacritical marks that mark short vowels and gemination. However in analyses, we want these diacritics to be indicated. Moreover, some letters in Arabic (in general) are often spelled inconsistently which leads to an increase in both sparsity (multiple forms of the same word) and ambiguity (same form corresponding to multiple words), e.g., vari ˇ are often writants of Hamzated Alif, @ Â or @ A, ten without their Hamza ( Z ’): @"
W13-2301,W12-2301,1,0.867863,"y and affixationally, and several classes of attachable clitics. For example, the Egyptian Arabic word AëñJ.JºJ ëð wi+ha+yi-ktib-uw+hA3 ‘and they will write it’ has two proclitics (+ ð wi+ ‘and’ and + è ha+ ‘will’), one prefix - ø yi- ‘3rd person’, one suffix ð- -uw ‘masculine plural’ and one pronominal enclitic Aë+ +hA ‘it/her’. The word is considered an inflected form of the lemma katab ‘write [lit. he wrote]’. An important challenge for NLP work on dialectal Arabic in general is the lack of an orthographic standard. Egyptian Arabic writers are often inconsistent even in their own writing (Habash et al., 2012a), e.g., the future particle h Ha appears as a separate word or as a proclitic + h/+ë Ha+/ha+, reflecting different pronunciations. Arabic orthography in general drops diacritical marks that mark short vowels and gemination. However in analyses, we want these diacritics to be indicated. Moreover, some letters in Arabic (in general) are often spelled inconsistently which leads to an increase in both sparsity (multiple forms of the same word) and ambiguity (same form corresponding to multiple words), e.g., vari ˇ are often writants of Hamzated Alif, @ Â or @ A, ten without their Hamza ( Z ’): @"
W13-2301,N13-1044,1,0.931926,"ust the words, but also malformed POS tags. A number of efforts exist on treebank enrichment for many languages including Arabic (Palmer et al., 2008; Hovy et al., 2006; Alkuhlani and Habash, 2011; Alkuhlani et al., 2013). Our morphological extension effort is similar to Alkuhlani et al. (2013)’s work except that they start with tokenizations, reduced POS tags and dependency trees and extend them to full morphological information. There has been a lot of work on Arabic POS tagging and morphological disambiguation (Habash and Rambow, 2005; Smith et al., 2005; Hajiˇc et al., 2005; Habash, 2010; Habash et al., 2013). The work by Habash et al. (2013) uses one of the resources we improve on in this paper. In their work, they simply attempt to “synchronize” unknown/malformed annotations with the morphological analyzer they use, thus forcing a reading on the word to make the unknown/malformed annotation usable. In our work, we address the cleaning issue directly. We intend to make these automatic corrections and extensions available in the future so that they can be used in future disambiguation tools. Maamouri et al. (2009) described a set of manual and automatic techniques used to improve on the quality of"
W13-2301,I08-2131,0,0.0212473,"on 6 presents some statistics on the Egyptian Arabic corpus annotated in one unified representation resulting from our correction and extension work. 1 ARZ is the language code for Egyptian Arabic, http://www-01.sil.org/iso639-3/ documentation.asp?id=arz 2 Related Work Much work has been done on automatic spelling correction. Both supervised and unsupervised approaches have been used employing a variety of tools, resources, and heuristics, e.g., morphological analyzers, language models, annotated data and edit-distance measures, respectively (Kukich, 1992; Oflazer, 1996; Shaalan et al., 2003; Hassan et al., 2008; Kolak and Resnik, 2002; Magdy and Darwish, 2006). Our work is different from these approaches in that it extends beyond spelling of word forms to deeper annotations. However, we use some of these techniques to correct not just the words, but also malformed POS tags. A number of efforts exist on treebank enrichment for many languages including Arabic (Palmer et al., 2008; Hovy et al., 2006; Alkuhlani and Habash, 2011; Alkuhlani et al., 2013). Our morphological extension effort is similar to Alkuhlani et al. (2013)’s work except that they start with tokenizations, reduced POS tags and dependen"
W13-2301,N06-2015,0,0.0158196,"g a variety of tools, resources, and heuristics, e.g., morphological analyzers, language models, annotated data and edit-distance measures, respectively (Kukich, 1992; Oflazer, 1996; Shaalan et al., 2003; Hassan et al., 2008; Kolak and Resnik, 2002; Magdy and Darwish, 2006). Our work is different from these approaches in that it extends beyond spelling of word forms to deeper annotations. However, we use some of these techniques to correct not just the words, but also malformed POS tags. A number of efforts exist on treebank enrichment for many languages including Arabic (Palmer et al., 2008; Hovy et al., 2006; Alkuhlani and Habash, 2011; Alkuhlani et al., 2013). Our morphological extension effort is similar to Alkuhlani et al. (2013)’s work except that they start with tokenizations, reduced POS tags and dependency trees and extend them to full morphological information. There has been a lot of work on Arabic POS tagging and morphological disambiguation (Habash and Rambow, 2005; Smith et al., 2005; Hajiˇc et al., 2005; Habash, 2010; Habash et al., 2013). The work by Habash et al. (2013) uses one of the resources we improve on in this paper. In their work, they simply attempt to “synchronize” unknow"
W13-2301,W06-1648,0,0.0236005,"Arabic corpus annotated in one unified representation resulting from our correction and extension work. 1 ARZ is the language code for Egyptian Arabic, http://www-01.sil.org/iso639-3/ documentation.asp?id=arz 2 Related Work Much work has been done on automatic spelling correction. Both supervised and unsupervised approaches have been used employing a variety of tools, resources, and heuristics, e.g., morphological analyzers, language models, annotated data and edit-distance measures, respectively (Kukich, 1992; Oflazer, 1996; Shaalan et al., 2003; Hassan et al., 2008; Kolak and Resnik, 2002; Magdy and Darwish, 2006). Our work is different from these approaches in that it extends beyond spelling of word forms to deeper annotations. However, we use some of these techniques to correct not just the words, but also malformed POS tags. A number of efforts exist on treebank enrichment for many languages including Arabic (Palmer et al., 2008; Hovy et al., 2006; Alkuhlani and Habash, 2011; Alkuhlani et al., 2013). Our morphological extension effort is similar to Alkuhlani et al. (2013)’s work except that they start with tokenizations, reduced POS tags and dependency trees and extend them to full morphological inf"
W13-2301,J93-2004,0,0.0472249,"urces developed under time/money constraints for such languages tend to tradeoff depth of representation with degree of noise. We present two methods for automatic correction and extension of morphological annotations, and demonstrate their success on three divergent Egyptian Arabic corpora. 1 Introduction Annotated corpora are essential for most research in natural language processing (NLP). For example, the development of treebanks, such as the Penn Treebank and the Penn Arabic Treebank, has been essential in pushing research on partof-speech (POS) tagging and parsing of English and Arabic (Marcus et al., 1993; Maamouri et al., 2004). The creation of such resources tends to be quite expensive and time consuming: guidelines need to be developed, annotators hired, trained, and regularly evaluated for quality control. For languages with complex morphologies, limited resources and tools, and/or lack of standard grammars, such as any of the Dialectal Arabic (DA) varieties, developing annotated resources can be a challenging task. As a result, annotated resources developed under time/money constraints for such languages tend to tradeoff depth of representation with degree of noise. In the extremes, we fi"
W13-2301,mohamed-etal-2012-annotating,0,0.0579208,"tations: corrections of rich noisy annotations and extensions of clean but shallow ones. We present our work on Egyptian Arabic, an important Arabic dialect with limited resources, and rich and ambiguous morphology. Resulting from this effort is the largest Egyptian Arabic corpus annotated in one common representation by pooling resources from three very different sources: a non-final, pre-release version of the ARZ1 corpora from the Linguistic Data Consortium (LDC) (Maamouri et al., 2012g), the LDC’s CallHome Egypt transcripts (Gadalla et al., 1997) and CMU’s Egyptian Arabic corpus (CMUEAC) (Mohamed et al., 2012). Although the paper focuses on Arabic, the basic problem is relevant to other languages, especially spontaneously written colloquial language forms such as those used in social media. The general solutions we propose are language independent given availability of specific language resources. Next we discuss some related work and relevant linguistic facts (Sections 2 and 3, respectively). Section 4 presents our annotation correction technique; and Section 5 presents out annotation extension technique. Finally, Section 6 presents some statistics on the Egyptian Arabic corpus annotated in one un"
W13-2301,J96-1003,0,0.0812661,"n extension technique. Finally, Section 6 presents some statistics on the Egyptian Arabic corpus annotated in one unified representation resulting from our correction and extension work. 1 ARZ is the language code for Egyptian Arabic, http://www-01.sil.org/iso639-3/ documentation.asp?id=arz 2 Related Work Much work has been done on automatic spelling correction. Both supervised and unsupervised approaches have been used employing a variety of tools, resources, and heuristics, e.g., morphological analyzers, language models, annotated data and edit-distance measures, respectively (Kukich, 1992; Oflazer, 1996; Shaalan et al., 2003; Hassan et al., 2008; Kolak and Resnik, 2002; Magdy and Darwish, 2006). Our work is different from these approaches in that it extends beyond spelling of word forms to deeper annotations. However, we use some of these techniques to correct not just the words, but also malformed POS tags. A number of efforts exist on treebank enrichment for many languages including Arabic (Palmer et al., 2008; Hovy et al., 2006; Alkuhlani and Habash, 2011; Alkuhlani et al., 2013). Our morphological extension effort is similar to Alkuhlani et al. (2013)’s work except that they start with t"
W13-2301,palmer-etal-2008-pilot,1,0.772222,"ve been used employing a variety of tools, resources, and heuristics, e.g., morphological analyzers, language models, annotated data and edit-distance measures, respectively (Kukich, 1992; Oflazer, 1996; Shaalan et al., 2003; Hassan et al., 2008; Kolak and Resnik, 2002; Magdy and Darwish, 2006). Our work is different from these approaches in that it extends beyond spelling of word forms to deeper annotations. However, we use some of these techniques to correct not just the words, but also malformed POS tags. A number of efforts exist on treebank enrichment for many languages including Arabic (Palmer et al., 2008; Hovy et al., 2006; Alkuhlani and Habash, 2011; Alkuhlani et al., 2013). Our morphological extension effort is similar to Alkuhlani et al. (2013)’s work except that they start with tokenizations, reduced POS tags and dependency trees and extend them to full morphological information. There has been a lot of work on Arabic POS tagging and morphological disambiguation (Habash and Rambow, 2005; Smith et al., 2005; Hajiˇc et al., 2005; Habash, 2010; Habash et al., 2013). The work by Habash et al. (2013) uses one of the resources we improve on in this paper. In their work, they simply attempt to “"
W13-2301,H05-1060,0,0.0446191,"Missing"
W13-4910,P11-2062,1,0.787315,"it et al., 2008; Nivre, 2009). In contrast to these negative results, Marton et al. (2013) showed positive results for using agreement morphology for Arabic. 2.2 Methodology In Marton et al. (2013), we investigated morphological features for dependency parsing of Modern Standard Arabic (MSA). The goal was to find a set of relevant, accurate and non-redundant features. We used both the MaltParser (Nivre, 2008) and the Easy-First 2 For more information on Arabic morphology in the context of natural language processing see Habash (2010). For a detailed analysis of morpho-syntactic agreement, see Alkuhlani and Habash (2011). 87 Parser (Goldberg and Elhadad, 2010). Since the Easy-First Parser performed better, we use it in all experiments reported in this paper. For MSA, the space of possible morphological features is quite large. We determined which morphological features help by performing a search through the feature space. In order to do this, we separated part-of-speech (POS) from the morphological features. We defined a core set of 12 POS features, and then explored combinations of morphological features in addition to this POS tagset. This core set of POS tags is similar to those proposed in cross-lingual"
W13-4910,E12-1069,1,0.838619,"erent from the data split we used in (Marton et al., 2013), so we retrained our models on the new splits (Diab et al., 2013). The data released for the Shared Task showed inconsistent availability of lemmas across gold and predicted input, so we used the ALMOR analyzer (Habash, 2007) with the SAMA databases (Graff et al., 2009) to determine a lemma given the word form and the provided (gold or predicted) POS tags. In addition to the lemmas, the ALMOR analyzer also provides morphological features in the feature-value representation our approach requires. Finally, we ran our existing converter (Alkuhlani and Habash, 2012) over this representation to obtain functional number and gender, as well as the rationality feature.3 For simplicity reasons, we used the MLE:W2+CATiB model (Alkuhlani and Habash, 2012), which was the best performing model on seen words, as opposed to the combination system that used a syntactic component with better results on unseen words. We did not perform Alif or Ya normalization on the data. We trained two models: one on 5,000 sentences of training data and one on the entire training data. 3.2 Results Our performance in the Shared Task for Arabic Dependency, Gold Tokenization, Predicted"
W13-4910,P99-1065,0,0.101049,"n which case it will be of little or no help for parsing, even if helpful when its gold values are provided. The CASE feature is very relevant and not redundant, but it cannot be predicted with high accuracy and overall it is not useful. Different languages vary with respect to which features may be most helpful given various tradeoffs among these three factors. It has been shown previously that if the relevant morphological features in assignment configurations can be recognized well enough, then they contribute to parsing accuracy. For example, modeling CASE in Czech improves Czech parsing (Collins et al., 1999): CASE is relevant, not redundant, and can be predicted with sufficient accuracy. However, it had been more difficult showing that agreement morphology helps parsing, with negative results for dependency parsing in several languages (Nivre et al., 2008; Eryigit et al., 2008; Nivre, 2009). In contrast to these negative results, Marton et al. (2013) showed positive results for using agreement morphology for Arabic. 2.2 Methodology In Marton et al. (2013), we investigated morphological features for dependency parsing of Modern Standard Arabic (MSA). The goal was to find a set of relevant, accurat"
W13-4910,J08-3003,0,0.0223474,"to which features may be most helpful given various tradeoffs among these three factors. It has been shown previously that if the relevant morphological features in assignment configurations can be recognized well enough, then they contribute to parsing accuracy. For example, modeling CASE in Czech improves Czech parsing (Collins et al., 1999): CASE is relevant, not redundant, and can be predicted with sufficient accuracy. However, it had been more difficult showing that agreement morphology helps parsing, with negative results for dependency parsing in several languages (Nivre et al., 2008; Eryigit et al., 2008; Nivre, 2009). In contrast to these negative results, Marton et al. (2013) showed positive results for using agreement morphology for Arabic. 2.2 Methodology In Marton et al. (2013), we investigated morphological features for dependency parsing of Modern Standard Arabic (MSA). The goal was to find a set of relevant, accurate and non-redundant features. We used both the MaltParser (Nivre, 2008) and the Easy-First 2 For more information on Arabic morphology in the context of natural language processing see Habash (2010). For a detailed analysis of morpho-syntactic agreement, see Alkuhlani and H"
W13-4910,N10-1115,0,0.327358,"st to these negative results, Marton et al. (2013) showed positive results for using agreement morphology for Arabic. 2.2 Methodology In Marton et al. (2013), we investigated morphological features for dependency parsing of Modern Standard Arabic (MSA). The goal was to find a set of relevant, accurate and non-redundant features. We used both the MaltParser (Nivre, 2008) and the Easy-First 2 For more information on Arabic morphology in the context of natural language processing see Habash (2010). For a detailed analysis of morpho-syntactic agreement, see Alkuhlani and Habash (2011). 87 Parser (Goldberg and Elhadad, 2010). Since the Easy-First Parser performed better, we use it in all experiments reported in this paper. For MSA, the space of possible morphological features is quite large. We determined which morphological features help by performing a search through the feature space. In order to do this, we separated part-of-speech (POS) from the morphological features. We defined a core set of 12 POS features, and then explored combinations of morphological features in addition to this POS tagset. This core set of POS tags is similar to those proposed in cross-lingual work (Rambow et al., 2006; Petrov et al."
W13-4910,P05-1071,1,0.758187,"orphological features is quite large. We determined which morphological features help by performing a search through the feature space. In order to do this, we separated part-of-speech (POS) from the morphological features. We defined a core set of 12 POS features, and then explored combinations of morphological features in addition to this POS tagset. This core set of POS tags is similar to those proposed in cross-lingual work (Rambow et al., 2006; Petrov et al., 2012). We performed this search independently for Gold input features and predicted input features. We used our MADA+TOKAN system (Habash and Rambow, 2005; Habash et al., 2009; Habash et al., 2012) for the prediction. As the EasyFirst Parser predicts links separately before labels, we first optimized for unlabeled attachment score, and then optimized the Easy-First Parser labeler for label score. As had been found in previous results, assignment features, specifically CASE and STATE, are very helpful in MSA. However, in MSA this is true only under gold conditions: since CASE is rarely explicit in the typically undiacritized written MSA, it has a dismal accuracy rate, which makes it useless when used in machine-predicted (real, non-gold) conditi"
W13-4910,J13-1008,1,0.634264,"System: The CADIM Arabic Dependency Parser Yuval Marton Microsoft Corporation City Center Plaza Bellevue, WA, USA Nizar Habash, Owen Rambow CCLS Columbia University New York, NY, USA Sarah Alkuhlani CS Department Columbia University New York, NY, USA cadim@ccls.columbia.edu 2.1 Abstract We describe the submission from the Columbia Arabic & Dialect Modeling group (CADIM) for the Shared Task at the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL’2013). We participate in the Arabic Dependency parsing task for predicted POS tags and features. Our system is based on Marton et al. (2013). 1 Introduction In this paper, we discuss the system that the Columbia Arabic & Dialect Modeling group (CADIM) submitted to the 2013 Shared Task on Parsing Morphologically Rich Languages (Seddah et al., 2013). We used a system for Arabic dependency parsing which we had previously developed, but retrained it on the training data splits used in this task. We only participated in the Arabic dependency parsing track, and in it, only optimized for predicted (non-gold) POS tags and features. We first summarize our previous work (Section 2). We then discuss our submission and the results (Section 3)"
W13-4910,C08-1081,0,0.0564306,"Missing"
W13-4910,J08-4003,0,0.0184236,"h sufficient accuracy. However, it had been more difficult showing that agreement morphology helps parsing, with negative results for dependency parsing in several languages (Nivre et al., 2008; Eryigit et al., 2008; Nivre, 2009). In contrast to these negative results, Marton et al. (2013) showed positive results for using agreement morphology for Arabic. 2.2 Methodology In Marton et al. (2013), we investigated morphological features for dependency parsing of Modern Standard Arabic (MSA). The goal was to find a set of relevant, accurate and non-redundant features. We used both the MaltParser (Nivre, 2008) and the Easy-First 2 For more information on Arabic morphology in the context of natural language processing see Habash (2010). For a detailed analysis of morpho-syntactic agreement, see Alkuhlani and Habash (2011). 87 Parser (Goldberg and Elhadad, 2010). Since the Easy-First Parser performed better, we use it in all experiments reported in this paper. For MSA, the space of possible morphological features is quite large. We determined which morphological features help by performing a search through the feature space. In order to do this, we separated part-of-speech (POS) from the morphologica"
W13-4910,petrov-etal-2012-universal,0,0.0385524,"lhadad, 2010). Since the Easy-First Parser performed better, we use it in all experiments reported in this paper. For MSA, the space of possible morphological features is quite large. We determined which morphological features help by performing a search through the feature space. In order to do this, we separated part-of-speech (POS) from the morphological features. We defined a core set of 12 POS features, and then explored combinations of morphological features in addition to this POS tagset. This core set of POS tags is similar to those proposed in cross-lingual work (Rambow et al., 2006; Petrov et al., 2012). We performed this search independently for Gold input features and predicted input features. We used our MADA+TOKAN system (Habash and Rambow, 2005; Habash et al., 2009; Habash et al., 2012) for the prediction. As the EasyFirst Parser predicts links separately before labels, we first optimized for unlabeled attachment score, and then optimized the Easy-First Parser labeler for label score. As had been found in previous results, assignment features, specifically CASE and STATE, are very helpful in MSA. However, in MSA this is true only under gold conditions: since CASE is rarely explicit in t"
W13-4910,J08-4010,0,\N,Missing
W13-4910,rambow-etal-2006-parallel,1,\N,Missing
W13-4917,P06-1084,0,0.0139791,"s of incomplete lexicon coverage. The morphologically disambiguated input files for the Raw (1-best) scenario were produced by running the raw text through the morphological disam23 Note that this additional layer in the constituency treebank adds a relatively easy set of nodes to the trees, thus “inflating” the evaluation scores compared to previously reported results. To compensate, a stricter protocol than is used in this task would strip one of the two POS layers prior to evaluation. 24 This split is slightly different than the split in previous studies. 160 biguator (tagger) described in Adler and Elhadad (2006; Goldberg et al. (2008),Adler (2007). The disambiguator is based on the same lexicon that is used to produce the lattice files, but utilizes an extra module for dealing with unknown tokens Adler et al. (2008). The core of the disambiguator is an HMM tagger trained on about 70M unannotated tokens using EM, and being supervised by the lexicon. As in the case of Arabic, we also provided data for the Predicted (gold token / predicted morphology) scenario. We used the same sequence labeler, Morfette (Chrupała et al., 2008), trained on the concatenation of POS and morphological gold features, leadi"
W13-4917,P08-1083,1,0.743016,"in the constituency treebank adds a relatively easy set of nodes to the trees, thus “inflating” the evaluation scores compared to previously reported results. To compensate, a stricter protocol than is used in this task would strip one of the two POS layers prior to evaluation. 24 This split is slightly different than the split in previous studies. 160 biguator (tagger) described in Adler and Elhadad (2006; Goldberg et al. (2008),Adler (2007). The disambiguator is based on the same lexicon that is used to produce the lattice files, but utilizes an extra module for dealing with unknown tokens Adler et al. (2008). The core of the disambiguator is an HMM tagger trained on about 70M unannotated tokens using EM, and being supervised by the lexicon. As in the case of Arabic, we also provided data for the Predicted (gold token / predicted morphology) scenario. We used the same sequence labeler, Morfette (Chrupała et al., 2008), trained on the concatenation of POS and morphological gold features, leading to a model with respectable accuracy.25 4.7 The Hungarian Treebank Hungarian is an agglutinative language, thus a lemma can have hundreds of word forms due to derivational or inflectional affixation (nomina"
W13-4917,W13-4903,0,0.0228459,"such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Re"
W13-4917,W10-1411,1,0.835873,"challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and w"
W13-4917,W10-1408,1,0.383126,"Missing"
W13-4917,E12-2012,1,0.0774441,"parsing evaluation campaign SANCL 2012 (Petrov and McDonald, 2012). The present shared task was extremely demanding on our participants. From 30 individuals or teams who registered and obtained the data sets, we present results for the seven teams that accomplished successful executions on these data in the relevant scenarios in the given the time frame. 5.1 Dependency Track Seven teams participated in the dependency track. Two participating systems are based on MaltParser: M ALTOPTIMIZER (Ballesteros, 2013) and AI:KU (Cirik and Sensoy, ¸ 2013). M ALTOPTIMIZER uses a variant of MaltOptimizer (Ballesteros and Nivre, 2012) to explore features relevant for the processing of morphological information. AI:KU uses a combination of MaltParser and the original MaltOptimizer. Their system development has focused on the integration of an unsupervised word clustering method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To"
W13-4917,W13-4907,0,0.0733412,"Missing"
W13-4917,W10-1404,0,0.0222482,"merged as to the evaluation of parsers in such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and"
W13-4917,W13-4916,1,0.230959,"Missing"
W13-4917,H91-1060,0,0.199934,"n the expected performance of parsers in real-world scenarios. Results reported for MRLs using gold morphological information are then, at best, optimistic. One reason for adopting this less-than-realistic evaluation scenario in previous tasks has been the lack of sound metrics for the more realistic scenario. Standard evaluation metrics assume that the number of terminals in the parse hypothesis equals the number of terminals in the gold tree. When the predicted morphological segmentation leads to a different number of terminals in the gold and parse trees, standard metrics such as ParsEval (Black et al., 1991) or Attachment Scores (Buchholz and Marsi, 2006) fail to produce a score. In this task, we use TedEval (Tsarfaty et al., 2012b), a metric recently suggested for joint morpho-syntactic evaluation, in which normalized tree-edit distance (Bille, 2005) on morphosyntactic trees allows us to quantify the success on the joint task in realistic parsing scenarios. Finally, the previous tasks focused on dependency parsing. When providing both constituency-based and dependency-based tracks, it is interesting to compare results across these frameworks so as to better understand the differences in performa"
W13-4917,D12-1133,1,0.807979,"cy-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure of sentences is expressed"
W13-4917,C10-1011,0,0.0102695,"r system development has focused on the integration of an unsupervised word clustering method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To the best of our knowledge, this is the first dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 2007b). The system combines the parser outputs via MaltBlender (Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-"
W13-4917,W07-1506,0,0.220289,"s of all nodes were marked using a simple heuristic. In case there was a daughter with the edge label HD, this daughter was marked, i.e., existing head markings were honored. Otherwise, if existing, the rightmost daughter with edge label NK (noun kernel) was marked. Otherwise, as default, the leftmost daughter was marked. In a second step, for each continuous part of a discontinuous constituent, a separate node was introduced. This corresponds 21 This version is available from http://www.ims. uni-stuttgart.de/forschung/ressourcen/ korpora/tiger.html 159 to the &quot;raising&quot; algorithm described by Boyd (2007). In a third steps, all those newly introduced nodes that did not cover the head daughter of the original discontinuous node were deleted. For the second and the third step, we used the same script as for the Swedish constituency data. Predicted Morphology For the predicted scenario, a single sequence of POS tags and morphological features has been assigned using the MATE toolchain via a model trained on the train set via crossvalidation on the training set. The MATE toolchain was used to provide predicted annotation for lemmas, POS tags, morphology, and syntax. In order to achieve the best re"
W13-4917,W06-2920,0,0.827477,"ouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007a) highlighted the usefulness of an alternative linguistic formalism for the development of competitive parsing models. Dependency relations are marked between input tokens directly, and allow the annotation of non-projective dependencies that are parseable efficiently. Dependency syntax was applied to the description of different types of languages (Tesnière, 1959; Mel’ˇcuk, 2001), which raised the hope that in these settings, parsing MRLs will further improve. However, the 2007 shared task organizers (Nivre et al., 2007a) concluded that: &quot;[Performance] classes are more ea"
W13-4917,W10-1409,1,0.0435485,"for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing"
W13-4917,candito-etal-2010-statistical,1,0.0386487,"g of 18,535 sentences,18 split into 14,759 sentences for training, 1,235 sentences for development, and 2,541 sentences for the final evaluation.19 Adapting the Data to the Shared Task The constituency trees are provided in an extended PTB bracketed format, with morphological features at the pre-terminal level only. They contain slight, automatically performed, modifications with respect to the original trees of the French treebank. The syntagmatic projection of prepositions and complementizers was normalized, in order to have prepositions and complementizers as heads in the dependency trees (Candito et al., 2010). The dependency representations are projective dependency trees, obtained through automatic conversion from the constituency trees. The conversion procedure is an enhanced version of the one described by Candito et al. (2010). Both the constituency and the dependency representations make use of coarse- and fine-grained POS tags (CPOS and FPOS respectively). The CPOS are the categories from the original treebank. The FPOS 18 The process of functional annotation is still ongoing, the objective of the FTB providers being to have all the 20000 sentences annotated with functional tags. 19 The firs"
W13-4917,W08-2102,0,0.0353476,"troduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality par"
W13-4917,A00-2018,0,0.0705659,"n analysis and comparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing E"
W13-4917,W11-3801,1,0.926035,"ers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard Engli"
W13-4917,chrupala-etal-2008-learning,0,0.045003,"Missing"
W13-4917,W10-1406,0,0.0618994,"Missing"
W13-4917,W13-4909,0,0.199525,"derived from the Hebrew Treebank V2 (Sima’an et al., 2001; Guthmann et al., 2009). The treebank is based on just over 6000 sentences from the daily newspaper ‘Ha’aretz’, manually annotated with morphological information and phrase-structure trees and extended with head information as described in Tsarfaty (2010, ch. 5). The unlabeled dependency version was produced by conversion from the constituency treebank as described in Goldberg (2011). Both the constituency and dependency trees were annotated with a set grammatical function labels conforming to Unified Stanford Dependencies by Tsarfaty (2013). 22 We also provided a predicted-all scenario, in which we provided morphological analysis lattices with POS and morphological information derived from the analyses of the SMOR derivational morphology (Schmid et al., 2004). These lattices were not used by any of the participants. Adapting the Data to the Shared Task While based on the same trees, the dependency and constituency treebanks differ in their POS tag sets, as well as in some of the morphological segmentation decisions. The main effort towards the shared task was unifying the two resources such that the two treebanks share the same"
W13-4917,J03-4003,0,0.48866,"omparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the ma"
W13-4917,W13-4905,1,0.719588,"method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To the best of our knowledge, this is the first dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 2007b). The system combines the parser outputs via MaltBlender (Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZE"
W13-4917,W13-4906,1,0.680312,"dependency track. Two participating systems are based on MaltParser: M ALTOPTIMIZER (Ballesteros, 2013) and AI:KU (Cirik and Sensoy, ¸ 2013). M ALTOPTIMIZER uses a variant of MaltOptimizer (Ballesteros and Nivre, 2012) to explore features relevant for the processing of morphological information. AI:KU uses a combination of MaltParser and the original MaltOptimizer. Their system development has focused on the integration of an unsupervised word clustering method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To the best of our knowledge, this is the first dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 200"
W13-4917,W08-1301,0,0.0393335,"Missing"
W13-4917,P98-1062,0,0.0491049,"Missing"
W13-4917,P08-1109,0,0.0220424,"ences. In order to avoid comparing apples and oranges, we use the unlabeled TedEval metric, which converts all representation types internally into the same kind of structures, called function trees. Here we use TedEval’s crossframework protocol (Tsarfaty et al., 2012a), which accomodates annotation idiosyncrasies. • Cross-Language Evaluation. Here, we compare parsers for the same representation type across different languages. Conducting a complete and faithful evaluation across languages 151 would require a harmonized universal annotation scheme (possibly along the lines of (de Marneffe and Manning, 2008; McDonald et al., 2013; Tsarfaty, 2013)) or task based evaluation. As an approximation we use unlabeled TedEval. Since it is unlabeled, it is not sensitive to label set size. Since it internally uses function-trees, it is less sensitive to annotation idiosyncrasies (e.g., head choice) (Tsarfaty et al., 2011). The former two dimensions are evaluated on the full sets. The latter two are evaluated on smaller, comparable, test sets. For completeness, we provide below the formal definitions and essential modifications of the evaluation software that we used. 3.4.1 Evaluation Metrics for Phrase Str"
W13-4917,J13-1005,1,0.838989,"html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard English data, questions begin to emerge, such as: What is the realistic performance of parsing MRLs using today’s methods? How do the different models compare with one another? How do different representation types deal with parsing one particular language? Does the success of a parsing model on a language correlate with its representation type and learning method? How to parse effectively in the face of resource scarcity? The first step to answering all of these"
W13-4917,W13-4908,1,0.872762,"Missing"
W13-4917,W10-1412,1,0.789087,"Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2013b) uses their variant of the easy-first parser combined with a feature-rich ensemble of lexical and syntactic resources. Four of the participating teams use external resources in addition to the parser. The IMS:S ZEGED :CIS team uses external morphological analyzers. C ADIM uses SAMA (Graff et al., 2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally"
W13-4917,N10-1115,1,0.576439,"Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2013b) uses their variant of the easy-first parser combined with a feature-rich ensemble of lexical and syntactic resources. Four of the participating teams use external resources in addition to the parser. The IMS:S ZEGED :CIS team uses external morphological analyzers. C ADIM uses SAMA (Graff et al., 2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally"
W13-4917,P08-1085,1,0.364225,"overage. The morphologically disambiguated input files for the Raw (1-best) scenario were produced by running the raw text through the morphological disam23 Note that this additional layer in the constituency treebank adds a relatively easy set of nodes to the trees, thus “inflating” the evaluation scores compared to previously reported results. To compensate, a stricter protocol than is used in this task would strip one of the two POS layers prior to evaluation. 24 This split is slightly different than the split in previous studies. 160 biguator (tagger) described in Adler and Elhadad (2006; Goldberg et al. (2008),Adler (2007). The disambiguator is based on the same lexicon that is used to produce the lattice files, but utilizes an extra module for dealing with unknown tokens Adler et al. (2008). The core of the disambiguator is an HMM tagger trained on about 70M unannotated tokens using EM, and being supervised by the lexicon. As in the case of Arabic, we also provided data for the Predicted (gold token / predicted morphology) scenario. We used the same sequence labeler, Morfette (Chrupała et al., 2008), trained on the concatenation of POS and morphological gold features, leading to a model with respe"
W13-4917,E09-1038,1,0.867766,"ices with POS and morphological information derived from the analyses of the SMOR derivational morphology (Schmid et al., 2004). These lattices were not used by any of the participants. Adapting the Data to the Shared Task While based on the same trees, the dependency and constituency treebanks differ in their POS tag sets, as well as in some of the morphological segmentation decisions. The main effort towards the shared task was unifying the two resources such that the two treebanks share the same lexical yields, and the same pre-terminal labels. To this end, we took the layering approach of Goldberg et al. (2009), and included two levels of POS tags in the constituency trees. The lower level is lexical, conforming to the lexical resource used to build the lattices, and is shared by the two treebanks. The higher level is syntactic, and follows the tag set and annotation decisions of the original constituency treebank.23 In addition, we unified the representation of morphological features, and fixed inconsistencies and mistakes in the treebanks. Data Split The Hebrew treebank is one of the smallest in our language set, and hence it is provided in only the small (5k) setting. For the sake of comparabilit"
W13-4917,C10-1045,1,0.826872,"nflectional and derivational morphology. It exhibits a high degree of morphological ambiguity due to the absence of the diacritics and inconsistent spelling of letters, such as Alif and Ya. As a consequence, the Buckwalter Standard Arabic Morphological Analyzer (Buckwalter, 2004; Graff et al., 2009) produces an average of 12 analyses per word. Data Sets The Arabic data set contains two treebanks derived from the LDC Penn Arabic Treebanks (PATB) (Maamouri et al., 2004b):11 the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), a dependency treebank, and the Stanford version of the PATB (Green and Manning, 2010), a phrasestructure treebank. We preprocessed the treebanks to obtain strict token matching between the treebanks and the morphological analyses. This required nontrivial synchronization at the tree token level between the PATB treebank, the CATiB treebank and the morphologically predicted data, using the PATB source tokens and CATiB feature word form as a dual synchronized pivot. The Columbia Arabic Treebank The Columbia Arabic Treebank (CATiB) uses a dependency representation that is based on traditional Arabic grammar and that emphasizes syntactic case relations (Habash and Roth, 2009; Haba"
W13-4917,W12-3410,0,0.0157938,"umulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard English data, questions begin to emerge, such as: What is the realis"
W13-4917,J13-1009,1,0.747017,"Missing"
W13-4917,P09-2056,1,0.833708,".2 The Arabic Treebanks Arabic is a morphologically complex language which has rich inflectional and derivational morphology. It exhibits a high degree of morphological ambiguity due to the absence of the diacritics and inconsistent spelling of letters, such as Alif and Ya. As a consequence, the Buckwalter Standard Arabic Morphological Analyzer (Buckwalter, 2004; Graff et al., 2009) produces an average of 12 analyses per word. Data Sets The Arabic data set contains two treebanks derived from the LDC Penn Arabic Treebanks (PATB) (Maamouri et al., 2004b):11 the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), a dependency treebank, and the Stanford version of the PATB (Green and Manning, 2010), a phrasestructure treebank. We preprocessed the treebanks to obtain strict token matching between the treebanks and the morphological analyses. This required nontrivial synchronization at the tree token level between the PATB treebank, the CATiB treebank and the morphologically predicted data, using the PATB source tokens and CATiB feature word form as a dual synchronized pivot. The Columbia Arabic Treebank The Columbia Arabic Treebank (CATiB) uses a dependency representation that is based on traditional A"
W13-4917,D07-1116,1,0.604822,"010), a phrasestructure treebank. We preprocessed the treebanks to obtain strict token matching between the treebanks and the morphological analyses. This required nontrivial synchronization at the tree token level between the PATB treebank, the CATiB treebank and the morphologically predicted data, using the PATB source tokens and CATiB feature word form as a dual synchronized pivot. The Columbia Arabic Treebank The Columbia Arabic Treebank (CATiB) uses a dependency representation that is based on traditional Arabic grammar and that emphasizes syntactic case relations (Habash and Roth, 2009; Habash et al., 2007). The CATiB treebank uses the word tokenization of the PATB 11 The LDC kindly provided their latest version of the Arabic Treebanks. In particular, we used PATB 1 v4.1 (Maamouri et al., 2005), PATB 2 v3.1 (Maamouri et al., 2004a) and PATB 3 v3.3. (Maamouri et al., 2009) train: #Sents #Tokens Lex. Size Avg. Length Ratio #NT/#Tokens Ratio #NT/#Sents #Non Terminals #POS tags #total NTs Dep. Label Set Size train5k: #Sents #Tokens Lex. Size Avg. Length Ratio #NT/#Tokens Ratio #NT/#Sents #Non Terminals #POS Tags #total NTs Dep. Label Set Size dev: #Sents #Tokens Lex. Size Avg. Length Ratio #NT/#Toke"
W13-4917,P07-2053,0,0.0323622,"Missing"
W13-4917,D07-1097,1,0.346865,"Missing"
W13-4917,D10-1002,0,0.0151688,"oaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predica"
W13-4917,P08-1067,0,0.0226773,"a-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information co"
W13-4917,J98-4004,0,0.0891486,"ir strengths and weaknesses. Finally, we summarize and conclude with challenges to address in future shared tasks (§8). 2 2.1 Background A Brief History of the SPMRL Field Statistical parsing saw initial success upon the availability of the Penn Treebank (PTB, Marcus et al., 1994). With that large set of syntactically annotated sentences at their disposal, researchers could apply advanced statistical modeling and machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying t"
W13-4917,J13-1006,1,0.798597,"hbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard English data, questions begin to emerge, such as: What is the realistic performance of parsing MRLs using today’s methods? How do the different models compare with one another? How do different representation types deal with parsing one particular language? Does the success of a parsing model on a language correlate with its representation type and learning method? Ho"
W13-4917,P03-1054,0,0.00438043,"d weaknesses. Finally, we summarize and conclude with challenges to address in future shared tasks (§8). 2 2.1 Background A Brief History of the SPMRL Field Statistical parsing saw initial success upon the availability of the Penn Treebank (PTB, Marcus et al., 1994). With that large set of syntactically annotated sentences at their disposal, researchers could apply advanced statistical modeling and machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank"
W13-4917,W06-1614,1,0.812546,"nd machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007a) hi"
W13-4917,kubler-etal-2008-compare,1,0.91565,"node to the root node in the output tree and the corresponding path in the gold tree. The path consists of a sequence of node labels between the terminal node and the root node, and the similarity of two paths is calculated by using the Levenshtein distance. This distance is normalized by path length, and the score of the tree is an aggregated score of the values for all terminals in the tree (xt is the leaf-ancestor path of t in tree x). P LA(h, g) = t∈yield(g) Lv(ht ,gt )/(len(ht )+len(gt )) |yield(g)| This metric was shown to be less sensitive to differences between annotation schemes in (Kübler et al., 2008), and was shown by Rehbein and van Genabith (2007a) to evaluate trees more faithfully than ParsEval in the face of certain annotation decisions. We used the implementation of Wagner (2012).6 3.4.2 Evaluation Metrics for Dependency Structures Attachment Scores Labeled and Unlabeled Attachment scores have been proposed as evaluation metrics for dependency parsing in the CoNLL shared tasks (Buchholz and Marsi, 2006; Nivre et al., 2007a) and have since assumed the role of standard metrics in multiple shared tasks and independent studies. Assume that g, h are gold and hypothesized dependency trees"
W13-4917,W12-3408,1,0.878953,"Missing"
W13-4917,P03-1056,0,0.0207769,"disposal, researchers could apply advanced statistical modeling and machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on depend"
W13-4917,W12-4615,1,0.809959,"ly. The conversion of TiGer into dependencies is a variant of the one by Seeker and Kuhn (2012), which does not contain empty nodes. It is based on the same TiGer release as the one used for the constituency data. Punctuation was attached as high as possible, without creating any new non-projective edges. Adapting the Data to the Shared Task For the constituency version, punctuation and other unattached elements were first attached to the tree. As attachment target, we used roughly the respective least common ancestor node of the right and left terminal neighbor of the unattached element (see Maier et al. (2012) for details), and subsequently, the crossing branches were resolved. This was done in three steps. In the first step, the head daughters of all nodes were marked using a simple heuristic. In case there was a daughter with the edge label HD, this daughter was marked, i.e., existing head markings were honored. Otherwise, if existing, the rightmost daughter with edge label NK (noun kernel) was marked. Otherwise, as default, the leftmost daughter was marked. In a second step, for each continuous part of a discontinuous constituent, a separate node was introduced. This corresponds 21 This version"
W13-4917,J93-2004,0,0.0437888,"participants, and then provide an analysis and comparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend."
W13-4917,D10-1004,0,0.0390834,"nd MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2013b) uses their variant of the easy-first parser combined with a feature-rich ensemble of lexical and syntactic resources. Four of the participating teams use external resources in addition to the parser. The IMS:S ZEGED :CIS team uses external morphological analyzers. C ADIM uses SAMA (Graff et al., 2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally uses Morfette (Chrupała et al., 2008) for"
W13-4917,J13-1008,1,0.913933,". Additionally, new questions emerged as to the evaluation of parsers in such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint"
W13-4917,W13-4910,1,0.915357,". Additionally, new questions emerged as to the evaluation of parsers in such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint"
W13-4917,N06-1020,0,0.225446,"for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on"
W13-4917,P05-1012,0,0.042194,"Missing"
W13-4917,moreno-etal-2000-treebank,0,0.0581254,"e generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007a) highlighted the usefulness of an alternative linguistic formalism for the development of competitive parsing models. Dependency"
W13-4917,nivre-etal-2006-talbanken05,1,0.442193,"subject agreement with respect to person and number has been dropped in modern Swedish. The Data Set The Swedish data sets are taken from the Talbanken section of the Swedish Treebank (Nivre and Megyesi, 2007). Talbanken is a syntactically annotated corpus developed in the 1970s, originally annotated according to the MAMBA scheme (Teleman, 1974) with a syntactic layer consisting of flat phrase structure and grammatical functions. The syntactic annotation was later automatically converted to full phrase structure with grammatical functions and from that to dependency structure, as described by Nivre et al. (2006). Both the phrase structure and the dependency version use the functional labels from the original MAMBA scheme, which provides a fine-grained classification of syntactic functions with 65 different labels, while the phrase structure annotation (which had to be inferred automatically) uses a coarse set of only 8 labels. For the release of the Swedish treebank, the POS level was re-annotated to conform to the current de facto standard for Swedish, which is the Stockholm-Umeå tagset (Ejerhed et al., 1992) with 25 base tags and 25 morpho-syntactic features, which together produce over 150 complex"
W13-4917,P06-1055,0,0.480329,"as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it"
W13-4917,N10-1003,0,0.0195824,"2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally uses Morfette (Chrupała et al., 2008) for morphological analysis and POS tagging. Finally, as already mentioned, AI:KU clusters words and POS tags in an unsupervised fashion exploiting additional, un-annotated data. 5.2 Constituency Track A single team participated in the constituency parsing task, the IMS:S ZEGED :CIS team (Björkelund et al., 2013). Their phrase-structure parsing system uses a combination of 8 PCFG-LA parsers, trained using a product-of-grammars procedure (Petrov, 2010). The 50-best parses of this combination are then reranked by a model based on the reranker by Charniak and Johnson (2005).33 5.3 6.1 Baselines We additionally provide the results of two baseline systems for the nine languages, one for constituency parsing and one for dependency parsing. For the dependency track, our baseline system is MaltParser in its default configuration (the arc-eager algorithm and liblinear for training). Results marked as BASE :M ALT in the next two sections report the results of this baseline system in different scenarios. The constituency parsing baseline is based on"
W13-4917,W07-2460,0,0.109747,"Missing"
W13-4917,D07-1066,0,0.0884872,"Missing"
W13-4917,W11-3808,0,0.027114,"rameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer an"
W13-4917,N06-2033,0,0.0563478,"rst dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 2007b). The system combines the parser outputs via MaltBlender (Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2"
W13-4917,schmid-etal-2004-smor,0,0.00857226,"information and phrase-structure trees and extended with head information as described in Tsarfaty (2010, ch. 5). The unlabeled dependency version was produced by conversion from the constituency treebank as described in Goldberg (2011). Both the constituency and dependency trees were annotated with a set grammatical function labels conforming to Unified Stanford Dependencies by Tsarfaty (2013). 22 We also provided a predicted-all scenario, in which we provided morphological analysis lattices with POS and morphological information derived from the analyses of the SMOR derivational morphology (Schmid et al., 2004). These lattices were not used by any of the participants. Adapting the Data to the Shared Task While based on the same trees, the dependency and constituency treebanks differ in their POS tag sets, as well as in some of the morphological segmentation decisions. The main effort towards the shared task was unifying the two resources such that the two treebanks share the same lexical yields, and the same pre-terminal labels. To this end, we took the layering approach of Goldberg et al. (2009), and included two levels of POS tags in the constituency trees. The lower level is lexical, conforming t"
W13-4917,W10-1410,1,0.889145,"Missing"
W13-4917,seeker-kuhn-2012-making,1,0.106665,"n constituency data set is based on the TiGer treebank release 2.2.21 The original annotation scheme represents discontinuous constituents such that all arguments of a predicate are always grouped under a single node regardless of whether there is intervening material between them or not (Brants et al., 2002). Furthermore, punctuation and several other elements, such as parentheses, are not attached to the tree. In order to make the constituency treebank usable for PCFG parsing, we adapted this treebank as described shortly. The conversion of TiGer into dependencies is a variant of the one by Seeker and Kuhn (2012), which does not contain empty nodes. It is based on the same TiGer release as the one used for the constituency data. Punctuation was attached as high as possible, without creating any new non-projective edges. Adapting the Data to the Shared Task For the constituency version, punctuation and other unattached elements were first attached to the tree. As attachment target, we used roughly the respective least common ancestor node of the right and left terminal neighbor of the unattached element (see Maier et al. (2012) for details), and subsequently, the crossing branches were resolved. This w"
W13-4917,P12-1046,0,0.00731402,"based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure of sentences is expressed through word formatio"
W13-4917,W11-3803,0,0.0414253,"to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCF"
W13-4917,W10-1405,1,0.891538,"Missing"
W13-4917,W10-1401,1,0.779419,"sentences is expressed through word formation, rather than constituent-order patterns as is the case in English and other configurational languages. MRLs express information concerning the grammatical function of a word and its grammatical relation to other words at the word level, via phenomena such as inflectional affixes, pronominal clitics, and so on (Tsarfaty et al., 2012c). The non-rigid tree structures and morphological ambiguity of input words contribute to the challenges of parsing MRLs. In addition, insufficient language resources were shown to also contribute to parsing difficulty (Tsarfaty et al., 2010; Tsarfaty et al., 2012c, and references therein). These challenges have initially been addressed by native-speaking experts using strong in-domain knowledge of the linguistic phenomena and annotation idiosyncrasies to improve the accuracy and efficiency of parsing models. More 146 Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages, pages 146–182, c Seattle, Washington, USA, 18 October 2013. 2013 Association for Computational Linguistics recently, advances in PCFG-LA parsing (Petrov et al., 2006) and language-agnostic data-driven dependency parsing (McD"
W13-4917,D11-1036,1,0.926772,"dependency parsing. When providing both constituency-based and dependency-based tracks, it is interesting to compare results across these frameworks so as to better understand the differences in performance between parsers of different types. We are now faced with an additional question: how can we compare parsing results across different frameworks? Adopting standard metrics will not suffice as we would be comparing apples and oranges. In contrast, TedEval is defined for both phrase structures and dependency structures through the use of an intermediate representation called function trees (Tsarfaty et al., 2011; Tsarfaty et al., 2012a). Using TedEval thus allows us to explore both dependency and constituency parsing frameworks and meaningfully compare the performance of parsers of different types. 149 3 3.1 Defining the Shared-Task Input and Output We define a parser as a structure prediction function that maps sequences of space-delimited input tokens (henceforth, tokens) in a language to a set of parse trees that capture valid morpho-syntactic structures in that language. In the case of constituency parsing, the output structures are phrase-structure trees. In dependency parsing, the output consis"
W13-4917,E12-1006,1,0.148172,"er languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure of sentences is expressed through word formation, rather than constituent-order patterns as is the case in English and other configurational languages. MRLs express information concerning the grammatical function of a word and its grammatical relation to other words at the word level, via phenomena such as inflectional affixes, pronominal clitics, and so on (Tsarfaty et al., 2012c). The non-rigid tree structures and morphological ambiguity of input words contribute to the challenges of parsing MRLs. In addition, insufficient language resources were shown to also contribute to parsing difficulty (Tsarfaty et al., 2010; Tsarfaty et al., 2012c, and references therein). These challenges have initially been addressed by native-speaking experts using strong in-domain knowledge of the linguistic phenomena and annotation idiosyncrasies to improve the accuracy and efficiency of parsing models. More 146 Proceedings of the Fourth Workshop on Statistical Parsing of Morphologicall"
W13-4917,P13-2103,1,0.111695,"les and oranges, we use the unlabeled TedEval metric, which converts all representation types internally into the same kind of structures, called function trees. Here we use TedEval’s crossframework protocol (Tsarfaty et al., 2012a), which accomodates annotation idiosyncrasies. • Cross-Language Evaluation. Here, we compare parsers for the same representation type across different languages. Conducting a complete and faithful evaluation across languages 151 would require a harmonized universal annotation scheme (possibly along the lines of (de Marneffe and Manning, 2008; McDonald et al., 2013; Tsarfaty, 2013)) or task based evaluation. As an approximation we use unlabeled TedEval. Since it is unlabeled, it is not sensitive to label set size. Since it internally uses function-trees, it is less sensitive to annotation idiosyncrasies (e.g., head choice) (Tsarfaty et al., 2011). The former two dimensions are evaluated on the full sets. The latter two are evaluated on smaller, comparable, test sets. For completeness, we provide below the formal definitions and essential modifications of the evaluation software that we used. 3.4.1 Evaluation Metrics for Phrase Structures ParsEval The ParsEval metrics (B"
W13-4917,P11-2033,1,0.563308,"em, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure o"
W13-4917,R13-1099,1,0.0375053,"orphology In order to provide the same POS tag set for the constituent and dependency treebanks, we used the dependency POS tagset for both treebank instances. Both versions of the treebank are available with gold standard and automatic morphological annotation. The automatic POS tagging was carried out by a 10-fold cross-validation on the shared task data set by magyarlanc, a natural language toolkit for processing Hungarian texts (segmentation, morphological analysis, POS tagging, and dependency parsing). The annotation provides POS tags and deep morphological features for each input token (Zsibrita et al., 2013).28 28 The full data sets of both the constituency and dependency versions of the Szeged Treebank are available at 161 4.8 The Korean Treebank The Treebank The Korean corpus is generated by collecting constituent trees from the K AIST Treebank (Choi et al., 1994), then converting the constituent trees to dependency trees using head-finding rules and heuristics. The K AIST Treebank consists of about 31K manually annotated constituent trees from 97 different sources (e.g., newspapers, novels, textbooks). After filtering out trees containing annotation errors, a total of 27,363 trees with 350,090"
W13-4917,E93-1064,0,\N,Missing
W13-4917,C00-1001,0,\N,Missing
W13-4917,C10-1061,1,\N,Missing
W13-4917,J13-1003,1,\N,Missing
W13-4917,C08-1112,1,\N,Missing
W13-4917,W08-1008,1,\N,Missing
W13-4917,P05-1022,0,\N,Missing
W13-4917,P98-1063,0,\N,Missing
W13-4917,C98-1060,0,\N,Missing
W13-4917,vincze-etal-2010-hungarian,1,\N,Missing
W13-4917,D07-1096,1,\N,Missing
W14-1604,P97-1017,0,0.0863408,"there is some work on converting from dialectal Arabic to MSA, which is similar to our work in terms of processing a dialectal input. However, our final output is in EGY and not MSA. Shaalan et al. (2007) introduced a rule-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic, which Habash (2008) employed as part of generating English transliterations from Arabic words in the context of machine translation. This work is similar to ours in terms of text transliteration. However, our work is not restricted to names. 4 Approach 4.1 Defining the Task Our task is as follows: for each Arabizi word in the input, we choose the Arabic script word which is the correct CODA spelling of th"
W14-1604,W12-4808,0,0.141881,"ransliteration from Arabizi to Arabic script, and then applied language modeling on the transliterated text. This is similar to our proposed work in terms of transliteration and language modeling. However, Darwish (2013) does not target a conventionalized orthography, while our system targets CODA. Additionally, Darwish (2013) transliterates Arabic words only after filtering out non-Arabic words, while we transliterate the whole input Arabizi. Finally, he does not use any morphological information, while we introduce the use of a morphological analyzer to support the transliteration pipeline. Chalabi and Gerges (2012) presented a hybrid approach for Arabizi transliteration. Their work relies on the use of character transformation rules that are either handcrafted by a linguist or automatically generated from training data. They also employ word-based and character-based language models for the final transliteration choice. Like Darwish (2013), the work done by Chalabi and Gerges (2012) is similar to ours except that it does not target a conventionalized orthography, and does not use deep morphological information, while our system does. CODA has been used as part of different approaches for modeling DA mor"
W14-1604,N13-1066,1,0.790154,"ld we convert Arabizi into? Our answer to this question is to use CODA, a conventional orthography created for the purpose of supporting NLP tools (Habash et al., 2012a). The goal of CODA is to reduce the data sparseness that comes from the same word form appearing in many spontaneous orthographies in data (be it annotated or unannotated). CODA has been defined for EGY as well as Tunisian Arabic (Zribi et al., 2014), and it has been used as part of different approaches for modeling DA morphology (Habash et al., 2012b), tagging (Habash et al., 2013; Pasha et al., 2014) and spelling correction (Eskander et al., 2013; Farra et al., 2014). This paper makes two main contributions. First, we clearly define the computational problem of transforming Arabizi to CODA. This improves over previous work by unambiguously fixing the In this paper, we address the problem of converting Dialectal Arabic (DA) text that is written in the Latin script (called Arabizi) into Arabic script following the CODA convention for DA orthography. The presented system uses a finite state transducer trained at the character level to generate all possible transliterations for the input Arabizi words. We then filter the generated list us"
W14-1604,P14-2027,1,0.915777,"nto? Our answer to this question is to use CODA, a conventional orthography created for the purpose of supporting NLP tools (Habash et al., 2012a). The goal of CODA is to reduce the data sparseness that comes from the same word form appearing in many spontaneous orthographies in data (be it annotated or unannotated). CODA has been defined for EGY as well as Tunisian Arabic (Zribi et al., 2014), and it has been used as part of different approaches for modeling DA morphology (Habash et al., 2012b), tagging (Habash et al., 2013; Pasha et al., 2014) and spelling correction (Eskander et al., 2013; Farra et al., 2014). This paper makes two main contributions. First, we clearly define the computational problem of transforming Arabizi to CODA. This improves over previous work by unambiguously fixing the In this paper, we address the problem of converting Dialectal Arabic (DA) text that is written in the Latin script (called Arabizi) into Arabic script following the CODA convention for DA orthography. The presented system uses a finite state transducer trained at the character level to generate all possible transliterations for the input Arabizi words. We then filter the generated list using a DA morphologica"
W14-1604,N06-1060,0,0.0836161,"ctal input. However, our final output is in EGY and not MSA. Shaalan et al. (2007) introduced a rule-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic, which Habash (2008) employed as part of generating English transliterations from Arabic words in the context of machine translation. This work is similar to ours in terms of text transliteration. However, our work is not restricted to names. 4 Approach 4.1 Defining the Task Our task is as follows: for each Arabizi word in the input, we choose the Arabic script word which is the correct CODA spelling of the input word and which carries the intended meaning (as determined in the context of the entire available text). We do n"
W14-1604,habash-etal-2012-conventional,1,0.732573,"established conventions to render the sounds of the DA sentence. Because the sound-to-letter rules of English are very different from those of Arabic, we obtain complex mappings between the two writing systems. This issue is compounded by the underlying problem that DA itself does not have any standard orthography in the Arabic script. Table 1 shows different plausible ways of writing an Egyptian Arabic (EGY) sentence in Arabizi and in Arabic script. Arabizi poses a problem for natural language processing (NLP). While some tools have recently become available for processing EGY input, e.g., (Habash et al., 2012b; Habash et al., 2013; Pasha et al., 2014), they expect Arabic script input (or a Buckwalter transliteration). They cannot process Arabizi. We therefore need a tool that converts from Arabizi to Arabic script. However, the lack of standard orthography in EGY compounds the problem: what should we convert Arabizi into? Our answer to this question is to use CODA, a conventional orthography created for the purpose of supporting NLP tools (Habash et al., 2012a). The goal of CODA is to reduce the data sparseness that comes from the same word form appearing in many spontaneous orthographies in data"
W14-1604,W12-2301,1,0.879522,"established conventions to render the sounds of the DA sentence. Because the sound-to-letter rules of English are very different from those of Arabic, we obtain complex mappings between the two writing systems. This issue is compounded by the underlying problem that DA itself does not have any standard orthography in the Arabic script. Table 1 shows different plausible ways of writing an Egyptian Arabic (EGY) sentence in Arabizi and in Arabic script. Arabizi poses a problem for natural language processing (NLP). While some tools have recently become available for processing EGY input, e.g., (Habash et al., 2012b; Habash et al., 2013; Pasha et al., 2014), they expect Arabic script input (or a Buckwalter transliteration). They cannot process Arabizi. We therefore need a tool that converts from Arabizi to Arabic script. However, the lack of standard orthography in EGY compounds the problem: what should we convert Arabizi into? Our answer to this question is to use CODA, a conventional orthography created for the purpose of supporting NLP tools (Habash et al., 2012a). The goal of CODA is to reduce the data sparseness that comes from the same word form appearing in many spontaneous orthographies in data"
W14-1604,N13-1044,1,0.945017,"ns to render the sounds of the DA sentence. Because the sound-to-letter rules of English are very different from those of Arabic, we obtain complex mappings between the two writing systems. This issue is compounded by the underlying problem that DA itself does not have any standard orthography in the Arabic script. Table 1 shows different plausible ways of writing an Egyptian Arabic (EGY) sentence in Arabizi and in Arabic script. Arabizi poses a problem for natural language processing (NLP). While some tools have recently become available for processing EGY input, e.g., (Habash et al., 2012b; Habash et al., 2013; Pasha et al., 2014), they expect Arabic script input (or a Buckwalter transliteration). They cannot process Arabizi. We therefore need a tool that converts from Arabizi to Arabic script. However, the lack of standard orthography in EGY compounds the problem: what should we convert Arabizi into? Our answer to this question is to use CODA, a conventional orthography created for the purpose of supporting NLP tools (Habash et al., 2012a). The goal of CODA is to reduce the data sparseness that comes from the same word form appearing in many spontaneous orthographies in data (be it annotated or un"
W14-1604,P08-2015,1,0.572407,"e-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic, which Habash (2008) employed as part of generating English transliterations from Arabic words in the context of machine translation. This work is similar to ours in terms of text transliteration. However, our work is not restricted to names. 4 Approach 4.1 Defining the Task Our task is as follows: for each Arabizi word in the input, we choose the Arabic script word which is the correct CODA spelling of the input word and which carries the intended meaning (as determined in the context of the entire available text). We do not merge two or more input words into a single Arabic script word. If CODA requires two con"
W14-1604,P07-2045,0,0.0151876,"following preprocessing steps to the input Arabizi text: • We separate all attached emoticons such as (:D, :p, etc.) and punctuation from the words. We only keep the apostrophe because it is used in Arabizi to distinguish between different sounds. 3ARRIB keeps track of any word offset change, so that it can reconstruct the same number of tokens at the end of the pipeline. The words in the parallel data are turned into space-separated character tokens, which we align using Giza++ (Och and Ney, 2003). We then use the phrase extraction utility in the Moses statistical machine translation system (Koehn et al., 2007) to extract a phrase table which operates over characters. The phrase table is then used to build a finite-state transducer (FST) that maps sequences of Arabizi characters into sequences of Arabic script characters. We use the negative logarithmic conditional probabilities of the Arabizi-to-Arabic pairs in the phrase tables as costs inside the FST. We use the FST to transduce an input Arabizi word to one or more words in Arabic script, where every resulting word in Arabic script is given a probabilistic score. • We tag emoticons and punctuation to protect them from any change through the pipel"
W14-1604,J03-1002,0,0.0107327,"input words (which constitute a “sausage” lattice) using an n-gram language model. 4.3 Preprocessing We apply the following preprocessing steps to the input Arabizi text: • We separate all attached emoticons such as (:D, :p, etc.) and punctuation from the words. We only keep the apostrophe because it is used in Arabizi to distinguish between different sounds. 3ARRIB keeps track of any word offset change, so that it can reconstruct the same number of tokens at the end of the pipeline. The words in the parallel data are turned into space-separated character tokens, which we align using Giza++ (Och and Ney, 2003). We then use the phrase extraction utility in the Moses statistical machine translation system (Koehn et al., 2007) to extract a phrase table which operates over characters. The phrase table is then used to build a finite-state transducer (FST) that maps sequences of Arabizi characters into sequences of Arabic script characters. We use the negative logarithmic conditional probabilities of the Arabizi-to-Arabic pairs in the phrase tables as costs inside the FST. We use the FST to transduce an input Arabizi word to one or more words in Arabic script, where every resulting word in Arabic script"
W14-1604,pasha-etal-2014-madamira,1,0.53623,"Missing"
W14-1604,W11-2602,1,0.832085,"t CODAFY works on spontaneous text written in Arabic script, while our system works on Arabizi, which involves a higher degree of ambiguity. However, we use CODAFY as a black-box module in our preprocessing. Additionally, there is some work on converting from dialectal Arabic to MSA, which is similar to our work in terms of processing a dialectal input. However, our final output is in EGY and not MSA. Shaalan et al. (2007) introduced a rule-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic, which Habash (2008) employed as part of generating English transliterations from Arabic words in the context of machine translation. This work is similar to ours in terms of text translite"
W14-1604,N13-1036,1,0.764251,"text written in Arabic script, while our system works on Arabizi, which involves a higher degree of ambiguity. However, we use CODAFY as a black-box module in our preprocessing. Additionally, there is some work on converting from dialectal Arabic to MSA, which is similar to our work in terms of processing a dialectal input. However, our final output is in EGY and not MSA. Shaalan et al. (2007) introduced a rule-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic, which Habash (2008) employed as part of generating English transliterations from Arabic words in the context of machine translation. This work is similar to ours in terms of text transliteration. However, our work is n"
W14-1604,2010.amta-papers.5,0,0.0449809,"system is that CODAFY works on spontaneous text written in Arabic script, while our system works on Arabizi, which involves a higher degree of ambiguity. However, we use CODAFY as a black-box module in our preprocessing. Additionally, there is some work on converting from dialectal Arabic to MSA, which is similar to our work in terms of processing a dialectal input. However, our final output is in EGY and not MSA. Shaalan et al. (2007) introduced a rule-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic, which Habash (2008) employed as part of generating English transliterations from Arabic words in the context of machine translation. This work is similar to ours"
W14-1604,zribi-etal-2014-conventional,1,0.904005,"r transliteration). They cannot process Arabizi. We therefore need a tool that converts from Arabizi to Arabic script. However, the lack of standard orthography in EGY compounds the problem: what should we convert Arabizi into? Our answer to this question is to use CODA, a conventional orthography created for the purpose of supporting NLP tools (Habash et al., 2012a). The goal of CODA is to reduce the data sparseness that comes from the same word form appearing in many spontaneous orthographies in data (be it annotated or unannotated). CODA has been defined for EGY as well as Tunisian Arabic (Zribi et al., 2014), and it has been used as part of different approaches for modeling DA morphology (Habash et al., 2012b), tagging (Habash et al., 2013; Pasha et al., 2014) and spelling correction (Eskander et al., 2013; Farra et al., 2014). This paper makes two main contributions. First, we clearly define the computational problem of transforming Arabizi to CODA. This improves over previous work by unambiguously fixing the In this paper, we address the problem of converting Dialectal Arabic (DA) text that is written in the Latin script (called Arabizi) into Arabic script following the CODA convention for DA o"
W14-1604,W02-0505,0,\N,Missing
W14-1604,W14-3629,0,\N,Missing
W14-1704,N12-1067,0,0.0945153,"Missing"
W14-1704,W13-1703,0,0.553096,"Missing"
W14-1704,W11-2838,0,0.437403,"Missing"
W14-1704,W12-2006,0,0.416041,"Missing"
W14-1704,P08-1118,0,0.0667098,"Missing"
W14-1704,W14-1701,0,0.309089,"Missing"
W14-1704,P11-1093,1,0.64212,"tion on the training set. This method prevents the source feature from dominating the context features, and improves the recall of the system. The other classifiers in the baseline system – noun number, verb agreement, verb form, and preposition – are trained on native English data, the Google Web 1T 5-gram corpus (henceforth, Google, (Brants and Franz, 2006)) with the Na¨ıve Bayes (NB) algorithm. All models use word ngram features derived from the 4-word window around the target word. In the preposition model, priors for preposition preferences are learned from the shared task training data (Rozovskaya and Roth, 2011). The modules targeting verb agreement and “Hence, the environmental *factor/factors also *contributes/contribute to various difficulties, *included/including problems in nuclear technology.” Error type Confusion set Noun number {factor, factors} Verb Agreement {contribute, contributes} {included, including, Verb Form includes, include} Table 2: Sample confusion sets for noun number, verb agreement, and verb form. 3 The Baseline System In this section, we briefly describe the University of Illinois system (henceforth Illinois; in the overview paper of the shared task the system is referred to"
W14-1704,D13-1074,1,0.92303,"competition covers all errors occurring in the data. Errors outside the target group were present in the task corpora last year as well, but were not evaluated. Our system extends the one developed by the University of Illinois (Rozovskaya et al., 2013) that placed first in the CoNLL-2013 competition. For this year’s shared task, the system has been extended and improved in several respects: we extended the set of errors addressed by the system, developed a general approach for improving the error-specific models, and added a joint inference component to address interaction among errors. See Rozovskaya and Roth (2013) for more detail. We briefly discuss the task (Section 2) and give an overview of the baseline Illinois system (Section 3). Section 4 presents the novel aspects of the system. In Section 5, we evaluate the complete system on the development data and show the results obtained on test. We offer error analysis and a brief discussion in Section 6. Section 7 concludes. The CoNLL-2014 shared task is an extension of last year’s shared task and focuses on correcting grammatical errors in essays written by non-native learners of English. In this paper, we describe the Illinois-Columbia system that part"
W14-1704,W12-2032,1,0.892017,"Missing"
W14-1704,E14-1038,1,0.918558,"sample confusion sets for noun, agreement, and form errors. Each classifier takes as input the corpus documents preprocessed with a part-of-speech tag2 http://cogcomp.cs.illinois.edu/page/ software view/POS 3 http://cogcomp.cs.illinois.edu/page/ software view/Chunker 1 ∅ denotes noun-phrase-initial contexts where an article is likely to have been omitted. The variants “a” and “an” are conflated and are restored later. 36 verb form mistakes draw on the linguisticallymotivated approach to correcting verb errors proposed in Rozovskaya et. al (2014). correcting verb errors, we refer the reader to Rozovskaya et al. (2014). 4 The Mec error category includes errors in spelling, context-sensitive spelling, capitalization, and punctuation. Our system addresses punctuation errors and capitalization errors. To correct capitalization errors, we collected words that are always capitalized in the training and development data when not occurring sentence-initially. The punctuation classifier includes two modules: a learned component targets missing and extraneous comma usage and is an AP classifier trained on the learner data with error inflation. A second, pattern-based component, complements the AP model: it inserts m"
W14-1704,W13-3602,1,\N,Missing
W14-1704,W13-3601,0,\N,Missing
W14-3603,E06-1047,1,0.489762,"nA /baTT+it+na/ ‘our duck’ and /mdars+ā +hum/ ‘she taught them’. Contributions that are specific to DA include the development of a pilot Levantine Arabic Treebank (LATB) of Jordanian Arabic, which contained morphological and syntactic annotations of about 26,000 words (Maamouri et al., 2006). To speed up the process of creating the LATB, Maamouri et al. (2006) adapted MSA Treebank guidelines to DA and experimented with extensions to the Buckwalter Arabic Morphological Analyzers (Buckwalter, 2004). The LATB was used in the Johns Hopkins workshop on Parsing Arabic Dialect (Rambow et al., 2005; Chiang et al., 2006), which supplemented the LATB effort with an experimental Levantine-MSA dictionary. The LATB effort differs from the work presented here in two respects. First, the LATB corpus consists of conversational telephone speech transcripts, which eliminated the orthographic variations issues that we face in this paper. Secondly, when the LATB was created, there were no robust tools for morphological analysis of any dialects; this is not the case any more. We plan to exploit existing tools for EGY to help the annotation effort. Third, PAL has many clitics that do not exist in MSA, e.g., the progressiv"
W14-3603,W14-3629,0,0.0176224,"iety. In the case of Arabic, unlike MSA that dominates the formal and written content outlets, as in the press, scientific articles, books, and historical narration, DAs are more naturally used in traditional and informal contexts, such as conversations in TV series, movies, or on social media platforms, providing socially powered commentary on different domains and topics. And given the lack of standard orthography, there is common mixing of phonetic spelling and MSA-cognate-based spelling in addition to the so-called Arabizi spelling – writing DAs in Roman script, rather than Arabic script (Darwish, 2014 and AlBadrashiny et al., 2014). Such noise imposes many challenges regarding the collection of high-coverage high-accuracy DA corpora. It is therefore important to remark that although bigger is better when it comes to corpus size, we focus more in this first iteration of our PAL corpus on precision and variety rather than mere 3.3 Dialectal Morphological Annotation Most of the work that explored morphology in Arabic focused on MSA (Al-Sughaiyer and AlKharashi, 2004; Buckwalter, 2004; Habash and Rambow, 2005; Graff et al., 2009; Habash, 2010). The contributions for DA morphology analysis, how"
W14-3603,P05-1071,1,0.76238,"ion to the so-called Arabizi spelling – writing DAs in Roman script, rather than Arabic script (Darwish, 2014 and AlBadrashiny et al., 2014). Such noise imposes many challenges regarding the collection of high-coverage high-accuracy DA corpora. It is therefore important to remark that although bigger is better when it comes to corpus size, we focus more in this first iteration of our PAL corpus on precision and variety rather than mere 3.3 Dialectal Morphological Annotation Most of the work that explored morphology in Arabic focused on MSA (Al-Sughaiyer and AlKharashi, 2004; Buckwalter, 2004; Habash and Rambow, 2005; Graff et al., 2009; Habash, 2010). The contributions for DA morphology analysis, however, are relatively scarce and are usually based on either extending available MSA tools to tackle DA specificities, as in the work of (Abo Bakr et al., 2008; Salloum and Habash, 2011), or modeling DAs directly, without relying on existing MSA contributions (Habash and Rambow, 2006). Due to the variations between MSA and DAs, available MSA tools and resources cannot be easily extended or transferred to work properly for DA (Maamouri, 21 size. That is, we tried not only to manually select and review the conte"
W14-3603,P09-2056,1,0.722837,"remain in MSA. Additionally, PAL in most of its sub-dialects collapses the feminine and masculine plurals and duals in verbs and 19 3. most nouns. Some specific inflections are ambiguous in PAL but not MSA, e.g.,  ﺣﺒﻴﯿﺖHbyt /Habbēt/ ‘I (or you [m.s.]) loved’. Related Work 3.1 Corpus Collection and Annotation There have been many contributions aiming to develop annotated Arabic language corpora, with the main objective of facilitating Arabic NLP applications. Notable contributions targeting MSA include the work of Maamouri and Cieri, (2002), Maamouri et al. (2004), Smrž and Hajič (2006), and Habash and Roth (2009). These efforts developed annotation guidelines for written MSA content producing large-scale Arabic Treebanks. Second, some specific morphemes are slightly or quite different in PAL from their MSA forms, e.g., the future marker is /sa/ in MSA but /Ha/ or /raH/ in PAL. Another prominent example is the feminine singular suffix morpheme (Ta Marbuta), which in MSA is pronounced as /at/ except at utterance final positions (where it is /a/). In some PAL urban sub dialects, it has multiple allomorphs that are phonologically and syntactically conditioned: /a/ (after non-front and emphatic consonants)"
W14-3603,W14-1604,1,0.724058,"Missing"
W14-3603,N13-1049,1,0.848131,"2012b). pB: Buckwalter POS The Buckwalter full POS tag, which identifies all clitics and affixes and the stem and assigns each a subtag. This representation treats clitics as separate tokens and abstracts the orthographic rewrites they undergo when cliticized. See the handling of the l/PREP+Al/DET in word #6 in Table 5. This representation is used by the LDC in the Penn Arabic Treebank (PATB) (Maamouri et al., 2004) and tools such as MADAMIRA (Pasha et al., 2014). It is a high granularity representation that allows researchers to easily go to coarser granularity POS (Diab 2007; Habash, 2010; Alkuhlani et al., 2013). The Buckwalter POS tag can be fully diacritized or undiacritized. Given the added complexity of producing diacritized text manually by annotators, we opted at this stage to only use undiacritized forms. • • that most Arabic speakers do not do and thus it requires a lot of training and precious attention to detail; (ii) MSA and EGY produce many morphemes and lexical items that are quite similar to PAL except in terms of the short vowels (compare the lemmas for word #5 in Tables 3, 4 and 5); (iii) PAL has many cases of multiple valid diacritizations as mentioned above. While we think a convent"
W14-3603,al-sabbagh-girju-2012-yadac,0,0.0598066,"šay’/ ‘for what thing?’. Examples of common words that are borrowed from other languages include the following: •  ﺭرﻭوﺯزﻧﺎﻣﻪﮫ/roznama/ ‘calendar’ (Persian) •  ﻛﻨﺪﺭرﺓة/kundara/ ‘shoe’ (Turkish) •  ﺑﻨﺪﻭوﺭرﺓة/banadora/ ‘tomato’ (Italian) •  ﺑﺮﻳﯾﻚ/brēk/ ‘brake (car)’ (English) •  ﺗﻠﻴﯿﻔﻴﯿﺰﻳﯾﻮﻥن/talifizyon/ ‘television’ (French) •  ﻣﺤﺴﻮﻡم/maHsūm/ ‘checkpoint’ (Hebrew) Other DA contributions include the Egyptian Colloquial Arabic Lexicon (ECAL) (Kilany, et al., 2002), which was developed as part of the CALLHOME Egyptian Arabic (CHE) corpus (Gadalla, et al., 1997). In addition to YADAC (Al-Sabbagh and Girju, 2012), which was based on dialectal content identification and web harvesting of blogs, micro blogs, and forums of EGY content. Similarly, the COLABA project (Diab et al., 2010) developed annotated dialectal content resources for Egyptian, Iraqi, Levantine, and Moroccan dialects, from online weblogs. 20 et al., 2006; Habash, et al., 2012b). Therefore, it is important to develop annotated and morpheme-segmented resources, along with morphological analysis tools, that are specific and tailored for DAs. One of the notable recent contributions for EGY morphological analysis was CALIMA (Habash et al., 2"
W14-3603,W12-2301,1,0.594546,"fficial written language of government, media and education in the Arab World, but it is not anyone’s native language; the spoken dialects vary widely across the Arab World and are the true native varieties Most Arabic NLP tools and resources were developed to serve Modern Standard Arabic (MSA), which is the official written language in 18 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 18–27, c October 25, 2014, Doha, Qatar. 2014 Association for Computational Linguistics of Arabic, yet they have no standard orthography and are not taught in schools (Habash et al., 2012, Zribi et al., 2014). dialects. The Druze dialect retains the /q/ pronunciation. Another example is the /k/ phoneme (corresponding to MSA  ﻙكk), which realizes as /tš/ in rural dialects. These difference cause the word for  ﻗﻠﺐqlb ‘heart’ to be pronounced as /qalb/, /’alb/, /kalb/ and /galb/ and to be ambiguous out of context with the word ﻛﻠﺐ klb ‘dog’ /kalb/ and /tšalb/. And similarly to EGY (but unlike Tunisian Arabic), the MSA phoneme /θ/ ( ﺙثθ) becomes /s/ or /t/, and the MSA phoneme /ð/ ( ﺫذð) becomes /z/ or /d/ in different lexical contexts, e.g., MSA  ﻛﺬﺏبkðb /kaðib/ ‘lyin"
W14-3603,N13-1044,1,0.822679,"developed annotated dialectal content resources for Egyptian, Iraqi, Levantine, and Moroccan dialects, from online weblogs. 20 et al., 2006; Habash, et al., 2012b). Therefore, it is important to develop annotated and morpheme-segmented resources, along with morphological analysis tools, that are specific and tailored for DAs. One of the notable recent contributions for EGY morphological analysis was CALIMA (Habash et al., 2012b). The CALIMA analyzer for EGY and the commonly used SAMA analyzer for MSA (Graff et al., 2009) are central in the functioning of the EGY morphological tagger MADA-ARZ (Habash et al., 2013), and its successor MADAMIRA (Pasha et al., 2014), which supports both MSA and EGY. 3.2 Dialectal Orthography Due to the lack of standardized orthography guidelines for DA, along with the phonological differences in comparison to MSA, and dialectal variations within the dialects themselves, there are many orthographic variations for written DA content. Writers in DA, regardless of the context, are often inconsistent with others and even with themselves when it comes to the written form of a dialect; writing with MSA driven orthography, or writing words phonologically sometimes. These orthograp"
W14-3603,maamouri-etal-2006-developing,1,0.699589,"mood, which remain in MSA. Additionally, PAL in most of its sub-dialects collapses the feminine and masculine plurals and duals in verbs and 19 3. most nouns. Some specific inflections are ambiguous in PAL but not MSA, e.g.,  ﺣﺒﻴﯿﺖHbyt /Habbēt/ ‘I (or you [m.s.]) loved’. Related Work 3.1 Corpus Collection and Annotation There have been many contributions aiming to develop annotated Arabic language corpora, with the main objective of facilitating Arabic NLP applications. Notable contributions targeting MSA include the work of Maamouri and Cieri, (2002), Maamouri et al. (2004), Smrž and Hajič (2006), and Habash and Roth (2009). These efforts developed annotation guidelines for written MSA content producing large-scale Arabic Treebanks. Second, some specific morphemes are slightly or quite different in PAL from their MSA forms, e.g., the future marker is /sa/ in MSA but /Ha/ or /raH/ in PAL. Another prominent example is the feminine singular suffix morpheme (Ta Marbuta), which in MSA is pronounced as /at/ except at utterance final positions (where it is /a/). In some PAL urban sub dialects, it has multiple allomorphs that are phonologically and syntactically conditioned: /a/ (after non-fr"
W14-3603,pasha-etal-2014-madamira,1,0.476314,"Missing"
W14-3603,W11-2602,1,0.534224,"t to remark that although bigger is better when it comes to corpus size, we focus more in this first iteration of our PAL corpus on precision and variety rather than mere 3.3 Dialectal Morphological Annotation Most of the work that explored morphology in Arabic focused on MSA (Al-Sughaiyer and AlKharashi, 2004; Buckwalter, 2004; Habash and Rambow, 2005; Graff et al., 2009; Habash, 2010). The contributions for DA morphology analysis, however, are relatively scarce and are usually based on either extending available MSA tools to tackle DA specificities, as in the work of (Abo Bakr et al., 2008; Salloum and Habash, 2011), or modeling DAs directly, without relying on existing MSA contributions (Habash and Rambow, 2006). Due to the variations between MSA and DAs, available MSA tools and resources cannot be easily extended or transferred to work properly for DA (Maamouri, 21 size. That is, we tried not only to manually select and review the content of the corpus, but also to assure that we covered a variety of topics and contexts, localities and sub-dialects, including the social class and gender of the speakers and writers. This is because such aspects help us discover new language phenomena in the dialect as w"
W14-3603,habash-etal-2012-conventional,1,\N,Missing
W14-3603,maamouri-etal-2014-developing,1,\N,Missing
W14-3603,zribi-etal-2014-conventional,1,\N,Missing
W14-3603,N13-1066,1,\N,Missing
W14-3605,C12-2011,0,0.247501,"Missing"
W14-3605,W14-3620,0,0.347563,"Missing"
W14-3605,W11-2838,0,0.0776592,"es. Our report includes an overview of the QALB corpus which was the source of the datasets used for training and evaluation, an overview of participating systems, results of the competition and an analysis of the results and systems. 1 Introduction The task of text correction has recently gained a lot of attention in the Natural Language Processing (NLP) community. Most of the effort in this area concentrated on English, especially on errors made by learners of English as a Second Language. Four competitions devoted to error correction for non-native English writers took place recently: HOO (Dale and Kilgarriff, 2011; Dale et al., 2012) and CoNLL (Ng et al., 2013; Ng et al., 2014). Shared tasks of this kind are extremely important, as they bring together researchers who focus on this problem and promote development and dissemination of key resources, such as benchmark datasets. Recently, there have been several efforts aimed at creating data resources related to the correction of Arabic text. Those include human annotated corpora (Zaghouani et al., 2014; Alfaifi and Atwell, 2012), spell-checking lexicon (Attia et al., 2012) and unannotated language learner corpora (Farwaneh and Tamimi, 2012). A natural ex"
W14-3605,W12-2006,0,0.0702953,"overview of the QALB corpus which was the source of the datasets used for training and evaluation, an overview of participating systems, results of the competition and an analysis of the results and systems. 1 Introduction The task of text correction has recently gained a lot of attention in the Natural Language Processing (NLP) community. Most of the effort in this area concentrated on English, especially on errors made by learners of English as a Second Language. Four competitions devoted to error correction for non-native English writers took place recently: HOO (Dale and Kilgarriff, 2011; Dale et al., 2012) and CoNLL (Ng et al., 2013; Ng et al., 2014). Shared tasks of this kind are extremely important, as they bring together researchers who focus on this problem and promote development and dissemination of key resources, such as benchmark datasets. Recently, there have been several efforts aimed at creating data resources related to the correction of Arabic text. Those include human annotated corpora (Zaghouani et al., 2014; Alfaifi and Atwell, 2012), spell-checking lexicon (Attia et al., 2012) and unannotated language learner corpora (Farwaneh and Tamimi, 2012). A natural extension to these res"
W14-3605,I13-2001,1,0.501252,"ompetitions is adopted: system outputs are compared against gold annotations using Precision, Recall and F1 . Systems are ranked based on the F1 scores obtained on the test set. The QALB Corpus One of the goals of the QALB project is to create a large manually corrected corpus of errors for a variety of Arabic texts, including user comments on news web sites, native and non-native speaker essays, and machine translation output. Within the framework of this project, comprehensive annotation guidelines and a specialized web-based annotation interface have been developed (Zaghouani et al., 2014; Obeid et al., 2013). The annotation process includes an initial automatic pre-processing step followed by an automatic correction of common spelling errors by the After the initial registration, the participants were provided with training and development sets and evaluation scripts. During the test period, the teams were given test data on which they needed to run their systems. Following the announcement of system results, the answer key to the test set was released. Participants authored description papers which will be presented in the Arabic NLP workshop. 40 Statistics Train. Dev. Test Number of docs. 19,41"
W14-3605,W12-5611,0,0.0562666,"Missing"
W14-3605,P05-1071,1,0.0923883,"Missing"
W14-3605,pasha-etal-2014-madamira,1,0.727075,"Missing"
W14-3605,W14-3615,0,0.0699428,"Missing"
W14-3605,W14-3618,1,0.793286,"Missing"
W14-3605,W14-3614,1,0.894222,"Missing"
W14-3605,W14-3621,0,0.0508845,"Missing"
W14-3605,zaghouani-etal-2014-large,1,0.605144,"ade by learners of English as a Second Language. Four competitions devoted to error correction for non-native English writers took place recently: HOO (Dale and Kilgarriff, 2011; Dale et al., 2012) and CoNLL (Ng et al., 2013; Ng et al., 2014). Shared tasks of this kind are extremely important, as they bring together researchers who focus on this problem and promote development and dissemination of key resources, such as benchmark datasets. Recently, there have been several efforts aimed at creating data resources related to the correction of Arabic text. Those include human annotated corpora (Zaghouani et al., 2014; Alfaifi and Atwell, 2012), spell-checking lexicon (Attia et al., 2012) and unannotated language learner corpora (Farwaneh and Tamimi, 2012). A natural extension to these resource production efforts is the creation of robust automatic systems for error correction. 2 Task Description The QALB shared task was created as a forum for competition and collaboration on automatic error correction in Modern Standard Arabic. The shared task makes use of the QALB corpus (Zaghouani et al., 2014), which is a manually-corrected collection of Arabic texts. The shared task participants were provided with tra"
W14-3605,W14-3617,0,0.0558201,"Missing"
W14-3605,W14-3616,0,0.123166,"Missing"
W14-3605,W14-3619,0,0.107829,"Missing"
W14-3605,W14-1701,0,\N,Missing
W14-3605,N12-1067,0,\N,Missing
W14-3605,W13-3602,1,\N,Missing
W14-3605,W15-3221,0,\N,Missing
W14-3605,W15-3220,0,\N,Missing
W14-3605,W15-3217,0,\N,Missing
W14-3605,W14-3622,1,\N,Missing
W14-3605,W15-3218,0,\N,Missing
W14-3605,W15-3214,0,\N,Missing
W14-3605,I08-2131,0,\N,Missing
W14-3605,W13-3601,0,\N,Missing
W14-3605,W11-2843,1,\N,Missing
W14-3612,W14-1604,1,0.873348,"buṣṣ/ “look” is  أنظر/’unZur/ in MSA. 3 per as part of the automatic transliteration step because they target the same conventional orthography of dialectal Arabic (CODA) (Habash et al., 2012a, 2012b), which we also target. There are several commercial products that convert Arabizi to Arabic script, namely: Microsoft Maren, 2 Google Ta3reeb, 3 Basis Arabic chat translator4 and Yamli.5 Since these products are for commercial purposes, there is little information available about their approaches, and whatever resources they use are not publicly available for research purposes. Furthermore, as Al-Badrashiny et al. (2014) point out, Maren, Ta3reeb and Yamli are primarily intended as input method support, not full text transliteration. As a result, their users’ goal is to produce Arabic script text not Arabizi text, which affects the form of the romanization they utilize as an intermediate step. The differences between such “functional romanization” and real Arabizi include that the users of these systems will use less or no code switching to English, and may employ character sequences that help them arrive at the target Arabic script form faster, which otherwise they would not write if they were targeting Arab"
W14-3612,W12-4808,0,0.117255,"(MSA) and dialectal Arabic (DA). Zaidan and Callison-Burch (2011) were interested in this problem at the inter-sentence level. They crawled a large dataset of MSA-DA news commentaries, and used Amazon Mechanical Turk to annotate the dataset at the sentence level. Elfardy et al. (2013) presented a system, AIDA, that tags each word in a sentence as either DA or MSA based on the context. Lui et al. (2014) proposed a system for language identification in Related Work Arabizi-Arabic Script Transliteration Previous efforts on automatic transliterations from Arabizi to Arabic script include work by Chalabi and Gerges (2012), Darwish (2013) and AlBadrashiny et al. (2014). All of these approaches rely on a model for character-to-character mapping that is used to generate a lattice of multiple alternative words which are then selected among using a language model. The training data used by Darwish (2013) is publicly available but it is quite limited (2,200 word pairs). The work we are describing here can help substantially improve the quality of such system. We use the system of Al-Badrashiny et al. (2014) in this pa2 http://www.getmaren.com http://www.google.com/ta3reeb 4 http://www.basistech.com/arabic-chat-trans"
W14-3612,R13-1026,0,0.0169932,"d topic modeling algorithms. Darwish (2013) and Voss et al. (2014) deal with exactly the problem of classifying tokens in Arabizi as Arabic or not. More specifically, Voss et al. (2014) deal with Moroccan Arabic, and with both French and English, meaning they do a three-way classification. Darwish (2013)&apos;s data is more focused on Egyptian and Levantine Arabic and code switching with English. Processing Social Media Text Finally, while English NLP for social media has attracted considerable attention recently (Clark and Araki, 2011; Gimpel et al., 2011; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much work on Arabic yet. Darwish et al. (2012) discuss NLP problems in retrieving Arabic microblogs (tweets). They discuss many of the same issues we do, notably the problems arising from the use of dialectal Arabic such as the lack of a standard orthography. Eskander et al. (2013) described a method for normalizing spontaneous orthography into CODA. 4 Egyptian Arabic has the advantage over all other dialects of Arabic of being the language of the largest linguistic community in the Arab region, and also of having a rich level of internet communication. 4.1 In BOLT Phase 2"
W14-3612,W14-3901,1,0.757221,"Missing"
W14-3612,N13-1066,1,0.386912,"&apos;s data is more focused on Egyptian and Levantine Arabic and code switching with English. Processing Social Media Text Finally, while English NLP for social media has attracted considerable attention recently (Clark and Araki, 2011; Gimpel et al., 2011; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much work on Arabic yet. Darwish et al. (2012) discuss NLP problems in retrieving Arabic microblogs (tweets). They discuss many of the same issues we do, notably the problems arising from the use of dialectal Arabic such as the lack of a standard orthography. Eskander et al. (2013) described a method for normalizing spontaneous orthography into CODA. 4 Egyptian Arabic has the advantage over all other dialects of Arabic of being the language of the largest linguistic community in the Arab region, and also of having a rich level of internet communication. 4.1 In BOLT Phase 2, LDC collected large volumes of naturally occurring informal text (SMS) and chat messages from individual users in English, Chinese and Egyptian Arabic (Song et al., 2014). Altogether we recruited 46 Egyptian Arabic participants, and of those 26 contributed data. To protect privacy, participation was"
W14-3612,P11-2008,0,0.0502639,"Missing"
W14-3612,W11-0704,0,0.0923825,"mixture model that is based on supervised topic modeling algorithms. Darwish (2013) and Voss et al. (2014) deal with exactly the problem of classifying tokens in Arabizi as Arabic or not. More specifically, Voss et al. (2014) deal with Moroccan Arabic, and with both French and English, meaning they do a three-way classification. Darwish (2013)&apos;s data is more focused on Egyptian and Levantine Arabic and code switching with English. Processing Social Media Text Finally, while English NLP for social media has attracted considerable attention recently (Clark and Araki, 2011; Gimpel et al., 2011; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much work on Arabic yet. Darwish et al. (2012) discuss NLP problems in retrieving Arabic microblogs (tweets). They discuss many of the same issues we do, notably the problems arising from the use of dialectal Arabic such as the lack of a standard orthography. Eskander et al. (2013) described a method for normalizing spontaneous orthography into CODA. 4 Egyptian Arabic has the advantage over all other dialects of Arabic of being the language of the largest linguistic community in the Arab region, and also of having a rich level"
W14-3612,habash-etal-2012-conventional,1,0.702911,"cation in Arabic takes place using a variety of orthographies and writing systems, including Arabic script, Arabizi, and a mixture of the two. Although not all social media communication uses Arabizi, the use of Arabizi is prevalent enough to pose a challenge for Arabic NLP research. In the context of natural language processing of social media Arabic, transliterating from Arabizi of various dialects to Arabic script is a necessary step, since many of the existing stateof-the-art resources for Arabic dialect processing and annotation expect Arabic script input (e.g., Salloum and Habash, 2011; Habash et al. 2012c; Pasha et al., 2014). To our knowledge, there are no naturally occurring parallel texts of Arabizi and Arabic script. In this paper, we describe the process of creating such a novel resource at the Linguistic Data Consortium (LDC). We believe this corpus will be essential for developing robust tools for converting Arabizi into Arabic script. Abstract This paper describes the process of creating a novel resource, a parallel Arabizi-Arabic script corpus of SMS/Chat data. The language used in social media expresses many differences from other written genres: its vocabulary is informal with inte"
W14-3612,W12-2301,1,0.860943,"cation in Arabic takes place using a variety of orthographies and writing systems, including Arabic script, Arabizi, and a mixture of the two. Although not all social media communication uses Arabizi, the use of Arabizi is prevalent enough to pose a challenge for Arabic NLP research. In the context of natural language processing of social media Arabic, transliterating from Arabizi of various dialects to Arabic script is a necessary step, since many of the existing stateof-the-art resources for Arabic dialect processing and annotation expect Arabic script input (e.g., Salloum and Habash, 2011; Habash et al. 2012c; Pasha et al., 2014). To our knowledge, there are no naturally occurring parallel texts of Arabizi and Arabic script. In this paper, we describe the process of creating such a novel resource at the Linguistic Data Consortium (LDC). We believe this corpus will be essential for developing robust tools for converting Arabizi into Arabic script. Abstract This paper describes the process of creating a novel resource, a parallel Arabizi-Arabic script corpus of SMS/Chat data. The language used in social media expresses many differences from other written genres: its vocabulary is informal with inte"
W14-3612,P97-1017,0,0.0276316,"tion. As a result, their users’ goal is to produce Arabic script text not Arabizi text, which affects the form of the romanization they utilize as an intermediate step. The differences between such “functional romanization” and real Arabizi include that the users of these systems will use less or no code switching to English, and may employ character sequences that help them arrive at the target Arabic script form faster, which otherwise they would not write if they were targeting Arabizi (Al-Badrashiny et al., 2014). Name Transliteration There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic. Although the general goal of transliterating from one script to another is shared between these efforts and ours, we are considering a more general form of the problem in that we do not restrict ourselves to names. Code Switching There is some work on code switching between Modern Standard Arabic (MSA) and dialectal Arabic (DA). Zaidan and Callison-Burch (2011) were interested in this problem at the inter"
W14-3612,maamouri-etal-2014-developing,1,0.720718,"ect Arabizi is used to write in multiple dialects of Arabic, and differences between the dialects themselves have an effect on the spellings chosen by individual writers using Arabizi. Because Egyptian Arabic is the dialect of the corpus cre1 http://www.darpa.mil/Our_Work/I2O/Programs/Broad_Op erational_Language_Translation_%28BOLT%29.aspx 94 ated for this project, we will briefly discuss some of the most relevant features of Egyptian Arabic with respect to Arabizi transliteration. For a more extended discussion of the differences between MSA and Egyptian Arabic, see Habash et al. (2012a) and Maamouri et al. (2014). Phonologically, Egyptian Arabic is characterized by the following features, compared with MSA: (a) The loss of the interdentals /ð/ and /θ/ which are replaced by /d/ or /z/ and /t/ or /s/ respectively, thus giving those two original consonants a heavier load. Examples include  ذكر/zakar/ “to mention”,  ذبح/dabaħ/ “to slaughter”,  ثلج/talg/ “ice”,  ثمن/taman/ “price”, and  ثبت/sibit/ “to stay in place, become immobile”. (b) The exclusion of /q/ and /ǰ/ from the consonantal system, being replaced by the /ʔ/ and /g/, e.g.,  قطن/ʔuṭn/ “cotton”, and جمل /gamal/ “camel”. At the level"
W14-3612,pasha-etal-2014-madamira,1,0.89422,"Missing"
W14-3612,D11-1141,0,0.0398961,"is based on supervised topic modeling algorithms. Darwish (2013) and Voss et al. (2014) deal with exactly the problem of classifying tokens in Arabizi as Arabic or not. More specifically, Voss et al. (2014) deal with Moroccan Arabic, and with both French and English, meaning they do a three-way classification. Darwish (2013)&apos;s data is more focused on Egyptian and Levantine Arabic and code switching with English. Processing Social Media Text Finally, while English NLP for social media has attracted considerable attention recently (Clark and Araki, 2011; Gimpel et al., 2011; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much work on Arabic yet. Darwish et al. (2012) discuss NLP problems in retrieving Arabic microblogs (tweets). They discuss many of the same issues we do, notably the problems arising from the use of dialectal Arabic such as the lack of a standard orthography. Eskander et al. (2013) described a method for normalizing spontaneous orthography into CODA. 4 Egyptian Arabic has the advantage over all other dialects of Arabic of being the language of the largest linguistic community in the Arab region, and also of having a rich level of internet communic"
W14-3612,W11-2602,1,0.567837,"013). Social media communication in Arabic takes place using a variety of orthographies and writing systems, including Arabic script, Arabizi, and a mixture of the two. Although not all social media communication uses Arabizi, the use of Arabizi is prevalent enough to pose a challenge for Arabic NLP research. In the context of natural language processing of social media Arabic, transliterating from Arabizi of various dialects to Arabic script is a necessary step, since many of the existing stateof-the-art resources for Arabic dialect processing and annotation expect Arabic script input (e.g., Salloum and Habash, 2011; Habash et al. 2012c; Pasha et al., 2014). To our knowledge, there are no naturally occurring parallel texts of Arabizi and Arabic script. In this paper, we describe the process of creating such a novel resource at the Linguistic Data Consortium (LDC). We believe this corpus will be essential for developing robust tools for converting Arabizi into Arabic script. Abstract This paper describes the process of creating a novel resource, a parallel Arabizi-Arabic script corpus of SMS/Chat data. The language used in social media expresses many differences from other written genres: its vocabulary i"
W14-3612,voss-etal-2014-finding,0,0.0375887,"then selected among using a language model. The training data used by Darwish (2013) is publicly available but it is quite limited (2,200 word pairs). The work we are describing here can help substantially improve the quality of such system. We use the system of Al-Badrashiny et al. (2014) in this pa2 http://www.getmaren.com http://www.google.com/ta3reeb 4 http://www.basistech.com/arabic-chat-translatortransforms-social-media-analysis/ 5 http://www.yamli.com/ 3 95 multilingual documents using a generative mixture model that is based on supervised topic modeling algorithms. Darwish (2013) and Voss et al. (2014) deal with exactly the problem of classifying tokens in Arabizi as Arabic or not. More specifically, Voss et al. (2014) deal with Moroccan Arabic, and with both French and English, meaning they do a three-way classification. Darwish (2013)&apos;s data is more focused on Egyptian and Levantine Arabic and code switching with English. Processing Social Media Text Finally, while English NLP for social media has attracted considerable attention recently (Clark and Araki, 2011; Gimpel et al., 2011; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much work on Arabic y"
W14-3612,P11-2007,0,0.0118384,"ere has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic. Although the general goal of transliterating from one script to another is shared between these efforts and ours, we are considering a more general form of the problem in that we do not restrict ourselves to names. Code Switching There is some work on code switching between Modern Standard Arabic (MSA) and dialectal Arabic (DA). Zaidan and Callison-Burch (2011) were interested in this problem at the inter-sentence level. They crawled a large dataset of MSA-DA news commentaries, and used Amazon Mechanical Turk to annotate the dataset at the sentence level. Elfardy et al. (2013) presented a system, AIDA, that tags each word in a sentence as either DA or MSA based on the context. Lui et al. (2014) proposed a system for language identification in Related Work Arabizi-Arabic Script Transliteration Previous efforts on automatic transliterations from Arabizi to Arabic script include work by Chalabi and Gerges (2012), Darwish (2013) and AlBadrashiny et al."
W14-3612,Q14-1003,0,0.0204432,"een these efforts and ours, we are considering a more general form of the problem in that we do not restrict ourselves to names. Code Switching There is some work on code switching between Modern Standard Arabic (MSA) and dialectal Arabic (DA). Zaidan and Callison-Burch (2011) were interested in this problem at the inter-sentence level. They crawled a large dataset of MSA-DA news commentaries, and used Amazon Mechanical Turk to annotate the dataset at the sentence level. Elfardy et al. (2013) presented a system, AIDA, that tags each word in a sentence as either DA or MSA based on the context. Lui et al. (2014) proposed a system for language identification in Related Work Arabizi-Arabic Script Transliteration Previous efforts on automatic transliterations from Arabizi to Arabic script include work by Chalabi and Gerges (2012), Darwish (2013) and AlBadrashiny et al. (2014). All of these approaches rely on a model for character-to-character mapping that is used to generate a lattice of multiple alternative words which are then selected among using a language model. The training data used by Darwish (2013) is publicly available but it is quite limited (2,200 word pairs). The work we are describing here"
W14-3612,W02-0505,0,\N,Missing
W14-3612,W14-3629,0,\N,Missing
W14-3612,song-etal-2014-collecting,1,\N,Missing
W14-3612,N06-1060,0,\N,Missing
W14-3614,I11-1017,0,0.0193196,"weighted finite-state transducer library. In CIAA, pages 11–23. the proposed systems build distinct models to address individual types of errors (see the CoNLL2013, 2014 proceedings (Ng et al., 2013a; Ng et al., 2014), and combine them afterwords using Integer Linear Programming for instance (Rozovskaya et al., 2013). This approach is relatively time-consuming when the number of error types increases. Interest in models that target all errors at once has increased, using either multi-class classifiers (Farra et al., 2014; Jia et al., 2013), of-the-shelf SMT techniques (Brockett et al., 2006; Mizumoto et al., 2011; Yuan and Felice, 2013; Buys and van der Merwe, 2013; Buys and van der Merwe, 2013), or building specialized decoders (Dahlmeier and Ng, 2012a). Our system addresses the weaknesses of the SMT approach using additional components in a pipeline architecture. Similar work on word-level and character-level model combination has been done in the context of translation between closely related languages (Nakov and Tiedemann, 2012). A character-level correction model has also been considered to reduce the out-of-vocabulary rate in translation systems (Habash, 2008). 5 Foundation). The statements made"
W14-3614,W14-3605,1,0.853538,"First, typical NLP tools lack in robustness against errors in their input. This sensitivity jeopardizes their usefulness especially for unedited text, which is prevalent on the web. Second, automated spell and grammar checkers facilitate text editing and can be of great help to nonnative speakers of a language. Several resources and shared tasks appeared recently, including the HOO task (Dale and Kilgarriff, 2010) and the CoNLL task on grammatical error correction (Ng et al., 2013b). In this paper we describe our participation to the first shared task on automatic error correction for Arabic (Mohit et al., 2014). While non-word errors are relatively easy to handle, the task is more challenging for grammatical and semantic errors. Detecting and correcting such errors require context-sensitive approaches in order to capture the dependencies between the words of a text at various lexical and semantic levels. All the more so for Arabic which 2 Pipeline Approach to Error Correction The PBSMT system accounts for context by learning, from a parallel corpus of annotated errors, mappings from erroneous multi-word segments of text to their corrections, and using a language model to help select the suitable cor"
W14-3614,P08-2015,1,0.810233,"ues (Brockett et al., 2006; Mizumoto et al., 2011; Yuan and Felice, 2013; Buys and van der Merwe, 2013; Buys and van der Merwe, 2013), or building specialized decoders (Dahlmeier and Ng, 2012a). Our system addresses the weaknesses of the SMT approach using additional components in a pipeline architecture. Similar work on word-level and character-level model combination has been done in the context of translation between closely related languages (Nakov and Tiedemann, 2012). A character-level correction model has also been considered to reduce the out-of-vocabulary rate in translation systems (Habash, 2008). 5 Foundation). The statements made herein are solely the responsibility of the authors. Nizar Habash performed most of his contribution to this paper while he was at the Center for Computational Learning Systems at Columbia University. Gabor Berend, Veronika Vincze, Sina Zarrieß, and Rich´ard Farkas. 2013. Lfg-based features for noun number and article grammatical errors. In Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task, pages 62–67, Sofia, Bulgaria, August. Association for Computational Linguistics. Chris Brockett, William B. Dolan, and Mi"
W14-3614,P12-2059,0,0.0210059,"s that target all errors at once has increased, using either multi-class classifiers (Farra et al., 2014; Jia et al., 2013), of-the-shelf SMT techniques (Brockett et al., 2006; Mizumoto et al., 2011; Yuan and Felice, 2013; Buys and van der Merwe, 2013; Buys and van der Merwe, 2013), or building specialized decoders (Dahlmeier and Ng, 2012a). Our system addresses the weaknesses of the SMT approach using additional components in a pipeline architecture. Similar work on word-level and character-level model combination has been done in the context of translation between closely related languages (Nakov and Tiedemann, 2012). A character-level correction model has also been considered to reduce the out-of-vocabulary rate in translation systems (Habash, 2008). 5 Foundation). The statements made herein are solely the responsibility of the authors. Nizar Habash performed most of his contribution to this paper while he was at the Center for Computational Learning Systems at Columbia University. Gabor Berend, Veronika Vincze, Sina Zarrieß, and Rich´ard Farkas. 2013. Lfg-based features for noun number and article grammatical errors. In Proceedings of the Seventeenth Conference on Computational Natural Language Learning"
W14-3614,W13-3610,0,0.0214864,"ojciech Skut, and Mehryar Mohri. 2007. Openfst: A general and efficient weighted finite-state transducer library. In CIAA, pages 11–23. the proposed systems build distinct models to address individual types of errors (see the CoNLL2013, 2014 proceedings (Ng et al., 2013a; Ng et al., 2014), and combine them afterwords using Integer Linear Programming for instance (Rozovskaya et al., 2013). This approach is relatively time-consuming when the number of error types increases. Interest in models that target all errors at once has increased, using either multi-class classifiers (Farra et al., 2014; Jia et al., 2013), of-the-shelf SMT techniques (Brockett et al., 2006; Mizumoto et al., 2011; Yuan and Felice, 2013; Buys and van der Merwe, 2013; Buys and van der Merwe, 2013), or building specialized decoders (Dahlmeier and Ng, 2012a). Our system addresses the weaknesses of the SMT approach using additional components in a pipeline architecture. Similar work on word-level and character-level model combination has been done in the context of translation between closely related languages (Nakov and Tiedemann, 2012). A character-level correction model has also been considered to reduce the out-of-vocabulary rat"
W14-3614,W13-3601,0,0.301464,"error correction generated considerable interest in the community since the early 1960s (Kukich, 1992) for at least two reasons. First, typical NLP tools lack in robustness against errors in their input. This sensitivity jeopardizes their usefulness especially for unedited text, which is prevalent on the web. Second, automated spell and grammar checkers facilitate text editing and can be of great help to nonnative speakers of a language. Several resources and shared tasks appeared recently, including the HOO task (Dale and Kilgarriff, 2010) and the CoNLL task on grammatical error correction (Ng et al., 2013b). In this paper we describe our participation to the first shared task on automatic error correction for Arabic (Mohit et al., 2014). While non-word errors are relatively easy to handle, the task is more challenging for grammatical and semantic errors. Detecting and correcting such errors require context-sensitive approaches in order to capture the dependencies between the words of a text at various lexical and semantic levels. All the more so for Arabic which 2 Pipeline Approach to Error Correction The PBSMT system accounts for context by learning, from a parallel corpus of annotated errors"
W14-3614,N03-1017,0,0.00389689,"e tagged themselves, cause their adjacent words to be marked as PROB instead. In this way, the subsequent components in the pipeline can be alerted to the possibility of a missing word via its surroundings. Any words not marked as PROB are given an “OK” tag. Gold tags, necessary for training, can be generated by comparing the text to its correction using some sequence alignment technique, for which we use SCLITE (Fiscus, 1998). For this task, we use Yamcha (Kudo and Mat2.3 Word-level PBSMT Correction We formalize the correction process as a phrasebased statistical machine translation problem (Koehn et al., 2003), at the word-level, and solve 1 We did not use MADAMIRA (the newest version of MADA) since it was not available when this component was built. 115 Back-off Primary Error Detection Character-level Correction Phrase tables Word-level PBSMT Correction N-best Reranking Punctuation Insertion , Input Reranked best hypothesis Error-tagged text . Output N-best hypotheses Figure 1: Input text is run through the error detection component which labels the problematic words. The labeled text is then fed to the character-level correction components which constructs a back-off phrase table. The PBSMT compo"
W14-3614,P07-2045,0,0.00354637,"eranking Punctuation Insertion , Input Reranked best hypothesis Error-tagged text . Output N-best hypotheses Figure 1: Input text is run through the error detection component which labels the problematic words. The labeled text is then fed to the character-level correction components which constructs a back-off phrase table. The PBSMT component then uses two phrase tables to generate n-best correction hypotheses. The reranking component selects the best hypothesis, and pass it to the punctuation insertion component in order to produce the final output. it using Moses, a well-known PBSMT tool (Koehn et al., 2007). The decoder constructs a correction hypothesis by first segmenting the input text into phrases, and mapping each phrase into its best correction using a combination of scores including a context-sensitive LM score. Unlike translation, error correction is mainly monotonic, therefore we set disallow reordering by setting the distortion limit in Moses to 0.2 When no mapping can be found for a given phrase in the primary phrase table, the decoder looks it up in the back-off model. The decoder searches the space of all possible correction hypotheses, resulting from alternative segmentations and m"
W14-3614,pasha-etal-2014-madamira,1,0.869619,"Missing"
W14-3614,W13-3612,0,0.0274093,"nder, number, person, aspect, voice, case, mood, state, proclitics and enclitics. This was done for two preceding words and two following words. However, the results were significantly outperformed by our final set-up. −1.7 0.8 Precision 0.6 AUC= 0.715 PRBE= 0.483, Cutoff= −0.349 Prec@rec(0.800)= 0.345, Cutoff= −1.045 0.2 0.4 3.3 1.61 1.0 4.93 Precision−Recall Curve 4 Character-level correction Related Work Both rule-based and data-driven approaches to error correction can be found in the literature (Sidorov et al., 2013; Berend et al., 2013; Yi et al., 2013) as well as hybridization of them (Putra and Szabo, 2013). Unlike our approach, most of We evaluate the character-level correction model by measuring the percentage of erroneous phrases that have been mapped to their in-context reference corrections. We found this percentage to be 117 System PBSMT backoff+PBSMT ED+backoff+PBSMT backoff+PBSMT+Rank backoff+PBSMT+Rank+PI PR 75.5 74.1 61.3 75.7 74.9 RC 49.5 51.8 45.4 52.1 54.2 F1 59.8 60.9 52.2 61.7 62.8 Table 1: Pipeline precision, recall and F1 scores. ED: error detection, PI: punctuation insertion. References Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wojciech Skut, and Mehryar Mohri. 2007. Open"
W14-3614,W13-3602,0,0.0694383,"4.1 61.3 75.7 74.9 RC 49.5 51.8 45.4 52.1 54.2 F1 59.8 60.9 52.2 61.7 62.8 Table 1: Pipeline precision, recall and F1 scores. ED: error detection, PI: punctuation insertion. References Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wojciech Skut, and Mehryar Mohri. 2007. Openfst: A general and efficient weighted finite-state transducer library. In CIAA, pages 11–23. the proposed systems build distinct models to address individual types of errors (see the CoNLL2013, 2014 proceedings (Ng et al., 2013a; Ng et al., 2014), and combine them afterwords using Integer Linear Programming for instance (Rozovskaya et al., 2013). This approach is relatively time-consuming when the number of error types increases. Interest in models that target all errors at once has increased, using either multi-class classifiers (Farra et al., 2014; Jia et al., 2013), of-the-shelf SMT techniques (Brockett et al., 2006; Mizumoto et al., 2011; Yuan and Felice, 2013; Buys and van der Merwe, 2013; Buys and van der Merwe, 2013), or building specialized decoders (Dahlmeier and Ng, 2012a). Our system addresses the weaknesses of the SMT approach using additional components in a pipeline architecture. Similar work on word-level and character"
W14-3614,W13-3613,0,0.0184864,"s where we train the complete list of features produced by MADAMIRA; that is part-ofspeech, gender, number, person, aspect, voice, case, mood, state, proclitics and enclitics. This was done for two preceding words and two following words. However, the results were significantly outperformed by our final set-up. −1.7 0.8 Precision 0.6 AUC= 0.715 PRBE= 0.483, Cutoff= −0.349 Prec@rec(0.800)= 0.345, Cutoff= −1.045 0.2 0.4 3.3 1.61 1.0 4.93 Precision−Recall Curve 4 Character-level correction Related Work Both rule-based and data-driven approaches to error correction can be found in the literature (Sidorov et al., 2013; Berend et al., 2013; Yi et al., 2013) as well as hybridization of them (Putra and Szabo, 2013). Unlike our approach, most of We evaluate the character-level correction model by measuring the percentage of erroneous phrases that have been mapped to their in-context reference corrections. We found this percentage to be 117 System PBSMT backoff+PBSMT ED+backoff+PBSMT backoff+PBSMT+Rank backoff+PBSMT+Rank+PI PR 75.5 74.1 61.3 75.7 74.9 RC 49.5 51.8 45.4 52.1 54.2 F1 59.8 60.9 52.2 61.7 62.8 Table 1: Pipeline precision, recall and F1 scores. ED: error detection, PI: punctuation insertion. Referen"
W14-3614,P13-2098,1,0.846224,"f n-best scoring hypotheses. scored n-best list is used for supervised training of a reranking model. We employ a pairwise approach to ranking which takes pairs of hypotheses as instances in learning, and formalizes the ranking problem as pairwise classification. For this task we use RankSVM (Joachims, 2002) which is a method based on Support Vector Machines (SVMs). We use only linear kernels to keep complexity low. We use a rich set of features including LM scores on surface forms, POS tags and lemmas. We also use a feature based on a global model of the semantic coherence of the hypotheses (Tomeh et al., 2013). The new top ranked hypothesis is the output of this step which is then fed to the next component. 2.4 We developed a model that predicts the occurrence of periods and commas in a given Arabic text. The core model is a decision tree classifier trained on the QALB parallel training data using WEKA (Hall et al., 2009). For each space between two words, the classifier decides whether or not to insert a punctuation mark, using a window size of three words surrounding the underlying space. The model uses the following features: 2.5 N-best List Reranking In this step, we combine LM information with"
W14-3614,W13-3617,0,0.0307163,"res produced by MADAMIRA; that is part-ofspeech, gender, number, person, aspect, voice, case, mood, state, proclitics and enclitics. This was done for two preceding words and two following words. However, the results were significantly outperformed by our final set-up. −1.7 0.8 Precision 0.6 AUC= 0.715 PRBE= 0.483, Cutoff= −0.349 Prec@rec(0.800)= 0.345, Cutoff= −1.045 0.2 0.4 3.3 1.61 1.0 4.93 Precision−Recall Curve 4 Character-level correction Related Work Both rule-based and data-driven approaches to error correction can be found in the literature (Sidorov et al., 2013; Berend et al., 2013; Yi et al., 2013) as well as hybridization of them (Putra and Szabo, 2013). Unlike our approach, most of We evaluate the character-level correction model by measuring the percentage of erroneous phrases that have been mapped to their in-context reference corrections. We found this percentage to be 117 System PBSMT backoff+PBSMT ED+backoff+PBSMT backoff+PBSMT+Rank backoff+PBSMT+Rank+PI PR 75.5 74.1 61.3 75.7 74.9 RC 49.5 51.8 45.4 52.1 54.2 F1 59.8 60.9 52.2 61.7 62.8 Table 1: Pipeline precision, recall and F1 scores. ED: error detection, PI: punctuation insertion. References Cyril Allauzen, Michael Riley, Joha"
W14-3614,W13-3607,0,0.0138704,"transducer library. In CIAA, pages 11–23. the proposed systems build distinct models to address individual types of errors (see the CoNLL2013, 2014 proceedings (Ng et al., 2013a; Ng et al., 2014), and combine them afterwords using Integer Linear Programming for instance (Rozovskaya et al., 2013). This approach is relatively time-consuming when the number of error types increases. Interest in models that target all errors at once has increased, using either multi-class classifiers (Farra et al., 2014; Jia et al., 2013), of-the-shelf SMT techniques (Brockett et al., 2006; Mizumoto et al., 2011; Yuan and Felice, 2013; Buys and van der Merwe, 2013; Buys and van der Merwe, 2013), or building specialized decoders (Dahlmeier and Ng, 2012a). Our system addresses the weaknesses of the SMT approach using additional components in a pipeline architecture. Similar work on word-level and character-level model combination has been done in the context of translation between closely related languages (Nakov and Tiedemann, 2012). A character-level correction model has also been considered to reduce the out-of-vocabulary rate in translation systems (Habash, 2008). 5 Foundation). The statements made herein are solely the"
W14-3614,zaghouani-etal-2014-large,1,0.830378,"Missing"
W14-3614,P11-1088,1,\N,Missing
W14-3614,W13-3606,0,\N,Missing
W14-3614,P06-1032,0,\N,Missing
W14-3614,N12-1067,0,\N,Missing
W14-3614,W13-3608,0,\N,Missing
W14-3614,P14-2027,1,\N,Missing
W14-3614,W10-4236,0,\N,Missing
W14-3622,P11-1093,1,0.834409,"ew The Columbia University system consists of several components designed to address different types of errors. We submitted three versions of the system. We refer to these as CLMB-1, CLMB-2, and CLMB-3. Table 1 lists all of the components and indicates which components are included in each version. The components are applied in the order shown in the table. Below we describe each component in more detail. 3.1 Maximum Likelihood Model 3.3 Na¨ıve Bayes for Unseen Words The Na¨ıve Bayes component addresses errors for words that were not seen in training. The system uses the approach proposed in Rozovskaya and Roth (2011) that proved to be successful for correcting errors made by English as a Second Language learners. The model operates at the word level and targets word replacement errors that involve single tokens. Candidate corrections are generated using a character confusion table that is based on the training data. The model is a Na¨ıve Bayes classifier trained on the Arabic Gigaword corpus (Parker et al., 2011) with word n-gram features in the 4-word window around the word to be corrected. The Na¨ıve Bayes component is used in the CLMB-1 system. MADAMIRA Corrector MADAMIRA (Pasha et al., 2014) is a tool"
W14-3622,W11-2602,1,0.834809,"Arabic speakers. Typically, an Arabic speaker has a native proficiency in one of the many Arabic dialects and learns to write and read MSA in a formal setting. For this reason, even in MSA texts produced by native Arabic speakers, one typically finds words and linguistic features specific to the writer’s native dialect that are not found in the standard language. To address such errors, we use Elissa (Salloum and Habash, 2012), which is Dialectal to Standard Arabic Machine Translation System. Elissa uses a rule-based approach that relies on the existence of a dialectal morphological analyzer (Salloum and Habash, 2011), a list of hand-written transfer rules, and dialectal-to-standard Arabic lexicons. Elissa uses different dialect identification techniques to select dialectal words and phrases (dialectal multi-word expressions) that need to be handled. Then equivalent MSA paraphrases of the selected words/phrases are generated and an MSA lattice for each input sentence is constructed. The paraphrases within the lattice are then ranked using language models and the n-best sentences are extracted from lattice. We use 5-gram language models trained using SRILM (Stolcke, 2002) on about 200 million untokenized, A"
W14-3622,N12-1067,0,0.114428,"articipating teams. We have presented three versions of the system; all of these incorporate several components that target different types of mistakes, which we presented and evaluated in this paper. • All sequences of the punctuation marks (., ?, !) that occur between two and six times are merged: e.g ! ! ! → !!!. 4 P 72.22 69.49 69.71 Experimental Results In Section 3, we described the individual system components that address different types of errors. In this section, we show how the system improves when each component is added into the system. System output is scored with the M2 scorer (Dahlmeier and Ng, 2012), the official scorer of the shared task. Table 2 reports performance results of each version of the Columbia system on the development data. Table 3 shows the performance results for the best-performing system, CLMB-1, as each system component is added. Acknowledgments This material is based on research funded by grant NPRP-4-1058-1-168 from the Qatar National Research Fund (a member of the Qatar Foundation). The statements made herein are solely the responsibility of the authors. Nizar Habash performed most of his contribution to this paper while he was at the Center for Computational Learni"
W14-3622,C12-3048,1,0.854648,"e model prediction. In other words, we only attempt to add missing punctuation. 3.6 Dialectal Usage Corrector Even though the shared task data is written in MSA, MSA is not a native language for Arabic speakers. Typically, an Arabic speaker has a native proficiency in one of the many Arabic dialects and learns to write and read MSA in a formal setting. For this reason, even in MSA texts produced by native Arabic speakers, one typically finds words and linguistic features specific to the writer’s native dialect that are not found in the standard language. To address such errors, we use Elissa (Salloum and Habash, 2012), which is Dialectal to Standard Arabic Machine Translation System. Elissa uses a rule-based approach that relies on the existence of a dialectal morphological analyzer (Salloum and Habash, 2011), a list of hand-written transfer rules, and dialectal-to-standard Arabic lexicons. Elissa uses different dialect identification techniques to select dialectal words and phrases (dialectal multi-word expressions) that need to be handled. Then equivalent MSA paraphrases of the selected words/phrases are generated and an MSA lattice for each input sentence is constructed. The paraphrases within the latti"
W14-3622,W12-5611,0,0.0465787,"Missing"
W14-3622,P14-2027,1,0.839873,"lso performs Alif and Ya spelling correction for the phenomena associated with these letters discussed in Section 2. The corrected form was included among the features and can be used for correcting the input. We use the corrections proposed by MADAMIRA and apply them to the data. As we show in Section 4, while the form proposed by MADAMIRA may not necessarily be correct, MADAMIRA performs at a very high precision. MADAMIRA corrector is used in the CLMB-1 and CLMB-2 systems. 3.4 The GSEC Model The CLMB-3 system implements a Generalized Character-Level Error Correction model (GSEC) proposed in Farra et al. (2014). GSEC is a supervised model that operates at the character level. Because of this, the source and the target side of the training data need to be aligned at the character level. We use the alignment tool Sclite (Fiscus, 1998). The alignment maps each source character to itself, a different character, a pair of characters, or an empty string. For the shared task, punctuation corrections are ignored since punctuation errors are handled by the punctuation corrector described in the following section. It should 161 also be noted that the model was not trained to insert missing characters. The mod"
W14-3622,zaghouani-etal-2014-large,1,0.743188,"Missing"
W14-3622,W14-3605,1,0.812099,"Missing"
W14-3622,W13-3601,0,0.0496276,"Missing"
W14-3622,W14-1701,0,0.0785017,"Missing"
W14-3622,pasha-etal-2014-madamira,1,0.768024,"in Rozovskaya and Roth (2011) that proved to be successful for correcting errors made by English as a Second Language learners. The model operates at the word level and targets word replacement errors that involve single tokens. Candidate corrections are generated using a character confusion table that is based on the training data. The model is a Na¨ıve Bayes classifier trained on the Arabic Gigaword corpus (Parker et al., 2011) with word n-gram features in the 4-word window around the word to be corrected. The Na¨ıve Bayes component is used in the CLMB-1 system. MADAMIRA Corrector MADAMIRA (Pasha et al., 2014) is a tool designed for morphological analysis and disambiguation of Modern Standard Arabic. MADAMIRA performs morphological analysis in context. This is a knowledge-rich resource that requires a morphological analyzer and a large corpus where every word is marked with its morphological features. The task organizers provided the shared task data pre-processed with MADAMIRA, including all of the features generated by the tool for every word. In addition to the morphological analysis and contextual morphological disambiguation, MADAMIRA also performs Alif and Ya spelling correction for the pheno"
W14-3623,P11-2103,0,0.0341937,"ent lexica in English and Arabic. Esuli and Sebastiani (2006) introduced English SentiWordNet (ESWN), a resource that associates synsets in the English WordNet (EWN) with scores for objectivity, positivity, and negativity. ESWN has been widely used for opinion mining in English (Denecke, 2008; Ohana and Tierney, 2009). Staiano and Guerini (2014) introduced DepecheMood, a 37K entry lexicon assigning emotion scores to words. This lexicon was created automatically by harvesting social media data and affective annotated data. In the context of developing sentiment lexica and resources for Arabic, Abdul-Mageed et al. (2011) evaluated the use of an adjective polarity lexicon on a manually annotated portion of the Penn Arabic Treebank. They describe the process of creating the adjective polarity lexicon (named SIFAAT) in Abdul-Mageed and Diab (2012) using a combination of manual and automatic annotations. The manual annotation consisted of extracting 3,982 Arabic adjectives from the Penn Arabic Tree (part 1) and manually labeling them into three tags: positive, negative or neutral. The automated annotation relied on the automatic translation of the ESWN synsets and glosses using Google translate. More recently, Ab"
W14-3623,esuli-sebastiani-2006-sentiwordnet,0,0.332094,"s and other low resource languages. We also present an extrinsic evaluation in terms of subjectivity and sentiment analysis. 1 Introduction Opinion mining refers to the extraction of subjectivity and polarity from text (Pang and Lee, 2005). With the growing availability and popularity of opinion rich resources such as online review sites and personal blogs, opinion mining is capturing the interest of many researchers due to its significant role in helping people make their decisions (Taboada et al., 2011). Some opinion mining methods in English rely on the English lexicon SentiWordnet (ESWN) (Esuli and Sebastiani, 2006; Baccianella et al., 2010) for extracting word-level sentiment polarity. Some researchers used the stored positive or Wassim El-Hajj Computer Science Department American University of Beirut, Lebanon we07@aub.edu.lb negative connotation of the words to combine them and derive the polarity of the text (Esuli and Sebastiani, 2005). Recently, special interest has been given to mining opinion from Arabic texts, and as a result, there has also been interest in developing an Arabic Lexicon for word-level sentiment evaluation. The availability of a large scale Arabic based SWN is still limited (Alha"
W14-3623,P05-1071,1,0.230666,"agated based on the links in the developed graph. The resulting Arabic sentiment lexicon which is of small size was compared to SIFAAT (Abdul-Mageed and Diab, 2012). We are inspired by these efforts for Arabic sentiment lexicon creation. We extend them by comparing different methods for creating such a resource with implications for other languages. Our lexicon is not only large-scale with high coverage and high accuracy, but it is also publicly available. Finally, our lemma-based lexicon is linked to a morphological analyzer for ease of use in conjunction with Arabic lemmatizer such as MADA (Habash and Rambow, 2005). 3 Approaches to Lexicon Creation We define our target Arabic Sentiment Lexicon (or ArSenL) as a resource, pairing Arabic lemmas used in the morphological analyzer SAMA with sentiment scores such as those used in ESWN (positive, negative and neutral scores). We briefly describe next the different resources we use, followed by two methods for creating ArSenL: using an existing Arabic WordNet or using English glosses in a dictionary. 166 3.1 Resources We rely on four existing resources to create ArSenL: English WordNet (EWN), Arabic WordNet (AWN), English SentiWordNet (ESWN) and SAMA. A high le"
W14-3623,abdul-mageed-diab-2014-sana,0,0.249034,"1) evaluated the use of an adjective polarity lexicon on a manually annotated portion of the Penn Arabic Treebank. They describe the process of creating the adjective polarity lexicon (named SIFAAT) in Abdul-Mageed and Diab (2012) using a combination of manual and automatic annotations. The manual annotation consisted of extracting 3,982 Arabic adjectives from the Penn Arabic Tree (part 1) and manually labeling them into three tags: positive, negative or neutral. The automated annotation relied on the automatic translation of the ESWN synsets and glosses using Google translate. More recently, Abdul-Mageed and Diab (2014) extended their lexicons creating SANA, a subjectivity and sentiment lexicon for Arabic. SANA combines different pre-existing lexica and involves extensive manual annotation, automatic machine translation and statistical formulation based on pointwise mutual information. The process also involved gloss matching across several resources such as THARWA (Diab et al., 2014) and SAMA (Graff et al., 2009). SANA included 224,564 entries which cover Modern Standard Arabic (MSA) as well as Egyptian and Levantine dialects. These entries are not distinct and possess many duplicates. Through these differe"
W14-3623,baccianella-etal-2010-sentiwordnet,0,0.116856,"guages. We also present an extrinsic evaluation in terms of subjectivity and sentiment analysis. 1 Introduction Opinion mining refers to the extraction of subjectivity and polarity from text (Pang and Lee, 2005). With the growing availability and popularity of opinion rich resources such as online review sites and personal blogs, opinion mining is capturing the interest of many researchers due to its significant role in helping people make their decisions (Taboada et al., 2011). Some opinion mining methods in English rely on the English lexicon SentiWordnet (ESWN) (Esuli and Sebastiani, 2006; Baccianella et al., 2010) for extracting word-level sentiment polarity. Some researchers used the stored positive or Wassim El-Hajj Computer Science Department American University of Beirut, Lebanon we07@aub.edu.lb negative connotation of the words to combine them and derive the polarity of the text (Esuli and Sebastiani, 2005). Recently, special interest has been given to mining opinion from Arabic texts, and as a result, there has also been interest in developing an Arabic Lexicon for word-level sentiment evaluation. The availability of a large scale Arabic based SWN is still limited (Alhazmi et al., 2013; Abdul-Mag"
W14-3623,P04-1035,0,0.00592674,"Missing"
W14-3623,P05-1015,0,0.0470128,"y publicly. In this paper, we address all of these issues and produce the first publicly available large scale Standard Arabic sentiment lexicon (ArSenL) using a combination of existing resources: ESWN, Arabic WordNet, and the Standard Arabic Morphological Analyzer (SAMA). We compare and combine two methods of constructing this lexicon with an eye on insights for Arabic dialects and other low resource languages. We also present an extrinsic evaluation in terms of subjectivity and sentiment analysis. 1 Introduction Opinion mining refers to the extraction of subjectivity and polarity from text (Pang and Lee, 2005). With the growing availability and popularity of opinion rich resources such as online review sites and personal blogs, opinion mining is capturing the interest of many researchers due to its significant role in helping people make their decisions (Taboada et al., 2011). Some opinion mining methods in English rely on the English lexicon SentiWordnet (ESWN) (Esuli and Sebastiani, 2006; Baccianella et al., 2010) for extracting word-level sentiment polarity. Some researchers used the stored positive or Wassim El-Hajj Computer Science Department American University of Beirut, Lebanon we07@aub.edu"
W14-3623,diab-etal-2014-tharwa,1,0.469568,"e (part 1) and manually labeling them into three tags: positive, negative or neutral. The automated annotation relied on the automatic translation of the ESWN synsets and glosses using Google translate. More recently, Abdul-Mageed and Diab (2014) extended their lexicons creating SANA, a subjectivity and sentiment lexicon for Arabic. SANA combines different pre-existing lexica and involves extensive manual annotation, automatic machine translation and statistical formulation based on pointwise mutual information. The process also involved gloss matching across several resources such as THARWA (Diab et al., 2014) and SAMA (Graff et al., 2009). SANA included 224,564 entries which cover Modern Standard Arabic (MSA) as well as Egyptian and Levantine dialects. These entries are not distinct and possess many duplicates. Through these different publications, the authors heavily rely on two types of techniques: manual annotations, which can be rather expensive (yet accurate) and automatic translation which is cheap (but very noisy since the Arabic output is not diacritized and no POS information was used). Their SANA lexicon has a mix of lemmas and inflected forms, many of which are not diacritized. This is"
W14-3623,J11-2001,0,0.00805408,"MA). We compare and combine two methods of constructing this lexicon with an eye on insights for Arabic dialects and other low resource languages. We also present an extrinsic evaluation in terms of subjectivity and sentiment analysis. 1 Introduction Opinion mining refers to the extraction of subjectivity and polarity from text (Pang and Lee, 2005). With the growing availability and popularity of opinion rich resources such as online review sites and personal blogs, opinion mining is capturing the interest of many researchers due to its significant role in helping people make their decisions (Taboada et al., 2011). Some opinion mining methods in English rely on the English lexicon SentiWordnet (ESWN) (Esuli and Sebastiani, 2006; Baccianella et al., 2010) for extracting word-level sentiment polarity. Some researchers used the stored positive or Wassim El-Hajj Computer Science Department American University of Beirut, Lebanon we07@aub.edu.lb negative connotation of the words to combine them and derive the polarity of the text (Esuli and Sebastiani, 2005). Recently, special interest has been given to mining opinion from Arabic texts, and as a result, there has also been interest in developing an Arabic Le"
W14-3623,P14-2063,0,\N,Missing
W14-3627,P06-1086,1,0.865853,"ia industry has traditionally played a dominant role in the Arab world, making the Egyptian dialect the most widely understood and used dialect. DA is now emerging as the language of informal communication online. DA differs phonologically, lexically, morphologically, and syntactically from MSA. And while MSA has an established standard orthography, the dialects do not: people write words reflecting their phonology and sometimes use roman script. Thus, MSA tools cannot effectively model DA; for instance, over one-third of Levantine verbs cannot be analyzed using an MSA morphological analyzer (Habash and Rambow, 2006). These differences make the direct use of MSA NLP tools and applications for handling dialects impractical. In this paper, we present a statistical machine translation system for English to Dialectal Arabic (DA), using Modern Standard Arabic (MSA) as a pivot. We create a core system to translate from English to MSA using a large bilingual parallel corpus. Then, we design two separate pathways for translation from MSA into DA: a two-step domain and dialect adaptation system and a one-step simultaneous domain and dialect adaptation system. Both variants of the adaptation systems are trained on"
W14-3627,W12-2301,1,0.940968,"for Machine Translation into Egyptian Arabic Serena Jeblee1 , Weston Feely1 , Houda Bouamor2 Alon Lavie1 , Nizar Habash3 and Kemal Oflazer2 1 Carnegie Mellon University {sjeblee, wfeely, alavie}@cs.cmu.edu 2 Carnegie Mellon University in Qatar hbouamor@qatar.cmu.edu, ko@cs.cmu.edu 3 New York University Abu Dhabi nizar.habash@nyu.edu Abstract chine translation (Zbib et al., 2012; Salloum and Habash, 2013; Salloum et al., 2014; Al-Mannai et al., 2014) and in terms of data collection (Cotterell and Callison-Burch, 2014; Bouamor et al., 2014; Salama et al., 2014) and basic enabling technologies (Habash et al., 2012; Pasha et al., 2014). However, the focus is on a small number of iconic dialects, (e.g., Egyptian). The Egyptian media industry has traditionally played a dominant role in the Arab world, making the Egyptian dialect the most widely understood and used dialect. DA is now emerging as the language of informal communication online. DA differs phonologically, lexically, morphologically, and syntactically from MSA. And while MSA has an established standard orthography, the dialects do not: people write words reflecting their phonology and sometimes use roman script. Thus, MSA tools cannot effective"
W14-3627,N13-1044,1,0.929805,"ey may not always be able to pinpoint exact linguistic differences. In the context of natural language processing (NLP), some Arabic dialects have started receiving increasing attention, particularly in the context of maEgyptian Arabic is much closer to MSA than it is to English, so one can get a system bet196 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 196–206, c October 25, 2014, Doha, Qatar. 2014 Association for Computational Linguistics nologies such as morphological analyzers are becoming available for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to tran"
W14-3627,W14-3628,0,0.190206,"Missing"
W14-3627,bouamor-etal-2014-multidialectal,1,0.847169,"r experimental setup and the results obtained. Then, we give an analysis of our system output in Section 7. Finally, we conclude and describe our future work in Section 8. 2 Related work Machine translation (MT) for dialectal Arabic (DA) is quite challenging given the limited resources to build rule-based models or train statistical models for MT. While there has been a considerable amount of work in the context of standard Arabic NLP (Habash, 2010), DA is impoverished in terms of available tools and resources compared to MSA, e.g., there are few parallel DAEnglish corpora (Zbib et al., 2012; Bouamor et al., 2014). The majority of DA resources are for speech recognition, although more and more resources for machine translation and enabling tech3 Using Phrase-Based MT as an Adaptation System For commercial use, MT output is usually postedited by a human translator in order to fix the errors generated by the MT system. This is often faster and cheaper than having a human translate 197 the document from scratch. However, we can apply statistical phrase-based MT to create an automatic machine post-editor (what we refer to in this paper as an adaptation system) to improve the output of an MT system, and mak"
W14-3627,W14-5311,0,0.0124183,"y translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation between Tunisian Arabic and MSA. These works are limited to a dictionary or rules that are not available for all dialects. Zbib et al. (2012) used crowdsourcing to translate sentences from Egyptian and Levantine into English, and thus built two bilingual corpora. The dialectal sentences were selected from a large corpus of Arabic web text. Then, they explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel data. They argued that differences in genre betwe"
W14-3627,I13-1048,0,0.0168271,"ent research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation between Tunisian Arabic and MSA. These works are limited to a dictionary or rules that are not available for all dialects. Zbib et al. (2012) used crowdsourcing to translate sentences from Egyptian and Levantine into English, and thus built two bilingual corpora. The dialectal sentences were selected from a large corpus of Arabic web text. Then, they explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel data. They argued that di"
W14-3627,P13-2121,0,0.0484788,"Missing"
W14-3627,P11-2031,1,0.921571,"m, which is a reordering window size of 7 for all systems, except for the phrase-based onestep domain and dialect adaptation system, which performs better with no reordering (0.2 BLEU better than a window of 7, 0.6 BLEU better than a window of 4), but these small differences in BLEU scores are within noise. The greatest difference in scores from the reordering windows was in the two-step systems domain adaptation step (MSA to MSA) on top of the phrase-based core, where a reordering window of 7 was 0.7 BLEU better than a window of 0. 6 6.1 Evaluation and Results For evaluation we use multeval (Clark et al., 2011) to calculate BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011), TER (Snover et al., 2006), and length of the test set for each system. We evaluate the core and adaptation systems on the MSA and Egyptian sides of the test set drawn from the 100k corpus, which we refer to as the 100k sets. The data used for evaluation is a genuine Egyptian Arabic generated from MSA, just like the data the systems were trained on. It is not practical to evaluate on naturallygenerated Egyptian Arabic in this case because the domain of our datasets is very formal, since most of the text comes from n"
W14-3627,W11-2123,0,0.0346794,"e one-step adaptation system, where no reordering produced the best result. We also tested two different heuristics for symmetrizing the word alignments: grow-diag and grow-diag-final-and (Och and Ney, 2003). We found that using grow-diag as our symmetrization heuristic produced slightly better scores on the 100k datasets. For the baseline and adaptation systems we built 5-gram language models with KenLM (Heafield et al., 2013) using the target side of the training set, and for the core system we used the large MSA language model described in section 4. We use KenLM because it has been shown (Heafield, 2011) to be faster and use less memory than SRILM (Stolcke, 2002) and IRSTLM (Federico et al., 2008). below each table. The difference in scores between the different reordering window sizes (7, 4, and 0) we tried for the adaptation systems was not large (between 0 and 0.7 BLEU). In the following tables we present the best results for each adaptation system, which is a reordering window size of 7 for all systems, except for the phrase-based onestep domain and dialect adaptation system, which performs better with no reordering (0.2 BLEU better than a window of 7, 0.6 BLEU better than a window of 4),"
W14-3627,cotterell-callison-burch-2014-multi,0,0.147926,"Missing"
W14-3627,2007.mtsummit-papers.34,0,0.0414651,"te 197 the document from scratch. However, we can apply statistical phrase-based MT to create an automatic machine post-editor (what we refer to in this paper as an adaptation system) to improve the output of an MT system, and make it more closely resemble the references. Simard et al. (2007) used a phrase-based MT system as an automatic posteditor for the output of a commercial rule-based MT system, showing that it produced better results than both the rule-based system alone and a single pass phrase-based MT system. This technique is also useful for adapting to a specific domain or dataset. Isabelle et al. (2007) used a statistical MT system to automatically post-edit the output of a generic rule-based MT system, to avoid manually customizing a system dictionary and to reduce the amount of manual post-editing required. For our adaptation systems, we build a core phrase-based MT system with a large amount of out-of-domain data, which allows us to have better coverage of the target language. For an adaptation system, we then build a second phrase-based MT system by translating the in-domain train, tune, and test sets through the core translation system, then using that data to build the second system. T"
W14-3627,P07-2045,0,0.00633831,"stem below. 1 198 http://arz.wikipedia.org/ System Design Baseline MT System 100K sent. English Translation Egyptian Arabic One-Step Adaptation MT System 5M sent. English Translation 100K sent. Domain & MSA Dialect Adaptation Egyptian Arabic Two-Step Adaptation MT System English 5M sent. 100K sent. Translation Domain Adaptation MSA 100K sent. In-domain MSA Dialect Adaptation Egyptian Arabic Figure 1: An overview of the different system architectures. Baseline System Two-Step Adaptation System Our baseline system is a single phrase-based English to Egyptian Arabic MT system, built using Moses (Koehn et al., 2007) on the 100k corpus described in Section 4. This system does not include any MSA data, nor does it have an adaptation system; it is a typical, one-pass MT system that translates English directly into Egyptian Arabic. We will show that using adaptation systems improves the results significantly. We also build a two-step adaptation system that consists of two adaptation steps: one to adapt the MSA output of the core system to the domain of the MSA in the 100k corpus, and a second system to translate the MSA output of the domain adaptation system into Egyptian Arabic. We use the first adaptation"
W14-3627,W11-2107,1,0.838244,"he phrase-based onestep domain and dialect adaptation system, which performs better with no reordering (0.2 BLEU better than a window of 7, 0.6 BLEU better than a window of 4), but these small differences in BLEU scores are within noise. The greatest difference in scores from the reordering windows was in the two-step systems domain adaptation step (MSA to MSA) on top of the phrase-based core, where a reordering window of 7 was 0.7 BLEU better than a window of 0. 6 6.1 Evaluation and Results For evaluation we use multeval (Clark et al., 2011) to calculate BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011), TER (Snover et al., 2006), and length of the test set for each system. We evaluate the core and adaptation systems on the MSA and Egyptian sides of the test set drawn from the 100k corpus, which we refer to as the 100k sets. The data used for evaluation is a genuine Egyptian Arabic generated from MSA, just like the data the systems were trained on. It is not practical to evaluate on naturallygenerated Egyptian Arabic in this case because the domain of our datasets is very formal, since most of the text comes from news sources, and dialectal Arabic is generally used in informal situations.2 B"
W14-3627,P12-2035,1,0.927262,"ools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation between Tunisian Arabic and MSA. These works are limited to a dictionary or rules that are not available for all dialects. Zbib et al. (2012) used crowdsourcing to translate sentences from Egyptian and Levantine into English, and thus built two bilingual corpora. The dialectal sentences were selected from a large corpus of Arabic web text. Then, they explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel"
W14-3627,P05-1071,1,0.686452,"and also to adapt to the Egyptian dialect. What we refer to as the “one-step” system is a core system plus one adaptation system, whereas the “two-step” system consists of the core plus two subsequent adaptation systems. We describe the systems in more detail in Section 5. sentences from NIST MT09 (NIST Multimodal Information Group, 2010b). We use a 5-gram MSA language model built using the SRILM toolkit (Stolcke, 2002) on 260 million words of MSA from the Arabic Gigaword (Parker et al., 2011). All our MSA parallel data and monolingual MSA language modeling data were tokenized with MADA v3.1 (Habash and Rambow, 2005) using the ATB (Arabic Treebank) tokenization scheme. For the adaptation systems, we build a 100k tri-parallel corpus Egyptian-MSA-English corpus. The MSA and English parts are extracted from the NIST corpus distributed by the Linguistic Data Consortium. The Egyptian sentences are obtained automatically by extending Mohamed et al. (2012) method for generating Egyptian Arabic from morphologically disambiguated MSA sentences. This rule-based method relies on 103 transformation rules covering essentially nouns, verbs and pronouns as well as certain lexical items. For each MSA sentence, this metho"
W14-3627,N07-1064,0,0.0331669,"ch recognition, although more and more resources for machine translation and enabling tech3 Using Phrase-Based MT as an Adaptation System For commercial use, MT output is usually postedited by a human translator in order to fix the errors generated by the MT system. This is often faster and cheaper than having a human translate 197 the document from scratch. However, we can apply statistical phrase-based MT to create an automatic machine post-editor (what we refer to in this paper as an adaptation system) to improve the output of an MT system, and make it more closely resemble the references. Simard et al. (2007) used a phrase-based MT system as an automatic posteditor for the output of a commercial rule-based MT system, showing that it produced better results than both the rule-based system alone and a single pass phrase-based MT system. This technique is also useful for adapting to a specific domain or dataset. Isabelle et al. (2007) used a statistical MT system to automatically post-edit the output of a generic rule-based MT system, to avoid manually customizing a system dictionary and to reduce the amount of manual post-editing required. For our adaptation systems, we build a core phrase-based MT"
W14-3627,J03-1002,0,0.00421305,"nts Since MSA and Egyptian are more similar to each other than they are to English, we tried several different reordering window sizes to find the optimal reordering distance for adapting MSA to Egyptian Arabic, including the typical reordering window of length 7, a smaller window of length 4, and no reordering at all. We found a reordering window 199 size of 7 to work best for all our systems, except for the one-step adaptation system, where no reordering produced the best result. We also tested two different heuristics for symmetrizing the word alignments: grow-diag and grow-diag-final-and (Och and Ney, 2003). We found that using grow-diag as our symmetrization heuristic produced slightly better scores on the 100k datasets. For the baseline and adaptation systems we built 5-gram language models with KenLM (Heafield et al., 2013) using the target side of the training set, and for the core system we used the large MSA language model described in section 4. We use KenLM because it has been shown (Heafield, 2011) to be faster and use less memory than SRILM (Stolcke, 2002) and IRSTLM (Federico et al., 2008). below each table. The difference in scores between the different reordering window sizes (7, 4,"
W14-3627,P02-1040,0,0.10335,"7 for all systems, except for the phrase-based onestep domain and dialect adaptation system, which performs better with no reordering (0.2 BLEU better than a window of 7, 0.6 BLEU better than a window of 4), but these small differences in BLEU scores are within noise. The greatest difference in scores from the reordering windows was in the two-step systems domain adaptation step (MSA to MSA) on top of the phrase-based core, where a reordering window of 7 was 0.7 BLEU better than a window of 0. 6 6.1 Evaluation and Results For evaluation we use multeval (Clark et al., 2011) to calculate BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011), TER (Snover et al., 2006), and length of the test set for each system. We evaluate the core and adaptation systems on the MSA and Egyptian sides of the test set drawn from the 100k corpus, which we refer to as the 100k sets. The data used for evaluation is a genuine Egyptian Arabic generated from MSA, just like the data the systems were trained on. It is not practical to evaluate on naturallygenerated Egyptian Arabic in this case because the domain of our datasets is very formal, since most of the text comes from news sources, and dialectal Arabic is gener"
W14-3627,2006.amta-papers.25,0,0.0165285,"d dialect adaptation system, which performs better with no reordering (0.2 BLEU better than a window of 7, 0.6 BLEU better than a window of 4), but these small differences in BLEU scores are within noise. The greatest difference in scores from the reordering windows was in the two-step systems domain adaptation step (MSA to MSA) on top of the phrase-based core, where a reordering window of 7 was 0.7 BLEU better than a window of 0. 6 6.1 Evaluation and Results For evaluation we use multeval (Clark et al., 2011) to calculate BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011), TER (Snover et al., 2006), and length of the test set for each system. We evaluate the core and adaptation systems on the MSA and Egyptian sides of the test set drawn from the 100k corpus, which we refer to as the 100k sets. The data used for evaluation is a genuine Egyptian Arabic generated from MSA, just like the data the systems were trained on. It is not practical to evaluate on naturallygenerated Egyptian Arabic in this case because the domain of our datasets is very formal, since most of the text comes from news sources, and dialectal Arabic is generally used in informal situations.2 Below we report BLEU scores"
W14-3627,pasha-etal-2014-madamira,1,0.871023,"Missing"
W14-3627,P11-2007,0,0.118831,"thod relies on 103 transformation rules covering essentially nouns, verbs and pronouns as well as certain lexical items. For each MSA sentence, this method provides more than one possible candidate, in its original version, the Egyptian sentence kept was chosen randomly. We extend the selection algorithm by scoring the different sentences using a language model. For this, we use SRILM with modified Kneser-Ney smoothing to build a 5-gram language model. The model is trained on a corpus including articles extracted from the Egyptian version of Wikipedia1 and the Egyptian side of the AOC corpus (Zaidan and Callison-Burch, 2011). We chose to include Egyptian Wikipedia for the formal level of sentences in it different from the regular DA written in blogs or microblogging websites (e.g., Twitter) and closer to the ones generated by our system. We split this data into train, tune, and test sets of 98,027, 960, and 961 sentences respectively, after removing duplicates across sets. The MSA corpus was tokenized using MADA and the Egyptian Arabic data was tokenized with MADA-ARZ v0.4 (Habash et al., 2013), both using the ATB tokenization scheme, with alif/ya normalization. 4 5 Data For the core English to MSA system, we use"
W14-3627,P13-2001,0,0.101077,"ble for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation between Tunisian Arabic and MSA. These works are limited to a dictionary or rules that are not available for all dialects. Zbib et al. (2012) used crowdsourcing to translate sentences from Egyptian and Levantine into English, and thus built two bilingual corpora. The dialectal sen"
W14-3627,N12-1006,0,0.393994,"ts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation between Tunisian Arabic and MSA. These works are limited to a dictionary or rules that are not available for all dialects. Zbib et al. (2012) used crowdsourcing to translate sentences from Egyptian and Levantine into English, and thus built two bilingual corpora. The dialectal sentences were selected from a large corpus of Arabic web text. Then, they explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel data. They argued that differences in genre between MSA and DA make bridging through MSA of limited value. For this reason, while pivoting through MSA, it is important to consider the domain and add an additional step: domain adaptation. The majority of previous e"
W14-3627,salama-etal-2014-youdacc,1,0.710505,"Missing"
W14-3627,N13-1036,1,0.844451,"English, so one can get a system bet196 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 196–206, c October 25, 2014, Doha, Qatar. 2014 Association for Computational Linguistics nologies such as morphological analyzers are becoming available for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation betwe"
W14-3627,P14-2125,1,0.860146,"Missing"
W14-3627,2010.amta-papers.5,0,0.287107,"than it is to English, so one can get a system bet196 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 196–206, c October 25, 2014, Doha, Qatar. 2014 Association for Computational Linguistics nologies such as morphological analyzers are becoming available for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowled"
W14-3901,W14-1604,1,0.912297,"al documents, using a generative mixture model that is based on supervised topic modeling algorithms. This is similar to our work in terms of identifying code switching. However, our system deals with Arabizi, a non-standard orthography with high variability, making the identification task much harder. Concerning specifically NLP for Arabizi, Darwish (2013) (published in an updated version as (Darwish, 2014)) is similar to our work in that he identifies English in Arabizi text and he also transliterates Arabic text from Arabizi to Arabic script. We compare our transliteration method to his in Al-Badrashiny et al. (2014). For identification of non-Arabic words in Arabizi, Darwish (2013) uses word and sequence-level features with CRF modeling; while we use SVMs and decision trees. Darwish (2013) identifies three tags: Arabic, foreign and others (such as email addresses and URLs). In contrast, we identify a bigger set: Arabic, foreign, names, sounds, punctuation use as a black box an existing component that we developed to transliterate from Arabizi to Arabic script (Al-Badrashiny et al., 2014). This paper concentrates on the task of identifying which tokens should be transliterated. A recent release of annotat"
W14-3901,W14-3612,1,0.804573,"rwish (2013) uses word and sequence-level features with CRF modeling; while we use SVMs and decision trees. Darwish (2013) identifies three tags: Arabic, foreign and others (such as email addresses and URLs). In contrast, we identify a bigger set: Arabic, foreign, names, sounds, punctuation use as a black box an existing component that we developed to transliterate from Arabizi to Arabic script (Al-Badrashiny et al., 2014). This paper concentrates on the task of identifying which tokens should be transliterated. A recent release of annotated data by the Linguistic Data Consortium (LDC, 2014c; Bies et al., 2014) has enabled novel research on this topic. The corpus provides each token with a tag, as well as a transliteration if appropriate. The tags identify foreign words, as well as Arabic words, names, punctuation, and sounds. Only Arabic words and names are transliterated. (Note that code switching is not distinguished from borrowing.) Emoticons, which may be isolated or part of an input token, are also identified, and converted into a conventional symbol (#). This paper presents taggers for the tags, and an end-to-end system which takes Arabizi input and produces a complex output which consists of"
W14-3901,W12-4808,0,0.0953446,"ally the case, hard. And, as in any language used in social media and chat, Arabizi may also include abbreviations, such as isa which An means é<Ë@ ZA à@ ˇ šA’ Allh ‘God willing’ and lol ‘laugh out loud’. The rows marked with Arabizi in Figure 1 demonstrate some of the salient features of Arabizi. The constructed example in the figure is of an SMS conversation in Egyptian Arabic. and emoticons. Furthermore, Darwish (2013) uses around 5K words for training his taggers and 3.5K words for testing; this is considerably smaller than our training and test sets of 113K and 32K words, respectively. Chalabi and Gerges (2012) presented a hybrid approach for Arabizi transliteration. Their work does not address the detection of English words, punctuation, emoticons, and so on. They also do not handle English when mixed with Arabizi. Voss et al. (2014) deal with exactly the problem of classifying tokens in Arabizi as Arabic or not. More specifically, they deal with Moroccan Arabic, and with both French and English, meaning they do a three-way classification. There are many differences between our work and theirs: they have noisy training data, and they have a much more balanced test set. They also only deal with fore"
W14-3901,habash-etal-2012-conventional,1,0.842679,"aid interpretation by indicating division of text into sentences and clauses, etc. Examples of punctuation marks are the semicolon ;, the exclamation mark ! and the right brace }. Emoticons are not considered punctuation and are handled as part of the transliteration task discussed below. Arabizi-to-Arabic Transliteration The second annotation task is about converting Arabizi to an Arabic-script-based orthography. Since, dialectal Arabic including Egyptian Arabic has no standard orthography in Arabic script, the annotation uses a conventionalized orthography for Dialectal Arabic called CODA (Habash et al., 2012a; Eskander et al., 2013; Zribi et al., 2014). Every word has a single orthographic representation in CODA. In the corpus we use, only words tagged as Arabic or Name are manually checked and corrected. The transliteration respects the whitespace boundaries of the original Arabizi words. In cases where an Arabizi word represents a prefix or suffix that should be joined in CODA to the next or previous word, a [+] symbol is added to mark this decision. Similarly, for Arabizi words that should be split into multiple CODA words, the CODA words are written with added [-] symbol delimiting the word b"
W14-3901,W12-2301,1,0.867263,"aid interpretation by indicating division of text into sentences and clauses, etc. Examples of punctuation marks are the semicolon ;, the exclamation mark ! and the right brace }. Emoticons are not considered punctuation and are handled as part of the transliteration task discussed below. Arabizi-to-Arabic Transliteration The second annotation task is about converting Arabizi to an Arabic-script-based orthography. Since, dialectal Arabic including Egyptian Arabic has no standard orthography in Arabic script, the annotation uses a conventionalized orthography for Dialectal Arabic called CODA (Habash et al., 2012a; Eskander et al., 2013; Zribi et al., 2014). Every word has a single orthographic representation in CODA. In the corpus we use, only words tagged as Arabic or Name are manually checked and corrected. The transliteration respects the whitespace boundaries of the original Arabizi words. In cases where an Arabizi word represents a prefix or suffix that should be joined in CODA to the next or previous word, a [+] symbol is added to mark this decision. Similarly, for Arabizi words that should be split into multiple CODA words, the CODA words are written with added [-] symbol delimiting the word b"
W14-3901,W14-3629,0,0.0893449,"ord is unknown in the LM, then its tag is assigned through MADAMIRA, a morphological disambiguator Pasha et al. (2014). Lui et al. (2014) proposed a system that does language identification in multilingual documents, using a generative mixture model that is based on supervised topic modeling algorithms. This is similar to our work in terms of identifying code switching. However, our system deals with Arabizi, a non-standard orthography with high variability, making the identification task much harder. Concerning specifically NLP for Arabizi, Darwish (2013) (published in an updated version as (Darwish, 2014)) is similar to our work in that he identifies English in Arabizi text and he also transliterates Arabic text from Arabizi to Arabic script. We compare our transliteration method to his in Al-Badrashiny et al. (2014). For identification of non-Arabic words in Arabizi, Darwish (2013) uses word and sequence-level features with CRF modeling; while we use SVMs and decision trees. Darwish (2013) identifies three tags: Arabic, foreign and others (such as email addresses and URLs). In contrast, we identify a bigger set: Arabic, foreign, names, sounds, punctuation use as a black box an existing compon"
W14-3901,R13-1026,0,0.016535,"system. This paper is structured as follows. We start by presenting related work (Section 2), and then we present relevant linguistic facts and explain how the data is annotated (Section 3). After summarizing our system architecture (Section 4) and experimental setup (Section 5), we present our systems for tagging in Sections 6, 7 and 8. The evaluation results are presented in Section 9. 2 Related Work While natural language processing for English in social media has attracted considerable attention recently (Clark and Araki, 2011; Gimpel et al., 2011; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much 2 T (which itself can be also be represented using the digit “6”). Text written in Arabizi also tends to have a large number of foreign words, that are either borrowings such as telephone, or code switching, such as love you!. Note that Arabizi often uses the source language orthography for borrowings (especially recent borrowings), even if the Arabic pronunciation is somewhat modified. As a result, distinguishing borrowings from code switching is, as is usually the case, hard. And, as in any language used in social media and chat, Arabizi may also include abbreviatio"
W14-3901,W14-3911,1,0.823497,"al with DA written in the Roman alphabet (though they do discuss non-Arabic characters). There is some work on code switching between Modern Standard Arabic (MSA) and dialectal Arabic (DA). Zaidan and Callison-Burch (2011) are interested in this problem at the intersentence level. They crawl a large dataset of MSA-DA news commentaries. They use Amazon Mechanical Turk to annotate the dataset at the sentence level. Then they use a language modeling approach to predict the class (MSA or DA) for an unseen sentence. There is other work on dialect identification, such as AIDA (Elfardy et al., 2013; Elfardy et al., 2014). In AIDA, some statistical and morphological analyses are applied to capture code switching between MSA and DA within the same sentence. Each word in the sentence is tagged to be either DA or MSA based on the context. The tagging process mainly depends on the language modeling (LM) approach, but if a word is unknown in the LM, then its tag is assigned through MADAMIRA, a morphological disambiguator Pasha et al. (2014). Lui et al. (2014) proposed a system that does language identification in multilingual documents, using a generative mixture model that is based on supervised topic modeling alg"
W14-3901,Q14-1003,0,0.0220534,"eling approach to predict the class (MSA or DA) for an unseen sentence. There is other work on dialect identification, such as AIDA (Elfardy et al., 2013; Elfardy et al., 2014). In AIDA, some statistical and morphological analyses are applied to capture code switching between MSA and DA within the same sentence. Each word in the sentence is tagged to be either DA or MSA based on the context. The tagging process mainly depends on the language modeling (LM) approach, but if a word is unknown in the LM, then its tag is assigned through MADAMIRA, a morphological disambiguator Pasha et al. (2014). Lui et al. (2014) proposed a system that does language identification in multilingual documents, using a generative mixture model that is based on supervised topic modeling algorithms. This is similar to our work in terms of identifying code switching. However, our system deals with Arabizi, a non-standard orthography with high variability, making the identification task much harder. Concerning specifically NLP for Arabizi, Darwish (2013) (published in an updated version as (Darwish, 2014)) is similar to our work in that he identifies English in Arabizi text and he also transliterates Arabic text from Arabizi"
W14-3901,N13-1066,1,0.89723,"Missing"
W14-3901,pasha-etal-2014-madamira,1,0.885156,"Missing"
W14-3901,P11-2008,0,0.0248831,"Missing"
W14-3901,D11-1141,0,0.0179926,"valuate the complete system. This paper is structured as follows. We start by presenting related work (Section 2), and then we present relevant linguistic facts and explain how the data is annotated (Section 3). After summarizing our system architecture (Section 4) and experimental setup (Section 5), we present our systems for tagging in Sections 6, 7 and 8. The evaluation results are presented in Section 9. 2 Related Work While natural language processing for English in social media has attracted considerable attention recently (Clark and Araki, 2011; Gimpel et al., 2011; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much 2 T (which itself can be also be represented using the digit “6”). Text written in Arabizi also tends to have a large number of foreign words, that are either borrowings such as telephone, or code switching, such as love you!. Note that Arabizi often uses the source language orthography for borrowings (especially recent borrowings), even if the Arabic pronunciation is somewhat modified. As a result, distinguishing borrowings from code switching is, as is usually the case, hard. And, as in any language used in social media and chat, Arabizi ma"
W14-3901,W11-0704,0,0.0699388,"us components, and evaluate the complete system. This paper is structured as follows. We start by presenting related work (Section 2), and then we present relevant linguistic facts and explain how the data is annotated (Section 3). After summarizing our system architecture (Section 4) and experimental setup (Section 5), we present our systems for tagging in Sections 6, 7 and 8. The evaluation results are presented in Section 9. 2 Related Work While natural language processing for English in social media has attracted considerable attention recently (Clark and Araki, 2011; Gimpel et al., 2011; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much 2 T (which itself can be also be represented using the digit “6”). Text written in Arabizi also tends to have a large number of foreign words, that are either borrowings such as telephone, or code switching, such as love you!. Note that Arabizi often uses the source language orthography for borrowings (especially recent borrowings), even if the Arabic pronunciation is somewhat modified. As a result, distinguishing borrowings from code switching is, as is usually the case, hard. And, as in any language used in social media"
W14-3901,voss-etal-2014-finding,0,0.251586,"in Figure 1 demonstrate some of the salient features of Arabizi. The constructed example in the figure is of an SMS conversation in Egyptian Arabic. and emoticons. Furthermore, Darwish (2013) uses around 5K words for training his taggers and 3.5K words for testing; this is considerably smaller than our training and test sets of 113K and 32K words, respectively. Chalabi and Gerges (2012) presented a hybrid approach for Arabizi transliteration. Their work does not address the detection of English words, punctuation, emoticons, and so on. They also do not handle English when mixed with Arabizi. Voss et al. (2014) deal with exactly the problem of classifying tokens in Arabizi as Arabic or not. More specifically, they deal with Moroccan Arabic, and with both French and English, meaning they do a three-way classification. There are many differences between our work and theirs: they have noisy training data, and they have a much more balanced test set. They also only deal with foreignness, and do not address the other tags we deal with, nor do they actually discuss transliteration itself. 3 3.2 The data set we use in this paper was created by the Linguistic Data Consortium (Bies et al., 2014; LDC, 2014a;"
W14-3901,P11-2007,0,0.119699,", pages 1–12, c October 25, 2014, Doha, Qatar. 2014 Association for Computational Linguistics work on Arabic yet. We give a brief summary of relevant work on Arabic. Darwish et al. (2012) discuss NLP problems in retrieving Arabic microblogs (tweets). They discuss many of the same issues we do, notably the problems arising from the use of DA such as the lack of a standard orthography. However, they do not deal with DA written in the Roman alphabet (though they do discuss non-Arabic characters). There is some work on code switching between Modern Standard Arabic (MSA) and dialectal Arabic (DA). Zaidan and Callison-Burch (2011) are interested in this problem at the intersentence level. They crawl a large dataset of MSA-DA news commentaries. They use Amazon Mechanical Turk to annotate the dataset at the sentence level. Then they use a language modeling approach to predict the class (MSA or DA) for an unseen sentence. There is other work on dialect identification, such as AIDA (Elfardy et al., 2013; Elfardy et al., 2014). In AIDA, some statistical and morphological analyses are applied to capture code switching between MSA and DA within the same sentence. Each word in the sentence is tagged to be either DA or MSA base"
W14-3901,zribi-etal-2014-conventional,1,0.894091,"Missing"
W14-3901,diab-etal-2014-tharwa,1,\N,Missing
W15-1614,abuhakema-etal-2008-annotating,0,0.311605,"access to detailed error statistics. This can provide learners with a very useful feedback and help them improve their proficiency level. 129 Proceedings of LAW IX - The 9th Linguistic Annotation Workshop, pages 129–139, c Denver, Colorado, June 5, 2015. 2015 Association for Computational Linguistics These errors may take place in words, phrases, language structures, and the ways words or expressions are used (Granger, 2003). For Arabic, there are few projects that aim at developing Arabic learner corpora and annotating them but most of them are not freely available for users or researchers (Abuhakema et al., 2008; Hassan and Daud, 2011). In this paper, we present our annotation method and our efforts for extending an L1 large scale Arabic language corpus and its manually edited corrections to include annotated non-native Arabic learner text (L2). This work is part of the Qatar Arabic Language Bank (QALB) project (Zaghouani et al., 2014b), a large-scale error annotation effort that aims to create a manually corrected corpus of errors for a variety of Arabic texts (the target size is 2 million words).1 Our overarching goal is to use our annotated corpus to develop components for automatic detection and"
W15-1614,W13-1703,0,0.0240313,"ar/CMU-CS-QTR-124.pdf 2 130 Section 2; then we describe the corpus and the annotation guidelines in Sections 3 and 4. Afterwards, we present our annotation tool and pipeline in Sections 5 and 6. Finally, we present an evaluation of the annotation quality and discuss the L2 annotation challenges in Section 7. 2 Related Work Currently available manually corrected learner corpora are generally limited when it comes to the language, size and the genre of data. Several corpora of learners of English annotated for errors are publicly available (Rozovskaya and Roth, 2010; Yannakoudakis et al., 2011; Dahlmeier et al., 2013), ranging in size between 60K words and more than one million words. Dickinson and Ledbetter (2012) annotated errors in student essays written by learners of Hungarian at three proficiency levels at Indiana University. The annotation was performed using EXMARaLDA, a freely available tool that allows multiple and concurrent annotations (Schmidt, 2010). Student errors were marked according to various categories of phonological, spelling, agreement and derivation errors. For Arabic, very few learner corpora annotation project have been built. Abuhakema et al. (2008) annotated a small corpus of 9K"
W15-1614,dickinson-ledbetter-2012-annotating,0,0.136697,"ines in Sections 3 and 4. Afterwards, we present our annotation tool and pipeline in Sections 5 and 6. Finally, we present an evaluation of the annotation quality and discuss the L2 annotation challenges in Section 7. 2 Related Work Currently available manually corrected learner corpora are generally limited when it comes to the language, size and the genre of data. Several corpora of learners of English annotated for errors are publicly available (Rozovskaya and Roth, 2010; Yannakoudakis et al., 2011; Dahlmeier et al., 2013), ranging in size between 60K words and more than one million words. Dickinson and Ledbetter (2012) annotated errors in student essays written by learners of Hungarian at three proficiency levels at Indiana University. The annotation was performed using EXMARaLDA, a freely available tool that allows multiple and concurrent annotations (Schmidt, 2010). Student errors were marked according to various categories of phonological, spelling, agreement and derivation errors. For Arabic, very few learner corpora annotation project have been built. Abuhakema et al. (2008) annotated a small corpus of 9K words of Arabic written materials produced by native speakers of English in the US who learned Ara"
W15-1614,N13-1066,1,0.853751,"ly accepted Arabic punctuation rules. 132 Dialectal Usage Errors: In comparison to Standard Arabic, where there are clear spelling standards and conventions, Arabic dialects do not have official orthographic standards partly since they were not commonly written until recently. Today, Arabic dialects are often seen in social media, but also in published novels (and there is even an Egyptian Arabic Wikipedia). Habash et al. (2012) proposed a Conventional Orthography for Dialectal Arabic (or CODA) targeting Egyptian Arabic for computational modeling purposes and demonstrated how to map to it in (Eskander et al., 2013) and (Pasha et al., 2014; Habash et al., 2013). CODAs for other dialects have also been proposed (Zribi et al., 2014; Jarrar et al., 2014). In our current annotation task we neither address dialectal Arabic spelling normalization (Eskander et al., 2013), nor do we systematically translate dialectal words into Standard Arabic (Salloum and Habash, 2013). We recognize that the Arabic language is in a diglossic situation and borrowing is frequent. Most of the texts provided for annotation are in Standard Arabic, but dialectal words are sometimes mistakenly used. We are interested in reducing vario"
W15-1614,I08-1059,0,0.0165036,"such as POS, lemma, gender, number or person. The robust design of MADAMIRA allows it to consider different possible spellings of words, especially relating to Ya/Alif-Maqsura, Ha/Ta-Marbuta and Hamzated Alif forms, which are very common error sources. MADAMIRA selects the correct form in context, thus correcting for these errors which are often connected to lemma choice or morphology. 7 7.1 Evaluation Inter-Annotator Agreement Our annotation effort consists of a single annotation pass as commonly done in many annotation projects due to time and budget constraints (Rozovskaya and Roth, 2010; Gamon et al., 2008; Izumi et al., 2004; Nagata et al., 2006). In order to evaluate the quality of our correction annotations, we frequently measure the inter-annotator agreement (IAA) to ensure that the annotators are following the guidelines provided consistently. A high level of agreement between the annotators indicates that the annotation is reliable and the guidelines are useful in producing homogeneous and consistent data. We measure the IAA by averaging WER (Word Error Rate) over all pairs of annotations to compute the AWER (Average 135 Word Error Rate).7 For the purpose of this evaluation, the WER refer"
W15-1614,habash-etal-2012-conventional,1,0.127188,"text uses one of multiple widely acceptable transliterations, the annotators should not modify the word. Punctuation Errors: Punctuation errors should be corrected according to the commonly accepted Arabic punctuation rules. 132 Dialectal Usage Errors: In comparison to Standard Arabic, where there are clear spelling standards and conventions, Arabic dialects do not have official orthographic standards partly since they were not commonly written until recently. Today, Arabic dialects are often seen in social media, but also in published novels (and there is even an Egyptian Arabic Wikipedia). Habash et al. (2012) proposed a Conventional Orthography for Dialectal Arabic (or CODA) targeting Egyptian Arabic for computational modeling purposes and demonstrated how to map to it in (Eskander et al., 2013) and (Pasha et al., 2014; Habash et al., 2013). CODAs for other dialects have also been proposed (Zribi et al., 2014; Jarrar et al., 2014). In our current annotation task we neither address dialectal Arabic spelling normalization (Eskander et al., 2013), nor do we systematically translate dialectal words into Standard Arabic (Salloum and Habash, 2013). We recognize that the Arabic language is in a diglossic"
W15-1614,N13-1044,1,0.82105,"tal Usage Errors: In comparison to Standard Arabic, where there are clear spelling standards and conventions, Arabic dialects do not have official orthographic standards partly since they were not commonly written until recently. Today, Arabic dialects are often seen in social media, but also in published novels (and there is even an Egyptian Arabic Wikipedia). Habash et al. (2012) proposed a Conventional Orthography for Dialectal Arabic (or CODA) targeting Egyptian Arabic for computational modeling purposes and demonstrated how to map to it in (Eskander et al., 2013) and (Pasha et al., 2014; Habash et al., 2013). CODAs for other dialects have also been proposed (Zribi et al., 2014; Jarrar et al., 2014). In our current annotation task we neither address dialectal Arabic spelling normalization (Eskander et al., 2013), nor do we systematically translate dialectal words into Standard Arabic (Salloum and Habash, 2013). We recognize that the Arabic language is in a diglossic situation and borrowing is frequent. Most of the texts provided for annotation are in Standard Arabic, but dialectal words are sometimes mistakenly used. We are interested in reducing various spelling inconsistencies that frequently oc"
W15-1614,W10-1802,0,0.0226722,"non-native speakers of other languages such as English (Leacock et al., 2010; Rozovskaya and Roth, 2010). Lexical Correction: Finally, if it is impossible to fully correct the word using the previous four steps, there is a clear case of word choice errors and the annotator may have to replace the word used. This can be employed to especially correct inadequate lexical choices or unknown words. In the example given in 5 3. Correct derivation errors; but keep root intact. 4 The minimum edits approach in error correction have already been used in the Error-tagged Learner Corpus of Czech project (Hana et al., 2010) 133 Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007): (in alphabetical orˇ der) AbtθjHxdðrzsšSDTDςγfqklmnhwy and the additional sym ˇ ¯  ˆ ð', yˆ Zø', ¯ bols: ’ Z, Â @, A @, A @, w h è, ý ø. 6 A clitic is a linguistic unit that is pronounced and written like an affix but is grammatically independent. Inflection Error Correction Original ˇ knt qd bdÂnA fy AlςAm AlmADy rHl¯h Alaý mk¯h. Correction ˇ knt qd bdÂt fy AlςAm AlmADy rHl¯h Alaý mk¯h. English Original Correction English Original Correction English Original Correction English  úÍ@ éÊgP  ú"
W15-1614,W14-3603,1,0.49852,"and conventions, Arabic dialects do not have official orthographic standards partly since they were not commonly written until recently. Today, Arabic dialects are often seen in social media, but also in published novels (and there is even an Egyptian Arabic Wikipedia). Habash et al. (2012) proposed a Conventional Orthography for Dialectal Arabic (or CODA) targeting Egyptian Arabic for computational modeling purposes and demonstrated how to map to it in (Eskander et al., 2013) and (Pasha et al., 2014; Habash et al., 2013). CODAs for other dialects have also been proposed (Zribi et al., 2014; Jarrar et al., 2014). In our current annotation task we neither address dialectal Arabic spelling normalization (Eskander et al., 2013), nor do we systematically translate dialectal words into Standard Arabic (Salloum and Habash, 2013). We recognize that the Arabic language is in a diglossic situation and borrowing is frequent. Most of the texts provided for annotation are in Standard Arabic, but dialectal words are sometimes mistakenly used. We are interested in reducing various spelling inconsistencies that frequently occur. So, as was done in the L1 annotation effort (Zaghouani et al., 2014b), we asked annotat"
W15-1614,W14-3605,1,0.412475,"us. The results obtained in the evaluation suggest that the annotators produced consistently similar results under the proposed guidelines. We believe that publishing this corpus will give researchers a common development and test set for developing related natural language processing applications. A subset of our L2 corpus will be used as part of the Second QALB Shared Task on Automatic Arabic Error Correction in conjunction with the ACL-2015 Workshop on Arabic NLP.9 This shared task follows the success of the First QALB Shared Task held in conjunction with EMNLP-2014 Workshop on Arabic NLP (Mohit et al., 2014). In the future, we will extend our annotation guidelines to address machine translation output correction (i.e., manual post-editing). We also plan to extend our systems for automatic correction of Arabic language errors (Jeblee et al., 2014; Rozovskaya et al., 2014) to handle L2 data, using the corpus discussed here for training and test purposes. 9 http://www.arabic-nlp.net/wanlp 137 Acknowledgements We thank anonymous reviewers for their valuable comments and suggestions. We also thank all our dedicated annotators: Noor Alzeer, Hoda Fathy, Hoda Ibrahim, Anissa Jrad, Samah Lakhal, Jihene Wa"
W15-1614,P06-1031,0,0.0280632,"erson. The robust design of MADAMIRA allows it to consider different possible spellings of words, especially relating to Ya/Alif-Maqsura, Ha/Ta-Marbuta and Hamzated Alif forms, which are very common error sources. MADAMIRA selects the correct form in context, thus correcting for these errors which are often connected to lemma choice or morphology. 7 7.1 Evaluation Inter-Annotator Agreement Our annotation effort consists of a single annotation pass as commonly done in many annotation projects due to time and budget constraints (Rozovskaya and Roth, 2010; Gamon et al., 2008; Izumi et al., 2004; Nagata et al., 2006). In order to evaluate the quality of our correction annotations, we frequently measure the inter-annotator agreement (IAA) to ensure that the annotators are following the guidelines provided consistently. A high level of agreement between the annotators indicates that the annotation is reliable and the guidelines are useful in producing homogeneous and consistent data. We measure the IAA by averaging WER (Word Error Rate) over all pairs of annotations to compute the AWER (Average 135 Word Error Rate).7 For the purpose of this evaluation, the WER refers to an annotation error and it is measure"
W15-1614,I13-2001,1,0.525343,"eyeglasses to read the book.’   @Q¯ @ ú Ë è @QÖÏ @ © A  P A¢ JË@ © A ú Ë H@ Table 1: Examples of the different parts of the correction priority order   ¯ h ‘mirror’ was replaced Table 1, the word è @QÖÏ @ AlmrA¯  P A¢ JË@ AlnDArAt ˇ by the word H@ ‘eyeglasses’. alignments starting from document tokenization to after human annotation. 5 6 The Annotation Tool In order to ensure the speed and efficiency of the annotation process, as well as better management, we provide the annotators with a web-based annotation framework, originally developed to manually correct errors in L1 texts (Obeid et al., 2013). The annotation interface allows annotators to perform different actions corresponding to the following types of corrections: (a) edit misspelled words; (b) move words that are not in the right location; (c) add missing words; (d) delete extraneous words; (e) merge words that have been split erroneously; and (f) split words that have been merged erroneously. In our final corpus output format, we record for each annotated file the list of actions taken by the annotator. These actions operate on one or two tokens depending on the action. We also supply token 134 The Annotation Pipeline The anno"
W15-1614,P02-1040,0,0.105018,"ear that ALC is less challenging than ALWC as shown in the IAA of the first round and second rounds. Overall, the high-level of agreement obtained in the second round shows that the annotators produced consistently similar results under the proposed guidelines; and their differences are all within acceptable variation. This of course makes the evaluation of automatic correction harder.8 7 The annotation manager is excluded from this evaluation. This problem might be solved by considering multiple references in the evaluation process similarly to what is done in machine translation evaluation (Papineni et al., 2002). Unfortu8 Original  ®Ö Ï @ úæîDKA ÐA« ú¯ éËA à@ ø ñK@ B@ . ZAKCJË@ ÉJ.¯ àA Anwy An sAnthy AlmqAl¯h fy ςAm AlAnsAn qbl AlθlAθA’. ‘I plan I will be-done the article in the year of humanity before Tuesday.’ Annotator 1 @ ÐA« á«  ®Ö Ï @ úæîE @ à @ ø ñK @ B éËA . ZAKCJË@ ÉJ.¯ àA ˇ Ânwy Ân Ânhy AlmqAl¯h ςn ςAm AlAnsAn qbl AlθlAθA’. ‘I plan to finish-off the article about the year of humanity before Tuesday.’ Annotator 2 @ ÕËA« á«  ®Ö Ï @ úæîE @ à @ ø ñK @ B éËA . ZAKCJË@ ÉJ.¯ àA ˇ Ânwy Ân Ânhy AlmqAl¯h ςn ςAlm AlAnsAn qbl AlθlAθA’. ‘I plan to finish-off the article about the"
W15-1614,pasha-etal-2014-madamira,1,0.792787,"Missing"
W15-1614,W10-1004,1,0.231979,"able at http://reports-archive.adm.cs.cmu.edu/ anon/qatar/CMU-CS-QTR-124.pdf 2 130 Section 2; then we describe the corpus and the annotation guidelines in Sections 3 and 4. Afterwards, we present our annotation tool and pipeline in Sections 5 and 6. Finally, we present an evaluation of the annotation quality and discuss the L2 annotation challenges in Section 7. 2 Related Work Currently available manually corrected learner corpora are generally limited when it comes to the language, size and the genre of data. Several corpora of learners of English annotated for errors are publicly available (Rozovskaya and Roth, 2010; Yannakoudakis et al., 2011; Dahlmeier et al., 2013), ranging in size between 60K words and more than one million words. Dickinson and Ledbetter (2012) annotated errors in student essays written by learners of Hungarian at three proficiency levels at Indiana University. The annotation was performed using EXMARaLDA, a freely available tool that allows multiple and concurrent annotations (Schmidt, 2010). Student errors were marked according to various categories of phonological, spelling, agreement and derivation errors. For Arabic, very few learner corpora annotation project have been built. A"
W15-1614,W14-3622,1,0.888722,"Missing"
W15-1614,N13-1036,1,0.851271,"shed novels (and there is even an Egyptian Arabic Wikipedia). Habash et al. (2012) proposed a Conventional Orthography for Dialectal Arabic (or CODA) targeting Egyptian Arabic for computational modeling purposes and demonstrated how to map to it in (Eskander et al., 2013) and (Pasha et al., 2014; Habash et al., 2013). CODAs for other dialects have also been proposed (Zribi et al., 2014; Jarrar et al., 2014). In our current annotation task we neither address dialectal Arabic spelling normalization (Eskander et al., 2013), nor do we systematically translate dialectal words into Standard Arabic (Salloum and Habash, 2013). We recognize that the Arabic language is in a diglossic situation and borrowing is frequent. Most of the texts provided for annotation are in Standard Arabic, but dialectal words are sometimes mistakenly used. We are interested in reducing various spelling inconsistencies that frequently occur. So, as was done in the L1 annotation effort (Zaghouani et al., 2014b), we asked annotators to flag the highly dialectal cases to be reviewed later by the annotation manager. The guidelines classify dialectal word issues into five categories inspired by Habash et al. (2008): dialectal lexical choice, p"
W15-1614,W08-1205,0,0.00798721,"etailed description of ALC is given at: http://www.arabiclearnercorpus.com/ 131 and structures, with some items overused and others significantly underused. They also contain varying degrees of grammatical, orthographic and lexical errors. Moreover, sentences written by Arabic L2 speaker have often a different structure and are not as fluent as sentences produced by a native speaker even when no clear mistakes can be found. Therefore, the correction task is complicated by the fact that the acceptability level of a given sentence differs widely within the native speaker annotators as stated by Tetreault and Chodorow (2008). These issues can be related to linguistic factors such as inter-language (L1 interference), the student’s teaching and learning methodology, and to the translation effect (conscious interference). Thus, correcting the Arabic L2 essays can be a very challenging task that requires a lot of interpretation efforts by the annotators. This will likely lead to lower inter-annotator agreement as there is often many possible ways to correct the L2 errors. In order to annotate the L2 corpus, we use our annotation guidelines designed for L1 (Zaghouani et al., 2014b) and add specific L2 annotation rules"
W15-1614,P11-1019,0,0.0242372,"ive.adm.cs.cmu.edu/ anon/qatar/CMU-CS-QTR-124.pdf 2 130 Section 2; then we describe the corpus and the annotation guidelines in Sections 3 and 4. Afterwards, we present our annotation tool and pipeline in Sections 5 and 6. Finally, we present an evaluation of the annotation quality and discuss the L2 annotation challenges in Section 7. 2 Related Work Currently available manually corrected learner corpora are generally limited when it comes to the language, size and the genre of data. Several corpora of learners of English annotated for errors are publicly available (Rozovskaya and Roth, 2010; Yannakoudakis et al., 2011; Dahlmeier et al., 2013), ranging in size between 60K words and more than one million words. Dickinson and Ledbetter (2012) annotated errors in student essays written by learners of Hungarian at three proficiency levels at Indiana University. The annotation was performed using EXMARaLDA, a freely available tool that allows multiple and concurrent annotations (Schmidt, 2010). Student errors were marked according to various categories of phonological, spelling, agreement and derivation errors. For Arabic, very few learner corpora annotation project have been built. Abuhakema et al. (2008) annot"
W15-1614,zaghouani-etal-2014-large,1,0.588046,"Missing"
W15-1614,zribi-etal-2014-conventional,1,0.33632,"Missing"
W15-1614,W14-3618,1,\N,Missing
W15-3204,W15-3214,0,0.0408316,"Missing"
W15-3204,I08-2131,0,0.0157927,"trated on English, especially on errors made by learners of English as a Second Language. Four competitions devoted to error correction for non-native English writers took place recently: HOO (Dale and Kilgarriff, 2011; Dale et al., 2012) and CoNLL (Ng et al., 2013; Ng et al., 2014). Shared tasks of this kind are extremely important, as they bring together researchers and promote the development of relevant techniques and dissemination of key resources, such as benchmark data sets. In the area of Arabic text correction, there has been a significant body of work, as well (Shaalan et al., 2003; Hassan et al., 2008). However, due to the lack of a common benchmark data set, making progress on this task has been difficult. The QALB shared task on automatic text correction of Arabic, 1 http://nlp.qatar.cmu.edu/qalb/ 26 Proceedings of the Second Workshop on Arabic Natural Language Processing, pages 26–35, c Beijing, China, July 26-31, 2015. 2014 Association for Computational Linguistics 2 Task Description The texts are manually annotated for errors by native Arabic speakers. The annotation begins with an initial automatic pre-processing step. Next, the files are processed with the morphological analysis and"
W15-3204,C12-2011,0,0.0931945,"Missing"
W15-3204,W14-3605,1,0.841304,"al Learning Systems, Columbia University 2 Carnegie Mellon University in Qatar 3 New York University Abu Dhabi 4 Ask.com alla@ccls.columbia.edu,hbouamor@qatar.cmu.edu,nizar.habash@nyu.edu wajdiz@qatar.cmu.edu,owo@qatar.cmu.edu,behrang@cmu.edu Abstract organized within the framework of the Qatar Arabic Language Bank (QALB) project,1 is the first effort aimed at constructing a benchmark data set, which will allow for development and evaluation of automatic correction systems for Arabic. In this paper, we present a summary of the second edition of the QALB competition. The first one – QALB-2014 (Mohit et al., 2014) – took place in conjunction with the Arabic NLP workshop at EMNLP-2014 and focused on errors found in online commentaries produced by native speakers of Arabic. QALB-2014 attracted a lot of attention and resulted in nine systems being submitted with a variety of approaches that included rule-based frameworks, machine-learning classifiers, and statistical machine translation methods. This year’s competition extends the first edition by adding another track that focuses on errors found in essays written by learners of Arabic. Eight teams participated in the competition this year, including seve"
W15-3204,W15-3216,0,0.0195413,"Missing"
W15-3204,W15-3220,0,0.0483413,"Missing"
W15-3204,W15-3217,1,0.853627,"Missing"
W15-3204,W15-3218,0,0.0309508,"Missing"
W15-3204,W15-3221,1,0.873886,"Missing"
W15-3204,W15-3215,0,0.125217,"Missing"
W15-3204,N12-1067,0,0.0704061,"ariety of techniques. For example, the CUFE system extracted rules from the morphological analyzer and learned their probabilities using the training data, while the UMMU system combined statistical machine6 Results In this section, we present the results of the competition. As was done in QALB-2014, we adopted the standard Precision (P), Recall (R), and F1 metric. This metric was also used in recent shared tasks on grammatical error correction in English: HOO competitions (Dale and Kilgarriff, 2011; Dale et al., 2012) and CoNLL (Ng et al., 2013). The results are computed using the M2 scorer (Dahlmeier and Ng, 2012) that was also used in the CoNLL shared tasks. Tables 8 and 9 present the official results of the evaluation on the test sets for the Aljazeera data and the L2 data, respectively. The results are sorted according to the F1 scores obtained by the 30 Rank 1 2 3 4 5 6 7 8 9 10 11 12 Team CUFE UMMU-1 GWU UMMU-2 QCRI QCMUQ TECH-2 TECH-1 TECH-3 ARIB-1 ARIB-2 SAHSOH MADAMIRA P 88.85 70.28 74.69 72.69 84.74 71.39 71.20 71.08 69.99 64.50 67.56 81.88 80.32 R 61.76 71.93 67.51 67.52 58.10 65.13 64.94 64.74 60.41 56.50 51.61 40.24 39.98 F1 72.87 71.10 70.92 70.01 68.94 68.12 67.93 67.76 64.85 60.23 58.52"
W15-3204,W11-2838,0,0.388272,"uage. The report includes an overview of the QALB corpus, which is the dataset used for training and evaluation, an overview of participating systems, results of the competition and an analysis of the results and systems. 1 Introduction The task of text correction has recently been attracting a lot of attention in the Natural Language Processing (NLP) community, but most of the effort in this area concentrated on English, especially on errors made by learners of English as a Second Language. Four competitions devoted to error correction for non-native English writers took place recently: HOO (Dale and Kilgarriff, 2011; Dale et al., 2012) and CoNLL (Ng et al., 2013; Ng et al., 2014). Shared tasks of this kind are extremely important, as they bring together researchers and promote the development of relevant techniques and dissemination of key resources, such as benchmark data sets. In the area of Arabic text correction, there has been a significant body of work, as well (Shaalan et al., 2003; Hassan et al., 2008). However, due to the lack of a common benchmark data set, making progress on this task has been difficult. The QALB shared task on automatic text correction of Arabic, 1 http://nlp.qatar.cmu.edu/qa"
W15-3204,I13-2001,1,0.600185,"ts are compared against gold annotations using Precision, Recall and F1 . Systems are ranked based on the F1 scores obtained on the test sets. 3 The QALB Corpus The QALB corpus was created as part of the QALB project. One of the goals of the QALB project is to develop a large manually corrected corpus for a variety of Arabic texts, including texts produced by native and non-native writers, as well as machine translation output. Within the framework of this project, comprehensive annotation guidelines and a specialized web-based annotation interface have been developed (Zaghouani et al., 2014; Obeid et al., 2013; Zaghouani et al., 2015a). 2 In the shared task, we specified two Add categories: add_before and add_after. Most of the add errors fall into the first category, and we combine these here into a single Add category. 3 Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007): (in alphabetical ˇ order) AbtθjHxdðrzsšSDTDςγfqklmnhwy and the additional ˇ ¯ symbols: ’ Z, Â @, A @ , A @, wˆ ð', yˆ Zø', ¯h è, ý ø. 4 Tables 1 and 2, and the appendix are reproduced from Mohit et al. (2014) to help explain the format of the files used in QALB-2014 and QALB-2015 sha"
W15-3204,W12-2006,0,0.289248,"n overview of the QALB corpus, which is the dataset used for training and evaluation, an overview of participating systems, results of the competition and an analysis of the results and systems. 1 Introduction The task of text correction has recently been attracting a lot of attention in the Natural Language Processing (NLP) community, but most of the effort in this area concentrated on English, especially on errors made by learners of English as a Second Language. Four competitions devoted to error correction for non-native English writers took place recently: HOO (Dale and Kilgarriff, 2011; Dale et al., 2012) and CoNLL (Ng et al., 2013; Ng et al., 2014). Shared tasks of this kind are extremely important, as they bring together researchers and promote the development of relevant techniques and dissemination of key resources, such as benchmark data sets. In the area of Arabic text correction, there has been a significant body of work, as well (Shaalan et al., 2003; Hassan et al., 2008). However, due to the lack of a common benchmark data set, making progress on this task has been difficult. The QALB shared task on automatic text correction of Arabic, 1 http://nlp.qatar.cmu.edu/qalb/ 26 Proceedings o"
W15-3204,W12-5611,0,0.0600366,"Missing"
W15-3204,pasha-etal-2014-madamira,1,0.852468,"Missing"
W15-3204,zaghouani-etal-2014-large,1,0.849061,"workshop at EMNLP-2014 (Mohit et al., 2014). QALB-2014 addressed errors in online user comments written to Aljazeera articles by native Arabic speakers. This year’s competition includes two tracks – native and non-native. In addition to the Aljazeera commentaries written by native speakers, it also includes texts produced by learners of Arabic as a foreign language (L2). Both the native and the non-native data is written in Modern Standard Arabic and is part of the QALB corpus (see Section 3), a manuallycorrected collection of Arabic texts. The Aljazeera section of the corpus is presented in Zaghouani et al. (2014). The L2 data is extracted from two learner corpora of Arabic – the Arabic Learners Written Corpus (ALWC) (Farwaneh and Tamimi, 2012) and the Arabic Learner Corpus (ALC) (Alfaifi and Atwell, 2012). For details about the L2 data, we refer the reader to Zaghouani et al. (2015a). The shared task participants were provided with training and development data to build their systems, but were also free to make use of additional resources, including corpora, linguistic resources, and software, as long as these were publicly available. For evaluation, a standard framework developed for similar error co"
W15-3204,W15-1614,1,0.759406,"nd the English translation. The errors in the original and the corrected forms are underlined and co-indexed. Table 2 presents a subset of the errors for the example shown in Table 1 along with the error types and annotation actions. The Appendix at the end of the paper lists all annotation actions for that example.4 Essays written by L2 speakers differ from the native texts both because of the genre and the types of mistakes. For this reason, the general QALB L1 annotation guidelines were extended by adding new rules describing the error correction procedure in texts produced by L2 speakers (Zaghouani et al., 2015a). Because the genres are different, the writing styles exhibit different distributions of words, phrases, and structures. Further, while native texts mostly contain orthographic and punctuation mistakes, non-native writings also reveal lexical choice errors, missing and extraneous words (e.g. articles, prepositions), and mistakes in word The QALB-2015 shared task extends QALB2014, the first shared task on Arabic text correction that was created as a forum for competition and collaboration on automatic error correction in Modern Standard Arabic and took place in conjunction with the Arabic NL"
W15-3204,W15-3219,1,0.765882,"Missing"
W15-3207,P13-2081,0,0.0194228,"Most studies concerning Arabic dialects focus on Egyptian, Levantine and Iraqi. Some efforts have been done to create dialectal resources such as Al-Sabbagh and Girju (2010) who built an Egyptian/MSA lexicon exploiting available data from the web. Other researchers focused on building parallel corpora between Arabic dialects, MSA and English (Zbib et al., 2012; Bouamor et al., 2014; Harrat et al., 2014). Habash et al. (2008) and Elfardy and Diab (2012) proposed some standard guidelines for the annotation of Arabic dialects. Other efforts focused in dialect identification (Habash et al., 2008; Elfardy and Diab, 2013; Zaidan and Callison-Burch, 2014) and • morphological variations: All morphological phenomena that exist in MSA exist also in TUN, but they are sometimes expressed differently. As cliticization is concerned, several MSA prepositions are attached to words on the TUN side. For example, the MSA mino prepositions úÎ« ςalaý &quot;on&quot; and áÓ &quot;from&quot; become in TUN respectively +« ς+ and +Ó m+ proclitics when the word following is definite (marked by the determinant 1 In Arabic orthography, short vowels are represented with optional diacritics which makes the language ambiguous. 2 Arabic orthographic trans"
W15-3207,al-sabbagh-girju-2010-mining,0,0.0234652,"erived from the root Ð h. h H j m and the patterns 1a22i3 and 1a22A3 respectively. • lexical variations: from a lexical point of view, the differences between MSA and TUN are significant. They are mainly due to the influence of other languages. Such TUN words still generally follow MSA morphology, sharing the same inflectional and derivational rules. Table 1 gives some examples of words of different origins. 3 Related work Processing Arabic dialects Most studies concerning Arabic dialects focus on Egyptian, Levantine and Iraqi. Some efforts have been done to create dialectal resources such as Al-Sabbagh and Girju (2010) who built an Egyptian/MSA lexicon exploiting available data from the web. Other researchers focused on building parallel corpora between Arabic dialects, MSA and English (Zbib et al., 2012; Bouamor et al., 2014; Harrat et al., 2014). Habash et al. (2008) and Elfardy and Diab (2012) proposed some standard guidelines for the annotation of Arabic dialects. Other efforts focused in dialect identification (Habash et al., 2008; Elfardy and Diab, 2013; Zaidan and Callison-Burch, 2014) and • morphological variations: All morphological phenomena that exist in MSA exist also in TUN, but they are someti"
W15-3207,feldman-etal-2006-cross,0,0.0816915,"Missing"
W15-3207,altantawy-etal-2010-morphological,1,0.844358,"phic representations. In our example, two rules are applied. First, the gemination3 rule, which allows to delete the vowel between the second and the third radical if it is followed by a suffix starting with a vowel. Then, a phonological rule that transforms the /t/ of the pattern i1ta2a3 to /T/.4 We get, at this step: /wa+iDTar∼+uwA/. Morphological analysis and generation of Arabic and its dialect MAGEAD is a morphological analyzer and generator for the Arabic language family (MSA and Arabic dialects). It processes Arabic verbs (Habash and Rambow, 2006; Habash et al., 2005) and Arabic nouns (Altantawy et al., 2010). MAGEAD relates a deep representation of a word with its surface form through a sequence of transformations. It can be used bidirectionally, to generate, as well as to analyze, surface forms. At a deep representation level, MAGEAD represents a word as a root, a pattern and a set of feature-value pairs. The features are translated to abstract morphemes which are then ordered, and expressed as concrete morphemes. Finally, morphological and phonological rewrite rules are applied. To describe the different processes made by MAGEAD, we use  @ ð waAiDTar∼uwA &quot;and the surface form @ð Q¢ they were"
W15-3207,P05-1071,1,0.680538,"trigram model is used to give the first best path while the unigram allowed to filter and score the lattice. Three different inputs can be handled by the POS tagger: an unscored lattice derived from the conversion, a scored lattice produced by the disambiguation based on the unigram language model and the first best path generated by the 3gram language model. 5.3 Table 4 gives the results of POS tagging of a MSA corpus using our different HMM taggers. These results are comparable to state-of-the-art MSA POS tagging systems: Habash and Roth (2009) report a higher result using the MADA system (Habash and Rambow, 2005). However, we cannot use the MADA system because it does not support POS tagging over a lattice, which we need for TUN POS tagging. It should be noted that the results in the table are for forms (real task), but also for gold lemmas and lmms. We present the lemma and lmm results only for comparative reasons as the starting point is artificial, and the performance numbers should be seen as upper bounds. bigram trigram Pos-Tagging forms 94.52 94.72 gold lemmas 97.61 97.63 gold lmms 96.84 96.94 Table 4: Accuracy of POS tagging of MSA corpus The taggers used in this work are based on Hidden Markov"
W15-3207,W13-2813,0,0.0208615,"re details, see (Hamdi et al., 2013). Due to the lexical differences between MSA and TUN, the conversion process cannot be limited to morphological transformations and requires some lexical transformations. We used three lexica to map from TUN to MSA: a lexicon of verbs, a lexicon of deverbal nouns and a lexicon of particles. 4.2.3 Lexicon of particles Arabic particles cover many categories: conjunctions, prepositions, clitics . . . Our lexicon, made of about 200 pairs (MSA particle, TUN particle), includes all of them. The MSA particles are extracted from the PATB and then translated to TUN (Boujelbane et al., 2013). In its current version, the lexicon matches 262 Tunisian particles to 143 MSA particles. 4.2.1 5 4.2 Lexica Lexicon of verbs Architecture and experiments Our system consists of three step: conversion, disambiguation and POS tagging. The TUN input sentence t1 t2 t3 . . . tn , is converted to a MSA lattice. The lattice is then disambiguated to produce a pseudo MSA target sentence m1 m2 m3 . . . mn . Next, a MSA tagger assign to The verbal lexicon consists of pairs of the form (PM SA , PT U N ) where PM SA and PT U N are themselves pairs made of a root and a pattern. Its development was based o"
W15-3207,P06-1086,1,0.882041,"ap the morphemic representation to the phonological and orthographic representations. In our example, two rules are applied. First, the gemination3 rule, which allows to delete the vowel between the second and the third radical if it is followed by a suffix starting with a vowel. Then, a phonological rule that transforms the /t/ of the pattern i1ta2a3 to /T/.4 We get, at this step: /wa+iDTar∼+uwA/. Morphological analysis and generation of Arabic and its dialect MAGEAD is a morphological analyzer and generator for the Arabic language family (MSA and Arabic dialects). It processes Arabic verbs (Habash and Rambow, 2006; Habash et al., 2005) and Arabic nouns (Altantawy et al., 2010). MAGEAD relates a deep representation of a word with its surface form through a sequence of transformations. It can be used bidirectionally, to generate, as well as to analyze, surface forms. At a deep representation level, MAGEAD represents a word as a root, a pattern and a set of feature-value pairs. The features are translated to abstract morphemes which are then ordered, and expressed as concrete morphemes. Finally, morphological and phonological rewrite rules are applied. To describe the different processes made by MAGEAD, w"
W15-3207,P09-2056,1,0.929017,"n corpus, it is a collection of political debates transcriptions. The trigram model is used to give the first best path while the unigram allowed to filter and score the lattice. Three different inputs can be handled by the POS tagger: an unscored lattice derived from the conversion, a scored lattice produced by the disambiguation based on the unigram language model and the first best path generated by the 3gram language model. 5.3 Table 4 gives the results of POS tagging of a MSA corpus using our different HMM taggers. These results are comparable to state-of-the-art MSA POS tagging systems: Habash and Roth (2009) report a higher result using the MADA system (Habash and Rambow, 2005). However, we cannot use the MADA system because it does not support POS tagging over a lattice, which we need for TUN POS tagging. It should be noted that the results in the table are for forms (real task), but also for gold lemmas and lmms. We present the lemma and lmm results only for comparative reasons as the starting point is artificial, and the performance numbers should be seen as upper bounds. bigram trigram Pos-Tagging forms 94.52 94.72 gold lemmas 97.61 97.63 gold lmms 96.84 96.94 Table 4: Accuracy of POS tagging"
W15-3207,E06-1047,1,0.908066,"Missing"
W15-3207,W05-0703,1,0.756785,"tation to the phonological and orthographic representations. In our example, two rules are applied. First, the gemination3 rule, which allows to delete the vowel between the second and the third radical if it is followed by a suffix starting with a vowel. Then, a phonological rule that transforms the /t/ of the pattern i1ta2a3 to /T/.4 We get, at this step: /wa+iDTar∼+uwA/. Morphological analysis and generation of Arabic and its dialect MAGEAD is a morphological analyzer and generator for the Arabic language family (MSA and Arabic dialects). It processes Arabic verbs (Habash and Rambow, 2006; Habash et al., 2005) and Arabic nouns (Altantawy et al., 2010). MAGEAD relates a deep representation of a word with its surface form through a sequence of transformations. It can be used bidirectionally, to generate, as well as to analyze, surface forms. At a deep representation level, MAGEAD represents a word as a root, a pattern and a set of feature-value pairs. The features are translated to abstract morphemes which are then ordered, and expressed as concrete morphemes. Finally, morphological and phonological rewrite rules are applied. To describe the different processes made by MAGEAD, we use  @ ð waAiDTar∼"
W15-3207,P11-1061,0,0.0825298,"Missing"
W15-3207,W05-0708,0,0.325435,"Missing"
W15-3207,habash-etal-2012-conventional,1,0.844173,"s all phonemes that exist in MSA. However, TUN has three extra phonemes /p/, /v/ and /g/. To a lesser extent, variations appear in some common words, that consist in dropping some short vowels1 on  the TUN side. For instance, H . AJ» ktAb2  &quot;book&quot; and I . J» ktb &quot;to write&quot; which exist in both languages but are pronounced differently: /kitAb/, /katab/ in MSA and /ktAb/, /ktib/ in Tunisian dialect. Concerning orthography, unlike MSA, which already has a standard orthography, Tunisian dialect is unstandardized. Zribi et al. (2014) proposes orthographic standards for TUN, following the works of Habash et al. (2012), that aim to establish a common orthographic convention for all Arabic dialects. marker +Ë@ Al+). Furthermore, indirect object pronouns are realized as enclitics in TUN verbs and not in MSA. On the other hand, some MSA clitics are detached in TUN. The MSA future particle proclitic + sa+ is real . bAš with ized as the autonomous particle AK TUN verbs. As for inflectional morphology, MSA has a richer system than TUN. In fact, MSA nominal case and verbal mood do not exist in TUN. The three MSA number values (singular, dual and plural) are reduced to singular and plural. On TUN side, the mascu"
W15-3207,P13-2112,0,0.0514903,"Missing"
W15-3207,N13-1044,1,0.924233,"Missing"
W15-3207,elfardy-diab-2012-simplified,0,0.0297093,"morphology, sharing the same inflectional and derivational rules. Table 1 gives some examples of words of different origins. 3 Related work Processing Arabic dialects Most studies concerning Arabic dialects focus on Egyptian, Levantine and Iraqi. Some efforts have been done to create dialectal resources such as Al-Sabbagh and Girju (2010) who built an Egyptian/MSA lexicon exploiting available data from the web. Other researchers focused on building parallel corpora between Arabic dialects, MSA and English (Zbib et al., 2012; Bouamor et al., 2014; Harrat et al., 2014). Habash et al. (2008) and Elfardy and Diab (2012) proposed some standard guidelines for the annotation of Arabic dialects. Other efforts focused in dialect identification (Habash et al., 2008; Elfardy and Diab, 2013; Zaidan and Callison-Burch, 2014) and • morphological variations: All morphological phenomena that exist in MSA exist also in TUN, but they are sometimes expressed differently. As cliticization is concerned, several MSA prepositions are attached to words on the TUN side. For example, the MSA mino prepositions úÎ« ςalaý &quot;on&quot; and áÓ &quot;from&quot; become in TUN respectively +« ς+ and +Ó m+ proclitics when the word following is definite (ma"
W15-3207,2013.mtsummit-papers.16,1,0.829942,"s. This method overgenerates and can produce wrong pairs. In order to face this problem, we filtered the MSA part using the MSA large-scale lexicon SAMA (Graff et al., 2009). At the end of the process, a lexicon made of 33, 271 entries is created (Hamdi et al., 2014). ( É¿ AK yÂkl becomes É¿AK yAkl ’he/it eats’). Finally, TUN verbs whose root ends with Z ’, behave the same way as verbs whose final root radical ø y in the perfective aspect. For example, roots of TUN verbs AJK YK. bdiynA &quot;we started&quot; and AJJ ÓP rmiynA &quot;we threw&quot; are respectively Z X H . bd’ and ø Ð P rmy. For more details, see (Hamdi et al., 2013). Due to the lexical differences between MSA and TUN, the conversion process cannot be limited to morphological transformations and requires some lexical transformations. We used three lexica to map from TUN to MSA: a lexicon of verbs, a lexicon of deverbal nouns and a lexicon of particles. 4.2.3 Lexicon of particles Arabic particles cover many categories: conjunctions, prepositions, clitics . . . Our lexicon, made of about 200 pairs (MSA particle, TUN particle), includes all of them. The MSA particles are extracted from the PATB and then translated to TUN (Boujelbane et al., 2013). In its cur"
W15-3207,Q13-1001,0,0.0473055,"Missing"
W15-3207,W14-5311,1,0.785537,"between TUN and MSA • phonological and orthographic variations: TUN has all phonemes that exist in MSA. However, TUN has three extra phonemes /p/, /v/ and /g/. To a lesser extent, variations appear in some common words, that consist in dropping some short vowels1 on  the TUN side. For instance, H . AJ» ktAb2  &quot;book&quot; and I . J» ktb &quot;to write&quot; which exist in both languages but are pronounced differently: /kitAb/, /katab/ in MSA and /ktAb/, /ktib/ in Tunisian dialect. Concerning orthography, unlike MSA, which already has a standard orthography, Tunisian dialect is unstandardized. Zribi et al. (2014) proposes orthographic standards for TUN, following the works of Habash et al. (2012), that aim to establish a common orthographic convention for all Arabic dialects. marker +Ë@ Al+). Furthermore, indirect object pronouns are realized as enclitics in TUN verbs and not in MSA. On the other hand, some MSA clitics are detached in TUN. The MSA future particle proclitic + sa+ is real . bAš with ized as the autonomous particle AK TUN verbs. As for inflectional morphology, MSA has a richer system than TUN. In fact, MSA nominal case and verbal mood do not exist in TUN. The three MSA number values ("
W15-3207,J00-1006,0,0.103881,"ue pairs to sets of abstract morphemes (AMs). In our example, the MBC verb-III maps asp:p and vox:a to the AM [PAT_PV:VIII][VOC_PV:VIIIact]. The feature value cnj:w is simply mapped to the AM [CNJ:W] while the features values per:3 gen:m num:prl asp:p is mapped to the AM [SUBJ_SUFF:3MP]. AMs are then ordered. At this point our example is represented as: (2) [CNJ:W] + [ROOT:Drr] [PAT_PV:VIII] [VOC_PV:VIII-act] + [SUBJ_SUFF:3MP] • Orthographic rules rewrite the orthographic representation. Using standard MSA diacritized orthography, our example becomes  @ ð waAiDTar∼uwA. @ð Q¢ MAGEAD follows (Kiraz, 2000) in using a multi-tape representation. It extends the analysis of Kiraz by introducing a fifth tier. The five tiers are the following : • Tier 1: pattern and affixational morphemes • Tier 2: root • Tier 3: vocalism • Tier 4: phonological representation • Tier 5: orthographic representation In the generation direction, tiers 1 through 3 are input tiers. Tier 4 is an output tier, and an input tier for the orthographic representation. MAGEAD handles Arabic nouns in the same way. Specific CMs, AMs and morpheme order are defined for nouns. The MBC hierarchy specifies relevant morphosyntactic featur"
W15-3207,H01-1035,0,0.191545,"Missing"
W15-3207,D12-1127,0,0.0661705,"Missing"
W15-3207,J14-1006,0,0.0185027,"Arabic dialects focus on Egyptian, Levantine and Iraqi. Some efforts have been done to create dialectal resources such as Al-Sabbagh and Girju (2010) who built an Egyptian/MSA lexicon exploiting available data from the web. Other researchers focused on building parallel corpora between Arabic dialects, MSA and English (Zbib et al., 2012; Bouamor et al., 2014; Harrat et al., 2014). Habash et al. (2008) and Elfardy and Diab (2012) proposed some standard guidelines for the annotation of Arabic dialects. Other efforts focused in dialect identification (Habash et al., 2008; Elfardy and Diab, 2013; Zaidan and Callison-Burch, 2014) and • morphological variations: All morphological phenomena that exist in MSA exist also in TUN, but they are sometimes expressed differently. As cliticization is concerned, several MSA prepositions are attached to words on the TUN side. For example, the MSA mino prepositions úÎ« ςalaý &quot;on&quot; and áÓ &quot;from&quot; become in TUN respectively +« ς+ and +Ó m+ proclitics when the word following is definite (marked by the determinant 1 In Arabic orthography, short vowels are represented with optional diacritics which makes the language ambiguous. 2 Arabic orthographic transliteration is presented in the Hab"
W15-3207,N12-1006,0,0.0182278,"inly due to the influence of other languages. Such TUN words still generally follow MSA morphology, sharing the same inflectional and derivational rules. Table 1 gives some examples of words of different origins. 3 Related work Processing Arabic dialects Most studies concerning Arabic dialects focus on Egyptian, Levantine and Iraqi. Some efforts have been done to create dialectal resources such as Al-Sabbagh and Girju (2010) who built an Egyptian/MSA lexicon exploiting available data from the web. Other researchers focused on building parallel corpora between Arabic dialects, MSA and English (Zbib et al., 2012; Bouamor et al., 2014; Harrat et al., 2014). Habash et al. (2008) and Elfardy and Diab (2012) proposed some standard guidelines for the annotation of Arabic dialects. Other efforts focused in dialect identification (Habash et al., 2008; Elfardy and Diab, 2013; Zaidan and Callison-Burch, 2014) and • morphological variations: All morphological phenomena that exist in MSA exist also in TUN, but they are sometimes expressed differently. As cliticization is concerned, several MSA prepositions are attached to words on the TUN side. For example, the MSA mino prepositions úÎ« ςalaý &quot;on&quot; and áÓ &quot;from&quot;"
W15-3207,mohamed-etal-2012-annotating,0,0.0605098,"Missing"
W15-3207,pasha-etal-2014-madamira,1,0.917159,"Missing"
W15-3207,zribi-etal-2014-conventional,1,0.845685,"al variations between TUN and MSA • phonological and orthographic variations: TUN has all phonemes that exist in MSA. However, TUN has three extra phonemes /p/, /v/ and /g/. To a lesser extent, variations appear in some common words, that consist in dropping some short vowels1 on  the TUN side. For instance, H . AJ» ktAb2  &quot;book&quot; and I . J» ktb &quot;to write&quot; which exist in both languages but are pronounced differently: /kitAb/, /katab/ in MSA and /ktAb/, /ktib/ in Tunisian dialect. Concerning orthography, unlike MSA, which already has a standard orthography, Tunisian dialect is unstandardized. Zribi et al. (2014) proposes orthographic standards for TUN, following the works of Habash et al. (2012), that aim to establish a common orthographic convention for all Arabic dialects. marker +Ë@ Al+). Furthermore, indirect object pronouns are realized as enclitics in TUN verbs and not in MSA. On the other hand, some MSA clitics are detached in TUN. The MSA future particle proclitic + sa+ is real . bAš with ized as the autonomous particle AK TUN verbs. As for inflectional morphology, MSA has a richer system than TUN. In fact, MSA nominal case and verbal mood do not exist in TUN. The three MSA number values ("
W15-3207,P08-2030,1,0.912901,"Missing"
W15-3207,P13-2001,0,0.0321949,"Missing"
W15-3207,W11-2602,1,0.899147,"Missing"
W15-3207,2010.amta-papers.5,0,0.0386245,"Missing"
W15-3207,I13-1133,0,\N,Missing
W15-3207,bouamor-etal-2014-multidialectal,1,\N,Missing
W15-3208,habash-etal-2012-conventional,1,0.647311,"udes languages with less normalization and standardization. These languages are used in daily life, interviews and for informal conversations. Algerian Arabic (henceforth, ALG) is one of the Western group of Arabic dialects spoken in Algeria. ALG differs from other Arabic dialects, neighboring or far ones by havIn this paper, we present a basic layout of ALG processing which is necessary to build efficient NLP tools and applications. This layout is a design of standard common convention orthography dedicated to ALG dialect. The proposed standard is an extension of that proposed in the work of Habash et al, (2012a) who proposed a Conventional Orthography for Dialectal Arabic (CODA). CODA is designed in order to develop computational models of Arabic dialects and provided a detailed description of its guidelines as applied to Egyptian Arabic (EGY). In this paper, we present a conventional orthography for Algerian Arabic. The paper is organized as follows. Section 2, discusses related works. In Section 3, we present an historical overview of ALG. In Section 4, we highlight the 69 Proceedings of the Second Workshop on Arabic Natural Language Processing, pages 69–79, c Beijing, China, July 26-31, 2015. 20"
W15-3208,W12-2301,1,0.574378,"Missing"
W15-3208,N09-1045,1,0.441436,"ultiple pronunciations in ALG. Definite Article If the word contains the article Al ()ال, we must distinguish between the sun and the moon letters. In the case of the sun letters, the &quot;L&quot; is silent and the letter that follows is doubled (gemination) in pronunciation and in writing, e.g.,  النّھارAlnnhAr &apos;day&apos; (not  انّھارAnnhAr). Conversely, with the moon letters, the ‘A’ is not pronounced, the &quot;L&quot; of the article is pronounced and the letter that follows is not doubled, neither in pronunciation nor in writing, e.g.,  القمرAlqmar ‘the moon’ (not  لقمرlqmar) (Saadane and Semmar, 2012; Biadsy et al., 2009). 76 Raw Text  إنشاء ﷲ ڤاع النساء الي.مرحبا بكم في بالتو حصة برنامج الخط لحمر لنھار اليومة والي يتزامن مع عيد المرأة  قبل منروحو. ب والديھم ووالدھم، إنشاء ﷲ يتھناو ب ماليھم.راھم يشوفو فينا إنشاء ﷲ أيام ﺳعيده وجميلة فحياتھم .للموضوع نتاع اليومة والي خصصناه للمرأة ف الجزاير وكيفاش راھي عايشة خلونا نرحبو بالضيوف تع لبرنامج mrHbA bkm fy plAtw HSħ brnAmj AlxT lHmr lnhAr Alywmħ wlly ytzAmn mς ςyd AlmrÂħ. ǍnšA&apos; Allh gAς AlnsA&apos; Aly rAhm yšwfw fynA ǍnšA&apos; Allh ÂyAm sςydh wjmylħ fHyAthm. ǍnšA&apos; Allh ythnAw b mAlyhm, b wAldyhm wwlAdhm. qbl mnrwhw llmwDwς ntAς Alywmħ wAly xSSnAh llmrÂħ f AljzA"
W15-3208,N13-1066,1,0.837687,", 2011) for more examples. principals are described in details in (Habash et al, 2012a). An example of Algerian CODA is presented in Table 5. 5.1 the map of the Algerian dialect (ALG) to CODA by summarizing the specific CODA guidelines for ALG. Firstly we chose a variant of the ALG which is the one used in the media as default. This variant represents the dialect of the capital city Algiers and follows the same orthographic rules as MSA by taking into accounts all the following exceptions and extensions. CODA Guiding Principles We summarize the main CODA design elements (Habash et al., 2012a, Eskander et al., 2013): • CODA is an internally consistent and coherent convention for writing Dialectal Arabic. • CODA is created for computational purposes. • CODA uses the Arabic script. • CODA is intended as a unified framework for writing all Arabic dialects. • CODA aims to strike an optimal balance between maintaining a level of dialectal uniqueness and establishing conventions based on MSA-DA similarities. CODA is designed respecting many principles: 5.3 Long Vowels In ALG CODA the long vowel /e:/, which do not exist in MSA, will be written as ay or iA depending on its MSA cognate: ay or aA, respectively. In"
W15-3208,zribi-etal-2014-conventional,1,0.4045,"y abstracts from these variations, whereas the LDC guideline are dedicated for transcription, and thus focus more on phonological variations in sub-dialects. A proposition for transcription Algerain dialect are developed in (Harrat et., 2014) where a set of rules for transcription Algerain dialect are defined and a grapheme-to-phoneme converter for this dialect was presented. Grapheme-to-Phoneme (G2P) conversion or phonetic transcription is the process which converts a written form of a word to its pronunciation form; hence this technique focuses only on phonological variations. Furthermore, (Zribi, et al., 2014) extend the CODA guidelines to take into account to Tunisian dialect and (Jarrar, et al., 2014) have adapted it to the Palestinian dialect. In addition, authors of Egyptian and Tunisian CODA encourage the adaptation of CODA to other Arabic dialects in order to create linguistic resources. Following this council, we extend in this paper CODA guidelines to ALG. 3 Algerian Arabic: Historical Overview Arabic speakers have Arabic dialects or vernacular as their mother tongues. These dialects can be stratified in two big families of dialects: the Western group (the Maghreb) or North African group an"
W15-3208,W14-3603,1,\N,Missing
W15-3210,W10-0712,0,0.0750112,"Missing"
W15-3210,W11-0413,0,0.342564,"Missing"
W15-3210,W14-3605,1,0.882858,"Missing"
W15-3210,P11-2099,0,0.0613414,"Missing"
W15-3210,S14-2004,0,0.653736,"ork Annotating Targets in English Fine-grained subjectivity annotation in the English language has recently started gaining interest, where annotation can include opinion targets, opinion sources, or phrase-level opinion expressions. One of the early datasets collected for identifying opinion targets is that of (Hu and Liu, 2004), where product features (e.g price, quality) were annotated in customer reviews of consumer electronics. These consisted of mostly explicit product features annotated by one person. Also in the product review domain, the SemEval Task on aspect feature mining in 2014 (Pontiki et al., 2014) was concerned with finding aspect features of products with the polarities towards them. The products (e.g ‘restaurant’) and coarse-grained features (e.g ‘service’) were provided to annotators, who identified the aspects (e.g ‘waiter’) and the corresponding sentiment. The MPQA corpus is an in-depth and generalpurpose resource for fine-grained subjectivity annotations (Wiebe et al., 2005; Wilson, 2008), containing annotations of opinion expressions at the phrase level while specifying polarities, sources, and target spans. The annotation scheme links each subjective expression to one or more a"
W15-3210,N15-1146,0,0.0478382,"Missing"
W15-3210,W10-0711,0,0.0268533,"Standard Arabic (MSA) newswire data which covered multiple domains including politics, sports, economy, culture, and others. Both the domains and the sentence-level sentiment were annotated by two trained annotators. Our data also comes from different domains, but it is from the genre of online commentaries, which have greater prevalence of dialect, imperfect grammar, and spelling errors. Also, to select less prevalent domains from our comments corpus, we used topic modeling. There have been other MTurk studies in Arabic; among them Zaidan and Callison-Burch (2011) who annotated dialectness, Denkowski et al. (2010) who annotated machine translation pairs, and Higgins et al. (2010) who annotated Arabic nicknames. To the best of our knowledge, there are no known studies for target or topic annotation for Arabic. 3 3.2 Instead of asking annotators to directly identify targets of opinions, which we believed to be a much harder task, we broke the annotation into two stages, each in a different series of HITs (Human Intelligence Tasks). The task guidelines were presented in Modern Standard Arabic (MSA) to guarantee that only Arabic speakers would be able to understand and work on them. Many of the insights in"
W15-3210,J11-1002,0,0.0465044,"topics or subjects - of opinionated text. Knowledge of the target is important for making sense of an opinion (e.g in ‘The will of the people will prevail over the regime’s brutality’, the opinion is positive towards ‘the people’ and negative towards ‘the regime’). An opinion system which can identify both targets and polarities of opinions, and which can summarize the opinions of writers towards different targets, will be more informative than one which only identifies the overall sentiment of the text. This problem has started gaining interest in the product review domain (Hu and Liu, 2004; Qiu et al., 2011), news and social media (Kim and Hovy, 2006; Jiang et al., 2011), and in general language and discourse (Wilson, 2008; Ruppenhofer et al., 2008; Somasundaran and Wiebe, 2009). Annotating targets of opinion is a difficult and expensive task, requiring definition of what constitutes a target, whether targets are linked to opinion expressions, and how the boundaries of target spans should be defined (e.g ‘the people’ 89 Proceedings of the Second Workshop on Arabic Natural Language Processing, pages 89–98, c Beijing, China, July 26-31, 2015. 2014 Association for Computational Linguistics tities wi"
W15-3210,ruppenhofer-etal-2008-finding,0,0.668451,"d analysis. 1 ‘The Lebanese PM said he was convinced that there would be a consensus on the presidential election, because since the moment the US and Iran had reached an understanding in the region, things were starting to look positive.’ Which is the opinion expression that leads us to believe that the PM is optimistic about the target presidential election? Is it ‘convinced’, ‘consensus’, ‘reached an understanding’, or ‘look positive’, or a combination of the above? Such decisions are difficult for annotators to agree on; many studies have noted these challenges (Stoyanov and Cardie, 2008; Ruppenhofer et al., 2008) which can make the task complex. Compared to the amount of resources available for sentiment and subjectivity analysis, there is much less annotated data available for this more fine-grained type of analysis. Due to the difficulty of the task, most of the available datasets of fine-grained subjectivity have been annotated by trained annotators or expert linguists, making the process slower and more expensive. In this work, we consider annotation of targets using a sequence of simple crowdsourced substeps. We focus on Arabic, where subjectivity analysis is of growing interest, and where there"
W15-3210,C10-1045,0,0.0838888,"Missing"
W15-3210,P09-1026,0,0.076877,"e regime’s brutality’, the opinion is positive towards ‘the people’ and negative towards ‘the regime’). An opinion system which can identify both targets and polarities of opinions, and which can summarize the opinions of writers towards different targets, will be more informative than one which only identifies the overall sentiment of the text. This problem has started gaining interest in the product review domain (Hu and Liu, 2004; Qiu et al., 2011), news and social media (Kim and Hovy, 2006; Jiang et al., 2011), and in general language and discourse (Wilson, 2008; Ruppenhofer et al., 2008; Somasundaran and Wiebe, 2009). Annotating targets of opinion is a difficult and expensive task, requiring definition of what constitutes a target, whether targets are linked to opinion expressions, and how the boundaries of target spans should be defined (e.g ‘the people’ 89 Proceedings of the Second Workshop on Arabic Natural Language Processing, pages 89–98, c Beijing, China, July 26-31, 2015. 2014 Association for Computational Linguistics tities within the span. Stoyanov and Cardie (2008) extended part of the MPQA corpus by annotating it for ‘topics’, arguing that ‘targets’ refer to the syntactic span of text that iden"
W15-3210,W10-0714,0,0.0301899,"ncluding politics, sports, economy, culture, and others. Both the domains and the sentence-level sentiment were annotated by two trained annotators. Our data also comes from different domains, but it is from the genre of online commentaries, which have greater prevalence of dialect, imperfect grammar, and spelling errors. Also, to select less prevalent domains from our comments corpus, we used topic modeling. There have been other MTurk studies in Arabic; among them Zaidan and Callison-Burch (2011) who annotated dialectness, Denkowski et al. (2010) who annotated machine translation pairs, and Higgins et al. (2010) who annotated Arabic nicknames. To the best of our knowledge, there are no known studies for target or topic annotation for Arabic. 3 3.2 Instead of asking annotators to directly identify targets of opinions, which we believed to be a much harder task, we broke the annotation into two stages, each in a different series of HITs (Human Intelligence Tasks). The task guidelines were presented in Modern Standard Arabic (MSA) to guarantee that only Arabic speakers would be able to understand and work on them. Many of the insights in the task design were gained from an extensive pilot study. Annotat"
W15-3210,W08-0122,0,0.0167861,"PQA corpus was recently annotated for entity-level targets (Deng and Wiebe, 2015) by specifying target entities within the MPQA span, leading to the annotation of 292 targets by two annotators. The entities were anchored to the head word of the noun phrase or verb phrase that refers to the entity or event. In our work, we only consider noun phrase entities, and we consider the noun phrase itself as an entity. Other fine-grained annotation studies include that of Toprak et al. (2010) who enrich target and holder annotations in consumer reviews with measures such as relevancy and intensity, and Somasundaran et al. (2008) who perform discourselevel annotation of opinion frames, which consist of opinions whose targets are described by similar or contrasting relations. In these studies, the annotation was usually done by trained individuals or someone who has knowledge and experience in the task. Our study is different in that it utilizes crowdsourcing for the annotation process, and it focuses on the marking of important entities and concepts as targets of opinions in the more noisy online commentary genre. We view targets as ‘real-world entities’, similar to the topics discussed by Stoyanov and Cardie (2008),"
W15-3210,stoyanov-cardie-2008-annotating,0,0.0217727,"reement. We present detailed analysis. 1 ‘The Lebanese PM said he was convinced that there would be a consensus on the presidential election, because since the moment the US and Iran had reached an understanding in the region, things were starting to look positive.’ Which is the opinion expression that leads us to believe that the PM is optimistic about the target presidential election? Is it ‘convinced’, ‘consensus’, ‘reached an understanding’, or ‘look positive’, or a combination of the above? Such decisions are difficult for annotators to agree on; many studies have noted these challenges (Stoyanov and Cardie, 2008; Ruppenhofer et al., 2008) which can make the task complex. Compared to the amount of resources available for sentiment and subjectivity analysis, there is much less annotated data available for this more fine-grained type of analysis. Due to the difficulty of the task, most of the available datasets of fine-grained subjectivity have been annotated by trained annotators or expert linguists, making the process slower and more expensive. In this work, we consider annotation of targets using a sequence of simple crowdsourced substeps. We focus on Arabic, where subjectivity analysis is of growing"
W15-3210,P10-1059,0,0.0161878,"y identify ‘topic clusters’, which group together all opinions referring to the same topic. In parallel with this work, part of the MPQA corpus was recently annotated for entity-level targets (Deng and Wiebe, 2015) by specifying target entities within the MPQA span, leading to the annotation of 292 targets by two annotators. The entities were anchored to the head word of the noun phrase or verb phrase that refers to the entity or event. In our work, we only consider noun phrase entities, and we consider the noun phrase itself as an entity. Other fine-grained annotation studies include that of Toprak et al. (2010) who enrich target and holder annotations in consumer reviews with measures such as relevancy and intensity, and Somasundaran et al. (2008) who perform discourselevel annotation of opinion frames, which consist of opinions whose targets are described by similar or contrasting relations. In these studies, the annotation was usually done by trained individuals or someone who has knowledge and experience in the task. Our study is different in that it utilizes crowdsourcing for the annotation process, and it focuses on the marking of important entities and concepts as targets of opinions in the mo"
W15-3210,P11-1016,0,0.101867,"get is important for making sense of an opinion (e.g in ‘The will of the people will prevail over the regime’s brutality’, the opinion is positive towards ‘the people’ and negative towards ‘the regime’). An opinion system which can identify both targets and polarities of opinions, and which can summarize the opinions of writers towards different targets, will be more informative than one which only identifies the overall sentiment of the text. This problem has started gaining interest in the product review domain (Hu and Liu, 2004; Qiu et al., 2011), news and social media (Kim and Hovy, 2006; Jiang et al., 2011), and in general language and discourse (Wilson, 2008; Ruppenhofer et al., 2008; Somasundaran and Wiebe, 2009). Annotating targets of opinion is a difficult and expensive task, requiring definition of what constitutes a target, whether targets are linked to opinion expressions, and how the boundaries of target spans should be defined (e.g ‘the people’ 89 Proceedings of the Second Workshop on Arabic Natural Language Processing, pages 89–98, c Beijing, China, July 26-31, 2015. 2014 Association for Computational Linguistics tities within the span. Stoyanov and Cardie (2008) extended part of the M"
W15-3210,W06-0301,0,0.167935,"Knowledge of the target is important for making sense of an opinion (e.g in ‘The will of the people will prevail over the regime’s brutality’, the opinion is positive towards ‘the people’ and negative towards ‘the regime’). An opinion system which can identify both targets and polarities of opinions, and which can summarize the opinions of writers towards different targets, will be more informative than one which only identifies the overall sentiment of the text. This problem has started gaining interest in the product review domain (Hu and Liu, 2004; Qiu et al., 2011), news and social media (Kim and Hovy, 2006; Jiang et al., 2011), and in general language and discourse (Wilson, 2008; Ruppenhofer et al., 2008; Somasundaran and Wiebe, 2009). Annotating targets of opinion is a difficult and expensive task, requiring definition of what constitutes a target, whether targets are linked to opinion expressions, and how the boundaries of target spans should be defined (e.g ‘the people’ 89 Proceedings of the Second Workshop on Arabic Natural Language Processing, pages 89–98, c Beijing, China, July 26-31, 2015. 2014 Association for Computational Linguistics tities within the span. Stoyanov and Cardie (2008) e"
W15-3210,zaghouani-etal-2014-large,1,0.794195,"Missing"
W15-3210,P11-2007,0,0.0283851,"iter of the post. sentence-level annotation study for Modern Standard Arabic (MSA) newswire data which covered multiple domains including politics, sports, economy, culture, and others. Both the domains and the sentence-level sentiment were annotated by two trained annotators. Our data also comes from different domains, but it is from the genre of online commentaries, which have greater prevalence of dialect, imperfect grammar, and spelling errors. Also, to select less prevalent domains from our comments corpus, we used topic modeling. There have been other MTurk studies in Arabic; among them Zaidan and Callison-Burch (2011) who annotated dialectness, Denkowski et al. (2010) who annotated machine translation pairs, and Higgins et al. (2010) who annotated Arabic nicknames. To the best of our knowledge, there are no known studies for target or topic annotation for Arabic. 3 3.2 Instead of asking annotators to directly identify targets of opinions, which we believed to be a much harder task, we broke the annotation into two stages, each in a different series of HITs (Human Intelligence Tasks). The task guidelines were presented in Modern Standard Arabic (MSA) to guarantee that only Arabic speakers would be able to u"
W16-2011,E12-1066,0,0.0316469,"Missing"
W16-2011,D11-1057,0,0.0579233,"Missing"
W16-2011,D13-1105,1,0.808386,"some additional morphological annotations (Yarowsky and Wicentowski, 2000; Snyder and Barzilay, 2008; Cucerzan and Yarowsky, 2002). Closer to the other end, we find work that focuses on defining morphological models with limited lexicons that are then extended using raw text (Clément et al., 2004; Forsberg et al., 2006). The setting of the shared task on morphological reinflection (Cotterell et al., 2016), which provides a rich partly annotated training data set, encourages methods that are supervised. Our shared task submission builds on our previously published work on paradigm completion (Eskander et al., 2013), which falls somewhere in the middle of the continuum outlined above. Our approach learns complete morphological models using rich morphological annotations. The match of the requirements for our approach and those for the shared task was far from perfect, but it was interesting to participate since we have always wanted to explore ways to reduce some of the expected input annotations – in particular word segmentations, which are not provided in the shared task. We present a high-level description and error analysis of the Columbia-NYUAD system for morphological reinflection, which builds on"
W16-2011,P06-1086,1,0.674397,"Missing"
W16-2011,J11-2002,0,0.0408374,"Missing"
W16-2011,P14-1127,1,0.782293,"Missing"
W16-2011,P08-1084,0,0.0701975,"Missing"
W16-2011,P00-1027,0,0.258465,"Missing"
W16-2011,clement-etal-2004-morphology,0,0.120772,"Missing"
W16-2011,W16-2002,0,0.0627876,"Missing"
W16-2011,W02-2006,0,0.195647,"Missing"
W16-4916,de-marneffe-etal-2006-generating,0,0.00803391,"Missing"
W16-4916,C10-2032,0,0.0230906,"Missing"
W16-4916,W12-2207,0,0.0174782,"y of text readability methods within various contexts,(Crossley et al., 2007; Zhang et al., 2013) further discuss how to extract the best readability features selection and readability performance. These papers present and compare several readability calculation methods and text cohesion issues, some of which are extensions to 123 the more traditional scores involving more elaborate feature analysis. As computational methods for natural language processing and machine learning matured, researchers began addressing the readability issue from this new angle, with increasingly promising results (Francois and Miltsakaki, 2012). More recent attempts at readability scoring, including (Collins-Thompson, 2014; Pil´an et al., 2014; Pil´an et al., 2016), discuss utilizing machine learning and Support Vector Machines (SVM), among other classifiers, to predict readability levels. Collins-Thompson (2014) discusses feature set selection, and classification algorithm choices, among other implementation details. Existing work analyzing second languages mostly treats the foreign language as a single coherent entity, without looking into different methods or resources for the learning process (Collins-Thompson, 2014), and withou"
W16-4916,W08-0909,0,0.0599372,"Missing"
W16-4916,W02-0109,0,0.0817156,"Missing"
W16-4916,W14-1821,0,0.0659375,"Missing"
W16-4916,P06-4018,0,\N,Missing
W17-1305,bouamor-etal-2014-multidialectal,1,0.888808,"Maamouri et al., 2012b; Maamouri et al., 2012a; Maamouri et al., 2014). As for LEV, there exist morphologically annotated corpora and a treebank (Jarrar et al., 2014; Jarrar et al., 2016; Maamouri et al., 2006). Newly developed corpora for other dialects include (Masmoudi et al., 2014; Sma¨ıli et al., 2014; Al-Shargi et al., 2016; Khalifa et al., 2016) for Tunisian, Algerian, Moroccan, Yemeni and Gulf Arabic respectively. Other notable efforts targeted multiple dialects such as the COLABA project, and the Tharwa dictionary (Diab et al., 2010; Diab et al., 2014). Parallel dialectal corpora by Bouamor et al. (2014) and Meftouh et al. (2015), in addition to the highly dialectal online commentary corpus by Zaidan and Callison-Burch (2011). Specifically for GLF, we use the Qafisheh Gulf Arabic Dictionary (Qafisheh, 1997) as well as the Gumar Corpus (Khalifa et al., 2016) in developing our analyzer. Dialectal Orthography Due to the lack of standardized orthography guidelines for DA, and given the major differences from MSA, dialects are usually written in ways that re36 3  iˇs ‘[negation]’ ending such as  Ê ¯ AÓ mA  ¯ AÓ qultiˇs in EGY and LEV as opposed to IÊ Gulf Arabic 3.1 Background mA qilt in"
W17-1305,D13-1105,1,0.954471,"lifa et al., 2016). We follow the conventions defined by Khalifa et al. (2016) for CODA GLF. et al., 2009; Habash and Rambow, 2006) were entirely manually designed. Similarly, Habash et al. (2012a) developed CALIMA, a morphological analyzer for Egyptian Arabic (hence CALIMAEGY ). CALIMAEGY was developed based on a lexicon of morphologically annotated data using several methods and then manually verified. Furthermore, Salloum and Habash (2011) extended existing SAMA and CALIMAEGY resources using hand crafted rules which extended affixes and clitics based on matching on existing ones. Recently, Eskander et al. (2013) developed a technique that generates a morphological analyzer based on an annotated corpus. They describe a technique in which they define inflectional classes for lexemes that represents morphosyntactic features in addition to inflected stems. They automatically ‘complete’ these classes in a process called paradigm completion. They also show that using manually annotated iconic inflectional classes helps in the overall performance. Using the aforementioned paradigm completion technique, a Moroccan Arabic and a Sanaani Yemeni Arabic morphological analyzers were created (Al-Shargi et al., 2016"
W17-1305,C16-1326,1,0.876731,"e that generates a morphological analyzer based on an annotated corpus. They describe a technique in which they define inflectional classes for lexemes that represents morphosyntactic features in addition to inflected stems. They automatically ‘complete’ these classes in a process called paradigm completion. They also show that using manually annotated iconic inflectional classes helps in the overall performance. Using the aforementioned paradigm completion technique, a Moroccan Arabic and a Sanaani Yemeni Arabic morphological analyzers were created (Al-Shargi et al., 2016). And very recently Eskander et al. (2016) presented a single pipeline to produce a morphological analyzer and tagger from a single annotation of a corpus; they produced resources for EGY and LEV. Other works that involve DA morphological modeling include the work of Abuata and Al-Omari (2015). Who developed a rule-based system to segment affixes and clitics in GLF text. They compare their results to other well known MSA stemmers. In this paper, we create morphological paradigms similar to the iconic inflectional classes discussed by Eskander et al. (2013). Our paradigms map from morphological features to fully inflected orthographic"
W17-1305,P06-1086,1,0.202044,"ainly spoken with little to no publicly available written content. Modern Standard Arabic (MSA) on the other hand is the official language in more than 20 countries, where most written documents from news articles, to educational materials and entertainment magazines, are written in MSA. Hence, most of the tools that are available for Natural Language Processing (NLP) tasks are focused on MSA. With the introduction of social media platforms online, dialectal written content is being produced abundantly. Using existing tools that were developed for MSA on DA proved to have limited performance (Habash and Rambow, 2006; Khalifa et al., 2016). Having resources specific to DA, such as morphological lexicons is important for Arabic NLP tasks, such as part-of-speech (POS) tagging and morphological disambiguation. Recently, dialects such as Egyptian (EGY) and Levantine (LEV) Arabic have been receiving increasing attention. Morphological analyzers for 2 Related Work 2.1 Arabic Morphological Modeling Much work has been done on Arabic morphological modeling, covering a wide range of different system designs. Earlier systems such as BAMA, SAMA and MAGEAD (Buckwalter, 2004; Graff  In Arabic éÒÊ¿ kalima¯ h means ‘Wor"
W17-1305,P09-2056,1,0.837908,"abstract over templatic roots; and lexical entries are specified in a lexicon as root-paradigm pairs, in a manner similar to the work of Habash and Rambow (2006). We convert the paradigms to the database representation used in MADAMIRA (Pasha et al., 2014) and CALIMAEGY (Habash et al., 2012a). 2.2 2.3 Dialectal Arabic Resources In addition to the above mentioned morphological analyzers, there exist other resources such as dictionaries and corpora for both DA and MSA. For annotated MSA corpora, several developed such as (Maamouri and Cieri, 2002; Maamouri et al., 2004; Smrˇz and Hajiˇc, 2006; Habash and Roth, 2009; Zaghouani et al., 2014). Many efforts targeted DA, notably, EGY (Gadalla et al., 1997; Kilany et al., 2002; AlSabbagh and Girju, 2012; Maamouri et al., 2012b; Maamouri et al., 2012a; Maamouri et al., 2014). As for LEV, there exist morphologically annotated corpora and a treebank (Jarrar et al., 2014; Jarrar et al., 2016; Maamouri et al., 2006). Newly developed corpora for other dialects include (Masmoudi et al., 2014; Sma¨ıli et al., 2014; Al-Shargi et al., 2016; Khalifa et al., 2016) for Tunisian, Algerian, Moroccan, Yemeni and Gulf Arabic respectively. Other notable efforts targeted multip"
W17-1305,W12-2301,1,0.263763,"specific to DA, such as morphological lexicons is important for Arabic NLP tasks, such as part-of-speech (POS) tagging and morphological disambiguation. Recently, dialects such as Egyptian (EGY) and Levantine (LEV) Arabic have been receiving increasing attention. Morphological analyzers for 2 Related Work 2.1 Arabic Morphological Modeling Much work has been done on Arabic morphological modeling, covering a wide range of different system designs. Earlier systems such as BAMA, SAMA and MAGEAD (Buckwalter, 2004; Graff  In Arabic éÒÊ¿ kalima¯ h means ‘Word’. We follow the naming convention from (Habash et al., 2012a) who developed CALIMAEGY since we are using the same format and analysis engine for the databases we create. 2 CALIMAGLF can be obtained from http://camel.abudhabi.nyu.edu/resources/. 1 35 Proceedings of The Third Arabic Natural Language Processing Workshop (WANLP), pages 35–45, c Valencia, Spain, April 3, 2017. 2017 Association for Computational Linguistics flects the words’ pronunciation or etymological relation to MSA cognates (Habash et al., 2012b), and even then with a lot of inconsistency. Furthermore, as with MSA, Arabic orthography ignores the spelling of short vowel diacritics, thus"
W17-1305,habash-etal-2012-conventional,1,0.297729,"specific to DA, such as morphological lexicons is important for Arabic NLP tasks, such as part-of-speech (POS) tagging and morphological disambiguation. Recently, dialects such as Egyptian (EGY) and Levantine (LEV) Arabic have been receiving increasing attention. Morphological analyzers for 2 Related Work 2.1 Arabic Morphological Modeling Much work has been done on Arabic morphological modeling, covering a wide range of different system designs. Earlier systems such as BAMA, SAMA and MAGEAD (Buckwalter, 2004; Graff  In Arabic éÒÊ¿ kalima¯ h means ‘Word’. We follow the naming convention from (Habash et al., 2012a) who developed CALIMAEGY since we are using the same format and analysis engine for the databases we create. 2 CALIMAGLF can be obtained from http://camel.abudhabi.nyu.edu/resources/. 1 35 Proceedings of The Third Arabic Natural Language Processing Workshop (WANLP), pages 35–45, c Valencia, Spain, April 3, 2017. 2017 Association for Computational Linguistics flects the words’ pronunciation or etymological relation to MSA cognates (Habash et al., 2012b), and even then with a lot of inconsistency. Furthermore, as with MSA, Arabic orthography ignores the spelling of short vowel diacritics, thus"
W17-1305,W14-3603,1,0.944126,"MSA, Arabic orthography ignores the spelling of short vowel diacritics, thus increasing the ambiguity of the written forms. As a result, it is rather challenging to computationally process raw DA text directly from the source, or even agree on a common normalization. Habash et al. (2012b) proposed a Conventional Orthography for Dialectal Arabic (CODA) as part of a solution allowing different researchers to agree on a set of DA orthographic conventions for computational purposes. CODA was first defined for EGY, but has been extended to Palestinian, Tunisian, Algerian, Maghrebi and Gulf Arabic (Jarrar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Turki et al., 2016; Khalifa et al., 2016). We follow the conventions defined by Khalifa et al. (2016) for CODA GLF. et al., 2009; Habash and Rambow, 2006) were entirely manually designed. Similarly, Habash et al. (2012a) developed CALIMA, a morphological analyzer for Egyptian Arabic (hence CALIMAEGY ). CALIMAEGY was developed based on a lexicon of morphologically annotated data using several methods and then manually verified. Furthermore, Salloum and Habash (2011) extended existing SAMA and CALIMAEGY resources using hand crafted rules which exte"
W17-1305,L16-1679,1,0.392211,"to no publicly available written content. Modern Standard Arabic (MSA) on the other hand is the official language in more than 20 countries, where most written documents from news articles, to educational materials and entertainment magazines, are written in MSA. Hence, most of the tools that are available for Natural Language Processing (NLP) tasks are focused on MSA. With the introduction of social media platforms online, dialectal written content is being produced abundantly. Using existing tools that were developed for MSA on DA proved to have limited performance (Habash and Rambow, 2006; Khalifa et al., 2016). Having resources specific to DA, such as morphological lexicons is important for Arabic NLP tasks, such as part-of-speech (POS) tagging and morphological disambiguation. Recently, dialects such as Egyptian (EGY) and Levantine (LEV) Arabic have been receiving increasing attention. Morphological analyzers for 2 Related Work 2.1 Arabic Morphological Modeling Much work has been done on Arabic morphological modeling, covering a wide range of different system designs. Earlier systems such as BAMA, SAMA and MAGEAD (Buckwalter, 2004; Graff  In Arabic éÒÊ¿ kalima¯ h means ‘Word’. We follow the namin"
W17-1305,maamouri-etal-2006-developing,1,0.822211,"the above mentioned morphological analyzers, there exist other resources such as dictionaries and corpora for both DA and MSA. For annotated MSA corpora, several developed such as (Maamouri and Cieri, 2002; Maamouri et al., 2004; Smrˇz and Hajiˇc, 2006; Habash and Roth, 2009; Zaghouani et al., 2014). Many efforts targeted DA, notably, EGY (Gadalla et al., 1997; Kilany et al., 2002; AlSabbagh and Girju, 2012; Maamouri et al., 2012b; Maamouri et al., 2012a; Maamouri et al., 2014). As for LEV, there exist morphologically annotated corpora and a treebank (Jarrar et al., 2014; Jarrar et al., 2016; Maamouri et al., 2006). Newly developed corpora for other dialects include (Masmoudi et al., 2014; Sma¨ıli et al., 2014; Al-Shargi et al., 2016; Khalifa et al., 2016) for Tunisian, Algerian, Moroccan, Yemeni and Gulf Arabic respectively. Other notable efforts targeted multiple dialects such as the COLABA project, and the Tharwa dictionary (Diab et al., 2010; Diab et al., 2014). Parallel dialectal corpora by Bouamor et al. (2014) and Meftouh et al. (2015), in addition to the highly dialectal online commentary corpus by Zaidan and Callison-Burch (2011). Specifically for GLF, we use the Qafisheh Gulf Arabic Dictionary"
W17-1305,maamouri-etal-2014-developing,1,0.922955,"Missing"
W17-1305,Y15-1004,0,0.0122976,"aamouri et al., 2012a; Maamouri et al., 2014). As for LEV, there exist morphologically annotated corpora and a treebank (Jarrar et al., 2014; Jarrar et al., 2016; Maamouri et al., 2006). Newly developed corpora for other dialects include (Masmoudi et al., 2014; Sma¨ıli et al., 2014; Al-Shargi et al., 2016; Khalifa et al., 2016) for Tunisian, Algerian, Moroccan, Yemeni and Gulf Arabic respectively. Other notable efforts targeted multiple dialects such as the COLABA project, and the Tharwa dictionary (Diab et al., 2010; Diab et al., 2014). Parallel dialectal corpora by Bouamor et al. (2014) and Meftouh et al. (2015), in addition to the highly dialectal online commentary corpus by Zaidan and Callison-Burch (2011). Specifically for GLF, we use the Qafisheh Gulf Arabic Dictionary (Qafisheh, 1997) as well as the Gumar Corpus (Khalifa et al., 2016) in developing our analyzer. Dialectal Orthography Due to the lack of standardized orthography guidelines for DA, and given the major differences from MSA, dialects are usually written in ways that re36 3  iˇs ‘[negation]’ ending such as  Ê ¯ AÓ mA  ¯ AÓ qultiˇs in EGY and LEV as opposed to IÊ Gulf Arabic 3.1 Background mA qilt in GLF ‘I did not say’. From"
W17-1305,pasha-etal-2014-madamira,1,0.942067,"Missing"
W17-1305,W15-3208,1,0.826394,"ing of short vowel diacritics, thus increasing the ambiguity of the written forms. As a result, it is rather challenging to computationally process raw DA text directly from the source, or even agree on a common normalization. Habash et al. (2012b) proposed a Conventional Orthography for Dialectal Arabic (CODA) as part of a solution allowing different researchers to agree on a set of DA orthographic conventions for computational purposes. CODA was first defined for EGY, but has been extended to Palestinian, Tunisian, Algerian, Maghrebi and Gulf Arabic (Jarrar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Turki et al., 2016; Khalifa et al., 2016). We follow the conventions defined by Khalifa et al. (2016) for CODA GLF. et al., 2009; Habash and Rambow, 2006) were entirely manually designed. Similarly, Habash et al. (2012a) developed CALIMA, a morphological analyzer for Egyptian Arabic (hence CALIMAEGY ). CALIMAEGY was developed based on a lexicon of morphologically annotated data using several methods and then manually verified. Furthermore, Salloum and Habash (2011) extended existing SAMA and CALIMAEGY resources using hand crafted rules which extended affixes and clitics based on matching on"
W17-1305,W11-2602,1,0.815459,"EGY, but has been extended to Palestinian, Tunisian, Algerian, Maghrebi and Gulf Arabic (Jarrar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Turki et al., 2016; Khalifa et al., 2016). We follow the conventions defined by Khalifa et al. (2016) for CODA GLF. et al., 2009; Habash and Rambow, 2006) were entirely manually designed. Similarly, Habash et al. (2012a) developed CALIMA, a morphological analyzer for Egyptian Arabic (hence CALIMAEGY ). CALIMAEGY was developed based on a lexicon of morphologically annotated data using several methods and then manually verified. Furthermore, Salloum and Habash (2011) extended existing SAMA and CALIMAEGY resources using hand crafted rules which extended affixes and clitics based on matching on existing ones. Recently, Eskander et al. (2013) developed a technique that generates a morphological analyzer based on an annotated corpus. They describe a technique in which they define inflectional classes for lexemes that represents morphosyntactic features in addition to inflected stems. They automatically ‘complete’ these classes in a process called paradigm completion. They also show that using manually annotated iconic inflectional classes helps in the overall"
W17-1305,zaghouani-etal-2014-large,1,0.857909,"., 2012b; Maamouri et al., 2012a; Maamouri et al., 2014). As for LEV, there exist morphologically annotated corpora and a treebank (Jarrar et al., 2014; Jarrar et al., 2016; Maamouri et al., 2006). Newly developed corpora for other dialects include (Masmoudi et al., 2014; Sma¨ıli et al., 2014; Al-Shargi et al., 2016; Khalifa et al., 2016) for Tunisian, Algerian, Moroccan, Yemeni and Gulf Arabic respectively. Other notable efforts targeted multiple dialects such as the COLABA project, and the Tharwa dictionary (Diab et al., 2010; Diab et al., 2014). Parallel dialectal corpora by Bouamor et al. (2014) and Meftouh et al. (2015), in addition to the highly dialectal online commentary corpus by Zaidan and Callison-Burch (2011). Specifically for GLF, we use the Qafisheh Gulf Arabic Dictionary (Qafisheh, 1997) as well as the Gumar Corpus (Khalifa et al., 2016) in developing our analyzer. Dialectal Orthography Due to the lack of standardized orthography guidelines for DA, and given the major differences from MSA, dialects are usually written in ways that re36 3  iˇs ‘[negation]’ ending such as  Ê ¯ AÓ mA  ¯ AÓ qultiˇs in EGY and LEV as opposed to IÊ Gulf Arabic 3.1 Background mA qilt in"
W17-1305,P11-2007,0,0.0596328,"annotated corpora and a treebank (Jarrar et al., 2014; Jarrar et al., 2016; Maamouri et al., 2006). Newly developed corpora for other dialects include (Masmoudi et al., 2014; Sma¨ıli et al., 2014; Al-Shargi et al., 2016; Khalifa et al., 2016) for Tunisian, Algerian, Moroccan, Yemeni and Gulf Arabic respectively. Other notable efforts targeted multiple dialects such as the COLABA project, and the Tharwa dictionary (Diab et al., 2010; Diab et al., 2014). Parallel dialectal corpora by Bouamor et al. (2014) and Meftouh et al. (2015), in addition to the highly dialectal online commentary corpus by Zaidan and Callison-Burch (2011). Specifically for GLF, we use the Qafisheh Gulf Arabic Dictionary (Qafisheh, 1997) as well as the Gumar Corpus (Khalifa et al., 2016) in developing our analyzer. Dialectal Orthography Due to the lack of standardized orthography guidelines for DA, and given the major differences from MSA, dialects are usually written in ways that re36 3  iˇs ‘[negation]’ ending such as  Ê ¯ AÓ mA  ¯ AÓ qultiˇs in EGY and LEV as opposed to IÊ Gulf Arabic 3.1 Background mA qilt in GLF ‘I did not say’. From a linguistic point of view, Gulf Arabic refers to the linguistic varieties spoken on the western c"
W17-1305,zribi-etal-2014-conventional,1,0.845447,"hy ignores the spelling of short vowel diacritics, thus increasing the ambiguity of the written forms. As a result, it is rather challenging to computationally process raw DA text directly from the source, or even agree on a common normalization. Habash et al. (2012b) proposed a Conventional Orthography for Dialectal Arabic (CODA) as part of a solution allowing different researchers to agree on a set of DA orthographic conventions for computational purposes. CODA was first defined for EGY, but has been extended to Palestinian, Tunisian, Algerian, Maghrebi and Gulf Arabic (Jarrar et al., 2014; Zribi et al., 2014; Saadane and Habash, 2015; Turki et al., 2016; Khalifa et al., 2016). We follow the conventions defined by Khalifa et al. (2016) for CODA GLF. et al., 2009; Habash and Rambow, 2006) were entirely manually designed. Similarly, Habash et al. (2012a) developed CALIMA, a morphological analyzer for Egyptian Arabic (hence CALIMAEGY ). CALIMAEGY was developed based on a lexicon of morphologically annotated data using several methods and then manually verified. Furthermore, Salloum and Habash (2011) extended existing SAMA and CALIMAEGY resources using hand crafted rules which extended affixes and cli"
W17-1314,W15-3202,1,0.89437,"Missing"
W17-1314,L16-1696,1,0.87262,"Missing"
W17-1314,W14-3623,1,0.83937,"advantages of using deep learning-based models, and confirm the importance of using morphological abstractions to address Arabic’s complex morphology. 1 Introduction Opinion mining, or sentiment analysis, aims at automatically extract subjectivity information from 110 Proceedings of The Third Arabic Natural Language Processing Workshop (WANLP), pages 110–118, c Valencia, Spain, April 3, 2017. 2017 Association for Computational Linguistics (EWGA) (Abbasi et al., 2008). Sentiment lexicons also provided an additional source of features that proved useful for the task (Abdul-Mageed et al., 2011; Badaro et al., 2014; Badaro et al., 2015). dled appropriately, in order to make use of the subjective information they may implicitly carry. In this paper, we present a characterization study of Twitter data collected from different Arab regions, namely Egypt, the Levant and the Arab Gulf. This study illustrates how the discussed topics, the writing style and other linguistic phenomena, vary significantly from one region to another, reflecting different usages of Twitter around the Arab world. We also evaluate the model that ranked first at SemEval-2016 Task 4 (Nakov et al., 2016) on “Sentiment Analysis in Twitt"
W17-1314,S16-1010,0,0.0587456,"Missing"
W17-1314,P11-2103,0,0.100389,"lish. Results highlight the advantages of using deep learning-based models, and confirm the importance of using morphological abstractions to address Arabic’s complex morphology. 1 Introduction Opinion mining, or sentiment analysis, aims at automatically extract subjectivity information from 110 Proceedings of The Third Arabic Natural Language Processing Workshop (WANLP), pages 110–118, c Valencia, Spain, April 3, 2017. 2017 Association for Computational Linguistics (EWGA) (Abbasi et al., 2008). Sentiment lexicons also provided an additional source of features that proved useful for the task (Abdul-Mageed et al., 2011; Badaro et al., 2014; Badaro et al., 2015). dled appropriately, in order to make use of the subjective information they may implicitly carry. In this paper, we present a characterization study of Twitter data collected from different Arab regions, namely Egypt, the Levant and the Arab Gulf. This study illustrates how the discussed topics, the writing style and other linguistic phenomena, vary significantly from one region to another, reflecting different usages of Twitter around the Arab world. We also evaluate the model that ranked first at SemEval-2016 Task 4 (Nakov et al., 2016) on “Sentim"
W17-1314,D15-1299,0,0.066207,"Missing"
W17-1314,C16-1326,1,0.8866,"Missing"
W17-1314,pasha-etal-2014-madamira,1,0.827091,"Missing"
W17-1314,N15-1078,0,0.024122,"ity and sentiment analysis (SSA) system for Arabic tweets used a feature set that includes different forms of the word (lexemes and lemmas), POS tags, presence of polar adjectives, writing style (MSA or DA), and genre-specific features including the user’s gender and ID (Abdul-Mageed et al., 2014). Machine translation was used to apply existing state-of-the-art models for English to translations of Arabic tweets. Despite slight accuracy drop caused by translation errors, these models are still considered efficient and effective, especially for low-resource languages (Refaee and Rieser, 2014b; Salameh et al., 2015). A new class of machine learning models based on deep learning have recently emerged. These models achieved high performances in both Arabic and English, such as the Recursive Auto Encoders (RAE) (Socher et al., 2011; Al Sallab et al., 2015), the Recursive Neural Tensor Networks (RNTN) (Socher et al., 2013) and Generalized Regression Neural Networks (GRNN) (Hobeica et al., 2011; Baly et al., 2016). Related Work Opinion Mining models for Arabic are generally developed by training machine learning classifiers using different types of features. The most common features are the word ngrams featur"
W17-1314,D13-1170,0,0.244427,"es of Twitter around the Arab world. We also evaluate the model that ranked first at SemEval-2016 Task 4 (Nakov et al., 2016) on “Sentiment Analysis in Twitter”. This model is developed for opinion mining in English, and uses feature engineering to extract surface, syntactic, semantic and Twitter-specific features. Therefore, we extract an equivalent feature set for Arabic to train a model for opinion mining in Arabic tweets. We compare this model to another class of models that are based on deep learning techniques. In particular, we use recursive deep models that achieved high performances (Socher et al., 2013; Tai et al., 2015). Experimental results show the advantage of deep learning at learning subjectivity in Arabic tweets without the need for artificial features that describe the properties and characteristics of Twitter data. The rest of this paper is organized as follows. Section 2 describes previous work on opinion mining with particular focus on application to Twitter data. Section 3 presents the characterization study and highlights distinctive characteristics of tweets collected from different Arab regions. Section 4 describes the opinion models that we evaluate in this paper, and experi"
W17-1314,P15-1150,0,0.0260598,"Missing"
W17-1314,P02-1053,0,0.0145304,"Missing"
W17-1314,zaghouani-etal-2014-large,1,0.902275,"Missing"
W17-1315,N09-1045,1,0.768689,"ystem of the script. The Arabic script FST is relatively simple, with 121 Figure 1: Overview of Phonetic Similarity Search algorithm netic dictionary for English.3 We also train on a hybrid corpus, which contains data from both CMU dictionary and ArabScribe. We do not train LSTM for Arabic orthography because there is not enough variation in the mapping between the script and the phonetic output to justify their use. most consonants just mapping to a single IPA output, but with one-to-many mappings for some characters such as the long vowels. Our Arabic FST contains all the rules described in Biadsy et al. (2009). The Roman script FST contains Arabizispecific heuristic mappings from one- or twocharacter Roman-script strings into IPA found in the Arabic language, e.g. gh mapping to /K/. It also includes digits, such as 5 mapping to /x/ p 3.2 Search State Enumeration Our goal is to find the words in the phonetic dictionary with the lowest phonetic distance from our query input encoded as phones. A naive approach would be to use the Wagner-Fischer dynamic programming algorithm to calculate the optimal alignment of insertions, deletions and substitutions, of our query against all terms in the dictionary."
W17-1315,W14-3629,0,0.0240967,"Missing"
W17-1315,N13-1066,1,0.851901,"perform well on noisy user input of guessed spellings of unfamiliar words as it is trained on web corpora which are written by people who have a generally stronger command of the language and therefore errors are often due to typos rather than not knowing how to spell the word. There is unfortunately no published material about the exact method used by Google’s transliteration or Yamli smart keyboard to map Roman-script input into Arabic words. In the context of spelling correction for Arabic, there has been a large number of efforts and resources (Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Mohit et al., 2014; Zaghouani et al., 2014) (among others).2 All of these efforts focus on contextual spelling correction or conventionalization. In this work we contribute a new data set, ArabScribe, that may be of use in that area of research. or in Arabic script). We benchmarked our system against two widely used tools to look up unfamiliar Arabic words, Google Translate and the Yamli Smart Arabic Keyboard. We show that we exceed the performance of both tools. The paper will proceed as follows. In Section 2 we discuss the related literature in transliteration, spell correction and phoneti"
W17-1315,N06-1060,0,0.237388,"). AbdulJaleel and Larkey (2003) proposed a statistical method for transliteration between Arabic and English. It does statistical alignment of a corpus of transliterated proper names, and produces the probability of transliterations of short n-grams between the two scripts. Then, input terms are segmented into the available n-grams, and all possible transliterations are produced and scored based on their joint probabilities. Habash (2009) used an ambiguous mapping that utilized the soundslike indexing system Double Metaphones (Philips, 2000) combined with the direct mapping scores defined by Freeman et al. (2006) to handle out-ofvocabulary words in the context of Arabic-English machine translation. Freeman et al. (2006) extended Levenshtein Edit Distance to allow for improved matching of Arabic and English versions of the same proper names. El-Kahky et al. (2011) use graph reinforcement models to learn mapping Spelling Correction Within a single orthography, a closely related problem is spellchecking. Commonly used algorithms employ statistical and edit-distance models over letters, phones or metaphone (Whitelaw et al., 2009; Kukich, 1992; Damerau, 1964; Oflazer, 1996; Atkinson, 2005; Philips, 1990; T"
W17-1315,W09-3504,0,0.0195068,"their algorithm. Their search algorithm also requires the alignment and calculation of phonetic distance of the query against the entire database of search terms, which can be prohibitively expensive for large query sets. between characters in different scripts in the context of transliteration mining. Al-Badrashiny et al. (2014) present a similar system where words are transcribed using a finite state transducer constructed from an aligned parallel Arabizi-Arabic corpus. The disadvantage of this and other learned methods (Ristad and Yianilos, 1998; Lin and Chen, 2002; Mangu and Brill, 1997; Jiampojamarn et al., 2009) is that they require aligned parallel corpora whereas our approach performs well without any data. We note that training data for attempted dictionary lookup of heard words is extremely scarce. Brawer et al. (2010) present an automatic transliteration system used to internationalize place names for Google Maps. Their approach relies on hand crafting rule sets, that map between orthographies and the IPA. Their approach does not require any training data; however, it requires expert knowledge of the writing system of different languages and is difficult for languages like English, which do not"
W17-1315,W02-2017,0,0.0976504,"sent any sort of performance evaluation for their algorithm. Their search algorithm also requires the alignment and calculation of phonetic distance of the query against the entire database of search terms, which can be prohibitively expensive for large query sets. between characters in different scripts in the context of transliteration mining. Al-Badrashiny et al. (2014) present a similar system where words are transcribed using a finite state transducer constructed from an aligned parallel Arabizi-Arabic corpus. The disadvantage of this and other learned methods (Ristad and Yianilos, 1998; Lin and Chen, 2002; Mangu and Brill, 1997; Jiampojamarn et al., 2009) is that they require aligned parallel corpora whereas our approach performs well without any data. We note that training data for attempted dictionary lookup of heard words is extremely scarce. Brawer et al. (2010) present an automatic transliteration system used to internationalize place names for Google Maps. Their approach relies on hand crafting rule sets, that map between orthographies and the IPA. Their approach does not require any training data; however, it requires expert knowledge of the writing system of different languages and is"
W17-1315,W14-3605,1,0.846293,"ser input of guessed spellings of unfamiliar words as it is trained on web corpora which are written by people who have a generally stronger command of the language and therefore errors are often due to typos rather than not knowing how to spell the word. There is unfortunately no published material about the exact method used by Google’s transliteration or Yamli smart keyboard to map Roman-script input into Arabic words. In the context of spelling correction for Arabic, there has been a large number of efforts and resources (Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Mohit et al., 2014; Zaghouani et al., 2014) (among others).2 All of these efforts focus on contextual spelling correction or conventionalization. In this work we contribute a new data set, ArabScribe, that may be of use in that area of research. or in Arabic script). We benchmarked our system against two widely used tools to look up unfamiliar Arabic words, Google Translate and the Yamli Smart Arabic Keyboard. We show that we exceed the performance of both tools. The paper will proceed as follows. In Section 2 we discuss the related literature in transliteration, spell correction and phonetic distance mapping."
W17-1315,J96-1003,0,0.0574436,"mapping scores defined by Freeman et al. (2006) to handle out-ofvocabulary words in the context of Arabic-English machine translation. Freeman et al. (2006) extended Levenshtein Edit Distance to allow for improved matching of Arabic and English versions of the same proper names. El-Kahky et al. (2011) use graph reinforcement models to learn mapping Spelling Correction Within a single orthography, a closely related problem is spellchecking. Commonly used algorithms employ statistical and edit-distance models over letters, phones or metaphone (Whitelaw et al., 2009; Kukich, 1992; Damerau, 1964; Oflazer, 1996; Atkinson, 2005; Philips, 1990; Toutanova and Moore, 2002). Our algorithm is distinguished from these, in that we are not only addressing the case where the user doesn’t know how to spell the word, but the much more challenging case where they have not heard the sound correctly. Whitelaw et al. (2009) describe the Google spell check system which takes a statistical approach using massive unannotated web corpora. Their dictionary of canonical terms contains the most common tokens appearing online, and they match misspelled words to their canonical form using a combination of a language context"
W17-1315,P02-1019,0,0.104477,") to handle out-ofvocabulary words in the context of Arabic-English machine translation. Freeman et al. (2006) extended Levenshtein Edit Distance to allow for improved matching of Arabic and English versions of the same proper names. El-Kahky et al. (2011) use graph reinforcement models to learn mapping Spelling Correction Within a single orthography, a closely related problem is spellchecking. Commonly used algorithms employ statistical and edit-distance models over letters, phones or metaphone (Whitelaw et al., 2009; Kukich, 1992; Damerau, 1964; Oflazer, 1996; Atkinson, 2005; Philips, 1990; Toutanova and Moore, 2002). Our algorithm is distinguished from these, in that we are not only addressing the case where the user doesn’t know how to spell the word, but the much more challenging case where they have not heard the sound correctly. Whitelaw et al. (2009) describe the Google spell check system which takes a statistical approach using massive unannotated web corpora. Their dictionary of canonical terms contains the most common tokens appearing online, and they match misspelled words to their canonical form using a combination of a language context and Levenshtein edit distance. Then, they build a statisti"
W17-1315,D09-1093,0,0.0316503,"Metaphones (Philips, 2000) combined with the direct mapping scores defined by Freeman et al. (2006) to handle out-ofvocabulary words in the context of Arabic-English machine translation. Freeman et al. (2006) extended Levenshtein Edit Distance to allow for improved matching of Arabic and English versions of the same proper names. El-Kahky et al. (2011) use graph reinforcement models to learn mapping Spelling Correction Within a single orthography, a closely related problem is spellchecking. Commonly used algorithms employ statistical and edit-distance models over letters, phones or metaphone (Whitelaw et al., 2009; Kukich, 1992; Damerau, 1964; Oflazer, 1996; Atkinson, 2005; Philips, 1990; Toutanova and Moore, 2002). Our algorithm is distinguished from these, in that we are not only addressing the case where the user doesn’t know how to spell the word, but the much more challenging case where they have not heard the sound correctly. Whitelaw et al. (2009) describe the Google spell check system which takes a statistical approach using massive unannotated web corpora. Their dictionary of canonical terms contains the most common tokens appearing online, and they match misspelled words to their canonical fo"
W17-1315,zaghouani-etal-2014-large,1,0.907644,"Missing"
W17-1315,D11-1128,0,\N,Missing
W17-1315,W02-0505,0,\N,Missing
W17-1320,N13-1049,1,0.828882,"sentation, with the addition of the semantic dashtags and the PATB complete morphological tags (BW) (Buckwalter, 2004). We supplement the trees with additional feature-value pairs representation in the style used in the MADAMIRA morphological analyzer and disambiguator (Pasha et al., 2014). We chose to convert the treebanks through this methodology to allow for the conversion of the existing CATiB treebank that has no parallel in PATB’s constituency representation. In the future, we envision enriching the CATiB treebank with the morphosyntactic features it lacks, using techniques described by Alkuhlani et al. (2013). ways headed either by a conjunction, or, if no conjunction is present, by a punctuation symbol. All conjuncts are at the same tree level. In PAUDT these structures are transformed so that the first conjunct is the head and all subsequent conjuncts are attached to it. Why Another Arabic Universal Dependency Treebank? PAUDT is based on PADT, which is a small treebank, compared to the existing PATB treebank. Our aim is to make use of the automatic conversion of PATB, parts 1, 2, and 3, into a richer version of CATiB, and use it to create NUDAR. This would allow us in the future to convert the r"
W17-1320,E12-2012,0,0.0523355,"Missing"
W17-1320,P09-2056,1,0.958176,"age Processing (NLP) applications, such as automatic summarization, question answering, and machine translation. This motivates the creation of treebanks on which these parsers can be trained. Treebanks have two main different syntactic representations. On one hand, there are phrase structure (constituency) treebanks such as the Penn Treebank (Marcus et al., 1993), and its sister treebanks such as the Penn Arabic Treebank (PATB) (Maamouri et al., 2004) and the Penn Chinese Treebank (Xue et al., 2005). On the other hand, there are dependency treebanks, such as Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), and the Prague Dependency Treebank (PDT) (Hajiˇc et al., 2001). Other treebanks that followed the style of PDT are the Slovene (Džeroski et al., 2006) and the Croatian (Berovi´c et al., 2012) treebanks, as well as the Prague Arabic Dependency Treebank (PADT) (Smrž et al., 2002; Hajiˇc et al., 2004; Smrž et al., 2008). Having these different syntactic representations makes it difficult to compare treebanks, and parsing results (Nilsson et al., 2007). This motivated the creation of the Universal Dependency 2.1 Universal Dependencies UD is an open community effort. It builds on the existing tre"
W17-1320,berovic-etal-2012-croatian,0,0.0407184,"Missing"
W17-1320,W08-1300,0,0.250802,"ollowed the style of PDT are the Slovene (Džeroski et al., 2006) and the Croatian (Berovi´c et al., 2012) treebanks, as well as the Prague Arabic Dependency Treebank (PADT) (Smrž et al., 2002; Hajiˇc et al., 2004; Smrž et al., 2008). Having these different syntactic representations makes it difficult to compare treebanks, and parsing results (Nilsson et al., 2007). This motivated the creation of the Universal Dependency 2.1 Universal Dependencies UD is an open community effort. It builds on the existing treebank structure of the Stanford dependencies (De Marneffe et al., 2006; De Marneffe and Manning, 2008; De Marneffe et al., 2014), as well as the universal Google dependency scheme (McDonald et al., 2013). In addition, it makes use of the Google Universal Parts-of-Speech (POS) Tagset (Petrov et al., 2011), and the morphosyntactic tag set of the interset interlingua (Zeman, 2008). The aim of UD is to facilitate the creation of treebanks in different languages that are consistent in their syntactic representation, while still allowing the extension of the relations to accommodate for language-specific constructs. The target of UD is to facilitate the development of multilingual learning systems,"
W17-1320,de-marneffe-etal-2006-generating,0,0.0509096,"Missing"
W17-1320,de-marneffe-etal-2014-universal,0,0.0604251,"Missing"
W17-1320,dukes-habash-2010-morphological,1,0.870902,"Missing"
W17-1320,D07-1116,1,0.848203,"kens, improved morphology) shared tasks. An extended dataset (282K tokens) was incorporated in the HamleDT collection, where 30 treebanks were first harmonized in the Prague annotation style, later in Stanford dependencies (Rosa et al., 2014). Finally, this dataset was converted to Universal 2 In this paper we use UD to refer to the general shared concept of Universal Dependency representation. For language specific decision and treebanks we will use the name of the treebanks, i.e. PAUDT or NUDAR. 3 All Arabic transliterations are provided in the HabashSoudi-Buckwalter transliteration scheme (Habash et al., 2007b). This scheme extends Buckwalter’s transliteration scheme (Buckwalter, 2002) to increase its readability while maintaining the 1-to-1 correspondence with Arabic orthography as represented in standard encodings of Arabic, i.e., Unicode, CP-1256, etc. The following are the only differences from Buckwalter’s scheme (which is indicated in parenthe (&), Aˇ @ (&lt;), yˆ ø' (}), ¯h è (p), ¯ @ (|), Â @ (>), w ˆ ð' ses): A  (v), ð X (∗), š  ($), Dˇ (Z), ς ¨ (E), γ ¨ (g), ý ø (Y), θH ã  (F), u˜  (N), ˜ı  (K), á  (‘). 167 (Habash and Roth, 2009),4 that converts PATB trees to the CATiB represe"
W17-1320,J93-2004,0,0.060851,"AR. 1 2 Related Work In this section we present the Universal Dependency syntactic representation, as well as some of the most prominent previous efforts on Modern Standard Arabic (MSA) treebanks. Introduction Parsers have been used in many Natural Language Processing (NLP) applications, such as automatic summarization, question answering, and machine translation. This motivates the creation of treebanks on which these parsers can be trained. Treebanks have two main different syntactic representations. On one hand, there are phrase structure (constituency) treebanks such as the Penn Treebank (Marcus et al., 1993), and its sister treebanks such as the Penn Arabic Treebank (PATB) (Maamouri et al., 2004) and the Penn Chinese Treebank (Xue et al., 2005). On the other hand, there are dependency treebanks, such as Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), and the Prague Dependency Treebank (PDT) (Hajiˇc et al., 2001). Other treebanks that followed the style of PDT are the Slovene (Džeroski et al., 2006) and the Croatian (Berovi´c et al., 2012) treebanks, as well as the Prague Arabic Dependency Treebank (PADT) (Smrž et al., 2002; Hajiˇc et al., 2004; Smrž et al., 2008). Having these different"
W17-1320,petrov-etal-2012-universal,0,0.0612175,"Missing"
W17-1320,J13-1008,1,0.821524,"e also compare the result of parsing directly in NUDAR space to parsing in CATiB space then converting to NUDAR representation. For our parsing experiments, we used the MaltParser (Nivre et al., 2006) to train an Arabic dependency parser in the space of both CATiB and NUDAR. We compared the output of the NUDAR parser, to the results of converting the output of the CATiB parser to NUDAR using the system described in Section 3. For the CATiB parser, we used the optimized settings described by Shahrour et al. (2016), and were able to achieve comparable results. We used the gold CATiBex POS tags (Marton et al., 2013), and gold morphological features derived from gold BW tags, to train the parser on the T RAIN dataset of PATB parts 1, 2, and 3. We tested on the T EST dataset of the same treebank parts. The output of the parser was then converted to NUDAR representation. For the NUDAR parser, we ran the MaltOptimizer (Ballesteros and Nivre, 2012) on the full T RAIN dataset of NUDAR. We used the optimized settings to train and run our parser. The results of these experiments are shown in Table 5. The first row shows the result of training the MaltParser on the NUDAR training dataset with the optimized settin"
W17-1320,W15-1821,0,0.0185271,"edicates without a copula are attached as if they were bare nominals. On the other hand, when a copula is involved, we reattach it as a dependent of the non-verbal predicate (in PADT, if the copula is present, it heads the clause). Similarly, prepositions head prepositional phrases in the Prague style but they are attached as modifiers of their nouns in PAUDT. Finally, coordination in the Prague style is alwith over 10 other treebanks scheduled for release in the upcoming version 2.0. The treebanks are in 47 languages, including Swedish (Nivre, 2014), Danish (Johannsen et al., 2015), Finnish (Pyysalo et al., 2015), Estonian (Muischnek et al., 2014), Norwegian (Øvrelid and Hohle, 2016), Croatian (Agi´c and Ljubeši´c, 2015), Persian (Seraji et al., 2016), Bulgarian (Osenova and Simov, 2015), Catalan and Spanish (Alonso and Zeman, 2016), as well as the Prague Arabic Universal Dependency Treebank (PAUDT), among others. 2.2 Arabic Treebanks A number of treebanks exist for MSA. These treebanks vary in terms of their syntactic representation (constituency vs. dependency), richness of annotation, and source of data. We discuss next four treebanks that are relevant to this paper. PATB: The Penn Arabic Treebank"
W17-1320,P13-2017,0,0.0221185,"t al., 2012) treebanks, as well as the Prague Arabic Dependency Treebank (PADT) (Smrž et al., 2002; Hajiˇc et al., 2004; Smrž et al., 2008). Having these different syntactic representations makes it difficult to compare treebanks, and parsing results (Nilsson et al., 2007). This motivated the creation of the Universal Dependency 2.1 Universal Dependencies UD is an open community effort. It builds on the existing treebank structure of the Stanford dependencies (De Marneffe et al., 2006; De Marneffe and Manning, 2008; De Marneffe et al., 2014), as well as the universal Google dependency scheme (McDonald et al., 2013). In addition, it makes use of the Google Universal Parts-of-Speech (POS) Tagset (Petrov et al., 2011), and the morphosyntactic tag set of the interset interlingua (Zeman, 2008). The aim of UD is to facilitate the creation of treebanks in different languages that are consistent in their syntactic representation, while still allowing the extension of the relations to accommodate for language-specific constructs. The target of UD is to facilitate the development of multilingual learning systems, and multilingual NLP, as well as allow for comparative linguistic studies and evaluation (Nivre et al"
W17-1320,rosa-etal-2014-hamledt,1,0.891739,"Missing"
W17-1320,D07-1096,0,0.190039,"Missing"
W17-1320,C16-2048,1,0.86773,"two treebanks. 4 We conducted some experiments to benchmark the parsing scores in the NUDAR treebank. We also compare the result of parsing directly in NUDAR space to parsing in CATiB space then converting to NUDAR representation. For our parsing experiments, we used the MaltParser (Nivre et al., 2006) to train an Arabic dependency parser in the space of both CATiB and NUDAR. We compared the output of the NUDAR parser, to the results of converting the output of the CATiB parser to NUDAR using the system described in Section 3. For the CATiB parser, we used the optimized settings described by Shahrour et al. (2016), and were able to achieve comparable results. We used the gold CATiBex POS tags (Marton et al., 2013), and gold morphological features derived from gold BW tags, to train the parser on the T RAIN dataset of PATB parts 1, 2, and 3. We tested on the T EST dataset of the same treebank parts. The output of the parser was then converted to NUDAR representation. For the NUDAR parser, we ran the MaltOptimizer (Ballesteros and Nivre, 2012) on the full T RAIN dataset of NUDAR. We used the optimized settings to train and run our parser. The results of these experiments are shown in Table 5. The first r"
W17-1320,P81-1022,0,0.745148,"Missing"
W17-1320,zeman-2008-reusable,1,0.772607,"ns makes it difficult to compare treebanks, and parsing results (Nilsson et al., 2007). This motivated the creation of the Universal Dependency 2.1 Universal Dependencies UD is an open community effort. It builds on the existing treebank structure of the Stanford dependencies (De Marneffe et al., 2006; De Marneffe and Manning, 2008; De Marneffe et al., 2014), as well as the universal Google dependency scheme (McDonald et al., 2013). In addition, it makes use of the Google Universal Parts-of-Speech (POS) Tagset (Petrov et al., 2011), and the morphosyntactic tag set of the interset interlingua (Zeman, 2008). The aim of UD is to facilitate the creation of treebanks in different languages that are consistent in their syntactic representation, while still allowing the extension of the relations to accommodate for language-specific constructs. The target of UD is to facilitate the development of multilingual learning systems, and multilingual NLP, as well as allow for comparative linguistic studies and evaluation (Nivre et al., 2016). In its last release of version 1.4, the UD treebank collection contained 64 different treebanks, 1 The noun Nudar PA  nuDAr is Arabic for ‘pure gold’. 166 Proceeding"
W17-1320,W15-5313,0,0.0198134,"in PADT, if the copula is present, it heads the clause). Similarly, prepositions head prepositional phrases in the Prague style but they are attached as modifiers of their nouns in PAUDT. Finally, coordination in the Prague style is alwith over 10 other treebanks scheduled for release in the upcoming version 2.0. The treebanks are in 47 languages, including Swedish (Nivre, 2014), Danish (Johannsen et al., 2015), Finnish (Pyysalo et al., 2015), Estonian (Muischnek et al., 2014), Norwegian (Øvrelid and Hohle, 2016), Croatian (Agi´c and Ljubeši´c, 2015), Persian (Seraji et al., 2016), Bulgarian (Osenova and Simov, 2015), Catalan and Spanish (Alonso and Zeman, 2016), as well as the Prague Arabic Universal Dependency Treebank (PAUDT), among others. 2.2 Arabic Treebanks A number of treebanks exist for MSA. These treebanks vary in terms of their syntactic representation (constituency vs. dependency), richness of annotation, and source of data. We discuss next four treebanks that are relevant to this paper. PATB: The Penn Arabic Treebank (Maamouri et al., 2004; Maamouri et al., 2009) is a Linguistic Data Consortium (LDC) project, for which there are currently 12 parts for MSA. PATB consists of constituency trees,"
W17-1320,pasha-etal-2014-madamira,1,0.916945,"Missing"
W17-1320,nivre-etal-2006-maltparser,0,\N,Missing
W17-1320,L16-1250,0,\N,Missing
W17-1320,L16-1374,0,\N,Missing
W17-1320,L16-1262,1,\N,Missing
W18-3703,W14-1820,0,0.0462165,"Missing"
W18-3703,L16-1038,0,0.117904,"abic readability. These are usually referred to as traditional, shallow, basic or base features in the literature for their simplicity. In contrast, Al-Khalifa and Al-Ajlan (2010) add word bi-gram perplexity scores to their feature set, a popular readability predictor in English and other languages. Depth of Features The set of features used in previous readability studies exhibit a range of complexity in terms of depth of processing needed to obtain them. While some studies have relied on raw text features requiring shallow computations (Al-Khalifa and Al-Ajlan, 2010; Al Tamimi et al., 2014; El-Haj and Rayson, 2016), most augment their feature set with lexical and morphological information by processing the text further and extracting features such as lemmas, morphemes, and part-of-speech tags (Cavalli-Sforza et al., 2014; Forsyth, 2014; Saddiki et al., 2015; Nassiri et al., 2017). We add another level of feature complexity by extracting features from syntactic parsing, used in readability assessment for other languages but so far untried for Arabic (Table 1). 21 3 8 F EAT Raw Base * Features for Readability Prediction F[1] Characters F[2] Tokens F[3] Characters/Tokens F[4] Sentences Textual features ass"
W18-3703,E09-1027,0,0.0285978,"e features (i.e. traditional measures (DuBay, 2004)) to compare to. Computational readability assessment presents a growing body of work leveraging NLP to extract complex textual features, and ML to build readability models from corpora, rather than relying on human expertise or intuition (Collins-Thompson, 2014). Approaches vary depending on the purpose of the readability prediction model, e.g., measuring readability for text simplification (Aluisio et al., 2010; Dell’Orletta et al., 2014a; Al Khalil et al., 2017), selecting more cognitively-predictive features for readers with disabilities (Feng et al., 2009) or for self-directed language learning (Beinborn et al., 2012). Features used in predicting readability range from surface features extracted from raw text (e.g. average word count per line), to more complex ones requiring heavier text processing such as syntactic parsing features (Heilman et al., 2007, 2008; Beinborn et al., 2012; Hancke et al., 2012). The use of language models is increasingly favored in the literature over simple frequency counts, ratios and averages commonly used to quantify features in traditional readability formulas (Collins-Thompson and Callan, 2005; Beinborn et al.,"
W18-3703,W10-1001,0,0.0194667,"ical analysis, or syntactic parsing. In Table 1, using these two dimensions, we situate ours and previous work and establish a common baseline of raw base features (i.e. traditional measures (DuBay, 2004)) to compare to. Computational readability assessment presents a growing body of work leveraging NLP to extract complex textual features, and ML to build readability models from corpora, rather than relying on human expertise or intuition (Collins-Thompson, 2014). Approaches vary depending on the purpose of the readability prediction model, e.g., measuring readability for text simplification (Aluisio et al., 2010; Dell’Orletta et al., 2014a; Al Khalil et al., 2017), selecting more cognitively-predictive features for readers with disabilities (Feng et al., 2009) or for self-directed language learning (Beinborn et al., 2012). Features used in predicting readability range from surface features extracted from raw text (e.g. average word count per line), to more complex ones requiring heavier text processing such as syntactic parsing features (Heilman et al., 2007, 2008; Beinborn et al., 2012; Hancke et al., 2012). The use of language models is increasingly favored in the literature over simple frequency c"
W18-3703,W12-2207,0,0.0191726,"r self-directed language learning (Beinborn et al., 2012). Features used in predicting readability range from surface features extracted from raw text (e.g. average word count per line), to more complex ones requiring heavier text processing such as syntactic parsing features (Heilman et al., 2007, 2008; Beinborn et al., 2012; Hancke et al., 2012). The use of language models is increasingly favored in the literature over simple frequency counts, ratios and averages commonly used to quantify features in traditional readability formulas (Collins-Thompson and Callan, 2005; Beinborn et al., 2012; François and Miltsakaki, 2012). We evaluate features extracted using both methods in this study. There is a modest body of work on readability prediction for Arabic with marked differences in modeling approaches pursued, feature complexity, dataset size and type (L1 vs. L2), and choice of evaluation metrics. We build our feature set with predictors frequently used for Arabic readability studies in the literature, and augment it with features from work carried out on other languages. Use of Language Modeling Features such as frequency counts, averages and other ratios seem to dominate the literature for Arabic readability."
W18-3703,P09-2056,1,0.813202,"e features are computed simply by counting occurrences within the document. Ratios are expressed as mathematical fractions, such as F[3], F[5], F[11] and so on. LM perplexity is computed per readability level(1, 2, 3, and 4) on (uni-, bi- and tri-)grams language models, generating 4 level scores per ngram and a total of 12 perplexity scores per feature. Figure 1 gives an idea of the linguistic annotation extracted for an example sentence and illustrates how feature values are computed for the F EAT Raw Base subset. The annotation was generated using the CamelParser. POS tagsets used are POS6 (Habash and Roth, 2009) and a higher granularity POS34 (Habash et al., 2012). We refer the user to Shahrour et al. (2016) for further details. We elaborate next on the feature names in Table 2: • F[9] Morphemes - approximated by counting proclitics + enclitics + stem for any given token, first explored by Cavalli-Sforza et al. (2014) and Forsyth (2014), further tested by Saddiki et al. (2015) and Nassiri et al. (2017). orph • All features in F EAT M Base.LM follow the MADAMIRA POS34 tag set (Pasha et al., 2014). • F[13], F[14] Open and closed class tokens are determined by POS34 tag • F[21], F[22] Marking passive vo"
W18-3703,C12-1065,0,0.101026,"ose of the readability prediction model, e.g., measuring readability for text simplification (Aluisio et al., 2010; Dell’Orletta et al., 2014a; Al Khalil et al., 2017), selecting more cognitively-predictive features for readers with disabilities (Feng et al., 2009) or for self-directed language learning (Beinborn et al., 2012). Features used in predicting readability range from surface features extracted from raw text (e.g. average word count per line), to more complex ones requiring heavier text processing such as syntactic parsing features (Heilman et al., 2007, 2008; Beinborn et al., 2012; Hancke et al., 2012). The use of language models is increasingly favored in the literature over simple frequency counts, ratios and averages commonly used to quantify features in traditional readability formulas (Collins-Thompson and Callan, 2005; Beinborn et al., 2012; François and Miltsakaki, 2012). We evaluate features extracted using both methods in this study. There is a modest body of work on readability prediction for Arabic with marked differences in modeling approaches pursued, feature complexity, dataset size and type (L1 vs. L2), and choice of evaluation metrics. We build our feature set with predictor"
W18-3703,N07-1058,0,0.0264995,"mpson, 2014). Approaches vary depending on the purpose of the readability prediction model, e.g., measuring readability for text simplification (Aluisio et al., 2010; Dell’Orletta et al., 2014a; Al Khalil et al., 2017), selecting more cognitively-predictive features for readers with disabilities (Feng et al., 2009) or for self-directed language learning (Beinborn et al., 2012). Features used in predicting readability range from surface features extracted from raw text (e.g. average word count per line), to more complex ones requiring heavier text processing such as syntactic parsing features (Heilman et al., 2007, 2008; Beinborn et al., 2012; Hancke et al., 2012). The use of language models is increasingly favored in the literature over simple frequency counts, ratios and averages commonly used to quantify features in traditional readability formulas (Collins-Thompson and Callan, 2005; Beinborn et al., 2012; François and Miltsakaki, 2012). We evaluate features extracted using both methods in this study. There is a modest body of work on readability prediction for Arabic with marked differences in modeling approaches pursued, feature complexity, dataset size and type (L1 vs. L2), and choice of evaluati"
W18-3703,W08-0909,0,0.0894081,"Missing"
W18-3703,L18-1366,1,0.356324,"and labelled with readability levels 1, 2, 3 and 4 in increasing difficulty. 4.1 Feature Extraction • F EAT Syn Base.LM text is annotated with syntactic parsing information using the CamelParser tool (Shahrour et al., 2016). L1 and L2 Data orph.Syn All F EAT Raw.M features are obtained Base from computing occurrences, averages and other ratios over: raw text (F EAT Raw Base ); lemmatization, tokenization and morpho-syntanctic annotaorph tion (F EAT M Base ); syntactic parsing annotation Syn orph.Syn (F EAT Base ). All F EAT Raw.M features LM We leverage the L1 leveled reading corpus built by Khalil et al. (2018) based on grades 1 through 12 of an Arabic school curriculum and a collection of adult-level fiction. The corpus was split across 4 levels of readability in increasing order of difficulty: level 1 (905 documents), level 2 (1,192 documents), level 3 (2,054 documents) and level 4 (18,089 documents). The first three levels are sourced from curricular texts, grades 1-4, 5-8 and 1 The scale goes from 0 (no proficiency) to 5 (native or bilingual proficiency) with + designation for intermediate levels, for further details http://www.govtilr.org/skills /ILRscale1.htm 24 Level 1 2 3 4 L1 Corpus Source"
W18-3703,J13-1008,1,0.832969,"nd Roth, 2009). The datasets are first enriched with several layers of linguistic annotation (e.g. Fig. 1) in preparation for feature extraction. Then, both raw text and annotations from the training set are used to build LMs for each of the 4 levels of readability (Table 3) with the SRILM toolkit (Stolcke et al., 2002). At this point, we begin extracting features from the various configurations of annotation and language models we generated: • F[123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134] A POS-based language model is generated with the extended CATiB POS tagset presented in (Marton et al., 2013). • F[135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146] A dependency language model is generated on the CATiB dependency tags in F[29, 30, 31, 32, 33, 34, 35, 36] to get different levels of dependency context information, the most salient one being dependency information for parent-child nodes in the parse tree. 4 • F EAT Raw Base.LM features are extracted directly from the raw text, e.g. total number of characters in a document. orph • F EAT M Base.LM text is annotated with morphological, lexical and morpho-syntactic information using the MADAMIRA tool (Pasha et al., 2014) for morph"
W18-3703,pasha-etal-2014-madamira,1,0.933999,"Missing"
W18-3703,C16-2048,1,0.867343,"s mathematical fractions, such as F[3], F[5], F[11] and so on. LM perplexity is computed per readability level(1, 2, 3, and 4) on (uni-, bi- and tri-)grams language models, generating 4 level scores per ngram and a total of 12 perplexity scores per feature. Figure 1 gives an idea of the linguistic annotation extracted for an example sentence and illustrates how feature values are computed for the F EAT Raw Base subset. The annotation was generated using the CamelParser. POS tagsets used are POS6 (Habash and Roth, 2009) and a higher granularity POS34 (Habash et al., 2012). We refer the user to Shahrour et al. (2016) for further details. We elaborate next on the feature names in Table 2: • F[9] Morphemes - approximated by counting proclitics + enclitics + stem for any given token, first explored by Cavalli-Sforza et al. (2014) and Forsyth (2014), further tested by Saddiki et al. (2015) and Nassiri et al. (2017). orph • All features in F EAT M Base.LM follow the MADAMIRA POS34 tag set (Pasha et al., 2014). • F[13], F[14] Open and closed class tokens are determined by POS34 tag • F[21], F[22] Marking passive voice as one of the few cases where diacritic marks are typically provided for disambiguation in oth"
W18-4924,2010.jeptalnrecital-court.36,0,0.0819924,"Missing"
W18-4924,P11-2062,1,0.719462,"ose source is spoken language, Chatbot’s source is written language. 2.2 The QGenP AT B Synthetic Treebank We decided to increase the number of annotated questions available to the model in order to increase its familiarity with interrogative structures. We implemented an automatic procedure to generate annotated questions similar to the latter stages of the work by Ali et al. (2010) and Heilman and Smith (2010) who used the parsed output of raw English data. Our procedure took as input an annotated PATB sentence, to which we added some extra gender, number, and rationality information (GNR) (Alkuhlani and Habash, 2011), and produced a set of annotated questions, following 21 question generators. Multiple question trees could be generated from each PATB tree. All questions began with a question word since this is the most common type of question.1 Each question-generating procedure worked by examining the semantic dash-tags available in the input PATB tree. The dash-tags used are: -SBJ (subject), -OBJ (object), -PRD (predicate), -DIR (direction), -LOC (locative), -TMP (temporal), and -CLR (closely related). The question generators implemented grammatical tree conversion rules on the input elements (Subject,"
W18-4924,R11-2011,0,0.0208469,"nguage with relatively low resources and rich morphology. Our results show that synthetic methods can be effective at significantly reducing parsing errors for a target domain without having to invest large resources on manual annotation; and the combination of manual and synthetic methods is our best domain-independent performer. 1 Introduction Automatic syntactic parsing for questions is a challenging task since most treebanks are built from news domain articles that contain few questions (Hermjakob, 2001). Consequently, parsers can have difficulty with parsing questions (Hara et al., 2011; Gayo, 2011). This is a problem, especially in low resource languages like Arabic where the main gold standard treebank, the Penn Arabic TreeBank (PATB) (Maamouri et al., 2004), contains only 428 questions out of 12k annotated sentences (PATB Part 3). In addition to the issue of sparse question data, parsing accuracy is further affected by the difference between the training data domain and the test data domain (Sekine, 1997; Haddow and Koehn, 2012; Van der Wees et al., 2015). The cost of manually building and labeling a treebank can be prohibitive; so different methods to maximize the impact of available"
W18-4924,C10-1045,0,0.0330481,"ing why PATB should always be part of the training data. We used a two-tailed paired t-Test to evaluate the significance of the error reduction exhibited by the cumulative model over the baseline. The p-values were 0.0039 for PATB, 0.086 for PATBQ, 8 × 10−5 for TalkShow, and 0.031 for Chatbot. Only the results of the PATBQ were not significant due to the small test size and the relatively small error reduction. 5 Related Work There is a large body of literature on automatic parsing for English and other languages (Charniak, 1997; Steedman et al., 2003; Judge et al., 2006; Kübler et al., 2009; Green and Manning, 2010; Petrov et al., 2010; Zaki et al., 2016). Some of these efforts dealt with the issue of automatic training data enrichment to boost parsing accuracy. Steedman et al. (2003) showed that self training, i.e., using the output of a parser on raw text as additional training data, did not do as well as co-training, i.e., iteratively retraining two (or more) parsers on each other’s output. We do not report here on self training experiments that we did because they gave negative results. Petrov et al. (2010) showed that training with the output of a different parser can increase accuracy. In this pap"
W18-4924,P09-2056,1,0.789243,"Missing"
W18-4924,W12-3154,0,0.0331374,"nks are built from news domain articles that contain few questions (Hermjakob, 2001). Consequently, parsers can have difficulty with parsing questions (Hara et al., 2011; Gayo, 2011). This is a problem, especially in low resource languages like Arabic where the main gold standard treebank, the Penn Arabic TreeBank (PATB) (Maamouri et al., 2004), contains only 428 questions out of 12k annotated sentences (PATB Part 3). In addition to the issue of sparse question data, parsing accuracy is further affected by the difference between the training data domain and the test data domain (Sekine, 1997; Haddow and Koehn, 2012; Van der Wees et al., 2015). The cost of manually building and labeling a treebank can be prohibitive; so different methods to maximize the impact of available human resources are utilized. One of these methods is model adaptation through using the output of a model trained on one domain (e.g., news) to annotate data from a different target domain (e.g., science fiction) (Su and Yan, 2017; Petrov et al., 2010). The automatically annotated data is then used to train a new model that has improved accuracy in the target domain. There are published efforts that deal specifically with adapting mod"
W18-4924,I11-1084,0,0.0220389,"andard Arabic, a language with relatively low resources and rich morphology. Our results show that synthetic methods can be effective at significantly reducing parsing errors for a target domain without having to invest large resources on manual annotation; and the combination of manual and synthetic methods is our best domain-independent performer. 1 Introduction Automatic syntactic parsing for questions is a challenging task since most treebanks are built from news domain articles that contain few questions (Hermjakob, 2001). Consequently, parsers can have difficulty with parsing questions (Hara et al., 2011; Gayo, 2011). This is a problem, especially in low resource languages like Arabic where the main gold standard treebank, the Penn Arabic TreeBank (PATB) (Maamouri et al., 2004), contains only 428 questions out of 12k annotated sentences (PATB Part 3). In addition to the issue of sparse question data, parsing accuracy is further affected by the difference between the training data domain and the test data domain (Sekine, 1997; Haddow and Koehn, 2012; Van der Wees et al., 2015). The cost of manually building and labeling a treebank can be prohibitive; so different methods to maximize the impact"
W18-4924,N10-1086,0,0.0921695,"Missing"
W18-4924,W01-1203,0,0.155362,"of three domains (news questions, political talk shows, and chatbots) for Modern Standard Arabic, a language with relatively low resources and rich morphology. Our results show that synthetic methods can be effective at significantly reducing parsing errors for a target domain without having to invest large resources on manual annotation; and the combination of manual and synthetic methods is our best domain-independent performer. 1 Introduction Automatic syntactic parsing for questions is a challenging task since most treebanks are built from news domain articles that contain few questions (Hermjakob, 2001). Consequently, parsers can have difficulty with parsing questions (Hara et al., 2011; Gayo, 2011). This is a problem, especially in low resource languages like Arabic where the main gold standard treebank, the Penn Arabic TreeBank (PATB) (Maamouri et al., 2004), contains only 428 questions out of 12k annotated sentences (PATB Part 3). In addition to the issue of sparse question data, parsing accuracy is further affected by the difference between the training data domain and the test data domain (Sekine, 1997; Haddow and Koehn, 2012; Van der Wees et al., 2015). The cost of manually building an"
W18-4924,P06-1063,0,0.0182881,"Missing"
W18-4924,J13-1008,1,0.853796,"nce between QTemp and the PATB is the prevalence of first and second person singular verbs and pronouns in the former versus third person plural verbs and pronouns in the latter. 3 Experimental Setup For all evaluations, the Stanford parser (Version 3.8.0) was used to train models for various combinations of train sets which were evaluated against all test sets. The parser’s command-line maxLength argument was set to 30 so as to exclude longer sentences. All other configuration variables were left to default. Given the complexity of evaluating both segmentation and syntactic parsing together (Marton et al., 2013; Tsarfaty et al., 2012), we used the gold segmentation but the POS tags were predicted. Table 4 shows the distribution of treebanks between train and test sets, which are explained in the next subsections. Treebank ATB ATBQ TalkShow Chatbot QGenP AT B QTemp Domain Train # Sentences (# Words) Test # Sentences (# Words) News articles 10,836 (320,998) 794 (12,884) News articles N/A 67 (1,054) Political talk show 544 (2,691) 143 (692) Conversational 239 (1,505) 62 (441) News articles (Synthetic) 962 (8,140) N/A Conversational (Synthetic) 1,607 (13,099) N/A Table 4: The various treebanks used in t"
W18-4924,D10-1069,0,0.0428826,"t 3). In addition to the issue of sparse question data, parsing accuracy is further affected by the difference between the training data domain and the test data domain (Sekine, 1997; Haddow and Koehn, 2012; Van der Wees et al., 2015). The cost of manually building and labeling a treebank can be prohibitive; so different methods to maximize the impact of available human resources are utilized. One of these methods is model adaptation through using the output of a model trained on one domain (e.g., news) to annotate data from a different target domain (e.g., science fiction) (Su and Yan, 2017; Petrov et al., 2010). The automatically annotated data is then used to train a new model that has improved accuracy in the target domain. There are published efforts that deal specifically with adapting models for question parsing (Judge et al., 2006; Petrov et al., 2010; Seddah and Candito, 2016). In this paper, we evaluate the efficacy of two low-cost synthetic treebank generation methods at improving the parsing accuracy of questions for Arabic in a number of domains. One of the methods we use relies on existing treebanks and uses phrase structure transformations to create questions from statements. The second"
W18-4924,L16-1375,0,0.018504,"eling a treebank can be prohibitive; so different methods to maximize the impact of available human resources are utilized. One of these methods is model adaptation through using the output of a model trained on one domain (e.g., news) to annotate data from a different target domain (e.g., science fiction) (Su and Yan, 2017; Petrov et al., 2010). The automatically annotated data is then used to train a new model that has improved accuracy in the target domain. There are published efforts that deal specifically with adapting models for question parsing (Judge et al., 2006; Petrov et al., 2010; Seddah and Candito, 2016). In this paper, we evaluate the efficacy of two low-cost synthetic treebank generation methods at improving the parsing accuracy of questions for Arabic in a number of domains. One of the methods we use relies on existing treebanks and uses phrase structure transformations to create questions from statements. The second method elicits generic unlexicalized templates from human users of a specific application. Another contribution of this paper is the creation of a manually annotated treebank of 988 questions (5.3k words) in two question-heavy domains to allow us to evaluate the three methods."
W18-4924,A97-1015,0,0.401004,"ce most treebanks are built from news domain articles that contain few questions (Hermjakob, 2001). Consequently, parsers can have difficulty with parsing questions (Hara et al., 2011; Gayo, 2011). This is a problem, especially in low resource languages like Arabic where the main gold standard treebank, the Penn Arabic TreeBank (PATB) (Maamouri et al., 2004), contains only 428 questions out of 12k annotated sentences (PATB Part 3). In addition to the issue of sparse question data, parsing accuracy is further affected by the difference between the training data domain and the test data domain (Sekine, 1997; Haddow and Koehn, 2012; Van der Wees et al., 2015). The cost of manually building and labeling a treebank can be prohibitive; so different methods to maximize the impact of available human resources are utilized. One of these methods is model adaptation through using the output of a model trained on one domain (e.g., news) to annotate data from a different target domain (e.g., science fiction) (Su and Yan, 2017; Petrov et al., 2010). The automatically annotated data is then used to train a new model that has improved accuracy in the target domain. There are published efforts that deal specif"
W18-4924,E03-1008,0,0.213798,"Missing"
W18-4924,D17-1127,0,0.0256088,"entences (PATB Part 3). In addition to the issue of sparse question data, parsing accuracy is further affected by the difference between the training data domain and the test data domain (Sekine, 1997; Haddow and Koehn, 2012; Van der Wees et al., 2015). The cost of manually building and labeling a treebank can be prohibitive; so different methods to maximize the impact of available human resources are utilized. One of these methods is model adaptation through using the output of a model trained on one domain (e.g., news) to annotate data from a different target domain (e.g., science fiction) (Su and Yan, 2017; Petrov et al., 2010). The automatically annotated data is then used to train a new model that has improved accuracy in the target domain. There are published efforts that deal specifically with adapting models for question parsing (Judge et al., 2006; Petrov et al., 2010; Seddah and Candito, 2016). In this paper, we evaluate the efficacy of two low-cost synthetic treebank generation methods at improving the parsing accuracy of questions for Arabic in a number of domains. One of the methods we use relies on existing treebanks and uses phrase structure transformations to create questions from"
W18-4924,W17-1320,1,0.887033,"Missing"
W18-4924,P12-2002,0,0.0190011,"the PATB is the prevalence of first and second person singular verbs and pronouns in the former versus third person plural verbs and pronouns in the latter. 3 Experimental Setup For all evaluations, the Stanford parser (Version 3.8.0) was used to train models for various combinations of train sets which were evaluated against all test sets. The parser’s command-line maxLength argument was set to 30 so as to exclude longer sentences. All other configuration variables were left to default. Given the complexity of evaluating both segmentation and syntactic parsing together (Marton et al., 2013; Tsarfaty et al., 2012), we used the gold segmentation but the POS tags were predicted. Table 4 shows the distribution of treebanks between train and test sets, which are explained in the next subsections. Treebank ATB ATBQ TalkShow Chatbot QGenP AT B QTemp Domain Train # Sentences (# Words) Test # Sentences (# Words) News articles 10,836 (320,998) 794 (12,884) News articles N/A 67 (1,054) Political talk show 544 (2,691) 143 (692) Conversational 239 (1,505) 62 (441) News articles (Synthetic) 962 (8,140) N/A Conversational (Synthetic) 1,607 (13,099) N/A Table 4: The various treebanks used in terms of domain, training"
W18-4924,P15-2092,0,0.060797,"Missing"
W18-5027,N16-3007,0,0.0497657,"Missing"
W18-5027,C16-2047,1,0.801219,"ext processed by the speech recognizer. This allows the user to recognize when the utterance has not been ‘heard’ correctly, and encourages them to use a clearer or louder voice when interacting with the avatar. The right side of Figure 2 shows the TOIA player interface. 243 6 Kit (NLTK) (Bird et al., 2009). For Arabic, we use the Standard Arabic Morphological Analyzer (SAMA) (Graff et al., 2009). Due to Arabic’s orthographic ambiguity, SAMA produces multiple analyses (lemmas and stems) per word. We select a single analysis using the Yamama system’s maximum liklihood models for Arabic lemmas (Khalifa et al., 2016). We further add lemma synonyms to increase the possibility of matching. For English, we used NLTK Synset support (Bird et al., 2009). For Arabic, we created synthetic synsets by clustering Arabic lemmas with the same English glosses. Only for English, the database of questions and answers is also enriched through automatically generated questions, based off of the answers, to increase the probability of finding an appropriate answer for an interactor’s query. The matching process is optimized for speed using a number of hash maps to allow the fast generation of an answer ranked list. The rank"
W18-5027,W06-1303,0,0.0300332,"eserve and tell stories. The system is designed to allow anybody, simply using a laptop, to create an avatar of themselves, thus facilitating cross-cultural and cross-generational sharing of narratives to wider audiences. The system currently supports monolingual and cross-lingual dialogues in Arabic and English, but can be extended to other languages. 1 2 Related Work TOIA is inspired by research at the University of Southern California’s Institute for Creative Technologies (ICT), such as SGT Blackwell, a digitally animated character designed to serve as an army conference information kiosk (Leuski et al., 2006). Users can talk to the character through a microphone, after which their speech is converted into text through an automatic speech recognition (ASR) system. This output is then analyzed by an answer selection module and the appropriate response is selected from the 83 pre-recorded lines that Blackwell can deliver. Another ICT project, based off of video recordings instead of digital media, is New Dimensions in Testimony (NDT), a prototype dialogue system allowing users to conduct conversations with Holocaust survivor Pinchas Gutter (Traum et al., 2015a,b; Artstein et al., 2015, 2016). Similar"
W18-5027,W15-4629,0,0.575703,"s an army conference information kiosk (Leuski et al., 2006). Users can talk to the character through a microphone, after which their speech is converted into text through an automatic speech recognition (ASR) system. This output is then analyzed by an answer selection module and the appropriate response is selected from the 83 pre-recorded lines that Blackwell can deliver. Another ICT project, based off of video recordings instead of digital media, is New Dimensions in Testimony (NDT), a prototype dialogue system allowing users to conduct conversations with Holocaust survivor Pinchas Gutter (Traum et al., 2015a,b; Artstein et al., 2015, 2016). Similarly, users talk to the Gutter Avatar through a microphone; their speech is then converted into text through ASR; a dialogue manager identifies the proper video to play back to simulate a conversational turn. The NDT setup is quite impressive in terms of the amount of resources that went into creating the avatar recording — hours of recording, use of top-of-the-line digital cinema cameras, etc. In TOIA, our goal is to create a system that will enable any avatar maker with a laptop and webcam to create and Introduction Conversational agents are software p"
W18-5806,D14-1110,0,0.0144612,"as a match when calculating average maximum F-score). We continue iterating until only a single root remains containing the entire vocabulary. These trees are single prototype because the input embeddings only provide one vector for each word, regardless of whether or not it is ambiguous in any way. While this is a limitation for these models,7 existing multi prototype word embeddings generally model sense ambiguity, which is easier to capture (though harder to evaluate) given the unsupervised settings in which embeddings are typically trained (Reisinger and Mooney, 2010; Huang et al., 2012; Chen et al., 2014; Bartunov et al., 2016). Adapting multi prototype embeding geminate consonants (e.g., XXP rdd → XP rd); (3) two words are determined to be possibly from the same paradigm if there exists a possible orthographic root–POS analysis shared by both words. DE L EX builds a multi prototype tree with a maximum depth of 1. For each leaf word, it uses the above algorithm to identify all words in the vocabulary which can possibly share a paradigm with the leaf word, and grafts them into the branch. Hence, a word can belong to more than one hypothesized paradigm. Because DE L EX has access 6 The system i"
W18-5806,N16-3003,0,0.0436566,"Missing"
W18-5806,E06-1047,1,0.521306,"Missing"
W18-5806,L16-1207,1,0.908086,"Missing"
W18-5806,K17-2001,0,0.0852911,"Missing"
W18-5806,P11-2062,1,0.853751,"Missing"
W18-5806,N15-1140,0,0.0593697,"Missing"
W18-5806,E17-2067,0,0.0864513,"Missing"
W18-5806,W14-3623,1,0.874233,"Missing"
W18-5806,W02-0506,0,0.176903,"calized ( DE L EX ) morphological analyzer to predict morphological relatedness. The analyzer covers all MSA closedclass affixes and clitics and their allowed combinations in open class parts-of-speech (POS); however there is no information about stems and lemmas in the model.6 The affixes and clitics and their compatibility rules were extracted from SAMA (Graff et al., 2009). They are relatively cheap to create for any DA or other languages. The independent, expensive component of SAMA is the information regarding stems and lemmas, which we used to form our evaluation set. We are inspired by Darwish (2002), who demonstrated the creation of an Arabic shallow analyzer in one day. Our approach can be easily extended to DA at least in a similar manner to Salloum and Habash (2014). To determine if two MSA words are possibly in the same paradigm, we do the following: (1) we use the analyzer to identify all potential stems with corresponding POS for each word (these stems are simply the leftover string after removing any prefixal and suffixal strings which match a prefixsuffix combination deemed compatible by SAMA); (2) each stem is deterministically converted into an orthographic root as per Eskander"
W18-5806,W98-1007,0,0.735304,"Missing"
W18-5806,P17-2072,0,0.0903415,"Missing"
W18-5806,E17-1032,0,0.252823,"e these maximum F-scores. This reflects how cohesively paradigms are represented in the tree.5 Additionally, we report the average depth at which templatic and concatenatively related paradigm mates are added. Because we evaluate via average maximum Fscore, this metric represents the potential performance of any given model. Future work will address predicting the depth level where average maximum F-score is achieved for a given leaf word via rule-based and/or empirical techniques that have proven successful for related tasks (Narasimhan et al., 2015; Soricut and Och, 2015; Cao and Rei, 2016; Bergmanis and Goldwater, 2017; Sakakini et al., 2017). Table 1: Statistics from the EVAL set. Morphological structures by level of abstraction. Ambiguous structures contain at least one lemma ambiguous form. Non-derivationally ambiguous structures contain at least one coincidentally lemma ambiguous form. Figure 2: Best clustering strategies for two paradigms–dotted versus dashed ovals–given single or multi prototype vocabulary representations. 3.3 3.2 Word Similarity Models We use the following word similarity models for clustering words in single and multi prototype tree representations. Approach and Evaluation Metric We"
W18-5806,P18-2089,1,0.937399,"adigms each, connected by both derivational and coincidental ambiguities. Line dotting style is only used to visually distinguish paradigm membership. . brdnA form a subparadigm, being the brd and AKXQK only words in Figure 1 which can all be derived  exclusively from lemmas, XP rad∼, ‘response’, XQK . bard, ‘coldness’, and 3.1 To train word embedding models, we use a corpus of 500,000 Arabic sentences (13 million words) randomly selected from the corpus used in Almahairi et al. (2016). This makes our findings more generalizable to DA, as many dialects have similar amounts of available data (Erdmann et al., 2018). We clean our corpus via standard preprocessing3 and analyze each word out of context with SAMA (Graff et al., 2009) to get the set of possible fully diacritized lemmas from which it could be derived.4 To build an evaluation set, we sum the frequencies of all types within each paradigm and bucket paradigms based on frequency. We randomly select evaluation paradigms such that all 10 buckets contribute at least 10 paradigms each. For all selected paradigms, any paradigms from the same clan are also selected, allowing us to assume that the paradigms included in the evaluation set are independent"
W18-5806,W16-1603,0,0.127593,"chieved, and average these maximum F-scores. This reflects how cohesively paradigms are represented in the tree.5 Additionally, we report the average depth at which templatic and concatenatively related paradigm mates are added. Because we evaluate via average maximum Fscore, this metric represents the potential performance of any given model. Future work will address predicting the depth level where average maximum F-score is achieved for a given leaf word via rule-based and/or empirical techniques that have proven successful for related tasks (Narasimhan et al., 2015; Soricut and Och, 2015; Cao and Rei, 2016; Bergmanis and Goldwater, 2017; Sakakini et al., 2017). Table 1: Statistics from the EVAL set. Morphological structures by level of abstraction. Ambiguous structures contain at least one lemma ambiguous form. Non-derivationally ambiguous structures contain at least one coincidentally lemma ambiguous form. Figure 2: Best clustering strategies for two paradigms–dotted versus dashed ovals–given single or multi prototype vocabulary representations. 3.3 3.2 Word Similarity Models We use the following word similarity models for clustering words in single and multi prototype tree representations. Ap"
W18-5806,K17-1042,0,0.0442473,"Missing"
W18-5806,W14-3603,1,0.907932,"Missing"
W18-5806,L18-1607,1,0.875901,"Missing"
W18-5806,W17-1305,1,0.903601,"Missing"
W18-5806,C16-2047,1,0.908518,"Missing"
W18-5806,Q17-1025,0,0.0211902,"al., 2009; Habash, 2010). These can be used for out-of-context analysis–which SAMA (Graff et al., 2009) performs for MSA–or they can be combined with machine learning approaches that leverage information from the context in which a word appears. MADAMIRA (Pasha et al., 2014), for example, is trained on an annotated corpus to disambiguate SAMA’s analyses based on the surrounding sentence. Other systems use machine learning without rules. They can train on annotated data, like Faruqui et al. (2016) who learn morpho-syntactic lexica from a small seed, or they can learn without supervision, like Luo et al. (2017) who induce &quot;morphological forests&quot; of derivationally related words by predicting suffixes and prefixes based on the vocabulary alone. Some approaches seek to be language independent. M ORFESSOR (Creutz and Lagus, 2005), for instance, segments words based on unannotated text. However, it deterRelated Work This work builds on several others addressing word embeddings and computational morphology. Word Embeddings Word embeddings are trained by predicting either a target word given its context (Continuous Bag of Words) or elements of the context given a target (SkipGram) in unannotated corpora (M"
W18-5806,Q15-1012,0,0.424244,"regardless of the depth level at which it was achieved, and average these maximum F-scores. This reflects how cohesively paradigms are represented in the tree.5 Additionally, we report the average depth at which templatic and concatenatively related paradigm mates are added. Because we evaluate via average maximum Fscore, this metric represents the potential performance of any given model. Future work will address predicting the depth level where average maximum F-score is achieved for a given leaf word via rule-based and/or empirical techniques that have proven successful for related tasks (Narasimhan et al., 2015; Soricut and Och, 2015; Cao and Rei, 2016; Bergmanis and Goldwater, 2017; Sakakini et al., 2017). Table 1: Statistics from the EVAL set. Morphological structures by level of abstraction. Ambiguous structures contain at least one lemma ambiguous form. Non-derivationally ambiguous structures contain at least one coincidentally lemma ambiguous form. Figure 2: Best clustering strategies for two paradigms–dotted versus dashed ovals–given single or multi prototype vocabulary representations. 3.3 3.2 Word Similarity Models We use the following word similarity models for clustering words in single an"
W18-5806,C16-1326,1,0.885006,"less effort than writing new rules. ministically produces context-irrelevant segmentations, causing error propagation in languages like Arabic, characterized by high lexical ambiguity (Saleh and Habash, 2009; Pasha et al., 2014). A few systems have incorporated word embeddings to perform segmentation (Narasimhan et al., 2015; Soricut and Och, 2015; Cao and Rei, 2016), with some attempting to model and analyze relations between underlying morphemes as well (Bergmanis and Goldwater, 2017; Sakakini et al., 2017), though none of these distinguish between inflectional and derivational morphology. Eskander et al. (2016b) propose another segmentation system using Adaptor Grammars for six typologically distinct languages. Snyder and Barzilay (2010) actually use multiple languages simultaneously, finding the parallels between them useful for disambiguation in morphological and syntactic tasks. 6 Conclusion and Future Work In this work, we demonstrated that out-of-context, rule-based knowledge of morphological structure, even in minimal supply, greatly complements what word embeddings can learn about morphology from words’ in-context behaviors. We discussed how Arabic’s morphological richness and many forms of"
W18-5806,C16-1086,0,0.0601752,"less effort than writing new rules. ministically produces context-irrelevant segmentations, causing error propagation in languages like Arabic, characterized by high lexical ambiguity (Saleh and Habash, 2009; Pasha et al., 2014). A few systems have incorporated word embeddings to perform segmentation (Narasimhan et al., 2015; Soricut and Och, 2015; Cao and Rei, 2016), with some attempting to model and analyze relations between underlying morphemes as well (Bergmanis and Goldwater, 2017; Sakakini et al., 2017), though none of these distinguish between inflectional and derivational morphology. Eskander et al. (2016b) propose another segmentation system using Adaptor Grammars for six typologically distinct languages. Snyder and Barzilay (2010) actually use multiple languages simultaneously, finding the parallels between them useful for disambiguation in morphological and syntactic tasks. 6 Conclusion and Future Work In this work, we demonstrated that out-of-context, rule-based knowledge of morphological structure, even in minimal supply, greatly complements what word embeddings can learn about morphology from words’ in-context behaviors. We discussed how Arabic’s morphological richness and many forms of"
W18-5806,Q16-1001,0,0.0219801,"orphological properties of words (Beesley, 1998; Khoja and Garside, 1999; Habash and Rambow, 2006; Smrž, 2007; Graff et al., 2009; Habash, 2010). These can be used for out-of-context analysis–which SAMA (Graff et al., 2009) performs for MSA–or they can be combined with machine learning approaches that leverage information from the context in which a word appears. MADAMIRA (Pasha et al., 2014), for example, is trained on an annotated corpus to disambiguate SAMA’s analyses based on the surrounding sentence. Other systems use machine learning without rules. They can train on annotated data, like Faruqui et al. (2016) who learn morpho-syntactic lexica from a small seed, or they can learn without supervision, like Luo et al. (2017) who induce &quot;morphological forests&quot; of derivationally related words by predicting suffixes and prefixes based on the vocabulary alone. Some approaches seek to be language independent. M ORFESSOR (Creutz and Lagus, 2005), for instance, segments words based on unannotated text. However, it deterRelated Work This work builds on several others addressing word embeddings and computational morphology. Word Embeddings Word embeddings are trained by predicting either a target word given i"
W18-5806,D15-1292,0,0.0317389,"Missing"
W18-5806,W12-2301,1,0.919096,"Missing"
W18-5806,P06-1086,1,0.785419,"iversity Abu Dhabi United Arab Emirates {ae1541,nizar.habash}@nyu.edu Abstract tion. We find these two responses to be complementary in a paradigm modeling task for Modern Standard Arabic (MSA). MSA is characterized by morphological richness and extreme orthographic ambiguity, compounding the issue of data sparsity with noise (Habash, 2010). Despite its challenges, MSA is relatively well resourced, with many solutions for morphological analysis and disambiguation leveraging large amounts of annotated data, hand crafted rules, and/or sophisticated neural architectures (Khoja and Garside, 1999; Habash and Rambow, 2006; Smrž, 2007; Graff et al., 2009; Pasha et al., 2014; Abdelali et al., 2016; Inoue et al., 2017; Zalmout and Habash, 2017). Such resources and techniques, however, are not available or not viable for the many under resourced and often mutually unintelligible dialects of Arabic (DA), which are similarly morphologically rich and highly ambiguous (Chiang et al., 2006; Erdmann et al., 2017). Many recent efforts seek to develop morphological resources for DA, but most are under developed or specific to one dialect (Habash et al., 2012; Eskander et al., 2013; Jarrar et al., 2014; Al-Shargi et al., 2"
W18-5806,W17-2632,0,0.100502,"Missing"
W18-5806,pasha-etal-2014-madamira,1,0.886738,"Missing"
W18-5806,D14-1162,0,0.0814536,"enative average join depths are only comparable horizontally with each other, i.e., within the same model. FT + We build another FT model by concatenating the vectors learned from two variant FT models, one with the normal window size of 5 and one with a narrow window size of 1. Both are trained on a preprocessed corpus where phrases have been probabilistically identified in potentially unique distributions over multiple copies of each sentence, as described in Erdmann et al. (2018).8 This technique attempts to better model syntactic cues– which are better encoded with narrow context windows (Pennington et al., 2014; Trask et al., 2015; Goldberg, 2016; Tu et al., 2017)–while avoiding treating non-compositional phrases as compositional, and also learning from multiple, potentially complementary phrase-chunkings of every sentence. By combining these sources of information, FT + is designed to learn more meaningful vectors without requiring additional data. We predict it will uniformly outperform FT by reducing noise in the handling of sparse forms like infrequent inflections–a hallmark of morphologically rich languages. W2V The Gensim implementation of ˇ ˇ WORD 2 VEC (Mikolov et al., 2013a; Reh˚ urek and S"
W18-5806,P14-1127,1,0.905823,"Missing"
W18-5806,N10-1013,0,0.0304058,"characterized by high lexical ambiguity (Saleh and Habash, 2009; Pasha et al., 2014). A few systems have incorporated word embeddings to perform segmentation (Narasimhan et al., 2015; Soricut and Och, 2015; Cao and Rei, 2016), with some attempting to model and analyze relations between underlying morphemes as well (Bergmanis and Goldwater, 2017; Sakakini et al., 2017), though none of these distinguish between inflectional and derivational morphology. Eskander et al. (2016b) propose another segmentation system using Adaptor Grammars for six typologically distinct languages. Snyder and Barzilay (2010) actually use multiple languages simultaneously, finding the parallels between them useful for disambiguation in morphological and syntactic tasks. 6 Conclusion and Future Work In this work, we demonstrated that out-of-context, rule-based knowledge of morphological structure, even in minimal supply, greatly complements what word embeddings can learn about morphology from words’ in-context behaviors. We discussed how Arabic’s morphological richness and many forms of ambiguity interact with different word similarity models’ ability to represent morphological structure in a paradigm clustering ta"
W18-5806,2009.mtsummit-caasl.5,1,0.753055,"extractor however, depends on embeddings to identify roots. Furthermore, their root extractor cannot be used to generate multi prototype models as it only produces one root per word. Finally, despite orthographic roots’ dependance on hand written rules, we show that these rules are very few, such that adapting Sakakini et al. (2017)’s root extractor to a new language or dialect would not necessarily require any less effort than writing new rules. ministically produces context-irrelevant segmentations, causing error propagation in languages like Arabic, characterized by high lexical ambiguity (Saleh and Habash, 2009; Pasha et al., 2014). A few systems have incorporated word embeddings to perform segmentation (Narasimhan et al., 2015; Soricut and Och, 2015; Cao and Rei, 2016), with some attempting to model and analyze relations between underlying morphemes as well (Bergmanis and Goldwater, 2017; Sakakini et al., 2017), though none of these distinguish between inflectional and derivational morphology. Eskander et al. (2016b) propose another segmentation system using Adaptor Grammars for six typologically distinct languages. Snyder and Barzilay (2010) actually use multiple languages simultaneously, finding"
W18-5806,N15-1186,0,0.322187,"level at which it was achieved, and average these maximum F-scores. This reflects how cohesively paradigms are represented in the tree.5 Additionally, we report the average depth at which templatic and concatenatively related paradigm mates are added. Because we evaluate via average maximum Fscore, this metric represents the potential performance of any given model. Future work will address predicting the depth level where average maximum F-score is achieved for a given leaf word via rule-based and/or empirical techniques that have proven successful for related tasks (Narasimhan et al., 2015; Soricut and Och, 2015; Cao and Rei, 2016; Bergmanis and Goldwater, 2017; Sakakini et al., 2017). Table 1: Statistics from the EVAL set. Morphological structures by level of abstraction. Ambiguous structures contain at least one lemma ambiguous form. Non-derivationally ambiguous structures contain at least one coincidentally lemma ambiguous form. Figure 2: Best clustering strategies for two paradigms–dotted versus dashed ovals–given single or multi prototype vocabulary representations. 3.3 3.2 Word Similarity Models We use the following word similarity models for clustering words in single and multi prototype tree"
W18-5806,N18-1087,1,0.899622,"Missing"
W18-5806,D17-1073,1,0.915182,"Missing"
W18-5816,N04-4038,0,0.106706,"alysis, Disambiguation and Tokenization We distinguish between analysis and disambiguation: analysis refers to identifying all of the different readings (analyses) of a word out of context; while disambiguation is about identifying the specific analysis in context. Tokenization is the process of segmenting a word into different units for downstream applications. There are many possible tokenization schemes and techniques to apply them (Habash and Sadat, 2006). The tokenized form of a word varies depending on the specific analysis of the word. Systems such as MADA (Habash et al., 2009), AMIRA (Diab et al., 2004), and MADAMIRA (Pasha et al., 2014) handle disambiguation and tokenization differently. Both MADA and MADAMIRA disambiguate the analyses that are produced by a morphological analyzer. The chosen analyses are then used to tokenize the words using morphological regeneration. AMIRA, on the other hand, has a different two step process in which a toeknization component is followed by part-of-speech (POS) tagging. The FARASA system (Abdelali et al., 2016) relies on probabilistic models of stems, prefixes, and suffixes, instead of using context information to produce high tokenization accuracy. YAMAM"
W18-5816,L18-1574,1,0.813858,"database (space) with a faster tokenization (time). We specifically add four tokenization schemes D1, D2, D3 and ATB (Habash, 2010), in both normalized and unnormalized forms. We refer to the normalized schemes as tokenization, and to the unnormalized schemes as segmentation. A normalized ATB tokenization for the word AëñJ.J» ktbwhA ‘they wrote it’ is Aë+ @ñJ.J» ktbwA+hA ‘they_wrote +it’, whereas an unnormalized ATB tokenization (segmentation) for the same word would be Aë+ñJ.J» ktbw+hA. In the lex6 The phonological representation we use follows the CAMEL Arabic Phonetic Inventory (CAPHI) (Habash et al., 2018), which is inspired by Arpabet (Shoup, 1980). 145 Multiple POS Tag Sets There are many Arabic POS tag sets used by different researchers and in different tools, e.g., Buckwalter (Buckwalter, 2002), MADA (Pasha et al., 2014), Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), CATiBex (Marton et al., 2013), Universal Dependencies (UD) (Nivre et al., 2016), and Kulick (Kulick et al., 2006). It is desirable to link these POS tag sets to each other. CALIMAStar currently supports four POS tag sets: the Buckwalter POS tag set, and the MADA POS tag set, both of which are part of the ALMOR datab"
W18-5816,W12-2301,1,0.890102,"orphology are not fully or consistently modeled. Examples include the discrepancy between form and function (in gender, number, case and state) as well as the rationality feature. The commonly used Penn Arabic Treebank (PATB) (Maamouri et al., 2004) and Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2002) do not model nominal functional features or rationality. Some previous attempts did not cover all these phenomena or focused on limited data sets (Smrž, 2007; Alkuhlani and Habash, 2011). 1  In Arabic, éÒÊ¿ /kalima/ means ‘word’. We follow and extend the naming convention from Habash et al. (2012) who developed CALIMAEGY , and Khalifa et al. (2017) who developed CALIMAGLF . The Star designation in CALIMAStar is intended to eventually represent all Arabic variants (MSA and dialects), and all possible features. 2 http://resources.camel-lab.com/. 140 Proceedings of the 15th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 140–150 c Brussels, Belgium, October 31, 2018. 2018 The Special Interest Group on Computational Morphology and Phonology https://doi.org/10.18653/v1/P17 2 Related Work Alkuhlani and Habash (2011) extended part of the PATB to in"
W18-5816,P05-1071,1,0.676083,"Missing"
W18-5816,P06-1086,1,0.79414,"h SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 140–150 c Brussels, Belgium, October 31, 2018. 2018 The Special Interest Group on Computational Morphology and Phonology https://doi.org/10.18653/v1/P17 2 Related Work Alkuhlani and Habash (2011) extended part of the PATB to include functional gender and number, and rationality, but did not cover the entire database used by BAMA or SAMA. ElixirFM (Smrž, 2007) includes functional gender and number, as well as full case and state modeling, but not rationality. ElixirFM, MAGEAD (Altantawy et al., 2010; Habash and Rambow, 2006) and AlKhalil Morpho Sys (Boudlal et al., 2010; Boudchiche et al., 2017) include roots, with varying degrees of accuracy. ElixirFM includes phonological forms; but ALMOR does not. However, Biadsy et al. (2009) presented orthography-to-phonology rules that can be used on automatically diacritized text to generate pronunciation dictionaries. Our goal is to make all these features be built-in as part of our CALIMAStar databases, and to fill in any gaps that were left by other efforts. In this section, we discuss previous work on Arabic morphological analysis and generation in terms of (a) algorit"
W18-5816,P11-2062,1,0.953702,"or Arabic morphology, we observe that there are still some unresolved challenges. First, some aspects of Arabic’s rich morphology are not fully or consistently modeled. Examples include the discrepancy between form and function (in gender, number, case and state) as well as the rationality feature. The commonly used Penn Arabic Treebank (PATB) (Maamouri et al., 2004) and Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2002) do not model nominal functional features or rationality. Some previous attempts did not cover all these phenomena or focused on limited data sets (Smrž, 2007; Alkuhlani and Habash, 2011). 1  In Arabic, éÒÊ¿ /kalima/ means ‘word’. We follow and extend the naming convention from Habash et al. (2012) who developed CALIMAEGY , and Khalifa et al. (2017) who developed CALIMAGLF . The Star designation in CALIMAStar is intended to eventually represent all Arabic variants (MSA and dialects), and all possible features. 2 http://resources.camel-lab.com/. 140 Proceedings of the 15th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 140–150 c Brussels, Belgium, October 31, 2018. 2018 The Special Interest Group on Computational Morphology and Pho"
W18-5816,W11-4416,1,0.781614,"proaches use very abstract and linguistically rich representations and rules to derive surface forms of the words (Beesley et al., 1989; Beesley, 1996; Habash and Rambow, 2006; Smrž, 2007). Other approaches pre-compile representations of the different components needed by the system: BAMA (Buckwalter, 2002), SAMA (Graff et al., 2009), and ALMORGEANA (ALMOR for short) (Habash, 2007) are examples of such systems. They use a six-table representation consisting of three lexical tables (for prefixes, suffixes, and stems), and three compatibility tables (prefix-suffix, prefixstem, and stem-suffix). Altantawy et al. (2011) described a method to bridge between these two types of solutions. The type of representation used naturally needs to synchronize with the appropriate algorithms for analysis and generation. CALIMAStar is of the second category (tabulated pre-compiled solutions), and it builds on the popularly used BAMA, SAMA, and ALMOR morphological analyzers. 2.2 2.3 Analysis, Disambiguation and Tokenization We distinguish between analysis and disambiguation: analysis refers to identifying all of the different readings (analyses) of a word out of context; while disambiguation is about identifying the specif"
W18-5816,altantawy-etal-2010-morphological,1,0.886455,"0 Proceedings of the 15th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 140–150 c Brussels, Belgium, October 31, 2018. 2018 The Special Interest Group on Computational Morphology and Phonology https://doi.org/10.18653/v1/P17 2 Related Work Alkuhlani and Habash (2011) extended part of the PATB to include functional gender and number, and rationality, but did not cover the entire database used by BAMA or SAMA. ElixirFM (Smrž, 2007) includes functional gender and number, as well as full case and state modeling, but not rationality. ElixirFM, MAGEAD (Altantawy et al., 2010; Habash and Rambow, 2006) and AlKhalil Morpho Sys (Boudlal et al., 2010; Boudchiche et al., 2017) include roots, with varying degrees of accuracy. ElixirFM includes phonological forms; but ALMOR does not. However, Biadsy et al. (2009) presented orthography-to-phonology rules that can be used on automatically diacritized text to generate pronunciation dictionaries. Our goal is to make all these features be built-in as part of our CALIMAStar databases, and to fill in any gaps that were left by other efforts. In this section, we discuss previous work on Arabic morphological analysis and generati"
W18-5816,C96-1017,0,0.530336,"e all these features be built-in as part of our CALIMAStar databases, and to fill in any gaps that were left by other efforts. In this section, we discuss previous work on Arabic morphological analysis and generation in terms of (a) algorithms and representations, (b) morphological knowledge, and (c) morphological disambiguation and tokenization. Table 1 compares the features supported by CALIMAStar and a number of analyzers discussed below. 2.1 Algorithms and Representations There are a number of dimensions over which solutions to Arabic morphology modeling have varied (Beesley et al., 1989; Beesley, 1996; Habash and Rambow, 2006; Smrž, 2007; Altantawy et al., 2010, 2011). One important aspect is the degree of explicitness of representing morphological rules and their interactions. Some approaches use very abstract and linguistically rich representations and rules to derive surface forms of the words (Beesley et al., 1989; Beesley, 1996; Habash and Rambow, 2006; Smrž, 2007). Other approaches pre-compile representations of the different components needed by the system: BAMA (Buckwalter, 2002), SAMA (Graff et al., 2009), and ALMORGEANA (ALMOR for short) (Habash, 2007) are examples of such system"
W18-5816,N09-1045,1,0.859019,"Missing"
W18-5816,P09-2056,1,0.786466,"normalized ATB tokenization for the word AëñJ.J» ktbwhA ‘they wrote it’ is Aë+ @ñJ.J» ktbwA+hA ‘they_wrote +it’, whereas an unnormalized ATB tokenization (segmentation) for the same word would be Aë+ñJ.J» ktbw+hA. In the lex6 The phonological representation we use follows the CAMEL Arabic Phonetic Inventory (CAPHI) (Habash et al., 2018), which is inspired by Arpabet (Shoup, 1980). 145 Multiple POS Tag Sets There are many Arabic POS tag sets used by different researchers and in different tools, e.g., Buckwalter (Buckwalter, 2002), MADA (Pasha et al., 2014), Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), CATiBex (Marton et al., 2013), Universal Dependencies (UD) (Nivre et al., 2016), and Kulick (Kulick et al., 2006). It is desirable to link these POS tag sets to each other. CALIMAStar currently supports four POS tag sets: the Buckwalter POS tag set, and the MADA POS tag set, both of which are part of the ALMOR database, as well as the CATiB and UD POS tag sets. We chose to start our extension with the CATiB and UD POS tag sets for their importance to the work on Arabic dependency parsing. This goal steered us to output the CATiB and UD POS tags following the ATB tokenization, which is the co"
W18-5816,N06-2013,1,0.853453,"Star is of the second category (tabulated pre-compiled solutions), and it builds on the popularly used BAMA, SAMA, and ALMOR morphological analyzers. 2.2 2.3 Analysis, Disambiguation and Tokenization We distinguish between analysis and disambiguation: analysis refers to identifying all of the different readings (analyses) of a word out of context; while disambiguation is about identifying the specific analysis in context. Tokenization is the process of segmenting a word into different units for downstream applications. There are many possible tokenization schemes and techniques to apply them (Habash and Sadat, 2006). The tokenized form of a word varies depending on the specific analysis of the word. Systems such as MADA (Habash et al., 2009), AMIRA (Diab et al., 2004), and MADAMIRA (Pasha et al., 2014) handle disambiguation and tokenization differently. Both MADA and MADAMIRA disambiguate the analyses that are produced by a morphological analyzer. The chosen analyses are then used to tokenize the words using morphological regeneration. AMIRA, on the other hand, has a different two step process in which a toeknization component is followed by part-of-speech (POS) tagging. The FARASA system (Abdelali et al"
W18-5816,W17-1305,1,0.850651,"amples include the discrepancy between form and function (in gender, number, case and state) as well as the rationality feature. The commonly used Penn Arabic Treebank (PATB) (Maamouri et al., 2004) and Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2002) do not model nominal functional features or rationality. Some previous attempts did not cover all these phenomena or focused on limited data sets (Smrž, 2007; Alkuhlani and Habash, 2011). 1  In Arabic, éÒÊ¿ /kalima/ means ‘word’. We follow and extend the naming convention from Habash et al. (2012) who developed CALIMAEGY , and Khalifa et al. (2017) who developed CALIMAGLF . The Star designation in CALIMAStar is intended to eventually represent all Arabic variants (MSA and dialects), and all possible features. 2 http://resources.camel-lab.com/. 140 Proceedings of the 15th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 140–150 c Brussels, Belgium, October 31, 2018. 2018 The Special Interest Group on Computational Morphology and Phonology https://doi.org/10.18653/v1/P17 2 Related Work Alkuhlani and Habash (2011) extended part of the PATB to include functional gender and number, and rationality,"
W18-5816,C16-2047,1,0.942807,"nd MADAMIRA (Pasha et al., 2014) handle disambiguation and tokenization differently. Both MADA and MADAMIRA disambiguate the analyses that are produced by a morphological analyzer. The chosen analyses are then used to tokenize the words using morphological regeneration. AMIRA, on the other hand, has a different two step process in which a toeknization component is followed by part-of-speech (POS) tagging. The FARASA system (Abdelali et al., 2016) relies on probabilistic models of stems, prefixes, and suffixes, instead of using context information to produce high tokenization accuracy. YAMAMA (Khalifa et al., 2016) is a MADAMIRAlike (analysis/disambiguation) system that disambiguates using a maximum likelihood model inspired by FARASA. CALIMAStar is primarily an out-of-context Morphological Knowledge Previous efforts show a wide range for the depth that morphological analyzers can produce. Some efforts include very shallow analyses such as in the Temple Translator’s Workstation Project (Vanni and Zajac, 1996) which only provided English glossing. Others include a range of formbased features, functional features, and morpheme forms, in addition to lexical features (Buckwalter, 2002; Smrž, 2007; Boudlal e"
W18-5816,J13-1008,1,0.885141,"he word AëñJ.J» ktbwhA ‘they wrote it’ is Aë+ @ñJ.J» ktbwA+hA ‘they_wrote +it’, whereas an unnormalized ATB tokenization (segmentation) for the same word would be Aë+ñJ.J» ktbw+hA. In the lex6 The phonological representation we use follows the CAMEL Arabic Phonetic Inventory (CAPHI) (Habash et al., 2018), which is inspired by Arpabet (Shoup, 1980). 145 Multiple POS Tag Sets There are many Arabic POS tag sets used by different researchers and in different tools, e.g., Buckwalter (Buckwalter, 2002), MADA (Pasha et al., 2014), Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), CATiBex (Marton et al., 2013), Universal Dependencies (UD) (Nivre et al., 2016), and Kulick (Kulick et al., 2006). It is desirable to link these POS tag sets to each other. CALIMAStar currently supports four POS tag sets: the Buckwalter POS tag set, and the MADA POS tag set, both of which are part of the ALMOR database, as well as the CATiB and UD POS tag sets. We chose to start our extension with the CATiB and UD POS tag sets for their importance to the work on Arabic dependency parsing. This goal steered us to output the CATiB and UD POS tags following the ATB tokenization, which is the commonly used tokenization format"
W18-5816,pasha-etal-2014-madamira,1,0.909779,"Missing"
W18-5816,W07-0801,0,0.21932,"tures Dima Taji, Salam Khalifa, Ossama Obeid, Fadhl Eryani, and Nizar Habash Computational Approaches to Modeling Languages Lab New York University Abu Dhabi {dima.taji, salamkhalifa, oobeid, fadhl.eryani, nizar.habash}@nyu.edu Abstract Second, the different existing tools do not all provide the same kind of information, which often led researchers to improvise extensions to accommodate their downstream task needs. One example is the phonological representation mappings that Biadsy et al. (2009) devised on top of the MADA disambiguation system (Habash et al., 2009) instead of using Elixir-FM (Smrž, 2007), which already included phonology. This is partially because Elixir-FM was not connected to a disambiguation system. Another example is the work by Habash et al. (2009) to provide generation capability on top of the BAMA (Buckwalter, 2002) algorithm and databases because BAMA, which was used to annotate the PATB, was analysis focused, unlike the finite-state solutions to Arabic morphology (Beesley et al., 1989). Third, many of the existing tools have different use requirements (operating system, programming language, etc.), and some have no easy-touse APIs. In this paper, we introduce CALIMAS"
W18-5816,X96-1024,0,0.782556,"agging. The FARASA system (Abdelali et al., 2016) relies on probabilistic models of stems, prefixes, and suffixes, instead of using context information to produce high tokenization accuracy. YAMAMA (Khalifa et al., 2016) is a MADAMIRAlike (analysis/disambiguation) system that disambiguates using a maximum likelihood model inspired by FARASA. CALIMAStar is primarily an out-of-context Morphological Knowledge Previous efforts show a wide range for the depth that morphological analyzers can produce. Some efforts include very shallow analyses such as in the Temple Translator’s Workstation Project (Vanni and Zajac, 1996) which only provided English glossing. Others include a range of formbased features, functional features, and morpheme forms, in addition to lexical features (Buckwalter, 2002; Smrž, 2007; Boudlal et al., 2010; Alkuhlani and Habash, 2011; Boudchiche et al., 2017). 141 BAMA SAMA ALMOR MAGEAD ElixirFM AlKhalil CALIMAStar Functional Gender and Number 7 7 7 partial partial partial 3 Case and State Modeling partial partial partial 3 3 partial 3 Rationality 7 7 7 7 7 7 3 Roots and Patterns 7 7 7 3 3 3 3 Phonological Representation 7 7 7 3 3 7 3 Number of Tokenization Schemes 1 1 1 1 1 1 4 Number of"
W18-5816,D17-1073,1,0.915786,"gy of the  masculine plural verb @ñJ.J» katabuwA ‘they wrote’ is / k a t a b uu /, as opposed to */ k a t a b uu aa /. This feature does not exist in SAMA or ALMOR. We extended our database entries with their respective phonological representation through an automatic process comparable to Biadsy et al. (2009). The definite article assimilation is handled through rewrite rules because it involves an interaction between a stem and a prefix. 4.6 4.7 Tokenization Schemes Tokenization is important for NLP tasks such as machine translation because it reduces word sparsity (Habash and Sadat, 2006; Zalmout and Habash, 2017b). Many tokenization schemes with different granularities and normalization rules exist, and the selection of tokenization scheme depends on the task on hand. In MADAMIRA, tokenization happens after analysis and disambiguation through an expensive regeneration process. Our contribution is the insight that since a particular tokenization is completely dependent on the analysis, we can specify the tokenization details in the database entry. This is a tradeoff of a bigger database (space) with a faster tokenization (time). We specifically add four tokenization schemes D1, D2, D3 and ATB (Habash,"
W19-3822,P11-2062,1,0.89414,"Missing"
W19-3822,W19-3805,0,0.0359119,"Missing"
W19-3822,E17-2104,0,0.0155772,"ded, replacing each with its partner, while maintaining the same ground truth. The goal here is to encourage learning algorithms to not pick up on biased distinctions. Building on CDA, (Zmigrod et al., 2019) presented a generative model that allows conversion between masculine inflected and feminine inflected sentences in four morphologically rich languages (Hebrew, Spanish, French and Italian) with a focus on animate nouns. Specifically for MT, Rabinovich et al. (2016) presented work on the preservation of author gender. Some researchers suggested improvement through co-reference resolution (Gonzales and Tuggener, 2017; Luong and Popescu-Belis, 2016). Vanmassenhove et al. (2018) conducted a series of experiments to improve morphological agreement and improve translation quality in NMT systems for 20 language pairs (none of which were Arabic). They compiled large datasets from Europarl (Koehn, 2005), including speaker gender and age, and trained NMT systems with the tagged language pair. They showed that providing tags that indicate the speaker’s gender to the system leads to significant improvements. Similarly, Elaraby et al. (2018) marked speaker and listener gender as meta-data input on the source sentenc"
W19-3822,K17-2001,0,0.0532134,"Missing"
W19-3822,P17-4012,0,0.0197793,"e main reason for this setup is that character-level representations are reported to be good in capturing and learning morphological aspects (Ling et al., 2015; Kim et al., 2016), which is important for a morphologically rich language like Arabic. Furthermore, character-level NMT modeling requires less vocabulary and helps reduce out-of-vocabulary by translating unseen words. Our character-based NMT system is an encoder-decoder model that uses the general global attention architecture introduced by Luong and Manning (2015). All the NMT models we use have been trained with the OpenNMT toolkit (Klein et al., 2017) with no restriction on the input vocabulary size. Specifically, we use long short-term memory units (LSTM), with hidden units of size 500 and 2 layers in both the encoder and decoder. The model is trained for 13 epochs, using Adam with a learning rate of 0.002 and mini-batches of 40 with no pre-trained embeddings. Our char-level embeddings are learned within the training of the model. Using different combinations of the data sets presented in Section 4, we build four reinflection models. • in-to-M is a model trained to map from the Balanced Input corpus (and Synthetic F) to the TargetM corpus"
W19-3822,2010.jeptalnrecital-long.29,1,0.821127,"Missing"
W19-3822,W19-3821,0,0.0523214,"Missing"
W19-3822,L16-1147,0,0.174977,"of experiments to improve morphological agreement and improve translation quality in NMT systems for 20 language pairs (none of which were Arabic). They compiled large datasets from Europarl (Koehn, 2005), including speaker gender and age, and trained NMT systems with the tagged language pair. They showed that providing tags that indicate the speaker’s gender to the system leads to significant improvements. Similarly, Elaraby et al. (2018) marked speaker and listener gender as meta-data input on the source sentence in an English-to-Arabic NMT system. The training data came from OpenSubtitle (Lison and Tiedemann, 2016). The authors used rules to identify the gender in the Arabic text. Prates et al. (2018) used Google Translate to translate a set consisting of a list of jobs and gender-specific sentences from a variety of gender-neutral languages into English. They showed that occupations related to science, engineering and mathematics present a strong stereotype towards the male gender. More recently, Font and Costa-jussà (2019) studied the impact of gender debiasing on NMT between English and Spanish using debiased and gender-neutral word embeddings. Google Translate publicly announced an effort to address"
W19-3822,2015.iwslt-evaluation.11,0,0.0155322,"uences of characters rather than words and learn to encode and decode at the character-level. The main reason for this setup is that character-level representations are reported to be good in capturing and learning morphological aspects (Ling et al., 2015; Kim et al., 2016), which is important for a morphologically rich language like Arabic. Furthermore, character-level NMT modeling requires less vocabulary and helps reduce out-of-vocabulary by translating unseen words. Our character-based NMT system is an encoder-decoder model that uses the general global attention architecture introduced by Luong and Manning (2015). All the NMT models we use have been trained with the OpenNMT toolkit (Klein et al., 2017) with no restriction on the input vocabulary size. Specifically, we use long short-term memory units (LSTM), with hidden units of size 500 and 2 layers in both the encoder and decoder. The model is trained for 13 epochs, using Adam with a learning rate of 0.002 and mini-batches of 40 with no pre-trained embeddings. Our char-level embeddings are learned within the training of the model. Using different combinations of the data sets presented in Section 4, we build four reinflection models. • in-to-M is a"
W19-3822,W16-2202,0,0.0225837,"partner, while maintaining the same ground truth. The goal here is to encourage learning algorithms to not pick up on biased distinctions. Building on CDA, (Zmigrod et al., 2019) presented a generative model that allows conversion between masculine inflected and feminine inflected sentences in four morphologically rich languages (Hebrew, Spanish, French and Italian) with a focus on animate nouns. Specifically for MT, Rabinovich et al. (2016) presented work on the preservation of author gender. Some researchers suggested improvement through co-reference resolution (Gonzales and Tuggener, 2017; Luong and Popescu-Belis, 2016). Vanmassenhove et al. (2018) conducted a series of experiments to improve morphological agreement and improve translation quality in NMT systems for 20 language pairs (none of which were Arabic). They compiled large datasets from Europarl (Koehn, 2005), including speaker gender and age, and trained NMT systems with the tagged language pair. They showed that providing tags that indicate the speaker’s gender to the system leads to significant improvements. Similarly, Elaraby et al. (2018) marked speaker and listener gender as meta-data input on the source sentence in an English-to-Arabic NMT sy"
W19-3822,P02-1040,0,0.107643,"ttings: (a) the Balanced Input D EV and T EST, and (b) the English-to-Arabic Google Translate output of the English sentences corresponding the Balanced Input D EV and T EST, D EVGT and T ESTGT (Section 4). We evaluate sentence gender reinflection against the D EV and T EST portions of the TargetF and TargetM corpora as references (also, Section 4). In addition to the single and two-step system, we include a “do-nothing” baseline that simply passes the input to the output as is. Reinflection Evaluation Reinflection results for each setup are reported in Table 5 in terms of the MT metric BLEU (Papineni et al., 2002). It is important to note that all the reported scores are on AYT-normalized texts.6 This normalization helps reduce the number of cases in which Alif, Ya, and Ta Marbuta are inconsistently represented in the references. The table specifies columns for Target M, and Target F, which indicate which reference is used for evaluation. For the Balanced Input, the best performance was achieved using the two-step system. The BLEU scores are very high because most of the 6 AYT refers to the orthographic normalization of AlifHamza forms, Ya/Alif-Maqsura forms, and Ta-Marbuta/Ha forms (Habash, 2010) Bala"
W19-3822,pasha-etal-2014-madamira,1,0.873221,"Missing"
W19-3822,D18-1334,0,0.29945,"ame ground truth. The goal here is to encourage learning algorithms to not pick up on biased distinctions. Building on CDA, (Zmigrod et al., 2019) presented a generative model that allows conversion between masculine inflected and feminine inflected sentences in four morphologically rich languages (Hebrew, Spanish, French and Italian) with a focus on animate nouns. Specifically for MT, Rabinovich et al. (2016) presented work on the preservation of author gender. Some researchers suggested improvement through co-reference resolution (Gonzales and Tuggener, 2017; Luong and Popescu-Belis, 2016). Vanmassenhove et al. (2018) conducted a series of experiments to improve morphological agreement and improve translation quality in NMT systems for 20 language pairs (none of which were Arabic). They compiled large datasets from Europarl (Koehn, 2005), including speaker gender and age, and trained NMT systems with the tagged language pair. They showed that providing tags that indicate the speaker’s gender to the system leads to significant improvements. Similarly, Elaraby et al. (2018) marked speaker and listener gender as meta-data input on the source sentence in an English-to-Arabic NMT system. The training data came"
W19-3822,D18-1521,0,0.0536282,"rst-person-singular masculine on top of a state-of-the-art gender-blind MT system on a held-out test set. Next, we discuss some related work (Section 2) and Arabic linguistic facts (Section 3). We present our Arabic parallel gender corpus in Section 4, gender identification in Section 5, and gender reinflection and MT results in Section 6. 2 Related Work Gender bias has been detected, studied, and partially addressed for standard and contextualized word embeddings in a number of studies (Bolukbasi et al., 2016; Caliskan et al., 2017; Sutton et al., 2018; Basta et al., 2019; Garg et al., 2018; Zhao et al., 2018, 2019). These studies showed that training word embeddings on large human produced corpora such as news text leads to encoding societal biases including gender and race. Some of these studies focused on quantifying the bias, and proposed approaches for mitigating it within word embeddings. In the context of data augmentation solutions, Lu et al. (2018) introduced counterfactual data augmentation (CDA), a generic methodology to mitigate bias in neural NLP tasks, where for each training instance, a copy with an intervention on its targeted words is added, replacing each with its partner, while"
W19-3822,P19-1161,0,0.240143,"ender, gender-blind single-output MT from English often results in I. J.£ AK @ ÂnA Tbyb1 ‘I am a Ø AK @ ÂnA mmrD~ ‘I am a [fe[male] doctor’/ éQÜ male] nurse’, which is inappropriate for female doctors and male nurses, respectively. Part of this problem comes from humangenerated data that mirrors the social biases and inequalities of the world we live in, and that results in biased models and representations. Many research efforts responded to this problem by debiasing and balancing the models created from the data through model modification or data augmentation (Font and Costa-jussà, 2019; Zmigrod et al., 2019). However, ultimately, even the most balanced and unbiased of models can be useless in gender-blind systems that are designed to generate a single text output. Such systems are doomed to unsurprisingly pass on the biases of the models they use, as demonstrated in the doctor/nurse example above. In contrast, gender-aware systems should be designed to produce outputs that are as gender-specific as the input information they have access to. The input gender information may be contextual (e.g., the input ‘she is a doctor’), or extra linguistics (e.g., the gender feature provided in the user profil"
W19-4214,2012.eamt-1.60,0,0.0103923,"nts and blogs, consisting of over 10 million words for each subset’s dialect region. It is worth noting however, that the granularity of their dialect regions is coarser than the granularity of CORPUS 6. Hence, their Maghrebi dialect corresponds to two dialects in CORPUS 6, Tunis and Rabat, while the remaining three dialect regions have rather obvious one-to-one correspondences with CORPUS 6, i.e., Egyptian to Cairo, Levantine to Beirut, and Gulf to Doha. For MSA, which rarely occurs consistently (i.e., outside of brief instances of code-mixing) in such casual domains, we used the TED corpus (Cettolo and Girardi, 2012) for our monolingual data set, finding a compromise between domain relevance and corpus size. It contains about 2.5 million words. Obviously, CORPUS 6 is small relative to other MT corpora, but this is exactly why it is a meaningful evaluation corpus. Larger parallel corpora are often only available for better resourced languages/domains where fully supervised segmenters are also more likely to be available, negating the need to build one’s own segmenter. Furthermore, as parallel data becomes less sparse, tokenization necessarily has less of an effect since models can memorize and effectively"
W19-4214,E06-1047,1,0.671899,"popular approaches to segmentation. Furthermore, we discuss the construction of DE S EG’s grammar and its disambiguation algorithm. 3.1 Data Arabic and its Dialects Arabic is highly diaglossic (Ferguson, 1959), with the relatively consistent high register of Modern Standard Arabic being learned in schools across the Arab World. Meanwhile the often mutually unintelligible low register variants—collectively known as dialectal Arabic (DA)—are spoken colloquially. The phonological, morpho-syntactic, and lexical variation within the Arabic sprachbund is comparable to that among Romance languages (Chiang et al., 2006; Rouchdy, 2013; Erdmann et al., 2017), leading to problematic noise in multidialect corpora (Erdmann et al., 2018). Furthermore, lack of spelling conventions in DA exacerbates data sparsity, as does a rich morphology featuring templatic phenomena and robust cliticization, making it challenging to train quality segmenters even with much supervised data. 3.3 De-lexical Analysis The DE S EG grammar provides all possible delexical analyses of words by assuming any n-gram 115 Morph.Feat. (A) Prefix (B) PV.1US PV.1UP PV.2MS PV.2FS ∅ ∅ ∅ ∅ +t +nA +t +t/ty PV.2US ∅ +ty PV.2UP PV.3MS PV.3FS PV.3UP ∅ ∅"
W19-4214,W02-0506,0,0.0290285,"upervised options like MOR FESSOR (Creutz and Lagus, 2005) and byte pair encoding (BPE) (Sennrich et al., 2016) assume no 1 Exponents refer to recurring means by which morphosyntactic properties are realized within classes of words, e.g., adding suffix +s to get the third person singular present tense for verbs like WALK, TALK, and SKIP. 113 Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 113–124 c Florence, Italy. August 2, 2019 2019 Association for Computational Linguistics on automatic shallow and deterministic segmentation for MSA. Darwish (2002) used limited resources and greedy techniques to automatically learn rules and statistics to build a shallow morphological analyzer. There are many MSA morphological analyzers with rich representations and good coverage that required very intensive efforts to create (Beesley, 1998; Buckwalter, 2004; Attia, 2006, 2007; Smrž, 2007; Boudchiche et al., 2017). Buckwalter (2004) is perhaps the most commonly used among them, as it contributed the representations for the Penn Arabic treebank (PATB) (Maamouri and Bies, 2004). The PATB has been the most used resource for supervised morphological disambi"
W19-4214,N04-4038,0,0.0304678,"ited resources and greedy techniques to automatically learn rules and statistics to build a shallow morphological analyzer. There are many MSA morphological analyzers with rich representations and good coverage that required very intensive efforts to create (Beesley, 1998; Buckwalter, 2004; Attia, 2006, 2007; Smrž, 2007; Boudchiche et al., 2017). Buckwalter (2004) is perhaps the most commonly used among them, as it contributed the representations for the Penn Arabic treebank (PATB) (Maamouri and Bies, 2004). The PATB has been the most used resource for supervised morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; AlGahtani and McNaught, 2015; Zalmout and Habash, 2017). Some efforts have used other annotated resources and/or large unannotated data sets (Lee et al., 2003; Abdelali et al., 2016; Freihat et al., 2018). More closely related to this paper, Erdmann and Habash (2018) demonstrated that delexicalized information provides a cheap means of inducing morphological knowledge and thereby predicting lexical information in MSA. They employ a de-lexicalized grammar which is similar to ours, but they do not handle dialectal variants or spelling variation. The"
W19-4214,D11-1057,0,0.0583525,"e been many approaches to address this problem, varying along a number of dimensions: the degree of language independence or specificity, the required amount of machine learning supervision, the degree of depth and richness of the morphological representations. Language agnostic unsupervised models There are many works using minimally supervised to unsupervised models of morphology for connecting morphologically related words and identifying optimal (and at times application dependent) segmentations (Smith and Eisner, 2005; Creutz and Lagus, 2005; Snyder and Barzilay, 2008; Poon et al., 2009; Dreyer and Eisner, 2011; Stallard et al., 2012; Sirts and Goldwater, 2013; Narasimhan et al., 2015; Sennrich et al., 2016; Eskander et al., 2016b; Ataman et al., 2017; Ataman and Federico, 2018; Eskander et al., 2018). In this paper, we compare to two popular language agnostic segmentation systems: MORFESSOR (Creutz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier efforts worked on rule-based approaches to mo"
W19-4214,W18-5806,1,0.84461,"007; Smrž, 2007; Boudchiche et al., 2017). Buckwalter (2004) is perhaps the most commonly used among them, as it contributed the representations for the Penn Arabic treebank (PATB) (Maamouri and Bies, 2004). The PATB has been the most used resource for supervised morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; AlGahtani and McNaught, 2015; Zalmout and Habash, 2017). Some efforts have used other annotated resources and/or large unannotated data sets (Lee et al., 2003; Abdelali et al., 2016; Freihat et al., 2018). More closely related to this paper, Erdmann and Habash (2018) demonstrated that delexicalized information provides a cheap means of inducing morphological knowledge and thereby predicting lexical information in MSA. They employ a de-lexicalized grammar which is similar to ours, but they do not handle dialectal variants or spelling variation. They also do not use the grammar for segmentation, but for pruning word embedding clusters in order to predict the paradigm membership of forms encountered in raw text. non-standard domains. Using a corpus of several Arabic dialects exhibiting rich and complex morphology, unstandardized spelling, and variation borde"
W19-4214,W15-3212,0,0.0220223,"s and statistics to build a shallow morphological analyzer. There are many MSA morphological analyzers with rich representations and good coverage that required very intensive efforts to create (Beesley, 1998; Buckwalter, 2004; Attia, 2006, 2007; Smrž, 2007; Boudchiche et al., 2017). Buckwalter (2004) is perhaps the most commonly used among them, as it contributed the representations for the Penn Arabic treebank (PATB) (Maamouri and Bies, 2004). The PATB has been the most used resource for supervised morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; AlGahtani and McNaught, 2015; Zalmout and Habash, 2017). Some efforts have used other annotated resources and/or large unannotated data sets (Lee et al., 2003; Abdelali et al., 2016; Freihat et al., 2018). More closely related to this paper, Erdmann and Habash (2018) demonstrated that delexicalized information provides a cheap means of inducing morphological knowledge and thereby predicting lexical information in MSA. They employ a de-lexicalized grammar which is similar to ours, but they do not handle dialectal variants or spelling variation. They also do not use the grammar for segmentation, but for pruning word embedd"
W19-4214,P18-2049,0,0.0170982,"learning supervision, the degree of depth and richness of the morphological representations. Language agnostic unsupervised models There are many works using minimally supervised to unsupervised models of morphology for connecting morphologically related words and identifying optimal (and at times application dependent) segmentations (Smith and Eisner, 2005; Creutz and Lagus, 2005; Snyder and Barzilay, 2008; Poon et al., 2009; Dreyer and Eisner, 2011; Stallard et al., 2012; Sirts and Goldwater, 2013; Narasimhan et al., 2015; Sennrich et al., 2016; Eskander et al., 2016b; Ataman et al., 2017; Ataman and Federico, 2018; Eskander et al., 2018). In this paper, we compare to two popular language agnostic segmentation systems: MORFESSOR (Creutz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier efforts worked on rule-based approaches to model dialectal morphology directly (Habash and Rambow, 2006; Habash et al., 2012), or exploiting existing MSA resources (Salloum and Habash, 2014). Later, a number of anno"
W19-4214,2006.bcs-1.5,0,0.0234228,"ke WALK, TALK, and SKIP. 113 Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 113–124 c Florence, Italy. August 2, 2019 2019 Association for Computational Linguistics on automatic shallow and deterministic segmentation for MSA. Darwish (2002) used limited resources and greedy techniques to automatically learn rules and statistics to build a shallow morphological analyzer. There are many MSA morphological analyzers with rich representations and good coverage that required very intensive efforts to create (Beesley, 1998; Buckwalter, 2004; Attia, 2006, 2007; Smrž, 2007; Boudchiche et al., 2017). Buckwalter (2004) is perhaps the most commonly used among them, as it contributed the representations for the Penn Arabic treebank (PATB) (Maamouri and Bies, 2004). The PATB has been the most used resource for supervised morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; AlGahtani and McNaught, 2015; Zalmout and Habash, 2017). Some efforts have used other annotated resources and/or large unannotated data sets (Lee et al., 2003; Abdelali et al., 2016; Freihat et al., 2018). More closely related to this pape"
W19-4214,W07-0809,0,0.062349,"Missing"
W19-4214,W98-1007,0,0.125184,"ngular present tense for verbs like WALK, TALK, and SKIP. 113 Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 113–124 c Florence, Italy. August 2, 2019 2019 Association for Computational Linguistics on automatic shallow and deterministic segmentation for MSA. Darwish (2002) used limited resources and greedy techniques to automatically learn rules and statistics to build a shallow morphological analyzer. There are many MSA morphological analyzers with rich representations and good coverage that required very intensive efforts to create (Beesley, 1998; Buckwalter, 2004; Attia, 2006, 2007; Smrž, 2007; Boudchiche et al., 2017). Buckwalter (2004) is perhaps the most commonly used among them, as it contributed the representations for the Penn Arabic treebank (PATB) (Maamouri and Bies, 2004). The PATB has been the most used resource for supervised morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; AlGahtani and McNaught, 2015; Zalmout and Habash, 2017). Some efforts have used other annotated resources and/or large unannotated data sets (Lee et al., 2003; Abdelali et al., 2016; Freihat et al., 2018). Mo"
W19-4214,K18-3001,0,0.0342528,"age. It separates all characters in the corpus, then performs a pre-determined number of join operations, merging all instances of specified bigrams. Joins are determined such that the resulting corpus will contain as few tokens as possible given the number of join operations allowed. Thus, while the algorithm is unsupervised and easy to apply to any language, it is linguistically naive, assuming that morphological organization is driven solely by enumerative efficiency concerns. Likely for this reason, BPE has not been demonstrated to be particularly useful for applications beyond neural MT (Kann et al., 2018). DE S EG Our model, described in Section 3, finds a compromise between the convenience of language agnostic unsupervised systems and the performance of systems leveraging language specific resources. DE S EG can be run with a minimum base length of either 2 or 3 characters and a priority of base fertility maximization (f ) over greedy base length minimization, or vice versa (g). Minimum base length and priority are represented as subscripts in all relevant tables. 4.2 Intrinsic Language Modeling Evaluation Table 3 shows the LM results for tokenizing COR PUS 6 where all trainable segmenters ar"
W19-4214,L18-1607,1,0.839039,"large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier efforts worked on rule-based approaches to model dialectal morphology directly (Habash and Rambow, 2006; Habash et al., 2012), or exploiting existing MSA resources (Salloum and Habash, 2014). Later, a number of annotation efforts have led to the creation of varying sizes of dialectal annotated corpora following the style of the PATB (Maamouri et al., 2014; Jarrar et al., 2016; Al-Shargi et al., 2016; Khalifa et al., 2018; Alshargi et al., 2019). The created annotations supported models for dialectal Arabic analysis, disambiguation and tokenization building on the same successful approaches in MSA (Eskander et al., 2016a; Habash et al., 2013; Pasha et al., 2014; Zalmout et al., 2018; Zalmout and Habash, 2019). More closely related to this paper, Eldesouki et al. (2017) used de-lexicalized analyStandard Arabic models Modern Standard Arabic (MSA) morphological analysis, disambiguation and tokenization has been the focus of a large number of efforts. Khoja and Garside (1999) was one of the earliest published effo"
W19-4214,W17-1305,1,0.812767,"as Sadat and Habash (2006) demonstrate it to be the most effective scheme for low resource Arabic MT. 2 While Arabic exhibits many other nonconcatenative, templatic phenomena which complicate segmentation and tokenization, clitics are always concatenated to the outsides of base forms after the templatic pattern has been applied and are thus easier to separate. Occasionally, fusional processes can alter phonemes/graphemes on either side of base–clitic or clitic–clitic boundaries, but no templatic process is ever invoked to alter the internal structure of bases by affixing any clitic. We follow Khalifa et al. (2017)’s approach to We use our grammar to build a de-lexicalized morphological analyzer for all DA dialects targeting the D3 segmentation scheme (Habash, 2010), which separates all clitics and only clitics from the base forms to which they attach. We chose D3 2 With more data, the more effective schemes are ATB and D2 (Sadat and Habash, 2006). ATB resembles D3 but does not separate the definite article proclitic. D2 resembles ATB but does not separate the pronominal enclitic. 116 extending paradigms with possible clitic combinations, though we don’t require any stem lexical information. Hence, we c"
W19-4214,P03-1051,0,0.145123,"rage that required very intensive efforts to create (Beesley, 1998; Buckwalter, 2004; Attia, 2006, 2007; Smrž, 2007; Boudchiche et al., 2017). Buckwalter (2004) is perhaps the most commonly used among them, as it contributed the representations for the Penn Arabic treebank (PATB) (Maamouri and Bies, 2004). The PATB has been the most used resource for supervised morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; AlGahtani and McNaught, 2015; Zalmout and Habash, 2017). Some efforts have used other annotated resources and/or large unannotated data sets (Lee et al., 2003; Abdelali et al., 2016; Freihat et al., 2018). More closely related to this paper, Erdmann and Habash (2018) demonstrated that delexicalized information provides a cheap means of inducing morphological knowledge and thereby predicting lexical information in MSA. They employ a de-lexicalized grammar which is similar to ours, but they do not handle dialectal variants or spelling variation. They also do not use the grammar for segmentation, but for pruning word embedding clusters in order to predict the paradigm membership of forms encountered in raw text. non-standard domains. Using a corpus of"
W19-4214,W04-1602,0,0.260333,"r Computational Linguistics on automatic shallow and deterministic segmentation for MSA. Darwish (2002) used limited resources and greedy techniques to automatically learn rules and statistics to build a shallow morphological analyzer. There are many MSA morphological analyzers with rich representations and good coverage that required very intensive efforts to create (Beesley, 1998; Buckwalter, 2004; Attia, 2006, 2007; Smrž, 2007; Boudchiche et al., 2017). Buckwalter (2004) is perhaps the most commonly used among them, as it contributed the representations for the Penn Arabic treebank (PATB) (Maamouri and Bies, 2004). The PATB has been the most used resource for supervised morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; AlGahtani and McNaught, 2015; Zalmout and Habash, 2017). Some efforts have used other annotated resources and/or large unannotated data sets (Lee et al., 2003; Abdelali et al., 2016; Freihat et al., 2018). More closely related to this paper, Erdmann and Habash (2018) demonstrated that delexicalized information provides a cheap means of inducing morphological knowledge and thereby predicting lexical information in MSA. They employ a de-lexicaliz"
W19-4214,C16-1326,1,0.824911,"r specificity, the required amount of machine learning supervision, the degree of depth and richness of the morphological representations. Language agnostic unsupervised models There are many works using minimally supervised to unsupervised models of morphology for connecting morphologically related words and identifying optimal (and at times application dependent) segmentations (Smith and Eisner, 2005; Creutz and Lagus, 2005; Snyder and Barzilay, 2008; Poon et al., 2009; Dreyer and Eisner, 2011; Stallard et al., 2012; Sirts and Goldwater, 2013; Narasimhan et al., 2015; Sennrich et al., 2016; Eskander et al., 2016b; Ataman et al., 2017; Ataman and Federico, 2018; Eskander et al., 2018). In this paper, we compare to two popular language agnostic segmentation systems: MORFESSOR (Creutz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier efforts worked on rule-based approaches to model dialectal morphology directly (Habash and Rambow, 2006; Habash et al., 2012), or exploiting existing MSA resources (S"
W19-4214,W18-5808,0,0.0183242,"degree of depth and richness of the morphological representations. Language agnostic unsupervised models There are many works using minimally supervised to unsupervised models of morphology for connecting morphologically related words and identifying optimal (and at times application dependent) segmentations (Smith and Eisner, 2005; Creutz and Lagus, 2005; Snyder and Barzilay, 2008; Poon et al., 2009; Dreyer and Eisner, 2011; Stallard et al., 2012; Sirts and Goldwater, 2013; Narasimhan et al., 2015; Sennrich et al., 2016; Eskander et al., 2016b; Ataman et al., 2017; Ataman and Federico, 2018; Eskander et al., 2018). In this paper, we compare to two popular language agnostic segmentation systems: MORFESSOR (Creutz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier efforts worked on rule-based approaches to model dialectal morphology directly (Habash and Rambow, 2006; Habash et al., 2012), or exploiting existing MSA resources (Salloum and Habash, 2014). Later, a number of annotation efforts have led"
W19-4214,C16-1086,0,0.014934,"r specificity, the required amount of machine learning supervision, the degree of depth and richness of the morphological representations. Language agnostic unsupervised models There are many works using minimally supervised to unsupervised models of morphology for connecting morphologically related words and identifying optimal (and at times application dependent) segmentations (Smith and Eisner, 2005; Creutz and Lagus, 2005; Snyder and Barzilay, 2008; Poon et al., 2009; Dreyer and Eisner, 2011; Stallard et al., 2012; Sirts and Goldwater, 2013; Narasimhan et al., 2015; Sennrich et al., 2016; Eskander et al., 2016b; Ataman et al., 2017; Ataman and Federico, 2018; Eskander et al., 2018). In this paper, we compare to two popular language agnostic segmentation systems: MORFESSOR (Creutz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier efforts worked on rule-based approaches to model dialectal morphology directly (Habash and Rambow, 2006; Habash et al., 2012), or exploiting existing MSA resources (S"
W19-4214,E17-2045,0,0.014182,"gual corpus with all dialects pooled and the MT system on all the dialects pooled. Individual–individual trains six segmenters on relevant subsections of the monolingual data and six MT systems on the relevant partitions of CORPUS 6. Individual–pooled trains individual segmenters but one pan-Arabic MT system, which is reasonable to reduce the over generation of the morphological model but leverage shared information during MT. Neural MT has been used with dialects (Hassan et al., 2017), but given the extreme scarcity of in-domain data, statistical MT (Koehn et al., 2007) is the better choice (Farajian et al., 2017) for comparing quality of segmentation in our setting. DE S EG consistently outperforms unsupervised alternatives BPE and MORFESSOR in Table 4 while approaching and even beating state-of-the-art systems FARASA and MADAMIRA in the individual–pooled environment. The Fertility-based model DE S EGf 2 outperforms its greedy counterpart, supporting the argument that base fertility plays a meaningful role in morphological organization. 5 The best DA performance is achieved on Beirut for the pooled mode and Doha for the Individual. Beirut is the least verbose of all dialects in unsegmented space, and"
W19-4214,J97-4004,0,0.768968,"iding evidence for the value of linguistic input during preprocessing. 1 Introduction Non-standard domains, dialectal variation, and unstandardized spelling make segmentation challenging, though morphologically rich languages require good segmentation to enable downstream applications from syntactic parsing to machine translation (MT). For domains lacking sufficient annotated data to train segmenters, one must resort to language specific greedy techniques or language agnostic unsupervised techniques. Greedy techniques use maximum matching to identify base words, leveraging large dictionaries (Guo, 1997). Yet such dictionaries are often unavailable or too expensive for low resource languages. Language agnostic unsupervised options like MOR FESSOR (Creutz and Lagus, 2005) and byte pair encoding (BPE) (Sennrich et al., 2016) assume no 1 Exponents refer to recurring means by which morphosyntactic properties are realized within classes of words, e.g., adding suffix +s to get the third person singular present tense for verbs like WALK, TALK, and SKIP. 113 Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 113–124 c Florence, Italy. August 2, 2"
W19-4214,W12-2301,1,0.854086,"an et al., 2015; Sennrich et al., 2016; Eskander et al., 2016b; Ataman et al., 2017; Ataman and Federico, 2018; Eskander et al., 2018). In this paper, we compare to two popular language agnostic segmentation systems: MORFESSOR (Creutz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier efforts worked on rule-based approaches to model dialectal morphology directly (Habash and Rambow, 2006; Habash et al., 2012), or exploiting existing MSA resources (Salloum and Habash, 2014). Later, a number of annotation efforts have led to the creation of varying sizes of dialectal annotated corpora following the style of the PATB (Maamouri et al., 2014; Jarrar et al., 2016; Al-Shargi et al., 2016; Khalifa et al., 2018; Alshargi et al., 2019). The created annotations supported models for dialectal Arabic analysis, disambiguation and tokenization building on the same successful approaches in MSA (Eskander et al., 2016a; Habash et al., 2013; Pasha et al., 2014; Zalmout et al., 2018; Zalmout and Habash, 2019). More c"
W19-4214,P05-1071,1,0.57381,"greedy techniques to automatically learn rules and statistics to build a shallow morphological analyzer. There are many MSA morphological analyzers with rich representations and good coverage that required very intensive efforts to create (Beesley, 1998; Buckwalter, 2004; Attia, 2006, 2007; Smrž, 2007; Boudchiche et al., 2017). Buckwalter (2004) is perhaps the most commonly used among them, as it contributed the representations for the Penn Arabic treebank (PATB) (Maamouri and Bies, 2004). The PATB has been the most used resource for supervised morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; AlGahtani and McNaught, 2015; Zalmout and Habash, 2017). Some efforts have used other annotated resources and/or large unannotated data sets (Lee et al., 2003; Abdelali et al., 2016; Freihat et al., 2018). More closely related to this paper, Erdmann and Habash (2018) demonstrated that delexicalized information provides a cheap means of inducing morphological knowledge and thereby predicting lexical information in MSA. They employ a de-lexicalized grammar which is similar to ours, but they do not handle dialectal variants or spelling variation. They also do not use the gra"
W19-4214,P06-1086,1,0.835068,"Goldwater, 2013; Narasimhan et al., 2015; Sennrich et al., 2016; Eskander et al., 2016b; Ataman et al., 2017; Ataman and Federico, 2018; Eskander et al., 2018). In this paper, we compare to two popular language agnostic segmentation systems: MORFESSOR (Creutz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier efforts worked on rule-based approaches to model dialectal morphology directly (Habash and Rambow, 2006; Habash et al., 2012), or exploiting existing MSA resources (Salloum and Habash, 2014). Later, a number of annotation efforts have led to the creation of varying sizes of dialectal annotated corpora following the style of the PATB (Maamouri et al., 2014; Jarrar et al., 2016; Al-Shargi et al., 2016; Khalifa et al., 2018; Alshargi et al., 2019). The created annotations supported models for dialectal Arabic analysis, disambiguation and tokenization building on the same successful approaches in MSA (Eskander et al., 2016a; Habash et al., 2013; Pasha et al., 2014; Zalmout et al., 2018; Zalmout and"
W19-4214,Q13-1021,0,0.0257759,"varying along a number of dimensions: the degree of language independence or specificity, the required amount of machine learning supervision, the degree of depth and richness of the morphological representations. Language agnostic unsupervised models There are many works using minimally supervised to unsupervised models of morphology for connecting morphologically related words and identifying optimal (and at times application dependent) segmentations (Smith and Eisner, 2005; Creutz and Lagus, 2005; Snyder and Barzilay, 2008; Poon et al., 2009; Dreyer and Eisner, 2011; Stallard et al., 2012; Sirts and Goldwater, 2013; Narasimhan et al., 2015; Sennrich et al., 2016; Eskander et al., 2016b; Ataman et al., 2017; Ataman and Federico, 2018; Eskander et al., 2018). In this paper, we compare to two popular language agnostic segmentation systems: MORFESSOR (Creutz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier efforts worked on rule-based approaches to model dialectal morphology directly (Habash and Ramb"
W19-4214,maamouri-etal-2014-developing,1,0.855905,"utz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier efforts worked on rule-based approaches to model dialectal morphology directly (Habash and Rambow, 2006; Habash et al., 2012), or exploiting existing MSA resources (Salloum and Habash, 2014). Later, a number of annotation efforts have led to the creation of varying sizes of dialectal annotated corpora following the style of the PATB (Maamouri et al., 2014; Jarrar et al., 2016; Al-Shargi et al., 2016; Khalifa et al., 2018; Alshargi et al., 2019). The created annotations supported models for dialectal Arabic analysis, disambiguation and tokenization building on the same successful approaches in MSA (Eskander et al., 2016a; Habash et al., 2013; Pasha et al., 2014; Zalmout et al., 2018; Zalmout and Habash, 2019). More closely related to this paper, Eldesouki et al. (2017) used de-lexicalized analyStandard Arabic models Modern Standard Arabic (MSA) morphological analysis, disambiguation and tokenization has been the focus of a large number of effor"
W19-4214,Q15-1012,0,0.120812,"imensions: the degree of language independence or specificity, the required amount of machine learning supervision, the degree of depth and richness of the morphological representations. Language agnostic unsupervised models There are many works using minimally supervised to unsupervised models of morphology for connecting morphologically related words and identifying optimal (and at times application dependent) segmentations (Smith and Eisner, 2005; Creutz and Lagus, 2005; Snyder and Barzilay, 2008; Poon et al., 2009; Dreyer and Eisner, 2011; Stallard et al., 2012; Sirts and Goldwater, 2013; Narasimhan et al., 2015; Sennrich et al., 2016; Eskander et al., 2016b; Ataman et al., 2017; Ataman and Federico, 2018; Eskander et al., 2018). In this paper, we compare to two popular language agnostic segmentation systems: MORFESSOR (Creutz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier efforts worked on rule-based approaches to model dialectal morphology directly (Habash and Rambow, 2006; Habash et al.,"
W19-4214,pasha-etal-2014-madamira,1,0.898429,"Missing"
W19-4214,N09-1024,0,0.0403568,"domains. There have been many approaches to address this problem, varying along a number of dimensions: the degree of language independence or specificity, the required amount of machine learning supervision, the degree of depth and richness of the morphological representations. Language agnostic unsupervised models There are many works using minimally supervised to unsupervised models of morphology for connecting morphologically related words and identifying optimal (and at times application dependent) segmentations (Smith and Eisner, 2005; Creutz and Lagus, 2005; Snyder and Barzilay, 2008; Poon et al., 2009; Dreyer and Eisner, 2011; Stallard et al., 2012; Sirts and Goldwater, 2013; Narasimhan et al., 2015; Sennrich et al., 2016; Eskander et al., 2016b; Ataman et al., 2017; Ataman and Federico, 2018; Eskander et al., 2018). In this paper, we compare to two popular language agnostic segmentation systems: MORFESSOR (Creutz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier efforts worked on ru"
W19-4214,P06-1001,1,0.710713,"of some minimum length can be an open class base, provided the remaining characters comprise a supported affix pattern. Hence, a simple grammar which only supports words without affixes or with a single suffix, +s, would return two analyses for wugs: wugs and wug +s, and one for foo: foo. To build such a grammar for an Arabic dialect, we target clitic affixation, as this phenomenon is nontemplatic with minimal fusional edits, making it easier to model with a smaller grammar, yet it accounts for a great deal of sparsity, as Arabic clitics are as productive as regular inflectional exponents. as Sadat and Habash (2006) demonstrate it to be the most effective scheme for low resource Arabic MT. 2 While Arabic exhibits many other nonconcatenative, templatic phenomena which complicate segmentation and tokenization, clitics are always concatenated to the outsides of base forms after the templatic pattern has been applied and are thus easier to separate. Occasionally, fusional processes can alter phonemes/graphemes on either side of base–clitic or clitic–clitic boundaries, but no templatic process is ever invoked to alter the internal structure of bases by affixing any clitic. We follow Khalifa et al. (2017)’s ap"
W19-4214,C18-1113,1,0.829968,"ard domain, but have limited support for multiple colloquial variants of the language. Finally, we note that, linguistically, our work is inspired by Bertram et al. (2000) who find that prolific stems with large derivational families are accessed more quickly. Their work suggests that stem fertility—or the productivity with which a stem can combine with different affixes—is cognitively relevant to morphological organization. 3 To demonstrate how our model handles such challenging phenomena, we apply it to the CORPUS 6 subset of the MADAR-BTEC (Takezawa et al., 2002) corpus of Arabic dialects (Salameh et al., 2018). This consists of 12,000 sentences in the travel domain (9,000 for training) parallel between English, MSA, and the DA varieties spoken in Beirut, Cairo, Doha, Rabat, and Tunis. This comprises a representative sample of the breadth of intra-DA variation (Bouamor et al., 2018). In addition to CORPUS 6, we also use large amounts of raw monolingual data to train our segmenter and the unsupervised baselines. To avoid introducing even more noise, we restrict our monolingual datasets as much as possible to similar domains. For DA, we use the four subsets of Almeman and Lee (2013)’s web crawl of for"
W19-4214,K17-1043,0,0.135443,"ated to this paper, Eldesouki et al. (2017) used de-lexicalized analyStandard Arabic models Modern Standard Arabic (MSA) morphological analysis, disambiguation and tokenization has been the focus of a large number of efforts. Khoja and Garside (1999) was one of the earliest published efforts 114 3.2 sis strategy for four colloquial varieties of Arabic, though they also use minimal training data and extract features from an open class lexicon to learn either an SVM or bi-LSTM-CRF disambiguation model. They further show that domain adaptation from existing MSA training data is beneficial. Also, Samih et al. (2017) applied a related model to segmentation, allowing different Arabic dialects to inform one another, thus avoiding the need to perform dialect identification during preprocessing. We compare our model to MADAMIRA (Pasha et al., 2014) and FARASA (Abdelali et al., 2016), which represent the fully supervised state of the art for segmenting Arabic in the standard domain, but have limited support for multiple colloquial variants of the language. Finally, we note that, linguistically, our work is inspired by Bertram et al. (2000) who find that prolific stems with large derivational families are acces"
W19-4214,P16-1162,0,0.489551,"rich languages require good segmentation to enable downstream applications from syntactic parsing to machine translation (MT). For domains lacking sufficient annotated data to train segmenters, one must resort to language specific greedy techniques or language agnostic unsupervised techniques. Greedy techniques use maximum matching to identify base words, leveraging large dictionaries (Guo, 1997). Yet such dictionaries are often unavailable or too expensive for low resource languages. Language agnostic unsupervised options like MOR FESSOR (Creutz and Lagus, 2005) and byte pair encoding (BPE) (Sennrich et al., 2016) assume no 1 Exponents refer to recurring means by which morphosyntactic properties are realized within classes of words, e.g., adding suffix +s to get the third person singular present tense for verbs like WALK, TALK, and SKIP. 113 Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 113–124 c Florence, Italy. August 2, 2019 2019 Association for Computational Linguistics on automatic shallow and deterministic segmentation for MSA. Darwish (2002) used limited resources and greedy techniques to automatically learn rules and statistics to buil"
W19-4214,P05-1044,0,0.0605835,"resourced languages often lack such resources for non-standard dialects and domains. There have been many approaches to address this problem, varying along a number of dimensions: the degree of language independence or specificity, the required amount of machine learning supervision, the degree of depth and richness of the morphological representations. Language agnostic unsupervised models There are many works using minimally supervised to unsupervised models of morphology for connecting morphologically related words and identifying optimal (and at times application dependent) segmentations (Smith and Eisner, 2005; Creutz and Lagus, 2005; Snyder and Barzilay, 2008; Poon et al., 2009; Dreyer and Eisner, 2011; Stallard et al., 2012; Sirts and Goldwater, 2013; Narasimhan et al., 2015; Sennrich et al., 2016; Eskander et al., 2016b; Ataman et al., 2017; Ataman and Federico, 2018; Eskander et al., 2018). In this paper, we compare to two popular language agnostic segmentation systems: MORFESSOR (Creutz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relat"
W19-4214,P08-1084,0,0.0300749,"r non-standard dialects and domains. There have been many approaches to address this problem, varying along a number of dimensions: the degree of language independence or specificity, the required amount of machine learning supervision, the degree of depth and richness of the morphological representations. Language agnostic unsupervised models There are many works using minimally supervised to unsupervised models of morphology for connecting morphologically related words and identifying optimal (and at times application dependent) segmentations (Smith and Eisner, 2005; Creutz and Lagus, 2005; Snyder and Barzilay, 2008; Poon et al., 2009; Dreyer and Eisner, 2011; Stallard et al., 2012; Sirts and Goldwater, 2013; Narasimhan et al., 2015; Sennrich et al., 2016; Eskander et al., 2016b; Ataman et al., 2017; Ataman and Federico, 2018; Eskander et al., 2018). In this paper, we compare to two popular language agnostic segmentation systems: MORFESSOR (Creutz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier e"
W19-4214,P12-2063,0,0.0260065,"address this problem, varying along a number of dimensions: the degree of language independence or specificity, the required amount of machine learning supervision, the degree of depth and richness of the morphological representations. Language agnostic unsupervised models There are many works using minimally supervised to unsupervised models of morphology for connecting morphologically related words and identifying optimal (and at times application dependent) segmentations (Smith and Eisner, 2005; Creutz and Lagus, 2005; Snyder and Barzilay, 2008; Poon et al., 2009; Dreyer and Eisner, 2011; Stallard et al., 2012; Sirts and Goldwater, 2013; Narasimhan et al., 2015; Sennrich et al., 2016; Eskander et al., 2016b; Ataman et al., 2017; Ataman and Federico, 2018; Eskander et al., 2018). In this paper, we compare to two popular language agnostic segmentation systems: MORFESSOR (Creutz and Lagus, 2005) and BPE (Sennrich et al., 2016). Both train on large corpora of unannotated text in an unsupervised manner. Dialectal Arabic models Work on dialectal Arabic morphology and tokenization is relatively newer than work on MSA. Some of the earlier efforts worked on rule-based approaches to model dialectal morpholog"
W19-4214,takezawa-etal-2002-toward,0,0.125582,"tate of the art for segmenting Arabic in the standard domain, but have limited support for multiple colloquial variants of the language. Finally, we note that, linguistically, our work is inspired by Bertram et al. (2000) who find that prolific stems with large derivational families are accessed more quickly. Their work suggests that stem fertility—or the productivity with which a stem can combine with different affixes—is cognitively relevant to morphological organization. 3 To demonstrate how our model handles such challenging phenomena, we apply it to the CORPUS 6 subset of the MADAR-BTEC (Takezawa et al., 2002) corpus of Arabic dialects (Salameh et al., 2018). This consists of 12,000 sentences in the travel domain (9,000 for training) parallel between English, MSA, and the DA varieties spoken in Beirut, Cairo, Doha, Rabat, and Tunis. This comprises a representative sample of the breadth of intra-DA variation (Bouamor et al., 2018). In addition to CORPUS 6, we also use large amounts of raw monolingual data to train our segmenter and the unsupervised baselines. To avoid introducing even more noise, we restrict our monolingual datasets as much as possible to similar domains. For DA, we use the four sub"
W19-4214,P17-1184,0,0.0449813,"Missing"
W19-4214,N18-1087,1,0.845553,"directly (Habash and Rambow, 2006; Habash et al., 2012), or exploiting existing MSA resources (Salloum and Habash, 2014). Later, a number of annotation efforts have led to the creation of varying sizes of dialectal annotated corpora following the style of the PATB (Maamouri et al., 2014; Jarrar et al., 2016; Al-Shargi et al., 2016; Khalifa et al., 2018; Alshargi et al., 2019). The created annotations supported models for dialectal Arabic analysis, disambiguation and tokenization building on the same successful approaches in MSA (Eskander et al., 2016a; Habash et al., 2013; Pasha et al., 2014; Zalmout et al., 2018; Zalmout and Habash, 2019). More closely related to this paper, Eldesouki et al. (2017) used de-lexicalized analyStandard Arabic models Modern Standard Arabic (MSA) morphological analysis, disambiguation and tokenization has been the focus of a large number of efforts. Khoja and Garside (1999) was one of the earliest published efforts 114 3.2 sis strategy for four colloquial varieties of Arabic, though they also use minimal training data and extract features from an open class lexicon to learn either an SVM or bi-LSTM-CRF disambiguation model. They further show that domain adaptation from exi"
W19-4214,D17-1073,1,0.788504,"allow morphological analyzer. There are many MSA morphological analyzers with rich representations and good coverage that required very intensive efforts to create (Beesley, 1998; Buckwalter, 2004; Attia, 2006, 2007; Smrž, 2007; Boudchiche et al., 2017). Buckwalter (2004) is perhaps the most commonly used among them, as it contributed the representations for the Penn Arabic treebank (PATB) (Maamouri and Bies, 2004). The PATB has been the most used resource for supervised morphological disambiguation (Diab et al., 2004; Habash and Rambow, 2005; Pasha et al., 2014; AlGahtani and McNaught, 2015; Zalmout and Habash, 2017). Some efforts have used other annotated resources and/or large unannotated data sets (Lee et al., 2003; Abdelali et al., 2016; Freihat et al., 2018). More closely related to this paper, Erdmann and Habash (2018) demonstrated that delexicalized information provides a cheap means of inducing morphological knowledge and thereby predicting lexical information in MSA. They employ a de-lexicalized grammar which is similar to ours, but they do not handle dialectal variants or spelling variation. They also do not use the grammar for segmentation, but for pruning word embedding clusters in order to pr"
W19-4214,P19-1173,1,0.834397,"ambow, 2006; Habash et al., 2012), or exploiting existing MSA resources (Salloum and Habash, 2014). Later, a number of annotation efforts have led to the creation of varying sizes of dialectal annotated corpora following the style of the PATB (Maamouri et al., 2014; Jarrar et al., 2016; Al-Shargi et al., 2016; Khalifa et al., 2018; Alshargi et al., 2019). The created annotations supported models for dialectal Arabic analysis, disambiguation and tokenization building on the same successful approaches in MSA (Eskander et al., 2016a; Habash et al., 2013; Pasha et al., 2014; Zalmout et al., 2018; Zalmout and Habash, 2019). More closely related to this paper, Eldesouki et al. (2017) used de-lexicalized analyStandard Arabic models Modern Standard Arabic (MSA) morphological analysis, disambiguation and tokenization has been the focus of a large number of efforts. Khoja and Garside (1999) was one of the earliest published efforts 114 3.2 sis strategy for four colloquial varieties of Arabic, though they also use minimal training data and extract features from an open class lexicon to learn either an SVM or bi-LSTM-CRF disambiguation model. They further show that domain adaptation from existing MSA training data is"
W19-4615,P11-2062,1,0.808984,"is a DIWAN file which includes the correct annotation for the entire corpus. In the last step, we automatically reformat the annotations into a format which is best suited for computational purposes; we perform a third round of error checking for format errors, which we fix automatically. Figure 1 shows these steps. • The morphemes of the word (prefixes, stem, suffixes) and their part-of-speech (POS). The stem is marked by the symbol # on either side. • The English gloss of the word. • Features indicating proclitics and enclitics. • Features indicating word POS, functional number and gender (Alkuhlani and Habash, 2011), and aspect. The annotation for one sentence in different dialects is shown in Table 2. This is not actually a sentence from our corpora, of course; we have chosen it to illustrate the annotation. Error Correction Linguistic annotation is carried out manually. In order to guarantee high levels of accuracy and precision, we performed extensive error checking and correction. After annotating the seven different corpora, the annotated words were compiled in the form of linguistic codes in either one file or separate files to be Morphological Features Annotated The DIWAN interface assists human a"
W19-4615,L16-1207,1,0.241992,"Arabic Treebank (Maamouri et al., 2014), Curras, the Pales1 The abbreviations we use intend to capture the country name and the city or region name when applicable. 2 http://www.semarch.uni-hd.de 137 Proceedings of the Fourth Arabic Natural Language Processing Workshop, pages 137–147 c Florence, Italy, August 1, 2019. 2019 Association for Computational Linguistics tinian Arabic annotated corpus (Jarrar et al., 2014), the Gulf Arabic Annotated corpus (Khalifa et al., 2018), Syrian, Jordanian dialectal corpora (Bouamor et al., 2014; Harrat et al., 2014), a small effort on Sanaani and Moroccan (AlShargi et al., 2016) (which this paper builds on), and SUAR (Al-Twairesh et al., 2018), a morphologically annotated corpus for Najdi and Hijazi which is semiautomatically annotated using the MADAMIRA tool (Pasha et al., 2014) and subsequently manually checked. Additionally, Voss et al. (2014) present a corpus of Moroccan dialect which has been annotated for language variety (code switching). Several of these efforts have followed the approach of Curras (Jarrar et al., 2014), which consists of around 70,000 words of a balanced genre corpus. The corpus was manually annotated using the DIWAN tool (Alshargi and Rambo"
W19-4615,W15-3206,1,0.826677,"Missing"
W19-4615,bouamor-etal-2014-multidialectal,1,0.820756,"ntine Arabic Treebank (specifically Jordanian) (Maamouri et al., 2006), the Egyptian Arabic Treebank (Maamouri et al., 2014), Curras, the Pales1 The abbreviations we use intend to capture the country name and the city or region name when applicable. 2 http://www.semarch.uni-hd.de 137 Proceedings of the Fourth Arabic Natural Language Processing Workshop, pages 137–147 c Florence, Italy, August 1, 2019. 2019 Association for Computational Linguistics tinian Arabic annotated corpus (Jarrar et al., 2014), the Gulf Arabic Annotated corpus (Khalifa et al., 2018), Syrian, Jordanian dialectal corpora (Bouamor et al., 2014; Harrat et al., 2014), a small effort on Sanaani and Moroccan (AlShargi et al., 2016) (which this paper builds on), and SUAR (Al-Twairesh et al., 2018), a morphologically annotated corpus for Najdi and Hijazi which is semiautomatically annotated using the MADAMIRA tool (Pasha et al., 2014) and subsequently manually checked. Additionally, Voss et al. (2014) present a corpus of Moroccan dialect which has been annotated for language variety (code switching). Several of these efforts have followed the approach of Curras (Jarrar et al., 2014), which consists of around 70,000 words of a balanced ge"
W19-4615,I13-1048,0,0.0212546,"nnotate corpora in context is a central step in developing morphological analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). However, other notable approaches and efforts that do not use annotated corpora have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multidialectal dictionary Tharwa (Diab et al., 2014), or extending MSA analyzers and resources (Salloum and Habash, 2014; Harrat et al., 2014; Boujelbane et al., 2013). Dialectal Variations Differences among the dialects are found on all levels of linguistic description, i.e., phonology, morphology, syntax, and the lexicon. We summarize three phonological and three morphological salient examples in Table 1 for our dialects: the pronunciation of MSA /q/ written  q,3 MSA /Ã/ written h. j and MSA /k/ written  k; and the various forms of the future, progressive and possessive particles. From a lexical point of view, there are many words that have different meanings across dialects. For example, the word úæ AÓ mA$y /ma:Si/ is ‘no’ in YE.SN and MA.RB, ‘yes/ok"
W19-4615,E06-1047,1,0.654672,"ialects and MSA Arabic dialects share many commonalities with Classical Arabic and Modern Standard Arabic (MSA). All variants of Arabic are morphologically complex as they include rich inflectional and derivational morphology that is expressed in two ways: namely, via templates and affixes. Furthermore, they contain several classes of attachable clitics. However, the dialects as a class differ in consistent ways from MSA, and they differ amongst each other. In fact, the differences between MSA and Dialectal Arabic (DA) have often been compared to those between Latin and the Romance languages (Chiang et al., 2006). The principal morpho-syntactic difference between DA and MSA is the loss of productive case marking, and nunation (tanween) on nouns, and mood on imperfective verbs. Linguistic Studies There are many theoretical and descriptive linguistic studies for the dialects we work on: Yemeni dialects (Watson, 1993, 2002), Najdi (Ingham, 1994), Gulf Arabic dialect (Holes, 1990), Jordanian (Bani-Yasin and Owens, 1987), Moroccan (Harrell, 1962), Syrian (Cowell, 1964), and Iraqi (Erwin, 1963); not to mentions comparative studies across dialects and MSA (Holes, 2004; Brustad, 2000). We make extensive use o"
W19-4615,D13-1105,1,0.876469,"as (Jarrar et al., 2014), which consists of around 70,000 words of a balanced genre corpus. The corpus was manually annotated using the DIWAN tool (Alshargi and Rambow, 2015), which we also use. The annotation in Curras is done by first using a morphological tagger for another Arabic dialect, namely MADAMIRA Egyptian (Pasha et al., 2014), to produce a base that was then corrected or accepted by a trained annotator. 3 Dialects: Linguistic Facts Other NLP Resources for Dialectal Arabic The effort to annotate corpora in context is a central step in developing morphological analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). However, other notable approaches and efforts that do not use annotated corpora have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multidialectal dictionary Tharwa (Diab et al., 2014), or extending MSA analyzers and resources (Salloum and Habash, 2014; Harrat et al., 2014; Boujelbane et al., 2013). Dialectal Variations Differences among the dialects are found on all levels of linguistic d"
W19-4615,W14-3603,1,0.962757,"he corpora used and some interesting facts specific to each dialect. Section 5 then presents our annotation methodology. We then briefly discuss morphological analyzers, and conclude. Introduction 2 As Arabic dialects (DA) become more widely written in social media, there is increased interest in the Arabic NLP community to have annotated corpora that will allow us to both study the dialects linguistically, and to create systems that can automatically process dialectal text. There have been important efforts to create relatively large corpora for Egyptian (Maamouri et al., 2014), Palestinian (Jarrar et al., 2014), and Emirati Arabic (Khalifa et al., 2018). While these resources are very helpful for single dialects, the problem is that there are many dialects, and in fact it is often unclear what to count as separate dialects (for example, the subdialects of Levantine). Therefore, we present a different approach in this paper: we annotate seven dialects, but with relatively smaller corpora (most around 30,000 words). Some of the dialects are closely related (Jordanian and Syrian), others are more distant (Moroccan). We use the same annotation methodology for all dialects: same guidelines, same processi"
W19-4615,C16-1326,1,0.865727,"Missing"
W19-4615,L16-1679,1,0.838055,"st around 30,000 words). Some of the dialects are closely related (Jordanian and Syrian), others are more distant (Moroccan). We use the same annotation methodology for all dialects: same guidelines, same processing steps, and same annotation file format. This makes our effort an Related Work Data Collections There have been several data collections centered on Arabic dialects, specifically spoken Arabic. A very useful resource is the Semitisches Tonarchiv at the University of Heidelberg in Germany.2 We have included two Yemeni transcriptions from this resource in our YE.TZ and YE.SN corpora. Khalifa et al. (2016) is a large collection of over 100M words of a number of Arabic dialect, although the majority is from the Gulf. Bouamor et al. (2018) created a large corpus with parallel data text from 25 Arab cities. Further data collections include (Al-Amri, 2000) which has not yet been digitized for use in NLP research. Annotated Corpora There are few annotated corpora for dialectal Arabic: the Levantine Arabic Treebank (specifically Jordanian) (Maamouri et al., 2006), the Egyptian Arabic Treebank (Maamouri et al., 2014), Curras, the Pales1 The abbreviations we use intend to capture the country name and t"
W19-4615,habash-etal-2012-conventional,1,0.903506,"gical tagger for another Arabic dialect, namely MADAMIRA Egyptian (Pasha et al., 2014), to produce a base that was then corrected or accepted by a trained annotator. 3 Dialects: Linguistic Facts Other NLP Resources for Dialectal Arabic The effort to annotate corpora in context is a central step in developing morphological analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). However, other notable approaches and efforts that do not use annotated corpora have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multidialectal dictionary Tharwa (Diab et al., 2014), or extending MSA analyzers and resources (Salloum and Habash, 2014; Harrat et al., 2014; Boujelbane et al., 2013). Dialectal Variations Differences among the dialects are found on all levels of linguistic description, i.e., phonology, morphology, syntax, and the lexicon. We summarize three phonological and three morphological salient examples in Table 1 for our dialects: the pronunciation of MSA /q/ written  q,3 MSA /Ã/ written h. j and MSA /k/ writte"
W19-4615,L18-1607,1,0.947802,"specific to each dialect. Section 5 then presents our annotation methodology. We then briefly discuss morphological analyzers, and conclude. Introduction 2 As Arabic dialects (DA) become more widely written in social media, there is increased interest in the Arabic NLP community to have annotated corpora that will allow us to both study the dialects linguistically, and to create systems that can automatically process dialectal text. There have been important efforts to create relatively large corpora for Egyptian (Maamouri et al., 2014), Palestinian (Jarrar et al., 2014), and Emirati Arabic (Khalifa et al., 2018). While these resources are very helpful for single dialects, the problem is that there are many dialects, and in fact it is often unclear what to count as separate dialects (for example, the subdialects of Levantine). Therefore, we present a different approach in this paper: we annotate seven dialects, but with relatively smaller corpora (most around 30,000 words). Some of the dialects are closely related (Jordanian and Syrian), others are more distant (Moroccan). We use the same annotation methodology for all dialects: same guidelines, same processing steps, and same annotation file format."
W19-4615,W12-2301,1,0.938969,"gical tagger for another Arabic dialect, namely MADAMIRA Egyptian (Pasha et al., 2014), to produce a base that was then corrected or accepted by a trained annotator. 3 Dialects: Linguistic Facts Other NLP Resources for Dialectal Arabic The effort to annotate corpora in context is a central step in developing morphological analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). However, other notable approaches and efforts that do not use annotated corpora have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multidialectal dictionary Tharwa (Diab et al., 2014), or extending MSA analyzers and resources (Salloum and Habash, 2014; Harrat et al., 2014; Boujelbane et al., 2013). Dialectal Variations Differences among the dialects are found on all levels of linguistic description, i.e., phonology, morphology, syntax, and the lexicon. We summarize three phonological and three morphological salient examples in Table 1 for our dialects: the pronunciation of MSA /q/ written  q,3 MSA /Ã/ written h. j and MSA /k/ writte"
W19-4615,maamouri-etal-2006-developing,1,0.692422,"v at the University of Heidelberg in Germany.2 We have included two Yemeni transcriptions from this resource in our YE.TZ and YE.SN corpora. Khalifa et al. (2016) is a large collection of over 100M words of a number of Arabic dialect, although the majority is from the Gulf. Bouamor et al. (2018) created a large corpus with parallel data text from 25 Arab cities. Further data collections include (Al-Amri, 2000) which has not yet been digitized for use in NLP research. Annotated Corpora There are few annotated corpora for dialectal Arabic: the Levantine Arabic Treebank (specifically Jordanian) (Maamouri et al., 2006), the Egyptian Arabic Treebank (Maamouri et al., 2014), Curras, the Pales1 The abbreviations we use intend to capture the country name and the city or region name when applicable. 2 http://www.semarch.uni-hd.de 137 Proceedings of the Fourth Arabic Natural Language Processing Workshop, pages 137–147 c Florence, Italy, August 1, 2019. 2019 Association for Computational Linguistics tinian Arabic annotated corpus (Jarrar et al., 2014), the Gulf Arabic Annotated corpus (Khalifa et al., 2018), Syrian, Jordanian dialectal corpora (Bouamor et al., 2014; Harrat et al., 2014), a small effort on Sanaani"
W19-4615,N13-1044,1,0.845771,"), which consists of around 70,000 words of a balanced genre corpus. The corpus was manually annotated using the DIWAN tool (Alshargi and Rambow, 2015), which we also use. The annotation in Curras is done by first using a morphological tagger for another Arabic dialect, namely MADAMIRA Egyptian (Pasha et al., 2014), to produce a base that was then corrected or accepted by a trained annotator. 3 Dialects: Linguistic Facts Other NLP Resources for Dialectal Arabic The effort to annotate corpora in context is a central step in developing morphological analyzers and taggers (Eskander et al., 2013; Habash et al., 2013). However, other notable approaches and efforts that do not use annotated corpora have focused on developing specific resources manually or semi-automatically, e.g., the Egyptian Arabic morphological analyzer (Habash et al., 2012b) which is built upon the Egyptian Colloquial Arabic Lexicon (Kilany et al., 2002), the multidialectal dictionary Tharwa (Diab et al., 2014), or extending MSA analyzers and resources (Salloum and Habash, 2014; Harrat et al., 2014; Boujelbane et al., 2013). Dialectal Variations Differences among the dialects are found on all levels of linguistic description, i.e., phon"
W19-4615,maamouri-etal-2014-developing,1,0.855497,"dialects in Section 4, summarizing the corpora used and some interesting facts specific to each dialect. Section 5 then presents our annotation methodology. We then briefly discuss morphological analyzers, and conclude. Introduction 2 As Arabic dialects (DA) become more widely written in social media, there is increased interest in the Arabic NLP community to have annotated corpora that will allow us to both study the dialects linguistically, and to create systems that can automatically process dialectal text. There have been important efforts to create relatively large corpora for Egyptian (Maamouri et al., 2014), Palestinian (Jarrar et al., 2014), and Emirati Arabic (Khalifa et al., 2018). While these resources are very helpful for single dialects, the problem is that there are many dialects, and in fact it is often unclear what to count as separate dialects (for example, the subdialects of Levantine). Therefore, we present a different approach in this paper: we annotate seven dialects, but with relatively smaller corpora (most around 30,000 words). Some of the dialects are closely related (Jordanian and Syrian), others are more distant (Moroccan). We use the same annotation methodology for all diale"
W19-4615,pasha-etal-2014-madamira,1,0.930495,"Missing"
W19-4615,voss-etal-2014-finding,0,0.0226381,"137–147 c Florence, Italy, August 1, 2019. 2019 Association for Computational Linguistics tinian Arabic annotated corpus (Jarrar et al., 2014), the Gulf Arabic Annotated corpus (Khalifa et al., 2018), Syrian, Jordanian dialectal corpora (Bouamor et al., 2014; Harrat et al., 2014), a small effort on Sanaani and Moroccan (AlShargi et al., 2016) (which this paper builds on), and SUAR (Al-Twairesh et al., 2018), a morphologically annotated corpus for Najdi and Hijazi which is semiautomatically annotated using the MADAMIRA tool (Pasha et al., 2014) and subsequently manually checked. Additionally, Voss et al. (2014) present a corpus of Moroccan dialect which has been annotated for language variety (code switching). Several of these efforts have followed the approach of Curras (Jarrar et al., 2014), which consists of around 70,000 words of a balanced genre corpus. The corpus was manually annotated using the DIWAN tool (Alshargi and Rambow, 2015), which we also use. The annotation in Curras is done by first using a morphological tagger for another Arabic dialect, namely MADAMIRA Egyptian (Pasha et al., 2014), to produce a base that was then corrected or accepted by a trained annotator. 3 Dialects: Linguist"
W19-4622,L18-1577,0,0.242839,"Missing"
W19-4622,D14-1154,0,0.0736532,"f the Arab World. Although primarily spoken, written dialectal Arabic has been increasingly used on social media. Automatic dialect identification is helpful for tasks such as sentiment analysis (Al-Twairesh et al., 2016), author profiling (Sadat et al., 2014), and machine translation (Salloum et al., 2014). Most previous work, shared tasks, and evaluation campaigns on Arabic dialect identification were limited in terms of dialectal variety targeting coarse-grained regional dialect classes (around five) plus Modern Standard Arabic (MSA) (Zaidan and CallisonBurch, 2013; Elfardy and Diab, 2013; Darwish et al., 2014; Malmasi et al., 2016; Zampieri et al., 2017; El-Haj et al., 2018). There are of course some recent noteworthy exceptions (Bouamor et al., 2018; Zaghouani and Charfi, 2018; AbdulMageed et al., 2018). In this paper, we present the results and findings of the MADAR Shared Task on Arabic Fine1 http://wanlp2019.arabic-nlp.net https://camel.abudhabi.nyu.edu/madar/ 3 http://resources.camel-lab.com. 2 199 Proceedings of the Fourth Arabic Natural Language Processing Workshop, pages 199–207 c Florence, Italy, August 1, 2019. 2019 Association for Computational Linguistics 2 Region Gulf of Aden Task Des"
W19-4622,W19-4633,0,0.188447,"Missing"
W19-4622,J14-1006,0,0.370824,"Missing"
W19-4622,W19-4628,0,0.174819,"Missing"
W19-4622,L18-1573,0,0.0500337,"ic has been increasingly used on social media. Automatic dialect identification is helpful for tasks such as sentiment analysis (Al-Twairesh et al., 2016), author profiling (Sadat et al., 2014), and machine translation (Salloum et al., 2014). Most previous work, shared tasks, and evaluation campaigns on Arabic dialect identification were limited in terms of dialectal variety targeting coarse-grained regional dialect classes (around five) plus Modern Standard Arabic (MSA) (Zaidan and CallisonBurch, 2013; Elfardy and Diab, 2013; Darwish et al., 2014; Malmasi et al., 2016; Zampieri et al., 2017; El-Haj et al., 2018). There are of course some recent noteworthy exceptions (Bouamor et al., 2018; Zaghouani and Charfi, 2018; AbdulMageed et al., 2018). In this paper, we present the results and findings of the MADAR Shared Task on Arabic Fine1 http://wanlp2019.arabic-nlp.net https://camel.abudhabi.nyu.edu/madar/ 3 http://resources.camel-lab.com. 2 199 Proceedings of the Fourth Arabic Natural Language Processing Workshop, pages 199–207 c Florence, Italy, August 1, 2019. 2019 Association for Computational Linguistics 2 Region Gulf of Aden Task Description The MADAR Shared Task included two subtasks: the MADAR Tra"
W19-4622,W14-3601,0,0.0818796,"AJK éJ ËAÓ úæK .ÈA®£ . . Q¯ñÊK QK A« .ÈA®£@ .  Q .ÈA®£ @ è » ø YK.  ªK . .ÈAîE éÊ KA ¯ IJ   ªK . .P AªË@ ø P@P YË@ ÈAK X é J.Ë IJ èQ AK @ .ÈA®£@ . @ èPQk . ø YK. .ÈA®£ @ Q¯ñÊK QK @X .ÈA®£ . èQ YJ«@ .ÈA®£@ Q CË .ÈA®£ è  AªK. @ ø P@P YË@ ÈAK X ñºK QK IJ  ªK . .P AªË@ CË èQ ùªK @ .ÈA®£ . CË . ÈA®£ Q¯ñÊK. ø YK. @ èQ úæ @ .ú ÍA®£ .XBð CË ÈñK QÓ I.m&apos; ¨AJÓ éJ ËAÓ úæK .P Aª ¨AJÓ ÈñK QÓ I. m. &apos; .P Aª  CË .ÈA®£ IJ »Ag. YK P @ Table 2: An example from Corpus 26 for the English sentence ‘I’d like a children’s sweater.’ Corpus collection Inspired by the work of Mubarak and Darwish (2014) we collected a set of Twitter user profiles that reflects the way users from different regions in the Arab World tweet. Unlike previous work (Zaghouani and Charfi, 2018), we do not search Twitter based on specific dialectal keywords. Rather, we search for tweets that contain a set of 25 seed hashtags corresponding to the 22 states of the Arab League (e.g., #Algeria, #Egypt, #Kuwait, etc.), in addition to the hashtags: ”#ArabWorld”, ”#ArabLeague” and ”#Arab”. We collected an equal number of profiles (175 * 25 = 4,375) from the search results of each of the hashtags. The profiles were all manua"
W19-4622,W19-4636,0,0.0437051,"Missing"
W19-4622,W19-4623,0,0.0791391,"Missing"
W19-4622,P13-2081,0,0.245192,"ross different regions of the Arab World. Although primarily spoken, written dialectal Arabic has been increasingly used on social media. Automatic dialect identification is helpful for tasks such as sentiment analysis (Al-Twairesh et al., 2016), author profiling (Sadat et al., 2014), and machine translation (Salloum et al., 2014). Most previous work, shared tasks, and evaluation campaigns on Arabic dialect identification were limited in terms of dialectal variety targeting coarse-grained regional dialect classes (around five) plus Modern Standard Arabic (MSA) (Zaidan and CallisonBurch, 2013; Elfardy and Diab, 2013; Darwish et al., 2014; Malmasi et al., 2016; Zampieri et al., 2017; El-Haj et al., 2018). There are of course some recent noteworthy exceptions (Bouamor et al., 2018; Zaghouani and Charfi, 2018; AbdulMageed et al., 2018). In this paper, we present the results and findings of the MADAR Shared Task on Arabic Fine1 http://wanlp2019.arabic-nlp.net https://camel.abudhabi.nyu.edu/madar/ 3 http://resources.camel-lab.com. 2 199 Proceedings of the Fourth Arabic Natural Language Processing Workshop, pages 199–207 c Florence, Italy, August 1, 2019. 2019 Association for Computational Linguistics 2 Region"
W19-4622,W19-4632,0,0.15859,"Missing"
W19-4622,W19-4624,0,0.0644897,"Missing"
W19-4622,W19-4626,0,0.0577171,"Missing"
W19-4622,W19-4627,0,0.031473,"Missing"
W19-4622,W14-5904,0,0.183785,"to target a large set of dialect labels at the city and country levels. The data for the shared task was created or collected under the Multi-Arabic Dialect Applications and Resources (MADAR) project. A total of 21 teams from 15 countries participated in the shared task. 1 Introduction Arabic has a number of diverse dialects from across different regions of the Arab World. Although primarily spoken, written dialectal Arabic has been increasingly used on social media. Automatic dialect identification is helpful for tasks such as sentiment analysis (Al-Twairesh et al., 2016), author profiling (Sadat et al., 2014), and machine translation (Salloum et al., 2014). Most previous work, shared tasks, and evaluation campaigns on Arabic dialect identification were limited in terms of dialectal variety targeting coarse-grained regional dialect classes (around five) plus Modern Standard Arabic (MSA) (Zaidan and CallisonBurch, 2013; Elfardy and Diab, 2013; Darwish et al., 2014; Malmasi et al., 2016; Zampieri et al., 2017; El-Haj et al., 2018). There are of course some recent noteworthy exceptions (Bouamor et al., 2018; Zaghouani and Charfi, 2018; AbdulMageed et al., 2018). In this paper, we present the results a"
W19-4622,W19-4625,0,0.0407356,"Missing"
W19-4622,C18-1113,1,0.76062,"Variant Total *6 54,000 *6 6,000 * 26 41,600 * 26 5,200 * 26 5,200 Table 3: Distribution of the train, dev and test sets provided for Subtask 1. Corpus annotation Three annotators, all native speakers of Arabic were hired to complete this task. They were provided with a list of Twitter user profiles and their corresponding URLs. They were asked to inspect each profile by checking if the user indicated his/her location, checking his/her tweets, and label it with its corresponding country when possible. In the context of dialect identification, the country label here refers to the Twitter 4 In (Salameh et al., 2018), the Corpus 6 test set corresponds to the 2,000 sentences from Corpus 26 corresponding to the Corpus 6’s five cities and MSA. 201 DrBehbehaniAM Kuwait DrBehbehaniAM Kuwait DrBehbehaniAM Kuwait HederAshraf Egypt HederAshraf Egypt HederAshraf Egypt samykhalildz Algeria samykhalildz Algeria samykhalildz Algeria    ZAJ.£ B@ QK ñK á  @X  Ë àñËñ®Kð  éÊ ¯A ®Ë@  B  . ªK H. CË@ Bð , I ® ¯ð . IJ  áÓ  K B@ ZAÓ á JJ¢ËAK B@ J ÊK AÓ ZAÓ QK ñJË@ Ðñ¯ úÎ« PñJËAÓ éÓA I.Ê®Ë@ . . .  QK A« ñë AÓ ø P IJm&apos; ë B@ ú¯ àñk . IJ m.&apos; QK A« úÍ@ AJ J«AJK. øX B ð @ I.jK ¬YêË@ . . . ú"
W19-4622,W19-4634,0,0.0370171,"Missing"
W19-4622,P14-2125,1,0.867703,"e city and country levels. The data for the shared task was created or collected under the Multi-Arabic Dialect Applications and Resources (MADAR) project. A total of 21 teams from 15 countries participated in the shared task. 1 Introduction Arabic has a number of diverse dialects from across different regions of the Arab World. Although primarily spoken, written dialectal Arabic has been increasingly used on social media. Automatic dialect identification is helpful for tasks such as sentiment analysis (Al-Twairesh et al., 2016), author profiling (Sadat et al., 2014), and machine translation (Salloum et al., 2014). Most previous work, shared tasks, and evaluation campaigns on Arabic dialect identification were limited in terms of dialectal variety targeting coarse-grained regional dialect classes (around five) plus Modern Standard Arabic (MSA) (Zaidan and CallisonBurch, 2013; Elfardy and Diab, 2013; Darwish et al., 2014; Malmasi et al., 2016; Zampieri et al., 2017; El-Haj et al., 2018). There are of course some recent noteworthy exceptions (Bouamor et al., 2018; Zaghouani and Charfi, 2018; AbdulMageed et al., 2018). In this paper, we present the results and findings of the MADAR Shared Task on Arabic F"
W19-4622,W19-4639,0,0.0527086,"Missing"
W19-4622,W19-4629,0,0.0882889,"Missing"
W19-4622,L18-1111,0,0.126051,"s such as sentiment analysis (Al-Twairesh et al., 2016), author profiling (Sadat et al., 2014), and machine translation (Salloum et al., 2014). Most previous work, shared tasks, and evaluation campaigns on Arabic dialect identification were limited in terms of dialectal variety targeting coarse-grained regional dialect classes (around five) plus Modern Standard Arabic (MSA) (Zaidan and CallisonBurch, 2013; Elfardy and Diab, 2013; Darwish et al., 2014; Malmasi et al., 2016; Zampieri et al., 2017; El-Haj et al., 2018). There are of course some recent noteworthy exceptions (Bouamor et al., 2018; Zaghouani and Charfi, 2018; AbdulMageed et al., 2018). In this paper, we present the results and findings of the MADAR Shared Task on Arabic Fine1 http://wanlp2019.arabic-nlp.net https://camel.abudhabi.nyu.edu/madar/ 3 http://resources.camel-lab.com. 2 199 Proceedings of the Fourth Arabic Natural Language Processing Workshop, pages 199–207 c Florence, Italy, August 1, 2019. 2019 Association for Computational Linguistics 2 Region Gulf of Aden Task Description The MADAR Shared Task included two subtasks: the MADAR Travel Domain Dialect Identification subtask, and the MADAR Twitter User Dialect Identification subtask. 2.1"
W19-4622,W19-4637,0,0.383619,"Missing"
W19-6621,Q17-1010,0,0.0130409,"no restriction on input’s vocabulary. We use long short-term memory units (LSTM) (Hochreiter and Schmidhuber, 1997), with hidden units of size 500 and two layers in both the encoder and decoder. The word embedding vector size for source/target is 300. English pretrained word embeddings were trained as skip-gram model (Mikolov et al., 2013) via gensim tool (Rehurek and Sojka, 2010) with settings: (size=300, window=8, min count=5) on English Gigaword 5th edition (Graff and Cieri, 2003) dataset. Arabic embeddings were trained on the Arabic Gigaword 5th edition (Parker et al., 2011) via FastText (Bojanowski et al., 2017), which showed better performance with morphologically rich languages (Erdmann et al., 2018). We give the designation of src/tgt++ to the system that uses both embeddings. 4.5 Evaluation Metrics The evaluation results are reported in case insensitive BLEU scores (Papineni et al., 2002) with their confidence intervals (CI) and p-values. Bootstrap resampling is used to compute statistical significance intervals (Koehn, 2004). Proceedings of MT Summit XVII, volume 1 5 5.1 Results Preprocessing and Learning Curve We examine Raw, ATB and D3 with and without BPE applied on top, across a learning cur"
W19-6621,W14-4012,0,0.225746,"glish translation on data preprecossed by various prominent tokenization schemes. Furthermore, we consider a range of data and vocabulary sizes and compare their effect on both approaches. Our empirical results show that the best choice of tokenization scheme is largely based on the type of model and the size of data. We also show that we can gain significant improvements using a system selection that combines the output from neural and statistical MT. 1 Introduction Neural machine translation (NMT) has been rapidly attracting the attention of the research community for its promising results (Cho et al., 2014b; Bahdanau et al., 2014; Wu et al., 2016; Vaswani et al., 2017). NMT is composed of two neural networks, an encoder and a decoder, where the encoder is fed a sentence from the source language and the decoder generates its translation, word by word, in the target language. Recently, NMT c 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 has been shown to outperform other MT systems in many language pairs, e.g. German-English, French-English and Basque-English (Escolano et al., 201"
W19-6621,D14-1179,0,0.0213359,"Missing"
W19-6621,D17-1148,0,0.0173335,"Bahdanau et al., 2014; Wu et al., 2016; Vaswani et al., 2017). NMT is composed of two neural networks, an encoder and a decoder, where the encoder is fed a sentence from the source language and the decoder generates its translation, word by word, in the target language. Recently, NMT c 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 has been shown to outperform other MT systems in many language pairs, e.g. German-English, French-English and Basque-English (Escolano et al., 2017; Dahlmann et al., 2017; Unanue et al., 2018). While Arabic MT has been mostly developed under statistical MT (SMT), NMT has also been applied and studied recently (Habash and Sadat, 2006; Almahairi et al., 2016; Durrani et al., 2017). Linguistically-motivated tokenization has shown to have a significant effect on SMT, particularly in the case of morphologically rich languages like Arabic (Habash and Sadat, 2006). However, it remains unclear if such techniques are well suited for NMT, where language-agnostic tokenizations, e.g. byte-pair encoding (BPE) (Sennrich et al., 2016), are widely used. Almahairi et al. (2016"
W19-6621,N12-1059,0,0.0309266,"3), and Arabic Treebank Tokenization. Decliticization of degree 2 outperformed the rest when applied individually. They reported improvement in MT performance when combining different schemes together. Almahairi et al. (2016) compared NMT and SMT on Arabic translation, and showed that NMT performs comparably to SMT. The best performance is achieved when Penn Arabic Treebank (ATB) tokenization is used with 51.19 and 49.70 BLEU points for SMT and NMT, respectively. The idea of system selection for MT exists in the literature, but mostly for model selection under the same approach (SMT or NMT) (Devlin and Matsoukas, 2012; Salloum et al., 2014). 3 Approach In our study, we systematically compare SMT and NMT on the following dimensions. Proceedings of MT Summit XVII, volume 1 3.1 Source Language Tokenization Much research has shown the importance of tokenization and orthographic normalization for SMT and NMT, as they deal with data sparsity (El Kholy and Habash, 2012; Habash and Sadat, 2006; Zalmout and Habash, 2017). Tokenization schemes can either be morphology-based or statistical/frequency-based (Pasha et al., 2014; Sennrich et al., 2016). We investigate both in the context of Arabic MT, both separately and"
W19-6621,P18-2089,1,0.867035,"Missing"
W19-6621,N06-2013,1,0.763429,"e from the source language and the decoder generates its translation, word by word, in the target language. Recently, NMT c 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 has been shown to outperform other MT systems in many language pairs, e.g. German-English, French-English and Basque-English (Escolano et al., 2017; Dahlmann et al., 2017; Unanue et al., 2018). While Arabic MT has been mostly developed under statistical MT (SMT), NMT has also been applied and studied recently (Habash and Sadat, 2006; Almahairi et al., 2016; Durrani et al., 2017). Linguistically-motivated tokenization has shown to have a significant effect on SMT, particularly in the case of morphologically rich languages like Arabic (Habash and Sadat, 2006). However, it remains unclear if such techniques are well suited for NMT, where language-agnostic tokenizations, e.g. byte-pair encoding (BPE) (Sennrich et al., 2016), are widely used. Almahairi et al. (2016) has looked into Arabic SMT and NMT, achieving the highest accuracy using the Penn Arabic Treebank (ATB) tokenization, with 51.2 and 49.7 BLEU points for SMT and N"
W19-6621,P17-4012,0,0.027077,"SMTtgt++ Raw 331K 52.78 ATB 208K 55.42 D3 190K 54.66 Raw+BPE 20K 53.78 ATB+BPE 20K 55.64 D3+BPE 20K 54.59 CI NMTscr/tgt++ ± 0.98 52.76 ± 1.07 53.54 ± 1.02 53.51 ± 1.10 52.41 ± 1.11 53.18 ± 1.07 53.38 CI P -value ± 1.24 0.412 ± 1.20 0.002 ± 1.20 0.027 ± 1.17 0.003 ± 1.15 0.001 ± 1.16 0.018 Table 1: Comparing Raw, ATB and D3 Tokenized cases without/with BPE on in-domain test (MT05), in terms of BLEU scores, where the Confidence Interval (CI) and P -value are reported. Bold font highlights best results by SMT and NMT. ong et al. (2015). All the NMT models have been trained using OpenNMT toolkit (Klein et al., 2017) with no restriction on input’s vocabulary. We use long short-term memory units (LSTM) (Hochreiter and Schmidhuber, 1997), with hidden units of size 500 and two layers in both the encoder and decoder. The word embedding vector size for source/target is 300. English pretrained word embeddings were trained as skip-gram model (Mikolov et al., 2013) via gensim tool (Rehurek and Sojka, 2010) with settings: (size=300, window=8, min count=5) on English Gigaword 5th edition (Graff and Cieri, 2003) dataset. Arabic embeddings were trained on the Arabic Gigaword 5th edition (Parker et al., 2011) via Fast"
W19-6621,W17-3204,0,0.0209327,"resources besides the target side of the training parallel corpus. In SMT, target language resources are used to build language models for fluency improvement. Whereas, many works have proven pretrained word embeddings to be useful in neural network models (Qi et al., 2018), and therefor, the same additional TLR are used to learn pretrained word embeddings that support the decoder in NMT. Here, the tgt++ designation next to the system name indicates the use of additional TLR. 3.4 Input Length and System Selection Many have reported NMT performing worse with long sentences (Cho et al., 2014a; Koehn and Knowles, 2017), which was caught in our error analysis and thus we explored combining the two MT systems via a system selection approach, where the selection of either translation is based on which is closer to the input length as a criterion. Whereas the sentence BLEU score is the criterion in the Oracle system selection. 4 Experimental Settings 4.1 Datasets The training dataset contains 1.2M sentence pairs in newswire (NW) domain from three Linguistic Data Consortium (LDC) resources: LDC2004T18, LDC2004T14, and LDC2007T08. For tuning, we use LDC2010T12 (MT04), which consists of Proceedings of MT Summit XV"
W19-6621,P07-2045,0,0.00691764,"1,535 sentence pairs mostly web collection, and has four English reference translations. 4.2 Preprocessing MADAMIRA (Pasha et al., 2014) is utilized for morphology-based tokenization of the source side. Sennrich et al. (2016)’s BPE implementation is used for learning and applying BPE models. We set vocabulary size to 20K in BPE learning after exploring multiple vocabulary sizes, including 10K, 20K and 30K, where the 20K setting achieved comparable results to the 30K and outperformed the 10K. Each BPE model is trained on source side of training data of the respective experiment. While Moses’ (Koehn et al., 2007) tokenizer and lowercaser are used for preparing the target side. 4.3 SMT settings We use Moses 3.0 (Koehn et al., 2007) to train SMT models with maximum phrase length of 8 tokens. Two versions of the language model are examined: 1) trained solely on the target side of the training dataset, and 2) trained on the target side and the English Gigaword 5th edition. 4.4 NMT settings We use the encoder-decoder with the general global attention architecture as introduced by LuDublin, Aug. 19-23, 2019 |p. 216 57 53 Raw ATB ATB 51 53 Raw+BPE 49 51 ATB+BPE 47 Raw 49 BLEU 55 BLEU NMTsrc/tgt++ 55 SMTtgt++"
W19-6621,W04-3250,0,0.165541,"Missing"
W19-6621,D15-1166,0,0.149737,"Missing"
W19-6621,pasha-etal-2014-madamira,1,0.864964,"Missing"
W19-6621,N18-2084,0,0.0226079,"are resting and distributing the new posts, said Ahmad Abou Hamida. Figure 1: Tokenization schemes applied to an example. tokens. Thus, the same sentences will be selected across different tokenization schemes. 3.3 Target Language Resources We design the training so that both systems will have access to the same additional target language resources besides the target side of the training parallel corpus. In SMT, target language resources are used to build language models for fluency improvement. Whereas, many works have proven pretrained word embeddings to be useful in neural network models (Qi et al., 2018), and therefor, the same additional TLR are used to learn pretrained word embeddings that support the decoder in NMT. Here, the tgt++ designation next to the system name indicates the use of additional TLR. 3.4 Input Length and System Selection Many have reported NMT performing worse with long sentences (Cho et al., 2014a; Koehn and Knowles, 2017), which was caught in our error analysis and thus we explored combining the two MT systems via a system selection approach, where the selection of either translation is based on which is closer to the input length as a criterion. Whereas the sentence"
W19-6621,P14-2125,1,0.886384,"enization. Decliticization of degree 2 outperformed the rest when applied individually. They reported improvement in MT performance when combining different schemes together. Almahairi et al. (2016) compared NMT and SMT on Arabic translation, and showed that NMT performs comparably to SMT. The best performance is achieved when Penn Arabic Treebank (ATB) tokenization is used with 51.19 and 49.70 BLEU points for SMT and NMT, respectively. The idea of system selection for MT exists in the literature, but mostly for model selection under the same approach (SMT or NMT) (Devlin and Matsoukas, 2012; Salloum et al., 2014). 3 Approach In our study, we systematically compare SMT and NMT on the following dimensions. Proceedings of MT Summit XVII, volume 1 3.1 Source Language Tokenization Much research has shown the importance of tokenization and orthographic normalization for SMT and NMT, as they deal with data sparsity (El Kholy and Habash, 2012; Habash and Sadat, 2006; Zalmout and Habash, 2017). Tokenization schemes can either be morphology-based or statistical/frequency-based (Pasha et al., 2014; Sennrich et al., 2016). We investigate both in the context of Arabic MT, both separately and in combination, to obs"
W19-6621,P16-1162,0,0.715124,"nd Basque-English (Escolano et al., 2017; Dahlmann et al., 2017; Unanue et al., 2018). While Arabic MT has been mostly developed under statistical MT (SMT), NMT has also been applied and studied recently (Habash and Sadat, 2006; Almahairi et al., 2016; Durrani et al., 2017). Linguistically-motivated tokenization has shown to have a significant effect on SMT, particularly in the case of morphologically rich languages like Arabic (Habash and Sadat, 2006). However, it remains unclear if such techniques are well suited for NMT, where language-agnostic tokenizations, e.g. byte-pair encoding (BPE) (Sennrich et al., 2016), are widely used. Almahairi et al. (2016) has looked into Arabic SMT and NMT, achieving the highest accuracy using the Penn Arabic Treebank (ATB) tokenization, with 51.2 and 49.7 BLEU points for SMT and NMT, respectively. In this paper, we study the impact of different preprocessing techniques in Arabic-English MT on both SMT and NMT, by examining various prominent tokenization schemes. We conduct learning curve experiments to study the interaction between data size and the choice of tokenization scheme. We study the performance under morphology-based and frequency-based tokenization schemes,"
W19-6621,L18-1141,0,0.0982117,"Wu et al., 2016; Vaswani et al., 2017). NMT is composed of two neural networks, an encoder and a decoder, where the encoder is fed a sentence from the source language and the decoder generates its translation, word by word, in the target language. Recently, NMT c 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 has been shown to outperform other MT systems in many language pairs, e.g. German-English, French-English and Basque-English (Escolano et al., 2017; Dahlmann et al., 2017; Unanue et al., 2018). While Arabic MT has been mostly developed under statistical MT (SMT), NMT has also been applied and studied recently (Habash and Sadat, 2006; Almahairi et al., 2016; Durrani et al., 2017). Linguistically-motivated tokenization has shown to have a significant effect on SMT, particularly in the case of morphologically rich languages like Arabic (Habash and Sadat, 2006). However, it remains unclear if such techniques are well suited for NMT, where language-agnostic tokenizations, e.g. byte-pair encoding (BPE) (Sennrich et al., 2016), are widely used. Almahairi et al. (2016) has looked into Arab"
W19-6621,P02-1040,0,0.104213,"Missing"
W19-6621,W17-4725,0,\N,Missing
zaghouani-etal-2014-large,W11-2602,1,\N,Missing
zaghouani-etal-2014-large,W10-1004,1,\N,Missing
zaghouani-etal-2014-large,P05-1071,1,\N,Missing
zaghouani-etal-2014-large,P11-1019,0,\N,Missing
zaghouani-etal-2014-large,P08-2015,1,\N,Missing
zaghouani-etal-2014-large,N13-1036,1,\N,Missing
zaghouani-etal-2014-large,W13-1703,0,\N,Missing
zaghouani-etal-2014-large,shaalan-etal-2012-arabic,0,\N,Missing
zaghouani-etal-2014-large,pasha-etal-2014-madamira,1,\N,Missing
zaghouani-etal-2014-large,dickinson-ledbetter-2012-annotating,0,\N,Missing
zaghouani-etal-2014-large,I13-2001,1,\N,Missing
zaghouani-etal-2014-large,abuhakema-etal-2008-annotating,0,\N,Missing
zaghouani-etal-2014-large,N13-1066,1,\N,Missing
zribi-etal-2014-conventional,habash-etal-2012-conventional,1,\N,Missing
zribi-etal-2014-conventional,I13-1133,1,\N,Missing
zribi-etal-2014-conventional,N13-1044,1,\N,Missing
zribi-etal-2014-conventional,pasha-etal-2014-madamira,1,\N,Missing
zribi-etal-2014-conventional,W13-2813,1,\N,Missing
zribi-etal-2014-conventional,N13-1066,1,\N,Missing
zribi-etal-2014-conventional,W12-2301,1,\N,Missing
