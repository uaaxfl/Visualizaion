2005.mtsummit-papers.36,N01-1018,0,0.0681459,"ation of multiple feature functions is implemented (Och and Ney, 2002). Additionally, original word-based translation models (Brown et al., 1993) have been replaced by phrase-based translation models (Zens et al., 2002) and (Koehn et al., 2003), which are estimated from aligned bilingual corpora by using relative frequencies. 275 On the other hand, the translation problem has also been approached from the ﬁnite-state perspective as the most natural way for integrating speech recognition and machine translation into a speech-to-speech translation system (Riccardi et al., 1996), (Vidal, 1997), (Bangalore and Riccardi, 2001) and (Casacuberta, 2001). In this kind of systems the translation model constitutes a ﬁnite-state network which is learned from training data. The translation system described in this paper implements a translation model based on the ﬁnite-state perspective, (de Gispert and Mari˜ no, 2002) and (de Gispert et al., 2004), which is used along with a log-linear combination of four additional feature functions (Crego et al., 2005). The implemented translation model, which is referred to as tuple n-gram model, diﬀers from the well known phrase-model approach (Koehn et al., 2003) in two basic issues."
2005.mtsummit-papers.36,J96-1002,0,0.115652,"entioned in the introduction, the translation system presented here implements a log-linear combination of feature functions 1 In the present version of the system, target words aligned to NULL are always attached to the following word. Further work in this area is proposed in the last section. along with the tuple n-gram model. This section describes the log-linear model and each of the four speciﬁc feature functions that are used. Finally, a brief description of the customized decoding tool that is used is presented. 3.1 Log-Linear Model Framework According to the maximum entropy framework (Berger et al., 1996), the corresponding translation hypothesis T , for a given source sentence S, is deﬁned by the target sentence that maximizes a log-linear combination of feature functions hi (S, T ), as described in the following equation:  argmax λi hi (S, T ) (2) T i where the λi ’s constitute the weighting coeﬃcients of the log-linear combination and the feature function hi (S, T ) corresponds to a logarithmic scaling of the ith -model probabilities. These weights are computed via an optimization procedure which maximizes the translation BLEU (Papineni et al., 2002) over a given development set. This opti"
2005.mtsummit-papers.36,J90-2002,0,0.523079,"Missing"
2005.mtsummit-papers.36,J93-2003,0,0.0465928,"ementation of translation algorithms based on statistical methods (Brown et al., 1990) and (1993). The ﬁrst SMT systems were based on the noisy channel approach, which models the probability of a target language sentence T given a source language sentence S as a translation model probability p(S|T ) times a target language model probability p(T ). In recent systems such an approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Additionally, original word-based translation models (Brown et al., 1993) have been replaced by phrase-based translation models (Zens et al., 2002) and (Koehn et al., 2003), which are estimated from aligned bilingual corpora by using relative frequencies. 275 On the other hand, the translation problem has also been approached from the ﬁnite-state perspective as the most natural way for integrating speech recognition and machine translation into a speech-to-speech translation system (Riccardi et al., 1996), (Vidal, 1997), (Bangalore and Riccardi, 2001) and (Casacuberta, 2001). In this kind of systems the translation model constitutes a ﬁnite-state network which is l"
2005.mtsummit-papers.36,N04-1033,0,0.157603,"Missing"
2005.mtsummit-papers.36,2005.iwslt-1.23,1,0.857305,"Missing"
2005.mtsummit-papers.36,2004.iwslt-evaluation.14,1,0.687498,"Missing"
2005.mtsummit-papers.36,P05-2012,1,0.78658,"Missing"
2005.mtsummit-papers.36,N03-1017,0,0.067546,"The ﬁrst SMT systems were based on the noisy channel approach, which models the probability of a target language sentence T given a source language sentence S as a translation model probability p(S|T ) times a target language model probability p(T ). In recent systems such an approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Additionally, original word-based translation models (Brown et al., 1993) have been replaced by phrase-based translation models (Zens et al., 2002) and (Koehn et al., 2003), which are estimated from aligned bilingual corpora by using relative frequencies. 275 On the other hand, the translation problem has also been approached from the ﬁnite-state perspective as the most natural way for integrating speech recognition and machine translation into a speech-to-speech translation system (Riccardi et al., 1996), (Vidal, 1997), (Bangalore and Riccardi, 2001) and (Casacuberta, 2001). In this kind of systems the translation model constitutes a ﬁnite-state network which is learned from training data. The translation system described in this paper implements a translation"
2005.mtsummit-papers.36,P02-1038,0,0.221853,"otivated by the development of computer resources needed to allow the implementation of translation algorithms based on statistical methods (Brown et al., 1990) and (1993). The ﬁrst SMT systems were based on the noisy channel approach, which models the probability of a target language sentence T given a source language sentence S as a translation model probability p(S|T ) times a target language model probability p(T ). In recent systems such an approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Additionally, original word-based translation models (Brown et al., 1993) have been replaced by phrase-based translation models (Zens et al., 2002) and (Koehn et al., 2003), which are estimated from aligned bilingual corpora by using relative frequencies. 275 On the other hand, the translation problem has also been approached from the ﬁnite-state perspective as the most natural way for integrating speech recognition and machine translation into a speech-to-speech translation system (Riccardi et al., 1996), (Vidal, 1997), (Bangalore and Riccardi, 2001) and (Casacuberta, 2001). In this kind of"
2005.mtsummit-papers.36,N04-1021,0,0.0290838,"length penalization in order to compensate the system preference for short target sentences caused by the presence of the previous target language model. This penalization depends on the total number of words contained in the partial translation hypothesis, and it is computed as follows: wp(Tk ) = exp(number of words in Tk ) (4) where, again, Tk refers to the partial translation hypothesis. The fourth and ﬁfth feature functions correspond to a forward and backward lexicon models. These models provide IBM 1 translation probabilities for each tuple based on the IBM 1 lexical parameters p(t|s) (Och et al., 2004). These lexicon models are computed according to the following equation: pIBM 1 ((t, s)n ) = I J   1 p(tin |sjn ) (5) (I + 1)J j=1 i=0 (3) where sjn and tin are the j th and ith words in the source and target sides of tuple (t, s)n , being J and I the corresponding total number words in each side of it. For computing the forward lexicon model, IBM model 1 lexical parameters from GIZA++ source-to-target alignments are used. In the case of the backward lexicon model, GIZA++ target-to-source alignments are used instead. where Tk refers to the partial translation hypothesis and wn to the nth wor"
2005.mtsummit-papers.36,P02-1040,0,0.115781,"cording to the maximum entropy framework (Berger et al., 1996), the corresponding translation hypothesis T , for a given source sentence S, is deﬁned by the target sentence that maximizes a log-linear combination of feature functions hi (S, T ), as described in the following equation:  argmax λi hi (S, T ) (2) T i where the λi ’s constitute the weighting coeﬃcients of the log-linear combination and the feature function hi (S, T ) corresponds to a logarithmic scaling of the ith -model probabilities. These weights are computed via an optimization procedure which maximizes the translation BLEU (Papineni et al., 2002) over a given development set. This optimization is performed by using an in-house developed optimization algorithm, which is based on a simplex method (Press et al., 2002). 3.2 Implemented Feature Functions The proposed translation system implements a total of ﬁve feature functions: • tuple 3-gram model, • target language model, • word penalty model, • source-to-target lexicon model, and • target-to-source lexicon model. The ﬁrst of these functions is the tuple 3-gram model, which was already described in the previous section. The second feature function implemented is a target language model"
2005.mtsummit-papers.36,2002.tmi-tutorials.2,0,0.0433398,"al., 1990) and (1993). The ﬁrst SMT systems were based on the noisy channel approach, which models the probability of a target language sentence T given a source language sentence S as a translation model probability p(S|T ) times a target language model probability p(T ). In recent systems such an approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Additionally, original word-based translation models (Brown et al., 1993) have been replaced by phrase-based translation models (Zens et al., 2002) and (Koehn et al., 2003), which are estimated from aligned bilingual corpora by using relative frequencies. 275 On the other hand, the translation problem has also been approached from the ﬁnite-state perspective as the most natural way for integrating speech recognition and machine translation into a speech-to-speech translation system (Riccardi et al., 1996), (Vidal, 1997), (Bangalore and Riccardi, 2001) and (Casacuberta, 2001). In this kind of systems the translation model constitutes a ﬁnite-state network which is learned from training data. The translation system described in this paper"
2005.mtsummit-papers.36,P00-1056,0,\N,Missing
2005.mtsummit-posters.11,J93-2003,0,0.0224343,"8034 Barcelona, Spain, rbanchs@gps.tsc.upc.edu Abstract This paper presents a strategy for detecting and using multi-word expressions in Statistical Machine Translation. Performance of the proposed strategy is evaluated in terms of alignment quality as well as translation accuracy. Evaluations are performed by using the Verbmobil corpus. Results from translation tasks from English-toSpanish and from Spanish-to-English are presented and discussed. 1 Introduction Statistical machine translation (SMT) was originally focused on word to word translation and was based on the noisy channel approach (Brown et al., 1993). Present SMT systems have evolved from the original ones in such a way that mainly diﬀer from them in two issues: ﬁrst, word-based translation models have been replaced by phrase-based translation models (Zens et al., 2002) and (Koehn et al., 2003); and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Nevertheless, it is interesting to call the attention about one important fact. Despite the change from a word-based to a phrase-based translation ap"
2005.mtsummit-posters.11,2005.iwslt-1.23,0,0.0341509,"Missing"
2005.mtsummit-posters.11,2004.iwslt-evaluation.14,0,0.0452393,"Missing"
2005.mtsummit-posters.11,2004.iwslt-papers.3,0,0.0238486,"Missing"
2005.mtsummit-posters.11,N03-1017,0,0.0177452,"as well as translation accuracy. Evaluations are performed by using the Verbmobil corpus. Results from translation tasks from English-toSpanish and from Spanish-to-English are presented and discussed. 1 Introduction Statistical machine translation (SMT) was originally focused on word to word translation and was based on the noisy channel approach (Brown et al., 1993). Present SMT systems have evolved from the original ones in such a way that mainly diﬀer from them in two issues: ﬁrst, word-based translation models have been replaced by phrase-based translation models (Zens et al., 2002) and (Koehn et al., 2003); and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Nevertheless, it is interesting to call the attention about one important fact. Despite the change from a word-based to a phrase-based translation approach, word to word approaches for inferring translation probabilities from bilingual data (Vogel et al., 1996; Och and Ney, 2003) continue to be widely used. On the other hand, from observing bilingual data sets, it becomes evident that in some ca"
2005.mtsummit-posters.11,2005.mtsummit-papers.36,1,0.412614,"Missing"
2005.mtsummit-posters.11,P02-1038,0,0.0182673,"1 Introduction Statistical machine translation (SMT) was originally focused on word to word translation and was based on the noisy channel approach (Brown et al., 1993). Present SMT systems have evolved from the original ones in such a way that mainly diﬀer from them in two issues: ﬁrst, word-based translation models have been replaced by phrase-based translation models (Zens et al., 2002) and (Koehn et al., 2003); and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Nevertheless, it is interesting to call the attention about one important fact. Despite the change from a word-based to a phrase-based translation approach, word to word approaches for inferring translation probabilities from bilingual data (Vogel et al., 1996; Och and Ney, 2003) continue to be widely used. On the other hand, from observing bilingual data sets, it becomes evident that in some cases it is just impossible to perform a word to word alignment between two phrases that are translations of each other. For example, certain combination of words might convey a meaning which is somehow"
2005.mtsummit-posters.11,J03-1002,0,0.114154,": ﬁrst, word-based translation models have been replaced by phrase-based translation models (Zens et al., 2002) and (Koehn et al., 2003); and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Nevertheless, it is interesting to call the attention about one important fact. Despite the change from a word-based to a phrase-based translation approach, word to word approaches for inferring translation probabilities from bilingual data (Vogel et al., 1996; Och and Ney, 2003) continue to be widely used. On the other hand, from observing bilingual data sets, it becomes evident that in some cases it is just impossible to perform a word to word alignment between two phrases that are translations of each other. For example, certain combination of words might convey a meaning which is somehow independent from the words it contains. This is the case of bilingual pairs such as “ﬁre engine” and “cami´ on de bomberos”. 396 Notice, from the example presented above, that a word-to-word alignment strategy would most probably1 provide the following Viterbi alignments for words"
2005.mtsummit-posters.11,J04-4002,0,0.0483562,"y a language feature, it will be repeated various times in the corpus, otherwise it will occur only once. Thus only those bilingual multi-words which appeared at least twice are selected. Still, some bilingual multi-words, whose source side is not the translation of the target side, can appear various times. An example is “de que - you”. To minimise this type of errors, we wanted to be able to select the N best asymmetry based BMWE, and ranked them according to their number of occurences. 3.1.2 Bilingual Phrase Extraction Here we refer to Bilingual Phrase (BP) as the bilingual phrases used by Och and Ney (2004). The BP are pairs of word groups which are supposed to be the translation of each other. The set of BP is consistent with the alignment and consists of all phrase pairs in which all words within the target language are only aligned to the words of the source language and vice versa. At least one word of the target language phrase has to be aligned with at least one word of the source language phrase. Finally, the algorithm takes into account possibly unaligned words at the boundaries of the target or source language phrases. We extracted all BP of length up to three words, with the algorithm"
2005.mtsummit-posters.11,W05-0827,0,0.0107756,"h the algorithm described by Och and Ney (2004). Again, we established a ranking between them. In that purpose, we estimated the phrase translation probability distribution by relative frequency: p(t|s) = N (t, s) N (s) (2) In equation 2, s and t stand for the source and target side of the BP, respectively. N (t, s) is the number of times the phrase s is translated by t, and N (s) is the number of times s occurs in the corpus. Data sparseness can cause probabilities estimated in this way to be overestimated, and the inverse probability (p(s|t)) has proved to contribute to a better estimation (Ruiz and Fonollosa, 2005). To increase reliability, we took the minimum of both relative frequencies as probability of a BP, as shown in equation 3: p(s, t) = min(p(t|s), p(s|t)) (3) Many phrases occur very few times but always appear as the translation of the same phrase in the other language, so that their mutual probability as given by equation 3 is 1. However, this does not necessarily imply that they are a good translation of each other. To avoid to give a high score to these entries, we took as ﬁnal score the minimum of the relative frequencies multiplied by the number of occurrences of this phrase pair in the w"
2005.mtsummit-posters.11,C96-2141,0,0.129176,"m them in two issues: ﬁrst, word-based translation models have been replaced by phrase-based translation models (Zens et al., 2002) and (Koehn et al., 2003); and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Nevertheless, it is interesting to call the attention about one important fact. Despite the change from a word-based to a phrase-based translation approach, word to word approaches for inferring translation probabilities from bilingual data (Vogel et al., 1996; Och and Ney, 2003) continue to be widely used. On the other hand, from observing bilingual data sets, it becomes evident that in some cases it is just impossible to perform a word to word alignment between two phrases that are translations of each other. For example, certain combination of words might convey a meaning which is somehow independent from the words it contains. This is the case of bilingual pairs such as “ﬁre engine” and “cami´ on de bomberos”. 396 Notice, from the example presented above, that a word-to-word alignment strategy would most probably1 provide the following Viterbi"
2005.mtsummit-posters.11,2002.tmi-tutorials.2,0,0.0300916,"rms of alignment quality as well as translation accuracy. Evaluations are performed by using the Verbmobil corpus. Results from translation tasks from English-toSpanish and from Spanish-to-English are presented and discussed. 1 Introduction Statistical machine translation (SMT) was originally focused on word to word translation and was based on the noisy channel approach (Brown et al., 1993). Present SMT systems have evolved from the original ones in such a way that mainly diﬀer from them in two issues: ﬁrst, word-based translation models have been replaced by phrase-based translation models (Zens et al., 2002) and (Koehn et al., 2003); and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Nevertheless, it is interesting to call the attention about one important fact. Despite the change from a word-based to a phrase-based translation approach, word to word approaches for inferring translation probabilities from bilingual data (Vogel et al., 1996; Och and Ney, 2003) continue to be widely used. On the other hand, from observing bilingual data sets, it become"
2006.iwslt-evaluation.17,W05-0820,0,0.0116848,", namely from Arabic, Chinese, Italian and Japanese into English for the open data track, thoroughly explaining all language-related preprocessing and optimization schemes. 1. Introduction Rooted in the Finite-State Transducers approach to SMT [1, 2] and estimating a joint-probability model between the source and the target languages, Ngram-based SMT has proved to be a very competitive alternative to phrase-based and other state-of-the-art systems in previous evaluation campaigns, as shown in [3]. This is specially true when dealing with pairs of languages with a relatively similar word order [4, 5]. Given the language pairs involved in this year’s evaluation, efforts have been focused on improving the word reordering strategies for Ngram-based SMT. Specifically, a novel reordering strategy based on extending the search graph with automatically-extracted reordering patterns is explored. Results are very promising while keeping computational expenses at a similar level of monotone search. Additionally, a novel tuple segmentation strategy based on the entropy of Part-Of-Speech distributions was used with slight improvements in model estimation. This paper is organized as follows. Section 2"
2006.iwslt-evaluation.17,W06-3114,0,0.0159274,", namely from Arabic, Chinese, Italian and Japanese into English for the open data track, thoroughly explaining all language-related preprocessing and optimization schemes. 1. Introduction Rooted in the Finite-State Transducers approach to SMT [1, 2] and estimating a joint-probability model between the source and the target languages, Ngram-based SMT has proved to be a very competitive alternative to phrase-based and other state-of-the-art systems in previous evaluation campaigns, as shown in [3]. This is specially true when dealing with pairs of languages with a relatively similar word order [4, 5]. Given the language pairs involved in this year’s evaluation, efforts have been focused on improving the word reordering strategies for Ngram-based SMT. Specifically, a novel reordering strategy based on extending the search graph with automatically-extracted reordering patterns is explored. Results are very promising while keeping computational expenses at a similar level of monotone search. Additionally, a novel tuple segmentation strategy based on the entropy of Part-Of-Speech distributions was used with slight improvements in model estimation. This paper is organized as follows. Section 2"
2006.iwslt-evaluation.17,2005.mtsummit-papers.36,1,0.472143,"g patterns. Section 4 focuses on tuple segmentation strategies, and contrasts the criterion on IBM model 1 probabilities from 2005 with a novel criterion based on Part-Of-Speech entropy distributions. Later on, Section 5 reports on all experiments carried out from Arabic, Chinese, Italian and Japanese into English for IWSLT 2006. Finally, Section 6 sums up the main conclusions from the paper and discusses future research lines. 2. 2005 system review The TALP Ngram-based SMT system performs a log-linear combination of a translation model and additional feature functions (see further details in [6, 7]). In contrast to phrasebased models, our translation model is estimated as a standard n-gram model of a bilingual language expressed in tuples. This way it approximates the joint probability between source and target languages capturing bilingual context, as described by the following equation: p(sJ1 , tI1 ) = K Y p((s, t)i |(s, t)i−N +1 , ..., (s, t)i−1 ) (1) i=1 where (s, t)i refers to the ith tuple of a sentence pair being segmented into K tuples. A detailed comparison between Ngram-based and phrase-based SMT can be found in [8]. 2.1. Tuple extraction Given a certain word-aligned parallel"
2006.iwslt-evaluation.17,2005.iwslt-1.23,1,0.868702,"l and additional feature functions (see further details in [6, 7]). In contrast to phrasebased models, our translation model is estimated as a standard n-gram model of a bilingual language expressed in tuples. This way it approximates the joint probability between source and target languages capturing bilingual context, as described by the following equation: p(sJ1 , tI1 ) = K Y p((s, t)i |(s, t)i−N +1 , ..., (s, t)i−1 ) (1) i=1 where (s, t)i refers to the ith tuple of a sentence pair being segmented into K tuples. A detailed comparison between Ngram-based and phrase-based SMT can be found in [8]. 2.1. Tuple extraction Given a certain word-aligned parallel corpus, tuples are extracted according to the following constraints [9]: • a monotonic segmentation of each bilingual sentence pair is produced • no word in a tuple is aligned to words outside of it • no smaller tuples can be extracted without violating the previous constraints 116 3. Word ordering strategies 2.2. Feature functions As additional feature functions to better guide the translation process, the system incorporates a target language model, a word bonus model and two lexicon models. The target language model is estimated"
2006.iwslt-evaluation.17,N04-1033,0,0.120187,"ated as a standard n-gram model of a bilingual language expressed in tuples. This way it approximates the joint probability between source and target languages capturing bilingual context, as described by the following equation: p(sJ1 , tI1 ) = K Y p((s, t)i |(s, t)i−N +1 , ..., (s, t)i−1 ) (1) i=1 where (s, t)i refers to the ith tuple of a sentence pair being segmented into K tuples. A detailed comparison between Ngram-based and phrase-based SMT can be found in [8]. 2.1. Tuple extraction Given a certain word-aligned parallel corpus, tuples are extracted according to the following constraints [9]: • a monotonic segmentation of each bilingual sentence pair is produced • no word in a tuple is aligned to words outside of it • no smaller tuples can be extracted without violating the previous constraints 116 3. Word ordering strategies 2.2. Feature functions As additional feature functions to better guide the translation process, the system incorporates a target language model, a word bonus model and two lexicon models. The target language model is estimated as a standard ngram over the target words, as follows: pLM (tk ) ≈ k Y p(wn |wn−N +1 , ..., wn−1 ) (2) n=1 where tk refers to the par"
2006.iwslt-evaluation.17,2005.mtsummit-papers.37,1,0.788658,"n |wn−N +1 , ..., wn−1 ) (2) n=1 where tk refers to the partial hypothesis and wn to the nth word in it. Usually, this feature is accompanied by a word bonus model based on sentence length, compensating the target language model preference for short sentences (in number of target words). This bonus depends on the number of target words in the partial hypothesis, denoted as: pW P (tk ) = exp(number of words in tk ) When dealing with pairs of languages with non-monotonic word order, a certain reordering strategy is required. Apart from that, tuples need to be extracted by an unfolding technique [11]. This means that the tuples are broken into smaller tuples, and these are sequenced in the order of the target words. In order not to lose the information on the correct order, the decoder performs then a reordered search (or a monotone search extended with reordering paths), which is guided by the n-gram model of the unfolded tuples and the additional feature models. Figure 1 shows an example of tuple unfolding compared to the monotonic extraction. The unfolding technique produces a different bilingual n-gram language model with reordered source words. (3) where tk refers to the partial hypo"
2006.iwslt-evaluation.17,A00-1031,0,0.0103336,"Language-dependent preprocessing For all language pairs, training sentences were split by using final dots on both sides of the bilingual text (when the number of dots was equal), increasing the number of sentences and reducing its length. Specific preprocessing for each language is detailed in the following respective section. 5.2.1. English Table 1: Arabic→English corpus statistics. sent. it en it it it it wrds 155k 166k 5,193 2,807 5,978 5,767 refs. 1 7 16 7 7 Table 2: Chinese→English corpus statistics. English preprocessing includes Part-Of-Speech tagging using freely-available TnT tagger [15] and lemmatization using wnmorph, included in the WordNet package [16]. The English Penn Treebank Tag Set used contains 36 different tags. 5.2.2. Arabic Following a similar approach to that in [17], we use the Buckwalter Arabic Morphological Analyzer2 to obtain possible word analyses for Arabic, and disambiguate them using the Morphological Analysis and Disambiguation for Arabic (MADA) tool [18], kindly provided by the University of Columbia. Once analyzed, Arabic words are segmented by separating all prefixes (prepositions, conjunctions, the article and the future marker) and suffixes (pronom"
2006.iwslt-evaluation.17,N06-2013,0,0.0357882,"mber of sentences and reducing its length. Specific preprocessing for each language is detailed in the following respective section. 5.2.1. English Table 1: Arabic→English corpus statistics. sent. it en it it it it wrds 155k 166k 5,193 2,807 5,978 5,767 refs. 1 7 16 7 7 Table 2: Chinese→English corpus statistics. English preprocessing includes Part-Of-Speech tagging using freely-available TnT tagger [15] and lemmatization using wnmorph, included in the WordNet package [16]. The English Penn Treebank Tag Set used contains 36 different tags. 5.2.2. Arabic Following a similar approach to that in [17], we use the Buckwalter Arabic Morphological Analyzer2 to obtain possible word analyses for Arabic, and disambiguate them using the Morphological Analysis and Disambiguation for Arabic (MADA) tool [18], kindly provided by the University of Columbia. Once analyzed, Arabic words are segmented by separating all prefixes (prepositions, conjunctions, the article and the future marker) and suffixes (pronominal clitics). The tool also provides POS tags for the resultant tokens. The Arabic Treebank tag set used contains 20 different tags. Corpora statistics for all language pairs can be found in 2 Ver"
2006.iwslt-evaluation.17,P05-1071,0,0.0218458,"n it it it it wrds 155k 166k 5,193 2,807 5,978 5,767 refs. 1 7 16 7 7 Table 2: Chinese→English corpus statistics. English preprocessing includes Part-Of-Speech tagging using freely-available TnT tagger [15] and lemmatization using wnmorph, included in the WordNet package [16]. The English Penn Treebank Tag Set used contains 36 different tags. 5.2.2. Arabic Following a similar approach to that in [17], we use the Buckwalter Arabic Morphological Analyzer2 to obtain possible word analyses for Arabic, and disambiguate them using the Morphological Analysis and Disambiguation for Arabic (MADA) tool [18], kindly provided by the University of Columbia. Once analyzed, Arabic words are segmented by separating all prefixes (prepositions, conjunctions, the article and the future marker) and suffixes (pronominal clitics). The tool also provides POS tags for the resultant tokens. The Arabic Treebank tag set used contains 20 different tags. Corpora statistics for all language pairs can be found in 2 Version 119 2.0. Linguistic Data Consortium Catalog: LDC2004L02. 5.2.3. Chinese official Chinese preprocessing included resegmentation and POStagging. These tasks were done by using ICTCLAS [19]. Resultan"
2006.iwslt-evaluation.17,W03-1730,0,0.0274114,"Missing"
2006.iwslt-evaluation.17,2004.iwslt-evaluation.14,1,\N,Missing
2006.iwslt-evaluation.17,E99-1010,0,\N,Missing
2006.iwslt-evaluation.17,J96-1002,0,\N,Missing
2006.iwslt-evaluation.17,W05-0823,1,\N,Missing
2006.iwslt-evaluation.17,N07-2022,1,\N,Missing
2006.iwslt-evaluation.17,2005.iwslt-1.1,0,\N,Missing
2006.iwslt-evaluation.17,J06-4004,1,\N,Missing
2006.iwslt-evaluation.17,N03-1017,0,\N,Missing
2006.iwslt-evaluation.17,J03-1002,0,\N,Missing
2006.iwslt-evaluation.17,2006.iwslt-evaluation.1,0,\N,Missing
2006.iwslt-evaluation.17,2005.iwslt-1.24,1,\N,Missing
2006.iwslt-evaluation.17,2006.iwslt-papers.2,1,\N,Missing
2006.iwslt-evaluation.17,atserias-etal-2006-freeling,0,\N,Missing
2006.iwslt-evaluation.17,2005.iwslt-1.11,0,\N,Missing
2006.iwslt-evaluation.17,P00-1056,0,\N,Missing
2006.iwslt-evaluation.17,2006.iwslt-papers.5,1,\N,Missing
2006.iwslt-evaluation.18,2005.iwslt-1.24,1,0.787344,"TALP phrase-based statistical machine translation system, enriched with the statistical machine reordering technique. We also report the combination of this system and the TALP-tuple, the n-gram-based statistical machine translation system. We report the results for all the tasks (Chinese, Arabic, Italian and Japanese to English) in the framework of the third evaluation campaign of the International Workshop on Spoken Language Translation. 1. Introduction This paper describes the TALP-phrase system for the IWSLT 2006, which is an enhanced version of the system reported in the 2005 evaluation [1]. The main difference is the integration of a new reordering technique called statistical machine reordering, which was presented in [2] in a different framework. Additionally, we report the results of combining the outputs of the two statistical machine translation TALP systems: phrase-based and n-gram-based. The latter of the two also participated in the 2005 evaluation and is described in [3]. Statistical machine translation systems are now usually modelled through a log-linear maximum entropy framework. e˜ = argmax e ( M X m=1 λm hm (e, f ) ) TALP-tuple. Finally, in Section 4, we report th"
2006.iwslt-evaluation.18,W06-1609,1,0.921033,"e combination of this system and the TALP-tuple, the n-gram-based statistical machine translation system. We report the results for all the tasks (Chinese, Arabic, Italian and Japanese to English) in the framework of the third evaluation campaign of the International Workshop on Spoken Language Translation. 1. Introduction This paper describes the TALP-phrase system for the IWSLT 2006, which is an enhanced version of the system reported in the 2005 evaluation [1]. The main difference is the integration of a new reordering technique called statistical machine reordering, which was presented in [2] in a different framework. Additionally, we report the results of combining the outputs of the two statistical machine translation TALP systems: phrase-based and n-gram-based. The latter of the two also participated in the 2005 evaluation and is described in [3]. Statistical machine translation systems are now usually modelled through a log-linear maximum entropy framework. e˜ = argmax e ( M X m=1 λm hm (e, f ) ) TALP-tuple. Finally, in Section 4, we report the results obtained for all the tasks of the evaluation, which include the translations from Chinese, Arabic, Italian and Japanese to Eng"
2006.iwslt-evaluation.18,W06-3125,1,0.836838,"ional Workshop on Spoken Language Translation. 1. Introduction This paper describes the TALP-phrase system for the IWSLT 2006, which is an enhanced version of the system reported in the 2005 evaluation [1]. The main difference is the integration of a new reordering technique called statistical machine reordering, which was presented in [2] in a different framework. Additionally, we report the results of combining the outputs of the two statistical machine translation TALP systems: phrase-based and n-gram-based. The latter of the two also participated in the 2005 evaluation and is described in [3]. Statistical machine translation systems are now usually modelled through a log-linear maximum entropy framework. e˜ = argmax e ( M X m=1 λm hm (e, f ) ) TALP-tuple. Finally, in Section 4, we report the results obtained for all the tasks of the evaluation, which include the translations from Chinese, Arabic, Italian and Japanese to English. 2. Description of the TALP-phrase System 2.1. Phrase-based Model The basic idea of phrase-based translation is to segment the given source sentence into units (here called phrases), then translate each phrase and finally compose the target sentence from th"
2006.iwslt-evaluation.18,P02-1038,0,0.0577834,"re consecutive along both sides of the bilingual phrase and (2) no word on either side of the phrase is aligned to a word outside the phrase. 2.2. Feature functions The baseline phrase-based system implements a log-linear combination of four feature functions, which are described as follows. • The translation model is estimated with relative frequencies. Given the collected phrase pairs, we estimate the phrase translation probability distribution by relative frequency in both directions. (1) The feature functions, hm , and weights, λi , are typically optimized to maximize the scoring function [4]. Two basic issues differentiate the n-gram-based system from the phrase-based system: the bilingual units are extracted from a monotonic segmentation of the training data; the unit probabilities are based on a standard back-off language model rather than directly on relative frequencies. In both systems, the introduction of reordering capabilities is crucial for certain language pairs. This paper is organized as follows. Section 2 describes the TALP-phrase system, with particular emphasis on a new reordering technique: the statistical machine reordering approach. In Section 3, we combine the"
2006.iwslt-evaluation.18,J04-4002,0,0.0302302,"X m=1 λm hm (e, f ) ) TALP-tuple. Finally, in Section 4, we report the results obtained for all the tasks of the evaluation, which include the translations from Chinese, Arabic, Italian and Japanese to English. 2. Description of the TALP-phrase System 2.1. Phrase-based Model The basic idea of phrase-based translation is to segment the given source sentence into units (here called phrases), then translate each phrase and finally compose the target sentence from these phrase translations. Given a sentence pair and a corresponding word alignment, phrases are extracted following the criterion in [5]. A phrase (or bilingual phrase) is any pair of m source words and n target words that satisfies two basic constraints (1) words are consecutive along both sides of the bilingual phrase and (2) no word on either side of the phrase is aligned to a word outside the phrase. 2.2. Feature functions The baseline phrase-based system implements a log-linear combination of four feature functions, which are described as follows. • The translation model is estimated with relative frequencies. Given the collected phrase pairs, we estimate the phrase translation probability distribution by relative frequen"
2006.iwslt-evaluation.18,2005.iwslt-1.6,0,0.0322379,"using the GIZA++ tool [7]. During word alignment, we used 50 classes per language. We aligned both translation directions and combined the two alignments with the union operation. train dev4 dev123 test ASRtest • Word classes (which were used to help the aligner and to perform the SMR process) were determined using “mkcls”, a tool freely-available with GIZA++. • The language model was estimated using the SRILM toolkit [8]. • The decoder was MARIE [9]. • The optimization tool used for computing log-linear weights was based on the simplex method [6]. Following the consensus strategy proposed in [10], the objective function was set to 100 · BLEU + 4 · N IST . 489 500 500 500 voc. 9.7k 9.6k 1,096 909 1,292 1,311 slen. 6.7 7.0 11.2 6.0 11.7 11.6 refs. 1 7 16 7 7 Corpus statistics for all language pairs can be found in Tables 1, 2, 3 and 4, respectively, where number of sentences, running words, vocabulary, sentence length and human references are shown. sent. train dev4 dev123 test ASRtest Experiments were carried out for all tasks of the IWSLT06 evaluation (Zh2En, Jp2En, Ar2En and It2En) using the BTEC Corpus provided for the open data track1 . it en it it it it 24.6k 489 500 500 500 wrds"
2006.iwslt-evaluation.18,A00-1031,0,0.0229282,"while randomly selecting 500 sentences from developments 1, 2 and 3 (around 160 sentences from each) to build an internal test set (dev123). zh en zh zh zh zh 4.4. Language-dependent preprocessing For all language pairs, training sentences were split by using full stops on both sides of the bilingual text (when the number of stops was equal), increasing the number of sentences and reducing their length. Specific preprocessing for each language is detailed in the respective section below. 4.4.1. English English preprocessing includes part-of-speech tagging using the freely-available TnT tagger [11] and lemmatization using wnmorph, included in the WordNet package [12]. 126 sent. train dev4 dev123 test ASRtest jp en jp jp jp jp 45.2k 489 500 500 500 wrds 390k 325k 6,758 3,818 7,367 7,494 voc. 10.6k 9.6k 1,169 936 1,301 1,331 slen. 8.6 7.2 13.8 7.6 14.7 15.0 refs. 1 7 16 7 7 Table 4: Japanese→English corpus statistics. 4.4.2. Arabic Following a similar approach to that taken in [13], we use the Buckwalter Arabic Morphological Analyzer2 to obtain possible word analyses for Arabic, and disambiguate them using the Morphological Analysis and Disambiguation for Arabic (MADA) tool [14], kindly p"
2006.iwslt-evaluation.18,N06-2013,0,0.0411805,"ing their length. Specific preprocessing for each language is detailed in the respective section below. 4.4.1. English English preprocessing includes part-of-speech tagging using the freely-available TnT tagger [11] and lemmatization using wnmorph, included in the WordNet package [12]. 126 sent. train dev4 dev123 test ASRtest jp en jp jp jp jp 45.2k 489 500 500 500 wrds 390k 325k 6,758 3,818 7,367 7,494 voc. 10.6k 9.6k 1,169 936 1,301 1,331 slen. 8.6 7.2 13.8 7.6 14.7 15.0 refs. 1 7 16 7 7 Table 4: Japanese→English corpus statistics. 4.4.2. Arabic Following a similar approach to that taken in [13], we use the Buckwalter Arabic Morphological Analyzer2 to obtain possible word analyses for Arabic, and disambiguate them using the Morphological Analysis and Disambiguation for Arabic (MADA) tool [14], kindly provided by the University of Columbia. Once analyzed, Arabic words are segmented by separating all prefixes (prepositions, conjunctions, the article and the future marker) and suffixes (pronominal clitics). The tool also provides POS tags for the resultant tokens. search (with m = 5 and j = 3) for all tasks and for all systems (with or without SMR technique); except for the Italian to E"
2006.iwslt-evaluation.18,P05-1071,0,0.0382995,"nT tagger [11] and lemmatization using wnmorph, included in the WordNet package [12]. 126 sent. train dev4 dev123 test ASRtest jp en jp jp jp jp 45.2k 489 500 500 500 wrds 390k 325k 6,758 3,818 7,367 7,494 voc. 10.6k 9.6k 1,169 936 1,301 1,331 slen. 8.6 7.2 13.8 7.6 14.7 15.0 refs. 1 7 16 7 7 Table 4: Japanese→English corpus statistics. 4.4.2. Arabic Following a similar approach to that taken in [13], we use the Buckwalter Arabic Morphological Analyzer2 to obtain possible word analyses for Arabic, and disambiguate them using the Morphological Analysis and Disambiguation for Arabic (MADA) tool [14], kindly provided by the University of Columbia. Once analyzed, Arabic words are segmented by separating all prefixes (prepositions, conjunctions, the article and the future marker) and suffixes (pronominal clitics). The tool also provides POS tags for the resultant tokens. search (with m = 5 and j = 3) for all tasks and for all systems (with or without SMR technique); except for the Italian to English task where a monotonic search was used. The primary system of each task is that which had the best performance in the internal test. In all tasks, the SMR improved the results in the internal te"
2006.iwslt-evaluation.18,W03-1730,0,0.0516051,"Missing"
2006.iwslt-evaluation.18,atserias-etal-2006-freeling,0,0.0138517,"for the internal test set (specially, for the Arabic and Japanese tasks). The higher the number of unknown words, the worse the SMR output and, consequently, the quality of translation. Here, a possible solution would be to predict word classes for unknown words in order to avoid their bad influence in the SMR output. 4.4.3. Chinese Set development test evaluation Chinese preprocessing included re-segmentation and POStagging. These tasks were performed using ICTCLAS [15]. 4.4.4. Italian Italian was POS-tagged and lemmatized using the freelyavailable FreeLing morpho-syntactic analysis package [16]. Additionally, Italian contracted prepositions were separated into preposition + article, for example ’alla’→’a la’, ’degli’→’di gli’ or ’dallo’→’da lo’. 4.4.5. Japanese When dealing with Japanese, one has to come up with new methods for overcoming the absence of delimiters between words. We addressed this issue by word segmentation using the freely available JUMAN tool [17] version 5.1. This tool was also used for POS-tagging of the Japanese text. 4.5. Results In Table 6 we show the results for all the TALP systems that participated in the IWSLT 2006: the TALP-phrase, the TALP-tuple and the"
2006.iwslt-evaluation.18,2004.iwslt-evaluation.8,0,\N,Missing
2006.iwslt-papers.5,P02-1038,0,0.052325,"eriments with the Simultaneous Perturbation Stochastic Approximation (SPSA) algorithm, and compare them to tuning with the widely used downhill simplex method. With IWSLT 2006 Chinese-English data, both methods showed similar performance, but SPSA was more robust to the choice of initial settings. 1. Introduction Statistical machine translation (SMT) was originally based on the noisy channel approach [1]. In present SMT systems, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented [2]. Translation quality can be improved by adjusting the weight of each feature function in the log-linear combination. This can be effectively performed by minimising translation error over a development corpus for which manually translated references are available [3]. This minimisation problem in multiple dimensions is difficult because of three main characteristics of the objective function. Firstly, it has no analytic representation, so the gradient cannot be calculated. Secondly, it has many local minima. Finally, its evaluation has a significant computational cost (depending on the scheme"
2006.iwslt-papers.5,P03-1021,0,0.34622,"he choice of initial settings. 1. Introduction Statistical machine translation (SMT) was originally based on the noisy channel approach [1]. In present SMT systems, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented [2]. Translation quality can be improved by adjusting the weight of each feature function in the log-linear combination. This can be effectively performed by minimising translation error over a development corpus for which manually translated references are available [3]. This minimisation problem in multiple dimensions is difficult because of three main characteristics of the objective function. Firstly, it has no analytic representation, so the gradient cannot be calculated. Secondly, it has many local minima. Finally, its evaluation has a significant computational cost (depending on the scheme, it implies translating the development corpus or re-ranking an n-best list for this corpus, and calculating some translation error measure). Gradient may be approximated, but this is costly since it requires typically as many function evaluations as the number of sc"
2006.iwslt-papers.5,2005.mtsummit-posters.19,0,0.0137668,"computational cost (depending on the scheme, it implies translating the development corpus or re-ranking an n-best list for this corpus, and calculating some translation error measure). Gradient may be approximated, but this is costly since it requires typically as many function evaluations as the number of scaling factors. Thus, algorithms based on derivatives are discarded. Algorithms which require many objective functions evaluations, such as simulated annealing or genetic algorithms, are also discarded. Two popular alternatives are Powell’s method [4, 5, 3] and the downhill simplex method [6, 5, 7]. In recent experiments at the 2006 John Hopkins University Summer Workshop on SMT, both methods achieved similar performance [8]. The simplex method is self-contained and straightforward and thus widely used for SMT tuning [7, 9, 10, 11], although it is not very efficient in terms of number of objective function evaluations for a high number of dimensions [12]. However, from the authors experience, a slight modification of initial parameters in the simplex optimisation can result in an appreciable difference in both the value of the local minimum found and the value of the optimal parameters."
2006.iwslt-papers.5,W05-0821,0,0.0206377,"y since it requires typically as many function evaluations as the number of scaling factors. Thus, algorithms based on derivatives are discarded. Algorithms which require many objective functions evaluations, such as simulated annealing or genetic algorithms, are also discarded. Two popular alternatives are Powell’s method [4, 5, 3] and the downhill simplex method [6, 5, 7]. In recent experiments at the 2006 John Hopkins University Summer Workshop on SMT, both methods achieved similar performance [8]. The simplex method is self-contained and straightforward and thus widely used for SMT tuning [7, 9, 10, 11], although it is not very efficient in terms of number of objective function evaluations for a high number of dimensions [12]. However, from the authors experience, a slight modification of initial parameters in the simplex optimisation can result in an appreciable difference in both the value of the local minimum found and the value of the optimal parameters. This difference is transmitted when these parameters are used to translate a test corpus. When a translation system is compared to a baseline, the difference arising only from the tuning process can be even greater than the difference ar"
2006.iwslt-papers.5,2005.mtsummit-papers.36,1,0.871032,"y since it requires typically as many function evaluations as the number of scaling factors. Thus, algorithms based on derivatives are discarded. Algorithms which require many objective functions evaluations, such as simulated annealing or genetic algorithms, are also discarded. Two popular alternatives are Powell’s method [4, 5, 3] and the downhill simplex method [6, 5, 7]. In recent experiments at the 2006 John Hopkins University Summer Workshop on SMT, both methods achieved similar performance [8]. The simplex method is self-contained and straightforward and thus widely used for SMT tuning [7, 9, 10, 11], although it is not very efficient in terms of number of objective function evaluations for a high number of dimensions [12]. However, from the authors experience, a slight modification of initial parameters in the simplex optimisation can result in an appreciable difference in both the value of the local minimum found and the value of the optimal parameters. This difference is transmitted when these parameters are used to translate a test corpus. When a translation system is compared to a baseline, the difference arising only from the tuning process can be even greater than the difference ar"
2006.iwslt-papers.5,W06-3125,1,0.814894,"imate the gradient as in equation 2 Step 5 Update λ estimate as in equation 1 Step 6 Iteration or termination. Return to Step 2 with k + 1 replacing k. Terminate if the maximum number of iterations have been reached or if there is little change in several successive iterates. 3. Experimental Settings 3.1. Translation system used Although the following discussion would be valid in many contexts, and in particular for any Empirical MT system, it is convenient here to present briefly the models implemented by our system, and whose respective weights are tuned. For a more complete description see [16]. The SMT approach used here considers a translation model which is based on a 4-grams language model of bilingual units which are referred to as tuples. Tuples are extracted from Viterbi alignments and can be formally defined as the set of shortest phrases that provides a monotonic segmentation of the bilingual corpus. In addition to the bilingual 4-gram translation model, the translation system implements a log linear combination of five additional feature functions: a 4-gram language model of the target language (denoted TM); a 4-gram language model of target POS-tags (TTM) which helps, alo"
2006.iwslt-papers.5,2001.mtsummit-papers.68,0,0.0164973,"down in which range the scaling factor of each model behaved. We selected the initial value of each parameter randomly within its corresponding range. Table 1 displays the initial points 1 Actually, 191 SPSA could also be used instead used in the experiments. ID 1 2 3 4 5 6 7 TM 0.29 0.5 0.58 1 1.1 1.2 1.3 TTM 0.52 0.5 0.42 1 0.22 0.53 0.34 WB 0.32 0.5 1.4 1 1.5 1.5 1.2 L1 1.7 0.5 0.2 1 1.6 1.3 0.85 L2 0.84 0.5 0.075 1 0.29 0.89 0.44 Table 1: Sets of initial parameters used in the experiments. In table 3 points are referred to by their ID number. The error function we choose is the BLEU score [17]. Actually it does not measure an error but a translation accuracy, so its opposite is to be minimised. were T was empirically set to 0.005. According to this probability distribution, the worse the new set of lambdas, the less probability to accept it. ˆ k ), we reSince we introduced an evaluation of E(λ placed the two-sided gradient approximation by a one-sided ˆ k ) and E(λ ˆk + one, which involves evaluations of E(λ perturbation). If the noise caused by the one-sided approximation (as opposed to the two-sided approximation) is small compared to the noise arising from the simultaneous appro"
2006.iwslt-papers.5,J06-4004,1,0.901943,".1±0.47 18.9±0.89 19.0±0.72 18.9±0.54 19.1±0.71 18.9±0.65 8 6 4 2 0 0 0.5 1 1.5 2 2.5 L1 WEIGHT 14 SPSA 12 10 NUMBER OF CASES ID 8 6 4 Table 4: Average BLEU score and standard deviation obtained with the simplex method (above) and SPSA method (below) in the development set, after 20, 40, 60, and 90 function evaluations, for each seed used to generate different algorithm conditions. Only seed ID numbers are displayed. 2 0 0 0.5 1 1.5 2 2.5 L1 WEIGHT Figure 1: Histogram of L1 model weights for simplex (above) and SPSA (below) nant, although this model has got a big impact in translation quality [19]. This is an indication of the interdependence of the various models. Figure 1 also suggests that there would be no point in averaging parameter values in order to gain generalisation power. As ultimate goal, we need to see if the stability of SPSA optimisations is conserved when translating new text (i.e. the test corpus). For each initial point and seed, and after a given number of function evaluations, we collected the optimum parameter set over the development corpus, and translated the test corpus with these parameters. Results are brought together in Table 5. Table 5 instructs, as expect"
2006.iwslt-papers.5,2006.iwslt-evaluation.17,1,\N,Missing
2006.iwslt-papers.5,J93-2003,0,\N,Missing
2006.iwslt-papers.5,P02-1040,0,\N,Missing
2007.iwslt-1.26,2006.iwslt-papers.2,1,0.882609,"4]. Efforts have been focused on improving translation according to human evaluation by further developing different stages of the SMT system: alignment and rescoring. As in previous years, we aligned the training corpus using Giza++ software. However, instead of keeping the default parameters, we performed a minimum translation error training procedure to adjust Giza++ smoothing parameters to the task. This procedure had been successful with an alignment system based on discriminative training [5]. For the rescoring we incorporate a neural network language model as previously experienced in [6]. The neural network language model mainly is able to produce a better generalization in the translation system. This paper is organized as follows. Section 2 briefly reviews last year’s system, including tuple definition and extraction, translation model and feature functions, decoding tool and reordering and optimization criterion. Section 3 describes the alignment translation-minimum-error training procedure. Section 4 focuses on rescoring using a neural language model (NNLM). Next, Section 5 reports on all experiments carried out from Arabic and Chinese into English for IWSLT 2007. Finally"
2007.iwslt-1.26,N04-1033,0,0.0623584,"ls, our translation model is estimated as a standard n-gram model of a bilingual language expressed in tuples. In this way, it approximates the joint probability between source and target languages capturing bilingual context, as described by the following equation: p(S, T ) = K Y p((˜ s, t˜)k |(˜ s, t˜)k−N +1 , ..., (˜ s, t˜)k−1 ) (1) k=1 where s refers to source, t to target, and (˜ s, t˜)k to the k th tuple of a given bilingual sentence pair segmented in K tuples. 2.2. Tuple extraction Given a certain word-aligned parallel corpus, tuples are extracted according to the following constraints [9]: • a monotonic segmentation of each bilingual sentence pair is produced • no word in a tuple is aligned to words outside of it • no smaller tuples can be extracted without violating the previous constraints However, when dealing with pairs of languages with nonmonotonic word order, a certain reordering strategy is required to extract more reusable units (less sparse). Hence, we allow the source words to be reordered before extracting translation units from training sentence pairs by following the word-to-word alignments. The unfolding technique is fully described in [10]. Figure 1 shows an ex"
2007.iwslt-1.26,2005.mtsummit-papers.37,1,0.856996,"following constraints [9]: • a monotonic segmentation of each bilingual sentence pair is produced • no word in a tuple is aligned to words outside of it • no smaller tuples can be extracted without violating the previous constraints However, when dealing with pairs of languages with nonmonotonic word order, a certain reordering strategy is required to extract more reusable units (less sparse). Hence, we allow the source words to be reordered before extracting translation units from training sentence pairs by following the word-to-word alignments. The unfolding technique is fully described in [10]. Figure 1 shows an example of tuple unfolding compared to the monotonic extraction. The unfolding technique produces a different bilingual n-gram language model with reordered source words. where tn refers to the nth word in the partial translation hypothesis T . Usually, this feature is accompanied by a word bonus model based on sentence length, compensating the target language model preference for short sentences (in number of target words). This bonus depends on the number of target words in the partial hypothesis, denoted as: pW P (T ) = exp(number of words in T ). The third and fourth fe"
2007.iwslt-1.26,2006.iwslt-papers.5,1,0.867108,"ChineseEnglish task, a secondary run was performed with a rescoring module, as described in Sections 4 and 5.3.2. 2.5. Feature Weights Optimization To tune the weight of each feature function in the SMT system, we used the Simultaneous Perturbation Stochastic Approximation (SPSA) algorithm [12]. SPSA is a stochastic implementation of the conjugate gradient method which requires only two evaluations of the objective function in each iteration, regardless of the dimension of the optimization problem. It was observed to be more robust than the Downhill Simplex method when tuning SMT coefficients [13]. The SPSA procedure is in the general recursive stochastic approximation form: ˆ k+1 = λ ˆ k − ak g ˆk ) ˆk (λ λ (5) lation tuples (as no word within a tuple can be linked to a word out of it [9]). Starting from the monotonic graph, each sequence of input POS tags fulfilling a source-side rewrite rule implies the addition of a reordering arc (which encodes the reordering detailed in the target-side of the rule). Figure 2 shows how three rewrite rules applied over an input sentence extend the search graph given the reordering patterns that match the source POS tag sequence 1 . ˆ k ) is the esˆ"
2007.iwslt-1.26,N07-2022,1,0.823419,"o phrase-based and other state-of-the-art systems in previous evaluation campaigns, as shown in [3, 4]. Efforts have been focused on improving translation according to human evaluation by further developing different stages of the SMT system: alignment and rescoring. As in previous years, we aligned the training corpus using Giza++ software. However, instead of keeping the default parameters, we performed a minimum translation error training procedure to adjust Giza++ smoothing parameters to the task. This procedure had been successful with an alignment system based on discriminative training [5]. For the rescoring we incorporate a neural network language model as previously experienced in [6]. The neural network language model mainly is able to produce a better generalization in the translation system. This paper is organized as follows. Section 2 briefly reviews last year’s system, including tuple definition and extraction, translation model and feature functions, decoding tool and reordering and optimization criterion. Section 3 describes the alignment translation-minimum-error training procedure. Section 4 focuses on rescoring using a neural language model (NNLM). Next, Section 5"
2007.iwslt-1.26,N06-2013,0,0.076004,"fluency and METEOR is well correlated to adequacy [4], we supposed that adding all references was beneficial to monolingual language models but not to the bilingual language model. Table 2: Chinese→English corpus statistics. 5.2. Data Preprocessing For all language pairs, training sentences were split by using final dots on both sides of the bilingual text (when the number of dots was equal), increasing the number of sentences and reducing its length. Specific preprocessing for each language is detailed in the following respective section. 5.2.1. Arabic Following a similar approach to that in [16], we used the MADA+TOKAN system for disambiguation and tokenization. For disambiguation only diacritic uni-gram statistics were employed. For tokenization we used the D3 scheme with -TAGBIES option. The D3 scheme splits the following set of clitics: w+, f+, b+, k+, l+, Al+ and pronominal clitics. The -TAGBIES option produces Bies POS tags on all taggable tokens. 5.2.2. Chinese Chinese preprocessing included re-segmentation using ICTCLAS [17] and POS tagging using the freely available Stanford Parser4 . 5.2.3. English English preprocessing includes Part-Of-Speech tagging using freely-available"
2007.iwslt-1.26,W03-1730,0,0.018621,"ts length. Specific preprocessing for each language is detailed in the following respective section. 5.2.1. Arabic Following a similar approach to that in [16], we used the MADA+TOKAN system for disambiguation and tokenization. For disambiguation only diacritic uni-gram statistics were employed. For tokenization we used the D3 scheme with -TAGBIES option. The D3 scheme splits the following set of clitics: w+, f+, b+, k+, l+, Al+ and pronominal clitics. The -TAGBIES option produces Bies POS tags on all taggable tokens. 5.2.2. Chinese Chinese preprocessing included re-segmentation using ICTCLAS [17] and POS tagging using the freely available Stanford Parser4 . 5.2.3. English English preprocessing includes Part-Of-Speech tagging using freely-available TnT tagger [18]. For alignment purpose only (of the ZhEn system), the English corpus was stemmed using the Snowball stemmer 5 , based on Porter’s algorithm. 5.3. Results 5.3.1. Alignment In the ZhEn system development work, we tried to improve word alignment by stemming the English corpus and make use of classes [19]. We also performed several combinations of source-target and target-source GIZA++ alignments (union, growing forward diagonal"
2007.iwslt-1.26,A00-1031,0,0.0277074,"he MADA+TOKAN system for disambiguation and tokenization. For disambiguation only diacritic uni-gram statistics were employed. For tokenization we used the D3 scheme with -TAGBIES option. The D3 scheme splits the following set of clitics: w+, f+, b+, k+, l+, Al+ and pronominal clitics. The -TAGBIES option produces Bies POS tags on all taggable tokens. 5.2.2. Chinese Chinese preprocessing included re-segmentation using ICTCLAS [17] and POS tagging using the freely available Stanford Parser4 . 5.2.3. English English preprocessing includes Part-Of-Speech tagging using freely-available TnT tagger [18]. For alignment purpose only (of the ZhEn system), the English corpus was stemmed using the Snowball stemmer 5 , based on Porter’s algorithm. 5.3. Results 5.3.1. Alignment In the ZhEn system development work, we tried to improve word alignment by stemming the English corpus and make use of classes [19]. We also performed several combinations of source-target and target-source GIZA++ alignments (union, growing forward diagonal method and Och’s refined method [20]), as well as concatenations of various of these combinations. Using stems and classes in the alignment improved translation results i"
2007.iwslt-1.26,E99-1010,0,0.0816899,"ion produces Bies POS tags on all taggable tokens. 5.2.2. Chinese Chinese preprocessing included re-segmentation using ICTCLAS [17] and POS tagging using the freely available Stanford Parser4 . 5.2.3. English English preprocessing includes Part-Of-Speech tagging using freely-available TnT tagger [18]. For alignment purpose only (of the ZhEn system), the English corpus was stemmed using the Snowball stemmer 5 , based on Porter’s algorithm. 5.3. Results 5.3.1. Alignment In the ZhEn system development work, we tried to improve word alignment by stemming the English corpus and make use of classes [19]. We also performed several combinations of source-target and target-source GIZA++ alignments (union, growing forward diagonal method and Och’s refined method [20]), as well as concatenations of various of these combinations. Using stems and classes in the alignment improved translation results in all cases, and the best combination for the system with pattern-based reordering was the union6 . At the end, the best alignment configuration for our baseline system was obtained with Giza++ software, running respectively 5, 5, 3 and 3 iterations of models 1, HMM, 3 and 4, using English stems and 50"
2007.iwslt-1.26,J03-1002,0,0.00791937,"y available Stanford Parser4 . 5.2.3. English English preprocessing includes Part-Of-Speech tagging using freely-available TnT tagger [18]. For alignment purpose only (of the ZhEn system), the English corpus was stemmed using the Snowball stemmer 5 , based on Porter’s algorithm. 5.3. Results 5.3.1. Alignment In the ZhEn system development work, we tried to improve word alignment by stemming the English corpus and make use of classes [19]. We also performed several combinations of source-target and target-source GIZA++ alignments (union, growing forward diagonal method and Och’s refined method [20]), as well as concatenations of various of these combinations. Using stems and classes in the alignment improved translation results in all cases, and the best combination for the system with pattern-based reordering was the union6 . At the end, the best alignment configuration for our baseline system was obtained with Giza++ software, running respectively 5, 5, 3 and 3 iterations of models 1, HMM, 3 and 4, using English stems and 50 classes and taking the union of source-target and target-source alignments. Table 3 show results for the new features of this year’s system. We optimized the foll"
2008.eamt-1.15,H05-1011,0,0.619332,"is paper deals with core aspects of discriminative word alignment systems, namely basic word association models as well as search strategies. We compare various low-computational-cost word association models: χ2 score, log-likelihood ratio and IBM model 1. We also compare three beam-search strategies. We show that it is more flexible and accurate to let links to the same word compete together, than introducing them sequentially in the alignment hypotheses, which is the strategy followed in several systems. 1 Introduction In this paper, we study core aspects of discriminative alignment systems [1, 2]. In these systems, the best alignment hypothesis is the one that maximises a linear combination of features. In Sect. 2 we propose some improvements of the beam-search algorithm implemented by Moore [1]. Then we present experimental results for different low-computational-cost word association score features (Sect. 3.1) and for the proposed search strategies (Sect. 3.2). Finally, we give some conclusions. 2 Search Strategies Search aims at finding the alignment (i.e. the set of links between source and target words) which maximises the sum of each feature cost, weighted by its respective weig"
2008.eamt-1.15,P05-1057,0,0.0787703,"is paper deals with core aspects of discriminative word alignment systems, namely basic word association models as well as search strategies. We compare various low-computational-cost word association models: χ2 score, log-likelihood ratio and IBM model 1. We also compare three beam-search strategies. We show that it is more flexible and accurate to let links to the same word compete together, than introducing them sequentially in the alignment hypotheses, which is the strategy followed in several systems. 1 Introduction In this paper, we study core aspects of discriminative alignment systems [1, 2]. In these systems, the best alignment hypothesis is the one that maximises a linear combination of features. In Sect. 2 we propose some improvements of the beam-search algorithm implemented by Moore [1]. Then we present experimental results for different low-computational-cost word association score features (Sect. 3.1) and for the proposed search strategies (Sect. 3.2). Finally, we give some conclusions. 2 Search Strategies Search aims at finding the alignment (i.e. the set of links between source and target words) which maximises the sum of each feature cost, weighted by its respective weig"
2008.eamt-1.15,J00-2004,0,0.695757,"lty, the hypothesis with the new link is better than the previous one. In the example of Fig. 2 (left figure), suppose that this was the case successively for links 1-2, 3-3 and 0-0, so that the best alignment hypothesis is {1-2, 3-3, 0-0}. Now if this hypothesis is expanded with link 2-2, the association cost is compensated by the decrease of the unlinked feature cost for “state”, and the new best hypothesis will include link 2-2. Expanding now this last hypothesis with link 2-1, the unlinked feature gain for “pais” cannot compensate for the distortion feature cost (due to crossing 4 Melamed [3] also starts with the empty alignment and links are added from most to least probable. 98 12th EAMT conference, 22-23 September 2008, Hamburg, Germany Fig. 2. Left: Baseline search: link-by-link search following word association score order [1]. Right: “source-word-score” search strategy. with “member-miembr”) plus the association cost. Thus link 2-1 is not included in the final hypothesis. On the contrary, if we would expand the hypotheses with link 2-1 first, the double unlinked feature gain (for “pais” and “state”) would compensate for the other costs, and link 2-1 would appear in the final"
2008.eamt-1.15,J03-1002,0,0.0219937,"This is much more efficient than Liu et al.’s search [2], which considers all possible links before selecting each link. http://gps-tsc.upc.es/veu/LR 100 12th EAMT conference, 22-23 September 2008, Hamburg, Germany contains 1.28 million sentence pairs of respectively 27.2 and 28.5 words length in average for English and Spanish. English and Spanish vocabulary size are respectively 106 and 153 thousand words. We divided randomly the alignment reference corpus in a 246-sentence development set and a 245-sentence test set. Evaluation was done with precision, recall and alignment error rate (AER) [5]. 3.1 Basic Word Association Models Our aim in this section is to compare very simple word association measures reported in the literature and which can be very useful for some applications. Cherry and Lin [6] and Lambert et al. [7] use χ2 scores [8]. However, Dunning [9] showed that the log-likelihood ratio (LLR) was a better method of accounting for rare events occurring in large samples. χ2 score indeed overestimates their significance. For example, the association between two singletons cooccurring in the same sentence pair gets the best possible χ2 score, and this association is 4 orders"
2008.eamt-1.15,P03-1012,0,0.0195281,"rmany contains 1.28 million sentence pairs of respectively 27.2 and 28.5 words length in average for English and Spanish. English and Spanish vocabulary size are respectively 106 and 153 thousand words. We divided randomly the alignment reference corpus in a 246-sentence development set and a 245-sentence test set. Evaluation was done with precision, recall and alignment error rate (AER) [5]. 3.1 Basic Word Association Models Our aim in this section is to compare very simple word association measures reported in the literature and which can be very useful for some applications. Cherry and Lin [6] and Lambert et al. [7] use χ2 scores [8]. However, Dunning [9] showed that the log-likelihood ratio (LLR) was a better method of accounting for rare events occurring in large samples. χ2 score indeed overestimates their significance. For example, the association between two singletons cooccurring in the same sentence pair gets the best possible χ2 score, and this association is 4 orders of magnitude less than the best score according to the LLR statistics. The LLR score was used by Melamed [3] for automatically constructing translation lexicons and by Moore [1] as a word association feature."
2008.eamt-1.15,N07-2022,1,0.810924,"lion sentence pairs of respectively 27.2 and 28.5 words length in average for English and Spanish. English and Spanish vocabulary size are respectively 106 and 153 thousand words. We divided randomly the alignment reference corpus in a 246-sentence development set and a 245-sentence test set. Evaluation was done with precision, recall and alignment error rate (AER) [5]. 3.1 Basic Word Association Models Our aim in this section is to compare very simple word association measures reported in the literature and which can be very useful for some applications. Cherry and Lin [6] and Lambert et al. [7] use χ2 scores [8]. However, Dunning [9] showed that the log-likelihood ratio (LLR) was a better method of accounting for rare events occurring in large samples. χ2 score indeed overestimates their significance. For example, the association between two singletons cooccurring in the same sentence pair gets the best possible χ2 score, and this association is 4 orders of magnitude less than the best score according to the LLR statistics. The LLR score was used by Melamed [3] for automatically constructing translation lexicons and by Moore [1] as a word association feature. We compared these assoc"
2008.eamt-1.15,J93-1003,0,0.0715936,"and 28.5 words length in average for English and Spanish. English and Spanish vocabulary size are respectively 106 and 153 thousand words. We divided randomly the alignment reference corpus in a 246-sentence development set and a 245-sentence test set. Evaluation was done with precision, recall and alignment error rate (AER) [5]. 3.1 Basic Word Association Models Our aim in this section is to compare very simple word association measures reported in the literature and which can be very useful for some applications. Cherry and Lin [6] and Lambert et al. [7] use χ2 scores [8]. However, Dunning [9] showed that the log-likelihood ratio (LLR) was a better method of accounting for rare events occurring in large samples. χ2 score indeed overestimates their significance. For example, the association between two singletons cooccurring in the same sentence pair gets the best possible χ2 score, and this association is 4 orders of magnitude less than the best score according to the LLR statistics. The LLR score was used by Melamed [3] for automatically constructing translation lexicons and by Moore [1] as a word association feature. We compared these association measures to IBM model 1 probabili"
2008.eamt-1.15,J93-2003,0,0.0317814,"ed that the log-likelihood ratio (LLR) was a better method of accounting for rare events occurring in large samples. χ2 score indeed overestimates their significance. For example, the association between two singletons cooccurring in the same sentence pair gets the best possible χ2 score, and this association is 4 orders of magnitude less than the best score according to the LLR statistics. The LLR score was used by Melamed [3] for automatically constructing translation lexicons and by Moore [1] as a word association feature. We compared these association measures to IBM model 1 probabilities [10]. Table 1 shows the alignment results for a basic system composed of the following features: word association, link bonus, unlinked word penalty and two distortion features (counting the number and amplitude of crossing links). The value of the word association feature was calculated as the sum of the word association costs of the links present in the alignment. This cost was simply obtained by taking (minus) the logarithm of respectively the χ2 score, IBM model 1 probabilities or the LLR score normalised to 1. For IBM model 1 probabilities, we had two features, one for each direction (source-"
2008.eamt-1.15,W04-3243,0,0.0157457,"a 11 points drop in precision.7 IBM model 1 probabilities are better than association scores and yield a 3.5 points improvement over χ2 word association scores. Of course, state-of-the-art models like IBM model 4 are expected to perform better. In lines 1 to 3 of Table 1, the unlinked penalty feature is uniform. In the “IBM1+UM” system, this feature was substituted by a penalty proportional to model 1 NULL link probability, yielding a gain of 2 points in precision and 1 point in recall. 7 This result may be surprising at first sight. In fact, it makes sense. To take the same example as Moore [11], in our corpus, singletons appearing in each side of the same sentence pair constitute a very significant event. The IBM model 1 probability in this case is actually equal to 1, and the χ2 score is also the best possible. Although no word can have a higher LLR score with a singleton than another singleton, the LLR score between more frequent words can be much higher. This makes a difference because the alignment hypotheses are expanded with the most probable links first. Thus compared to χ2 , the LLR score gives a relatively higher importance to links involving frequent words, which may be st"
2008.eamt-1.15,H91-1026,0,\N,Missing
2008.iwslt-evaluation.17,J03-1002,0,0.00397375,"I1 maximizing a loglinear combination of several feature models [4]: - 116 - ( eˆI1 = arg max eI1 M X ) λm hm (eI1 , f1J ) m=1 where the feature functions hm refer to the system models and the set of λm refers to the weights corresponding to these models. Proceedings of IWSLT 2008, Hawaii - U.S.A. The N gram-based approach regards translation as a stochastic process maximizing the joint probability p(f, e), leading to a decomposition based on bilingual n-grams, socalled tuples, that are extracted from a word-to-word alignment (performed with GIZA++ tool1 and generated by growdiag-final method [5]). Given a certain word-aligned parallel corpus, tuples are extracted according to the following constraints [6]: languages capturing bilingual context, as described by the following equation: p(S, T ) = K Y p((˜ s, t˜)k |(˜ s, t˜)k−N +1 , ..., (˜ s, t˜)k−1 ) (1) k=1 where s refers to source, t to target, and (˜ s, t˜)k to the k tuple of a given bilingual sentence pair segmented in K tuples. The bilingual TM actually constitutes an n-gram-based language model (LM) of tuples, which approximates the joint probability between the languages under consideration and can be seen here as a LM, where t"
2008.iwslt-evaluation.17,N04-1033,0,0.0316825,"I1 , f1J ) m=1 where the feature functions hm refer to the system models and the set of λm refers to the weights corresponding to these models. Proceedings of IWSLT 2008, Hawaii - U.S.A. The N gram-based approach regards translation as a stochastic process maximizing the joint probability p(f, e), leading to a decomposition based on bilingual n-grams, socalled tuples, that are extracted from a word-to-word alignment (performed with GIZA++ tool1 and generated by growdiag-final method [5]). Given a certain word-aligned parallel corpus, tuples are extracted according to the following constraints [6]: languages capturing bilingual context, as described by the following equation: p(S, T ) = K Y p((˜ s, t˜)k |(˜ s, t˜)k−N +1 , ..., (˜ s, t˜)k−1 ) (1) k=1 where s refers to source, t to target, and (˜ s, t˜)k to the k tuple of a given bilingual sentence pair segmented in K tuples. The bilingual TM actually constitutes an n-gram-based language model (LM) of tuples, which approximates the joint probability between the languages under consideration and can be seen here as a LM, where the language is composed by tuples. th • a monotonic segmentation of each bilingual sentence pair is produced • n"
2008.iwslt-evaluation.17,W06-1609,1,0.710642,"2008, Hawaii - U.S.A. 2.5. Statistical Machine Reordering 3.1. Punctuation restoration The conception of the Statistical Machine Reordering (SMR) stems from the idea of using the powerful techniques developed for SMT and to translate the source language (S) into a reordered source language (S’), which more closely matches the order of the target language. To infer more reorderings, it makes use of word classes. To correctly integrate the SMT and SMR systems, both are concatenated by using a word graph which offers weighted reordering hypotheses to the SMT system. The details are described in [8] and [9]. We decided to embed punctuation restoration in the main translation step. For this purpose we preprocessed the training corpus as follows: 2.6. Translation models interpolation The resulting preprocessed training corpus is used to train a standard SMT system (wi stands for the i-th word). During the post-evaluation period we have implemented a TM interpolation strategy following the ideas proposed in [3], where the authors present a promising technique of target LMs linear interpolation. These findings open the way to involve additional monolingual information into the translation pr"
2008.iwslt-evaluation.17,W07-0721,1,0.843062,"awaii - U.S.A. 2.5. Statistical Machine Reordering 3.1. Punctuation restoration The conception of the Statistical Machine Reordering (SMR) stems from the idea of using the powerful techniques developed for SMT and to translate the source language (S) into a reordered source language (S’), which more closely matches the order of the target language. To infer more reorderings, it makes use of word classes. To correctly integrate the SMT and SMR systems, both are concatenated by using a word graph which offers weighted reordering hypotheses to the SMT system. The details are described in [8] and [9]. We decided to embed punctuation restoration in the main translation step. For this purpose we preprocessed the training corpus as follows: 2.6. Translation models interpolation The resulting preprocessed training corpus is used to train a standard SMT system (wi stands for the i-th word). During the post-evaluation period we have implemented a TM interpolation strategy following the ideas proposed in [3], where the authors present a promising technique of target LMs linear interpolation. These findings open the way to involve additional monolingual information into the translation process, a"
2008.iwslt-evaluation.17,2007.mtsummit-papers.29,0,0.0263997,"iod we have implemented a TM interpolation strategy following the ideas proposed in [3], where the authors present a promising technique of target LMs linear interpolation. These findings open the way to involve additional monolingual information into the translation process, and also gives a motivation to interpolate the translation and reordering tables in a linear way. Due to a small amount of available in-domain data (IWSLT training material), we have used an out-of-domain 130K-line subset from the Arabic News, English Translation of Arabic Treebank and Ummah LDC parallel corpora (VIOLIN) [10] to increase the final translation and reordering tables. Both corpus statistics can be found in table 1. Instead of time-consuming iterative TM reconstruction and using the highest BLEU score as an maximization criteria, we adjust the weights as a function of the lowest perplexity estimated by the corresponding interpolated combination of the target-side LMs and generalize the optimization results on the interpolated translation and reordering models. The word-to-word alignment was obtained from the joint database (IWSLT + VIOLIN). Then, we separately computed the translation and reordering t"
2008.iwslt-evaluation.17,P07-2045,0,0.0159161,"ssion Corpus (BTEC) Arabic to English translation task. The model weights were tuned with the 2006 development corpus (Dev6), containing 489 sentences and 6 reference translations and the 2002 development set (500 sentences and 16 reference translations) was used as an internal test, according to which we take a decision about better or worse system performance. 4.1.1. Arabic data preprocessing In this section we present a phrase-based MT system that was used in the evaluation. This system is based on the well-known MOSES2 toolkit, which is nowadays considered as a state-of-the-art SMT system [11]. The training and weights tuning procedures are explained in details in the above-mentioned publication, as well as, on the MOSES web page: http://www.statmt.org/moses/. 2 www.statmt.org/moses/ We used a similar approach to that shown in [12], namely the MADA+TOKAN system for disambiguation and tokenization. For disambiguation only diacritic unigram statistics were employed. For tokenization we used the D3 scheme with -TAGBIES option. The scheme splits the following set of enclitics: w+, f+, b+, k+, l+, Al+ and pronominal enclitics. The -TAGBIES option produces Bies POS tags on all taggable t"
2008.iwslt-evaluation.17,N06-2013,0,0.0588409,"anslations) was used as an internal test, according to which we take a decision about better or worse system performance. 4.1.1. Arabic data preprocessing In this section we present a phrase-based MT system that was used in the evaluation. This system is based on the well-known MOSES2 toolkit, which is nowadays considered as a state-of-the-art SMT system [11]. The training and weights tuning procedures are explained in details in the above-mentioned publication, as well as, on the MOSES web page: http://www.statmt.org/moses/. 2 www.statmt.org/moses/ We used a similar approach to that shown in [12], namely the MADA+TOKAN system for disambiguation and tokenization. For disambiguation only diacritic unigram statistics were employed. For tokenization we used the D3 scheme with -TAGBIES option. The scheme splits the following set of enclitics: w+, f+, b+, k+, l+, Al+ and pronominal enclitics. The -TAGBIES option produces Bies POS tags on all taggable tokens. 3 http://www.slc.atr.jp/IWSLT2008/ - 118 - Proceedings of IWSLT 2008, Hawaii - U.S.A. Sentences Words Average sentence length Vocabulary IWSLT Arabic 24.45 K 170.24 K 6.96 10.89 K English 24.45 K 188.54 K 7.71 6.92 K VIOLIN Arabic 130.5"
2008.iwslt-evaluation.17,2005.iwslt-1.8,0,0.0320169,"n”) outperforms BTEC-only system by 1.8 BLEU points and 1.2 METEOR points for the CRR track and by 2.1 BLEU points and by about 1 METEOR points for the ASR track measured on the official evaluation test set. ”Supplied 2” line stands for the results obtained with the TALPtuples system as described in sub-section 4.1.3. - 119 - • TM(s), direct and inverse phrase/word based TM. • Distortion model, which assigns a cost linear to the reordering distance, while the cost is based on the number of source words which are skipped when translating a new source phrase. • Lexicalized word reordering model [15]. • Word and phrase penalties, which count the number of words and phrases in the target string. • Target-side LM. The TM and reordering model were trained using the standard MOSES tools. Weights of feature functions were tuned by using the optimization tools from the MOSES package. The search operation was accomplished by MOSES decoder. The experiments with the Chinese to English MT were carried out on the BTEC Chinese-English data [16] augmented with HIT-corpus4 , Olympic-corpus5 and PKUcorpus6 from Chinese LDC. 20K BTEC sentence pairs were supplied for the IWSLT 2008 evaluation campaign. HI"
2008.iwslt-evaluation.17,takezawa-etal-2002-toward,0,0.0149266,"ng distance, while the cost is based on the number of source words which are skipped when translating a new source phrase. • Lexicalized word reordering model [15]. • Word and phrase penalties, which count the number of words and phrases in the target string. • Target-side LM. The TM and reordering model were trained using the standard MOSES tools. Weights of feature functions were tuned by using the optimization tools from the MOSES package. The search operation was accomplished by MOSES decoder. The experiments with the Chinese to English MT were carried out on the BTEC Chinese-English data [16] augmented with HIT-corpus4 , Olympic-corpus5 and PKUcorpus6 from Chinese LDC. 20K BTEC sentence pairs were supplied for the IWSLT 2008 evaluation campaign. HIT corpus contains 132K sentence pairs in total, and is known as a multi-source ChineseEnglish parallel corpus; Olympic corpus has 54K bilingual sentences mainly from sport and travelling domains; while PKU-corpus has about 200K parallel phrases and is considered as a domain-balanced corpus. Besides, the English part of the Tanaka corpus7 was used as a complementary training 4 http://mitlab.hit.edu.cn/index.php/resources 5 http://www.chin"
2008.iwslt-evaluation.17,W03-1730,0,0.0212439,"OR)/2 0.6016 0.6055 0.6210 0.5892 0.5320 0.5320 0.5473 0.5296 NIST 8.5253 8.5940 8.8772 8.7421 7.2878 7.2808 7.6113 7.5862 Table 2: Official and post-evaluation results for Arabic-English translation. Sentences Words Vocabulary Chinese 19,972 164K 8,506 IWSLT’08 English Spanish 19,972 19,972 182K 147K 8,301 16,953 All additional data Chinese English 379,065 379,065 4,834K 5,036K 57,055 75,156 Table 3: Corpus used during the Chinese-English training material for the target-side LM. The I2R research group performed word segmentation for the Chinese part using ICTCLAS tools8 developed in the ICT [17]. Table 3 reports the basic statistics of the principal and additional corpora that were used to build the Chinese-toEnglish SMT system. Regarding English-to-Spanish translation, no extra corpora were used. “you ’re”, and negations like “don’t”, “wouldn’t” or “can’t” were split as “do n’t”, “would n’t” and “ca n’t”. The output of this system was performed in accordance with the official evaluation specification, without any postprocessing needed. Table 5 shows the results of the EnglishSpanish system trained with the BTEC corpus. 4.2.1. Chinese-English independent results The union of the BTEC"
2008.iwslt-evaluation.17,N04-1022,0,0.0541414,"and “you’re” were split as “we ’ll” and 8 http://www.nlp.org.cn/project/project.php?proj BLEU NIST METEOR id=6 - 120 - Our primary approach to the pivot task was a system cascade. Using the 50-best list of translation hypotheses generated by the decoder for the Chinese-to-English system, a 4-best list was made for each of the first list instances, totally representing a 200-best of possible Spanish translations for each Chinese sentence. From that 200-best list, which is allowed for repetitions, the single-best translation was computed using a Minimum Bayes Risk (MBR) strategy as described in [18]. We used the MOSES implementation of the MBR algorithm. This strategy of 200-best list rescoring performed better than a single-best list selection for both systems, gaining 2.5 BLEU points in the development set. Proceedings of IWSLT 2008, Hawaii - U.S.A. 4.2.4. Secondary submission As an alternative approach to the system cascade, we followed a different strategy for the secondary submission combining the phrase translation probabilities of the two language pairs (Chinese-English and English-Spanish translations) with the strategy proposed in [19] to obtain the translation probabilities for"
2008.iwslt-evaluation.17,P07-1108,0,0.0348074,"m Bayes Risk (MBR) strategy as described in [18]. We used the MOSES implementation of the MBR algorithm. This strategy of 200-best list rescoring performed better than a single-best list selection for both systems, gaining 2.5 BLEU points in the development set. Proceedings of IWSLT 2008, Hawaii - U.S.A. 4.2.4. Secondary submission As an alternative approach to the system cascade, we followed a different strategy for the secondary submission combining the phrase translation probabilities of the two language pairs (Chinese-English and English-Spanish translations) with the strategy proposed in [19] to obtain the translation probabilities for each Chinese-Spanish phrase. The final phrase probabilities are calculated as followed: φ(fi |ei ) = X φ(fi |pi )φ(pi |ei ) (2) pi where φ(fi |ei ) corresponds to the translation probability of the Chinese phrase fi given the Spanish phrase ei , φ(fi |pi ) stands for the translation probability of the Chinese phrase fi given the English phrase pi and φ(pi |ei ) stands for the translation probability of the English phrase pi given the Spanish phrase ei . It is important to mention that the English and Spanish phrases are lowercased in this system and"
2008.iwslt-evaluation.17,carreras-etal-2004-freeling,0,0.029059,"6 sentences with 16 Spanish references for tuning the system. The basic statistics of this corpus can be seen in table 7. 4.3.1. Data preprocessing The Chinese corpus was not preprocessed before translation: the corpus was tokenized by words and the punctuation marks were separated. Note that the TM, as well as the LM and reordering model, was trained with punctuation marks and the official test set that did not contain this information, therefore it was preprocessed with the hidden-ngram tool to restore it. The Spanish part of the corpus was lowercased and tokenized using the Freeling toolkit[20], an open source tool for language analysis. It splitted the enclitics from the Spanish verbs (d´amelo → da +me +lo) and also generated the POS tags that were lately used to estimate a target-side POS LM and in postprocessing. 4.3.2. Data postprocessing Once the decoding process had finished, the output of the system was still lowercased and splitted with the enclitics and the POS tags were generated. Afterwards, a postprocess including two steps was performed: firstly, the original morphological verbs form was restored using the enclitics and POS tags information; on the next step, the case i"
2008.iwslt-evaluation.17,2007.iwslt-1.1,0,\N,Missing
2008.iwslt-evaluation.17,2006.iwslt-evaluation.1,0,\N,Missing
2009.iwslt-evaluation.3,2007.tmi-papers.28,0,0.0210389,"ith the - 24 - novel technique. Section 6 discusses the results obtained on the evaluation campaign and, finally, Section 7 presents the conclusions. 2. Related work The phrase-based translation model allows to introduce both source and target context information in comparison to the word-based translation model. However, the idea of introducing context information is simplified in the phrase-based systems given that all training sentences contribute equally to the final translation. More complex works which introduce source context information can be found in the SMT literature. For example, [10, 4] incorporate source language context using neighbouring words, part-of-speech tags and/or supertags. They use a memory-based classification approach to obtain the probability for the given additional contexts with the source phrase. Works such as [2] embed context-rich approaches from Word Sense Disambiguation methods. Other related works focus on extending the translation and target language model using neural networks [8] which aims at smoothing both the translation and target language model in order to use the n-grams more adequate in the translated sentence. 3. Phrase-based Baseline System"
2009.iwslt-evaluation.3,takezawa-etal-2002-toward,0,0.0155654,"re more, optimized with a modified mert algorithm which translates one sentence at a time. The resulting increment in translation time (i.e. the optimization time as well) is around three times with respect to the translation time of the standard Moses baseline system. The proposed methodology is graphically illustrated in Figure 1. - 25 - Figure 1: Example of source context information methodology. 5. Experiments We participated on the Arabic and Chinese to English BTEC task (correct recognition results). Experiments with the Arabic and Chinese to English MT were carried out on the BTEC data [11]. Corpus statistics are shown Tables 1, 2 and 3. Model weights were tuned with the 2006 development corpus (Dev6), containing 489 sentences and 6 reference translations. The internal test set was the 2007 development set (486 sentences and 16 reference translations), according to which we make a decision about better or worse system performance. Weights obtained in the optimization where used as well for the evaluation test. However, in the evaluation campaign, we concatenated the training, development and test sets from Table 1, 2, 3 and we used the concatenation as training data for translat"
2009.iwslt-evaluation.3,D07-1007,0,0.209434,"formation in comparison to the word-based translation model. However, the idea of introducing context information is simplified in the phrase-based systems given that all training sentences contribute equally to the final translation. More complex works which introduce source context information can be found in the SMT literature. For example, [10, 4] incorporate source language context using neighbouring words, part-of-speech tags and/or supertags. They use a memory-based classification approach to obtain the probability for the given additional contexts with the source phrase. Works such as [2] embed context-rich approaches from Word Sense Disambiguation methods. Other related works focus on extending the translation and target language model using neural networks [8] which aims at smoothing both the translation and target language model in order to use the n-grams more adequate in the translated sentence. 3. Phrase-based Baseline System The basic idea of phrase-based translation is to segment the given source sentence into units (hereinafter called phrases), then translate each phrase and finally compose the target sentence from these phrase translations. Basically, a bilingual phr"
2009.iwslt-evaluation.3,N04-4026,0,0.0277623,"stems were phrase-based systems as described in Section 3 and both were based on MOSES open source package [6]. IBM word reordering constraints [1] were applied during decoding to reduce the computational complexity. The other models and feature functions employed by MOSES decoder were: • TM(s), direct and inverse phrase/word based TM (10 words as maximum length per phrase). • Distortion model, which assigns a cost linear to the reordering distance, while the cost is based on the number of source words which are skipped when translating a new source phrase. • Lexicalized word reordering model [5, 12]. • Word and phrase penalties, which count the number of words and phrases in the target string. • Target-side LM (4-gram). Table 2: Chinese training, development, test and evaluation sets. The TM and reordering model were trained using the standard MOSES tools. Weights of feature functions were tuned by using the optimization tools from the MOSES package. The search operation was accomplished by MOSES decoder. In the primary submission, we introduced context information as explained in Section 4. Several tools provided in the Moses package were modified in order to introduce the novel techniq"
2009.iwslt-evaluation.3,N06-2013,0,0.0276593,"ions. The internal test set was the 2007 development set (486 sentences and 16 reference translations), according to which we make a decision about better or worse system performance. Weights obtained in the optimization where used as well for the evaluation test. However, in the evaluation campaign, we concatenated the training, development and test sets from Table 1, 2, 3 and we used the concatenation as training data for translating the evaluation set. 5.1. Arabic data One first run we participated was the Arabic to English BTEC translation task. We used a similar approach to that shown in [3], namely the MADA+TOKAN system for disambiguation and tokenization. For disambiguation only diacritic unigram statistics were employed. For tokenization we used the D3 scheme with -TAGBIES option. The scheme splits the following set of enclitics: w+, f+, b+, k+, l+, Al+ and pronominal enclitics. The -TAGBIES option produces Bies POS tags on all taggable tokens. Table 1 gives details about the training, developement and test set that we used to make experiments. The first column shows the Arabic corpus statistics without processing and the second column shows the Arabic corpus statistics after"
2009.iwslt-evaluation.3,2009.eamt-1.32,0,0.0144978,"ith the - 24 - novel technique. Section 6 discusses the results obtained on the evaluation campaign and, finally, Section 7 presents the conclusions. 2. Related work The phrase-based translation model allows to introduce both source and target context information in comparison to the word-based translation model. However, the idea of introducing context information is simplified in the phrase-based systems given that all training sentences contribute equally to the final translation. More complex works which introduce source context information can be found in the SMT literature. For example, [10, 4] incorporate source language context using neighbouring words, part-of-speech tags and/or supertags. They use a memory-based classification approach to obtain the probability for the given additional contexts with the source phrase. Works such as [2] embed context-rich approaches from Word Sense Disambiguation methods. Other related works focus on extending the translation and target language model using neural networks [8] which aims at smoothing both the translation and target language model in order to use the n-grams more adequate in the translated sentence. 3. Phrase-based Baseline System"
2009.iwslt-evaluation.3,2005.iwslt-1.8,0,0.0324938,"stems were phrase-based systems as described in Section 3 and both were based on MOSES open source package [6]. IBM word reordering constraints [1] were applied during decoding to reduce the computational complexity. The other models and feature functions employed by MOSES decoder were: • TM(s), direct and inverse phrase/word based TM (10 words as maximum length per phrase). • Distortion model, which assigns a cost linear to the reordering distance, while the cost is based on the number of source words which are skipped when translating a new source phrase. • Lexicalized word reordering model [5, 12]. • Word and phrase penalties, which count the number of words and phrases in the target string. • Target-side LM (4-gram). Table 2: Chinese training, development, test and evaluation sets. The TM and reordering model were trained using the standard MOSES tools. Weights of feature functions were tuned by using the optimization tools from the MOSES package. The search operation was accomplished by MOSES decoder. In the primary submission, we introduced context information as explained in Section 4. Several tools provided in the Moses package were modified in order to introduce the novel techniq"
2009.iwslt-evaluation.3,P07-2045,0,0.0054081,"21 820 - Table 3: English training, development, test and evaluation sets before the preprocessing (English) and after (English’) Table 1: Arabic training, development, test and evaluation sets before the preprocessing (Arabic) and after (Arabic’) Training Sentences Words Vocabulary Sentences Words Vocabulary Sentences Words Vocabulary Chinese 21,484 182,2k 8,773 489 3,169 881 507 3,352 888 469 3,019 859 a contrastive system we submitted the MOSES-based system. Both Machine Translation Systems were phrase-based systems as described in Section 3 and both were based on MOSES open source package [6]. IBM word reordering constraints [1] were applied during decoding to reduce the computational complexity. The other models and feature functions employed by MOSES decoder were: • TM(s), direct and inverse phrase/word based TM (10 words as maximum length per phrase). • Distortion model, which assigns a cost linear to the reordering distance, while the cost is based on the number of source words which are skipped when translating a new source phrase. • Lexicalized word reordering model [5, 12]. • Word and phrase penalties, which count the number of words and phrases in the target string. • Targ"
2009.iwslt-evaluation.3,D07-1045,1,0.856591,"ng sentences contribute equally to the final translation. More complex works which introduce source context information can be found in the SMT literature. For example, [10, 4] incorporate source language context using neighbouring words, part-of-speech tags and/or supertags. They use a memory-based classification approach to obtain the probability for the given additional contexts with the source phrase. Works such as [2] embed context-rich approaches from Word Sense Disambiguation methods. Other related works focus on extending the translation and target language model using neural networks [8] which aims at smoothing both the translation and target language model in order to use the n-grams more adequate in the translated sentence. 3. Phrase-based Baseline System The basic idea of phrase-based translation is to segment the given source sentence into units (hereinafter called phrases), then translate each phrase and finally compose the target sentence from these phrase translations. Basically, a bilingual phrase is a pair of m source words and n target words. For extraction from a bilingual word aligned training corpus, two additional constraints are considered: 1. the words are con"
2010.eamt-1.17,W06-1009,0,0.0232147,"ure function which is ‘1’ in case of appearing in both segmentations or ’0’ in the opposite case. 5 Experimental framework The phrase-based system used in this paper is based on the well-known MOSES toolkit, which is nowadays considered as a state-of-theart SMT system (Koehn et al., 2007). The training and weights tuning procedures are explained in details in the above-mentioned publication, as well as, on the MOSES web page: http://www.statmt.org/moses/. 5.1 Corpus statistics Experiments were carried out on the English to Spanish Bible task, which have been proven to be a valid NLP resource (Chew et al., 2006). The main advantages of using this corpus are that it is the world’s most translated book, with translations in over 2,100 languages (often, multiple translations per language) and easy availability, often in electronic form and in the public domain; it covers a variety of literary styles including narrative, poetry, and correspondence; great care is taken over the translations; it has a standard structure which Figure 4: Example of the phrase extraction process in the CONCAT approach. New phrases added by the collocation-based system are marked with a ∗∗. allows parallel alignment on a verse"
2010.eamt-1.17,W06-2402,1,0.789473,"ociation for Machine Translation. Introducing chunking in the standard phrasebased SMT system is a relatively frequent study (Zhou et al., 2004; Wang et al., 2002; Ma et al., 2007). Chunking may be used either to improve reordering or to enhance the translation table. For example, authors in (Zhang et al., 2007) present a shallow chunking based on syntactic information and they use the chunks to reorder phrases. Other studies report the impact on the quality of word alignment and in translation after using various types of multi-word expressions which can be regarded as a type of chunks, see (Lambert and Banchs, 2006) or sub-sentential sequences (Macken et al., 2008; Groves and Way, 2005). Chunking is usually performed on a syntactic or semantic basis which forces to have a tool for parsing or similar. We propose to introduce the collocation segmentation developed by (Daudaravicius, 2009) which is language independent. This collocation segmentation was applied in keyword assigment task and a high classification improvement was achieved (Daudaravicius, 2010). We use this collocation segmentation technique to enrich the phrase translation table. The phrase translation table is composed of phrase units which"
2010.eamt-1.17,2007.tmi-papers.14,0,0.0199906,"is the phrase-based system (Koehn et al., 2003) which implements a maximum entropy approach based on a combination of feature functions. The Moses system (Koehn et al., 2007) is an implementation of this phrase-based machine translation approach. An input sentence is first split into sequences of words (so-called phrases), which are then mapped one-to-one to target phrases using a large phrase translation table. c 2010 European Association for Machine Translation. Introducing chunking in the standard phrasebased SMT system is a relatively frequent study (Zhou et al., 2004; Wang et al., 2002; Ma et al., 2007). Chunking may be used either to improve reordering or to enhance the translation table. For example, authors in (Zhang et al., 2007) present a shallow chunking based on syntactic information and they use the chunks to reorder phrases. Other studies report the impact on the quality of word alignment and in translation after using various types of multi-word expressions which can be regarded as a type of chunks, see (Lambert and Banchs, 2006) or sub-sentential sequences (Macken et al., 2008; Groves and Way, 2005). Chunking is usually performed on a syntactic or semantic basis which forces to ha"
2010.eamt-1.17,C08-1067,0,0.015889,"in the standard phrasebased SMT system is a relatively frequent study (Zhou et al., 2004; Wang et al., 2002; Ma et al., 2007). Chunking may be used either to improve reordering or to enhance the translation table. For example, authors in (Zhang et al., 2007) present a shallow chunking based on syntactic information and they use the chunks to reorder phrases. Other studies report the impact on the quality of word alignment and in translation after using various types of multi-word expressions which can be regarded as a type of chunks, see (Lambert and Banchs, 2006) or sub-sentential sequences (Macken et al., 2008; Groves and Way, 2005). Chunking is usually performed on a syntactic or semantic basis which forces to have a tool for parsing or similar. We propose to introduce the collocation segmentation developed by (Daudaravicius, 2009) which is language independent. This collocation segmentation was applied in keyword assigment task and a high classification improvement was achieved (Daudaravicius, 2010). We use this collocation segmentation technique to enrich the phrase translation table. The phrase translation table is composed of phrase units which generally are extracted from a word aligned paral"
2010.eamt-1.17,J96-1001,0,0.487108,"Missing"
2010.eamt-1.17,J93-1007,0,0.933659,"same phrase. This paper is organized as follows. First, we detail the different collocation segmentation techniques proposed. Secondly, we make a brief description of the phrase-based SMT system and how we introduce the collocation segmentation to improve the phrase-based SMT system. Then, we present experiments performed in an standard phrase-based system comparing the phrase extraction. Finally, we present the conclusions. 2 Collocation segmentation The Dice score is used to measure the association strength of two words. This score is used, for instance, in the collocation compiler XTract (Smadja, 1993) and in the lexicon extraction system Champollion (Smadja and Hatzivassiloglou, 1996). Dice is defined as follows: Dice(x; y) = 2f (x, y) f (x) + f (y) where f (x, y) is the frequency of co-occurrence of x and y, and f (x) and f (y) the frequencies of occurrence of x and y anywhere in the text. If x and y tend to occur in conjunction, their Dice score will be high. The text is seen as a changing curve of the word associativity values (see Figure 1 and Figure 2). The collocation segmentation is the process of detecting the boundaries of collocation segments within a text. A collocation segment"
2010.eamt-1.17,W00-0726,0,0.176514,"Missing"
2010.eamt-1.17,N03-1017,0,0.0169827,"ent over 0.7 BLEU absolute) are achieved in translation quality. 1 Introduction Machine Translation (MT) investigates the use of computer software to translate text or speech from one language to another. Statistical machine translation (SMT) has become one of the most popular MT approaches given the combination of several factors. Among them, it is relatively straightforward to build an SMT system given the freely available software and, additionally, the system construction does not require of any language experts. Nowadays, one of the most popular SMT approaches is the phrase-based system (Koehn et al., 2003) which implements a maximum entropy approach based on a combination of feature functions. The Moses system (Koehn et al., 2007) is an implementation of this phrase-based machine translation approach. An input sentence is first split into sequences of words (so-called phrases), which are then mapped one-to-one to target phrases using a large phrase translation table. c 2010 European Association for Machine Translation. Introducing chunking in the standard phrasebased SMT system is a relatively frequent study (Zhou et al., 2004; Wang et al., 2002; Ma et al., 2007). Chunking may be used either to"
2010.eamt-1.17,P07-2045,0,0.0104666,"f computer software to translate text or speech from one language to another. Statistical machine translation (SMT) has become one of the most popular MT approaches given the combination of several factors. Among them, it is relatively straightforward to build an SMT system given the freely available software and, additionally, the system construction does not require of any language experts. Nowadays, one of the most popular SMT approaches is the phrase-based system (Koehn et al., 2003) which implements a maximum entropy approach based on a combination of feature functions. The Moses system (Koehn et al., 2007) is an implementation of this phrase-based machine translation approach. An input sentence is first split into sequences of words (so-called phrases), which are then mapped one-to-one to target phrases using a large phrase translation table. c 2010 European Association for Machine Translation. Introducing chunking in the standard phrasebased SMT system is a relatively frequent study (Zhou et al., 2004; Wang et al., 2002; Ma et al., 2007). Chunking may be used either to improve reordering or to enhance the translation table. For example, authors in (Zhang et al., 2007) present a shallow chunkin"
2010.eamt-1.17,2002.tmi-tutorials.2,0,0.0275678,"ch forces to have a tool for parsing or similar. We propose to introduce the collocation segmentation developed by (Daudaravicius, 2009) which is language independent. This collocation segmentation was applied in keyword assigment task and a high classification improvement was achieved (Daudaravicius, 2010). We use this collocation segmentation technique to enrich the phrase translation table. The phrase translation table is composed of phrase units which generally are extracted from a word aligned parallel corpus. Given this word alignment, an extraction of contiguous phrases is carried out (Zens et al., 2002), specifically all extracted phrases fulfill the following restrictions: all source (target) words within a phrase are aligned only to target (source) words within the same phrase. This paper is organized as follows. First, we detail the different collocation segmentation techniques proposed. Secondly, we make a brief description of the phrase-based SMT system and how we introduce the collocation segmentation to improve the phrase-based SMT system. Then, we present experiments performed in an standard phrase-based system comparing the phrase extraction. Finally, we present the conclusions. 2 C"
2010.eamt-1.17,W07-0401,0,0.0282134,"ctions. The Moses system (Koehn et al., 2007) is an implementation of this phrase-based machine translation approach. An input sentence is first split into sequences of words (so-called phrases), which are then mapped one-to-one to target phrases using a large phrase translation table. c 2010 European Association for Machine Translation. Introducing chunking in the standard phrasebased SMT system is a relatively frequent study (Zhou et al., 2004; Wang et al., 2002; Ma et al., 2007). Chunking may be used either to improve reordering or to enhance the translation table. For example, authors in (Zhang et al., 2007) present a shallow chunking based on syntactic information and they use the chunks to reorder phrases. Other studies report the impact on the quality of word alignment and in translation after using various types of multi-word expressions which can be regarded as a type of chunks, see (Lambert and Banchs, 2006) or sub-sentential sequences (Macken et al., 2008; Groves and Way, 2005). Chunking is usually performed on a syntactic or semantic basis which forces to have a tool for parsing or similar. We propose to introduce the collocation segmentation developed by (Daudaravicius, 2009) which is la"
2010.iwslt-evaluation.26,2010.eamt-1.17,1,0.915535,"ase is a pair of m source words and n target words. For extraction from a bilingual word aligned training corpus, two additional constraints are considered: similar threshold definition conditions for different associativity measures. Different associativity measures have different scale of values and it is difficult to set threshold manually. Threshold level is kept as low as possible. Higher threshold value makes shorter collocation segments and vice versa. Shorter collocation segments are more confident collocations and we may expect better translation results. Nevertheless, the results of [3] show that longer collocation segments are more preferable. There are many associativity measures that could be used to calculate the associativity values between tokens (a more comprehensive list could be found in [11]). To explore different measures we included the six following metrics: 1. Mutual Information (MI): M I(wi , wi+1 ) = N ∗ f (wi , wi+1 ) f (w1 ) + f (wi+1 ) dice(wi , wi+1 ) = 2 ∗ f (wi , wi+1 ) f (wi ) + f (wi+1 ) 1. the words are consecutive, and, 2. they are consistent with the word alignment matrix. Given the collected phrase pairs, the phrase translation probability distrib"
2010.iwslt-evaluation.26,J04-4002,0,0.0195448,"segmented data into the phrase-based system. As follows, Section 6 shows the experimental details of the system and the experiments performed with the novel technique. Finally, Section 7 presents the conclusions. 2. Related work One of the main problems in the statistical machine translation approach is how to segment the bilingual corpus in order to build the most appropriate translation dictionary. Standard phrase-based SMT systems first align the parallel corpus at the word level by using IBM probabilities and then use standard constraints (see section 3) to extract final translation units [10]. Variations of this type of segmentation can be found in [8, 1, 6]. Other approaches consist in integrating the phrase segmentation and alignment, one example is in [14] where they use the point-wise mutual information between the source and target words to identify aligned phrase pairs. In [9] they use a greedy algorithm to compute recursive alignments from a bilingual parallel corpus. Here, we propose to combine the standard phrase-based segmentation [10] with a complementary bilingual segmentation which is learned from a statistical collocation segmen189 Proceedings of the 7th Internationa"
2010.iwslt-evaluation.26,P06-2084,0,0.0305339,"tivity measures. Different associativity measures have different scale of values and it is difficult to set threshold manually. Threshold level is kept as low as possible. Higher threshold value makes shorter collocation segments and vice versa. Shorter collocation segments are more confident collocations and we may expect better translation results. Nevertheless, the results of [3] show that longer collocation segments are more preferable. There are many associativity measures that could be used to calculate the associativity values between tokens (a more comprehensive list could be found in [11]). To explore different measures we included the six following metrics: 1. Mutual Information (MI): M I(wi , wi+1 ) = N ∗ f (wi , wi+1 ) f (w1 ) + f (wi+1 ) dice(wi , wi+1 ) = 2 ∗ f (wi , wi+1 ) f (wi ) + f (wi+1 ) 1. the words are consecutive, and, 2. they are consistent with the word alignment matrix. Given the collected phrase pairs, the phrase translation probability distribution is commonly estimated by relative frequency in both directions. The translation model is combined together with the following six additional feature models: the target language model, the word and the phrase bonus"
2010.iwslt-evaluation.26,J93-1007,0,0.203913,", four tokens). The boundary of a segment is set between adjacent tokens when the value of associativity between these two adjacent tokens is lower than the average of preceding and following associativity values. Some examples of segmentation of English and French sentences are presented in Table 1. The result of collocation segmentation is a segmented text, no dictionaries are produces and no evaluation of segments is made. The segmented text could be used to create a dictionary of collocations. Such dictionary accepts all collocation segments. The main difference from Choueka [2] and Smadja[12] methods is that collocation segmentation accepts all collocations and no significance tests for collocations are performed. The main advantage of this segmentation is the ability to perform collocation segmentation of both small and large corpora, and no manually segmented corpora or other databases and language processing tools are required. 5. Introducing the collocation segmentation into a phrase-based system In order to build the augmented phrase table with the technique mentioned in section 4, we segmented each language of the bilingual corpus independently and then, using the collocatio"
2010.iwslt-evaluation.26,takezawa-etal-2002-toward,0,0.0385848,"integrate the baseline segmentation with the new phrases (hereinafter, collocation segmentation new phrases) or the baseline segmentation with the existing phrases (hereinafter, collocation segmentation smooth). chi2(wi , wi+1 ) = N = f (wi ) ∗ f (wi+1 ) N ∗ f (wi , wi+1 ) − f (wi ) ∗ f (wi+1 ) ∗ N − f (wi ) + f (wi , wi+1 ) N ∗ f (wi , wi+1 ) − f (wi ) ∗ f (wi+1 ) ∗ N − f (wi+1 ) + f (wi , wi+1 ) 5. Gravity-Counts (GC)[5]: gc(wi , wi+1 ) =   f (wi ) ∗ f (wi , wi+1 ) = log n(wi )   f (wi+1 ) ∗ f (wi , wi+1 ) +log n0 (wi+1 ) 6. Experiments We participated in the French-to-English BTEC task [13] in the correct recognition results. We build our baseline system using MOSES with the standard configuration http://www.statmt.org/moses/. 6. T-score: tscore(wi , wi+1 ) = f (wi , wi+1 ) − f (wi )fN(wi+1 ) p f (wi , wi+1 ) The next step after setting the associativity threshold boundaries is to apply an average minimum law (AML) as described in [3] and [4]. The average minimum law is applied to the three adjacent associativity values (i.e., four tokens). The boundary of a segment is set between adjacent tokens when the value of associativity between these two adjacent tokens is lower than the"
2010.iwslt-evaluation.26,W10-1712,1,0.834596,"systems. 1. Introduction The Universitat Polit`ecnica de Catalunya (UPC), Barcelona Media Innovation Center (BMIC) and Vytautas Magnus University (VMU) participated together in the IWSLT 2010 evaluation campaign. This paper describes the UPC-BMICVMU system, which is basically a statistical phrase-based system enriched with collocation segmentation information. Adding a novel segmentation in an SMT system allows to enrich the translation dictionary and/or to smooth the existing translation probabilities. Basically, we extend the work presented in the WMT 2010 evaluation for Spanish-to-English [7] by experimenting with different statistical scores to segment a monolingual training corpus and by analysing if it is better to add new translation phrases and/or to smooth the existing ones. We participated in the French-to-English BTEC task. Our primary and contrastive systems were two standard phrase-based SMT systems enriched with different novel segmentations. This paper is organized as follows. Section 2 makes a brief description of some related work to the introduction of new segmentations in SMT. Section 3 describes the baseline system. Then, Section 4 reports different statistical cr"
2010.iwslt-evaluation.26,J06-4004,1,0.847561,"on 6 shows the experimental details of the system and the experiments performed with the novel technique. Finally, Section 7 presents the conclusions. 2. Related work One of the main problems in the statistical machine translation approach is how to segment the bilingual corpus in order to build the most appropriate translation dictionary. Standard phrase-based SMT systems first align the parallel corpus at the word level by using IBM probabilities and then use standard constraints (see section 3) to extract final translation units [10]. Variations of this type of segmentation can be found in [8, 1, 6]. Other approaches consist in integrating the phrase segmentation and alignment, one example is in [14] where they use the point-wise mutual information between the source and target words to identify aligned phrase pairs. In [9] they use a greedy algorithm to compute recursive alignments from a bilingual parallel corpus. Here, we propose to combine the standard phrase-based segmentation [10] with a complementary bilingual segmentation which is learned from a statistical collocation segmen189 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3"
2011.eamt-1.18,J07-2003,0,0.0521452,"euven, Belgium, May 2011 get language sentence eˆ (usually referred as “English”). Among all possible target language sentences e we choose the one with the highest score, as show in equation (1): "" M # X eˆ = arg max λm hm (f, e) (1) e m=1 This equation, called the log-linear model, is a variation of the source-channel approach to SMT (Brown et al., 1990). It was proposed by Och and Ney (2002) and allows using more than two models and to weight them independently. Frequently used paradigms of SMT based on the log-linear model are Phrase-based SMT (Koehn et al., 2003), Hierarchical-based SMT (Chiang, 2007) and Ngram-based SMT (Mari˜no et al., 2006). In our experiments we used the Ngrambased approach. The Ngram-based approach relies on the concept of tuple. A tuple is a bilingual unit with consecutive words both on the source and target side that is consistent with the word alignment. They must provide a unique monotonic segmentation of the sentence pair and they cannot be inside other tuple. This unique segmentation allows us to see the translation model as a language model, where the language is composed of tuples instead of words. That way, the context used in the translation model is bilingu"
2011.eamt-1.18,2005.iwslt-1.23,1,0.892438,"Missing"
2011.eamt-1.18,2009.eamt-1.8,1,0.899687,"Missing"
2011.eamt-1.18,2010.amta-papers.21,0,0.147527,"m such adaptation, and they all require a small indomain corpus whether it is bilingual or not, for the system to adapt. Some of them include: concatenate corpora and model interpolation (Koehn and Schroeder, 2007), using mono-lingual and crosslingual information retrieval (Hildebrand et al., 2005; Xu et al., 2007; Snover et al., 2008), language model adaptation for difficult to translate phrases (Mohit et al., 2009), generating a synthetic corpus (Ueffing et al., 2007; Schwenk and Senellart, 2009) and finally post-editing approaches (Isabelle et al., 2007) combined with incremental training (Hardt and Elming, 2010). The strategy proposed here assumes we have an out-of-domain system and a revised corpus that is composed of a small bilingual in-domain corpus and the translation of its source side computed with the system we like to adapt. 3.2 User feedback. Similar to domain adaptation, user feedback is also a valid scenario for the proposed strategy. In this case, a previously trained SMT system is used to translate sentences provided by different users. Then, if the users consider it convenient, they can suggest a better translation than the one the system obtained. If we saved all those suggestions tog"
2011.eamt-1.18,2005.eamt-1.19,0,0.0305893,"a method to adapt to different domains is preferred than building a whole new system for each domain we face. Moreover, it might be the only plausible solution if we have a big out-of-domain parallel corpus but a small indomain corpus which, if used alone, would perform poorly. Different methods have been studied to perform such adaptation, and they all require a small indomain corpus whether it is bilingual or not, for the system to adapt. Some of them include: concatenate corpora and model interpolation (Koehn and Schroeder, 2007), using mono-lingual and crosslingual information retrieval (Hildebrand et al., 2005; Xu et al., 2007; Snover et al., 2008), language model adaptation for difficult to translate phrases (Mohit et al., 2009), generating a synthetic corpus (Ueffing et al., 2007; Schwenk and Senellart, 2009) and finally post-editing approaches (Isabelle et al., 2007) combined with incremental training (Hardt and Elming, 2010). The strategy proposed here assumes we have an out-of-domain system and a revised corpus that is composed of a small bilingual in-domain corpus and the translation of its source side computed with the system we like to adapt. 3.2 User feedback. Similar to domain adaptation,"
2011.eamt-1.18,W07-0733,0,0.0306855,"reviews as expected. Text corpora can be different in vocabulary, style or grammar and a method to adapt to different domains is preferred than building a whole new system for each domain we face. Moreover, it might be the only plausible solution if we have a big out-of-domain parallel corpus but a small indomain corpus which, if used alone, would perform poorly. Different methods have been studied to perform such adaptation, and they all require a small indomain corpus whether it is bilingual or not, for the system to adapt. Some of them include: concatenate corpora and model interpolation (Koehn and Schroeder, 2007), using mono-lingual and crosslingual information retrieval (Hildebrand et al., 2005; Xu et al., 2007; Snover et al., 2008), language model adaptation for difficult to translate phrases (Mohit et al., 2009), generating a synthetic corpus (Ueffing et al., 2007; Schwenk and Senellart, 2009) and finally post-editing approaches (Isabelle et al., 2007) combined with incremental training (Hardt and Elming, 2010). The strategy proposed here assumes we have an out-of-domain system and a revised corpus that is composed of a small bilingual in-domain corpus and the translation of its source side compute"
2011.eamt-1.18,N03-1017,0,0.0188374,"ciation for Machine Translation, p. 121128 Leuven, Belgium, May 2011 get language sentence eˆ (usually referred as “English”). Among all possible target language sentences e we choose the one with the highest score, as show in equation (1): "" M # X eˆ = arg max λm hm (f, e) (1) e m=1 This equation, called the log-linear model, is a variation of the source-channel approach to SMT (Brown et al., 1990). It was proposed by Och and Ney (2002) and allows using more than two models and to weight them independently. Frequently used paradigms of SMT based on the log-linear model are Phrase-based SMT (Koehn et al., 2003), Hierarchical-based SMT (Chiang, 2007) and Ngram-based SMT (Mari˜no et al., 2006). In our experiments we used the Ngrambased approach. The Ngram-based approach relies on the concept of tuple. A tuple is a bilingual unit with consecutive words both on the source and target side that is consistent with the word alignment. They must provide a unique monotonic segmentation of the sentence pair and they cannot be inside other tuple. This unique segmentation allows us to see the translation model as a language model, where the language is composed of tuples instead of words. That way, the context u"
2011.eamt-1.18,W04-3250,0,0.0453004,"Missing"
2011.eamt-1.18,2005.mtsummit-papers.11,0,0.0199597,"has actually three parts: The source side of the bilingual corpus, the target output (computed with the trained system) and the target correction (the target side of the bilingual corpus). We present now two different cases that illustrates the scenario described before. Additionally, we can see a graphical description of the general case in Figure 1. 3.1 Domain adaptation. Because SMT systems are tightly coupled to their corpus domain, they are prone to commit errors when they translate sentences that belong to a different domain. For instance, a SMT system trained with the Europarl Corpus (Koehn, 2005) may not translate movie reviews as expected. Text corpora can be different in vocabulary, style or grammar and a method to adapt to different domains is preferred than building a whole new system for each domain we face. Moreover, it might be the only plausible solution if we have a big out-of-domain parallel corpus but a small indomain corpus which, if used alone, would perform poorly. Different methods have been studied to perform such adaptation, and they all require a small indomain corpus whether it is bilingual or not, for the system to adapt. Some of them include: concatenate corpora a"
2011.eamt-1.18,J06-4004,1,0.890768,"Missing"
2011.eamt-1.18,2009.eamt-1.22,0,0.151889,"ght be the only plausible solution if we have a big out-of-domain parallel corpus but a small indomain corpus which, if used alone, would perform poorly. Different methods have been studied to perform such adaptation, and they all require a small indomain corpus whether it is bilingual or not, for the system to adapt. Some of them include: concatenate corpora and model interpolation (Koehn and Schroeder, 2007), using mono-lingual and crosslingual information retrieval (Hildebrand et al., 2005; Xu et al., 2007; Snover et al., 2008), language model adaptation for difficult to translate phrases (Mohit et al., 2009), generating a synthetic corpus (Ueffing et al., 2007; Schwenk and Senellart, 2009) and finally post-editing approaches (Isabelle et al., 2007) combined with incremental training (Hardt and Elming, 2010). The strategy proposed here assumes we have an out-of-domain system and a revised corpus that is composed of a small bilingual in-domain corpus and the translation of its source side computed with the system we like to adapt. 3.2 User feedback. Similar to domain adaptation, user feedback is also a valid scenario for the proposed strategy. In this case, a previously trained SMT system is used t"
2011.eamt-1.18,P02-1038,0,0.0276868,"uage sentence f (usually referred as “French”) into a tarMikel L. Forcada, Heidi Depraetere, Vincent Vandeghinste (eds.) Proceedings of the 15th Conference of the European Association for Machine Translation, p. 121128 Leuven, Belgium, May 2011 get language sentence eˆ (usually referred as “English”). Among all possible target language sentences e we choose the one with the highest score, as show in equation (1): "" M # X eˆ = arg max λm hm (f, e) (1) e m=1 This equation, called the log-linear model, is a variation of the source-channel approach to SMT (Brown et al., 1990). It was proposed by Och and Ney (2002) and allows using more than two models and to weight them independently. Frequently used paradigms of SMT based on the log-linear model are Phrase-based SMT (Koehn et al., 2003), Hierarchical-based SMT (Chiang, 2007) and Ngram-based SMT (Mari˜no et al., 2006). In our experiments we used the Ngrambased approach. The Ngram-based approach relies on the concept of tuple. A tuple is a bilingual unit with consecutive words both on the source and target side that is consistent with the word alignment. They must provide a unique monotonic segmentation of the sentence pair and they cannot be inside oth"
2011.eamt-1.18,padro-etal-2010-freeling,0,0.116155,"Missing"
2011.eamt-1.18,2001.mtsummit-papers.68,0,0.010657,"n-gram n, T MBase is the baseline translation model and T MAdd is the new translation model computed in the third step. To determine the value of α we tuned the system considering five different values and kept the one that obtained the highest BLEU score. Table 5 shows the different BLEU scores obtained with the development set and α = 0.85 as the best candidate. 5 Results and discussion. We built two different systems and used α = 0.85 for the interpolation. The results obtained over the correction and test corpora can be seen in Table 6. The second and third column correspond to the BLEU (Papineni et al., 2001) scores obtained by the different systems in the Correction and Test corpora, using only one reference. The fourth column gives the confidence level for test BLEU being higher than the baseline test BLEU. Notice that all revised system performed better in the correction corpus, which is obvious because it is part of the revised corpus. Also, they all improved the baseline test score. What is interesting is that once we added the lexical filter, the correction BLEU decreased and the test BLEU increased. It means that the filter is helping the system generalize its learning. Moreover, even thoug"
2011.eamt-1.18,2009.mtsummit-posters.17,0,0.0157044,"corpus but a small indomain corpus which, if used alone, would perform poorly. Different methods have been studied to perform such adaptation, and they all require a small indomain corpus whether it is bilingual or not, for the system to adapt. Some of them include: concatenate corpora and model interpolation (Koehn and Schroeder, 2007), using mono-lingual and crosslingual information retrieval (Hildebrand et al., 2005; Xu et al., 2007; Snover et al., 2008), language model adaptation for difficult to translate phrases (Mohit et al., 2009), generating a synthetic corpus (Ueffing et al., 2007; Schwenk and Senellart, 2009) and finally post-editing approaches (Isabelle et al., 2007) combined with incremental training (Hardt and Elming, 2010). The strategy proposed here assumes we have an out-of-domain system and a revised corpus that is composed of a small bilingual in-domain corpus and the translation of its source side computed with the system we like to adapt. 3.2 User feedback. Similar to domain adaptation, user feedback is also a valid scenario for the proposed strategy. In this case, a previously trained SMT system is used to translate sentences provided by different users. Then, if the users consider it c"
2011.eamt-1.18,D08-1090,0,0.0552669,"preferred than building a whole new system for each domain we face. Moreover, it might be the only plausible solution if we have a big out-of-domain parallel corpus but a small indomain corpus which, if used alone, would perform poorly. Different methods have been studied to perform such adaptation, and they all require a small indomain corpus whether it is bilingual or not, for the system to adapt. Some of them include: concatenate corpora and model interpolation (Koehn and Schroeder, 2007), using mono-lingual and crosslingual information retrieval (Hildebrand et al., 2005; Xu et al., 2007; Snover et al., 2008), language model adaptation for difficult to translate phrases (Mohit et al., 2009), generating a synthetic corpus (Ueffing et al., 2007; Schwenk and Senellart, 2009) and finally post-editing approaches (Isabelle et al., 2007) combined with incremental training (Hardt and Elming, 2010). The strategy proposed here assumes we have an out-of-domain system and a revised corpus that is composed of a small bilingual in-domain corpus and the translation of its source side computed with the system we like to adapt. 3.2 User feedback. Similar to domain adaptation, user feedback is also a valid scenario"
2011.eamt-1.18,2007.mtsummit-tutorials.1,0,0.0566478,"out-of-domain parallel corpus but a small indomain corpus which, if used alone, would perform poorly. Different methods have been studied to perform such adaptation, and they all require a small indomain corpus whether it is bilingual or not, for the system to adapt. Some of them include: concatenate corpora and model interpolation (Koehn and Schroeder, 2007), using mono-lingual and crosslingual information retrieval (Hildebrand et al., 2005; Xu et al., 2007; Snover et al., 2008), language model adaptation for difficult to translate phrases (Mohit et al., 2009), generating a synthetic corpus (Ueffing et al., 2007; Schwenk and Senellart, 2009) and finally post-editing approaches (Isabelle et al., 2007) combined with incremental training (Hardt and Elming, 2010). The strategy proposed here assumes we have an out-of-domain system and a revised corpus that is composed of a small bilingual in-domain corpus and the translation of its source side computed with the system we like to adapt. 3.2 User feedback. Similar to domain adaptation, user feedback is also a valid scenario for the proposed strategy. In this case, a previously trained SMT system is used to translate sentences provided by different users. Th"
2011.eamt-1.18,2007.mtsummit-papers.68,0,0.0286385,"ferent domains is preferred than building a whole new system for each domain we face. Moreover, it might be the only plausible solution if we have a big out-of-domain parallel corpus but a small indomain corpus which, if used alone, would perform poorly. Different methods have been studied to perform such adaptation, and they all require a small indomain corpus whether it is bilingual or not, for the system to adapt. Some of them include: concatenate corpora and model interpolation (Koehn and Schroeder, 2007), using mono-lingual and crosslingual information retrieval (Hildebrand et al., 2005; Xu et al., 2007; Snover et al., 2008), language model adaptation for difficult to translate phrases (Mohit et al., 2009), generating a synthetic corpus (Ueffing et al., 2007; Schwenk and Senellart, 2009) and finally post-editing approaches (Isabelle et al., 2007) combined with incremental training (Hardt and Elming, 2010). The strategy proposed here assumes we have an out-of-domain system and a revised corpus that is composed of a small bilingual in-domain corpus and the translation of its source side computed with the system we like to adapt. 3.2 User feedback. Similar to domain adaptation, user feedback is"
2011.eamt-1.18,J90-2002,0,\N,Missing
2011.eamt-1.18,P02-1040,0,\N,Missing
2011.eamt-1.20,padro-etal-2010-freeling,0,\N,Missing
2011.eamt-1.20,J90-2002,0,\N,Missing
2011.eamt-1.20,P02-1040,0,\N,Missing
2011.eamt-1.20,2009.eamt-1.8,1,\N,Missing
2011.eamt-1.20,D08-1090,0,\N,Missing
2011.eamt-1.20,2009.eamt-1.22,0,\N,Missing
2011.eamt-1.20,W07-0733,0,\N,Missing
2011.eamt-1.20,J06-4004,1,\N,Missing
2011.eamt-1.20,N03-1017,0,\N,Missing
2011.eamt-1.20,P02-1038,0,\N,Missing
2011.eamt-1.20,2005.mtsummit-papers.11,0,\N,Missing
2011.eamt-1.20,W04-3250,0,\N,Missing
2011.eamt-1.20,2005.eamt-1.19,0,\N,Missing
2011.eamt-1.20,2009.mtsummit-posters.17,0,\N,Missing
2011.eamt-1.20,J07-2003,0,\N,Missing
banchs-etal-2006-acceptance,H92-1005,0,\N,Missing
banchs-etal-2006-acceptance,P99-1073,0,\N,Missing
banchs-etal-2006-acceptance,P02-1038,0,\N,Missing
D15-1265,E06-1002,0,0.00885896,"e likely to be informal and noisy than written sentences, which makes expressions more ambiguous and variable. To solve these issues, we propose a three step approach for Wikification on spoken dialogues. At the first step, a set of classifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each sectio"
D15-1265,C12-1028,0,0.0129421,"language to the relevant concepts in knowledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations. In this work, we focus on the following differences between spoken dialogues and written texts as sources for Wikification. Firstly, at l"
D15-1265,D13-1184,0,0.0151252,"e-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit along with article-level concepts. 2225 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2225–2229, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computational Linguistics. Guide: In the morning I sugges"
D15-1265,D07-1074,0,0.0137772,"nd noisy than written sentences, which makes expressions more ambiguous and variable. To solve these issues, we propose a three step approach for Wikification on spoken dialogues. At the first step, a set of classifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit alon"
D15-1265,N13-1122,0,0.0803846,"ant concepts in knowledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations. In this work, we focus on the following differences between spoken dialogues and written texts as sources for Wikification. Firstly, at least two speakers"
D15-1265,P11-1138,0,0.0220007,"ssifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit along with article-level concepts. 2225 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2225–2229, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computational"
D15-1265,P11-1095,0,0.0383067,"Missing"
D15-1265,P14-1036,0,0.0204408,"owledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations. In this work, we focus on the following differences between spoken dialogues and written texts as sources for Wikification. Firstly, at least two speakers are engaged in a dial"
E14-2009,N03-1017,0,0.00763079,"lability of internet almost everywhere, have allowed for lots of traditional on-line applications and services to be deployed on these mobile platforms. In this demo paper we describe “CHISPA on the GO” a Chinese-Spanish translation service that intends to provide a portable and easy to use language assistance tool for travelers between Chinese and Spanish speaking countries. The main three characteristics of the presented demo system are as follows: 2 SMT system description The translation technology used in our system is based on the well-known phrase-based translation statistical approach (Koehn et al., 2003). This approach performs the translation splitting the source sentence in segments and assigning to each segment a bilingual phrase from a phrasetable. Bilingual phrases are translation units that contain source words and target words, and have different scores associated to them. These bilingual phrases are then selected in order to maximize a linear combination of feature functions. Such strategy is known as the log-linear model (Och and Ney, 2002). The two main feature functions are the translation model and the target language model. Additional models include lexical weights, phrase and wo"
E14-2009,P07-2045,0,0.00523924,"was synthetically produced by translating from English, (4) a large TAUS corpus (TausData, 2013) which comes from technical translation memories, and (5) an inhouse developed small corpus in the transportation and hospitality domains. In total we have 70 million words. A careful preprocessing was developed for all languages. Chinese was segmented with Stanford segmenter (Tseng et al., 2005) and Spanish was preprocessed with Freeling (Padr´o et al., 2010). When Spanish is used as a source language, it is preprocessed by lower-casing and unaccented the input. Finally, we use the MOSES decoder (Koehn et al., 2007) with standard configuration: aligngrow-final-and alignment symmetrization, 5-gram language model with interpolation and kneser-ney discount and phrase-smoothing and lexicalized reordering. We use our in-house developed corpus to optimize because our application is targeted to the travelers-in-need domain. 3 Web Translator and Mobile Application Figure 1: Block diagram of the system architecture This section describes the main system architecture and the main features of web translator and the mobile applications. 3.1 of the two PHP scripts supports Chinese to Spanish translations and the othe"
E14-2009,padro-etal-2010-freeling,0,0.0293451,"Missing"
E14-2009,2009.mtsummit-posters.15,0,0.0144715,"s. For Chinese-Spanish, we use (1) the Holy Bible corpus (Banchs and Li, 2008), (2) the • First, the system uses a direct translation between Chinese and Spanish, rather than using a pivot language as intermediate step as most of the current commercial systems do when dealing with distant languages. 33 Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 33–36, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics United Nations corpus, which was released for research purposes (Rafalovitch and Dale, 2009), (3) a small subset of the European Parliament Plenary Speeches where the Chinese part was synthetically produced by translating from English, (4) a large TAUS corpus (TausData, 2013) which comes from technical translation memories, and (5) an inhouse developed small corpus in the transportation and hospitality domains. In total we have 70 million words. A careful preprocessing was developed for all languages. Chinese was segmented with Stanford segmenter (Tseng et al., 2005) and Spanish was preprocessed with Freeling (Padr´o et al., 2010). When Spanish is used as a source language, it is pre"
E14-2009,P02-1038,0,\N,Missing
I11-1154,P07-1092,0,0.0828654,"s on the Chinese-English corpus and EnglishSpanish corpus, and then building a pivot translation model for Chinese-Spanish translation using English as a pivot language as proposed in (Wu and Wang, 2007); the second one obtained better results and it was based on a cascade approach. The idea here is to translate from Chinese into English and then from English to Spanish, which means performing two translations. Besides the research mentioned above, which directly addressed the Chinese-Spanish language pair, we may also find in the literature another approach similar to Wu’s (2007) authored by Cohn and Lapata (2007). Basically, they also used several intermediate pivot language to create source-totarget phrases that are lately interpolate with a direct system build with a source-to-target parallel corpus. Apart from the BTEC3 corpus available through the IWSLT4 competition and Holy Bible datasets described in (Paul, 2008) and (Banchs and Li, 2008), respectively, there is a recent release of a six language parallel corpus (including both Chinese and Spanish) from United Nations (UN) for research purposes (Rafalovith and Dale, 2009). Using the recently released UN parallel corpus as a starting point, this"
I11-1154,P07-2026,0,0.0162423,"eudo-Corpus System This approach translates the pivot section of the source-pivot parallel corpus to the target language using a pivot-target system built previously. Then, a source-target SMT system is built using the source side and the translated pivot side of the source-pivot corpus. The pseudo-corpus system is tuned using a direct source-target development corpus. 2.4 Pivot combination Using the 1-best translation output from the different pivot strategies, we built an N-best list and computed the final translation using MBR. MBR has been used both during decoding (Kumar and Byrne, 2004; Ehling et al., 2007) and as a postprocess over an N-best list. The current version of the M OSES toolkit includes both MBR implementations. For the system combinations we used the second one. The MBR algorithm implemented in M OSES uses (1 − BLEU )β as the Loss Function. The value β weights the hypothesis proportionally to its translation score, but we considered all our hypothesis as equal so β was a constant and therefore could be discarded. At the end, MBR choose the hypotheses E ′ that fulfills:   X E ′ = arg min  1 − BLEU (E, Eˆ′ ) (1) Eˆ′ E6=Eˆ′ It is important to mention that all N-best list must have"
I11-1154,P05-1071,0,0.0419567,"E ′ ) is a brevity penalty if the hypothesis E ′ is shorter than the reference E. Then pn (E, E ′ ) = pn (E ′ , E) and ∀E, E ′ : length(E) &gt; length(E ′ ) : 1 − BLEU (E, E ′ ) ≥ 1 − BLEU (E ′ , E) 3 (3) Evaluation Framework This section introduces the details of the evaluation framework used. We report the UN corpus statistics, a description of how we built the systems and the evaluation details. the same training, tuning and testing sets. All corpora were tokenized, using the standard M OSES tokenizer for Spanish, English and French; ictclass (Zhang et al., 2003) for Chinese; and MADA+TOKAN (Habash and Rambow, 2005) for Arabic. The Spanish, English and French corpora were lowercased. If a sentence had more than 100 words in any language, it was deleted from all corpora. If a sentence pair had a word ratio bigger than three for any Chinese-Pivot or Pivot-Spanish parallel corpora, it was deleted from all corpora. For all languages, we identify all sentences that occur only once in the corpora. The tuning and testing sets where drawn from the available multilingual corpus by using a maximum perplexity and lowest outof-vocabulary word criterion over the English part of the dataset. In order to do this, perpl"
I11-1154,N03-1017,0,0.0114307,"nish translation which are tested in this work. Section 3 presents the evaluation framework. Then, section 4 reports the experiments (including the system combination) and the results. Finally, section 5 concludes and proposes new research directions. 2 Direct and pivot statistical machine translation approaches There are several strategies that we can follow when translating a pair of languages in Statistical Machine Translation. The next three sub-sections present the details of the ones we are using in this work. 2.1 Direct system Our direct system uses the phrase-based translation system (Koehn et al., 2003). This popular system implements a log-linear model in which a source language sentence f J = f1 , f2 , . . . , fJ is translated into another language (target) sentence eI = e1 , e2 , . . . , eI by searching for the translation hypothesis eˆI maximizing a log-linear combination of several feature models (Och, 2003). The main system models are the translation model and the language model. The first one deals with the issue of which target language phrase fj translates a source language phrase ei and the latter model estimates the probability of translation hypothesis. 1362 Apart from these two"
I11-1154,P07-2045,0,0.00650059,"target) sentence eI = e1 , e2 , . . . , eI by searching for the translation hypothesis eˆI maximizing a log-linear combination of several feature models (Och, 2003). The main system models are the translation model and the language model. The first one deals with the issue of which target language phrase fj translates a source language phrase ei and the latter model estimates the probability of translation hypothesis. 1362 Apart from these two models, there are other standard models such as the lexical models, the word bonus, and the reordering model. For decoding, we used the M OSES toolkit (Koehn et al., 2007) with the option of Minimum Bayes Risk (MBR) (Kumar and Byrne, 2004) decoding. Therefore the 1best translation obtained is not the one with highest priority but the one that is most similar to the most likely translation. The option was activated with its default parameters so it considered the top 200 distinct hypothesis to compute the 1best. 2.2 Cascade System This approach handles the source-pivot and the pivot-target system independently. They are both built and tuned to improve their local translation quality and then joined to translate from the source language to the target language in"
I11-1154,W04-3250,0,0.129168,"Missing"
I11-1154,N04-1022,0,0.224825,"International Joint Conference on Natural Language Processing, pages 1361–1365, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP problem in hand by means of pivot-language strategies through the other languages available in the UN parallel corpus, such as Arabic, English and French. More specifically, strategies such as system cascading and pseudo-corpus generation are implemented and compared against a baseline system implementing a direct translation approach. We propose a system combination different from previous ones (Wu and Wang, 2009) and based on the Minimum Bayes Risk (MBR) (Kumar and Byrne, 2004) technique using both pivot strategies which is capable to highly outperform the direct system. To the best of our knowledge, this idea was not explored before and it is a way of increasing the quality of translation between languages with scarce bilingual resources. In addition, we are performing a combination of the same system but introducing new information through the pivot language. The paper is structured as follows. Section 2 describes the main strategies for performing Chineseto-Spanish translation which are tested in this work. Section 3 presents the evaluation framework. Then, secti"
I11-1154,P03-1021,0,0.0327603,"everal strategies that we can follow when translating a pair of languages in Statistical Machine Translation. The next three sub-sections present the details of the ones we are using in this work. 2.1 Direct system Our direct system uses the phrase-based translation system (Koehn et al., 2003). This popular system implements a log-linear model in which a source language sentence f J = f1 , f2 , . . . , fJ is translated into another language (target) sentence eI = e1 , e2 , . . . , eI by searching for the translation hypothesis eˆI maximizing a log-linear combination of several feature models (Och, 2003). The main system models are the translation model and the language model. The first one deals with the issue of which target language phrase fj translates a source language phrase ei and the latter model estimates the probability of translation hypothesis. 1362 Apart from these two models, there are other standard models such as the lexical models, the word bonus, and the reordering model. For decoding, we used the M OSES toolkit (Koehn et al., 2007) with the option of Minimum Bayes Risk (MBR) (Kumar and Byrne, 2004) decoding. Therefore the 1best translation obtained is not the one with highe"
I11-1154,2009.mtsummit-posters.15,0,0.0110614,"lso find in the literature another approach similar to Wu’s (2007) authored by Cohn and Lapata (2007). Basically, they also used several intermediate pivot language to create source-totarget phrases that are lately interpolate with a direct system build with a source-to-target parallel corpus. Apart from the BTEC3 corpus available through the IWSLT4 competition and Holy Bible datasets described in (Paul, 2008) and (Banchs and Li, 2008), respectively, there is a recent release of a six language parallel corpus (including both Chinese and Spanish) from United Nations (UN) for research purposes (Rafalovith and Dale, 2009). Using the recently released UN parallel corpus as a starting point, this work focuses on the problem of developing Chinese-Spanish phrase-based SMT technologies with a limited set of bilingual resources. We explore and evaluate different alternatives for the 3 4 Basic Traveller Expressions Corpus International Workshop on Spoken Language Translation 1361 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 1361–1365, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP problem in hand by means of pivot-language strategies through the other language"
I11-1154,P07-1108,0,0.345231,"-Spanish tracks. One of them was focused on direct translation and the other one on pivot translation through 1 2 www.ethnologue.org/ethno docs/distribution.asp?by=size http://mastarpj.nict.go.jp/IWSLT2008/ English. Best translation results were obtained by far in the pivot task. The best system in the pivot task (Wang et al., 2008) compared two different approaches: The first one, training two translation models on the Chinese-English corpus and EnglishSpanish corpus, and then building a pivot translation model for Chinese-Spanish translation using English as a pivot language as proposed in (Wu and Wang, 2007); the second one obtained better results and it was based on a cascade approach. The idea here is to translate from Chinese into English and then from English to Spanish, which means performing two translations. Besides the research mentioned above, which directly addressed the Chinese-Spanish language pair, we may also find in the literature another approach similar to Wu’s (2007) authored by Cohn and Lapata (2007). Basically, they also used several intermediate pivot language to create source-totarget phrases that are lately interpolate with a direct system build with a source-to-target para"
I11-1154,P09-1018,0,0.294516,"op on Spoken Language Translation 1361 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 1361–1365, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP problem in hand by means of pivot-language strategies through the other languages available in the UN parallel corpus, such as Arabic, English and French. More specifically, strategies such as system cascading and pseudo-corpus generation are implemented and compared against a baseline system implementing a direct translation approach. We propose a system combination different from previous ones (Wu and Wang, 2009) and based on the Minimum Bayes Risk (MBR) (Kumar and Byrne, 2004) technique using both pivot strategies which is capable to highly outperform the direct system. To the best of our knowledge, this idea was not explored before and it is a way of increasing the quality of translation between languages with scarce bilingual resources. In addition, we are performing a combination of the same system but introducing new information through the pivot language. The paper is structured as follows. Section 2 describes the main strategies for performing Chineseto-Spanish translation which are tested in t"
I11-1154,W03-1730,0,0.0155253,"in the hypothesis E ′ with reference E; and γ(E, E ′ ) is a brevity penalty if the hypothesis E ′ is shorter than the reference E. Then pn (E, E ′ ) = pn (E ′ , E) and ∀E, E ′ : length(E) &gt; length(E ′ ) : 1 − BLEU (E, E ′ ) ≥ 1 − BLEU (E ′ , E) 3 (3) Evaluation Framework This section introduces the details of the evaluation framework used. We report the UN corpus statistics, a description of how we built the systems and the evaluation details. the same training, tuning and testing sets. All corpora were tokenized, using the standard M OSES tokenizer for Spanish, English and French; ictclass (Zhang et al., 2003) for Chinese; and MADA+TOKAN (Habash and Rambow, 2005) for Arabic. The Spanish, English and French corpora were lowercased. If a sentence had more than 100 words in any language, it was deleted from all corpora. If a sentence pair had a word ratio bigger than three for any Chinese-Pivot or Pivot-Spanish parallel corpora, it was deleted from all corpora. For all languages, we identify all sentences that occur only once in the corpora. The tuning and testing sets where drawn from the available multilingual corpus by using a maximum perplexity and lowest outof-vocabulary word criterion over the E"
I11-1154,2008.iwslt-evaluation.17,1,\N,Missing
I11-1154,2008.iwslt-evaluation.18,0,\N,Missing
I11-1154,2008.iwslt-evaluation.1,0,\N,Missing
I11-1154,2008.iwslt-evaluation.4,0,\N,Missing
J06-4004,W05-0823,1,0.838951,"Missing"
J06-4004,W00-0508,0,0.0142428,"y approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney 2002). As an extension of the machine translation problem, technological advances in the fields of automatic speech recognition (ASR) and text to speech synthesis (TTS) made it possible to envision the challenge of spoken language translation (SLT) (Kay, Gawron, and Norvig 1992). According to this, SMT has also been approached from a finite-state point of view as the most natural way of integrating ASR and SMT (Riccardi, Pieraccini, and Bocchieri 1996; Vidal 1997; Knight and Al-Onaizan 1998; Bangalore and Riccardi 2000). In this SMT approach, translation models are implemented by means of finitestate transducers for which transition probabilities are learned from bilingual data. As opposed to phrase-based translation models, which consider probabilities between target and source units referred to as phrases, finite-state translation models rely on probabilities among sequences of bilingual units, which are defined by the transitions of the transducer. The translation system described in this article implements a translation model that has been derived from the finite-state perspective—more specifically, from"
J06-4004,J96-1002,0,0.02988,"Missing"
J06-4004,J90-2002,0,0.81424,"nslation was conceived as the problem of finding a sentence by decoding a given “encrypted” version of it (Weaver 1955). Although the idea seemed very feasible, enthusiasm faded shortly afterward because of the computational limitations of the time (Hutchins 1986). Finally, during the nineties, two factors made it possible for SMT to become an actual and practical technology: first, significant increment in both the computational power and storage capacity of computers, and second, the availability of large volumes of bilingual data. The first SMT systems were developed in the early nineties (Brown et al. 1990, 1993). These systems were based on the so-called noisy channel approach, which models the probability of a target language sentence T given a source language sentence S as the product of a translation-model probability p(S|T), which accounts for adequacy of translation contents, times a target language probability p(T), which accounts for fluency of target constructions. For these first SMT systems, translation-model probabilities at the sentence level were approximated from word-based translation models that were trained by using bilingual corpora (Brown et al. 1993). In the case of target"
J06-4004,J93-2003,0,0.0556776,"d in the early nineties (Brown et al. 1990, 1993). These systems were based on the so-called noisy channel approach, which models the probability of a target language sentence T given a source language sentence S as the product of a translation-model probability p(S|T), which accounts for adequacy of translation contents, times a target language probability p(T), which accounts for fluency of target constructions. For these first SMT systems, translation-model probabilities at the sentence level were approximated from word-based translation models that were trained by using bilingual corpora (Brown et al. 1993). In the case of target language probabilities, these were generally trained from monolingual data by using n-grams. Present SMT systems have evolved from the original ones in such a way that mainly differ from them in two respects: first, word-based translation models have been ∗ Department of Signal Theory and Communications, Campus Nord, Barcelona 08034, Spain. Submission received: 9 August 2005; revised submission received: 26 April 2006; accepted for publication: 5 July 2006 © 2006 Association for Computational Linguistics Computational Linguistics Volume 32, Number 4 replaced by phrase-b"
J06-4004,J04-2004,0,0.856987,"models are implemented by means of finitestate transducers for which transition probabilities are learned from bilingual data. As opposed to phrase-based translation models, which consider probabilities between target and source units referred to as phrases, finite-state translation models rely on probabilities among sequences of bilingual units, which are defined by the transitions of the transducer. The translation system described in this article implements a translation model that has been derived from the finite-state perspective—more specifically, from the work of Casacuberta (2001) and Casacuberta and Vidal (2004). However, whereas in this earlier work the translation model is implemented by using a finite-state transducer, in the system presented here the translation model is implemented by using n-grams. In this way, the proposed translation system can take full advantage of the smoothing and consistency provided by standard back-off n-gram models. The translation model presented here actually constitutes a language model of a sort of “bilanguage” composed of bilin˜ 2002). An alternagual units, which will be referred to as tuples (de Gispert and Marino tive approach, which relies on bilingual-unit un"
J06-4004,N04-1033,0,0.0140655,"Missing"
J06-4004,2005.iwslt-1.23,1,0.883592,"Missing"
J06-4004,2005.mtsummit-papers.37,1,0.855856,"Missing"
J06-4004,2006.amta-papers.4,1,0.763242,"Missing"
J06-4004,P05-2012,1,0.804737,"Missing"
J06-4004,C86-1155,0,0.079146,"ament Plenary Sessions (EPPS). 1. Introduction The beginnings of statistical machine translation (SMT) can be traced back to the early fifties, closely related to the ideas from which information theory arose (Shannon and Weaver 1949) and inspired by works on cryptography (Shannon 1949, 1951) during World War II. According to this view, machine translation was conceived as the problem of finding a sentence by decoding a given “encrypted” version of it (Weaver 1955). Although the idea seemed very feasible, enthusiasm faded shortly afterward because of the computational limitations of the time (Hutchins 1986). Finally, during the nineties, two factors made it possible for SMT to become an actual and practical technology: first, significant increment in both the computational power and storage capacity of computers, and second, the availability of large volumes of bilingual data. The first SMT systems were developed in the early nineties (Brown et al. 1990, 1993). These systems were based on the so-called noisy channel approach, which models the probability of a target language sentence T given a source language sentence S as the product of a translation-model probability p(S|T), which accounts for"
J06-4004,knight-al-onaizan-1998-translation,0,0.230855,"more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney 2002). As an extension of the machine translation problem, technological advances in the fields of automatic speech recognition (ASR) and text to speech synthesis (TTS) made it possible to envision the challenge of spoken language translation (SLT) (Kay, Gawron, and Norvig 1992). According to this, SMT has also been approached from a finite-state point of view as the most natural way of integrating ASR and SMT (Riccardi, Pieraccini, and Bocchieri 1996; Vidal 1997; Knight and Al-Onaizan 1998; Bangalore and Riccardi 2000). In this SMT approach, translation models are implemented by means of finitestate transducers for which transition probabilities are learned from bilingual data. As opposed to phrase-based translation models, which consider probabilities between target and source units referred to as phrases, finite-state translation models rely on probabilities among sequences of bilingual units, which are defined by the transitions of the transducer. The translation system described in this article implements a translation model that has been derived from the finite-state persp"
J06-4004,N03-1017,0,0.0258625,"Missing"
J06-4004,2005.mtsummit-papers.36,1,0.177804,"Missing"
J06-4004,P00-1056,0,0.0440511,"tence pairs are removed from the training data to allow for a better performance of the alignment tool. Sentence pairs are removed according to the following two criteria: r r Fertility filtering: removes sentence pairs with a word ratio larger than a predefined threshold value. Length filtering: removes sentence pairs with at least one sentence of more than 100 words in length. This helps to maintain bounded alignment computational times. After preprocessing, word-to-word alignments are performed in both directions, source-to-target and target-to-source. In our system implementation, GIZA++ (Och and Ney 2000) is used for computing the alignments. A total of five iterations for models IBM-1 and HMM, and three iterations for models IBM-3 and IBM-4, are performed. Then, the obtained alignment sets are used for computing the intersection and the union of alignments from which tuples and embedded-word tuples are extracted, respectively. 4.2.2 Tuple Extraction and Pruning. A tuple set for each translation direction is extracted from the union set of alignments while avoiding source-nulled tuples by using the procedure described in Section 2.2.2. Then, the resulting tuple vocabularies are pruned accordin"
J06-4004,P02-1038,0,0.884384,"034, Spain. Submission received: 9 August 2005; revised submission received: 26 April 2006; accepted for publication: 5 July 2006 © 2006 Association for Computational Linguistics Computational Linguistics Volume 32, Number 4 replaced by phrase-based translation models (Zens, Och, and Ney 2002; Koehn, Och, and Marcu 2003) which are directly estimated from aligned bilingual corpora by considering relative frequencies, and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney 2002). As an extension of the machine translation problem, technological advances in the fields of automatic speech recognition (ASR) and text to speech synthesis (TTS) made it possible to envision the challenge of spoken language translation (SLT) (Kay, Gawron, and Norvig 1992). According to this, SMT has also been approached from a finite-state point of view as the most natural way of integrating ASR and SMT (Riccardi, Pieraccini, and Bocchieri 1996; Vidal 1997; Knight and Al-Onaizan 1998; Bangalore and Riccardi 2000). In this SMT approach, translation models are implemented by means of finitesta"
J06-4004,J03-1002,0,0.00706932,"gram model alone, in the case of Table 2, and by using the tuple n-gram model along with the additional four feature functions described in Section 3.2, in the case of Table 3. Both translation directions, Spanish to English (ES → EN) and English to Spanish (EN → ES), are considered in each table. In the case of Table 2, model size and translation accuracy are evaluated against the type of alignment set used for extracting tuples. Three different alignment sets are considered: source-to-target, the union of source-to-target and target-to-source, and the “refined” alignment method described by Och and Ney (2003). For the results presented in Table 2, a pruning parameter value of N = 20 was used for the Spanish-to-English direction, while a value of N = 30 was used for the English-to-Spanish direction. As can be clearly seen in Table 2, the union alignment set happens to be the most favorable one for extracting tuples in both translation directions since it provides a significantly better translation accuracy, in terms of BLEU score, than the other two alignment sets considered. Notice also in Table 2 that the union set is the one providing the smallest model sizes according to the number of bigrams a"
J06-4004,P02-1040,0,0.105596,"alignment sets. Notice that BLEU measurements in this table correspond to translations computed by using the tuple n-gram model alone. Direction Alignment set Tuple voc. Bigrams Trigrams BLEU ES → EN Source-to-target union refined Source-to-target union refined 1.920 2.040 2.111 1.813 2.023 2.081 6.426 6.009 6.851 6.263 6.092 6.920 2.353 1.798 2.398 2.268 1.747 2.323 0.4424 0.4745 0.4594 0.4152 0.4276 0.4193 EN → ES when tuples are extracted from different alignment sets and when different pruning parameters are used, respectively. Translation accuracy is measured in terms of the BLEU score (Papineni et al. 2002), which is computed here for translations generated by using the tuple n-gram model alone, in the case of Table 2, and by using the tuple n-gram model along with the additional four feature functions described in Section 3.2, in the case of Table 3. Both translation directions, Spanish to English (ES → EN) and English to Spanish (EN → ES), are considered in each table. In the case of Table 2, model size and translation accuracy are evaluated against the type of alignment set used for extracting tuples. Three different alignment sets are considered: source-to-target, the union of source-to-targ"
J06-4004,N03-2036,0,0.00459439,"k the translation model is implemented by using a finite-state transducer, in the system presented here the translation model is implemented by using n-grams. In this way, the proposed translation system can take full advantage of the smoothing and consistency provided by standard back-off n-gram models. The translation model presented here actually constitutes a language model of a sort of “bilanguage” composed of bilin˜ 2002). An alternagual units, which will be referred to as tuples (de Gispert and Marino tive approach, which relies on bilingual-unit unigram probabilities, was developed by Tillmann and Xia (2003); in contrast, the approach presented here considers bilingualunit n-gram probabilities. In addition to the tuple n-gram translation model, the translation system presented here implements four specific feature functions that are log-linearly combined along with the translation model for performing the decoding ˜ et al. 2005). (Marino This article is intended to provide a detailed description of the n-gram-based translation system, as well as to demonstrate the system performance in a widedomain, large-vocabulary translation task. The article is structured as follows. First, Section 2 presents"
J06-4004,2002.tmi-tutorials.2,0,0.201063,"Missing"
J06-4004,2004.iwslt-evaluation.14,1,\N,Missing
J06-4004,N04-1021,0,\N,Missing
N07-2022,P06-1002,0,0.0591237,"systems use a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Within this 1 Hereinafter, alignment will refer to word alignment, unless otherwise stated. A more general difficulty, however, is that of finding an alignment evaluation metric favoring alignments which benefit Machine Translation. The fact that the required alignment characteristics depend on each particular system makes it even more difficult. It seems that high precision alignments are better for phrase-based SMT (Chen and Federico, 2006; Ayan and Dorr, 2006), whereas high recall alignments are more suited to N-gram SMT (Mari˜no et al., 2006). In this context, alignment quality improvements does not necessarily imply translation quality improvements. This is in agreement with the observation of a poor correlation between word alignment error rate (AER (Och and Ney, 2000)) and automatic translation evaluation metrics (Ittycheriah and Roukos, 2005; Vilar et al., 2006). 85 Proceedings of NAACL HLT 2007, Companion Volume, pages 85–88, c Rochester, NY, April 2007. 2007 Association for Computational Linguistics Recently some alignment evaluation metrics"
N07-2022,J93-2003,0,0.0320352,"Missing"
N07-2022,N06-1014,0,0.0312338,"ot tuned in function of the translation task, but only indirectly. In this paper, we propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion. In this approach, alignments are optimized for the translation task. In addition, no link labels at the word level are needed. This framework is evaluated in terms of automatic translation evaluation metrics, and an improvement of translation quality is observed. 1 Tuning alignment for an MT system is subject to practical difficulties. Unsupervised systems (Och and Ney, 2003; Liang et al., 2006) are based on generative models trained with the EM algorithm. They require large computational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. Introduction In the first SMT systems (Brown et al., 1993), word alignment was introduced as a hidden variable of the translation model. When word-based translation models have been replaced by phrase-based models (Zens et al., 2002), alignment1 and translation model trai"
N07-2022,P05-1057,0,0.0715665,"roach, alignments are optimized for the translation task. In addition, no link labels at the word level are needed. This framework is evaluated in terms of automatic translation evaluation metrics, and an improvement of translation quality is observed. 1 Tuning alignment for an MT system is subject to practical difficulties. Unsupervised systems (Och and Ney, 2003; Liang et al., 2006) are based on generative models trained with the EM algorithm. They require large computational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. Introduction In the first SMT systems (Brown et al., 1993), word alignment was introduced as a hidden variable of the translation model. When word-based translation models have been replaced by phrase-based models (Zens et al., 2002), alignment1 and translation model training have become two separated tasks. The system of Brown et al. was based on the noisy channel approach. Present SMT systems use a more general maximum entropy approach in which a log-linear combination of multiple feature funct"
N07-2022,J06-4004,1,0.894597,"Missing"
N07-2022,H05-1011,0,0.215348,"are optimized for the translation task. In addition, no link labels at the word level are needed. This framework is evaluated in terms of automatic translation evaluation metrics, and an improvement of translation quality is observed. 1 Tuning alignment for an MT system is subject to practical difficulties. Unsupervised systems (Och and Ney, 2003; Liang et al., 2006) are based on generative models trained with the EM algorithm. They require large computational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. Introduction In the first SMT systems (Brown et al., 1993), word alignment was introduced as a hidden variable of the translation model. When word-based translation models have been replaced by phrase-based models (Zens et al., 2002), alignment1 and translation model training have become two separated tasks. The system of Brown et al. was based on the noisy channel approach. Present SMT systems use a more general maximum entropy approach in which a log-linear combination of multiple feature functions is imple"
N07-2022,C00-2163,0,0.0304844,"ion metric favoring alignments which benefit Machine Translation. The fact that the required alignment characteristics depend on each particular system makes it even more difficult. It seems that high precision alignments are better for phrase-based SMT (Chen and Federico, 2006; Ayan and Dorr, 2006), whereas high recall alignments are more suited to N-gram SMT (Mari˜no et al., 2006). In this context, alignment quality improvements does not necessarily imply translation quality improvements. This is in agreement with the observation of a poor correlation between word alignment error rate (AER (Och and Ney, 2000)) and automatic translation evaluation metrics (Ittycheriah and Roukos, 2005; Vilar et al., 2006). 85 Proceedings of NAACL HLT 2007, Companion Volume, pages 85–88, c Rochester, NY, April 2007. 2007 Association for Computational Linguistics Recently some alignment evaluation metrics have been proposed which are more informative when the alignments are used to extract translation units (Fraser and Marcu, 2006; Ayan and Dorr, 2006). However, these metrics assess translation quality very indirectly. In this paper, we propose a novel framework for discriminative training of alignment models with au"
N07-2022,P02-1038,0,0.0396225,"eriah and Roukos, 2005) is easy, but the need of annotated data is a problem. Introduction In the first SMT systems (Brown et al., 1993), word alignment was introduced as a hidden variable of the translation model. When word-based translation models have been replaced by phrase-based models (Zens et al., 2002), alignment1 and translation model training have become two separated tasks. The system of Brown et al. was based on the noisy channel approach. Present SMT systems use a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Within this 1 Hereinafter, alignment will refer to word alignment, unless otherwise stated. A more general difficulty, however, is that of finding an alignment evaluation metric favoring alignments which benefit Machine Translation. The fact that the required alignment characteristics depend on each particular system makes it even more difficult. It seems that high precision alignments are better for phrase-based SMT (Chen and Federico, 2006; Ayan and Dorr, 2006), whereas high recall alignments are more suited to N-gram SMT (Mari˜no et al., 2006). In this context, alignment quality improveme"
N07-2022,J03-1002,0,0.0134264,"el parameters are not tuned in function of the translation task, but only indirectly. In this paper, we propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion. In this approach, alignments are optimized for the translation task. In addition, no link labels at the word level are needed. This framework is evaluated in terms of automatic translation evaluation metrics, and an improvement of translation quality is observed. 1 Tuning alignment for an MT system is subject to practical difficulties. Unsupervised systems (Och and Ney, 2003; Liang et al., 2006) are based on generative models trained with the EM algorithm. They require large computational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. Introduction In the first SMT systems (Brown et al., 1993), word alignment was introduced as a hidden variable of the translation model. When word-based translation models have been replaced by phrase-based models (Zens et al., 2002), alignment1 and t"
N07-2022,P03-1021,0,0.0892164,"Missing"
N07-2022,P06-1097,0,0.0225194,"ignment quality improvements does not necessarily imply translation quality improvements. This is in agreement with the observation of a poor correlation between word alignment error rate (AER (Och and Ney, 2000)) and automatic translation evaluation metrics (Ittycheriah and Roukos, 2005; Vilar et al., 2006). 85 Proceedings of NAACL HLT 2007, Companion Volume, pages 85–88, c Rochester, NY, April 2007. 2007 Association for Computational Linguistics Recently some alignment evaluation metrics have been proposed which are more informative when the alignments are used to extract translation units (Fraser and Marcu, 2006; Ayan and Dorr, 2006). However, these metrics assess translation quality very indirectly. In this paper, we propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion. Thus we just need a reference aligned at the sentence level instead of link labels at the word level. The paper is structured as follows. Section 2 explains the models used in our word aligner, focusing on the features designed to account for the specificities of the SMT system. In section 3, our minimum error training procedure is described and experim"
N07-2022,H91-1026,0,0.185519,"d because word positions s2 and s3 are embedded between links s1-t1 and s4-t1. Thus the link s4-t1 may introduces data sparseness in the translation model, although it may be a correct link. So we want to have a feature which counts the number of embedded word positions in an alignment. Figure 1: Word positions embedded in a tuple. In addition to the embedded word position feature, we used the same two distortion features as Moore to penalize reorderings in the alignment (one sums the number of crossing links, and the other one sums the amplitude of crossing links). We also used the φ2 score (Gale and Church, 1991) as a word association model, and as a POS-tags association model. 3 Experimental Work For these experiments we used the ChineseEnglish data provided for IWSLT’06 evaluation campaign (Paul, 2006). The training set contains 46000 sentences (of 6.7 and 7.0 average length). Parameters were tuned over the development set (dev4) provided, consisting of 489 sentences of 11.2 words in average, with 7 references. Our test set was a selection of 500 sentences (of 6 words in average, with 16 references) among dev1, dev2 and dev3 sets. 3.1 Optimization Procedure Once the alignment models were computed, a"
N07-2022,H05-1012,0,0.141103,"for the translation task. In addition, no link labels at the word level are needed. This framework is evaluated in terms of automatic translation evaluation metrics, and an improvement of translation quality is observed. 1 Tuning alignment for an MT system is subject to practical difficulties. Unsupervised systems (Och and Ney, 2003; Liang et al., 2006) are based on generative models trained with the EM algorithm. They require large computational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. Introduction In the first SMT systems (Brown et al., 1993), word alignment was introduced as a hidden variable of the translation model. When word-based translation models have been replaced by phrase-based models (Zens et al., 2002), alignment1 and translation model training have become two separated tasks. The system of Brown et al. was based on the noisy channel approach. Present SMT systems use a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Wit"
N07-2022,2006.iwslt-papers.7,0,0.200467,"gnment characteristics depend on each particular system makes it even more difficult. It seems that high precision alignments are better for phrase-based SMT (Chen and Federico, 2006; Ayan and Dorr, 2006), whereas high recall alignments are more suited to N-gram SMT (Mari˜no et al., 2006). In this context, alignment quality improvements does not necessarily imply translation quality improvements. This is in agreement with the observation of a poor correlation between word alignment error rate (AER (Och and Ney, 2000)) and automatic translation evaluation metrics (Ittycheriah and Roukos, 2005; Vilar et al., 2006). 85 Proceedings of NAACL HLT 2007, Companion Volume, pages 85–88, c Rochester, NY, April 2007. 2007 Association for Computational Linguistics Recently some alignment evaluation metrics have been proposed which are more informative when the alignments are used to extract translation units (Fraser and Marcu, 2006; Ayan and Dorr, 2006). However, these metrics assess translation quality very indirectly. In this paper, we propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion. Thus we just need a reference aligned at t"
N07-2022,2006.iwslt-papers.5,1,0.800234,"TM). A baseline SMT system, consisting of MARIE decoder and this translation model as unique feature2 , was used to produce a translation (OUT) of the development source set. Then, translation quality over the development set is maximized by iteratively varying the set of coefficients. The optimization procedure was performed by using the SPSA algorithm (Spall, 1992). SPSA is a stochastic implementation of the conjugate gradient method which requires only two evaluations of the objective function. It was observed to be more robust than the Downhill Simplex method when tuning SMT coefficients (Lambert and Banchs, 2006). Each function evaluation required to align the training corpus and build a new translation model. The algorithm converged after about 80 evaluations, lasting each 17 minutes with a 3 GHz processor. Alignment decoding was performed with a beam of 10 (it took 50 seconds and required 8 MB memory). Finally, the corpus was aligned with the optimum set of coefficients, and a full SMT system was build, with a target language model (trained on the provided training data), a word bonus model and two lexical models. SMT models weights were optimized with a standard Minimum Error Training (MET) strateg"
N07-2022,2002.tmi-tutorials.2,0,0.015191,"upervised systems (Och and Ney, 2003; Liang et al., 2006) are based on generative models trained with the EM algorithm. They require large computational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. Introduction In the first SMT systems (Brown et al., 1993), word alignment was introduced as a hidden variable of the translation model. When word-based translation models have been replaced by phrase-based models (Zens et al., 2002), alignment1 and translation model training have become two separated tasks. The system of Brown et al. was based on the noisy channel approach. Present SMT systems use a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Within this 1 Hereinafter, alignment will refer to word alignment, unless otherwise stated. A more general difficulty, however, is that of finding an alignment evaluation metric favoring alignments which benefit Machine Translation. The fact that the required alignment characteristics depen"
N07-2022,2006.iwslt-evaluation.1,0,\N,Missing
P11-2027,P07-1038,0,0.0252942,"ational Linguistics 2 Related Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machine translation evaluation, two workshops have been organizing shared-tasks and evaluation campaigns over the last four years: the NIST Metrics for Machine Translation Challenge 1 (MetricsMATR) and the Workshop on Statistical Machine Translation 2 (WMT); which were actually held as one single event in their most recent edition in 2010. The dataset used in this work corresponds to WMT-07. This dataset is used, instead of a more recent one, because no human judgments on adequacy and fluency have been conducted in WMT after year 2007, a"
P11-2027,W05-0909,0,0.044527,"entation. Section 4 presents the results of the conducted comparative evaluations. Finally, section 5 presents the main conclusions and relevant issues to be dealt with in future research. 153 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 153–158, c Portland, Oregon, June 19-24, 2011. 2011 Association for Computational Linguistics 2 Related Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machine translation evaluation, two workshops have been organizing shared-tasks and evaluation campaigns over the last four years: the NIST Metrics for Machine Translation"
P11-2027,2005.eamt-1.15,0,0.0161368,"sociation for Computational Linguistics 2 Related Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machine translation evaluation, two workshops have been organizing shared-tasks and evaluation campaigns over the last four years: the NIST Metrics for Machine Translation Challenge 1 (MetricsMATR) and the Workshop on Statistical Machine Translation 2 (WMT); which were actually held as one single event in their most recent edition in 2010. The dataset used in this work corresponds to WMT-07. This dataset is used, instead of a more recent one, because no human judgments on adequacy and fluency have been conducted i"
P11-2027,C04-1072,0,0.0335804,"llowed by Meteor and AM-FM, while NIST exhibits the lowest correlation coefficient values. Recall that our proposed AM-FM metric is not using reference translations for assessing translation quality, while the other three metrics are. In a similar exercise, the correlation coefficients were also computed at the sentence level (i.e. the units of analysis were sentences). These results are summarized in Table 3. As metrics are computed 4 As no development dataset was available for this particular task, a subset of the same evaluation dataset had to be used. at the sentence level, smoothed-bleu (Lin and Och, 2004) was used in this case. Again, all correlation coefficients presented in the table are statistically significant with p<0.01. Metric sBLEU NIST Meteor AM-FM Adequacy 0.3089 0.1208 0.3220 0.2142 Fluency 0.3361 0.0834 0.3065 0.2256 Metric sBLEU NIST Meteor AM-FM AM FM H Mean 0.3486 0.1201 0.3405 0.2406 Table 3: Pearson’s correlation coefficients (computed at the sentence level) between automatic metrics and human-generated scores As seen from the table, in this case, BLEU and Meteor are the metrics exhibiting the largest correlation coefficients, followed by AM-FM and NIST. 4.2 by looking at the"
P11-2027,P02-1040,0,0.0837101,"ork and the specific dataset that has been used in the experimental work. Section 3, provides details on the proposed AM-FM framework and the specific metric implementation. Section 4 presents the results of the conducted comparative evaluations. Finally, section 5 presents the main conclusions and relevant issues to be dealt with in future research. 153 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 153–158, c Portland, Oregon, June 19-24, 2011. 2011 Association for Computational Linguistics 2 Related Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machi"
P11-2027,quirk-2004-training,0,0.0213381,"2011. 2011 Association for Computational Linguistics 2 Related Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machine translation evaluation, two workshops have been organizing shared-tasks and evaluation campaigns over the last four years: the NIST Metrics for Machine Translation Challenge 1 (MetricsMATR) and the Workshop on Statistical Machine Translation 2 (WMT); which were actually held as one single event in their most recent edition in 2010. The dataset used in this work corresponds to WMT-07. This dataset is used, instead of a more recent one, because no human judgments on adequacy and fluency h"
P11-2027,U05-1019,0,0.0123316,"on for Computational Linguistics:shortpapers, pages 153–158, c Portland, Oregon, June 19-24, 2011. 2011 Association for Computational Linguistics 2 Related Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machine translation evaluation, two workshops have been organizing shared-tasks and evaluation campaigns over the last four years: the NIST Metrics for Machine Translation Challenge 1 (MetricsMATR) and the Workshop on Statistical Machine Translation 2 (WMT); which were actually held as one single event in their most recent edition in 2010. The dataset used in this work corresponds to WMT-07. This dataset"
P11-2027,2009.mtsummit-papers.16,0,0.0462511,"lated Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machine translation evaluation, two workshops have been organizing shared-tasks and evaluation campaigns over the last four years: the NIST Metrics for Machine Translation Challenge 1 (MetricsMATR) and the Workshop on Statistical Machine Translation 2 (WMT); which were actually held as one single event in their most recent edition in 2010. The dataset used in this work corresponds to WMT-07. This dataset is used, instead of a more recent one, because no human judgments on adequacy and fluency have been conducted in WMT after year 2007, and human evaluation da"
P11-2027,C04-1046,0,\N,Missing
P11-2027,W07-0718,0,\N,Missing
P11-2027,P09-2034,0,\N,Missing
P12-2040,P12-3007,1,0.233317,"Missing"
P12-2040,J93-2003,0,0.0471495,"d characteristics. 1 Introduction Data driven applications have proliferated in Computational Linguistics during the last decade. Several factors, such as the availability of more powerful computers, an almost unlimited storage capacity, the availability of large volumes of data in digital format, as well as the recent advances in machine learning theory, have significantly contributed to such a proliferation. Among the many applications that have benefited from this data-driven boom, probably the most representative examples are: information retrieval (Qin et al., 2008), machine translation (Brown et al., 1993), question answering (Molla-Aliod and Vicedo, 2010) and dialogue systems (Rieser and Lemon, 2011). In the specific case of dialogue systems, data acquisition can impose some challenges depending on the specific domain and task the dialogue system is targeted for. In some specific domains, in which human-human dialogue applications already exists, data collection is generally straight forward, while in some other cases, data design and collection can constitute a complex problem (Williams and Young, 2003; Zue, 2007; Misu et al., 2009). Depending on the objective being pursued, dialogue systems"
P12-2040,A00-1010,0,0.38775,"c domain and task the dialogue system is targeted for. In some specific domains, in which human-human dialogue applications already exists, data collection is generally straight forward, while in some other cases, data design and collection can constitute a complex problem (Williams and Young, 2003; Zue, 2007; Misu et al., 2009). Depending on the objective being pursued, dialogue systems can be grouped into two major categories: task-oriented and chat-oriented systems. In the first case, the system is required to help the user to accomplish a specific goal or objective (Busemann et al., 1997; Stallard, 2000). In the second case, the system objective is mainly entertainment oriented. Systems in this category are required to play, chitchat or just accompany the user (Weizenbaum, 1966; Wallis, 2010). In this work, we focus our attention on dialogue data which is suitable for training chat-oriented dialogue systems. Different from task-oriented dialogue collections (Mann, 2003), instead of being concentrated on a specific domain or area of knowledge, the training dataset for a chat-oriented dialogue system must cover a wide variety of domains, as well as be able to provide a fair representation of wo"
P12-2040,W10-2705,0,0.0775183,"n some other cases, data design and collection can constitute a complex problem (Williams and Young, 2003; Zue, 2007; Misu et al., 2009). Depending on the objective being pursued, dialogue systems can be grouped into two major categories: task-oriented and chat-oriented systems. In the first case, the system is required to help the user to accomplish a specific goal or objective (Busemann et al., 1997; Stallard, 2000). In the second case, the system objective is mainly entertainment oriented. Systems in this category are required to play, chitchat or just accompany the user (Weizenbaum, 1966; Wallis, 2010). In this work, we focus our attention on dialogue data which is suitable for training chat-oriented dialogue systems. Different from task-oriented dialogue collections (Mann, 2003), instead of being concentrated on a specific domain or area of knowledge, the training dataset for a chat-oriented dialogue system must cover a wide variety of domains, as well as be able to provide a fair representation of world-knowledge semantics and pragmatics (Bunt, 2000). To this end, we have collected dialogues from movie scripts aiming at constructing a dialogue corpus which should provide a good sample of"
P12-2040,A97-1006,0,0.272599,"epending on the specific domain and task the dialogue system is targeted for. In some specific domains, in which human-human dialogue applications already exists, data collection is generally straight forward, while in some other cases, data design and collection can constitute a complex problem (Williams and Young, 2003; Zue, 2007; Misu et al., 2009). Depending on the objective being pursued, dialogue systems can be grouped into two major categories: task-oriented and chat-oriented systems. In the first case, the system is required to help the user to accomplish a specific goal or objective (Busemann et al., 1997; Stallard, 2000). In the second case, the system objective is mainly entertainment oriented. Systems in this category are required to play, chitchat or just accompany the user (Weizenbaum, 1966; Wallis, 2010). In this work, we focus our attention on dialogue data which is suitable for training chat-oriented dialogue systems. Different from task-oriented dialogue collections (Mann, 2003), instead of being concentrated on a specific domain or area of knowledge, the training dataset for a chat-oriented dialogue system must cover a wide variety of domains, as well as be able to provide a fair rep"
P12-2040,W03-2111,0,\N,Missing
P12-3007,W10-4351,0,0.0208001,"samples. Additional strategies allowing for system adaptation and learning implemented over the same vector model space framework are also described and discussed. 1 Introduction Dialogue systems have been gaining popularity recently as the demand for such kind of applications have increased in many different areas. Additionally, recent advances in other related language technologies such as speech recognition, discourse analysis and natural language understanding have made possible for dialogue systems to find practical applications that are commercially exploitable (Pieraccini et al., 2009; Griol et al., 2010). From the application point of view, dialogue systems can be categorized into two major classes: task-oriented and chat-oriented. In the case of taskoriented dialogue systems, the main objective of such a system is to help the user to complete a task, which typically includes booking transportation or accommodation services, requesting specific information from a service facility, etc. (Busemann et al., 1997; Seneff and Polifroni, 2000; Stallard, 2000). On the other hand, chat-oriented systems are not intended to help the user completing any specific task, but to provide a means for participa"
P12-3007,W03-2112,0,0.124206,"ted systems are not intended to help the user completing any specific task, but to provide a means for participating in a game, or just for chitchat or entertainment. Typical examples of chat-oriented dialogue systems are the so called chat bots (Weizenbaum, 1966; Ogura et al., 2003, Wallis, 2010). In this paper, we introduce IRIS (Informal Response Interactive System), a chat-oriented dialogue system that is based on the vector space model framework (Salton et al., 1975; van Rijsbergen, 2005). From the operational point of view, IRIS belongs to the category of example-based dialogue systems (Murao et al., 2003). Its dialogue strategy is supported by a large database of dialogues that is used to provide candidate responses to a given user input. The search for candidate responses is performed by computing the cosine similarity metric into the vector space model representation, in which each utterance in the dialogue database is represented by a vector. Different from example-based question answering systems (Vicedo, 2002; Xue et al., 2008), IRIS uses a dual search strategy. In addition to the current user input, which is compared with all existent utterances in the database, a vector representation o"
P12-3007,W03-2108,0,0.0275964,"ented dialogue systems, the main objective of such a system is to help the user to complete a task, which typically includes booking transportation or accommodation services, requesting specific information from a service facility, etc. (Busemann et al., 1997; Seneff and Polifroni, 2000; Stallard, 2000). On the other hand, chat-oriented systems are not intended to help the user completing any specific task, but to provide a means for participating in a game, or just for chitchat or entertainment. Typical examples of chat-oriented dialogue systems are the so called chat bots (Weizenbaum, 1966; Ogura et al., 2003, Wallis, 2010). In this paper, we introduce IRIS (Informal Response Interactive System), a chat-oriented dialogue system that is based on the vector space model framework (Salton et al., 1975; van Rijsbergen, 2005). From the operational point of view, IRIS belongs to the category of example-based dialogue systems (Murao et al., 2003). Its dialogue strategy is supported by a large database of dialogues that is used to provide candidate responses to a given user input. The search for candidate responses is performed by computing the cosine similarity metric into the vector space model represent"
P12-3007,W10-2705,0,0.0365337,"ms, the main objective of such a system is to help the user to complete a task, which typically includes booking transportation or accommodation services, requesting specific information from a service facility, etc. (Busemann et al., 1997; Seneff and Polifroni, 2000; Stallard, 2000). On the other hand, chat-oriented systems are not intended to help the user completing any specific task, but to provide a means for participating in a game, or just for chitchat or entertainment. Typical examples of chat-oriented dialogue systems are the so called chat bots (Weizenbaum, 1966; Ogura et al., 2003, Wallis, 2010). In this paper, we introduce IRIS (Informal Response Interactive System), a chat-oriented dialogue system that is based on the vector space model framework (Salton et al., 1975; van Rijsbergen, 2005). From the operational point of view, IRIS belongs to the category of example-based dialogue systems (Murao et al., 2003). Its dialogue strategy is supported by a large database of dialogues that is used to provide candidate responses to a given user input. The search for candidate responses is performed by computing the cosine similarity metric into the vector space model representation, in which"
P12-3007,P12-2040,1,0.20203,"its last selected utterance towards the vector space representation of the previous user turn, so that the probability of generating the same response given a similar user input will be increased.  Discourage (–): IRIS will push the vector space representation of its last selected utterance apart from the vector space representation of the previous user turn, so that the probability of generating the same response given a similar user input will be decreased. 2.2 Dialogue Data Collection For the current implementation of IRIS, a subset of the Movie-DiC dialogue data collection has been used (Banchs, 2012). Movie-DiC is a dialogue corpus that has been extracted from movie scripts which are freely available at The Internet Movie Script Data Collection (http://www.imsdb.com/). In this subsection, we present a brief description on the specific data subset used for the implementation of IRIS, as well as we briefly review the process followed for collecting the data and extracting the dialogues. First of all, dialogues have to be identified and parsed from the collected html files. Three basic elements are extracted from the scripts: speakers, utterances and context. The speaker and utterance elemen"
P12-3007,A97-1006,0,0.305741,"ion, discourse analysis and natural language understanding have made possible for dialogue systems to find practical applications that are commercially exploitable (Pieraccini et al., 2009; Griol et al., 2010). From the application point of view, dialogue systems can be categorized into two major classes: task-oriented and chat-oriented. In the case of taskoriented dialogue systems, the main objective of such a system is to help the user to complete a task, which typically includes booking transportation or accommodation services, requesting specific information from a service facility, etc. (Busemann et al., 1997; Seneff and Polifroni, 2000; Stallard, 2000). On the other hand, chat-oriented systems are not intended to help the user completing any specific task, but to provide a means for participating in a game, or just for chitchat or entertainment. Typical examples of chat-oriented dialogue systems are the so called chat bots (Weizenbaum, 1966; Ogura et al., 2003, Wallis, 2010). In this paper, we introduce IRIS (Informal Response Interactive System), a chat-oriented dialogue system that is based on the vector space model framework (Salton et al., 1975; van Rijsbergen, 2005). From the operational poi"
P12-3007,A00-1010,0,\N,Missing
P13-2042,J92-4003,0,0.114588,"proposed trigger model (Lau et al. 1993, Rosenfeld 1996) that relies on the bigrams of arbitrary distance, i.e. distance-independent. Latent-semantic language model approaches (Bellegarda 1998, Coccaro 2005) weight word counts with TFIDF to highlight their semantic importance towards the prediction. In this type of approach, count statistics are accumulated from long contexts, typically beyond ten to twenty words. In order to confine the complexity introduced by such long contexts, word ordering is ignored (i.e. bag-of-words paradigm). Other approaches such as the class-based language model (Brown 1992, Kneser & Ney 1993) 233 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 233–237, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics use POS or POS-like classes of the history-words for prediction. The structured language model (Chelba & Jelinek 2000) determines the “heads” in the history-context by using a parsing tree. There are also works on skipping irrelevant history-words in order to reveal more informative ngrams (Siu & Ostendorf 2000, Guthrie et al. 2006). Cache language models exploit temporal word frequenc"
P13-2042,P96-1041,0,0.178362,",   0, which results in a division by zero. For the first problem, we have attempted to redistribute the counts among the word-pairs at different distances (as observed within the window). We assumed that the counts of word-pairs are smooth in the distance domain and that the influence of a word decays as the distance increases. Accordingly, we used a weighted moving-average filter for performing the smoothing. Similar approaches have also been used in other works (Coccaro 2005, Lv & Zhai 2009). Notice, however, that this strategy is different from other conventional smoothing techniques (Chen & Goodman 1996), which rely mainly on the countof-count statistics for re-estimating and smoothing the original counts. For the second problem, when a word-pair was not seen at any distance (within the window), we arbitrarily assigned a small probability value, ∆ |   ,   0.01 , to provide a slight chance for such a word-pair   ,  to occur at close distances. 4.3 Term-Occurrence Model Component During the decoupling operation (from Eq.2 to Eq.3), the TD model held only the distance information while the count information has been ignored. Notice the normalization of word-pair counts in Eq.6. As a"
P13-2042,P98-2239,0,0.0605763,"roduces and motivates our proposed approach. Section 4 presents in detail the derivation of both TD and TO model components. Section 5 presents some perplexity evaluation results. Finally, section 6 presents our conclusions and proposed future work. 2 Related Work The distant bigram model (Huang et.al 1993, Simon et al. 1997, Brun et al. 2007) disassembles the n-gram into (n−1) word-pairs, such that each pair is modeled by a distance-k bigram model, where 1      1 . Each distance-k bigram model predicts the target-word based on the occurrence of a history-word located k positions behind. Zhou & Lua (1998) enhanced the effectiveness of the model by filtering out those wordpairs exhibiting low correlation, so that only the well associated distant bigrams are retained. This approach is referred to as the distance-dependent trigger model, and is similar to the earlier proposed trigger model (Lau et al. 1993, Rosenfeld 1996) that relies on the bigrams of arbitrary distance, i.e. distance-independent. Latent-semantic language model approaches (Bellegarda 1998, Coccaro 2005) weight word counts with TFIDF to highlight their semantic importance towards the prediction. In this type of approach, count st"
P13-2042,guthrie-etal-2006-closer,0,0.0185418,"digm). Other approaches such as the class-based language model (Brown 1992, Kneser & Ney 1993) 233 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 233–237, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics use POS or POS-like classes of the history-words for prediction. The structured language model (Chelba & Jelinek 2000) determines the “heads” in the history-context by using a parsing tree. There are also works on skipping irrelevant history-words in order to reveal more informative ngrams (Siu & Ostendorf 2000, Guthrie et al. 2006). Cache language models exploit temporal word frequencies in the history (Kuhn & Mori 1990, Clarkson & Robinson 1997). 3 Motivation of the Proposed Approach The attributes of distance and co-occurrence are exploited and modeled differently in each language modeling approach. In the n-gram model, for example, these two attributes are jointly taken into account in the ordered word-sequence. Consequently, the n-gram model can only be effectively implemented within a short history-context (e.g. of size of three or four). Both, the conventional trigger model and the latent-semantic model capture th"
P13-2042,H93-1016,0,0.279295,"Missing"
P13-2042,C98-2234,0,\N,Missing
P14-2004,W02-0702,0,0.224513,"ing multi-topic conversations with users to provide them a more natural interaction with the system. However, the majority of previous work on dialog interfaces has focused on dealing with only a single target task. Although some multitask dialog systems have been proposed (Lin et al., 1999; Ikeda et al., 2008; Celikyilmaz et al., 2011), they have aimed at just choosing the most probable one for each input from the sub-systems, each of which is independently operated from others. To analyze and maintain dialog topics from a more systematic perspective in a given dialog flow, some researchers (Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008) have considered this dialog topic identification as a separate sub-problem of dialog management and attempted to solve it with text categorization approaches for the recognized utterances in a given turn. The major obstacle to the success of these approaches results from the differences between 19 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 19–23, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics t 0 1 Speaker Guide Tourist Guide 2 3 4"
P14-2004,P06-1093,0,0.666074,"ization tasks, the proper category for each textual unit can be assigned based only on its own content. However, the dialog topic at each turn can be determined not only by the user’s intentions captured from the given utterances, but also by the system’s decisions for dialog management purposes. Thus, the text categorization approaches can only be effective for the user-initiative cases when users tend to mention the topic-related expressions explicitly in their utterances. The other direction of dialog topic tracking approaches made use of external knowledge sources including domain models (Roy and Subramaniam, 2006), heuristics (Young et al., 2007), and agendas (Bohus and Rudnicky, 2003; Lee et al., 2008). These knowledge-based methods have an advantage of dealing with system-initiative dialogs, because dialog flows can be controlled by the system based on given resources. However, this aspect can limit the flexibility to handle the user’s responses which are contradictory to the system’s suggestions. Moreover, these approaches face cost problems for building a sufficient amount of resources to cover broad states of complex dialogs, because these resources should be manually prepared by human experts for"
P14-2004,W12-6006,0,0.0242007,"get there from Orchard Road? You can take the north-south line train from Orchard Road and stop at Raffles Place station. Is this walking distance from the station to the destination? Yes, it’ll take only ten minutes on foot. Alright. Well, you can also enjoy some seafoods at the riverside near the place. What food do you have any recommendations to try there? If you like spicy foods, you must try chilli crab which is one of our favourite dishes here in Singapore. Great! I’ll try that. Topic Transition NONE→NONE effort toward building resources for topic tracking. Recently, some researchers (Wilcock, 2012; Breuing et al., 2011) have shown the feasibility of using Wikipedia knowledge to build dialog systems. While each of these studies mainly focuses only on a single type of information including category relatedness or hyperlink connectedness, this work aims at incorporating various knowledge obtained from Wikipedia into the model using a composite kernel method. Our composite kernel consists of two different kernels: a history sequence kernel and a domain context tree kernel. Both represent the current dialog context at a given turn with a set of relevant Wikipedia paragraphs which are select"
P14-2004,P06-1104,0,0.0336331,"contradictory to the system’s suggestions. Moreover, these approaches face cost problems for building a sufficient amount of resources to cover broad states of complex dialogs, because these resources should be manually prepared by human experts for each specific domain. In this paper, we propose a composite kernel to explore various types of information obtained from Wikipedia for mixed-initiative dialog topic tracking without significant costs for building resources. Composite kernels have been successfully applied to improve the performances in other NLP problems (Zhao and Grishman, 2005; Zhang et al., 2006) by integrating multiple individual kernels, which aim to overcome the errors occurring at one level by information from other levels. Our composite kernel consists of a history sequence and a domain context tree kernels, both of which are composed based on similar textual units in Wikipedia articles to a given dialog context. Dialog topic tracking aims at analyzing and maintaining topic transitions in ongoing dialogs. This paper proposes a composite kernel approach for dialog topic tracking to utilize various types of domain knowledge obtained from Wikipedia. Two kernels are defined based on"
P14-2004,P02-1034,0,0.101364,"h of which is a subtree rooted at each paragraph node in: Pt = {pi |sim (xt , pi ) > θ}, where θ is a threshold value to select the relevant paragraphs. Each subtree consists of a set of features from a given paragraph in the Wikipedia collection in a hierarchical structure. Figure 3 shows an example of a constructed tree. Since this constructed tree structure represents semantic, discourse, and structural information extracted from the similar Wikipedia paragraphs to each given instance, we can explore these more enriched features to build the topic tracking model using a subset tree kernel (Collins and Duffy, 2002) which computes the similarity between each pair of trees in the feature space as follows: X X △ (n1 , n2 ) , Kt (T1 , T2 ) = Figure 3: An example of domain context tree the linear kernel between the vectors representing fundamental features extracted from the utterances themselves and the results of linguistic preprocessors. The composition is performed by linear combination as follows: K(x1 , x2 ) =α · Kl (V1 , V2 ) + β · Ks (S1 , S2 ) + γ · Kt (T1 , T2 ), where Vi , Si , and Ti are the feature vector, history sequence, and domain context tree of xi , respectively, Kl is the linear kernel co"
P14-2004,P05-1052,0,0.0255996,"ser’s responses which are contradictory to the system’s suggestions. Moreover, these approaches face cost problems for building a sufficient amount of resources to cover broad states of complex dialogs, because these resources should be manually prepared by human experts for each specific domain. In this paper, we propose a composite kernel to explore various types of information obtained from Wikipedia for mixed-initiative dialog topic tracking without significant costs for building resources. Composite kernels have been successfully applied to improve the performances in other NLP problems (Zhao and Grishman, 2005; Zhang et al., 2006) by integrating multiple individual kernels, which aim to overcome the errors occurring at one level by information from other levels. Our composite kernel consists of a history sequence and a domain context tree kernels, both of which are composed based on similar textual units in Wikipedia articles to a given dialog context. Dialog topic tracking aims at analyzing and maintaining topic transitions in ongoing dialogs. This paper proposes a composite kernel approach for dialog topic tracking to utilize various types of domain knowledge obtained from Wikipedia. Two kernels"
P14-2004,W02-0214,0,0.400567,"rsations with users to provide them a more natural interaction with the system. However, the majority of previous work on dialog interfaces has focused on dealing with only a single target task. Although some multitask dialog systems have been proposed (Lin et al., 1999; Ikeda et al., 2008; Celikyilmaz et al., 2011), they have aimed at just choosing the most probable one for each input from the sub-systems, each of which is independently operated from others. To analyze and maintain dialog topics from a more systematic perspective in a given dialog flow, some researchers (Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008) have considered this dialog topic identification as a separate sub-problem of dialog management and attempted to solve it with text categorization approaches for the recognized utterances in a given turn. The major obstacle to the success of these approaches results from the differences between 19 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 19–23, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics t 0 1 Speaker Guide Tourist Guide 2 3 4 5 6 7 Tourist Guide Touri"
P14-2004,P08-1072,0,0.195535,"nt. However, the dialog topic at each turn can be determined not only by the user’s intentions captured from the given utterances, but also by the system’s decisions for dialog management purposes. Thus, the text categorization approaches can only be effective for the user-initiative cases when users tend to mention the topic-related expressions explicitly in their utterances. The other direction of dialog topic tracking approaches made use of external knowledge sources including domain models (Roy and Subramaniam, 2006), heuristics (Young et al., 2007), and agendas (Bohus and Rudnicky, 2003; Lee et al., 2008). These knowledge-based methods have an advantage of dealing with system-initiative dialogs, because dialog flows can be controlled by the system based on given resources. However, this aspect can limit the flexibility to handle the user’s responses which are contradictory to the system’s suggestions. Moreover, these approaches face cost problems for building a sufficient amount of resources to cover broad states of complex dialogs, because these resources should be manually prepared by human experts for each specific domain. In this paper, we propose a composite kernel to explore various type"
P14-2004,C02-1082,0,\N,Missing
P16-1091,D13-1106,0,0.074876,"Missing"
P16-1091,P14-1062,0,0.390605,"h three different channels for current, previous, and history utterances Convolutional layer with multiple kernel sizes Max pooling layer Dense layer w softmax output Figure 2: Convolutional neural network architecture for dialogue topic tracking. 3 Models successes of bag-of-words or bag-of-ngrams considering the existence of each linguistic unit independently and the important roles of compositional structures in linguistics, CNN models have recently achieved significant improvements also in some natural language processing tasks (Collobert et al., 2011; Shen et al., 2014; Yih et al., 2014; Kalchbrenner et al., 2014a; Kim, 2014). The classifier f can be built with supervised machine learning techniques, when a set of example dialogues manually annotated with gold standard labels are available as a training set. The earlier studies (Kim et al., 2014a; Kim et al., 2014b) also proposed supervised classification approaches particularly focusing on kernel methods to incorporate domain knowledge obtained from external resources into the linear vector space models based on bag-of-words features extracted from the training dialogues. This work, on the other hand, aims at improving the classification capabilities"
P16-1091,P14-2004,1,0.90801,"tell, 2008; Ikeda et al., 2008; Celikyilmaz et al., 2011). In these approaches, a given user input at each turn is categorized into topic classes, each of which triggers the corresponding sub-system specializing in the particular topic. Despite many previous efforts, the sentence categorization methods still have the 963 Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 963–973, c Berlin, Germany, August 7-12, 2016. 2016 Association for Computational Linguistics in mixed-initiative human-human conversations, which is called dialogue topic tracking (Kim et al., 2014a; Kim et al., 2014b). In these studies, the tracking task is formulated as a classification problem for each utterance-level, similar to the sentence categorization approaches. But the target of the classification is not just an individual topic category to which each input sentence belongs, but the decision whether a topic transition occurs at a given turn as well as what the most probable topic category will follow after the transition. This paper presents our work also on dialogue topic tracking mainly focusing on the following issues. Firstly, in addition to transitions between dialogue s"
P16-1091,D14-1181,0,0.00730014,"or current, previous, and history utterances Convolutional layer with multiple kernel sizes Max pooling layer Dense layer w softmax output Figure 2: Convolutional neural network architecture for dialogue topic tracking. 3 Models successes of bag-of-words or bag-of-ngrams considering the existence of each linguistic unit independently and the important roles of compositional structures in linguistics, CNN models have recently achieved significant improvements also in some natural language processing tasks (Collobert et al., 2011; Shen et al., 2014; Yih et al., 2014; Kalchbrenner et al., 2014a; Kim, 2014). The classifier f can be built with supervised machine learning techniques, when a set of example dialogues manually annotated with gold standard labels are available as a training set. The earlier studies (Kim et al., 2014a; Kim et al., 2014b) also proposed supervised classification approaches particularly focusing on kernel methods to incorporate domain knowledge obtained from external resources into the linear vector space models based on bag-of-words features extracted from the training dialogues. This work, on the other hand, aims at improving the classification capabilities only with th"
P16-1091,W02-0214,0,0.0393585,"contextually related to each other. In this scenario, every participant in the conversation is required to understand the on-going topic discussed at each moment, detect any topic shift made by others, and make a decision to selfinitiate a new topic. These human capabilities for handling topics are also expected from dialogue systems to achieve natural and human-like conversations. Many studies have been conducted on multidomain or multi-task dialogue systems by means of sentence-level topic identification as a subtask of natural language understanding (Lin et al., 1999; Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008; Ikeda et al., 2008; Celikyilmaz et al., 2011). In these approaches, a given user input at each turn is categorized into topic classes, each of which triggers the corresponding sub-system specializing in the particular topic. Despite many previous efforts, the sentence categorization methods still have the 963 Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 963–973, c Berlin, Germany, August 7-12, 2016. 2016 Association for Computational Linguistics in mixed-initiative human-human conversations, which is called dialogue t"
P16-1091,P14-1140,0,0.0177072,"ut sequence. In a traditional RNN, hidden states connecting between input sequences and output labels are repeatedly updated with the operation s~t = g(U xt + W st−1 ), where xt is the t-th element in a given input sequence, s~t ∈ R|s |is the hidden state at t with |s |hidden units, and g is a non-linear activation function. The parameters U and W are shared all the time steps. RNNs have been successfully applied to several natural language processing tasks including language modeling (Mikolov et al., 2010), text generation (Sutskever et al., 2011), and machine translation (Auli et al., 2013; Liu et al., 2014), all of which focus on dealing with variable length word sequences. On the other hand, an input sequence to be handled in dialogue topic tracking is composed of utterance-level units instead of words. In our model (Figure 3), each utterance is represented by the k-dimensional vector ~ut ∈ Rk assigned with pre-trained sentence-level embeddings (Le and Mikolov, 2014). And then, a sequence of the utterance vectors within h time steps are connected in the recurrent layers. The default sequence of applying the recurrent operation is the ascending order from the former to the recent utterances, whi"
P16-1091,C00-2137,0,0.102675,"Missing"
P16-1091,P14-2105,0,0.0134265,"mbedding layer with three different channels for current, previous, and history utterances Convolutional layer with multiple kernel sizes Max pooling layer Dense layer w softmax output Figure 2: Convolutional neural network architecture for dialogue topic tracking. 3 Models successes of bag-of-words or bag-of-ngrams considering the existence of each linguistic unit independently and the important roles of compositional structures in linguistics, CNN models have recently achieved significant improvements also in some natural language processing tasks (Collobert et al., 2011; Shen et al., 2014; Yih et al., 2014; Kalchbrenner et al., 2014a; Kim, 2014). The classifier f can be built with supervised machine learning techniques, when a set of example dialogues manually annotated with gold standard labels are available as a training set. The earlier studies (Kim et al., 2014a; Kim et al., 2014b) also proposed supervised classification approaches particularly focusing on kernel methods to incorporate domain knowledge obtained from external resources into the linear vector space models based on bag-of-words features extracted from the training dialogues. This work, on the other hand, aims at improving the"
P16-1091,W02-0702,0,0.07709,"es of multiple topics contextually related to each other. In this scenario, every participant in the conversation is required to understand the on-going topic discussed at each moment, detect any topic shift made by others, and make a decision to selfinitiate a new topic. These human capabilities for handling topics are also expected from dialogue systems to achieve natural and human-like conversations. Many studies have been conducted on multidomain or multi-task dialogue systems by means of sentence-level topic identification as a subtask of natural language understanding (Lin et al., 1999; Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008; Ikeda et al., 2008; Celikyilmaz et al., 2011). In these approaches, a given user input at each turn is categorized into topic classes, each of which triggers the corresponding sub-system specializing in the particular topic. Despite many previous efforts, the sentence categorization methods still have the 963 Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 963–973, c Berlin, Germany, August 7-12, 2016. 2016 Association for Computational Linguistics in mixed-initiative human-human conversations,"
P16-1091,W95-0107,0,0.185358,"ds, you must try chilli crab which is one of our favourite dishes. Great! I’ll try that. f (t) B-OPEN B-ATTR I-ATTR B-ATTR I-ATTR B-TRSP I-TRSP I-TRSP I-TRSP I-TRSP B-TRSP I-TRSP B-FOOD I-FOOD I-FOOD I-FOOD Figure 1: Examples of dialogue topic tracking on a tour guide dialogue labelled with BIO tags. ATTR, TRSP and FOOD denotes the topic categories of attraction, transportation, and food, respectively. Dialogue Topic Tracking Dialogue topic tracking is defined as a multi-class classification problem to categorize the topic state at each time step into the labels encoded in BIO tagging scheme (Ramshaw and Marcus, 1995) as follows:  B-{c ∈ C} if ut is at the beginning     of a segment belongs to c,  I-{c ∈ C} else if ut is inside a f (t) =   segment belongs to c,    O otherwise, where ut is the t-th utterance in a given dialogue session and C is a closed set of topic categories. 964 Figure 1 shows an example of topic tracking on a dialogue fragment between a tour guide and a tourist. Since each tag starting with ‘B’ should occur at the beginning of a new segment after a topic transition from its previous one, the label sequence indicates that this conversation is divided into six segments at t = {"
P16-1091,C02-1082,0,\N,Missing
P16-1091,P08-1072,0,\N,Missing
W05-0823,N04-1033,0,0.265878,"Missing"
W05-0823,2004.iwslt-evaluation.14,1,0.848754,"Missing"
W05-0823,N03-1017,0,0.0598703,"Missing"
W05-0823,P00-1056,0,0.0836903,"e pairs with a word ratio larger than 2.4. As a result of this preprocessing, the number of sentences in each training set was slightly reduced. However, no significant reduction was produced. In the case of French, a re-tokenizing procedure was performed in which all apostrophes appearing alone were attached to their corresponding words. For example, pairs of tokens such as l ’ and qu ’ were reduced to single tokens such as l’ and qu’. 134 Once the training data was preprocessed, a wordto-word alignment was performed in both directions, source-to-target and target-to-source, by using GIZA++ (Och and Ney, 2000). As an approximation to the most probable alignment, the Viterbi alignment was considered. Then, the intersection and union of alignment sets in both directions were computed for each training set. 3.2 Feature Function Computation The considered translation system implements a total of five feature functions. The first of these models is the tuple 3-gram model, which was already described in section 2. Tuples for the translation model were extracted from the union set of alignments as shown in Figure 1. Once tuples had been extracted, the tuple vocabulary was pruned by using histogram pruning"
W05-0823,P02-1038,0,0.0900962,"were generated by using a statistical machine translation system which implements a log-linear combination of feature functions along with a bilingual n-gram translation model. 2 Bilingual N-gram Translation Model 1 Introduction During the last decade, statistical machine translation (SMT) systems have evolved from the original word-based approach (Brown et al., 1993) into phrase-based translation systems (Koehn et al., 2003). Similarly, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple models is implemented (Och and Ney, 2002). The SMT approach used in this work implements a log-linear combination of feature functions along with a translation model which is based on bilingual n-grams. This translation model was developed by de Gispert and Mari˜no (2002), and it differs from the well known phrase-based translation model in two basic issues: first, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. This model is described in section 2. Translation results from the four source languages made available for the shared task ("
W05-0823,P02-1040,0,0.0765659,"ts a beam-search strategy based on dynamic programming and takes into account all the five feature functions described above simultaneously. It also allows for three different pruning methods: threshold pruning, histogram pruning, and hypothesis recombination. For all the results presented in this work the decoder’s monotonic search modality was used. An optimization tool, which is based on a simplex method (Press et al., 2002), was developed and used for computing log-linear weights for each of the feature functions described above. This algorithm adjusts the log-linear weights so that BLEU (Papineni et al., 2002) is maximized over a given development set. One optimization for each language pair was performed by using the 2000-sentence development sets made available for the shared task. 4 Shared Task Results Table 2 presents the BLEU scores obtained for the shared task test data. Each test set consisted of 2000 sentences. The computed BLEU scores were case insensitive and used one translation reference. 135 sufficient and that , in the future , it is necessary to develop the Union better and a different structure... It is evident from these translation outputs that translation quality decreases when m"
W05-0823,J93-2003,0,\N,Missing
W06-2402,N03-1017,0,0.0300367,"valuations are performed by using real-life data, namely the European Parliament corpus. Results from translation tasks from English-to-Spanish and from Spanish-to-English are presented and discussed. 1 Introduction Statistical machine translation (SMT) was originally focused on word to word translation and was based on the noisy channel approach (Brown et al., 1993). Present SMT systems have evolved from the original ones in such a way that mainly differ from them in two issues: first, word-based translation models have been replaced by phrasebased translation models (Zens et al., 2002) and (Koehn et al., 2003); and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Nevertheless, it is interesting to call the attention about one important fact. Despite the change from a word-based to a phrase-based translation approach, word to word approaches for inferring alignment models from bilingual data (Vogel et al., 1996; Och and Ney, 2003) continue to be widely used. On the other hand, from observing bilingual data sets, it becomes evident that in some cases it 1"
W06-2402,2005.mtsummit-posters.11,1,0.647276,"feature functions involved which can actually help the SMT system to get the right translation. However these ideas motivate for exploring alternatives for using multi-word expression information in order to improve alignment quality and consequently translation accuracy. In this sense, our idea of a multi-word expression (hereafter MWE) refers in principle to word sequences which cannot be translated literally word-to-word. However, the automatic technique studied in this work for extracting and identifying MWEs does not necessarily follow this definition rigorously. In a preliminary study (Lambert and Banchs, 2005), we presented a technique for extracting bilingual multi-word expressions (BMWE) from parallel corpora. In that study, BMWEs identified in a small corpus2 were grouped as a unique toThis paper studies a strategy for identifying and using multi-word expressions in Statistical Machine Translation. The performance of the proposed strategy for various types of multi-word expressions (like nouns or verbs) is evaluated in terms of alignment quality as well as translation accuracy. Evaluations are performed by using real-life data, namely the European Parliament corpus. Results from translation task"
W06-2402,2005.mtsummit-papers.36,1,0.827507,"Missing"
W06-2402,W02-2001,0,0.0279132,"e, alignment results strongly depends on corpus statistics. 2 VERBMOBIL (Arranz et al., 2003) 9 • no word inside the tuple is aligned to words outside the tuple, and • no smaller tuples can be extracted without violating the previous constraints. ken before training alignment models. As a result, both alignment quality and translation accuracy were slightly improved. In this paper we applied the same BMWE extraction technique, with various improvements, to a large corpus (EPPS, described in section 4.1). Since this is a statistical technique, and frequencies of multi-word expressions are low (Baldwin and Villavicencio, 2002), the size of the corpus is an important factor. A few very basic rules based on part-of-speech have also been added to filter out noisy entries in the dictionary. Finally, BMWEs have been classified into three categories (nouns, verbs and others). In addition to the impact of the whole set, the impact of each category has been evaluated separately. The technique will be explained in section 3, after presenting the baseline translation system used (section 2). Experimental results are presented in section 4. Finally some conclusions are presented and further work in this area is depicted. 2 As"
W06-2402,P02-1038,0,0.0133702,"1 Introduction Statistical machine translation (SMT) was originally focused on word to word translation and was based on the noisy channel approach (Brown et al., 1993). Present SMT systems have evolved from the original ones in such a way that mainly differ from them in two issues: first, word-based translation models have been replaced by phrasebased translation models (Zens et al., 2002) and (Koehn et al., 2003); and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Nevertheless, it is interesting to call the attention about one important fact. Despite the change from a word-based to a phrase-based translation approach, word to word approaches for inferring alignment models from bilingual data (Vogel et al., 1996; Och and Ney, 2003) continue to be widely used. On the other hand, from observing bilingual data sets, it becomes evident that in some cases it 1 Of course, alignment results strongly depends on corpus statistics. 2 VERBMOBIL (Arranz et al., 2003) 9 • no word inside the tuple is aligned to words outside the tuple, and • no smaller tuples can be"
W06-2402,A00-1031,0,0.0297219,"ure 2 would be the following: “lo siento ; esto es verdad – I ’m sorry , this is true”. In order to increase the recall, BMWE detection was insensitive to the case of the first letter of each multi-word. The detection engine also allows a search based on lemmas. Two strategies are possible. In the first one, search is first carried out with full forms, so that lemmas are resorted to only if no match is found with full forms. In the second strategy, only lemmas are considered. • Its source or target side ends with an indefinite determiner English data have been POS-tagged using the TnT tagger (Brants, 2000), after the lemmas have been extracted with wnmorph, included in the Wordnet package (Miller et al., 1991). POS-tagging for Spanish has been performed using the FreeLing analysis tool (Carreras et al., 2004). Finally, the BMWE set has been divided in three subsets, according to the following criteria, applied in this order: • If source AND target sides of a BMWE contain at least a verb, it is assigned to the “verb” class. 3.4 • If source AND target sides of a BMWE contain at least a noun, it is assigned to the “noun” class. The modified training corpus, with identified BMWEs grouped in a uniqu"
W06-2402,J03-1002,0,0.027423,"wo issues: first, word-based translation models have been replaced by phrasebased translation models (Zens et al., 2002) and (Koehn et al., 2003); and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Nevertheless, it is interesting to call the attention about one important fact. Despite the change from a word-based to a phrase-based translation approach, word to word approaches for inferring alignment models from bilingual data (Vogel et al., 1996; Och and Ney, 2003) continue to be widely used. On the other hand, from observing bilingual data sets, it becomes evident that in some cases it 1 Of course, alignment results strongly depends on corpus statistics. 2 VERBMOBIL (Arranz et al., 2003) 9 • no word inside the tuple is aligned to words outside the tuple, and • no smaller tuples can be extracted without violating the previous constraints. ken before training alignment models. As a result, both alignment quality and translation accuracy were slightly improved. In this paper we applied the same BMWE extraction technique, with various improvements, to a la"
W06-2402,J93-2003,0,0.0101771,"using multi-word expressions in Statistical Machine Translation. The performance of the proposed strategy for various types of multi-word expressions (like nouns or verbs) is evaluated in terms of alignment quality as well as translation accuracy. Evaluations are performed by using real-life data, namely the European Parliament corpus. Results from translation tasks from English-to-Spanish and from Spanish-to-English are presented and discussed. 1 Introduction Statistical machine translation (SMT) was originally focused on word to word translation and was based on the noisy channel approach (Brown et al., 1993). Present SMT systems have evolved from the original ones in such a way that mainly differ from them in two issues: first, word-based translation models have been replaced by phrasebased translation models (Zens et al., 2002) and (Koehn et al., 2003); and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Nevertheless, it is interesting to call the attention about one important fact. Despite the change from a word-based to a phrase-based translation a"
W06-2402,J04-4002,0,0.0143237,"the alignment (and not in asymmetries only), so most BP are not BMWEs but word sequences that can be decomposed and translated word to word. 3.2 Lexical and Morpho-syntactic Filters In English and Spanish, a list of stop words3 (respectively 19 and 26) was established. The BMWE dictionary was also processed by a PartOf-Speech (POS) tagger and eight rules were written to filter out noisy entries. These rules depend on the tag set used. Examples of criteria to reject a BMWE include: 3.1.2 Scoring Based on Bilingual Phrases Here we refer to Bilingual Phrase (BP) as the bilingual phrases used by Och and Ney (2004). The BP are pairs of word groups which are supposed to be the translation of each other. The set of BP is consistent with the alignment and consists of all phrase pairs in which all words within the target language are only aligned to the words of the source language and vice versa. At least one word of the target language phrase has to be aligned with at least one word of the source language phrase. Finally, the algorithm takes into ac• Its source or target side only contains stop words • Its source or target side ends with a coordination conjunction 3 frequently occurring, semantically insi"
W06-2402,carreras-etal-2004-freeling,0,0.028016,"Missing"
W06-2402,2001.mtsummit-papers.68,0,0.0685027,"Missing"
W06-2402,2005.iwslt-1.23,0,0.0323502,"Missing"
W06-2402,C96-2141,0,0.0459094,"iffer from them in two issues: first, word-based translation models have been replaced by phrasebased translation models (Zens et al., 2002) and (Koehn et al., 2003); and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Nevertheless, it is interesting to call the attention about one important fact. Despite the change from a word-based to a phrase-based translation approach, word to word approaches for inferring alignment models from bilingual data (Vogel et al., 1996; Och and Ney, 2003) continue to be widely used. On the other hand, from observing bilingual data sets, it becomes evident that in some cases it 1 Of course, alignment results strongly depends on corpus statistics. 2 VERBMOBIL (Arranz et al., 2003) 9 • no word inside the tuple is aligned to words outside the tuple, and • no smaller tuples can be extracted without violating the previous constraints. ken before training alignment models. As a result, both alignment quality and translation accuracy were slightly improved. In this paper we applied the same BMWE extraction technique, with various i"
W06-2402,2002.tmi-tutorials.2,0,0.0310025,"translation accuracy. Evaluations are performed by using real-life data, namely the European Parliament corpus. Results from translation tasks from English-to-Spanish and from Spanish-to-English are presented and discussed. 1 Introduction Statistical machine translation (SMT) was originally focused on word to word translation and was based on the noisy channel approach (Brown et al., 1993). Present SMT systems have evolved from the original ones in such a way that mainly differ from them in two issues: first, word-based translation models have been replaced by phrasebased translation models (Zens et al., 2002) and (Koehn et al., 2003); and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Nevertheless, it is interesting to call the attention about one important fact. Despite the change from a word-based to a phrase-based translation approach, word to word approaches for inferring alignment models from bilingual data (Vogel et al., 1996; Och and Ney, 2003) continue to be widely used. On the other hand, from observing bilingual data sets, it becomes evident"
W06-2402,2004.iwslt-evaluation.14,0,0.0234831,"Missing"
W06-3101,P04-1079,0,0.0149782,"sibilities for improvements. 1 Patrik Lambert† Rafael Banchs† 2 Introduction The evaluation of the generated output is an important issue for all natural language processing (NLP) tasks, especially for machine translation (MT). Automatic evaluation is preferred because human evaluation is a time consuming and expensive task. Related Work There is a number of publications dealing with various automatic evaluation measures for machine translation output, some of them proposing new measures, some proposing improvements and extensions of the existing ones (Doddington, 2002; Papineni et al., 2002; Babych and Hartley, 2004; Matusov et al., 2005). Semi-automatic evaluation measures have been also investigated, for example in (Nießen et al., 2000). An automatic metric which uses base forms and synonyms of the words in order to correlate better to human judgements has been 1 Proceedings of the Workshop on Statistical Machine Translation, pages 1–6, c New York City, June 2006. 2006 Association for Computational Linguistics proposed in (Banerjee and Lavie, 2005). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al."
W06-3101,W05-0909,0,0.0366343,"lation output, some of them proposing new measures, some proposing improvements and extensions of the existing ones (Doddington, 2002; Papineni et al., 2002; Babych and Hartley, 2004; Matusov et al., 2005). Semi-automatic evaluation measures have been also investigated, for example in (Nießen et al., 2000). An automatic metric which uses base forms and synonyms of the words in order to correlate better to human judgements has been 1 Proceedings of the Workshop on Statistical Machine Translation, pages 1–6, c New York City, June 2006. 2006 Association for Computational Linguistics proposed in (Banerjee and Lavie, 2005). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. Automatic methods for error analysis to our knowledge have not been studied yet. Many publications propose the use of morphosyntactic information for improving the performance of a statistical machine translation system. Various methods for treating morphological and syntactical differences between German and English are investigated in (Nießen and Ney, 2000; Nie"
W06-3101,N04-4015,0,0.00900173,"has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. Automatic methods for error analysis to our knowledge have not been studied yet. Many publications propose the use of morphosyntactic information for improving the performance of a statistical machine translation system. Various methods for treating morphological and syntactical differences between German and English are investigated in (Nießen and Ney, 2000; Nießen and Ney, 2001a; Nießen and Ney, 2001b). Morphological analysis has been used for improving Arabic-English translation (Lee, 2004), for SerbianEnglish translation (Popovi´c et al., 2005) as well as for Czech-English translation (Goldwater and McClosky, 2005). Inflectional morphology of Spanish verbs is dealt with in (Popovi´c and Ney, 2004; de Gispert et al., 2005). To the best of our knowledge, the use of morpho-syntactic information for error analysis of translation output has not been investigated so far. 3 Morpho-syntactic Information and Automatic Evaluation We propose the use of morpho-syntactic information in combination with the automatic evaluation measures WER and PER in order to get more details about the tran"
W06-3101,2005.iwslt-1.19,1,0.729357,"s. 1 Patrik Lambert† Rafael Banchs† 2 Introduction The evaluation of the generated output is an important issue for all natural language processing (NLP) tasks, especially for machine translation (MT). Automatic evaluation is preferred because human evaluation is a time consuming and expensive task. Related Work There is a number of publications dealing with various automatic evaluation measures for machine translation output, some of them proposing new measures, some proposing improvements and extensions of the existing ones (Doddington, 2002; Papineni et al., 2002; Babych and Hartley, 2004; Matusov et al., 2005). Semi-automatic evaluation measures have been also investigated, for example in (Nießen et al., 2000). An automatic metric which uses base forms and synonyms of the words in order to correlate better to human judgements has been 1 Proceedings of the Workshop on Statistical Machine Translation, pages 1–6, c New York City, June 2006. 2006 Association for Computational Linguistics proposed in (Banerjee and Lavie, 2005). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006) and a detailed"
W06-3101,C00-2162,1,0.81769,"Banerjee and Lavie, 2005). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. Automatic methods for error analysis to our knowledge have not been studied yet. Many publications propose the use of morphosyntactic information for improving the performance of a statistical machine translation system. Various methods for treating morphological and syntactical differences between German and English are investigated in (Nießen and Ney, 2000; Nießen and Ney, 2001a; Nießen and Ney, 2001b). Morphological analysis has been used for improving Arabic-English translation (Lee, 2004), for SerbianEnglish translation (Popovi´c et al., 2005) as well as for Czech-English translation (Goldwater and McClosky, 2005). Inflectional morphology of Spanish verbs is dealt with in (Popovi´c and Ney, 2004; de Gispert et al., 2005). To the best of our knowledge, the use of morpho-syntactic information for error analysis of translation output has not been investigated so far. 3 Morpho-syntactic Information and Automatic Evaluation We propose the use of"
W06-3101,2001.mtsummit-papers.45,1,0.834325,"05). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. Automatic methods for error analysis to our knowledge have not been studied yet. Many publications propose the use of morphosyntactic information for improving the performance of a statistical machine translation system. Various methods for treating morphological and syntactical differences between German and English are investigated in (Nießen and Ney, 2000; Nießen and Ney, 2001a; Nießen and Ney, 2001b). Morphological analysis has been used for improving Arabic-English translation (Lee, 2004), for SerbianEnglish translation (Popovi´c et al., 2005) as well as for Czech-English translation (Goldwater and McClosky, 2005). Inflectional morphology of Spanish verbs is dealt with in (Popovi´c and Ney, 2004; de Gispert et al., 2005). To the best of our knowledge, the use of morpho-syntactic information for error analysis of translation output has not been investigated so far. 3 Morpho-syntactic Information and Automatic Evaluation We propose the use of morpho-syntactic infor"
W06-3101,W01-1407,1,0.840883,"05). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. Automatic methods for error analysis to our knowledge have not been studied yet. Many publications propose the use of morphosyntactic information for improving the performance of a statistical machine translation system. Various methods for treating morphological and syntactical differences between German and English are investigated in (Nießen and Ney, 2000; Nießen and Ney, 2001a; Nießen and Ney, 2001b). Morphological analysis has been used for improving Arabic-English translation (Lee, 2004), for SerbianEnglish translation (Popovi´c et al., 2005) as well as for Czech-English translation (Goldwater and McClosky, 2005). Inflectional morphology of Spanish verbs is dealt with in (Popovi´c and Ney, 2004; de Gispert et al., 2005). To the best of our knowledge, the use of morpho-syntactic information for error analysis of translation output has not been investigated so far. 3 Morpho-syntactic Information and Automatic Evaluation We propose the use of morpho-syntactic infor"
W06-3101,niessen-etal-2000-evaluation,1,0.397729,"nt issue for all natural language processing (NLP) tasks, especially for machine translation (MT). Automatic evaluation is preferred because human evaluation is a time consuming and expensive task. Related Work There is a number of publications dealing with various automatic evaluation measures for machine translation output, some of them proposing new measures, some proposing improvements and extensions of the existing ones (Doddington, 2002; Papineni et al., 2002; Babych and Hartley, 2004; Matusov et al., 2005). Semi-automatic evaluation measures have been also investigated, for example in (Nießen et al., 2000). An automatic metric which uses base forms and synonyms of the words in order to correlate better to human judgements has been 1 Proceedings of the Workshop on Statistical Machine Translation, pages 1–6, c New York City, June 2006. 2006 Association for Computational Linguistics proposed in (Banerjee and Lavie, 2005). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. Automatic methods for error analysis to our kno"
W06-3101,P02-1040,0,0.115841,"t`ecnica de Catalunya (UPC), Barcelona, Spain ⊥ ITC-irst, Centro per la Ricerca Scientifica e Tecnologica, Trento, Italy {popovic,ney}@informatik.rwth-aachen.de {gupta,federico}@itc.it {agispert,canton}@gps.tsc.upc.es {lambert,banchs}@gps.tsc.upc.es Abstract A variety of automatic evaluation measures have been proposed and studied over the last years, some of them are shown to be a very useful tool for comparing different systems as well as for evaluating improvements within one system. The most widely used are Word Error Rate (WER), Position Independent Word Error Rate (PER), the BLEU score (Papineni et al., 2002) and the NIST score (Doddington, 2002). However, none of these measures give any details about the nature of translation errors. A relationship between these error measures and the actual errors in the translation outputs is not easy to find. Therefore some analysis of the translation errors is necessary in order to define the main problems and to focus the research efforts. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006), but like human evaluation, this is also a time consuming task. The goal of this work is to present a framework for au"
W06-3101,popovic-ney-2004-towards,1,0.340303,"Missing"
W06-3101,popovic-ney-2006-pos,1,0.738548,"Missing"
W06-3101,2005.mtsummit-papers.34,1,0.721067,"173 0.15 0.09 2.7 1.7 840 1094 22774 26917 4081 3958 0.14 0.25 2.8 2.6 Table 1: Corpus statistics for the Spanish-English EPPS task (running words include punctuation marks) corpus). The statistics of the corpora can be seen in Table 1. The statistical machine translation system used in this work is based on a log-linear combination of seven different models. The most important ones are phrase based models in both directions, additionally IBM1 models at the phrase level in both directions as well as phrase and length penalty are used. A more detailed description of the system can be found in (Vilar et al., 2005; Zens et al., 2005). 4.3 Experiments The translation experiments have been done in both translation directions on both sizes of the corpus. In order to examine improvements of the baseline system, a new system with POS-based word reorderings of nouns and adjectives as proposed in (Popovi´c and Ney, 2006) is also analysed. Adjectives in the Spanish language are usually placed after the corresponding noun, whereas for English it is the other way round. Therefore, local reorderings of nouns and ad3 WER 34.5 33.5 41.8 38.9 PER 25.5 25.2 30.7 29.5 BLEU 54.7 56.4 43.2 48.5 English→Spanish full base"
W06-3101,vilar-etal-2006-error,1,0.542481,"Missing"
W06-3101,2005.iwslt-1.20,1,0.479674,"7 840 1094 22774 26917 4081 3958 0.14 0.25 2.8 2.6 Table 1: Corpus statistics for the Spanish-English EPPS task (running words include punctuation marks) corpus). The statistics of the corpora can be seen in Table 1. The statistical machine translation system used in this work is based on a log-linear combination of seven different models. The most important ones are phrase based models in both directions, additionally IBM1 models at the phrase level in both directions as well as phrase and length penalty are used. A more detailed description of the system can be found in (Vilar et al., 2005; Zens et al., 2005). 4.3 Experiments The translation experiments have been done in both translation directions on both sizes of the corpus. In order to examine improvements of the baseline system, a new system with POS-based word reorderings of nouns and adjectives as proposed in (Popovi´c and Ney, 2006) is also analysed. Adjectives in the Spanish language are usually placed after the corresponding noun, whereas for English it is the other way round. Therefore, local reorderings of nouns and ad3 WER 34.5 33.5 41.8 38.9 PER 25.5 25.2 30.7 29.5 BLEU 54.7 56.4 43.2 48.5 English→Spanish full baseline reorder 13k bas"
W06-3101,H05-1085,0,\N,Missing
W06-3120,A00-1031,0,0.0229195,"ese figures in the optimization function. 3 Shared Task Results 3.1 Data The data provided for this shared task corresponds to a subset of the official transcriptions of the European Parliament Plenary Sessions, and it is available through the shared task website at: http://www.statmt.org/wmt06/shared-task/. The development set used to tune the system consists of a subset (500 first sentences) of the official development set made available for the Shared Task. We carried out a morphological analysis of the data. The English POS-tagging has been carried out using freely available T N T tagger (Brants, 2000). In the Spanish case, we have used the F reeling (Carreras et al., 2004) analysis tool which generates the POS-tagging for each input word. 3.2 Systems configurations The baseline system is the same for all tasks and includes the following features functions: cp, pp, lm, ibm1, ibm1−1 , wb, pb. The POStag target language model has been used in those tasks for which the tagger was available. Table 1 shows the reordering configuration used for each task. The Block Reordering (application 2) has been used when the source language belongs to the Romanic family. The length of the block is limited t"
W06-3120,W05-0827,1,0.879283,"Missing"
W06-3120,2005.iwslt-1.23,1,0.907982,"Missing"
W06-3120,W06-3125,1,0.884485,"Missing"
W06-3120,P05-2012,1,0.889176,"Missing"
W06-3120,W05-0831,0,0.0297232,"Full verb forms The morphology of the verbs usually differs in each language. Therefore, it is interesting to classify the verbs in order to address the rich variety of verbal forms. Each verb is reduced into its base form and reduced POS tag as explained in (de Gispert, 2005). This transformation is only done for the alignment, and its goal is to simplify the work of the word alignment improving its quality. Block reordering (br) The difference in word order between two languages is one of the most significant sources of error in SMT. Related works either deal with reordering in general as (Kanthak et al., 2005) or deal with local reordering as (Tillmann and Ney, 2003). We report a local reordering technique, which is implemented as a preprocessing stage, with two applications: (1) to improve only alignment quality, and (2) to improve alignment quality and to infer reordering in translation. Here, we present a short explanation of the algorithm, for further details see Costa-juss`a and Fonollosa (2006). 142 Proceedings of the Workshop on Statistical Machine Translation, pages 142–145, c New York City, June 2006. 2006 Association for Computational Linguistics of the bilingual phrase, and no word on ei"
W06-3120,W06-3114,0,0.0221223,"ts to observe its efficiency in all the pairs used in this evaluation. The rgraph has been applied in those cases where: we do not use br2 (there is no sense in applying them simultaneously); and we have the tagger for the source language model available. In the case of the pair GeEn, we have not experimented any reordering, we left the application of both reordering approaches as future work. 3.3 Discussion Table 2 presents the BLEU scores evaluated on the test set (using TRUECASE) for each configuration. The official results were slightly better because a lowercase evaluation was used, see (Koehn and Monz, 2006). For both, Es2En and Fr2En tasks, br helps slightly. The improvement of the approach depends on the quality of the alignment. The better alignments allow to extract higher quality Alignment Blocks (Costa-juss`a and Fonollosa, 2006). The En2Es task is improved when adding both br1 and rgraph. Similarly, the En2Fr task seems to perform fairly well when using the rgraph. In this case, the improvement of the approach depends on the quality of the alignment patterns (Crego et al., 2006). However, it has the advantage of delaying the final decision of reordering to the overall search, where all mod"
W06-3120,N03-1017,0,0.00728769,"o infer reordering in translation. Here, we present a short explanation of the algorithm, for further details see Costa-juss`a and Fonollosa (2006). 142 Proceedings of the Workshop on Statistical Machine Translation, pages 142–145, c New York City, June 2006. 2006 Association for Computational Linguistics of the bilingual phrase, and no word on either side of the phrase is aligned to a word out of the phrase. We limit the maximum size of any given phrase to 7. The huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (Koehn et al., 2003) as the probability of reappearance of larger phrases decreases. 2.3 Figure 1: Example of an Alignment Block, i.e. a pair of consecutive blocks whose target translation is swapped This reordering strategy is intended to infer the most probable reordering for sequences of words, which are referred to as blocks, in order to monotonize current data alignments and generalize reordering for unseen pairs of blocks. Given a word alignment, we identify those pairs of consecutive source blocks whose translation is swapped, i.e. those blocks which, if swapped, generate a correct monotone translation. Fi"
W06-3120,J04-4002,0,0.0268059,"created). Based on this information, the source side of the bilingual corpora are reordered. In case of applying the reordering technique for purpose (1), we modify only the source training corpora to realign and then we recover the original order of the training corpora. In case of using Block Reordering for purpose (2), we modify all the source corpora (both training and test), and we use the new training corpora to realign and build the final translation system. 2.2 Phrase Extraction Given a sentence pair and a corresponding word alignment, phrases are extracted following the criterion in Och and Ney (2004). A phrase (or bilingual phrase) is any pair of m source words and n target words that satisfies two basic constraints: words are consecutive along both sides 143 Feature functions Conditional and posterior probability (cp, pp) Given the collected phrase pairs, we estimate the phrase translation probability distribution by relative frequency in both directions. The target language model (lm) consists of an n-gram model, in which the probability of a translation hypothesis is approximated by the product of word n-gram probabilities. As default language model feature, we use a standard word-base"
W06-3120,carreras-etal-2004-freeling,0,\N,Missing
W06-3120,J03-1005,0,\N,Missing
W06-3120,N04-1033,0,\N,Missing
W06-3125,W05-0823,1,0.872672,"Missing"
W06-3125,A00-1031,0,0.117706,"d over the development set for each of the six translation directions considered. 163 This baseline system is actually very similar to the system used for last year’s shared task “Exploiting Parallel Texts for Statistical Machine Translation” of ACL’05 Workshop on Building and Using Parallel Texts: Data-Driven Machine Translation and Beyond (Banchs et al., 2005), whose results are available at: http://www.statmt.org/wpt05/ mt-shared-task/. A more detailed description of the system can be found in (2005). The tools used for POS-tagging were Freeling (Carreras et al., 2004) for Spanish and TnT (Brants, 2000) for English. All language models were estimated using the SRI language modeling toolkit. Word-to-word alignments were extracted with GIZA++. Improvements in word-toword alignments were achieved through verb group classification as described in (de Gispert, 2005). 3 Reordering Framework In this section we outline the reordering framework used for the experiments (Crego and Mari˜no, 2006). A highly constrained reordered search is performed by means of a set of reordering patterns (linguistically motivated rewrite patterns) which are used to extend the monotone search graph with additional arcs."
W06-3125,carreras-etal-2004-freeling,0,0.0548444,"Missing"
W06-3125,W06-3120,1,0.883993,"Missing"
W06-3125,N04-1033,0,0.0842803,"Missing"
W06-3125,P05-2012,1,0.901179,"Missing"
W06-3125,N03-1017,0,0.00542142,"luation with a tagged target language model (using Part-Of-Speech tags). For both Spanish-English translation directions and the English-to-French translation task, the baseline system allows for linguistically motivated sourceside reorderings. 2 Baseline N-gram-based SMT System 1 Introduction The statistical machine translation approach used in this work implements a log-linear combination of feature functions along with a translation model which is based on bilingual n-grams (de Gispert and Mari˜no, 2002). This translation model differs from the well known phrase-based translation approach (Koehn et al., 2003) in two basic issues: first, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. This translation approach is described in detail in (Mari˜no et al., 2005). For those translation tasks with Spanish or English as target language, an additional tagged (usAs already mentioned, the translation model used here is based on bilingual n-grams. It actually constitutes a language model of bilingual units, referred to as tuples, which approximates the joint probability between source and target languages by us"
W06-3125,2005.mtsummit-papers.36,1,0.909254,"Missing"
W06-3125,J93-2003,0,\N,Missing
W07-0713,E06-1032,0,0.0191741,"sk, namely the ranking of systems. Furthermore we argue that machine translation evaluations should be regarded as statistical processes, both for human and automatic evaluation. We show how confidence ranges for state-of-the-art evaluation measures such as WER and TER can be computed accurately and efficiently without having to resort to Monte Carlo estimates. We give an example of our new evaluation scheme, as well as a comparison with classical automatic and human evaluation on data from a recent international evaluation campaign. 1 However, automatic measures also have big disadvantages; (Callison-Burch et al., 2006) describes some of them. A major problem is that a given sentence in one language can have several correct translations in another language and thus, the measure of similarity with one or even a small amount of reference translations will never be flexible enough to truly reflect the wide range of correct possibilities of a translation. 1 This holds in particular for long sentences and wide- or open-domain tasks like the ones dealt with in current MT projects and evaluations. Introduction Evaluation of machine translation (MT) output is a difficult and still open problem. As in other natural l"
W07-0713,1993.eamt-1.1,0,0.0573576,"binary comparison experiments, each judge was given hypothesis translations ei,X , ei,Y . She could then judge ei,X to be better than, equal to, or worse than ei,Y . All these judgments were counted over the systems. We define a sentence score ri,X,Y for this evaluation method as follows:   +1 ei,X is better than ei,Y ri,X,Y := 0 . (2) ei,X is equal to ei,Y  −1 e is worse than e i,X i,Y Then, the total evaluation score for a binary comparison of systems X and Y is m RX,Y 1 X ri,X,Y , := m (3) i=1 with m the number of evaluated sentences. For this case, namely R being an arithmetic mean, (Efron and Tibshirani, 1993) gives an explicit formula for the estimated standard error of the score RX,Y . To simplify the notation, we will use R instead of RX,Y from now on, and ri instead of ri,X,Y . v um X 1 u t (ri − R)2 . se[R] = (4) m−1 i=1 With x denoting the number of sentences where ri = 1, and y denoting the number of sentences where ri = −1, x−y m R= Train (5) and with basic algebra 1 se[R] = m−1 Test r (x − y)2 x+y− . m (6) Moreover, we can explicitly give an estimate for E[R0 ]: The null hypothesis is that both systems are “equally good”. Then, we should expect as many sentences where X is better than Y as"
W07-0713,W06-3114,0,0.0339031,", there can be biases among the human judges. Large amounts of sentences must therefore be evaluated and procedures like evaluation normalization must be carried out before significant conclusions from the evaluation can be drawn. Another important drawback, which is also one of the causes of the aforementioned problems, is that it is very difficult to define the meaning of the numerical scores precisely. Even if human judges have explicit evaluation guidelines at hand, they still find it difficult to assign a numerical value which represents the quality of the translation for many sentences (Koehn and Monz, 2006). In this paper we present an alternative to this evaluation scheme. Our method starts from the observation that normally the final objective of a human evaluation is to find a “ranking” of different systems, and the absolute score for each system is not relevant (and it can even not be comparable between different evaluations). We focus on a method that aims to simplify the task of the judges and allows to rank the systems according to their translation quality. 3 Binary System Comparisons The main idea of our method relies in the fact that a human evaluator, when presented two different tran"
W07-0713,W05-0903,1,0.854992,"impossible to eliminate them if humans are involved. If one of the judges prefers one kind of structure, there will a bias for a system producing such output, independently of the evaluation procedure. However, the suppression of explicit numerical scores eliminates an additional bias of evaluators. It has been observed that human judges often give scores within 6 Note however that possible evaluator biases can have a great influence in these statistics. a certain range (e.g. in the mid-range or only extreme values), which constitute an additional difficulty when carrying out the evaluation (Leusch et al., 2005). Our method suppresses this kind of bias. Another advantage of our method is the possibility of assessing improvements within one system. With one evaluation we can decide if some modifications actually improve performance. This evaluation even gives us a confidence interval to weight the significance of an improvement. Carrying out a full adequacy-fluency analysis would require a lot more effort, without giving more useful results. 7 Conclusion We presented a novel human evaluation technique that simplifies the task of the evaluators. Our method relies on two basic observations. The first on"
W07-0713,P03-1021,0,0.0111467,"restricted the number of systems in order to keep the evaluation effort manageable for a first experimental setup to test the feasibility of our method. The ranking of 5 systems can be carried out with as few as 7 comparisons, but the ranking of 9 systems requires 19 comparisons. 5 Evaluation Results i=1 (9) With this Equation, Monte-Carlo-estimates are no longer necessary for examining the significance of WER, PER, TER, etc. Unfortunately, we do not expect such a short explicit formula to exist for the standard BLEU score. Still, a confidence range for BLEU can be estimated by bootstrapping (Och, 2003; Zhang and Vogel, 2004). 100 Seven human bilingual evaluators (6 native speakers and one near-native speaker of Spanish) carried out the evaluation. 100 sentences were randomly chosen and assigned to each of the evaluators for every system comparison, as discussed in Section 3.3. The results can be seen in Table 2 and Figure 2. Counts 4 http://www.tc-star.org/ ● ● ● ● 400 300 B−D E−A ●D−C B−A D−A 0 10 20 ● A−C E−B 200 ● 100 # &quot;Second system better&quot; 70 60 50 40 30 ● 0 # &quot;Second system better&quot; B−A D−C A−C E−A E−B B−D D−A ● 0 10 20 30 40 50 60 70 0 # &quot;First system better&quot; 100 200 300 400 # &quot;Firs"
W07-0713,P02-1040,0,0.0919255,"of correct possibilities of a translation. 1 This holds in particular for long sentences and wide- or open-domain tasks like the ones dealt with in current MT projects and evaluations. Introduction Evaluation of machine translation (MT) output is a difficult and still open problem. As in other natural language processing tasks, automatic measures which try to asses the quality of the translation can be computed. The most widely known are the Word Error Rate (WER), the Position independent word Error Rate (PER), the NIST score (Doddington, 2002) and, especially in recent years, the BLEU score (Papineni et al., 2002) and the Translation ErIf the actual quality of a translation in terms of usefulness for human users is to be evaluated, human evaluation needs to be carried out. This is however a costly and very time-consuming process. In this work we present a novel approach to human evaluation that simplifies the task for human judges. Instead of having to assign numerical scores to each sentence to be evaluated, as is done in current evaluation procedures, human judges choose the best one out of two candidate translations. We show how this method can be used to rank an arbitrary number of systems and pres"
W07-0713,2005.mtsummit-papers.34,1,0.679589,"oject4 . The goal of this project is to build a speech-to-speech translation system that can deal with real life data. Three translation directions are dealt with in the project: Spanish to English, English to Spanish and Chinese to English. For the system comparison we concentrated only in the English to Spanish direction. The corpus for the Spanish–English language pair consists of the official version of the speeches held in the European Parliament Plenary Sessions (EPPS), as available on the web page of the European Parliament. A more detailed description of the EPPS data can be found in (Vilar et al., 2005). Table 1 shows the statistics of the corpus. A total of 9 different MT systems participated in this condition in the evaluation campaign that took place in February 2006. We selected five representative systems for our study. Henceforth we shall refer to these systems as System A through System E. We restricted the number of systems in order to keep the evaluation effort manageable for a first experimental setup to test the feasibility of our method. The ranking of 5 systems can be carried out with as few as 7 comparisons, but the ranking of 9 systems requires 19 comparisons. 5 Evaluation Res"
W07-0713,2004.tmi-1.9,0,0.0207347,"the number of systems in order to keep the evaluation effort manageable for a first experimental setup to test the feasibility of our method. The ranking of 5 systems can be carried out with as few as 7 comparisons, but the ranking of 9 systems requires 19 comparisons. 5 Evaluation Results i=1 (9) With this Equation, Monte-Carlo-estimates are no longer necessary for examining the significance of WER, PER, TER, etc. Unfortunately, we do not expect such a short explicit formula to exist for the standard BLEU score. Still, a confidence range for BLEU can be estimated by bootstrapping (Och, 2003; Zhang and Vogel, 2004). 100 Seven human bilingual evaluators (6 native speakers and one near-native speaker of Spanish) carried out the evaluation. 100 sentences were randomly chosen and assigned to each of the evaluators for every system comparison, as discussed in Section 3.3. The results can be seen in Table 2 and Figure 2. Counts 4 http://www.tc-star.org/ ● ● ● ● 400 300 B−D E−A ●D−C B−A D−A 0 10 20 ● A−C E−B 200 ● 100 # &quot;Second system better&quot; 70 60 50 40 30 ● 0 # &quot;Second system better&quot; B−A D−C A−C E−A E−B B−D D−A ● 0 10 20 30 40 50 60 70 0 # &quot;First system better&quot; 100 200 300 400 # &quot;First system better&quot; (a) Eac"
W07-0720,W06-3125,1,0.849606,"Missing"
W07-0720,W06-1609,1,0.795127,"Missing"
W07-0720,W06-3114,0,0.0213063,"this system participation in the ACL 2007 SECOND WORK SHOP ON STATISTICAL MACHINE TRANSLA TION . Results on three pairs of languages are reported, namely from Spanish, French and German into English (and the other way round) for both the in-domain and out-of-domain tasks. 2 Baseline N-gram-based SMT System 1 Introduction Based on estimating a joint-probability model between the source and the target languages, Ngram-based SMT has proved to be a very competitive alternatively to phrase-based and other state-of-the-art systems in previous evaluation campaigns, as shown in (Koehn and Monz, 2005; Koehn and Monz, 2006). Given the challenge of domain adaptation, efforts have been focused on improving strategies for Ngram-based SMT which could generalize better. Specifically, a novel reordering strategy is explored. It is based on extending the search by using precomputed statistical information. Results are promising while keeping computational expenses at a similar level as monotonic search. Additionally, a bonus for tuples from the out-of-domain corpus is The translation model is based on bilingual n-grams. It actually constitutes a language model of bilingual units, referred to as tuples, which approximat"
W07-0720,J06-4004,1,0.847357,"Missing"
W07-0720,E99-1010,0,0.731366,"smaller tuples which reduces the translation vocabulary sparseness. These new tuples are used to build the SMT system. 3 Baseline System Enhanced with a Weighted Reordering Input Graph This section briefly describes the statistical machine reordering (SMR) technique. Further details on the architecture of SMR system can be found on (Costa-juss`a and Fonollosa, 2006). 3.1 Concept The SMR system can be seen as a SMT system which translates from an original source language (S) to a reordered source language (S’), given a target language (T). The SMR technique works with statistical word classes (Och, 1999) instead of words themselves (particularly, we have used 200 classes in all experiments). Figure 1: SMR approach in the (A) training step (B) in the test step (the weight of each arch is in brackets). 3.2 Using SMR technique to improve SMT training The original source corpus S is translated into the reordered source corpus S’ with the SMR system. Figure 1 (A) shows the corresponding block diagram. The reordered training source corpus and the original training target corpus are used to build the SMT system. The main difference here is that the training is computed with the S’2T task instead of"
W07-0720,W05-0820,0,\N,Missing
W08-0315,W08-0315,1,0.0512755,"Missing"
W08-0315,J90-2002,0,0.809551,"Missing"
W08-0315,W07-0718,0,0.152941,"Missing"
W08-0315,carreras-etal-2004-freeling,0,0.138533,"Missing"
W08-0315,W06-3114,0,0.151633,"Missing"
W08-0315,P00-1056,0,0.073606,"Missing"
W08-0315,J04-4002,0,0.0735646,"Missing"
W08-0315,W05-0820,0,\N,Missing
W08-0315,A00-1031,0,\N,Missing
W08-0315,J06-4004,1,\N,Missing
W09-0414,J04-4002,0,0.0266217,"is translated into target language using translation table, (3) the target phrases are reordered to be inherent in the target language. A bilingual phrase (which in the context of SMT do not necessarily coincide with their linguistic analogies) is any pair of m source words and n target words that satisfies two basic constraints: (1) words are consecutive along both sides of the bilingual phrase and (2) no word on either side of the phrase is aligned to a word outside the phrase. Given a sentence pair and a corresponding wordto-word alignment, phrases are extracted following the criterion in (Och and Ney, 2004). The probability of the phrases is estimated by relative frequencies of their appearance in the training corpus. Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 85–89, c Athens, Greece, 30 March – 31 March 2009. 2009 Association for Computational Linguistics 85 Classically, a phrase-based translation system implements a log-linear model in which a foreign language sentence f1J = f1 , f2 , ..., fJ is translated into another language eI1 = e1 , e2 , ..., eI by searching for the translation hypothesis eˆI1 maximizing a log-linear combination of several feature model"
W09-0414,J90-2002,0,0.572532,"he probability of the phrases is estimated by relative frequencies of their appearance in the training corpus. Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 85–89, c Athens, Greece, 30 March – 31 March 2009. 2009 Association for Computational Linguistics 85 Classically, a phrase-based translation system implements a log-linear model in which a foreign language sentence f1J = f1 , f2 , ..., fJ is translated into another language eI1 = e1 , e2 , ..., eI by searching for the translation hypothesis eˆI1 maximizing a log-linear combination of several feature models (Brown et al., 1990): eˆI1 = arg max eI1 ( M X w P (w) = λEuroparl · PEuroparl + λN C · PNwC (1) w and PNwC are probabilities aswhere PEuroparl signed to the word sequence w by the LM estimated on Europarl and NC data, respectively. The scale factor values are automatically optimized to obtain the lowest perplexity ppl(w) produced by the interpolated LM P (w). We used the standard script compute − best − mix from the SRI LM package (Stolcke, 2002) for optimization. On the next step, the optimized coefficients λEuroparl and λN C are generalized on the interpolated translation and reordering models. In other words,"
W09-0414,W07-0717,0,0.0343889,"he corresponding improvement in BLEU score is presented in Section 3.3 and summary of the obtained results (Table 4). ) λm hm (eI1 , f1J ) m=1 where the feature functions hm refer to the system models and the set of λm refers to the weights corresponding to these models. 2.1 Translation models interpolation We implemented a TM interpolation strategy following the ideas proposed in (Schwenk and Estève, 2008), where the authors present a promising technique of target LMs linear interpolation; in (Koehn and Schroeder, 2007) where a log-linear combination of TMs is performed; and specifically in (Foster and Kuhn, 2007) where the authors present various ways of TM combination and analyze in detail the TM domain adaptation. In the framework of the evaluation campaign, there were two Spanish-to-English parallel training corpora available: Europarl v.4 corpus (about 50M tokens) and News Commentary (NC) corpus (about 2M tokens). The test dataset provided by the organizers this year was from the news domain, so we considered the Europarl training corpus as &quot;out-of-domain&quot; data and the News Commentary as &quot;in-domain&quot; training material. Unfortunately, the in-domain corpus is much smaller in size, however the Europar"
W09-0414,W07-0733,0,0.0262365,"l LMs and the 2009 development set (English and Spanish references) can be found in Table 1, while the corresponding improvement in BLEU score is presented in Section 3.3 and summary of the obtained results (Table 4). ) λm hm (eI1 , f1J ) m=1 where the feature functions hm refer to the system models and the set of λm refers to the weights corresponding to these models. 2.1 Translation models interpolation We implemented a TM interpolation strategy following the ideas proposed in (Schwenk and Estève, 2008), where the authors present a promising technique of target LMs linear interpolation; in (Koehn and Schroeder, 2007) where a log-linear combination of TMs is performed; and specifically in (Foster and Kuhn, 2007) where the authors present various ways of TM combination and analyze in detail the TM domain adaptation. In the framework of the evaluation campaign, there were two Spanish-to-English parallel training corpora available: Europarl v.4 corpus (about 50M tokens) and News Commentary (NC) corpus (about 2M tokens). The test dataset provided by the organizers this year was from the news domain, so we considered the Europarl training corpus as &quot;out-of-domain&quot; data and the News Commentary as &quot;in-domain&quot; tra"
W09-0414,P07-2045,0,0.00511337,"investigate the translation models (TMs) interpolation for a state-of-the-art phrase-based translation system. Inspired by the work presented in (Schwenk and Estève, 2008), we attack this challenge using the coefficients obtained for the corresponding monolingual language models (LMs) for TMs interpolation. On the second step, we have performed additional word reordering experiments, comparing the results obtained with a statistiTALP-UPC phrase-based SMT The system developed for this year’s shared task is based on a state-of-the-art SMT system implemented within the open-source MOSES toolkit (Koehn et al., 2007). A phrase-based translation is considered as a three step algorithm: (1) the source sequence of words is segmented in phrases, (2) each phrase is translated into target language using translation table, (3) the target phrases are reordered to be inherent in the target language. A bilingual phrase (which in the context of SMT do not necessarily coincide with their linguistic analogies) is any pair of m source words and n target words that satisfies two basic constraints: (1) words are consecutive along both sides of the bilingual phrase and (2) no word on either side of the phrase is aligned t"
W09-0414,N04-1022,0,\N,Missing
W09-0414,2009.eamt-1.27,1,\N,Missing
W10-0718,esuli-sebastiani-2006-sentiwordnet,0,0.0127386,"gure 1: An example sentence (a) and the three HIT designs used in the experiments: (b) HIT1: a simple categorization scheme, (c) HIT2: a graded categorization scheme, and (d) HIT3: a continuous triangular scoring scheme containing both a horizontal positive-negative axis and a vertical subjective-objective axis. workers to use both a horizontal positive-negative axis and a vertical subjective-objective axis by placing the example sentence anywhere inside the triangle. The subjective-objective axis expresses the degree to which the sentence contains opinionated content and was earlier used by (Esuli and Sebastiani, 2006). For example, the sentence ‘I think this is a wonderful car’ clearly marks an opinion and should be positioned towards the subjective end, while the sentence ‘The car has six cilinders’ should be located towards the objective end. Figure 1d contains an example of HIT3. In order not to burden the workers with overly complex instructions, we did not mention this subjective-objective axis but asked them instead to place ambiguous sentences towards the center of the horizontal positive-negative axis and more objective, non-opinionated sentences towards the lower neutral tip of the triangle. For e"
W10-0718,D08-1027,0,0.37677,"Missing"
W10-1712,J93-1007,0,0.542371,"Missing"
W10-1712,2010.eamt-1.17,1,0.900144,"els among others. Introduction 1 in coop2 3 eration with BMIC and VMU participated in the The TALP Research Center of the UPC 3 Collocation segmentation Collocation segmentation is the process of deSpanish-to-English WMT task. Our primary subtecting boundaries between collocation segments mission was a phrase-based SMT system enhanced within a text (Daudaravicius and Marcinkeviciene, with POS tags and our contrastive submission was 2004). A collocation segment is a piece of text bean augmented phrase-based system using collocatween boundaries. The boundaries are established tion segmentation (Costa-jussà et al., 2010), which in two steps using two dierent measures: the Dice mainly is a way of introducing new phrases in the score and a Average Minimum Law (AML). translation table. This paper presents the descripThe Dice score is used to measure the association of both systems together with the results that tion strength between two words. It has been used we obtained in the evaluation task and is organized before in the collocation compiler XTract (Smadja, as follows: rst, Section 2 and 3 present a brief de1993) and in the lexicon extraction system Chamscription of a phrase-based SMT, followed by a genpol"
W10-1712,N04-4026,0,0.143207,"Missing"
W10-1712,P07-2045,0,0.00766655,"Missing"
W10-1712,2005.mtsummit-papers.11,0,0.00867525,"lues. 4 Ocial test sent Internal test Ocial test 137 369 408 213 119 1246 72 188 2, 106 128 168 2662 The language models were built using SRILM (Stolcke, Table 2: 2002). ocial test sets 4.1 Corpus Unknown words found in internal and It is important to notice that neither the United This year, the translation task provided four difNations nor the Gigaword corpus were used for ferent sources to collect corpora for the Spanishbilingual training. Nevertheless, the English part English pair. Bilingual corpora included version 5 from the United Nations and the monolingual of the Europarl Corpus (Koehn, 2005), the News News corpus were used to build the language model Commentary corpus and the United Nations corof our systems. pus. Additional English corpora was available from the News corpus. The organizers also allowed the 4.1.1 Unknown words use of the English Gigaword Third and Fourth EdiWe analyzed the content from the internal and oftion, released by the LDC. As for development cial test and realized that they both contained and internal test, the test sets from 2008 and 2009 many words that were not seen in the training data. translation tasks were available. Table 2 shows the number of un"
W10-1712,J03-1002,0,0.0100814,"peration with BMIC2 and Bilingual phrases are translation VMU . In phrase-based SMT, the phrase units that contain source words and target words, table is the main tool in translation. It is e.g. created extracting phrases from an aligned and have dierent scores associated to them. These parallel corpus and then computing transbilingual phrases are then sorted in order to maxlation model scores with them. Performing imize a linear combination of feature functions. a collocation segmentation over the source Such strategy is known as the log-linear model and target corpus before the alignment (Och and Ney, 2003) and it is formally dened as: < unidad de traducci´ on |translation unit >, causes that dierent and larger phrases "" are extracted from the same original doceˆ = arg max uments. We performed this segmentation e and used the union of this phrase set with 1 M X λm hm (e, f ) (1) m=1 the phrase set extracted from the nonwhere segmented corpus to compute the phrase weights table. We present the congurations conare the translation model (TM) and the target sidered and also report results obtained language model (LM). Additional models include with internal and ocial test sets. POS target langua"
W10-1712,J96-1001,0,\N,Missing
W10-1712,A00-1031,0,\N,Missing
W10-1712,W09-0414,1,\N,Missing
W10-1712,W07-0702,0,\N,Missing
W11-1014,2010.amta-papers.23,0,\N,Missing
W11-1014,J93-2003,0,\N,Missing
W11-1014,W06-1009,0,\N,Missing
W11-1014,P07-2045,0,\N,Missing
W11-1014,N03-1017,0,\N,Missing
W11-1014,P02-1038,0,\N,Missing
W11-1014,2007.tmi-papers.6,0,\N,Missing
W11-1014,carpuat-wu-2008-evaluation,0,\N,Missing
W11-1014,2009.eamt-1.32,0,\N,Missing
W11-2156,W11-1014,1,0.889484,"Missing"
W11-2156,P07-2045,0,0.0103481,"Missing"
W11-2156,P03-1021,0,0.00665573,"July 30–31, 2011. 2011 Association for Computational Linguistics 2 Phrase-based SMT baseline system The phrase-based approach to SMT performs the translation splitting the source sentence in segments and assigning to each segment a bilingual phrase from a phrase-table. Bilingual phrases are translation units that contain source words and target words, e.g. unit´e de traduction — translation unit, and have different scores associated to them. These bilingual phrases are then selected in order to maximize a linear combination of feature functions. Such strategy is known as the log-linear model (Och, 2003) and it is formally defined as: "" eˆ = arg max e M X # λm hm (e, f ) (1) m=1 where hm are different feature functions with weights λm . The two main feature functions are the translation model (TM) and the target language model (LM). Additional models include lexical weights, phrase and word penalty and reordering. 3 Semantic feature function Source context information is generally disregarded in phrase-based systems given that all training sentences contribute equally to the final translation. The main objective in this section is to motivate the use of a semantic feature function we have rec"
W11-3207,W09-3517,0,0.0458781,"Automata Theory (Knight, 2009). Several different approaches to transliteration have been proposed in the literature (Arbabi et al., 1994; Divay and Vitale, 1997; Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Li et al., 2004; Tao et al., 2006; Yoon et al., 2007; Jansche and Sproat, 2009) covering specific transliteration tasks between English and a large variety of languages such as Japanese (Knight and Graehl, 1998), French (Divay and Vitale, 1997), Arabic (Arbabi et al., 1994; Al-Onaizan and Knight, 2002), Chinese (Ren et al., 2009; Kwong, 2009), Hindi (Chinnakotla and Damani, 2009; Das et al., 2009; Haque et al., 2009), Tamil (Vijayanand, 2009) and Korean (Hong et al., 2009), among others. Nevertheless, despite of the large body of research on automatic transliteration, and as far as we are concerned, there have not been research efforts reported on this area for the specific case of Spanish and Chinese. According to this, the main objective of this work is twofold: first, to create an experimental dataset for transliteration between Chinese and Spanish; and, second, to report some research results on transliteration tasks between these two languages. The remaining of the paper is struc"
W11-3207,W09-3523,0,0.0143934,"night, 2009). Several different approaches to transliteration have been proposed in the literature (Arbabi et al., 1994; Divay and Vitale, 1997; Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Li et al., 2004; Tao et al., 2006; Yoon et al., 2007; Jansche and Sproat, 2009) covering specific transliteration tasks between English and a large variety of languages such as Japanese (Knight and Graehl, 1998), French (Divay and Vitale, 1997), Arabic (Arbabi et al., 1994; Al-Onaizan and Knight, 2002), Chinese (Ren et al., 2009; Kwong, 2009), Hindi (Chinnakotla and Damani, 2009; Das et al., 2009; Haque et al., 2009), Tamil (Vijayanand, 2009) and Korean (Hong et al., 2009), among others. Nevertheless, despite of the large body of research on automatic transliteration, and as far as we are concerned, there have not been research efforts reported on this area for the specific case of Spanish and Chinese. According to this, the main objective of this work is twofold: first, to create an experimental dataset for transliteration between Chinese and Spanish; and, second, to report some research results on transliteration tasks between these two languages. The remaining of the paper is structured as follows. Fir"
W11-3207,W09-3524,0,0.0208515,"ion have been proposed in the literature (Arbabi et al., 1994; Divay and Vitale, 1997; Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Li et al., 2004; Tao et al., 2006; Yoon et al., 2007; Jansche and Sproat, 2009) covering specific transliteration tasks between English and a large variety of languages such as Japanese (Knight and Graehl, 1998), French (Divay and Vitale, 1997), Arabic (Arbabi et al., 1994; Al-Onaizan and Knight, 2002), Chinese (Ren et al., 2009; Kwong, 2009), Hindi (Chinnakotla and Damani, 2009; Das et al., 2009; Haque et al., 2009), Tamil (Vijayanand, 2009) and Korean (Hong et al., 2009), among others. Nevertheless, despite of the large body of research on automatic transliteration, and as far as we are concerned, there have not been research efforts reported on this area for the specific case of Spanish and Chinese. According to this, the main objective of this work is twofold: first, to create an experimental dataset for transliteration between Chinese and Spanish; and, second, to report some research results on transliteration tasks between these two languages. The remaining of the paper is structured as follows. First, in section 2, the main technical issue evaluated in t"
W11-3207,W09-3519,0,0.0144036,"just should be required to learn how to throw away some Spanish syllables. On the other hand, this certainly posses a problem for the case of Chineseto-Spanish transliteration as the transliteration model must be able to generate Spanish syllables from no Chinese correspondents. However, we still expect an overall gain as the former case is more common that the latter one. 3 Transliteration Approach For implementing the transliteration system, we have used the Phrase-Based Statistical Machine Translation approach, which has been proven to be a good strategy for transliteration (Noeman, 2009; Jia et al., 2009). Within this approach, transliteration is performed as a machine translation task over substring units of both the source and the target languages. More specifically, we use the MOSES toolkit (Koehn et al., 2007). 43 4 • Dataset Construction As no named entity dataset is available for transliteration purposes between Spanish and Chinese, the first objective of this work was the creation of such a dataset. Despite the fact that Chinese and Spanish are the most spoken native languages in the word, the amount of bilingual resources for this specific language pair happens to be very scarce (Costa"
W11-3207,W09-3503,0,0.0248791,"Missing"
W11-3207,W09-3508,0,0.0386785,"ally grounded on Finite-state Automata Theory (Knight, 2009). Several different approaches to transliteration have been proposed in the literature (Arbabi et al., 1994; Divay and Vitale, 1997; Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Li et al., 2004; Tao et al., 2006; Yoon et al., 2007; Jansche and Sproat, 2009) covering specific transliteration tasks between English and a large variety of languages such as Japanese (Knight and Graehl, 1998), French (Divay and Vitale, 1997), Arabic (Arbabi et al., 1994; Al-Onaizan and Knight, 2002), Chinese (Ren et al., 2009; Kwong, 2009), Hindi (Chinnakotla and Damani, 2009; Das et al., 2009; Haque et al., 2009), Tamil (Vijayanand, 2009) and Korean (Hong et al., 2009), among others. Nevertheless, despite of the large body of research on automatic transliteration, and as far as we are concerned, there have not been research efforts reported on this area for the specific case of Spanish and Chinese. According to this, the main objective of this work is twofold: first, to create an experimental dataset for transliteration between Chinese and Spanish; and, second, to report some research results on transliteration tasks between these two languages. The remaining of"
W11-3207,P07-2045,0,0.0103943,"three segmentation schemes described in the previous section. More specifically, characters, syllables and the proposed sub-syllabic units are considered for Spanish. The other two parameters to be considered for evaluation purposes are the order of the target language model and the alignment strategy used for phrase extraction. In the case of the target language model, four different orders are compared, namely: 1-gram, 2-gram, 3-gram and 4gram; and in the case of the alignment strategy, three different methods are compared, namely: source-to-target, target-to-source and grow-diagfinal-and (Koehn et al., 2007). According to this, our experimental work involves the construction of 72 different transliteration systems, by considering 2 transliteration directions, 3 Spanish segmentation schemes, 4 target language model orders, and 3 alignment strategies. In each of these transliteration systems, the standard set of phrase-based features, which include the forward and backward relative frequencies and lexical models, as well as the target language and phrase-length penalty models, are used. As evaluation metric for assessing transliteration quality we use the BLEU score (Papineni et al., 2001). In the"
W11-3207,W09-3537,0,0.0183918,"blem can be theoretically grounded on Finite-state Automata Theory (Knight, 2009). Several different approaches to transliteration have been proposed in the literature (Arbabi et al., 1994; Divay and Vitale, 1997; Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Li et al., 2004; Tao et al., 2006; Yoon et al., 2007; Jansche and Sproat, 2009) covering specific transliteration tasks between English and a large variety of languages such as Japanese (Knight and Graehl, 1998), French (Divay and Vitale, 1997), Arabic (Arbabi et al., 1994; Al-Onaizan and Knight, 2002), Chinese (Ren et al., 2009; Kwong, 2009), Hindi (Chinnakotla and Damani, 2009; Das et al., 2009; Haque et al., 2009), Tamil (Vijayanand, 2009) and Korean (Hong et al., 2009), among others. Nevertheless, despite of the large body of research on automatic transliteration, and as far as we are concerned, there have not been research efforts reported on this area for the specific case of Spanish and Chinese. According to this, the main objective of this work is twofold: first, to create an experimental dataset for transliteration between Chinese and Spanish; and, second, to report some research results on transliteration tasks between t"
W11-3207,W09-3532,0,0.0244716,"any case, the problem can be theoretically grounded on Finite-state Automata Theory (Knight, 2009). Several different approaches to transliteration have been proposed in the literature (Arbabi et al., 1994; Divay and Vitale, 1997; Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Li et al., 2004; Tao et al., 2006; Yoon et al., 2007; Jansche and Sproat, 2009) covering specific transliteration tasks between English and a large variety of languages such as Japanese (Knight and Graehl, 1998), French (Divay and Vitale, 1997), Arabic (Arbabi et al., 1994; Al-Onaizan and Knight, 2002), Chinese (Ren et al., 2009; Kwong, 2009), Hindi (Chinnakotla and Damani, 2009; Das et al., 2009; Haque et al., 2009), Tamil (Vijayanand, 2009) and Korean (Hong et al., 2009), among others. Nevertheless, despite of the large body of research on automatic transliteration, and as far as we are concerned, there have not been research efforts reported on this area for the specific case of Spanish and Chinese. According to this, the main objective of this work is twofold: first, to create an experimental dataset for transliteration between Chinese and Spanish; and, second, to report some research results on transliteration t"
W11-3207,W06-1630,0,0.0221252,"e Transliteration Rafael E. Banchs Human Language Technology Department, Institute for Infocomm Research 1 Fusionopolis Way, #21-01 Connexis South, Singapore 138632 rembanchs@i2r.a-star.edu.sg The transliteration task can be approached from either a rule-based or a statistical perspective, but in any case, the problem can be theoretically grounded on Finite-state Automata Theory (Knight, 2009). Several different approaches to transliteration have been proposed in the literature (Arbabi et al., 1994; Divay and Vitale, 1997; Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Li et al., 2004; Tao et al., 2006; Yoon et al., 2007; Jansche and Sproat, 2009) covering specific transliteration tasks between English and a large variety of languages such as Japanese (Knight and Graehl, 1998), French (Divay and Vitale, 1997), Arabic (Arbabi et al., 1994; Al-Onaizan and Knight, 2002), Chinese (Ren et al., 2009; Kwong, 2009), Hindi (Chinnakotla and Damani, 2009; Das et al., 2009; Haque et al., 2009), Tamil (Vijayanand, 2009) and Korean (Hong et al., 2009), among others. Nevertheless, despite of the large body of research on automatic transliteration, and as far as we are concerned, there have not been resear"
W11-3207,P04-1021,0,0.0374701,"or Spanish-Chinese Transliteration Rafael E. Banchs Human Language Technology Department, Institute for Infocomm Research 1 Fusionopolis Way, #21-01 Connexis South, Singapore 138632 rembanchs@i2r.a-star.edu.sg The transliteration task can be approached from either a rule-based or a statistical perspective, but in any case, the problem can be theoretically grounded on Finite-state Automata Theory (Knight, 2009). Several different approaches to transliteration have been proposed in the literature (Arbabi et al., 1994; Divay and Vitale, 1997; Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Li et al., 2004; Tao et al., 2006; Yoon et al., 2007; Jansche and Sproat, 2009) covering specific transliteration tasks between English and a large variety of languages such as Japanese (Knight and Graehl, 1998), French (Divay and Vitale, 1997), Arabic (Arbabi et al., 1994; Al-Onaizan and Knight, 2002), Chinese (Ren et al., 2009; Kwong, 2009), Hindi (Chinnakotla and Damani, 2009; Das et al., 2009; Haque et al., 2009), Tamil (Vijayanand, 2009) and Korean (Hong et al., 2009), among others. Nevertheless, despite of the large body of research on automatic transliteration, and as far as we are concerned, there ha"
W11-3207,W09-3509,0,0.0306626,"ent approaches to transliteration have been proposed in the literature (Arbabi et al., 1994; Divay and Vitale, 1997; Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Li et al., 2004; Tao et al., 2006; Yoon et al., 2007; Jansche and Sproat, 2009) covering specific transliteration tasks between English and a large variety of languages such as Japanese (Knight and Graehl, 1998), French (Divay and Vitale, 1997), Arabic (Arbabi et al., 1994; Al-Onaizan and Knight, 2002), Chinese (Ren et al., 2009; Kwong, 2009), Hindi (Chinnakotla and Damani, 2009; Das et al., 2009; Haque et al., 2009), Tamil (Vijayanand, 2009) and Korean (Hong et al., 2009), among others. Nevertheless, despite of the large body of research on automatic transliteration, and as far as we are concerned, there have not been research efforts reported on this area for the specific case of Spanish and Chinese. According to this, the main objective of this work is twofold: first, to create an experimental dataset for transliteration between Chinese and Spanish; and, second, to report some research results on transliteration tasks between these two languages. The remaining of the paper is structured as follows. First, in section 2, the main"
W11-3207,W09-3525,0,0.0166215,"teration model just should be required to learn how to throw away some Spanish syllables. On the other hand, this certainly posses a problem for the case of Chineseto-Spanish transliteration as the transliteration model must be able to generate Spanish syllables from no Chinese correspondents. However, we still expect an overall gain as the former case is more common that the latter one. 3 Transliteration Approach For implementing the transliteration system, we have used the Phrase-Based Statistical Machine Translation approach, which has been proven to be a good strategy for transliteration (Noeman, 2009; Jia et al., 2009). Within this approach, transliteration is performed as a machine translation task over substring units of both the source and the target languages. More specifically, we use the MOSES toolkit (Koehn et al., 2007). 43 4 • Dataset Construction As no named entity dataset is available for transliteration purposes between Spanish and Chinese, the first objective of this work was the creation of such a dataset. Despite the fact that Chinese and Spanish are the most spoken native languages in the word, the amount of bilingual resources for this specific language pair happens to be"
W11-3207,P07-1015,0,0.0184924,"Rafael E. Banchs Human Language Technology Department, Institute for Infocomm Research 1 Fusionopolis Way, #21-01 Connexis South, Singapore 138632 rembanchs@i2r.a-star.edu.sg The transliteration task can be approached from either a rule-based or a statistical perspective, but in any case, the problem can be theoretically grounded on Finite-state Automata Theory (Knight, 2009). Several different approaches to transliteration have been proposed in the literature (Arbabi et al., 1994; Divay and Vitale, 1997; Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Li et al., 2004; Tao et al., 2006; Yoon et al., 2007; Jansche and Sproat, 2009) covering specific transliteration tasks between English and a large variety of languages such as Japanese (Knight and Graehl, 1998), French (Divay and Vitale, 1997), Arabic (Arbabi et al., 1994; Al-Onaizan and Knight, 2002), Chinese (Ren et al., 2009; Kwong, 2009), Hindi (Chinnakotla and Damani, 2009; Das et al., 2009; Haque et al., 2009), Tamil (Vijayanand, 2009) and Korean (Hong et al., 2009), among others. Nevertheless, despite of the large body of research on automatic transliteration, and as far as we are concerned, there have not been research efforts reported"
W11-3207,C00-2163,0,0.0386331,"l Random Fields (Lafferty et al., 2001). From this step a list of 1,608 Spanish names were collected. • A reduced list of named entities was generated by manually filtering the original list. In this process some errors derived from the first automatic step were removed, as well as any valid name entity not belonging to the two basic categories of persons and places. In this second step, the list was reduced to 948 names. • The corresponding Chinese versions of the names were extracted from the Chinese side of the dataset. This was done automatically by aligning both corpus at the word level (Och and Ney, 2000), and using the alignment links to identify the corresponding transliteration candidates for each Spanish name in the list. The automatically extracted list of corresponding Chinese names was manually depurated. Because of the noisy nature of the alignment process, in several cases either more than one Chinese word was assigned to the same Spanish names or an erroneous Chinese word was selected. After this second filtering processing, the final bilingual list of 841 names was obtained. Dataset Names Substrings Vocab. Chinese Spa (char) Spa (sub) Spa (syl) 841 841 841 841 2,190 4,766 3,005 2,16"
W11-3207,W11-3202,0,0.0206041,"rategies are evaluated: character-based, syllabicbased and a proposed sub-syllabic segmentation scheme. Experimental results show that syllabic-based segmentation is the most effective strategy for Spanish-to-Chinese transliteration, while the proposed sub-syllabic segmentation is the most effective scheme in the case of Chinese-to-Spanish transliteration. 1 Introduction Transliteration can be defined as the process of transcribing a word from one language to another by using the characters of the latter’s alphabet. This actually constitutes a “phonetic translation of names across languages” (Zhang et al., 2011). Transliteration is typically used to construct appropriate translations for words that either do not have specific equivalents or are inexistent in the target language, such as, for instance, names of people, institutions or geographical locations. Although they are conceptually similar tasks, technically speaking, translation and transliteration exhibit some important differences. For instance, while translation mainly operates at the word level, transliteration does it at the sub-word level. Perhaps, the most important difference is the fact that in the transliteration task, reordering of"
W11-3207,W09-3505,0,\N,Missing
W11-3207,W02-0505,0,\N,Missing
W11-3207,P02-1040,0,\N,Missing
W11-3207,J98-4003,0,\N,Missing
W11-3207,P03-1021,0,\N,Missing
W12-0104,D07-1053,0,0.0249248,"rmance, we trained a translation system by relaxing the top ranked words in the vocabulary of the target language. In this way, there will be a large number of words in the source language that will be translated to a null token. For example: la (the in Spanish) and es (is in Spanish) will be both translated to a null token in English. This relaxation of terms is only applied to the target language vocabulary, and it is conducted 3 Frequent Word Prediction Word prediction has been widely studied and used in several different tasks such as, for example, augmented and alternative communication (Wandmacher and Antoine, 2007) and spelling correction (Thiele et al., 2000). In addition to the commonly used word n-gram, various language modeling techniques have been applied, such as the semantic model (Luís and Rosa, 2002; Wandmacher and Antoine, 2007) and the class-based model (Thiele et al., 2000; Zohar and Roth, 2000; Ruch et al., 2001). The role of such a word predictor in our considered problem is to recover the null tokens in the translation output by replacing them with the words that best fit the sentence. This task is essentially a classification problem, in which the most suitable relaxed word for recoverin"
W12-0104,A00-2017,0,0.104131,"Missing"
W12-0104,W07-0718,0,0.0525733,"Missing"
W13-2801,W13-2816,0,0.0501134,"Missing"
W13-2801,W13-2813,0,0.0217301,"Missing"
W13-2801,2008.eamt-1.6,0,0.0725213,"Missing"
W13-2801,W13-2804,0,0.0365849,"Missing"
W13-2801,W13-2805,0,0.0466293,"Missing"
W13-2801,W13-2814,0,0.0251731,"d in corresponding representations (a RBMT example is LFG (Lexical Functional Grammars) analysis and the corresponding XLE translation architecture). In HyTra 2013 there are three approaches dealing with multilevel information: • Turki Khemakhem et al. (2013) present work about an English-Arabic SMT system that uses morphological decomposition and morpho-syntactic annotation of the target language and incorporates the corresponding information in a statistical feature model. Essentially, the statistical feature language model replaces words by feature arrays. 3.4 Other multilevel approaches • Pal et al. (2013) propose a combination of aligners: GIZA++, Berkeley and rule-based for English-Bengali. • Hsieh et al. (2013) use comparable corpora extracted from Wikipedia to extract parallel fragments for the purpose of extending an English-Bengali training corpus. Semantic approaches The introduction of semantics in statistical MT has been approached to solve word sense disambiguation challenges covering the area of lexical semantics and, more recently, there have been different techniques using semantic roles covering shallow semantics, as well as the use of distributional semantics for improving transl"
W13-2801,W13-2806,0,0.0246185,"Missing"
W13-2801,W13-2807,0,0.0435616,"Missing"
W13-2801,W13-2817,0,0.0294611,"responding XLE translation architecture). In HyTra 2013 there are three approaches dealing with multilevel information: • Turki Khemakhem et al. (2013) present work about an English-Arabic SMT system that uses morphological decomposition and morpho-syntactic annotation of the target language and incorporates the corresponding information in a statistical feature model. Essentially, the statistical feature language model replaces words by feature arrays. 3.4 Other multilevel approaches • Pal et al. (2013) propose a combination of aligners: GIZA++, Berkeley and rule-based for English-Bengali. • Hsieh et al. (2013) use comparable corpora extracted from Wikipedia to extract parallel fragments for the purpose of extending an English-Bengali training corpus. Semantic approaches The introduction of semantics in statistical MT has been approached to solve word sense disambiguation challenges covering the area of lexical semantics and, more recently, there have been different techniques using semantic roles covering shallow semantics, as well as the use of distributional semantics for improving translation unit selection. Approaches treating the incorporation of semantics into MT in HyTra 2013 include the fol"
W13-2801,W13-2815,0,0.0580296,"Missing"
W13-2801,W13-2811,0,0.014586,"nd corresponding POS-based restructuring of the input. Basically, they focus on taking advantage of the fact that Korean has compound words, which - for the purpose of alignment - are split and reordered similarly to Chinese. 3.5 In a number of linguistic theories information from the morphological, syntactic and semantic level is considered conjointly and merged in corresponding representations (a RBMT example is LFG (Lexical Functional Grammars) analysis and the corresponding XLE translation architecture). In HyTra 2013 there are three approaches dealing with multilevel information: • Turki Khemakhem et al. (2013) present work about an English-Arabic SMT system that uses morphological decomposition and morpho-syntactic annotation of the target language and incorporates the corresponding information in a statistical feature model. Essentially, the statistical feature language model replaces words by feature arrays. 3.4 Other multilevel approaches • Pal et al. (2013) propose a combination of aligners: GIZA++, Berkeley and rule-based for English-Bengali. • Hsieh et al. (2013) use comparable corpora extracted from Wikipedia to extract parallel fragments for the purpose of extending an English-Bengali train"
W13-2801,W13-2810,0,0.0239078,"Missing"
W13-2801,W13-2818,0,0.0263833,"extracted from Wikipedia to extract parallel fragments for the purpose of extending an English-Bengali training corpus. Semantic approaches The introduction of semantics in statistical MT has been approached to solve word sense disambiguation challenges covering the area of lexical semantics and, more recently, there have been different techniques using semantic roles covering shallow semantics, as well as the use of distributional semantics for improving translation unit selection. Approaches treating the incorporation of semantics into MT in HyTra 2013 include the following research work: • Tambouratzis et al. (2013) describe a hybrid MT architecture that uses very few bilingual corpus and a large monolingual one. The linguistic information is extracted using pattern recognition techniques. Table 1 summarizes the papers that have been presented in the Second HyTra Workshop. The papers are arranged into the table according to the linguistic level they address. • Rudnick et al. (2013) present a combination of Maximum Entropy Markov Models and HMM to perform lexical selection in the sense of cross-lingual word sense disambiguation (i.e. by choice from the set of translation alternatives). The system is meant"
W13-2801,W13-2808,0,0.058822,"Missing"
W13-2801,W10-1737,0,0.0651783,"Missing"
W13-2801,W13-2803,0,0.0495517,"Missing"
W13-2801,W13-2809,0,0.0597288,"Missing"
W13-2801,W13-2812,0,0.0196328,"often considered and represented simultaneously (not only in unification-based approaches) and the same is true for MT systems. Syntax had been addressed originally in SMT in the form of so called phrase-based SMT without any reference to linguistic structures; during 3 • Bouillon et al. (2013) presents two methodologies to correct homophone confusions. The first one is based on hand-coded rules and the second one is based on weighted graphs derived from a pronunciation resource. • Laki et al. (2013) combine pre-reordering rules with morphological and factored models for English-to-Turkish. • Li et al. (2013) propose pre-reordering rules to be used for alignment-based reordering, and corresponding POS-based restructuring of the input. Basically, they focus on taking advantage of the fact that Korean has compound words, which - for the purpose of alignment - are split and reordered similarly to Chinese. 3.5 In a number of linguistic theories information from the morphological, syntactic and semantic level is considered conjointly and merged in corresponding representations (a RBMT example is LFG (Lexical Functional Grammars) analysis and the corresponding XLE translation architecture). In HyTra 201"
W13-3301,W12-3129,0,0.0892933,"Missing"
W13-3301,W02-1801,0,0.0452804,"f identifying meaningful endpoints of utterances before transmitting a translation. For example, there is a perceived lag time for speakers when trying to book flights or order products over the phone. This lag time diminishes conversation quality since it takes too long for each speaker to receive a translation at either end of the system (Paulik et al., 2009). If we can develop a method to automatically identify segments of meaning as they are spoken, then we could significantly reduce the perceived lag time in real-time speech-to-speech translation systems and improve conversation quality (Baobao et al., 2002; Hamon et al., 2009). The problem of absence of correspondence arises when there is a lexical unit (single words or groups of words) that occurs in L1 but not in L2 (Lambert et al., 2005). It happens when words belonging to a concept do not correspond to phrases that can be aligned in both languages. This 3 Similarity Agreement We implemented segmentation similarity (S) from Fournier and Inkpen (2012). Segmentation similarity was formulated to address some gaps of the WindowDiff (W D) metric, including unequal penalty for errors as well as the need to add padding to the ends of each segmentat"
W13-3301,P98-2141,0,0.30242,"eal-time, they naturally segment speech in “minimal sense units” (Ol´eron & Nanpon, 1965; Ben´ıtez & Bajo, 1998) in order to convey the same information from one language to another as though there were a 1-to-1 mapping of concepts between both languages. Further, it is known that people can hold up to 7+/- 2 “chunks” of information in memory at a time by creating and applying meaningful organization schemes to input (Miller, 1956). However, there is no definitive linguistic description for the kind of “meaning units” that human translators create (Signorelli et al., 2011; Hamon et al., 2009; Mima et al., 1998). The ability to chunk text according to units of meaning is key to developing more sophisticated machine translation (MT) systems that operate in • At what level of granularity do English and Chinese speakers construct meaning units in text? • Do English and Chinese speakers organize meaning units systematically such that meaning unit segmentations are not random? • How well do English and Chinese speakers agree on meaning unit boundaries? • Are there salient syntactic features of meaning units in English and Chinese? • Can we automatically identify a 1-to-1 mapping of concepts for parallel t"
W13-3301,N12-1016,0,0.079346,"omatically identify segments of meaning as they are spoken, then we could significantly reduce the perceived lag time in real-time speech-to-speech translation systems and improve conversation quality (Baobao et al., 2002; Hamon et al., 2009). The problem of absence of correspondence arises when there is a lexical unit (single words or groups of words) that occurs in L1 but not in L2 (Lambert et al., 2005). It happens when words belonging to a concept do not correspond to phrases that can be aligned in both languages. This 3 Similarity Agreement We implemented segmentation similarity (S) from Fournier and Inkpen (2012). Segmentation similarity was formulated to address some gaps of the WindowDiff (W D) metric, including unequal penalty for errors as well as the need to add padding to the ends of each segmentation (Pevzner & Hearst, 2002). There are 3 types of segmentation errors for (S), listed below: 1. s1 contains a boundary that is off by n potential boundaries in s2 2. s1 contains a boundary that s2 does not, or 3. s2 contains a boundary that s1 does not These three types of errors are understood as transpositions in the case of error type 1, and as 2 4 substitutions in the case of error types 2 and 3."
W13-3301,C96-1070,0,0.809452,"Missing"
W13-3301,E09-1040,0,0.330363,"Missing"
W13-3301,J02-1002,0,0.104128,"Missing"
W13-3301,N04-1030,0,0.106586,"Missing"
W13-3301,C88-1057,0,0.162679,"Missing"
W13-3301,P10-2012,0,0.0729024,"Missing"
W13-3301,W10-1733,0,0.0352146,"Missing"
W13-3301,P03-1054,0,0.00665411,"Missing"
W13-3301,W03-1730,0,0.00868617,"Universal Declaration of Human Rights. The number of words and number of sentences by language and genre is presented below in Table 1. Preprocessing: To prepare the text samples for annotation, we did some preprocessing. We removed periods and commas in both languages, since these markings can give structure and meaning to the text which could influence annotator decisions about meaning unit boundaries. For the English data, we did not fold to lowercase and we acknowledge that this was a design oversight. The Chinese text was automatically segmented into words before the task using ICTCLAS (Zhang et al., 2003). This was done in order to encourage Chinese speakers to look beyond the characterlevel and word-level, since word segmentation is a well-known NLP task for the Chinese language. The Chinese UDHR data consisted of 856 characters. We placed checkboxes between each word in the text. In their analysis and comparison of this new metric, Fournier and Inkpen (2012) demonstrated the advantages of using (S) over using (W D) for different kinds of segmentation cases such as maximal/minimal segmentation, full misses, near misses, and segmentation mass scale effects. They found that in each of these cas"
W13-3301,C98-2136,0,\N,Missing
W13-4023,H89-1033,0,0.610472,"Missing"
W13-4023,W06-1302,0,0.0641376,"Missing"
W13-4023,W11-2004,0,0.0254443,"Missing"
W13-4023,P12-3007,1,\N,Missing
W14-1013,N03-1017,0,0.00371587,"isy channel and the phrase-based approaches. As seen later, this will result in the incorporation of a new model component, which can be also used as a feature function within the context of the maximum entropy framework. (3) where ?? and ?? refer to individual words occurring in ? and ? , respectively. The probabilities ?(?? |?? ) are referred to as lexical models and they represent the probability of an individual source word ?? to be the translation of a given target word ?? . These lexical models are estimated by using word alignment probabilities. In statistical phrase-based translation (Koehn et al., 2003), the translation model is approximated by means of phrase-level probabilities (a phrase is a bilingual pair of sub-sentence units that is consistent with the word alignments). Within this framework, translation probabilities at the sentence-level are computed from phraselevel probabilities as follows: ?(?|?) = ∏? ?(?? |?? ) (4) where ?? and ?? refer to phrases (i.e. groups of words) occurring in ? and ? , respectively. The probabilities ?(?? |?? ) are estimated by means of relative frequencies and, accordingly, they are referred to as relative frequency models. Finally, in (Och and Ney, 2002)"
W14-1013,2010.amta-papers.23,0,\N,Missing
W14-1013,P02-1038,0,\N,Missing
W14-1013,2007.tmi-papers.6,0,\N,Missing
W14-1013,carpuat-wu-2008-evaluation,0,\N,Missing
W14-1013,W11-1014,1,\N,Missing
W14-1013,2009.eamt-1.32,0,\N,Missing
W14-3306,W11-2156,1,0.605388,"Missing"
W14-3306,P07-2045,0,0.00412561,"educed dimension vector-space model, which is constructed either by means of standard latent semantic analysis or using deep representation as decribed in section 3. Introduction This paper describes the joint participation of the Instituto Polit´ecnico Nacional (IPN) and the Universitat Polit`ecnica de Valencia (UPV) in cooperation with Institute for Infocomm Research (I2R) on the 9th Workshop on Statistical Machine Translation (WMT 2014). In particular, our participation was in the English-to-Hindi translation task. Our baseline system is an standard phrasebased SMT system built with Moses (Koehn et al., 2007). Starting from this system we propose to introduce a source-context feature function inspired by previous works (R. Costa-juss`a and Banchs, 2011; Banchs and Costa-juss`a, 2011). The main novelty of this work is that the source-context feature is computed in a new deep representation. The rest of the paper is organized as follows. Section 2 presents the motivation of this semantic feature and the description of how the source context feature function is added to Moses. Section 3 explains how both the latent semantic indexing and deep representation of sentences are used to better compute simi"
W14-3306,W11-1014,1,\N,Missing
W14-4345,W14-4337,0,0.0856688,"istribution over a set of hypotheses. Although the most widely studied approaches have been based on generative models (Williams and Young, 2007; Williams, 2010; Young et al., 2010; Thomson and Young, 2010; Gaˇsi´c and Young, 2011; Raux and Ma, 2011), recently, some researchers have reported that discriminative models (Bohus and Rudnicky, 2006; Lee, 2013; Zilka et al., 2013) achieved comparable, or even better, performances than generative models, especially in the tasks of the first dialog state tracking challenge (DSTC) (Williams et al., 2013). This work focuses on the second phase of DSTC (Henderson et al., 2014). The major difference of DSTC 2 from the previous challenge is that user goals can be changed even in a single dialog session. This aspect can cause the limitations of the previous approaches assuming the fixed user goal for each session. To solve this dynamic state tracking problem, we propose a sequential labeling approach using linear-chain conditional random fields (CRFs) (Lafferty et al., 2001). This approach aims to improve the performances of the tracker in the case of goal changes by jointly performing prediction and segmentation of dialog states. This paper presents a sequential labe"
W14-4345,W13-4065,0,0.0415623,"s have utilized statistical machine learning techniques to obtain the distribution over a set of hypotheses. Although the most widely studied approaches have been based on generative models (Williams and Young, 2007; Williams, 2010; Young et al., 2010; Thomson and Young, 2010; Gaˇsi´c and Young, 2011; Raux and Ma, 2011), recently, some researchers have reported that discriminative models (Bohus and Rudnicky, 2006; Lee, 2013; Zilka et al., 2013) achieved comparable, or even better, performances than generative models, especially in the tasks of the first dialog state tracking challenge (DSTC) (Williams et al., 2013). This work focuses on the second phase of DSTC (Henderson et al., 2014). The major difference of DSTC 2 from the previous challenge is that user goals can be changed even in a single dialog session. This aspect can cause the limitations of the previous approaches assuming the fixed user goal for each session. To solve this dynamic state tracking problem, we propose a sequential labeling approach using linear-chain conditional random fields (CRFs) (Lafferty et al., 2001). This approach aims to improve the performances of the tracker in the case of goal changes by jointly performing prediction"
W14-4345,W13-4066,0,0.0184172,"ea, food, name, and price range. Assuming the possible value set for each slot is fixed, this task can be considered to be a problem of finding the distributions over these hypotheses. While the previous challenge aims at identifying a single fixed goal for each session, the models for DSTC 2 should be able to handle goal changes during a session, as shown in Figure 1. 2.2 (c) Requested chain on the phone slot Figure 2: Examples of dialog state tracking as sequential labeling with liner-chain CRFs 3 Method Method Tracking Although some discriminative approaches (Lee, 2013; Zilka et al., 2013; Lee and Eskenazi, 2013; Ren et al., 2013) have successfully applied to the dialog state tracking tasks of DSTC 1 by exploring various features, they have limited ability to perform the DSTC 2 tasks, because the previous models trained based on the features mostly extracted under the assumption that the user goal in a session is unchangeable. To overcome this limitation, we propose a sequential labeling approach using linear-chain CRFs for dynamic dialog state tracking. Method tracking is performed by classifying the way of requesting information by a user into the following four categories: ‘by constraints’, ‘by al"
W14-4345,W13-4070,0,0.0543973,"mbanchs}@i2r.a-star.edu.sg Abstract worse, the confidence scores could be unreliable and inconsistent in some cases. The other direction of dialog state tracking approaches have utilized statistical machine learning techniques to obtain the distribution over a set of hypotheses. Although the most widely studied approaches have been based on generative models (Williams and Young, 2007; Williams, 2010; Young et al., 2010; Thomson and Young, 2010; Gaˇsi´c and Young, 2011; Raux and Ma, 2011), recently, some researchers have reported that discriminative models (Bohus and Rudnicky, 2006; Lee, 2013; Zilka et al., 2013) achieved comparable, or even better, performances than generative models, especially in the tasks of the first dialog state tracking challenge (DSTC) (Williams et al., 2013). This work focuses on the second phase of DSTC (Henderson et al., 2014). The major difference of DSTC 2 from the previous challenge is that user goals can be changed even in a single dialog session. This aspect can cause the limitations of the previous approaches assuming the fixed user goal for each session. To solve this dynamic state tracking problem, we propose a sequential labeling approach using linear-chain conditi"
W14-4345,W13-4069,0,0.0795767,"32 {kims,rembanchs}@i2r.a-star.edu.sg Abstract worse, the confidence scores could be unreliable and inconsistent in some cases. The other direction of dialog state tracking approaches have utilized statistical machine learning techniques to obtain the distribution over a set of hypotheses. Although the most widely studied approaches have been based on generative models (Williams and Young, 2007; Williams, 2010; Young et al., 2010; Thomson and Young, 2010; Gaˇsi´c and Young, 2011; Raux and Ma, 2011), recently, some researchers have reported that discriminative models (Bohus and Rudnicky, 2006; Lee, 2013; Zilka et al., 2013) achieved comparable, or even better, performances than generative models, especially in the tasks of the first dialog state tracking challenge (DSTC) (Williams et al., 2013). This work focuses on the second phase of DSTC (Henderson et al., 2014). The major difference of DSTC 2 from the previous challenge is that user goals can be changed even in a single dialog session. This aspect can cause the limitations of the previous approaches assuming the fixed user goal for each session. To solve this dynamic state tracking problem, we propose a sequential labeling approach using"
W14-4345,P99-1026,0,0.0882861,"at analyzes and maintains this dialog state at each moment. The major obstacle to dialog state tracking is that the inputs to the tracker are likely to be noisy because of the errors produced by automatic speech recognition (ASR) and spoken language understanding (SLU) processes which are required to be performed prior to the tracking. Thus, many researchers have focused on improving the robustness of dialog state trackers against ASR and SLU errors. The simplest ways to tackle this problem have been based on handcrafted rules mainly on the confidence scores obtained from ASR and SLU modules (Nakano et al., 1999; Wang and Lemon, 2013). However, these approaches have the limitation that building the quality rules manually is expensive and, what is 2 Problem Definition A dialog state defined in DSTC 2 consists of the following three components: goals, method, and requested slots. 2.1 Goals Tracking Goals represent the constraint values which are truly intended by a user at each moment. These values can be represented by using a slot filling 332 Proceedings of the SIGDIAL 2014 Conference, pages 332–336, c Philadelphia, U.S.A., 18-20 June 2014. 2014 Association for Computational Linguistics Utterance S1"
W14-4345,W13-4071,0,0.138729,"e range. Assuming the possible value set for each slot is fixed, this task can be considered to be a problem of finding the distributions over these hypotheses. While the previous challenge aims at identifying a single fixed goal for each session, the models for DSTC 2 should be able to handle goal changes during a session, as shown in Figure 1. 2.2 (c) Requested chain on the phone slot Figure 2: Examples of dialog state tracking as sequential labeling with liner-chain CRFs 3 Method Method Tracking Although some discriminative approaches (Lee, 2013; Zilka et al., 2013; Lee and Eskenazi, 2013; Ren et al., 2013) have successfully applied to the dialog state tracking tasks of DSTC 1 by exploring various features, they have limited ability to perform the DSTC 2 tasks, because the previous models trained based on the features mostly extracted under the assumption that the user goal in a session is unchangeable. To overcome this limitation, we propose a sequential labeling approach using linear-chain CRFs for dynamic dialog state tracking. Method tracking is performed by classifying the way of requesting information by a user into the following four categories: ‘by constraints’, ‘by alternatives’, ‘by na"
W14-4345,W13-4067,0,0.0171984,"ains this dialog state at each moment. The major obstacle to dialog state tracking is that the inputs to the tracker are likely to be noisy because of the errors produced by automatic speech recognition (ASR) and spoken language understanding (SLU) processes which are required to be performed prior to the tracking. Thus, many researchers have focused on improving the robustness of dialog state trackers against ASR and SLU errors. The simplest ways to tackle this problem have been based on handcrafted rules mainly on the confidence scores obtained from ASR and SLU modules (Nakano et al., 1999; Wang and Lemon, 2013). However, these approaches have the limitation that building the quality rules manually is expensive and, what is 2 Problem Definition A dialog state defined in DSTC 2 consists of the following three components: goals, method, and requested slots. 2.1 Goals Tracking Goals represent the constraint values which are truly intended by a user at each moment. These values can be represented by using a slot filling 332 Proceedings of the SIGDIAL 2014 Conference, pages 332–336, c Philadelphia, U.S.A., 18-20 June 2014. 2014 Association for Computational Linguistics Utterance S1 U1 S2 U2 S3 U3 S4 U4 S5"
W15-0618,W11-1407,0,0.298695,"Missing"
W15-0618,W05-0210,0,0.612343,"Missing"
W15-0618,N03-1033,0,0.0147071,"Missing"
W15-0618,N12-1092,0,\N,Missing
W15-3901,P04-1021,1,\N,Missing
W15-3902,J98-4003,0,0.37313,"2015 Machine Transliteration Shared Task Rafael E. Banchs1, Min Zhang2, Xiangyu Duan2, Haizhou Li1, A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {minzhang,xiangyuduan}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-re"
W15-3902,P07-2045,0,0.00686568,"Missing"
W15-3902,P07-1119,0,0.0443311,"A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {minzhang,xiangyuduan}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondenc"
W15-3902,P06-1010,0,0.0359544,"Duan2, Haizhou Li1, A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {minzhang,xiangyuduan}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use"
W15-3902,W15-3912,0,0.127502,"Missing"
W15-3902,W15-3911,0,0.0752468,"Missing"
W15-3902,C02-1099,0,0.0658677,"gyuduan}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of several different models or knowledge sources to support the tr"
W15-3902,N10-1103,0,\N,Missing
W15-3902,W10-2402,1,\N,Missing
W15-3902,P04-1021,1,\N,Missing
W15-3902,W03-1508,0,\N,Missing
W15-3902,W02-0505,0,\N,Missing
W15-3902,N07-1047,0,\N,Missing
W15-3902,P06-1103,0,\N,Missing
W15-3902,W10-2401,1,\N,Missing
W15-3902,P98-2220,0,\N,Missing
W15-3902,C98-2215,0,\N,Missing
W15-3902,W06-1672,0,\N,Missing
W15-3902,D08-1037,0,\N,Missing
W15-3902,P08-1045,0,\N,Missing
W15-3902,W11-3202,1,\N,Missing
W15-3902,W15-3913,0,\N,Missing
W15-3902,W15-3909,0,\N,Missing
W15-3902,W11-3201,1,\N,Missing
W15-3902,W09-3504,0,\N,Missing
W15-4106,C96-1070,0,0.0505185,"se situations, full understanding and full generation is not mandatory, as the interpreter must keep the main speaker’s pace because ‘concurrent’ time constraints exist. Current machine translation technologies have been theoretically and empirically designed under assumptions related to the first and second categories defined above. As far as we know, only few attempts have been done to apply machine translation to the specific problem of simultaneous interpretation. Indeed, previous research in this area can be traced back to the Vermobil 1 project, as well as to work from Kitano (1991) and Furuse and Iida (1996), who proposed the use of incremental translation. Later on, Mima et al. (1998) developed the idea of example-based incremental transfer. The main objective of this discussion paper is to highlight the differences and similarities between the human task of simultaneous interpretation and statistical machine translation aiming at proposing Abstract This discussion paper presents and analyses the main conceptual differences and similarities between the human task of simultaneous interpretation and the statistical approach to machine translation. A psycho-cognitive model of the simultaneous inter"
W15-4106,W11-1014,1,0.89624,"Missing"
W15-4106,P05-1048,0,0.023936,"rdering decisions in this task must be mainly done based on target language information. Post-edition. This subtask is responsible for concatenating the reordered target units. This subtask must deal with two specific types of problems: boundary overlapping, where consecutive units are to be merged by resolving possible word overlap37 tics, syntax-based machine translation, and crosslanguage information retrieval. Significant effort on using source-context information to improve target unit selection has been reported during the last few years for both domain adaptation and lexical semantics (Carpuat and Wu 2005, España-Bonet et al. 2009, Haque et al. 2010, Banchs and Costa-jussà 2011) multiword expression identification, name entity recognition and shallow parsing. A recent study (Williams et al. 2013) explored the task of meaning unit segmentation by human annotators in languages such as English and Chinese. The result of this study suggested that no optimal solution seems to exist for this problem. Although any random segmentation is definitively not acceptable, it seems to be some preferential but variable trends on how humans perform meaning unit segmentation. 3.3 Target Unit Reordering Reorderi"
W15-4106,D07-1077,0,0.0357389,"that, in this specific subtask, we are dealing with chunk-based reordering rather than wordbased reordering. Indeed, word-reordering is assumed to be accounted for during the phase of target unit selection, in which each target meaning unit should already incorporate the corresponding word-reordering that is required to convey the desired meaning. Valuable research related to this area includes lexicalized reordering as well as class-based reordering, dependency parsing and syntax based machine translation (Li et al. 2007, Nagata et al 2006, Zhang et al. 2007, Costa-jussa and Fonollosa 2006, Wang et al. 2007). 3.2 Target Unit Selection One of the most interesting observations derived from the psycho-cognitive model is that the translation of a given meaning unit seems to be uniquely determined by its surrounding context. This fact allows for a theoretical justification on decoupling the problem of unit selection from the problem of reordering (long reordering, actually), as the problem of target unit selection becomes independent from the target language structure, which can be dealt with afterwards by means of reordering strategies that should only use target language information. The main proper"
W15-4106,P13-1126,0,0.023166,"Missing"
W15-4106,W13-3301,1,0.842414,"t deal with two specific types of problems: boundary overlapping, where consecutive units are to be merged by resolving possible word overlap37 tics, syntax-based machine translation, and crosslanguage information retrieval. Significant effort on using source-context information to improve target unit selection has been reported during the last few years for both domain adaptation and lexical semantics (Carpuat and Wu 2005, España-Bonet et al. 2009, Haque et al. 2010, Banchs and Costa-jussà 2011) multiword expression identification, name entity recognition and shallow parsing. A recent study (Williams et al. 2013) explored the task of meaning unit segmentation by human annotators in languages such as English and Chinese. The result of this study suggested that no optimal solution seems to exist for this problem. Although any random segmentation is definitively not acceptable, it seems to be some preferential but variable trends on how humans perform meaning unit segmentation. 3.3 Target Unit Reordering Reordering is probably one of the most important challenges in SMT research, as well as it is the key factor responsible for decoding being an NPcomplete problem (Zaslavskiy et al. 2009). The significant"
W15-4106,W06-1609,0,0.0915659,"Missing"
W15-4106,2007.iwslt-1.3,0,0.0245255,"g the quality of the resulting translations. Notice that, in this specific subtask, we are dealing with chunk-based reordering rather than wordbased reordering. Indeed, word-reordering is assumed to be accounted for during the phase of target unit selection, in which each target meaning unit should already incorporate the corresponding word-reordering that is required to convey the desired meaning. Valuable research related to this area includes lexicalized reordering as well as class-based reordering, dependency parsing and syntax based machine translation (Li et al. 2007, Nagata et al 2006, Zhang et al. 2007, Costa-jussa and Fonollosa 2006, Wang et al. 2007). 3.2 Target Unit Selection One of the most interesting observations derived from the psycho-cognitive model is that the translation of a given meaning unit seems to be uniquely determined by its surrounding context. This fact allows for a theoretical justification on decoupling the problem of unit selection from the problem of reordering (long reordering, actually), as the problem of target unit selection becomes independent from the target language structure, which can be dealt with afterwards by means of reordering strategies that should on"
W15-4106,P06-1090,0,\N,Missing
W15-4106,P98-2141,0,\N,Missing
W15-4106,C98-2136,0,\N,Missing
W15-4615,P08-1072,0,0.0325984,"empted to solve this problem with text categorization approaches for the utterances in a given turn. However, these approaches can only be effective for the cases when users mention the topic-related expressions explicitly in their utterances, because the models for text categorization assume that the proper category for each textual unit can be assigned based only on its own contents. The other direction of dialogue topic tracking made use of external knowledge sources including domain models (Roy and Subramaniam, 2006), heuristics (Young et al., 2007), and agendas (Bohus and Rudnicky, 2003; Lee et al., 2008). While 124 Proceedings of the SIGDIAL 2015 Conference, pages 124–128, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics t 0 1 Speaker Guide Tourist 2 Tourist Guide Tourist Guide Guide 3 4 Tourist Guide 5 Tourist 6 Guide Tourist Guide 7 Tourist Guide 8 Tourist Utterance How can I help you? Can you recommend some good places to visit in Singapore? Well if you like to visit an icon of Singapore, Merlion park will be a nice place to visit. That is a symbol for your country, right? Yes, we use that to symbolise Singapore. Okay. The lion head symbolised th"
W15-4615,E06-1002,0,0.0128954,"obtained from both given texts and Wikipedia collection, our proposed method utilizing the results from Wikification contributes to improve the tracking performances compared to the former approaches based on dialogue segment-level correspondences. 2 t 1 Wikification of Concept Mentions in Spoken Dialogues Wikification aims at linking mentions to the relevant entries in Wikipedia. As shown in the examples in Figure 2 for the dialogue in Figure 1, this task is performed by dealing with co-references, ambiguities, and variabilities of the mentions. Following most previous work on Wikification (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Dredze et al., 2010; Han and Sun, 2011; Chen and Ji, 2011), this work also takes a supervised learning to rank algorithm for determining the most relevant concept for each mention in transcribed utterances. In this work, every noun phrase in a given dialogue session is defined as a single mention. To capture more abstract concepts, we take not only named entities or base noun phrases, but also every complex or recursive noun phrase in a dialogue as the instance to be linked. For each mention, a set of candidates are retrieved from a Lucene 1"
W15-4615,D11-1071,0,0.0136063,"n contributes to improve the tracking performances compared to the former approaches based on dialogue segment-level correspondences. 2 t 1 Wikification of Concept Mentions in Spoken Dialogues Wikification aims at linking mentions to the relevant entries in Wikipedia. As shown in the examples in Figure 2 for the dialogue in Figure 1, this task is performed by dealing with co-references, ambiguities, and variabilities of the mentions. Following most previous work on Wikification (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Dredze et al., 2010; Han and Sun, 2011; Chen and Ji, 2011), this work also takes a supervised learning to rank algorithm for determining the most relevant concept for each mention in transcribed utterances. In this work, every noun phrase in a given dialogue session is defined as a single mention. To capture more abstract concepts, we take not only named entities or base noun phrases, but also every complex or recursive noun phrase in a dialogue as the instance to be linked. For each mention, a set of candidates are retrieved from a Lucene 1 index on the whole Wikipedia collection divided by section-level. The ranking score s(m, c) for a given pair o"
W15-4615,W02-0702,0,0.063244,"atures can significantly improve the performances of the task in mixed-initiative human-human dialogues. 1 Introduction Dialogue topic tracking aims at detecting topic transitions and predicting topic categories in ongoing dialogues which address more than a single topic. Since human communications in real-world situations tend to consist of a series of multiple topics even for a single domain, tracking dialogue topics plays a key role in analyzing human-human dialogues as well as improving the naturalness of human-machine interactions by conducting multitopic conversations. Some researchers (Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008) attempted to solve this problem with text categorization approaches for the utterances in a given turn. However, these approaches can only be effective for the cases when users mention the topic-related expressions explicitly in their utterances, because the models for text categorization assume that the proper category for each textual unit can be assigned based only on its own contents. The other direction of dialogue topic tracking made use of external knowledge sources including domain models (Roy and Subramaniam, 2006), heuristics (Youn"
W15-4615,C10-1032,0,0.0294281,"d utilizing the results from Wikification contributes to improve the tracking performances compared to the former approaches based on dialogue segment-level correspondences. 2 t 1 Wikification of Concept Mentions in Spoken Dialogues Wikification aims at linking mentions to the relevant entries in Wikipedia. As shown in the examples in Figure 2 for the dialogue in Figure 1, this task is performed by dealing with co-references, ambiguities, and variabilities of the mentions. Following most previous work on Wikification (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Dredze et al., 2010; Han and Sun, 2011; Chen and Ji, 2011), this work also takes a supervised learning to rank algorithm for determining the most relevant concept for each mention in transcribed utterances. In this work, every noun phrase in a given dialogue session is defined as a single mention. To capture more abstract concepts, we take not only named entities or base noun phrases, but also every complex or recursive noun phrase in a dialogue as the instance to be linked. For each mention, a set of candidates are retrieved from a Lucene 1 index on the whole Wikipedia collection divided by section-level. The r"
W15-4615,P06-1093,0,0.0371547,"tions. Some researchers (Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008) attempted to solve this problem with text categorization approaches for the utterances in a given turn. However, these approaches can only be effective for the cases when users mention the topic-related expressions explicitly in their utterances, because the models for text categorization assume that the proper category for each textual unit can be assigned based only on its own contents. The other direction of dialogue topic tracking made use of external knowledge sources including domain models (Roy and Subramaniam, 2006), heuristics (Young et al., 2007), and agendas (Bohus and Rudnicky, 2003; Lee et al., 2008). While 124 Proceedings of the SIGDIAL 2015 Conference, pages 124–128, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics t 0 1 Speaker Guide Tourist 2 Tourist Guide Tourist Guide Guide 3 4 Tourist Guide 5 Tourist 6 Guide Tourist Guide 7 Tourist Guide 8 Tourist Utterance How can I help you? Can you recommend some good places to visit in Singapore? Well if you like to visit an icon of Singapore, Merlion park will be a nice place to visit. That is a symbol for your"
W15-4615,P11-1095,0,0.0351157,"Missing"
W15-4615,P14-2004,1,0.717279,"khwan Kim, Rafael E. Banchs, Haizhou Li Human Language Technology Department Institute for Infocomm Research Singapore 138632 {kims,rembanchs,hli}@i2r.a-star.edu.sg Abstract these knowledge-based methods have an advantage of dealing with system-initiative dialogues by controlling dialogue flows based on given resources, they have drawbacks in low flexibility to handle the user’s responses and high costs for building the resources. Recently, we have proposed to explore domain knowledge from Wikipedia for mixed-initiative dialogue topic tracking without significant costs for building resources (Kim et al., 2014a; Kim et al., 2014b). In these methods, a set of articles that have similar contents to a given dialogue segment are selected using vector space model. Then various types of information obtained from the articles are utilized to learn topic trackers based on kernel methods. In this work, we focus on the following limitations of our former work in retrieving relevant concepts at a given turn with the term vector similarity between each pair of dialogue segment and Wikipedia article. Firstly, the contents of conversation could be expressed in totally different ways from the descriptions in the"
W15-4615,W02-0214,0,0.0362271,"tly improve the performances of the task in mixed-initiative human-human dialogues. 1 Introduction Dialogue topic tracking aims at detecting topic transitions and predicting topic categories in ongoing dialogues which address more than a single topic. Since human communications in real-world situations tend to consist of a series of multiple topics even for a single domain, tracking dialogue topics plays a key role in analyzing human-human dialogues as well as improving the naturalness of human-machine interactions by conducting multitopic conversations. Some researchers (Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008) attempted to solve this problem with text categorization approaches for the utterances in a given turn. However, these approaches can only be effective for the cases when users mention the topic-related expressions explicitly in their utterances, because the models for text categorization assume that the proper category for each textual unit can be assigned based only on its own contents. The other direction of dialogue topic tracking made use of external knowledge sources including domain models (Roy and Subramaniam, 2006), heuristics (Young et al., 2007), and agend"
W15-4615,C02-1082,0,\N,Missing
W16-0506,W13-1703,0,0.174173,"” scientific language should look like. Initiating this task, we expected the participating teams to help identify the characteristics of “good” scientific language, and help create a consensus of which language improvements are acceptable (or necessary). Six participating teams took on the challenge. 1 Courtney Napoles Johns Hopkins University courtneyn@jhu.edu An extensive overview of the automated grammatical error detection for language learners was conducted by Leacock et al. (2010). In subsequent years two English language learner (ELL) corpora were made available for research purposes (Dahlmeier et al., 2013; Yannakoudakis et al., 2011). While these achievements are critical for language learners, we also need to develop tools that support genre-specific writing features. This shared task focused on the genre of scientific writing. Most scientific publications are written in English by non-native speakers of English. Submitted articles are often returned to the authors with an encouragement to improve the language or have a native speaker proofread the paper. Pierson (2004) lists 10 top reasons why manuscripts are not accepted for publication, with poor writing in the 7th place. Introduction The"
W16-0506,W11-2838,0,0.0655697,"error detection and correction, and constituted a major step towards evaluating the feasibility of building novel grammar error correction technologies. The Automated Evaluation of Scientific Writing, or AESW, is the task of identifying sentences in need of correction to ensure their appropriateness in a scientific prose. The data set comes from a professional editing company, VTeX, with two aligned versions of the same text – before and after editing – and covers a variety of textual infelicities that proofreaders have edited. While previous shared tasks focused solely on grammatical errors (Dale and Kilgarriff, 2011; Dale et al., 2012; Ng et al., 2013; Ng et al., 2014), this time edits cover other types of linguistic misfits as well, including those that almost certainly could be interpreted as style issues and similar “matters of opinion”. The latter arise because of different language editing traditions, experience, and the absence of uniform agreement on what “good” scientific language should look like. Initiating this task, we expected the participating teams to help identify the characteristics of “good” scientific language, and help create a consensus of which language improvements are acceptable ("
W16-0506,W12-2006,0,0.173063,"ion, and constituted a major step towards evaluating the feasibility of building novel grammar error correction technologies. The Automated Evaluation of Scientific Writing, or AESW, is the task of identifying sentences in need of correction to ensure their appropriateness in a scientific prose. The data set comes from a professional editing company, VTeX, with two aligned versions of the same text – before and after editing – and covers a variety of textual infelicities that proofreaders have edited. While previous shared tasks focused solely on grammatical errors (Dale and Kilgarriff, 2011; Dale et al., 2012; Ng et al., 2013; Ng et al., 2014), this time edits cover other types of linguistic misfits as well, including those that almost certainly could be interpreted as style issues and similar “matters of opinion”. The latter arise because of different language editing traditions, experience, and the absence of uniform agreement on what “good” scientific language should look like. Initiating this task, we expected the participating teams to help identify the characteristics of “good” scientific language, and help create a consensus of which language improvements are acceptable (or necessary). Six"
W16-0506,C10-2103,0,0.0642734,"systems in the converted probabilities analysis. As demonstrated, different statistics produce dissimilar system rankings. The official scores for both tasks are the F-score, as defined in the workshop description, but there is evidence that the evaluation could be improved in future tasks. UW-SU and HITS pointed out that favoring recall over precision improves their F-score, which increases the system’s ranking but decreases its accuracy. Precision has been shown to be more effective when providing feedback on grammatical errors, with less, accurate feedback better than inaccurate feedback (Nagata and Nakatani, 2010). For future shared tasks, additional evaluation methods should be investigated, including F0.5 , which weights precision more than recall, and a comparison to human evaluation, such as is done by the Workshop on Machine Translation (Bojar et al., 2015). 7.1 The trends of system predictions The initial impetus to organize this competition was to gain insight into the specifics of scientific writing as a genre and, with the help of participants, to make an estimation of whether it is possible to offer any robust automatic solutions to support researchers with non-native English background in wr"
W16-0506,P11-1019,0,0.139131,"ould look like. Initiating this task, we expected the participating teams to help identify the characteristics of “good” scientific language, and help create a consensus of which language improvements are acceptable (or necessary). Six participating teams took on the challenge. 1 Courtney Napoles Johns Hopkins University courtneyn@jhu.edu An extensive overview of the automated grammatical error detection for language learners was conducted by Leacock et al. (2010). In subsequent years two English language learner (ELL) corpora were made available for research purposes (Dahlmeier et al., 2013; Yannakoudakis et al., 2011). While these achievements are critical for language learners, we also need to develop tools that support genre-specific writing features. This shared task focused on the genre of scientific writing. Most scientific publications are written in English by non-native speakers of English. Submitted articles are often returned to the authors with an encouragement to improve the language or have a native speaker proofread the paper. Pierson (2004) lists 10 top reasons why manuscripts are not accepted for publication, with poor writing in the 7th place. Introduction The vast number of scientific pap"
W16-0506,W15-3001,0,\N,Missing
W16-0506,W13-3601,0,\N,Missing
W16-2703,P05-1045,0,0.0336585,"Missing"
W16-2703,W03-0419,0,0.0437085,"Missing"
W16-2703,W95-0107,0,0.0925598,"6.0). It is based on linear chain Conditional Random Field (Jenny Rose Finkel et al., 2005). The models were trained on a mixture of CoNLL, MUC-6, MUC-7 and ACE named entity corpora. The basic required output tags are “PERSON”, “LOCATION” and “ORGANIZATION”. 1 Integration https://spacy.io/ 22 Fig. 1. System diagram for automated evaluation 3 The overall system structure of the integrated evaluation system is shown in Fig. 1. In the process of evaluation, an annotated (gold-standard) input document must be provided. Currently, the supported format is IOB (short for Inside, Outside, Beginning) (Ramshaw and Marcus, 1995). In this scheme, every line in the file represents one token with two fields: the word itself and its named entity type. Empty lines denote sentence boundaries. Following is an example of the representation: Albert I-PERSON Einstein I-PERSON was O born O in O Ulm I-LOCATION .O With the methodology defined in section 2, it is ready to evaluate all the selected tools with any data file annotated in the IOB format. Evaluation 3.1 Evaluation Corpus Since all the selected NER tools are able to classify the three entity types: PERSON, LOCATION and ORGANIZATION, the evaluation corpus must contain at"
W16-2703,W09-3302,0,0.0167464,"is an example of the representation: Albert I-PERSON Einstein I-PERSON was O born O in O Ulm I-LOCATION .O With the methodology defined in section 2, it is ready to evaluate all the selected tools with any data file annotated in the IOB format. Evaluation 3.1 Evaluation Corpus Since all the selected NER tools are able to classify the three entity types: PERSON, LOCATION and ORGANIZATION, the evaluation corpus must contain at least the above three entity types. The format is better to be in the supported IOB chunk representation. We found that WikiGold 2 meets the above requirements. WikiGold (Balasuriya et al. 2009) is an annotated corpus over a small sample of Wikipedia articles in CoNLL format (IOB). It contains 145 documents (separated by “DOCSTART-”), 1696 sentences and 39152 tokens. The statistics of named entities is shown in table 1. The prefix “I-” in the tag means that the tag is inside a chunk. While the prefix “B-” indicates that the tag is the beginning of a chunk and is only used when a tag is followed by a tag of the same type without “O” tag between them. The “O” tag just means it is out of the chunk. This IOB chunk representation is much easier for manual annotation than inside XML annota"
W16-2703,W09-1119,0,0.162953,"Missing"
W16-2703,C96-1079,0,0.649285,"Missing"
W16-2703,W99-0613,0,0.0897117,"Missing"
W16-2703,W03-1306,0,0.019176,"he configuration of the proposed hybrid NER system. Both tools showed good scores in our previous evaluation and are able to identify DATE entity without any extra setting (Stanford NER 7-class model includes the DATE type). Our first target domain of application is Wikipedia pages about Singapore. To construct the hybrid NER system, we simply combined the outputs of the Stanford NER system and spaCy NER by using union method. In addition, a dictionary with limited entries on PERSON, LOCATION and ORGANIZATION about Singapore was also created with the expectation of improving system precision (Tsuruoka and Tsujii 2003; Cohen and Sarawagi, 2004). We set the dictionary to have the highest priority when there is any conflict with the outputs from other tools. Then followed by Stanford NER tool, it 24 has the second highest priority determination of final named entities. 4.2 on the Table 4. Evaluation results on History testing dataset Data for Evaluation P Stanford In order to evaluate the performance of the hybrid system, we manually annotated twenty two web pages. All the web pages are from Singapore National Library Board eResources3 . Half of the web pages are about Singapore history, another half are fro"
W16-2703,W03-0430,0,0.0366912,"Missing"
W16-2703,W02-2029,0,0.0490196,"Missing"
W16-2703,A00-1034,0,0.0282468,"Missing"
W16-2703,W11-0207,0,\N,Missing
W16-2708,P04-1021,1,0.668693,"Missing"
W16-2709,W16-2713,0,0.0529993,"Missing"
W16-2709,W15-3912,0,0.0431505,"Missing"
W16-2709,W16-2711,0,0.147552,"Missing"
W16-2709,P04-1021,1,0.691542,"Xiangyu Duan2,Rafael E. Banchs1, Min Zhang2, Haizhou Li1, A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {xiangyuduan,minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based met"
W16-2709,D08-1037,0,0.0235887,"mbanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {xiangyuduan,minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combinatio"
W16-2709,W10-2401,1,0.722231,"rs to the combination of several different models or knowledge sources to support the transliteration generation process. The first machine transliteration shared task (Li et al. 2009b, Li et al. 2009a) was organized and conducted aspart of NEWS 2009 at ACLIJCNLP 2009. It was the first time that common benchmarking data in diverse language pairs was provided for evaluating state-of-the-art machine transliteration. While the focus of the 2009 shared task was on establishing the quality metrics and on setting up a baselinefor transliteration quality based on those metrics, the 2010 shared task (Li et al. 2010a, Li et al. 2010b) focused on expanding the scope of the transliteration generation task to about a dozen languages and on exploring the quality of the task depending on the direction of transliteration. In NEWS 2011 (Zhang et al. 2011a, Zhang et al. 2011b), Abstract This report presents the results from the Machine Transliteration Shared Task conducted as part of The Sixth Named Entities Workshop (NEWS 2016) held at ACL 2016in Berlin, Germany. Similar to previous editions of NEWS Workshop, the Shared Task featured machine transliteration of proper names over 14 different language pairs, incl"
W16-2709,W09-3504,0,0.0634137,"Missing"
W16-2709,W15-3911,0,0.117942,"Missing"
W16-2709,N10-1103,0,0.0421265,"Missing"
W16-2709,C02-1099,0,0.0830346,",minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of several different models or knowledge sources to support the tran"
W16-2709,W16-2710,0,0.20966,"Missing"
W16-2709,P06-1103,0,0.0441788,"China 215006 {xiangyuduan,minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of several different models or knowledge sources t"
W16-2709,P07-1119,0,0.0158206,"A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {xiangyuduan,minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences t"
W16-2709,P06-1010,0,0.0387549,"hang2, Haizhou Li1, A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {xiangyuduan,minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of p"
W16-2709,P98-2220,0,0.225327,"s Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of several different models or knowledge sources to support the transliteration generation process. The first machine"
W16-2709,W15-3910,0,0.0327487,"Missing"
W16-2709,W15-3913,0,0.0273111,"Missing"
W16-2709,W06-1672,0,0.0300352,"afael E. Banchs1, Min Zhang2, Haizhou Li1, A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {xiangyuduan,minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl"
W16-2709,W03-1508,0,\N,Missing
W16-2709,W02-0505,0,\N,Missing
W16-2709,N07-1047,0,\N,Missing
W16-2709,P07-2045,0,\N,Missing
W16-2709,C98-2215,0,\N,Missing
W16-2709,W11-3202,1,\N,Missing
W16-2709,W12-4402,1,\N,Missing
W16-2709,J98-4003,0,\N,Missing
W16-2709,W11-3201,1,\N,Missing
W18-2404,D14-1162,0,0.0815301,"L : m0 ×k, with m0 unique conWhile PIN is a straightforward simulation of the semantic priming mechanism between a prime and its potential targets in different classes, PIC and PC are variants of a categorization mechanism referred to as the Basic Level (Rosch et al., 1976), in which the targets are intermediate, dominant concepts that represent the category. 23 # utterances in train # utterances in dev # utterances in test # labels vocab. size† max utterance length ATIS MEDIA 3982 995 893 127 572 46 12908 1259 3005 138 1671 192 word embedding sources for the two datasets are GloVe (English) (Pennington et al., 2014) and fastText (French) (Bojanowski et al., 2016), respectively. In particular, we found that there are about 100 words missing in the fastText French word embedding. Some of the words, however, are due to original tokenization in MEDIA. 4.2 Table 1: Statistics of datasets. a mix of words and entities. † The vocabulary is To facilitate mini-batching for training, the utterances were padded to the maximum utterance length. For all experiments, we use one set of fixed hyperparameters to enable meaingful comparison. The dimension of word embedding is 300 for both GloVe and fastText. Following the"
W18-2404,D17-1035,0,0.0130226,"nth Named Entities Workshop, pages 22–26 c Melbourne, Australia, July 20, 2018. 2018 Association for Computational Linguistics sequence-based NLP tasks, particularly, machine translation (Bahdanau et al., 2014; Luong et al., 2015). Since attention allows the neural networks to dynamically attend to important features in the inputs, it is a suitable mechanism to achieve the objective of semantic priming between utterances and labels. Conditional random field (CRF) has been used together with RNNs, sometimes also including CNNs, to improve accuracy (Mesnil et al., 2013, 2015; Ma and Hovy, 2016; Reimers and Gurevych, 2017b). Dinarelli et al. (2017) proposes to learn label embedding for improving tagging accuracy, while our label embedding is computed directly from pre-trained word embeddings. Furthermore, our approach does not require shifted label sequences as input. To use external knowledge, previous studies consider graph or entity embedding (Huang et al., 2017; Chen et al., 2016; Yang and Mitchell, 2017), together with other contextual information, such as dependency graph (Huang et al., 2017) or sentence structures (Chen et al., 2016). Specifically, Yang and Mitchell (2017) extends LSTM with graph embedd"
W18-2404,H94-1010,0,0.598437,"the F1 scores are the average of that in the first 30 epochs in three independent runs. The results shown are for baseline with trainable embedding (BE), baseline with pre-trained embedding (BP), and the strategies defined in Section 3.1, i.e., PIC, PIN and PC. For PC, the concepts are the keywords that have occurred in the labels. Example concepts include airline in ATIS and chambre in MEDIA. A total of 30 and 53 concepts are extracted for PC in ATIS and MEDIA, respectively. Two datasets on spoken dialogues were used in the experiments, namely, the Air Travel Information System (ATIS) task (Dahl et al., 1994) and MEDIA, French dialogues collected by ELDA (Bonneau-Maynard et al., 2005). The statistics of the two datasets is given in Table 1. For MEDIA, using entities significantly impacts the performance. Thus entities are used together with words in utterances, as implied by the size of vocabulary in Table 1. Since bi-directional LSTM is used in the architecture in Figure 1, no context word windows (Mesnil et al., 2015) were used as additional inputs in the datasets. The pre-trained 1 Setup and Hyperparameters 2 https://keras.io/ 24 http://www.cnts.ua.ac.be/conll2000/chunking/output.html Although"
W18-2404,P17-1132,0,0.0193863,"priming between utterances and labels. Conditional random field (CRF) has been used together with RNNs, sometimes also including CNNs, to improve accuracy (Mesnil et al., 2013, 2015; Ma and Hovy, 2016; Reimers and Gurevych, 2017b). Dinarelli et al. (2017) proposes to learn label embedding for improving tagging accuracy, while our label embedding is computed directly from pre-trained word embeddings. Furthermore, our approach does not require shifted label sequences as input. To use external knowledge, previous studies consider graph or entity embedding (Huang et al., 2017; Chen et al., 2016; Yang and Mitchell, 2017), together with other contextual information, such as dependency graph (Huang et al., 2017) or sentence structures (Chen et al., 2016). Specifically, Yang and Mitchell (2017) extends LSTM with graph embedding to learn concepts from knowledge bases and integrate the concept embedding into the state vectors of words. In contrast, our approach does not learn or parse sentences to get extra contextual information, which is suitable for languages lacking well trained parsers. Moreover, context integration is achieved without fine-tuning the underlying RNN structure yet rather through the attention"
W18-2404,D17-1274,0,0.0310632,"sm to achieve the objective of semantic priming between utterances and labels. Conditional random field (CRF) has been used together with RNNs, sometimes also including CNNs, to improve accuracy (Mesnil et al., 2013, 2015; Ma and Hovy, 2016; Reimers and Gurevych, 2017b). Dinarelli et al. (2017) proposes to learn label embedding for improving tagging accuracy, while our label embedding is computed directly from pre-trained word embeddings. Furthermore, our approach does not require shifted label sequences as input. To use external knowledge, previous studies consider graph or entity embedding (Huang et al., 2017; Chen et al., 2016; Yang and Mitchell, 2017), together with other contextual information, such as dependency graph (Huang et al., 2017) or sentence structures (Chen et al., 2016). Specifically, Yang and Mitchell (2017) extends LSTM with graph embedding to learn concepts from knowledge bases and integrate the concept embedding into the state vectors of words. In contrast, our approach does not learn or parse sentences to get extra contextual information, which is suitable for languages lacking well trained parsers. Moreover, context integration is achieved without fine-tuning the underlying RN"
W18-2404,D15-1166,0,0.0782711,"contextual information in utterance sequences (Mesnil et al., 2015) and dependencies between labels (Ma and Hovy, 2016) to improve performance in sequence labelling tasks. However, there is limited work to use contextual information in utterances to inform 2 Related Work Our proposed method draws on the attention mechanism, which has shown to be effective for 22 Proceedings of the Seventh Named Entities Workshop, pages 22–26 c Melbourne, Australia, July 20, 2018. 2018 Association for Computational Linguistics sequence-based NLP tasks, particularly, machine translation (Bahdanau et al., 2014; Luong et al., 2015). Since attention allows the neural networks to dynamically attend to important features in the inputs, it is a suitable mechanism to achieve the objective of semantic priming between utterances and labels. Conditional random field (CRF) has been used together with RNNs, sometimes also including CNNs, to improve accuracy (Mesnil et al., 2013, 2015; Ma and Hovy, 2016; Reimers and Gurevych, 2017b). Dinarelli et al. (2017) proposes to learn label embedding for improving tagging accuracy, while our label embedding is computed directly from pre-trained word embeddings. Furthermore, our approach doe"
W18-2404,P16-1101,0,0.0232177,"both the prime and the target typically belong to the same semantic category. Semantic priming can be explained in terms of induced activation in associative neural networks (McClelland and Rogers, 2003). Further, there is empirical evidence to suggest that the processing of words in natural language is influenced by preceding words that are semantically related (Foss, 1982). Therefore, semantic priming approaches would enable improvements in sequence labelling. Previous studies have leveraged contextual information in utterance sequences (Mesnil et al., 2015) and dependencies between labels (Ma and Hovy, 2016) to improve performance in sequence labelling tasks. However, there is limited work to use contextual information in utterances to inform 2 Related Work Our proposed method draws on the attention mechanism, which has shown to be effective for 22 Proceedings of the Seventh Named Entities Workshop, pages 22–26 c Melbourne, Australia, July 20, 2018. 2018 Association for Computational Linguistics sequence-based NLP tasks, particularly, machine translation (Bahdanau et al., 2014; Luong et al., 2015). Since attention allows the neural networks to dynamically attend to important features in the input"
W18-2408,P04-1021,1,0.453791,"Missing"
W18-2409,W18-2414,0,0.0493369,"Missing"
W18-2409,P04-1021,1,0.614661,"en1, Rafael E. Banchs2, Min Zhang3, Xiangyu Duan3, Haizhou Li4 1 Singapore University of Technology and Design, Singapore nancychen@alum.mit.edu 2 Nanyang Technological University, Singapore rbanchs@ntu.edu.sg 3 Soochow University, China {minzhang,xiangyuduan}@suda.edu.cn 4 National University of Singapore, Singapore haizhou.li@nus.edu.sg All of the above points to the critical need for robust machine transliteration methods and systems. Significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, AlOnaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These efforts fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthographyrelated features while phoneme-based methods"
W18-2409,W10-2401,1,0.712599,"ently, neural network approaches have been explored with varying successes, depending on the size of the training data. The first machine transliteration shared task (Li et al. 2009a, Li et al. 2009b) was organized and conducted as part of NEWS 2009 at ACLIJCNLP 2009. It was the first time that common benchmarking data in diverse language pairs was provided for evaluating state-of-the-art machine transliteration. While the focus of the 2009 shared task was on establishing the quality metrics and on setting up a baseline for transliteration quality based on those metrics, the 2010 shared task (Li et al. 2010a, Li et al. 2010b) foAbstract This report presents the results from the Named Entity Transliteration Shared Task conducted as part of The Seventh Named Entities Workshop (NEWS 2018) held at ACL 2018 in Melbourne, Australia. Similar to previous editions of NEWS, the Shared Task featured 19 tasks on proper name transliteration, including 13 different languages and two different Japanese scripts. A total of 6 teams from 8 different institutions participated in the evaluation, submitting 424 runs, involving different transliteration methodologies. Four performance metrics were used to report the"
W18-2409,D08-1037,0,0.0247158,"um.mit.edu 2 Nanyang Technological University, Singapore rbanchs@ntu.edu.sg 3 Soochow University, China {minzhang,xiangyuduan}@suda.edu.cn 4 National University of Singapore, Singapore haizhou.li@nus.edu.sg All of the above points to the critical need for robust machine transliteration methods and systems. Significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, AlOnaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These efforts fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthographyrelated features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of"
W18-2409,P17-4012,0,0.0145929,"e-based machine translation). All other systems used some version of neural modeling. It is interesting to note that non-neural systems by SINGA, while not the highest in performance, are generally comparable to neural systems or system combinations which include neural models. Regarding the systems participating in this year evaluation, the UALB’s system (Najafi et al. 2018) was based on multiple system combinations. They presented experimental results involving five different well-known transliteration approaches: DirecTL+ (Jiampojamarn et al. 2009), Sequitur (Bisani and Ney 2008), OpenNMT (Klein et al. 2017), BaseNMT (Sutskever et al. 2014), and RL-NMT (Najafi et al., 2018). They T)EnPe 0 WIPO 0.2 0.4 SINGA UQAM 0.6 UJUS 0.8 EDI 1 UALB Figure 1: Mean F-scores (Top-1) on the evaluation set for all primary submissions and tasks. The UJUS system (Kundu et al. 2018) used an RNN-based NMT framework and a CNN-based NMT framework, where both byte-pair encoding and character-based segmentation were employed for both cases. They also adopted an ensemble method to choose the hypothesis that has the highest frequency of occurrence to further improve accuracy. The EDI system (Grundkiewicz et al. 2018) system"
W18-2409,C02-1099,0,0.129101,"oochow University, China {minzhang,xiangyuduan}@suda.edu.cn 4 National University of Singapore, Singapore haizhou.li@nus.edu.sg All of the above points to the critical need for robust machine transliteration methods and systems. Significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, AlOnaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These efforts fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthographyrelated features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of several different models or knowledge sources to support the transliter"
W18-2409,P06-1103,0,0.0560026,"ore rbanchs@ntu.edu.sg 3 Soochow University, China {minzhang,xiangyuduan}@suda.edu.cn 4 National University of Singapore, Singapore haizhou.li@nus.edu.sg All of the above points to the critical need for robust machine transliteration methods and systems. Significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, AlOnaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These efforts fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthographyrelated features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of several different models or knowledge sources to supp"
W18-2409,P07-1119,0,0.0417746,"Li4 1 Singapore University of Technology and Design, Singapore nancychen@alum.mit.edu 2 Nanyang Technological University, Singapore rbanchs@ntu.edu.sg 3 Soochow University, China {minzhang,xiangyuduan}@suda.edu.cn 4 National University of Singapore, Singapore haizhou.li@nus.edu.sg All of the above points to the critical need for robust machine transliteration methods and systems. Significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, AlOnaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These efforts fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthographyrelated features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to gen"
W18-2409,P07-2045,0,0.0067284,"Missing"
W18-2409,P06-1010,0,0.0603142,"ngyu Duan3, Haizhou Li4 1 Singapore University of Technology and Design, Singapore nancychen@alum.mit.edu 2 Nanyang Technological University, Singapore rbanchs@ntu.edu.sg 3 Soochow University, China {minzhang,xiangyuduan}@suda.edu.cn 4 National University of Singapore, Singapore haizhou.li@nus.edu.sg All of the above points to the critical need for robust machine transliteration methods and systems. Significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, AlOnaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These efforts fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthographyrelated features while phoneme-based methods (Knight and Graehl 1998) make use of phonet"
