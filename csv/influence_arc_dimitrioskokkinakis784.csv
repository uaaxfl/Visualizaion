borin-etal-2010-diabase,elenius-etal-2008-language,0,\N,Missing
borin-etal-2010-diabase,fillmore-etal-2002-framenet,0,\N,Missing
borin-etal-2010-diabase,W04-2607,0,\N,Missing
D17-1107,P16-2094,0,0.0553127,"Missing"
D17-1107,borin-etal-2012-korp,0,0.0216362,"n word. Has this word been visited yet? Have any later words been visited? No Yes No First-pass first fixation Later-pass first fixation Yes Multi-fixation Re-fixation Table 3: Four types of fixations two texts using the Sparv annotation tool2 (Borin et al., 2016). Specifically, each word was lemmatized and labeled with its part-of-speech (POS). We assign a frequency value for each word lemma according to the number of times it occurs (per one million words) in the “Modern” language section of the Korp Swedish language corpus3 , which contained 10.7 billion word tokens at the time of writing (Borin et al., 2012). These frequency values are POS-disambiguated. We then partition the frequency values into high and low frequencies, with a threshold of 20 occurrences per million words. This threshold was chosen 2 https://spraakbanken.gu.se/eng/ research/infrastructure/sparv 3 https://spraakbanken.gu.se/eng/ korp-info We then define an augmented feature set, hereafter Biondi+word, which takes into account these word-level annotations. Specifically, we create new features corresponding to each of the fixationbased baseline features. (The original feature set also includes saccade amplitude, the computation o"
D17-1107,W14-3204,0,0.0739583,"Missing"
D17-1107,J15-4001,0,0.0278096,"Missing"
D17-1107,W15-5123,1,0.894142,"Missing"
E99-1035,C92-1027,0,0.535504,"Missing"
E99-1035,1992.tmi-1.11,0,0.00891671,"tic, finite-state, level recognizer, (Abney, 1996). Moreover, there is also the possibility of grouping words and/or part-of-speech tags using morphological and semantic criteria. 3.2 G r a m m a r Rules Some of the most important groups include: • N o u n P h r a s e s , Grammar0: the number of patterns in grammar0 is 180, divided in six different groups, depending on the length and complexity of the patterns. A large number of (parallel) coordination rules are also implemented at this level, depending on the similarity of the conjuncts with respect to several different characteristics, (cf. Nagao, 1992). • P r e p o s i t i o n a l P h r a s e s , Grammar1: the majority of prepositional phrases are noun Proceedings of EACL &apos;99 phrases preceded by a preposition. Trapped adverbials, belonging to the noun phrase and not identified while applying grammar0, are merged within the np. Both simple and multiword prepositions are used. • Verbal Groups, Grammar2: identifies and labels phrasal, non-phrasal, and complex verbal formations. The rules allow for any number of auxiliary verbs, possible intervening adverbs, and end with a main verb or particle. A distinction is made between finite/infinite act"
E99-1035,W98-1303,0,0.0444457,"Missing"
jarborg-etal-2002-lexical,2001.mtsummit-papers.34,0,\N,Missing
jarborg-etal-2002-lexical,H93-1061,0,\N,Missing
jarborg-etal-2002-lexical,P96-1006,0,\N,Missing
jarborg-etal-2002-lexical,S01-1011,1,\N,Missing
jarborg-etal-2002-lexical,corazzari-etal-2000-experiment,0,\N,Missing
jarborg-etal-2002-lexical,kokkinakis-etal-2000-annotating,1,\N,Missing
johansson-etal-2012-semantic,N10-1138,0,\N,Missing
johansson-etal-2012-semantic,J08-2001,0,\N,Missing
johansson-etal-2012-semantic,S07-1048,1,\N,Missing
johansson-etal-2012-semantic,W04-3212,0,\N,Missing
johansson-etal-2012-semantic,J92-4003,0,\N,Missing
johansson-etal-2012-semantic,P09-1003,0,\N,Missing
johansson-etal-2012-semantic,P08-1068,0,\N,Missing
johansson-etal-2012-semantic,W08-2123,1,\N,Missing
johansson-etal-2012-semantic,P07-1071,0,\N,Missing
johansson-etal-2012-semantic,P06-2057,1,\N,Missing
johansson-etal-2012-semantic,J02-3001,0,\N,Missing
johansson-etal-2012-semantic,P02-1031,0,\N,Missing
johansson-etal-2012-semantic,C08-1050,1,\N,Missing
kokkinakis-2006-collection,ide-etal-2000-xces,0,\N,Missing
kokkinakis-2006-collection,teufel-elhadad-2002-collection,0,\N,Missing
kokkinakis-2006-collection,W05-1306,0,\N,Missing
kokkinakis-2006-collection,E99-1001,0,\N,Missing
kokkinakis-2006-collection,C04-1039,0,\N,Missing
kokkinakis-2006-collection,W05-0304,0,\N,Missing
kokkinakis-2006-collection,E99-1035,1,\N,Missing
kokkinakis-2006-collection,H92-1045,0,\N,Missing
kokkinakis-2006-collection,P02-1032,0,\N,Missing
kokkinakis-2006-collection,sekine-nobata-2004-definition,0,\N,Missing
kokkinakis-2006-collection,wermter-hahn-2004-annotated,0,\N,Missing
kokkinakis-2006-collection,erk-pado-2004-powerful,0,\N,Missing
kokkinakis-2006-collection,baroni-bernardini-2004-bootcat,0,\N,Missing
kokkinakis-2008-mesh,W07-1026,0,\N,Missing
kokkinakis-2008-mesh,W07-1017,0,\N,Missing
kokkinakis-2008-mesh,P02-1032,0,\N,Missing
kokkinakis-2008-mesh,kokkinakis-dannells-2006-recognizing,1,\N,Missing
kokkinakis-2008-mesh,W04-3106,0,\N,Missing
kokkinakis-2008-mesh,kokkinakis-2008-semantically,1,\N,Missing
kokkinakis-2008-semantically,sekine-nobata-2004-definition,0,\N,Missing
kokkinakis-2008-semantically,kokkinakis-2006-collection,1,\N,Missing
kokkinakis-2008-semantically,kokkinakis-dannells-2006-recognizing,1,\N,Missing
kokkinakis-dannells-2006-recognizing,W01-0516,0,\N,Missing
kokkinakis-dannells-2006-recognizing,kokkinakis-2006-collection,1,\N,Missing
kokkinakis-etal-2000-annotating,W97-0803,0,\N,Missing
kokkinakis-etal-2000-annotating,H93-1053,0,\N,Missing
kokkinakis-etal-2000-annotating,E99-1035,1,\N,Missing
kokkinakis-etal-2014-hfst,U07-1010,0,\N,Missing
kokkinakis-etal-2014-hfst,W06-0503,0,\N,Missing
kokkinakis-etal-2014-hfst,E99-1001,0,\N,Missing
kokkinakis-etal-2014-hfst,W09-1119,0,\N,Missing
kokkinakis-etal-2014-hfst,C08-1034,0,\N,Missing
kokkinakis-etal-2014-hfst,P10-1015,0,\N,Missing
kokkinakis-etal-2014-hfst,W03-0419,0,\N,Missing
kokkinakis-etal-2014-hfst,P09-3003,0,\N,Missing
kokkinakis-etal-2014-hfst,C02-1130,0,\N,Missing
kokkinakis-etal-2014-hfst,W12-5701,0,\N,Missing
kokkinakis-etal-2014-hfst,sekine-nobata-2004-definition,0,\N,Missing
kokkinakis-etal-2014-hfst,C96-1079,0,\N,Missing
kokkinakis-etal-2014-hfst,W98-1603,1,\N,Missing
kokkinakis-gerdin-2010-swedish,C04-1087,0,\N,Missing
kokkinakis-gerdin-2010-swedish,A00-1031,0,\N,Missing
kokkinakis-gerdin-2010-swedish,W09-4410,0,\N,Missing
kokkinakis-gerdin-2010-swedish,W09-4505,1,\N,Missing
L18-1200,K17-1033,0,0.0974177,"oman’); even the wrong word referring to a piece of information is accepted (e.g., ‘ladder’ instead of ‘stool’; ‘shelf’ instead of ‘cabinet’ or ‘cupboard’) Moreover, these information units can be identified both with a top down approach (Croisile et al., 1996) or a bottom up one, e.g. using clustering word embeddings of the naming expressions (Yancheva & Rudzicz, 2016). Usually, subjects are given credit for mentioning the presence of a given ICU and thus this set of ICUs enables easy comparison across subjects and easy scoring of the predefined contents of the picture (Boschi et al., 2017). Sirts et al. (2017) applies the notion of semantic idea density3 (SID) on the same image, in which each SID is a count of the pre-defined information content units and is computed by counting the number of ICUs mentioned in the text and then normalising them by the total number of word tokens. 2.3 Cookie-Theft Datasets The most extensive dataset of the picture description publicly available is the DementiaBank4 corpus, a part of the TalkBank project, collected between 1983-88; (Becker et al., 1994; MacWhinney et al., 2011). DementiaBank is a clinical dataset which consists of interview recordings and transcripts"
L18-1200,williams-etal-2010-cambridge,0,0.175443,"s for the study of various types of dementia. In contrast to spontaneous speech the Cookie-theft allows control for content and context. Moreover, the figure is often used 1 Other spoken language elicitation procedures include the Wechsler’s Logical Memory (Wechsler, 1997), an immediate and delayed story recall test. 1252 because of the clear, straightforward drawings that reduce ambiguity and lessen the effect of memory problems. The picture allows the variation between speech-styles to be reduced, and also “minimizes confounds in analysis due to the controlled nature of the speech content” (Williams et al., 2010). 2.1 Previous Work Based on the Cookie-Theft Narratives based on the Cookie-theft picture have been a source of knowledge for clinical and experimental research worldwide which also enables potential cross-linguistic comparisons. The Cookie-theft stimuli has been used to elicit written narratives, and this can be especially useful when evaluating people with Alzheimer’s, as written language has been shown to be impaired even at the early stages of the disease. E.g., Forbes et al. (2004) reported significantly worse written discourse production at the mild and moderate stages of AD compared to"
L18-1200,W15-5123,1,0.845882,"yntactic complexity markers (such as [context free] production rules; dependency distance; noun phrase average length and noun phrase density; (iii) psycholinguistic measures (such as familiarity); (iv) imformation units (such as content density). Measures that can give an indication of semantic deficits are important and likely to be present even in the early stages of MCI. A large number of acoustic features (such as speech rate, pause frequency, filled pauses, total pause duration; pitch and formants) have been proposed as relevant in the literature (Roark et al., 2011; Ahmed et al., 2013; Yancheva et al., 2015) and it pinpoints the importance of distinguishing between vocal changes that occur with normal aging and those that are associated with MCI (and SCI). 8. chosen picture description task will be suitable for detecting subtle language deficits in patients with subjective and mild cognitive impairment, is a question we are currently investigating. We anticipate that a single image might limit our future findings, however we believe that the breadth of analysis as outlined above and the combination of features of both the audio signal (e.g., prosody) and text (e.g., information content units) cou"
N19-1367,W06-1615,0,0.0568066,"xtraction pipeline; however, they did not consider multilingual classification directly. More generally, multilingual NLP is an active and growing area of research. Some approaches to improving classifier performance on a resourcepoor target language by leveraging a resource-rich source language include: translate the target language to the source language (or vice versa) and 3660 1 https://dementia.talkbank.org/ train a unilingual classifier (Wan, 2009); extract features from the two languages separately and then use domain adaptation techniques to train a classifier for the target language (Blitzer et al., 2006; Prettenhofer and Stein, 2010); or determine a common representation for both languages and then extract features from the combined corpus to train a multilingual classifier (Ammar et al., 2016). In the extreme case, one can also consider purely cross-lingual classification, in which the classifier is trained solely on the source language, but tested on the target language. We use a supervised domain adaptation approach, similar to that of Daum´e III (2007), by considering each language to be a different domain. In related (though not multilingual) work, Masrani et al. (2017) also used this a"
N19-1367,J92-4003,0,0.248848,".0 (2.6) 28.6 (1.4) 33 22F/11M 79.2 (6.6) 11.3 (4.0) 18.9 (3.9) participants were asked to perform the CTP task in their respective languages. In English, the image was shown on paper and speech was digitally recorded, while in the French study, the image was displayed on a tablet and speech was recorded via the tablet microphone. Features Class-Based Language Modelling In contrast to the previous work on AD classification, we measure not only which information units are mentioned, but also the order in which they are mentioned. Our approach has some similarity to class-based language models (Brown et al., 1992), in which words are first grouped into classes (or clusters), and then the language model is trained on the classes rather than the individual words. One benefit to this approach is improved generalisability (Hoidekr et al., 2006), and another is the ability of classes to span different languages (T¨ackstr¨om et al., 2012). 3 AD Table 1: Demographics of participants, where AD indicates Alzheimer’s disease, and HC indicates healthy control. The Mini Mental State Examination (MMSE) is global measure of cognitive status. 3.2 2.4 French HC Methodology 3.1 Data Data were taken from two corpora: a"
N19-1367,hoidekr-etal-2006-benefit,0,0.127725,"Missing"
N19-1367,P07-1033,0,0.657228,"Missing"
N19-1367,W11-2123,0,0.0245669,"ch language), and used to translate the full narratives to sequences of information units. As an example, the English A boy is standing on a stool and French Le garc¸on est sur un tabouret would both be mapped to the sequence B OY S TOOL. Features relating to the occurrence of each distinct information unit comprise the info feature set, described in Table 2b. Additionally, new features are derived from language models build on the sequence of information units. To this end, concept-based language models are trained for English and French in a leave-one-out fashion, using the kenlm framework (Heafield, 2011). Models up to 5-grams were constructed. For each participant, two language models are constructed for each n: one trained on the healthy control (HC) population and one trained on the AD population. The participant is left out of the model built on their associated diagnostic group. The trained language models are then applied to the held-out participant’s sequence of information units and various language model (LM) features are extracted (Table 2c). 3661 Actions STEAL , FALL , WASH , OVERFLOW, GIRL’ S AC TION , WOMAN ’ S INDIFFERENCE Actors BOY, GIRL , CHILD ( REN ), WOMAN Places KITCHEN ,"
N19-1367,N19-1199,1,0.300126,"o improve the AUC on the French dataset from 0.85 to 0.89. We also developed a new set of features for this task, using concept-based language modelling, which improved AUC from 0.80 to 0.85 in the unilingual case, and 0.88 to 0.89 in the multilingual case. Future work will involve extending the set of features involved, incorporating data from other languages, and testing whether similar techniques can be effective for detecting earlier stages of cognitive decline, such as MCI. Other work from our group has also begun to explore the use of unsupervised methods and out-of-domain data sources (Li et al., 2019). Technical challenges aside, collaborations of this nature can be difficult due to the sensitive nature of the data, and the need to respect ethical guidelines and participant consent when sharing and storing data. With this in mind, we recommend to other researchers working in similar domains to consider from the outset whether their data could eventually be shared, and to make suitable provisions in their ethics protocols and participant consent forms. We look to DementiaBank as a model for this kind of data-sharing and openness, and hope that researchers can continue to find ways to share"
N19-1367,P10-1114,0,0.0314006,"wever, they did not consider multilingual classification directly. More generally, multilingual NLP is an active and growing area of research. Some approaches to improving classifier performance on a resourcepoor target language by leveraging a resource-rich source language include: translate the target language to the source language (or vice versa) and 3660 1 https://dementia.talkbank.org/ train a unilingual classifier (Wan, 2009); extract features from the two languages separately and then use domain adaptation techniques to train a classifier for the target language (Blitzer et al., 2006; Prettenhofer and Stein, 2010); or determine a common representation for both languages and then extract features from the combined corpus to train a multilingual classifier (Ammar et al., 2016). In the extreme case, one can also consider purely cross-lingual classification, in which the classifier is trained solely on the source language, but tested on the target language. We use a supervised domain adaptation approach, similar to that of Daum´e III (2007), by considering each language to be a different domain. In related (though not multilingual) work, Masrani et al. (2017) also used this approach to adapt a dataset of A"
N19-1367,J15-4001,0,0.0348046,"Missing"
N19-1367,W16-4211,0,0.144803,"g, perceptual speed and language (B¨ackman et al., 2005; Weiner et al., 2008). Machine learning experiments using speech and language for the detection of dementia or related disorders have been conducted in many languages, including English (Roark et al., 2011; Mirheidari et al., 2016; Fraser et al., 2016; Asgari et al., 2017), French (Tr¨oger et al., 2017; K¨onig et al., 2018), German (Weiner et al., 2016), Hungarian (Szatloczki et al., 2015; Vincze et al., 2016), Spanish (Meil´an et al., 2014), Greek (Satt et al., 2013), Swedish (Lundholm Fors et al., 2018; Fraser et al., 2018a), Japanese (Shibata et al., 2016), Portuguese (Alu´ısio et al., 2016), and Mandarin Chinese (Lai et al., 2009). Most studies acknowledge that small data sets are a limitation and describe the difficulties in gathering more data, including the challenges in patient recruitment, the expense of running clinically-based studies, and the manual effort required for transcription and annotation. Here, we consider whether it could be possible to increase the amount of available data by augmenting a corpus in one language with data from another language, and thus improve predictive per3659 Proceedings of NAACL-HLT 2019, pages 3659–367"
N19-1367,K17-1033,0,0.0912277,"e (Blitzer et al., 2006; Prettenhofer and Stein, 2010); or determine a common representation for both languages and then extract features from the combined corpus to train a multilingual classifier (Ammar et al., 2016). In the extreme case, one can also consider purely cross-lingual classification, in which the classifier is trained solely on the source language, but tested on the target language. We use a supervised domain adaptation approach, similar to that of Daum´e III (2007), by considering each language to be a different domain. In related (though not multilingual) work, Masrani et al. (2017) also used this approach to adapt a dataset of AD narratives to their MCI classification task. English N Gender Age Education MMSE (/30) HC AD 241 154F/87M 64.8 (7.7) 14.2 (2.6) 29.1 (1.1) 309 189F/120M 71.4 (8.4) 12.8 (3.0) 19.8 (5.7) 25 19F/6M 75.4 (7.0) 14.0 (2.6) 28.6 (1.4) 33 22F/11M 79.2 (6.6) 11.3 (4.0) 18.9 (3.9) participants were asked to perform the CTP task in their respective languages. In English, the image was shown on paper and speech was digitally recorded, while in the French study, the image was displayed on a tablet and speech was recorded via the tablet microphone. Features"
N19-1367,N12-1052,0,0.0878325,"Missing"
N19-1367,P16-2030,0,0.0605087,"Missing"
N19-1367,P09-1027,0,0.0384355,"I), and found that classification results could be improved in both English and Swedish by incorporating multilingual topic modelling into the feature extraction pipeline; however, they did not consider multilingual classification directly. More generally, multilingual NLP is an active and growing area of research. Some approaches to improving classifier performance on a resourcepoor target language by leveraging a resource-rich source language include: translate the target language to the source language (or vice versa) and 3660 1 https://dementia.talkbank.org/ train a unilingual classifier (Wan, 2009); extract features from the two languages separately and then use domain adaptation techniques to train a classifier for the target language (Blitzer et al., 2006; Prettenhofer and Stein, 2010); or determine a common representation for both languages and then extract features from the combined corpus to train a multilingual classifier (Ammar et al., 2016). In the extreme case, one can also consider purely cross-lingual classification, in which the classifier is trained solely on the source language, but tested on the target language. We use a supervised domain adaptation approach, similar to t"
N19-1367,P16-1221,1,0.810925,"formation units”, which have been widely used in subsequent research. 2.2 NLP for AD Classification Several recent studies have used NLP and machine learning to analyse speech samples from people with dementia and other cognitive disorders. Most relevant here, are those which focus on picture description tasks in English or French. DementiaBank1 is a large database of CTP narratives from AD patients and controls, containing primarily English data. A number of recent papers report classification results on this corpus (Prud’hommeaux and Roark, 2015; Fraser et al., 2016; Al-Hameed et al., 2016; Yancheva and Rudzicz, 2016; Sirts et al., 2017). Language analysis of English-language CTP data from other sources has also been used to differentiate between different underlying pathologies in AD (Rentoumi et al., 2014), and variants of frontotemporal lobar degeneration (Pakhomov et al., 2010). In French, picture description was one of multiple tasks used to elicit speech for the classification of participants with mild cognitive impairment and AD reported by K¨onig et al. (2015) and K¨onig et al. (2018), although only acoustic processing was used. 2.3 Multi- and Cross-Lingual NLP There has been very little prior wor"
S01-1022,kokkinakis-etal-2000-annotating,1,\N,Missing
samiotou-etal-2004-intelligent,P94-1051,0,\N,Missing
W01-1713,A00-1040,0,0.0702334,"Missing"
W01-1713,C92-2082,0,\N,Missing
W01-1713,E99-1035,1,\N,Missing
W07-0901,C02-1130,0,0.0290102,"em we use originates from the work conducted in the Nomen Nescio project; for details see Johannessen et al. (2005). In brief, the Swedish system is a multipurpose NER system, comprised by a number of modules applied in a pipeline fash-ion. Six major components can be distinguished, making a clear separation between lexical, gram-matical and processing resources. The six compo-nents are: • lists of multiword names, taken from various Internet sites or extracted from various corpora, running directly over the tokenised text being processed; • • • 4.1 erarchies for various tasks, both specific (Fleischman and Hovy, 2002) and generic (Sekine, 2004). Our current system implements a rather finegrained named entity taxonomy with 8 main named entitiy types as well as 57 subtypes. Details can be found in Johannessen et al., 2005, and Kokkinakis, 2004. The eight main categories are: • Person (PRS): people names (forenames, surnames), groups of people, animal/pet names, mythological, theonyms; a rule-based, shallow parsing component that uses finite-state grammars, one grammar for each type of entity recognized; a module that uses the annotations produced by the previous two components, which have a high rate in prec"
W07-0901,P06-1141,0,0.0134061,"d the obtained results. text word Dalarne Asptomten Härnevi* Sabbathsberg Wenern* # 6 1 1 1 7 Kaknäs Kallmar 1 1 gazeteer Dalarna --Arnevi Sabbatsberg Werner,Waern Vänern Valnäs,Ramnäs Kalmar LD 1 --2 1 2 2 2 1 ann. loc --prs loc prs loc loc loc ?? yes no yes no yes yes biguous words, and information for disambiguation is derived from the entire document. Similarly, label consistency, the preference of the same annotation for the same word sequence everywhere in a particular discourse, is a comparable approach for achieving qualitatively higher recall rates with minimal resource overhead (cf. Krishnan and Manning, 2006). Such an approach has been used, e.g., by Aramaki et al. (2006), for the identification of personal health information (age, id, date, phone, location and doctor´s and patient´s names). Table 1. LD between potential NEs and the gazeteers; ‘*’: both are locations;‘??’: correct annot.? 5 The Document Centered Approach There is a known tradeoff between rule-based and statistical systems. Handcrafted grammar-based systems typically obtain better results, but at the cost of considerable manual effort by domain experts. Statistical NER systems typically require a large amount of manually annotated"
W07-0901,sekine-nobata-2004-definition,0,0.0298924,"cted in the Nomen Nescio project; for details see Johannessen et al. (2005). In brief, the Swedish system is a multipurpose NER system, comprised by a number of modules applied in a pipeline fash-ion. Six major components can be distinguished, making a clear separation between lexical, gram-matical and processing resources. The six compo-nents are: • lists of multiword names, taken from various Internet sites or extracted from various corpora, running directly over the tokenised text being processed; • • • 4.1 erarchies for various tasks, both specific (Fleischman and Hovy, 2002) and generic (Sekine, 2004). Our current system implements a rather finegrained named entity taxonomy with 8 main named entitiy types as well as 57 subtypes. Details can be found in Johannessen et al., 2005, and Kokkinakis, 2004. The eight main categories are: • Person (PRS): people names (forenames, surnames), groups of people, animal/pet names, mythological, theonyms; a rule-based, shallow parsing component that uses finite-state grammars, one grammar for each type of entity recognized; a module that uses the annotations produced by the previous two components, which have a high rate in precision, in order to make dec"
W07-0901,W01-0716,0,0.0191305,"e subject (e.g. berätta ‘to tell’, fundera ‘to think’, tröttna ‘to become tired’). These are used in conjunction with orthographic markers in the text, such as capitalization, for the recognition of personal names. In this work, we consider the first group (designators) as relevant knowledge to be extracted from the person name recognizer, which is explored for the annotation of animate instances in the literary texts. The designators are implemented as a separate module in the current pipeline, and constitute a piece of information which is considered important for a wide range of tasks (cf. Orasan and Evans, 2001). The designators are divided into four groups: designators that denote the nationality or the ethnic/racial group of a person (e.g. tysken ‘the German [person]’); designators that denote a profession (e.g. läkaren ‘the doctor’); those that denote family ties and relationships (e.g. svärson ‘son in law’); and finally a group that indicates a human individual but cannot be unambiguously categorized into any of the three other groups (e.g. patienten ‘the patient’). Apart from this grouping, inherent qualities, for at least a large group of the designators, (internal evidence/morphological cues)"
W07-2452,E99-1001,0,0.0414154,"ssible errors and assign new annotations based on existing ones, e.g. by combining annotation fragments. In the current work, seven types of NEs are recognized3: persons, locations, organizations, names of drugs and diseases, time expressions and a set of different types of measure expressions such as “age” and “temperature” (Table 1). The annotation uses the XML identifiers ENAMEX, TIMEX and NUMEX; for details see Kokkinakis (2004). The lack of annotated data in the domain prohibits us from using, and thus training, a statistically 1 The module is inspired by the document centred approach by Mikheev et al. (1999). This is a form of on-line learning from documents under processing which looks at unambiguous usages for assigning annotations in ambiguous words. A similar method has been also used by Aramaki et al., 2006, called labelled consistency for de-identification of PHIs. 2 This module has not used in the current work, since we applied bulk annotation on a very large sample, while this module has best performance in single, coherent articles. 3 These name categories are a subset of the original system which also covers three more entities, namely artifacts, work&art and events (e.g. names of confe"
W07-2453,I05-5005,1,0.755467,"texts. 4 Discussion Target text analysis is the very first step in the design and development of Natural Language Generation systems. Moreover, several researchers have emphasised the fact that corpus analysis is instrumental in reducing the effort involved in constructing the complex knowledge bases 335 Dimitrios Kokkinakis, Maria Toporowska Gronostaj, Catalina Hallett and David Hardcastle generally required by NLG systems (Knight & Hatzivassiloglou 1995, Langkilde & Knight 1998, Pan & Shaw 2004). Since our intended target texts emulate the style and lexical content of the analysed corpora (Hallett & Scott, 2005), we are able to offer several recommendations and scoring mechanisms for bilingual English-Swedish NLG systems. More specifically, we are able to: • • 5 informing an NLG system with regard to the appropriate lexical choices and syntactic constructions assess whether an automatically generated text is appropriate as patient information material, by analysing its readability level, lexical composition and syntactic complexity and comparing with the reference lay corpus. Similarly, for NLG systems that generate multiple variants, our analysis can help score the alternatives in order to make the"
W07-2453,J07-1006,1,0.844331,"Missing"
W07-2453,P95-1034,0,0.0155504,"Missing"
W07-2453,P98-1116,0,0.0305285,"Missing"
W07-2453,C98-1112,0,\N,Missing
W09-4505,A00-1031,0,0.0422007,"hey are considered the most important and typical in a core terminology [20]. However hybrid approaches such as the C-value/NC-value try to combine linguistics (term candidates and term formation patterns), statistics (ranking based on term length, frequency of occurrence and frequency of nested terms) and contextual information (re-ranking term candidates based on co-occurrence with significant context words) in order to suggest multiword terms. We have applied the C-value method [15] on our corpus to extract multi-word terms. For the linguistic analysis we used the TnT part of speech tagger [21] trained on general Swedish corpora and enhanced with a few hundred new words which were problematic for the tagger. For instance, new words ending in -ns were annotated by default as genitives but in the corpus such words are rather nominatives, insufficiens (insufficiency) and prevalens (prevalence). Other words were exclusively found as adjectival modifiers in general corpora rather than nouns in the medical corpora. Alternative morphosyntactic descriptions were added for these forms in the lexicon, e.g. the homograph terminal (as noun – predominant in general corpora or as adjective – pred"
W09-4505,C04-1087,0,0.45289,"Missing"
W10-1108,gellerstam-etal-2000-bank,0,0.0957353,"Missing"
W10-1108,C04-1140,0,0.0241693,"et al., 2009.) 2.4 Related studies Since most of the available clinical documents are in free-text form, a number of stylistically oriented efforts to characterize the data from various angles have taken place. This may include various topics, from viewing detailed information about specific items (e.g. readability, Kim et al., 2007) to identifying patterns and structures in order to provide better technology to automatically process the sublanguage (Pakhomov et al., 2006). The majority of such efforts investigate different aspects of linguistic features at a monolingual level, for instance, Hahn & Wermter (2004); Tomanek et al., (2007); Chung (2009); Harkema et al., (2009); while for a thorough review of various related issues see Meystre et al., (2008). In the Nordic context, Josefsson (1999) discusses Swedish clinical language and shows examples on how verb constructions in a clinical setting differ from a non clinical setting. One claim is that the physician unmarks the verb forms for agentivity when writing about the patient and what actions she takes, for example, Patienten hallucinerar [The patient hallucinates] instead of the normal form Patienten får hallucinationer [The patient experiences h"
W10-1110,S07-1018,0,0.0587782,"Missing"
W10-1110,burchardt-etal-2006-salto,0,\N,Missing
W10-1110,brants-hansen-2002-developments,0,\N,Missing
W10-1110,W09-1401,0,\N,Missing
W11-4111,P10-1015,0,0.0436522,"Missing"
W11-4111,doddington-etal-2004-automatic,0,0.0545437,"a number of techniques that have applicability to any type of text; for a general review see Hachey (2009). Such techniques can facilitate more advanced research on literature and provide the appropriate mechanisms for generating multiple views on corpora and insights on people, places, and events in a large scale, through various types of relations. Relation extraction was introduced in the mid 1990s by the Template Element and Template Relation tasks in MUC-6 (Message Understanding Conferences) and followed by the ACE (Automatic Content Extraction) Relation Detection/Recognition tasks (cf. Doddington et al., 2004). Since then it has been an active and fruitful area of research, partly driven by the explosion of the available information via the Web and partly by the evidence that embedded relations are useful for various NLP tasks such as Q&A and Information Retrieval. Relation extraction approaches (particularly binary ones) can be classified in various ways. Knowledge engineering approaches (e.g., rulebased, linguistic based), learning approaches (e.g., statistical, machine learning, bootstrapping) and hybrid ones; for an overview of techniques see Jinxiu (2007). Learning approaches become more and m"
W11-4111,C02-1130,0,0.0430217,"Swesaurus in order to identify synonyms for some of these lexical units. This way we can increase the amount of the words that can be part of various relations types. Thus, for the word kollega ‘colleague’ we can get a set of acceptable near synonyms such as arbetskamrat ‘co-worker’ but unfortunately also a number of not so suitable near synonyms such as kompis ‘buddy’, therefore we had to manually go through such near synonym lists and discard erroneous entries. 3.2 Named Entities and Animacy There has been some work in the past on defining and applying rich name hierarchies, both specific (Fleischman & Hovy, 2002) and generic (Sekine, 2004) to various corpora. However, in other approaches (Kokkinakis, 2004) the wealth of name types is captured by implementing a fine-grained named entity taxonomy by keeping a small generic set of named entity types as main types and modeling the rest using a subtype mechanism. In this latter work a Person entity (a reference to a real word entity) is defined as proper nouns – personal names (forenames, surnames), animal/pet names, mythological names, names of Gods etc. – and common nouns and noun phrases denoting groups/sets of people. In this work the rule-based compon"
W11-4111,P04-1053,0,0.246633,"or Digital Humanities and Cultural Heritage Workshop, pages 70–77, Hissar, Bulgaria, 16 September 2011. and extracting facts for entities (e.g., individuals) can be easily exploited in various possible ways by NLP technologies such as summarization and question answering (e.g., Jing et al., 2007). 2 characters speak within 300 words each other, and finally, a social network is constructed from the conversations. Nodes are named speakers and edges appear if there was a conversation between two characters, a heavier edge means more conversations. Our approach is mainly influenced by the work by Hasegawa et al. (2004) who proposed an unsupervised, domain-neutral approach to relation extraction by clustering named entity pairs according to the similarity of context words intervening between two entities and selecting the most frequent words from the context to label the relation. Related Work Natural-language processing is an attractive approach to processing large text collections for relation extraction (usually defined as a relation predicate ranging over two arguments, e.g., concepts or people) and there exist a number of techniques that have applicability to any type of text; for a general review see H"
W11-4111,P07-1131,0,0.159317,"cognition tasks (cf. Doddington et al., 2004). Since then it has been an active and fruitful area of research, partly driven by the explosion of the available information via the Web and partly by the evidence that embedded relations are useful for various NLP tasks such as Q&A and Information Retrieval. Relation extraction approaches (particularly binary ones) can be classified in various ways. Knowledge engineering approaches (e.g., rulebased, linguistic based), learning approaches (e.g., statistical, machine learning, bootstrapping) and hybrid ones; for an overview of techniques see Jinxiu (2007). Learning approaches become more and more common in the open domain i.e. large corpora of web scale, cf. Agichtein & Gravano, (2000); Christensen et al. (2010); relations are also of particular interest and prominent in the (bio)medical domain; e.g. Rosario & Hearst (2004); Giles & Wren (2008); Roberts et al. (2008). Elson et al. (2010) describe a method to extract social networks from literature (nineteenth-century British novels and serials) depending on the ability to determine when two characters are in conversation. The authors use a named-entity tagger to automatically locate all the na"
W11-4111,W01-0716,0,0.0393975,"(a reference to a real word entity) is defined as proper nouns – personal names (forenames, surnames), animal/pet names, mythological names, names of Gods etc. – and common nouns and noun phrases denoting groups/sets of people. In this work the rule-based component for Person entity identification utilizes a large set of designator words (e.g., various types of nominal mentions) and phrases (e.g., typically verbal constructions) that require animate subjects, a relevant piece of knowledge which is explored for the annotation of animate instances in literary texts and other related tasks (cf. Orasan & Evans, 2001). These designators are divided into four groups according to their semantic denotation:  nationality or the ethnic/racial group of a person (e.g. tysken ‘the German [person]’)  profession (e.g. läkaren ‘the doctor’)  family ties and relationships (e.g. svärson ‘son in law’; moster ‘aunt [from the mother’s side]’)  individual that cannot be unambiguously categorized into any of the other three groups (e.g. patienten ‘the patient’) Animacy markers are further marked for gender (male, female or unknown/unresolved such as barn ‘child’). An example of animacy annotation is given below. In this"
W11-4111,W10-0907,0,0.0298041,"of the available information via the Web and partly by the evidence that embedded relations are useful for various NLP tasks such as Q&A and Information Retrieval. Relation extraction approaches (particularly binary ones) can be classified in various ways. Knowledge engineering approaches (e.g., rulebased, linguistic based), learning approaches (e.g., statistical, machine learning, bootstrapping) and hybrid ones; for an overview of techniques see Jinxiu (2007). Learning approaches become more and more common in the open domain i.e. large corpora of web scale, cf. Agichtein & Gravano, (2000); Christensen et al. (2010); relations are also of particular interest and prominent in the (bio)medical domain; e.g. Rosario & Hearst (2004); Giles & Wren (2008); Roberts et al. (2008). Elson et al. (2010) describe a method to extract social networks from literature (nineteenth-century British novels and serials) depending on the ability to determine when two characters are in conversation. The authors use a named-entity tagger to automatically locate all the names in a novel and then a classifier that automatically assigns a speaker to every instance of direct speech in the novel using features of the surrounding text"
W11-4111,W08-0602,0,0.0201502,"l. Relation extraction approaches (particularly binary ones) can be classified in various ways. Knowledge engineering approaches (e.g., rulebased, linguistic based), learning approaches (e.g., statistical, machine learning, bootstrapping) and hybrid ones; for an overview of techniques see Jinxiu (2007). Learning approaches become more and more common in the open domain i.e. large corpora of web scale, cf. Agichtein & Gravano, (2000); Christensen et al. (2010); relations are also of particular interest and prominent in the (bio)medical domain; e.g. Rosario & Hearst (2004); Giles & Wren (2008); Roberts et al. (2008). Elson et al. (2010) describe a method to extract social networks from literature (nineteenth-century British novels and serials) depending on the ability to determine when two characters are in conversation. The authors use a named-entity tagger to automatically locate all the names in a novel and then a classifier that automatically assigns a speaker to every instance of direct speech in the novel using features of the surrounding text. A “conversation” occurs if two 3 Material: a Prose Fiction Corpus Prose fiction is a just one type of textual material that has been brought into the electr"
W11-4111,P04-1055,0,0.0390841,"NLP tasks such as Q&A and Information Retrieval. Relation extraction approaches (particularly binary ones) can be classified in various ways. Knowledge engineering approaches (e.g., rulebased, linguistic based), learning approaches (e.g., statistical, machine learning, bootstrapping) and hybrid ones; for an overview of techniques see Jinxiu (2007). Learning approaches become more and more common in the open domain i.e. large corpora of web scale, cf. Agichtein & Gravano, (2000); Christensen et al. (2010); relations are also of particular interest and prominent in the (bio)medical domain; e.g. Rosario & Hearst (2004); Giles & Wren (2008); Roberts et al. (2008). Elson et al. (2010) describe a method to extract social networks from literature (nineteenth-century British novels and serials) depending on the ability to determine when two characters are in conversation. The authors use a named-entity tagger to automatically locate all the names in a novel and then a classifier that automatically assigns a speaker to every instance of direct speech in the novel using features of the surrounding text. A “conversation” occurs if two 3 Material: a Prose Fiction Corpus Prose fiction is a just one type of textual ma"
W11-4111,sekine-nobata-2004-definition,0,0.0353229,"ms for some of these lexical units. This way we can increase the amount of the words that can be part of various relations types. Thus, for the word kollega ‘colleague’ we can get a set of acceptable near synonyms such as arbetskamrat ‘co-worker’ but unfortunately also a number of not so suitable near synonyms such as kompis ‘buddy’, therefore we had to manually go through such near synonym lists and discard erroneous entries. 3.2 Named Entities and Animacy There has been some work in the past on defining and applying rich name hierarchies, both specific (Fleischman & Hovy, 2002) and generic (Sekine, 2004) to various corpora. However, in other approaches (Kokkinakis, 2004) the wealth of name types is captured by implementing a fine-grained named entity taxonomy by keeping a small generic set of named entity types as main types and modeling the rest using a subtype mechanism. In this latter work a Person entity (a reference to a real word entity) is defined as proper nouns – personal names (forenames, surnames), animal/pet names, mythological names, names of Gods etc. – and common nouns and noun phrases denoting groups/sets of people. In this work the rule-based component for Person entity ident"
W11-4206,E99-1035,1,0.783088,"Missing"
W11-4206,kokkinakis-gerdin-2010-swedish,1,0.897582,"Missing"
W11-4206,I05-1006,0,0.0312798,"e can be gained by applying and improving on a number of pre-parsing stages. The idea is that various morphosyntactic and semantic representation layers can pave the way of substantial text complexity reduction as long as the parser can be made aware of these layers. Therefore, by putting effort on various levels of representation (pre-processing) we can hypothesize, and actually show, that performance can be improved. Thus, we help the parser in such a way that it can avoid some hard decisions, e.g. bracketing and structural ambiguities. We follow, and to a certain degree, extend the idea of Lease & Charniak (2005) discussed earlier. Our strategy is primarily based on four (domain) adaptations: 2 37 Nivre & Nilsson (2004) have showed that significant improvement in parsing accuracy for Swedish could be achieved if multiword function words are taken under consideration. words) while the parsing of this segment (in a simplified form) becomes np: <en latent diabetes&gt; np: <mellitus&gt;, that is two separate noun phrases. However, if we apply terminology recognition and then combine (in some suitable way) that information with the part-of-speech (e.g., by adding a feature to the part-of-speech) then we end with"
W11-4206,A00-1031,0,0.00591283,"vocabulary at the lexical resources we use) the rest are domain-independent adaptations. 3.3 Adaptations deal with the resolvement of at least some of the possible types of problems that can arise during parsing. For instance, we manage to dramatically increase the lexical coverage by efficiently dealing with unknown words, e.g., genre specific vocabulary. The majority of unknown words can be captured by the use of domain terminologies. A number of individual terms from such terminologies have been incorporated into the part-of-speech tagger&apos;s lexicon, for that purpose we use the TnT tagger (Brants, 2000). Similarly, for various types of multiword tokens, we have manually added a large number of common multiword function words (e.g., adverbs, preposition, determiners) in the part-ofspeech tagger&apos;s lexicon2. While for the majority of other types of multiword expressions (i.e., terms and named entities) which are identified during terminology and named entity recognition, possibly erroneous part-of-speech annotation does not have impact during parsing. For instance the part-of-speech annotation of the segment: en latent diabetes mellitus &apos;a latent diabetes mellitus&apos; becomes: en/DI@US@S latent/AQ"
W11-4206,W11-0804,0,0.0408177,"Missing"
W11-4206,I05-2038,0,\N,Missing
W11-4206,rinaldi-etal-2008-dependency,0,\N,Missing
W13-0403,E06-1042,0,0.0675861,"storms as natural phenomena and then those where the word is used in a non-literal sense. Other work is specifically geared towards metaphor recognition [14]. For instance, two kinds of metaphorical language is distinguished, ”conventional metaphors”, mostly idiomatic expressions, that become a part of an ordinary discourse, and ”creative metaphors”, which are distinctly novel or ad hoc uses of language, since neither the creator nor the audience has encountered the metaphor before. Creative metaphors are frequently used in conversation to describe an emotional experience [5]. Birke & Sarkar [2] presented a system for automatically classifying literal and non literal usages of phrasal and expression verbs, for example ”throw away”, through nearly unsupervised word-sense disambiguation and various clustering techniques based on models build on hand-annotated data. Finally, figurative usage seems to be an important research topic in the medical domain and there is some evidence that supports this claim. For example, it has been shown that figurative language has an active role in the narratives of patients with cancer. Such non-literal usage, e.g. metaphors, can bridge the gap between"
W13-0403,W07-1106,0,0.0439622,"guage is present in the health records. Does it depend on lack of understanding from the coders side (usually a contact nurse); is it simply a convenient way to describe symptoms and states; is there lack of appropriate nomenclature? Moreover, an idiom type often has a literal interpretation as well. Therefore, the exploration of e.g. use of informative prior knowledge about the overall syntactic behavior of potentially-idiomatic expressions to determine whether an instance of the expression is used idiomatically or not, is of great importance for many (semantically oriented) NLP applications [6], an issue that requires more studies, particularly in critical domains where the distinction can have severe consequences. Moreover, the identification of figurative expressions, which describe physical or emotional symptoms, is a very useful supporting component, since these important expressions can be then automatically linked to existing medical ontologies and enhance e.g., decision support or other systems. Currently, the experimentation is based on limited amount of data, therefore it is difficult to draw clear conclusions as to the magnitude of the impact the ability to identify idioma"
W13-0403,E06-1043,0,0.0738295,"such as ”than”. A simile differs from a metaphor in that the latter compares two unlike things by saying that the one thing is the other thing. Similes can be negative, too, asserting that two things are unlike in one or more respects. Finally, previous work has shown that common figures of speech, such as idioms and metaphors, also involve some degree of lexical and syntactic variability, in the sense that, for instance, some allow pluralization while some not. 3 Previous Research Some of the work that has been conducted from a strong corpus based and/or NLP perspective includes the work by [8] who focus on a particular class of English idiomatic expression, i.e., those that involve the combination of a verb plus a noun in its direct object position. Fazly & Stevenson [8] investigated a lexicon-based method were a lexical and syntactic flexibility (e.g., verbal inflection; pluralization; internal modification; use of determiner types; passivization) was allowed in a restrictive form. Among the idioms examined, some exhibited limited morphosyntactic flexibility, while others were more syntactically flexible. For instance, the idiom ”shoot the breeze” can undergo verbal inflection, i."
W13-0403,P10-1071,0,0.0418916,"non-literal usage, e.g. metaphors, can bridge the gap between the cancer experience and the world of technology and treatment, helping patients to symbolically control their illness [13] while other studies have looked at how non-literal language shifts throughout a person’s recovery period [3]. We believe that detection of figurative language can play an important role both for the deep understanding of the discourse and communication interplay, and particularly, also for the part of NLP that involves automatic text understanding, where figurative language is considered a serious bottleneck [16]. 4 Experimental Setting This study is part of an ongoing larger project which investigates how complex, vague and long-standing symptoms with no identified organic cause are put into context, interpreted and acted upon in primary health-care interactions. It is based on studying interactions between patients and nurses giving advice over telephone, consultations between patients and physicians, interviews and study patients’ medical records and case notes. Eighteen eligible patients who have contacted their primary health care centre by telephone, have had at least eight physical consultation"
W13-0403,shutova-teufel-2010-metaphor,0,0.0637615,"clinical language processing needs to account for figurative language usage, and this paper provides a description, and preliminary results towards this goal. Since the empirical, clinical data used in the study is limited in size, there is no formal distinction made between different sub-classifications of figurative language. e.g., metaphors, idioms or simile. As a matter of fact, all these types of expressions form a continuum with fuzzy boundaries [9], and most of the NLP-oriented approaches discussed in the past have used either very large data for the analysis or hand annotates samples [17], a situation that has been prohibitive so far in our project. Therefore distinction is solely based on a more general level, namely between literal versus figurative language, and on a more quantitative and corpus-based level, supported with concrete examples that illustrate several types of figurative expressions in the clinical discourse. The main research questions that this paper asks are whether there are traces of figurative language (or at least a subset of such types) in patient-doctor and patient-nurse interactions, how can they be found in a convenient way and whether these are tran"
W14-1102,W11-1103,0,0.0206927,"f medical websites can give us insight into the language being used and the information needs of the users in the medical domain. 2 Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi) @ EACL 2014, pages 2–10, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics tor space models were compared, by embedding them in graphs, and graph random walk models in order to determine similarity between concepts, and showed that some random walk models can achieve results as good as or even better than the vector models. In (Gaillard and Gaume, 2011), it was shown that drawing clusters of synonyms in which pairs of nodes have a strong confluence is a strong indication of aiding two synonymy graphs accommodate each others’ conflicting edges. Their work was a step for defining a similarity measure between graphs that is not based on edge-to-edge disagreement but rather on structural agreement. bels are used to create a semantic community. We have compared the obtained semantic communities with the graph communities using a wellknown similarity measure and observed that the communities identified from these two different approaches overlap."
W15-0710,W14-0902,0,0.0373848,"Missing"
W15-0710,P09-1080,0,0.0186664,"ons (Pennacchiotti & Zanzotto, 2008; Mueller, 2009; Manning, 2011; Piotrowski, 2012; Jockers, 2013; McEnery & Baker, 2014). The focus of such research is to reduce the time consuming, manual work that is often carried out e.g. by historians or other literature scholars, in order to identify valid, useful and meaningful results such as semantic associations, gender patterns and features of human networks (Agarwal et al., 2012). Also, recently, a small number of studies have been published where gender and other biographical characteristics are explored (Hota et al., 2006; Argamon et al., 2007; Garera & Yarowsky, 2009; Bullard & Oveesdotter Alm, 2014). These methods apply various types of classifiers with good performance results. Boes (2014) discusses the content of the “Vocations of the Novel Project” which consists of a database of roughly 13,000 German-language prose works, published between 1750-1950, and in which each entry in this database is tagged with vocational metadata identifying occupations that receive extended narrative treatment. Fifteen occupational clusters, such as agricultural professions, health and nautical professions, are used for estimating the proportional distribution of those w"
W15-0710,W12-1010,0,\N,Missing
W15-0710,W11-1512,0,\N,Missing
W15-0710,N13-1090,0,\N,Missing
W15-0710,W12-2513,0,\N,Missing
W15-0710,P05-1045,0,\N,Missing
W16-6104,W14-3210,0,0.0253212,"apidly2. Automatic spoken language analysis and eye movement measurements are two of the newer complementary diagnostic tool with great potential for dementia diagnostics (Laske et al., 2014). Furthermore, the identification of important linguistic and extra-linguistic features such as lexical and syntactic complexity, are becoming an established way to train and test machine learning classifiers that can be used to differentiate between subjects with various forms of dementia and healthy controls or between different types of dementia subjects (Lagun et al., 2011; Roark et al., 2011; Olubolu Orimaye et al., 2014; Rentoumi et al., 2014). Although language is not the only diagnostic factor for cognitive impairment, several recent studies (Yancheva et al., 2015) have demonstrated that automatic linguistic analysis, primarily of speech samples, produced by people with mild or moderate cognitive impairment compared to healthy individuals can identify objective evidence and measurable (progressive) language disorders. Garrard & Elvevåg (2014) comment that computer-assisted analysis of large language datasets could contribute to the understanding of brain disorders. Although, none of the studies presented i"
W16-6104,W15-5123,0,0.0225747,"r dementia diagnostics (Laske et al., 2014). Furthermore, the identification of important linguistic and extra-linguistic features such as lexical and syntactic complexity, are becoming an established way to train and test machine learning classifiers that can be used to differentiate between subjects with various forms of dementia and healthy controls or between different types of dementia subjects (Lagun et al., 2011; Roark et al., 2011; Olubolu Orimaye et al., 2014; Rentoumi et al., 2014). Although language is not the only diagnostic factor for cognitive impairment, several recent studies (Yancheva et al., 2015) have demonstrated that automatic linguistic analysis, primarily of speech samples, produced by people with mild or moderate cognitive impairment compared to healthy individuals can identify objective evidence and measurable (progressive) language disorders. Garrard & Elvevåg (2014) comment that computer-assisted analysis of large language datasets could contribute to the understanding of brain disorders. Although, none of the studies presented in the special issue of Cortex vol. 55 moved “beyond the representation of language as text” and therefore finding reliable ways of incorporating featu"
W17-0220,W13-5639,0,0.0589816,"Missing"
W17-0220,W09-3834,0,0.0111251,"e also envisaged. Two wide-coverage parser systems will be used for parsing the speech transcripts. The Malt parser for Swedish (Nivre et al., 2006), that outputs grammatical dependency relations, and a constituent parser for the same language (Kokkinakis, 2001) that utilises a semiautomatically developed grammar. Although the transcribed corpus is describing spoken language and contains various spoken language phenomena, such as filled pauses, we chose to keep the verbatim transcriptions intact. Such phenomena are usually deleted prior to parsing for better performance (Lease & Johnson 2006; Geertzen, 2009). Moreover, since we apply a 2tier text grid configuration during the transcription, we can easily experiment with both 178 the orthographic transcription spelling) and the verbatim one. 5.4 (standardized Eye-tracking analysis Eye tracking data has been used in machine learning methods in the near past. By taking advantage of biomarkers extracted from eye dynamics (Lagun et al; 2011) there is an indication that these could aid the automatic detection of cognitive impairment (i.e., distinguish healthy controls from MCI-patients). Several studies provide evidence and suggest that eye movements c"
W17-0220,W14-3210,0,0.0247178,"en language analysis and eye movement measurements are two of the newer complementary diagnostic tools with great potential for dementia diagnostics (Laske et al., 2014). Furthermore, the identification of important linguistic and extra-linguistic features such as lexical and syntactic complexity, are becoming an established way to train and test supervised machine learning classifiers that can be used to differentiate between individuals with various forms of dementia and healthy controls or between individuals with different types of dementia (Lagun et al., 2011; Roark et al., 2011; Olubolu Orimaye et al., 2014; Rentoumi et al., 2014). Although language is not the only diagnostic factor for cognitive impairment, several recent studies (Yancheva et al., 2015) have demonstrated that automatic linguistic analysis, primarily of connected speech samples, produced by people with mild or moderate cognitive impairment compared to healthy individuals can identify with good accuracy objective evidence and measurable (progressive) language disorders. Garrard & Elvevåg (2014) comment that computer-assisted analysis of large language datasets could contribute to the understanding of brain disorders. Although, no"
W17-0220,N06-2019,0,0.0110903,"ranscribed language are also envisaged. Two wide-coverage parser systems will be used for parsing the speech transcripts. The Malt parser for Swedish (Nivre et al., 2006), that outputs grammatical dependency relations, and a constituent parser for the same language (Kokkinakis, 2001) that utilises a semiautomatically developed grammar. Although the transcribed corpus is describing spoken language and contains various spoken language phenomena, such as filled pauses, we chose to keep the verbatim transcriptions intact. Such phenomena are usually deleted prior to parsing for better performance (Lease & Johnson 2006; Geertzen, 2009). Moreover, since we apply a 2tier text grid configuration during the transcription, we can easily experiment with both 178 the orthographic transcription spelling) and the verbatim one. 5.4 (standardized Eye-tracking analysis Eye tracking data has been used in machine learning methods in the near past. By taking advantage of biomarkers extracted from eye dynamics (Lagun et al; 2011) there is an indication that these could aid the automatic detection of cognitive impairment (i.e., distinguish healthy controls from MCI-patients). Several studies provide evidence and suggest tha"
W17-0220,williams-etal-2010-cambridge,0,0.0224548,"Missing"
W17-0220,W15-5123,0,0.0140705,"(Laske et al., 2014). Furthermore, the identification of important linguistic and extra-linguistic features such as lexical and syntactic complexity, are becoming an established way to train and test supervised machine learning classifiers that can be used to differentiate between individuals with various forms of dementia and healthy controls or between individuals with different types of dementia (Lagun et al., 2011; Roark et al., 2011; Olubolu Orimaye et al., 2014; Rentoumi et al., 2014). Although language is not the only diagnostic factor for cognitive impairment, several recent studies (Yancheva et al., 2015) have demonstrated that automatic linguistic analysis, primarily of connected speech samples, produced by people with mild or moderate cognitive impairment compared to healthy individuals can identify with good accuracy objective evidence and measurable (progressive) language disorders. Garrard & Elvevåg (2014) comment that computer-assisted analysis of large language datasets could contribute to the understanding of brain disorders. Although, none of the studies presented in the special issue of Cortex vol. 55 moved “beyond the representation of language as text” and therefore finding reliabl"
W19-3012,borin-etal-2012-korp,0,0.011264,"de a renewed GDS (Global Deterioration Scale) classification and neuropsychological tests. The study was approved by local ethical committee (ref. number: 206-16, 2016 and T021-18, 2018). 3.2 3.3.2 To explore different cognitive processes engaged over the course of the one minute task, SVF performance is examined in 10 second steps. Words in the transcript were assigned to a temporal interval based on their onset. Word count is determined for each interval, disregarding repetitions from earlier intervals. Lexical frequency of words were determined using the KORP collection of Swedish corpora (Borin et al., 2012). Transition times between consecutive words were defined as the difference between the end of the current word and the onset of the next. Word frequency and transition times are reported as the average over each interval. Clinical Assessments Participants in the Gothenburg MCI study were classified as having SCI, MCI, or dementia, and the controls were recruited separately and evaluated to ascertain that they were cognitively healthy. The classification is based on the Global Deterioration Scale (GDS), where level 1 codes for cognitively healthy, level 2 SCI, level 3 MCI and level 4 and above"
W19-3012,W17-0220,1,0.72325,"). This reduction across strategy generalises to persons with aMCI producing significantly less categorical words (Price et al., 2012; Mueller et al., 2015). Nikolai et al. (2018) found categorical differences between naming animals and vegeta3 3.1 Methods Recruitment and Data Acquisition All the participants in the current study on ”Linguistic and extra-linguistic parameters for early detection of cognitive impairment” were recruited from the Gothenburg MCI study (Wallin et al., 2016). All participants were speakers of Swedish, selected according to detailed inclusion and exclusion criteria (Kokkinakis et al., 2017). Data collection took place in a quiet lab environment where participants were fitted with a lapel microphone (AudioTechnica ATR3350) and digitally recorded 104 animals. Clusters and switches were determined based on a temporal metric proposed by Troeger et al. (2019). In this approach, the cluster structure is solely determined by the temporal position of words in the recording. Consecutive words are clustered if the transition time between them is shorter than then average transition time over the sample. This threshold is furthermore scaled over the process of the task to account for the d"
W19-3012,W17-6926,1,0.779422,"ors2 , Hali Lindsay1 , Marie Eckerstr¨ om2 , Jan Alexandersson1 , Dimitrios Kokkinakis2 1 German Research Center for Artificial Intelligence (DFKI), Saarbr¨ ucken, Germany 2 University of Gothenburg, Gothenburg, Sweden nicklas.linz@dfki.de, kristina.lundholmfors@gu.se, hali.lindsay@dfki.de marie.eckerstrom@neuro.gu.se, jan.alexandersson@dfki.de, dimitrios.kokkinakis@gu.se Abstract power of semantic verbal fluency for dementia due to Alzheimers Disease (AD) and its precursor Mild Cognitive Impairment (MCI) (Henry et al., 2004; Auriacombe et al., 2006; Gomez and White, 2006; Raoux et al., 2008; Linz et al., 2017). As there is currently no cure for AD, preventive medication labeled to delay the onset or worsening of symptoms is the primary course of action, with an emphasis on early intervention being a beneficial factor for effective treatment. Early identification of subtle symptoms is also valuable for drug trial screening programs and supports early behavioral interventions that can delay the onset of the disease (Ashford et al., 2007; Zucchella et al., 2018). SVF has been used to identify the early stages of dementia through traditional crude measures, such as the total number of unique words prod"
