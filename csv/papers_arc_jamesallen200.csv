2020.lrec-1.396,A Broad-Coverage Deep Semantic Lexicon for Verbs,2020,-1,-1,1,1,17476,james allen,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Progress on deep language understanding is inhibited by the lack of a broad coverage lexicon that connects linguistic behavior to ontological concepts and axioms. We have developed COLLIE-V, a deep lexical resource for verbs, with the coverage of WordNet and syntactic and semantic details that meet or exceed existing resources. Bootstrapping from a hand-built lexicon and ontology, new ontological concepts and lexical entries, together with semantic role preferences and entailment axioms, are automatically derived by combining multiple constraints from parsing dictionary definitions and examples. We evaluated the accuracy of the technique along a number of different dimensions and were able to obtain high accuracy in deriving new concepts and lexical entries. COLLIE-V is publicly available."
W18-5010,A Situated Dialogue System for Learning Structural Concepts in Blocks World,2018,0,1,2,1,28042,ian perera,Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"We present a modular, end-to-end dialogue system for a situated agent to address a multimodal, natural language dialogue task in which the agent learns complex representations of block structure classes through assertions, demonstrations, and questioning. The concept to learn is provided to the user through a set of positive and negative visual examples, from which the user determines the underlying constraints to be provided to the system in natural language. The system in turn asks questions about demonstrated examples and simulates new examples to check its knowledge and verify the user{'}s description is complete. We find that this task is non-trivial for users and generates natural language that is varied yet understood by our deep language understanding architecture."
W18-5048,{C}ogent: A Generic Dialogue System Shell Based on a Collaborative Problem Solving Model,2018,0,3,3,0,28043,lucian galescu,Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"The bulk of current research in dialogue systems is focused on fairly simple task models, primarily state-based. Progress on developing dialogue systems for more complex tasks has been limited by the lack generic toolkits to build from. In this paper we report on our development from the ground up of a new dialogue model based on collaborative problem solving. We implemented the model in a dialogue system shell (Cogent) that al-lows developers to plug in problem-solving agents to create dialogue systems in new domains. The Cogent shell has now been used by several independent teams of researchers to develop dialogue systems in different domains, with varied lexicons and interaction style, each with their own problem-solving back-end. We believe this to be the first practical demonstration of the feasibility of a CPS-based dialogue system shell."
W18-1402,Building and Learning Structures in a Situated Blocks World Through Deep Language Understanding,2018,0,3,2,1,28042,ian perera,Proceedings of the First International Workshop on Spatial Language Understanding,0,"We demonstrate a system for understanding natural language utterances for structure description and placement in a situated blocks world context. By relying on a rich, domain-specific adaptation of a generic ontology and a logical form structure produced by a semantic parser, we obviate the need for an intermediate, domain-specific representation and can produce a reasoner that grounds and reasons over concepts and constraints with real-valued data. This linguistic base enables more flexibility in interpreting natural language expressions invoking intrinsic concepts and features of structures and space. We demonstrate some of the capabilities of a system grounded in deep language understanding and present initial results in a structure learning task."
S18-2028,Putting Semantics into Semantic Roles,2018,0,1,1,1,17476,james allen,Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics,0,"While there have been many proposals for theories of semantic roles over the years, these models are mostly justified by intuition and the only evaluation methods have been inter-annotator agreement. We explore three different ideas for providing more rigorous theories of semantic roles. These ideas give rise to more objective criteria for designing role sets, and lend themselves to some experimental evaluation. We illustrate the discussion by examining the semantic roles in TRIPS."
P18-2119,Tackling the Story Ending Biases in The Story Cloze Test,2018,0,7,2,0,29074,rishi sharma,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"The Story Cloze Test (SCT) is a recent framework for evaluating story comprehension and script learning. There have been a variety of models tackling the SCT so far. Although the original goal behind the SCT was to require systems to perform deep language understanding and commonsense reasoning for successful narrative understanding, some recent models could perform significantly better than the initial baselines by leveraging human-authorship biases discovered in the SCT dataset. In order to shed some light on this issue, we have performed various data analysis and analyzed a variety of top performing models presented for this task. Given the statistics we have aggregated, we have designed a new crowdsourcing scheme that creates a new SCT dataset, which overcomes some of the biases. We benchmark a few models on the new dataset and show that the top-performing model on the original SCT dataset fails to keep up its performance. Our findings further signify the importance of benchmarking NLP systems on various evolving test sets."
J18-1003,A Notion of Semantic Coherence for Underspecified Semantic Representation,2018,-1,-1,3,1,30397,mehdi manshadi,Computational Linguistics,0,"The general problem of finding satisfying solutions to constraint-based underspecified representations of quantifier scope is NP-complete. Existing frameworks, including Dominance Graphs, Minimal Recursion Semantics, and Hole Semantics, have struggled to balance expressivity and tractability in order to cover real natural language sentences with efficient algorithms. We address this trade-off with a general principle of coherence, which requires that every variable introduced in the domain of discourse must contribute to the overall semantics of the sentence. We show that every underspecified representation meeting this criterion can be efficiently processed, and that our set of representations subsumes all previously identified tractable sets."
W17-1719,Compositionality in Verb-Particle Constructions,2017,22,0,3,0,11651,archna bhatia,Proceedings of the 13th Workshop on Multiword Expressions ({MWE} 2017),0,"We are developing a broad-coverage deep semantic lexicon for a system that parses sentences into a logical form expressed in a rich ontology that supports reasoning. In this paper we look at verb-particle constructions (VPCs), and the extent to which they can be treated compositionally vs idiomatically. First we distinguish between the different types of VPCs based on their compositionality and then present a set of heuristics for classifying specific instances as compositional or not. We then identify a small set of general sense classes for particles when used compositionally and discuss the resulting lexical representations that are being added to the lexicon. By treating VPCs as compositional whenever possible, we attain broad coverage in a compact way, and also enable interpretations of novel VPC usages not explicitly present in the lexicon."
W17-0906,{LSDS}em 2017 Shared Task: The Story Cloze Test,2017,0,32,5,1,20402,nasrin mostafazadeh,"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics",0,"The LSDSem{'}17 shared task is the Story Cloze Test, a new evaluation for story understanding and script learning. This test provides a system with a four-sentence story and two possible endings, and the system must choose the correct ending to the story. Successful narrative understanding (getting closer to human performance of 100{\%}) requires systems to link various levels of semantics to commonsense knowledge. A total of eight systems participated in the shared task, with a variety of approaches including."
P17-1084,Apples to Apples: Learning Semantics of Common Entities Through a Novel Comprehension Task,2017,21,1,2,1,29075,omid bakhshandeh,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Understanding common entities and their attributes is a primary requirement for any system that comprehends natural language. In order to enable learning about common entities, we introduce a novel machine comprehension task, GuessTwo: given a short paragraph comparing different aspects of two real-world semantically-similar entities, a system should guess what those entities are. Accomplishing this task requires deep language understanding which enables inference, connecting each comparison paragraph to different levels of knowledge about world entities and their attributes. So far we have crowdsourced a dataset of more than 14K comparison paragraphs comparing entities from a variety of categories such as fruits and animals. We have designed two schemes for evaluation: open-ended, and binary-choice prediction. For benchmarking further progress in the task, we have collected a set of paragraphs as the test set on which human can accomplish the task with an accuracy of 94.2{\%} on open-ended prediction. We have implemented various models for tackling the task, ranging from semantic-driven to neural models. The semantic-driven approach outperforms the neural models, however, the results indicate that the task is very challenging across the models."
W16-6006,Towards Broad-coverage Meaning Representation: The Case of Comparison Structures,2016,0,0,2,1,29075,omid bakhshandeh,Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods,0,None
W16-2505,Story Cloze Evaluator: Vector Space Representation Evaluation by Predicting What Happens Next,2016,12,14,5,1,20402,nasrin mostafazadeh,Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for {NLP},0,"The main intrinsic evaluation for vector space representation has been focused on textual similarity, where the task is to predict how semantically similar two words or sentences are. We propose a novel framework, Story Cloze Evaluator, for evaluating vector representations which goes beyond textual similarity and captures the notion of predicting what should happen next given a context. This evaluation methodology is simple to run, scalable, reproducible by the community, non-subjective, 100% agreeable by human, and challenging to the state-of-theart models, which makes it a promising new framework for further investment of the representation learning community."
W16-1007,{C}a{T}e{RS}: Causal and Temporal Relation Scheme for Semantic Annotation of Event Structures,2016,36,23,4,1,20402,nasrin mostafazadeh,Proceedings of the Fourth Workshop on Events,0,"Learning commonsense causal and temporal relation between events is one of the major steps towards deeper language understanding. This is even more crucial for understanding stories and script learning. A prerequisite for learning scripts is a semantic framework which enables capturing rich event structures. In this paper we introduce a novel semantic annotation framework, called Causal and Temporal Relation Scheme (CaTeRS), which is unique in simultaneously capturing a comprehensive set of temporal and causal relations between events. By annotating a total of 1,600 sentences in the context of 320 five-sentence short stories sampled from ROCStories corpus, we demonstrate that these stories are indeed full of causal and temporal relations. Furthermore, we show that the CaTeRS annotation scheme enables high inter-annotator agreement for broad-coverage event entity annotation and moderate agreement on semantic link annotation."
N16-1098,A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories,2016,27,106,8,1,20402,nasrin mostafazadeh,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
K16-1007,Learning to Jointly Predict Ellipsis and Comparison Structures,2016,22,0,3,1,29075,omid bakhshandeh,Proceedings of The 20th {SIGNLL} Conference on Computational Natural Language Learning,0,None
W15-3801,Complex Event Extraction using {DRUM},2015,-1,-1,1,1,17476,james allen,Proceedings of {B}io{NLP} 15,0,None
W15-0103,From Adjective Glosses to Attribute Concepts: Learning Different Aspects That an Adjective Can Describe,2015,22,8,2,1,29075,omid bakhshandeh,Proceedings of the 11th International Conference on Computational Semantics,0,"Adjectives are one of the major contributors to conveying subjective meaning to sentences. Understanding the semantics of adjectives is essential for understanding natural language sentences. In this paper we propose a novel approach for learning different properties that an adjective can describe, corresponding to the xe2x80x98attribute conceptsxe2x80x99, which is not currently available in existing linguistic resources. We accomplish this by reading adjective glosses and bootstrapping attribute concepts from a seed of adjectives. We show that we can learn new attribute concepts using adjective glosses of WordNet adjectives with high accuracy as compared with human annotation on a test set."
S15-2134,{S}em{E}val-2015 Task 5: {QA} {T}emp{E}val - Evaluating Temporal Information Understanding with Question Answering,2015,10,22,5,0.75,37290,hector llorens,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"QA TempEval shifts the goal of previous TempEvals away from an intrinsic evaluation methodology toward a more extrinsic goal of question answering. This evaluation requires systems to capture temporal information relevant to perform an end-user task, as opposed to corpus-based evaluation where all temporal information is equally important. Evaluation results show that the best automated TimeML annotations reach over 30% recall on questions with xe2x80x98yesxe2x80x99 answer and about 50% on easier questions with xe2x80x98noxe2x80x99 answers. Features that helped achieve better results are event coreference and a time expression reasoner."
K15-1023,"Quantity, Contrast, and Convention in Cross-Situated Language Comprehension",2015,29,2,2,1,28042,ian perera,Proceedings of the Nineteenth Conference on Computational Natural Language Learning,0,"Typically, visually-grounded language learning systems only accept feature data about objects in the environment that are explicitly mentioned, whether through annotation labels or direct reference through natural language. We show that when objects are described ambiguously using natural language, a system can use a combination of the pragmatic principles of Contrast and Conventionality, and multiple-instance learning to learn from ambiguous examples in an online fashion. Applying child language learning strategies to visual learning enables more effective learning in real-time environments, which can lead to enhanced teaching interactions with robots or grounded systems in multi-object environments."
D15-1115,Semantic Framework for Comparison Structures in Natural Language,2015,24,1,2,1,29075,omid bakhshandeh,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"Comparison is one of the most important phenomena in language for expressing objective and subjective facts about various entities. Systems that can understand and reason over comparative structure can play a major role in the applications which require deeper understanding of language. In this paper we present a novel semantic framework for representing the meaning of comparative structures in natural language, which models comparisons as predicate-argument pairs interconnected with semantic roles. Our framework supports not only adjectival, but also adverbial, nominal, and verbal comparatives. With this paper, we provide a novel dataset of gold-standard comparison structures annotated according to our semantic framework."
W14-2401,Learning a Lexicon for Broad-coverage Semantic Parsing,2014,11,4,1,1,17476,james allen,Proceedings of the {ACL} 2014 Workshop on Semantic Parsing,0,"While there has been significant recent work on learning semantic parsers for specific task/ domains, the results donxe2x80x99t transfer from one domain to another domains. We describe a project to learn a broad-coverage semantic lexicon for domain independent semantic parsing. The technique involves several bootstrapping steps starting from a semantic parser based on a modest-sized hand-built semantic lexicon. We demonstrate that the approach shows promise in building a semantic lexicon on the scale of WordNet, with more coverage and detail that currently available in widely-used resources such as VerbNet. We view having such a lexicon as a necessary prerequisite for any attempt at attaining broad-coverage semantic parsing in any domain. The approach we described applies to all word classes, but in this paper we focus here on verbs, which are the most critical phenomena facing semantic parsing."
W13-0905,Automatic Metaphor Detection using Large-Scale Lexical Resources and Conventional Metaphor Extraction,2013,21,20,3,0,37311,yorick wilks,Proceedings of the First Workshop on Metaphor in {NLP},0,"The paper presents an experimental algorithm to detect conventionalized metaphors implicit in the lexical data in a resource like WordNet, where metaphors are coded into the senses and so would never be detected by any algorithm based on the violation of preferences, since there would always be a constraint satisfied by such senses. We report an implementation of this algorithm, which was implemented first the preference constraints in VerbNet. We then derived in a systematic way a far more extensive set of constraints based on WordNet glosses, and with this data we reimplemented the detection algorithm and got a substantial improvement in recall. We suggest that this technique could contribute to improve the performance of existing metaphor detection strategies that do not attempt to detect conventionalized metaphors. The new WordNet-derived data is of wider significance because it also contains adjective constraints, unlike any existing lexical resource, and can be applied to any language with a semantic parser (and WN) for it."
W13-0103,Automatically Deriving Event Ontologies for a {C}ommon{S}ense Knowledge Base,2013,22,6,1,1,17476,james allen,Proceedings of the 10th International Conference on Computational Semantics ({IWCS} 2013) {--} Long Papers,0,We describe work aimed at building commonsense knowledge by reading word definitions using deep understanding techniques. The end result is a knowledge base allowing complex concepts to be reasoned about using OWL-DL reasoners. We show that we can use this system to automatically create a mid-level ontology for WordNet verbs that has good agreement with human intuition with respect to both the hypernym and causality relations. We present a detailed error analysis that reveals areas of future work needed to enable high-performance learning of conceptual knowledge by reading.
S13-2001,"{S}em{E}val-2013 Task 1: {T}emp{E}val-3: Evaluating Time Expressions, Events, and Temporal Relations",2013,21,183,4,1,37291,naushad uzzaman,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"Within the SemEval-2013 evaluation exercise, the TempEval-3 shared task aims to advance research on temporal information processing. It follows on from TempEval-1 and -2, with: a three-part structure covering temporal expression, event, and temporal relation extraction; a larger dataset; and new single measures to rank systems xe2x80x90 in each task and in general. In this paper, we describe the participantsxe2x80x99 approaches, results, and the observations from the results, which may guide future research in this area."
P13-1007,"Plurality, Negation, and Quantification:Towards Comprehensive Quantifier Scope Disambiguation",2013,26,4,3,1,30397,mehdi manshadi,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Recent work on statistical quantifier scope disambiguation (QSD) has improved upon earlier work by scoping an arbitrary number and type of noun phrases. No corpusbased method, however, has yet addressed QSD when incorporating the implicit universal of plurals and/or operators such as negation. In this paper we report early, though promising, results for automatic QSD when handling both phenomena. We also present a general model for learning to build partial orders from a set of pairwise preferences. We give ann logn algorithm for finding a guaranteed approximation of the optimal solution, which works very well in practice. Finally, we significantly improve the performance of the previous model using a rich set of automatically generated features."
S12-1022,Expanding the Range of Tractable Scope-Underspecified Semantic Representations,2012,18,1,2,1,30397,mehdi manshadi,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"Over the past decade, several underspecification frameworks have been proposed that efficiently solve a big subset of scope-underspecified semantic representations within the realm of the most popular constraint-based formalisms. However, there exists a family of coherent natural language sentences whose underspecified representation does not belong to this subset. It has remained an open question whether there exists a tractable superset of these frameworks, covering this family. In this paper, we show that the answer to this question is yes. We define a superset of the previous frameworks, which is solvable by similar algorithms with the same time and space complexity."
manshadi-etal-2012-annotation,An Annotation Scheme for Quantifier Scope Disambiguation,2012,15,1,2,1,30397,mehdi manshadi,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Annotating natural language sentences with quantifier scoping has proved to be very hard. In order to overcome the challenge, previous work on building scope-annotated corpora has focused on sentences with two explicitly quantified noun phrases (NPs). Furthermore, it does not address the annotation of scopal operators or complex NPs such as plurals and definites. We present the first annotation scheme for quantifier scope disambiguation where there is no restriction on the type or the number of scope-bearing elements in the sentence. We discuss some of the most prominent complex scope phenomena encountered in annotating the corpus, such as plurality and type-token distinction, and present mechanisms to handle those phenomena."
J12-3002,{S}quibs: Fruit Carts: A Domain and Corpus for Research in Dialogue Systems and Psycholinguistics,2012,16,4,3,0,43381,gregory aist,Computational Linguistics,0,"We describe a novel domain, Fruit Carts, aimed at eliciting human language production for the twin purposes of (a) dialogue system research and development and (b) psycholinguistic research. Fruit Carts contains five tasks: choosing a cart, placing it on a map, painting the cart, rotating the cart, and filling the cart with fruit. Fruit Carts has been used for research in psycholinguistics and in dialogue systems. Based on these experiences, we discuss how well the Fruit Carts domain meets four desired features: unscripted, context-constrained, controllable difficulty, and separability into semi-independent subdialogues. We describe the domain in sufficient detail to allow others to replicate it; researchers interested in using the corpora themselves are encouraged to contact the authors directly."
W11-1108,Unrestricted Quantifier Scope Disambiguation,2011,21,3,2,1,30397,mehdi manshadi,Proceedings of {T}ext{G}raphs-6: Graph-based Methods for Natural Language Processing,0,"We present the first work on applying statistical techniques to unrestricted Quantifier Scope Disambiguation (QSD), where there is no restriction on the type or the number of quantifiers in the sentence. We formulate unrestricted QSD as learning to build a Directed Acyclic Graph (DAG) and define evaluation metrics based on the properties of DAGs. Previous work on statistical scope disambiguation is very limited, only considering sentences with two explicitly quantified noun phrases (NPs). In addition, they only handle a restricted list of quantifiers. In our system, all NPs, explicitly quantified or not (e.g. definites, bare singulars/plurals, etc.), are considered for possible scope interactions. We present early results on applying a simple model to a small corpus. The preliminary results are encouraging, and we hope will motivate further research in this area."
W11-0219,Building Timelines from Narrative Clinical Records: Initial Results Based-on Deep Natural Language Understanding,2011,18,29,2,0,38460,hyuckchul jung,Proceedings of {B}io{NLP} 2011 Workshop,0,"We present an end-to-end system that processes narrative clinical records, constructs timelines for the medical histories of patients, and visualizes the results. This work is motivated by real clinical records and our general approach is based on deep semantic natural language understanding."
P11-2025,A Corpus of Scope-disambiguated {E}nglish Text,2011,14,5,2,1,30397,mehdi manshadi,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"Previous work on quantifier scope annotation focuses on scoping sentences with only two quantified noun phrases (NPs), where the quantifiers are restricted to a predefined list. It also ignores negation, modal/logical operators, and other sentential adverbials. We present a comprehensive scope annotation scheme. We annotate the scope interaction between all scopal terms in the sentence from quantifiers to scopal adverbials, without putting any restriction on the number of scopal terms in a sentence. In addition, all NPs, explicitly quantified or not, with no restriction on the type of quantification, are investigated for possible scope interactions."
P11-2061,Temporal Evaluation,2011,9,39,2,1,37291,naushad uzzaman,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"In this paper we propose a new method for evaluating systems that extract temporal information from text. It uses temporal closure to reward relations that are equivalent but distinct. Our metric measures the overall performance of systems with a single score, making comparison between different systems straightforward. Our approach is easy to implement, intuitive, accurate, scalable and computationally inexpensive."
S10-1062,{TRIPS} and {TRIOS} System for {T}emp{E}val-2: Extracting Temporal Information from Text,2010,12,94,2,1,37291,naushad uzzaman,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"Extracting temporal information from raw text is fundamental for deep language understanding, and key to many applications like question answering, information extraction, and document summarization. In this paper, we describe two systems we submitted to the TempEval 2 challenge, for extracting temporal information from raw text. The systems use a combination of deep semantic parsing, Markov Logic Networks and Conditional Random Field classifiers. Our two submitted systems, TRIPS and TRIOS, approached all tasks and outperformed all teams in two tasks. Furthermore, TRIOS mostly had second-best performances in other tasks. TRIOS also outperformed the other teams that attempted all the tasks. Our system is notable in that for tasks C -- F, they operated on raw text while all other systems used tagged events and temporal expressions in the corpus as input."
uzzaman-allen-2010-trios,{TRIOS}-{T}ime{B}ank Corpus: Extended {T}ime{B}ank Corpus with Help of Deep Understanding of Text,2010,7,8,2,1,37291,naushad uzzaman,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"TimeBank (Pustejovsky et al, 2003a), a reference for TimeML (Pustejovsky et al, 2003b) compliant annotation, is widely used temporally annotated corpus in the community. It captures time expressions, events, and relations between events and event and temporal expression; but there is room for improvements in this hand-annotated widely used TimeBank corpus. This work is one such effort to extend the TimeBank corpus. Our first goal is to suggest missing TimeBank events and temporal expressions, i.e. events and temporal expressions that were missed by TimeBank annotators. Along with that this paper also suggests some additions to TimeML language by adding new event features (ontology type), some more SLINKs and also relations between events with their arguments, which we call RLINK (relation link). With our new suggestions we present the TRIOS-TimeBank corpus, an extended TimeBank corpus. We conclude by suggesting our future work to clean the TimeBank corpus even more and automatically generating larger temporally annotated corpus for the community."
N09-2012,{TESLA}: A Tool for Annotating Geospatial Language Corpora,2009,4,6,3,1,44439,nate blaylock,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"In this paper, we present The gEoSpatial Language Annotator (TESLA)--a tool which supports human annotation of geospatial language corpora. TESLA interfaces with a GIS database for annotating grounded geospatial entities and uses Google Earth for visualization of both entity search results and evolving object and speaker position from GPS tracks. We also discuss a current annotation effort using TESLA to annotate location descriptions in a geospatial language corpus."
W08-2227,Deep Semantic Analysis of Text,2008,17,73,1,1,17476,james allen,Semantics in Text Processing. {STEP} 2008 Conference Proceedings,0,"We describe a graphical logical form as a semantic representation for text understanding. This representation was designed to bridge the gap between highly expressive deep representations of logical forms and more shallow semantic encodings such as word senses and semantic relations. It preserves rich semantic content while allowing for compact ambiguity encoding and viable partial representations. We describe our system for semantic text processing, which has the TRIPS parser at the core, augmented with statistical preprocessing techniques and online lexical lookup. We also present an evaluation metric for the representation and use it to evaluate the performance of the TRIPS parser on the common task paragraphs."
gallo-etal-2008-production,Production in a Multimodal Corpus: how Speakers Communicate Complex Actions,2008,9,4,3,0,46087,carlos gallo,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,We describe a new multimodal corpus currently under development. The corpus consists of videos of task-oriented dialogues that are annotated for speakerÂs verbal requests and domain action executions. This resource provides data for new research on language production and comprehension. The corpus can be used to study speakersÂ decisions as to how to structure their utterances given the complexity of the message they are trying to convey.
W07-1207,Deep Linguistic Processing for Spoken Dialogue Systems,2007,17,49,1,1,17476,james allen,{ACL} 2007 Workshop on Deep Linguistic Processing,0,"We describe a framework for deep linguistic processing for natural language understanding in task-oriented spoken dialogue systems. The goal is to create domaingeneral processing techniques that can be shared across all domains and dialogue tasks, combined with domain-specific optimization based on an ontology mapping from the generic LF to the application ontology. This framework has been tested in six domains that involve tasks such as interactive planning, coordination operations, tutoring, and learning."
N07-4001,Demonstration of {PLOW}: A Dialogue System for One-Shot Task Learning,2007,2,3,1,1,17476,james allen,Proceedings of Human Language Technologies: The Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics ({NAACL}-{HLT}),0,"We describe a system that can learn new procedure models effectively from one demonstration by the user. Previous work to learn tasks through observing a demonstration (e.g., Lent & Laird, 2001) has required observing many examples of the same task. One-shot learning of tasks presents a significant challenge because the observed sequence is inherently incomplete -- the user only performs the steps required for the current situation. Furthermore, their decision-making processes, which reflect the control structures in the procedure, are not revealed."
W05-1525,Generic Parsing for Multi-Domain Semantic Interpretation,2005,8,21,3,1,41055,myroslava dzikovska,Proceedings of the Ninth International Workshop on Parsing Technology,0,"Producing detailed syntactic and semantic representations of natural language is essential for practical dialog systems such as plan-based assistants and tutorial systems. Development of such systems is time-consuming and costly as they are typically hand-crafted for each application, and dialog corpus data is more difficult to obtain than text. The TRIPS parser and grammar addresses these issues by providing broad coverage of common constructions in practical dialog and producing semantic representations suitable for dialog processing across domains. Our system bootstraps dialog system development in new domains and helps build parsed corpora."
W05-1526,Online Statistics for a Unification-Based Dialogue Parser,2005,10,3,3,0,1344,micha elsner,Proceedings of the Ninth International Workshop on Parsing Technology,0,"We describe a method for augmenting unification-based deep parsing with statistical methods. We extend and adapt the Bikel parser, which uses head-driven lexical statistics, to dialogue. We show that our augmented parser produces significantly fewer constituents than the baseline system and achieves comparable bracketing accuracy, even yielding slight improvements for longer sentences."
P05-3022,Two Diverse Systems Built using Generic Components for Spoken Dialogue (Recent Progress on {TRIPS}),2005,3,12,1,1,17476,james allen,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"This paper describes recent progress on the TRIPS architecture for developing spoken-language dialogue systems. The interactive poster session will include demonstrations of two systems built using TRIPS: a computer purchasing assistant, and an object placement (and manipulation) task."
2005.sigdial-1.20,A Collaborative Problem-Solving Model of Dialogue,2005,-1,-1,2,1,44439,nate blaylock,Proceedings of the 6th SIGdial Workshop on Discourse and Dialogue,0,None
W04-2302,Stochastic Language Generation in a Dialogue System: Toward a Domain Independent Generator,2004,17,19,2,0.109197,980,nathanael chambers,Proceedings of the 5th {SIG}dial Workshop on Discourse and Dialogue at {HLT}-{NAACL} 2004,0,"Abstract : Until recently. surface generation in dialogue systems has served the purpose of simply providing a backend to other areas of research. The generation component of such systems usually consists of templates and canned text, providing inflexible, unnatural output. To make matters worse, the resources are typically specific to the domain in question and not portable to new tasks. In contrast, domain-independent generation systems typically require large grammars, full lexicons, complex collocational information, and much more. Furthermore, these frameworks have primarily been applied to text applications and it is not clear that the same systems could perform well in a dialogue application. This paper explores the feasibility of adapting such systems to create a domain-independent generation component useful for dialogue systems. It utilizes the domain independent semantic form of The Rochester Interactive Planning System (TRIPS) with a domain independent stochastic surface generation module. We show that a written text language model can be used to predict dialogue utterances from an over-generated word forest. We also present results from a human oriented evaluation in an emergency planning domain."
W04-0304,Incremental Parsing with Reference Interaction,2004,24,17,3,0,50885,scott stoness,Proceedings of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together,0,We present a general architecture for incremental interaction between modules in a speech-to-intention continuous understanding dialogue system. This architecture is then instantiated in the form of an incremental parser which receives suitability feedback on NP constituents from a reference resolution module. Oracle results indicate that perfect NP suitability judgments can provide a labelled-bracket error reduction of as much as 42% and an efficiency improvement of 30%. Preliminary experiments in which the parser incorporates feedback judgments based on the set of referents found in the discourse context achieve a maximum error reduction of 9.3% and efficiency gain of 4.6%. The parser is also able to incrementally instantiate the semantics of underspecified pronouns based on matches from the discourse context. These results suggest that the architecture holds promise as a platform for incremental parsing supporting continuous understanding.
W04-0214,Discourse Annotation in the Monroe Corpus,2004,14,10,5,0,191,joel tetreault,Proceedings of the Workshop on Discourse Annotation,0,"We describe a method for annotating spoken dialog corpora using both automatic and manual annotation. Our semi-automated method for corpus development results in a corpus combining rich semantics, discourse information and reference annotation, and allows us to explore issues relating these."
swift-etal-2004-semi,Semi-automatic Syntactic and Semantic Corpus Annotation with a Deep Parser,2004,9,12,4,1,41163,mary swift,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"We describe a semi-automatic method for linguistically rich corpus annotation using a broad-coverage deep parser to generate syntactic structure, semantic representation and discourse information for task-oriented dialogs. The parser-generated analyses are checked by trained annotators. Incomplete coverage and incorrect analyses are addressed through lexicon and grammar development, after which the dialogs undergo another cycle of parsing and checking. Currently we have 85% correct annotations in our emergency rescue task domain and 70% in our medication scheduling domain. This iterative process of corpus annotation allows us to create domain-specific gold-standard corpora for test suites and corpus-based experiments as part of general system development."
C04-1055,Skeletons in the parser: Using a shallow parser to improve deep parsing,2004,18,14,2,1,41163,mary swift,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,We describe a simple approach for integrating shallow and deep parsing. We use phrase structure bracketing obtained from the Collins parser as filters to guide deep parsing. Our experiments demonstrate that our technique yields substantial gains in speed along with modest improvements in accuracy.
W02-0201,Synchronization in an Asynchronous Agent-based architecture for Dialogue Systems,2002,17,22,2,1,44439,nate blaylock,Proceedings of the Third {SIG}dial Workshop on Discourse and Dialogue,0,"Most dialogue architectures are either pipelined or, if agent-based, are restricted to a pipelined flow-of-information. The TRIPS dialogue architecture is agent-based and asynchronous, with several layers of information flow. We present this architecture and the synchronization issues we encountered in building a truly distributed, agent-based dialogue architecture."
W00-0307,{TRIPS}- 911 System Demonstration,2000,2,3,1,1,17476,james allen,ANLP-NAACL 2000 Workshop: Conversational Systems,0,None
J99-4003,"Speech repains, intonational phrases, and discourse markers: modeling speakers{'} utterances in spoken dialogue",1999,127,164,2,0.952381,40772,peter heeman,Computational Linguistics,0,"Interactive spoken dialogue provides many new challenges for natural language understanding systems. One of the most critical challenges is simply determining the speaker's intended utterances: both segmenting a speaker's turn into utterances and determining the intended words in each utterance. Even assuming perfect word recognition, the latter problem is complicated by the occurrence of speech repairs, which occur where speakers go back and change (or repeat) something they just said. The words that are replaced or repeated are no longer part of the intended utterance, and so need to be identified. Segmenting turns and resolving repairs are strongly interwined with a third task: identifying discourse markers. Because of the interactions, and interactions with POS tagging and speech recognition, we need to address these tasks together and early on in the processing stream. This paper presents a statistical language model in which we redefine the speech recognition problem so that it includes the identification of POS tags, discourse markers, speech repairs, and intonational phrases. By solving these simultaneously, we obtain better results on each task than addressing them separately. Our model is able to identify 72% of turn-internal intonational boundaries with a precision of 71%, 97% of discourse markers with 96% precision, and detect and correct 66% of repairs with 74% precision."
P97-1033,"Intonational Boundaries, Speech Repairs, and Discourse Markers: Modeling Spoken Dialog",1997,26,32,2,1,40772,peter heeman,35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,1,"To understand a speaker's turn of a conversation, one needs to segment it into intonational phrases, clean up any speech repairs that might have occurred, and identify discourse markers. In this paper, we argue that these problems must be resolved together, and that they must be resolved early in the processing stream. We put forward a statistical language model that resolves these problem, does POS tagging, and can be used as the language model of a speech recognizer. We find that by accounting for the interactions between these tasks that the performance on each task improves, as does POS tagging and perplexity."
P96-1009,A Robust System for Natural Spoken Dialogue,1996,21,202,1,1,17476,james allen,34th Annual Meeting of the Association for Computational Linguistics,1,"This paper describes a system that leads us to believe in the feasibility of constructing natural spoken dialogue systems in task-oriented domains. It specifically addresses the issue of robust interpretation of speech in the presence of recognition errors. Robustness is achieved by a combination of statistical error post-correction, syntactically- and semantically-driven robust parsing, and extensive use of the dialogue context. We present an evaluation of the system using time-to-completion and the quality of the final solution that suggests that most native speakers of English can use the system successfully with virtually no training."
P94-1001,Discourse Obligations in Dialogue Processing,1994,20,186,2,0,16786,david traum,32nd Annual Meeting of the Association for Computational Linguistics,1,"We show that in modeling social interaction, particularly dialogue, the attitude of obligation can be a useful adjunct to the popularly considered attitudes of belief, goal, and intention and their mutual and shared counterparts. In particular, we show how discourse obligations can be used to account in a natural manner for the connection between a question and its answer in dialogue and how obligations can be used along with other parts of the discourse context to extend the coverage of a dialogue system."
P94-1041,Detecting and Correcting Speech Repairs,1994,13,43,2,1,40772,peter heeman,32nd Annual Meeting of the Association for Computational Linguistics,1,"Interactive spoken dialog provides many new challenges for spoken language systems. One of the most critical is the prevalence of speech repairs. This paper presents an algorithm that detects and corrects speech repairs based on finding the repair pattern. The repair pattern is built by finding word matches and word replacements, and identifying fragments and editing terms. Rather than using a set of prebuilt templates, we build the pattern on the fly. In a the fair test, our method, when combined with a statistical model to filter possible repairs, was successful at detecting and correcting 80% of the repairs, without using prosodic information or a parser."
H94-1034,Tagging Speech Repairs,1994,15,20,2,1,40772,peter heeman,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop held at {P}lainsboro, {N}ew {J}ersey, {M}arch 8-11, 1994",0,"This paper describes a method of detecting speech repairs that uses a part-of-speech tagger. The tagger is given knowledge about category transitions for speech repairs, and so is able to mark a transition either as a likely repair or as fluent speech. Other contextual clues, such as editing terms, word fragments, and word matchings, are also factored in by modifying the transition probabilities."
H94-1120,Natural Language Planning Dialogue for Interactive,1994,0,0,1,1,17476,james allen,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop held at {P}lainsboro, {N}ew {J}ersey, {M}arch 8-11, 1994",0,"The goal of this project is to develop the underlying technologies for spoken dialogue systems to serve as highly interactive interfaces to AI-based reasoning systems. Most current speech and natural language projects are focusing on applications that involve only limited dialog, and little intelligent reasoning, such as data-base query and form-filling applications. But the great promise for speech and natural language interfaces is in providing useful interfaces to complex reasoning systems such as planning systems and expert systems."
H93-1033,Generic Plan Recognition for Dialogue Systems,1993,11,15,2,0,49274,george ferguson,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993",0,"We describe a general framework for encoding rich domain models and sophisticated plan reasoning capabilities. The approach uses graph-based reasoning to address a wide range of tasks that typically arise in dialogue systems. The graphical plan representation is independent of but connected to the underlying representation of action and time. We describe types of plan recognition that are needed, illustrating these with examples from dialogues collected as part of the TRAINS project. The algorithms for the tasks are presented, and issues in the formalization of the reasoning processes are discussed."
H93-1114,Natural Language Planning Dialogue for Intelligent Applications,1993,0,0,1,1,17476,james allen,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993",0,"The goal of this project is to develop the underlying technologies for spoken dialogue systems that serve as interfaces to complex, state-of-the-art reasoning systems. Most current speech and natural language projects are focusing on applications that involve very little intelligent reasoning, such as data-base query and form-filling. However, the great promise for speech and natural language interfaces is in providing useful interfaces to complex AI reasoning systems such as planning systems and expert systems."
H92-1002,Session {I}: Evaluating Spoken Language,1992,-1,-1,1,1,17476,james allen,"Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, {F}ebruary 23-26, 1992",0,None
H91-1032,Session 5: Natural Language {I},1991,-1,-1,1,1,17476,james allen,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,None
H91-1064,Discourse Structure in the {TRAINS} Project,1991,2,22,1,1,17476,james allen,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,"In a natural dialog, a considerable proportion of the utterances actually relate to the maintenance of the dialog itself rather than to furthering the task or goals motivating the conversation. For example, many utterances serve to acknowledge, clarify, correct a previous utterance rather than pursue some goal in the domain. In addition, natural dialog is full of false starts, ungrammatical sentences and other complexities not found in in written language. This paper describes our recent efforts to define and construct a model of discourse interaction that handle dialogs that are rich in these natural dialog-related phenomena."
H91-1105,"Natural Language, Knowledge Representation and Discourse",1991,-1,-1,1,1,17476,james allen,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,None
H90-1101,"Natural Language, Knowledge Representation, and Discourse",1990,0,0,1,1,17476,james allen,"Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",0,"The principal objective of this project is to develop a system for representing and reasoning about the discourse context in extended man-machine dialogs. Current focus areas include the development of a general theory of multi-agent planning to account for the structure of natural-language dialog, the development of a general knowledge representation for capturing a wide range of natural language semantics, and the development of a general, error- tolerant parser and semantic interpreter for English that can be guided by discourse information. Specifically, we are developing a model of discourse plans that includes actions such as introducing a new topic, as well as the actions of clarifying, correcting or acknowledging parts of the previous dialog. We are exploring how far the planning approach can be extended, and how the traditional language components, i.e. parsing, semantic interpretation and discourse processing, relate to the planning component."
P89-1026,Two Constraints on Speech Act Ambiguity,1989,16,41,2,0,56479,elizabeth hinkelman,27th Annual Meeting of the Association for Computational Linguistics,1,"Existing plan-based theories of speech act interpretation do not account for the conventional aspect of speech acts. We use patterns of linguistic features (e.g. mood, verb form, sentence adverbials, thematic roles) to suggest a range of speech act interpretations for the utterance. These are filtered using plan-based conversational implicatures to eliminate inappropriate ones. Extended plan reasoning is available but not necessary for familiar forms. Taking speech act ambiguity seriously, with these two constraints, explains how Can you pass the salt? is a typical indirect request while Are you able to pass the salt? is not."
H89-2052,Using Structural Constraints for Speech Act Interpretation,1989,17,2,1,1,17476,james allen,"Speech and Natural Language: Proceedings of a Workshop Held at Cape Cod, Massachusetts, October 15-18, 1989",0,"We present a speech act interpretation system that has the generality of previous plan-based approaches but also can distinguish subtleties of phrasing. As a result, a sentence such as Can you pass the salt can be recognized as a request to pass the salt, whereas Tell me whether you are able to pass the salt is a question about the hearer's abilities. The system also provides a framework for integrating spoken language information, namely intonation and prosody, into the speech act interpretation process. The resulting system is more accurate than previous approaches and is considerably more efficient in dealing with everyday conventional sentences."
H89-2071,"Natural Language, Knowledge Representation and Discourse",1989,-1,-1,1,1,17476,james allen,"Speech and Natural Language: Proceedings of a Workshop Held at Cape Cod, Massachusetts, October 15-18, 1989",0,None
P84-1063,A Plan Recognition Model for Clarification Subdialogues,1984,18,27,2,0,6782,diane litman,10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics,1,"One of the promising approaches to analyzing task-oriented dialogues has involved modeling the plans of the speakers in the task domain. In general, these models work well as long as the topic follows the task structure closely, but they have difficulty in accounting for clarification subdialogues and topic change. We have developed a model based on a hierarchy of plans and metaplans that accounts for the clarification subdialogues while maintaining the advantages of the plan-based approach."
P82-1004,What{'}s in a Semantic Network?,1982,23,30,1,1,17476,james allen,20th Annual Meeting of the Association for Computational Linguistics,1,"Ever since Wood's What's in a Link paper, there has been a growing concern for formalization in the study of knowledge representation. Several arguments have been made that frame representation languages and semantic-network languages are syntactic variants of the first-order predicate calculus (FOPC). The typical argument proceeds by showing how any given frame or network representation can be mapped to a logically isomorphic FOPC representation. For the past two years we have been studying the formalization of knowledge retrievers as well as the representation languages that they operate on. This paper presents a representation language in the notation of FOPC whose form facilitates the design of a semantic-network-like retriever."
P81-1017,What{'}s Necessary to Hide?: Modeling Action Verbs,1981,17,9,1,1,17476,james allen,19th Annual Meeting of the Association for Computational Linguistics,1,"This paper considers what types of knowledge one must possess in order to reason about actions. Rather than concentrating on how actions are performed, as is done in the problem-solving literature, it examines the set of conditions under which an action can be said to have occurred. In other words, if one is told that action A occurred, what can be inferred about the state of the world? In particular, if the representation can define such conditions, it must have good models of time, belief, and intention. This paper discusses these issues and suggests a formalism in which general actions and events can be defined. Throughout, the action of hiding a book from someone is used as a motivating example."
P79-1021,"Plans, Inference, and Indirect Speech Acts",1979,9,5,1,1,17476,james allen,17th Annual Meeting of the Association for Computational Linguistics,1,"One of the central concerns of a theory of pra~atics is to explain what actions language users per fo rm by making u t t e r a n c e s . Th is concern i s a lso r e l e v a n t to the d e s i g n e r s o f c o n v e r s a t i o n a l language unde rs tand ing systems, e s p e c i a l l y those i n tended to coope ra te w i t h a user in the e x e c u t i o n o f some t ask ( e . g . , t he Computer C o n s u l t a n t t ask d iscussed in Walker [1978])."
T78-1017,Speech Acts as a Basis for Understanding Dialogue Coherence,1978,9,52,2,0,57785,raymond perrault,Theoretical Issues in Natural Language Processing-2,0,"Webster's dictionary defines coherence as the quality of being logically integrated, consistent, and intelligible. If one were asked whether a sequence of physical acts being performed by an agent was coherent, a crucial factor in the decision would be whether the acts were perceived as contributing to the achievement of an overall goal. In that case they can frequently be described briefly, by naming the goal or the procedure executed to achieve it. Once the intended goal has been conjectured, the sequence can be described as a more or less correct, more or less optimal attempt at the achievement of the goal."
J78-3024,Speech Acts as a Basis for Understanding Dialogue Coherence,1978,9,52,2,0,57785,raymond perrault,American Journal of Computational Linguistics,0,"Webster's dictionary defines coherence as the quality of being logically integrated, consistent, and intelligible. If one were asked whether a sequence of physical acts being performed by an agent was coherent, a crucial factor in the decision would be whether the acts were perceived as contributing to the achievement of an overall goal. In that case they can frequently be described briefly, by naming the goal or the procedure executed to achieve it. Once the intended goal has been conjectured, the sequence can be described as a more or less correct, more or less optimal attempt at the achievement of the goal."
