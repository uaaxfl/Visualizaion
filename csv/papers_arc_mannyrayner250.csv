2021.computel-1.3,{LARA} in the Service of Revivalistics and Documentary Linguistics: Community Engagement and Endangered Languages,2021,-1,-1,3,0,11419,ghilad zuckermann,Proceedings of the 4th Workshop on the Use of Computational Methods in the Study of Endangered Languages Volume 1 (Papers),0,None
2020.lrec-1.40,Constructing Multimodal Language Learner Texts Using {LARA}: Experiences with Nine Languages,2020,-1,-1,12,0,16669,elham akhlaghi,Proceedings of the 12th Language Resources and Evaluation Conference,0,"LARA (Learning and Reading Assistant) is an open source platform whose purpose is to support easy conversion of plain texts into multimodal online versions suitable for use by language learners. This involves semi-automatically tagging the text, adding other annotations and recording audio. The platform is suitable for creating texts in multiple languages via crowdsourcing techniques that can be used for teaching a language via reading and listening. We present results of initial experiments by various collaborators where we measure the time required to produce substantial LARA resources, up to the length of short novels, in Dutch, English, Farsi, French, German, Icelandic, Irish, Swedish and Turkish. The first results are encouraging. Although there are some startup problems, the conversion task seems manageable for the languages tested so far. The resulting enriched texts are posted online and are freely available in both source and compiled form."
P16-2027,An Open Web Platform for Rule-Based Speech-to-Sign Translation,2016,7,4,1,1,11421,manny rayner,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We present an open web platform for developing, compiling, and running rulebased speech to sign language translation applications. Speech recognition is performed using the Nuance Recognizer 10.2 toolkit, and signed output, including both manual and non-manual components, is rendered using the JASigning avatar system. The platform is designed to make the component technologies readily accessible to sign language experts who are not necessarily computer scientists. Translation grammars are written in a version of Synchronous Context-Free Grammar adapted to the peculiarities of sign language. All processing is carried out on a remote server, with content uploaded and accessed through a web interface. Initial experiences show that simple translation grammars can be implemented on a time-scale of a few hours to a few days and produce signed output readily comprehensible to Deaf informants. Overall, the platform drastically lowers the barrier to entry for researchers interested in building applications that generate high-quality signed language."
L16-1036,A Shared Task for Spoken {CALL}?,2016,0,9,3,1,34762,claudia baur,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We argue that the field of spoken CALL needs a shared task in order to facilitate comparisons between different groups and methodologies, and describe a concrete example of such a task, based on data collected from a speech-enabled online tool which has been used to help young Swiss German teens practise skills in English conversation. Items are prompt-response pairs, where the prompt is a piece of German text and the response is a recorded English audio file. The task is to label pairs as {``}accept{''} or {``}reject{''}, accepting responses which are grammatically and linguistically correct to match a set of hidden gold standard answers as closely as possible. Initial resources are provided so that a scratch system can be constructed with a minimal investment of effort, and in particular without necessarily using a speech recogniser. Training data for the task will be released in June 2016, and test data in January 2017."
baur-etal-2014-using,Using a Serious Game to Collect a Child Learner Speech Corpus,2014,14,6,2,1,34762,claudia baur,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We present an English-L2 child learner speech corpus, produced by 14 year old Swiss German-L1 students in their third year of learning English, which is currently in the process of being collected. The collection method uses a web-enabled multimodal language game implemented using the CALL-SLT platform, in which subjects hold prompted conversations with an animated agent. Prompts consist of a short animated Engligh-language video clip together with a German-language piece of text indicating the semantic content of the requested response. Grammar-based speech understanding is used to decide whether responses are accepted or rejected, and dialogue flow is controlled using a simple XML-based scripting language; the scripts are written to allow multiple dialogue paths, the choice being made randomly. The system is gamified using a score-and-badge framework with four levels of badges. We describe the application, the data collection and annotation procedures, and the initial tranche of data. The full corpus, when complete, should contain at least 5,000 annotated utterances."
2014.tc-1.24,A tool for building multilingual voice questionnaires,2014,4,2,3,0,40331,alejandro armando,Proceedings of Translating and the Computer 36,0,"We describe a prototype platform for creating multilingual voice questionnaires. Content is defined using a simple form-based language with units for questions, question-groups and answers; questionnaire definitions are compiled into efficient speech recognition packages and tables, and the resulting applications can be deployed over the web on both desktop and mobile platforms. We sketch our initial questionnaire application, which is designed for gathering information related to availability of anti-malaria measures in sub-Saharan Africa. It contains 114 question-groups and 218 questions."
2014.lilt-10.2,{CALL}-{SLT}: A Spoken {CALL} System Based on Grammar and Speech Recognition,2014,-1,-1,1,1,11421,manny rayner,"Linguistic Issues in Language Technology, Volume 10, 2014",0,"We describe CALL-SLT, a speech-enabled Computer-Assisted Language Learning application where the central idea is to prompt the student with an abstract representation of what they are supposed to say, and then use a combination of grammar-based speech recognition and rule-based translation to rate their response. The system has been developed to the level of a mature prototype, freely deployed on the web, with versions for several languages. We present an overview of the core system architecture and the various types of content we have developed. Finally, we describe several evaluations, the last of which is a study carried out over about a week using 130 subjects recruited through the Amazon Mechanical Turk, in which CALL-SLT was contrasted against a control version where the speech recognition component was disabled. The improvement in student learning performance between the two groups was significant at p {\textless} 0.02."
W13-2816,Two Approaches to Correcting Homophone Confusions in a Hybrid Machine Translation System,2013,14,1,5,0,2866,pierrette bouillon,Proceedings of the Second Workshop on Hybrid Approaches to Translation,0,"In the context of a hybrid French-to-English SMT system for translating online forum posts, we present two methods for addressing the common problem of homophone confusions in colloquial written language. The first is based on hand-coded rules; the second on weighted graphs derived from a large-scale pronunciation resource, with weights trained from a small bicorpus of domain language. With automatic evaluation, the weighted graph method yields an improvement of about 0.63 BLEU points, while the rulebased method scores about the same as the baseline. On contrastive manual evaluation, both methods give highly significant improvements (p < 0.0001) and score about equally when compared against each other."
rayner-etal-2012-evaluating,Evaluating Appropriateness Of System Responses In A Spoken {CALL} Game,2012,8,5,1,1,11421,manny rayner,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We describe an experiment carried out using a French version of CALL-SLT, a web-enabled CALL game in which students at each turn are prompted to give a semi-free spoken response which the system then either accepts or rejects. The central question we investigate is whether the response is appropriate; we do this by extracting pairs of utterances where both members of the pair are responses by the same student to the same prompt, and where one response is accepted and one rejected. When the two spoken responses are presented in random order, native speakers show a reasonable degree of agreement in judging that the accepted utterance is better than the rejected one. We discuss the significance of the results and also present a small study supporting the claim that native speakers are nearly always recognised by the system, while non-native speakers are rejected a significant proportion of the time."
fuchs-etal-2012-scalable,A Scalable Architecture For Web Deployment of Spoken Dialogue Systems,2012,8,20,3,0,43004,matthew fuchs,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We describe a scalable architecture, particularly well-suited to cloud-based computing, which can be used for Web-deployment of spoken dialogue systems. In common with similar platforms, like WAMI and the Nuance Mobile Developer Platform, we use a client/server approach in which speech recognition is carried out on the server side; our architecture, however, differs from these systems in offering considerably more elaborate server-side functionality, based on large-scale grammar-based language processing and generic dialogue management. We describe two substantial applications, built using our framework, which we argue would have been hard to construct in WAMI or NMDP. Finally, we present a series of evaluations carried out using CALL-SLT, a speech translation game, where we contrast performance in Web and desktop versions. Task Error Rate in the Web version is only slightly inferior that in the desktop one, and the average additional latency is under half a second. The software is generally available for research purposes."
tsourakis-rayner-2012-corpus,A Corpus for a Gesture-Controlled Mobile Spoken Dialogue System,2012,18,0,2,1,2869,nikos tsourakis,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Speech and hand gestures offer the most natural modalities for everyday human-to-human interaction. The availability of diverse spoken dialogue applications and the proliferation of accelerometers on consumer electronics allow the introduction of new interaction paradigms based on speech and gestures. Little attention has been paid however to the manipulation of spoken dialogue systems through gestures. Situation-induced disabilities or real disabilities are determinant factors that motivate this type of interaction. In this paper we propose six concise and intuitively meaningful gestures that can be used to trigger the commands in any SDS. Using different machine learning techniques we achieve a classification error for the gesture patterns of less than 5{\%}, and we also compare our own set of gestures to ones proposed by users. Finally, we examine the social acceptability of the specific interaction scheme and encounter high levels of acceptance for public use."
2012.amta-papers.25,Using Source-Language Transformations to Address Register Mismatches in {SMT},2012,6,5,1,1,11421,manny rayner,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"Mismatches between training and test data are a ubiquitous problem for real SMT applications. In this paper, we examine a type of mismatch that commonly arises when translating from French and similar languages: available training data is mostly formal register, but test data may well be informal register. We consider methods for defining surface transformations that map common informal language constructions into their formal language counterparts, or vice versa; we then describe two ways to use these mappings, either to create artificial training data or to pre-process source text at run-time. An initial evaluation performed using crowd-sourced comparisons of alternate translations produced by a French-to-English SMT system suggests that both methods can improve performance, with run-time pre-processing being the more effective of the two."
2011.freeopmt-1.5,Bootstrapping a statistical speech translator from a rule-based one,2011,-1,-1,1,1,11421,manny rayner,Proceedings of the Second International Workshop on Free/Open-Source Rule-Based Machine Translation,0,None
tsourakis-etal-2010-examining,Examining the Effects of Rephrasing User Input on Two Mobile Spoken Language Systems,2010,11,0,3,1,2869,nikos tsourakis,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"During the construction of a spoken dialogue system much effort is spent on improving the quality of speech recognition as possible. However, even if an application perfectly recognizes the input, its understanding may be far from what the user originally meant. The user should be informed about what the system actually understood so that an error will not have a negative impact in the later stages of the dialogue. One important aspect that this work tries to address is the effect of presenting the systemÂs understanding during interaction with users. We argue that for specific kinds of applications itÂs important to confirm the understanding of the system before obtaining the output. In this way the user can avoid misconceptions and problems occurring in the dialogue flow and he can enhance his confidence in the system. Nevertheless this has an impact on the interaction, as the mental workload increases, and the userÂs behavior may adapt to the systemÂs coverage. We focus on two applications that implement the notion of rephrasing userÂs input in a different way. Our study took place among 14 subjects that used both systems on a Nokia N810 Internet Tablet."
rayner-etal-2010-multilingual,A Multilingual {CALL} Game Based on Speech Translation,2010,13,31,1,1,11421,manny rayner,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We describe a multilingual Open Source CALL game, CALL-SLT, which reuses speech translation technology developed using the Regulus platform to create an automatic conversation partner that allows intermediate-level language students to improve their fluency. We contrast CALL-SLT with Wang's and Seneff's ``translation game'' system, in particular focussing on three issues. First, we argue that the grammar-based recognition architecture offered by Regulus is more suitable for this type of application; second, that it is preferable to prompt the student in a language-neutral form, rather than in the L1; and third, that we can profitably record successful interactions by native speakers and store them to be reused as online help for students. The current system, which will be demoed at the conference, supports four L2s (English, French, Japanese and Swedish) and two L1s (English and French). We conclude by describing an evaluation exercise, where a version of CALL-SLT configured for English L2 and French L1 was used by several hundred high school students. About half of the subjects reported positive impressions of the system."
2010.eamt-1.39,A Bootstrapped Interlingua-Based {SMT} Architecture,2010,-1,-1,1,1,11421,manny rayner,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,None
W09-2607,Using Artificially Generated Data to Evaluate Statistical Machine Translation,2009,16,2,1,1,11421,manny rayner,Proceedings of the 2009 Workshop on Grammar Engineering Across Frameworks ({GEAF} 2009),0,"Although Statistical Machine Translation (SMT) is now the dominant paradigm within Machine Translation, we argue that it is far from clear that it can outperform Rule-Based Machine Translation (RBMT) on small- to medium-vocabulary applications where high precision is more important than recall. A particularly important practical example is medical speech translation. We report the results of experiments where we configured the various grammars and rule-sets in an Open Source medium-vocabulary multi-lingual medical speech translation system to generate large aligned bilingual corpora for English xe2x86x92 French and English xe2x86x92 Japanese, which were then used to train SMT models based on the common combination of Giza, Moses and SRILM. The resulting SMTs were unable fully to reproduce the performance of the RBMT, with performance topping out, even for English xe2x86x92 French, with less than 70% of the SMT translations of previously unseen sentences agreeing with RBMT translations. When the outputs of the two systems differed, human judges reported the SMT result as frequently being worse than the RBMT result, and hardly ever better; moreover, the added robustness of the SMT only yielded a small improvement in recall, with a large penalty in precision."
W09-1503,Using Paraphrases of Deep Semantic Representions to Support Regression Testing in Spoken Dialogue Systems,2009,15,2,2,0,46954,beth hockey,"Proceedings of the Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing ({SETQA}-{NLP} 2009)",0,"Rule-based spoken dialogue systems require a good regression testing framework if they are to be maintainable. We argue that there is a tension between two extreme positions when constructing the database of test examples. On the one hand, if the examples consist of input/output tuples representing many levels of internal processing, they are fine-grained enough to catch most processing errors, but unstable under most system modifications. If the examples are pairs of user input and final system output, they are much more stable, but too coarse-grained to catch many errors. In either case, there are fairly severe difficulties in judging examples correctly. We claim that a good compromise can be reached by implementing a paraphrasing mechanism which maps internal semantic representations into surface forms, and carrying out regression testing using paraphrases of semantic forms rather than the semantic forms themselves. We describe an implementation of the idea using the Open Source Regulus toolkit, where paraphrases are produced using Regulus grammars compiled in generation mode. Paraphrases can also be used at run-time to produce confirmations. By compiling the paraphrase grammar a second time, as a recogniser, it is possible in a simple and natural way to guarantee that confirmations are always within system coverage."
2009.mtsummit-posters.16,Using Artificial Data to Compare the Difficulty of Using Statistical Machine Translation in Different Language-Pairs,2009,0,1,1,1,11421,manny rayner,Proceedings of Machine Translation Summit XII: Posters,0,None
W08-1702,Making Speech Look Like Text in the Regulus Development Environment,2008,16,0,2,0,47729,elisabeth kron,Coling 2008: Proceedings of the workshop on Grammar Engineering Across Frameworks,0,"We present an overview of the development environment for Regulus, an Open Source platform for construction of grammar-based speech-enabled systems, focussing on recent work whose goal has been to introduce uniformity between text and speech views of Regulus-based applications. We argue the advantages of being able to switch quickly between text and speech modalities in interactive and offline testing, and describe how the new functionalities enable rapid prototyping of spoken dialogue systems and speech translators."
W08-1506,The 2008 {M}ed{SLT} System,2008,7,0,1,1,11421,manny rayner,Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications,0,"MedSLT is a grammar-based medical speech translation system intended for use in doctor-patient diagnosis dialogues, which provides coverage of several different subdomains and multiple language pairs. Vocabulary ranges from about 350 to 1000 surface words, depending on the language and subdomain. We will demo three different versions of the system: an anyto-any multilingual version involving the languages Japanese, English, French and Arabic, a bidirectional English $ Spanish version, and a mobile version running on a hand-held PDA. We will also demo the Regulus development environment, focussing on features which support rapid prototyping of grammar-based speech translation systems."
W08-1511,A Small-Vocabulary Shared Task for Medical Speech Translation,2008,0,5,1,1,11421,manny rayner,Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications,0,We outline a possible small-vocabulary shared task for the emerging medical speech translation community. Data would consist of about 2000 recorded and transcribed utterances collected during an evaluation of an English
bouillon-etal-2008-developing,Developing Non-{E}uropean Translation Pairs in a Medium-Vocabulary Medical Speech Translation System,2008,10,9,9,0,2866,pierrette bouillon,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We describe recent work on MedSLT, a medium-vocabulary interlingua-based medical speech translation system, focussing on issues that arise when handling languages of which the grammar engineer has little or no knowledge. We show how we can systematically create and maintain multiple forms of grammars, lexica and interlingual representations, with some versions being used by language informants, and some by grammar engineers. In particular, we describe the advantages of structuring the interlingua definition as a simple semantic grammar, which includes a human-readable surface form. We show how this allows us to rationalise the process of evaluating translations between languages lacking common speakers, and also makes it possible to create a simple generic tool for debugging to-interlingua translation rules. Examples presented focus on the concrete case of translation between Japanese and Arabic in both directions."
tsourakis-etal-2008-building,Building Mobile Spoken Dialogue Applications Using Regulus,2008,10,13,4,1,2869,nikos tsourakis,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Regulus is an Open Source platform that supports construction of rule-based medium-vocabulary spoken dialogue applications. It has already been used to build several substantial speech-enabled applications, including NASAÂs Clarissa procedure navigator and Geneva UniversityÂs MedSLT medical speech translator. System like these would be far more useful if they were available on a hand-held device, rather than, as with the present version, on a laptop. In this paper we describe the Open Source framework we have developed, which makes it possible to run Regulus applications on generally available mobile devices, using a distributed client-server architecture that offers transparent and reliable integration with different types of ASR systems. We describe the architecture, an implemented calendar application prototype hosted on a mobile device, and an evaluation. The evaluation shows that performance on the mobile device is as good as performance on a normal desktop PC."
C08-1090,Almost Flat Functional Semantics for Speech Translation,2008,10,6,1,1,11421,manny rayner,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"We introduce a novel semantic representation formalism, Almost Flat Functional semantics (AFF), which is designed as an intelligent compromise between linguistically motivated predicate/argument semantics and ad hoc engineering solutions based on flat feature/value lists; the central idea is to tag each semantic element with the functional marking which most closely surrounds it. We argue that AFF is well-suited for medium-vocabulary speech translation applications, and describe simple and general algorithms for parsing, generating and performing transfer using AFF representations. The formalism has been fully implemented within a medium-vocabulary interlingua-based Open Source speech translation system which translates between English, French, Japanese and Arabic."
2008.eamt-1.24,Comparing two different bidirectional versions of the limited-domain medical spoken language translator {M}ed{SLT},2008,12,3,4,1,37884,marianne starlander,Proceedings of the 12th Annual conference of the European Association for Machine Translation,0,"This paper reports preliminary results of an evalu ation during which two different bidirectional versions of the limited-dom ain medical spoken language translator MedSLT were compared in a hospital setting. The more restricted version (V.1) only allows Yes-No answers and short elliptical sentence s, while the less restricted version (V.2) allows Yes-No answers, short elliptical sentences a nd full sentences. Although WER is marginally better for V.1, task performance is marg inally worse. There appear to be two main reasons for this disparity; short sentences ar e often badly recognised and patients tend to find it difficult to limit themselves to ellipsi s, even if they receive clear instructions about not using full sentences."
2008.amta-govandcom.4,Many-to-Many Multilingual Medical Speech Translation on a {PDA},2008,24,13,3,0,15923,kyoko kanzaki,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Government and Commercial Uses of MT,0,"Particularly considering the requirement of high reliability, we argue that the most appropriate architecture for a medical speech translator that can be realised using today{'}s technology combines unidirectional (doctor to patient) translation, medium-vocabulary controlled language coverage, interlingua-based translation, an embedded help component, and deployability on a hand-held hardware platform. We present an overview of the Open Source MedSLT prototype, which has been developed in accordance with these design principles. The system is implemented on top of the Regulus and Nuance 8.5 platforms, translates patient examination questions for all language pairs in the set {English, French, Japanese, Arabic, Catalan}, using vocabularies of about 400 to 1 100 words, and can be run in a distributed client/server environment, where the client application is hosted on a Nokia Internet Tablet device."
W07-1806,A Bidirectional Grammar-Based Medical Speech Translator,2007,19,13,7,0,2866,pierrette bouillon,Proceedings of the Workshop on Grammar-Based Approaches to Spoken Language Processing,0,"We describe a bidirectional version of the grammar-based MedSLT medical speech system. The system supports simple medical examination dialogues about throat pain between an English-speaking physician and a Spanish-speaking patient. The physician's side of the dialogue is assumed to consist mostly of WH-questions, and the patient's of elliptical answers. The paper focusses on the grammar-based speech processing architecture, the ellipsis resolution mechanism, and the online help system."
W07-1807,A Development Environment for Building Grammar-Based Speech-Enabled Applications,2007,6,2,2,0,47729,elisabeth kron,Proceedings of the Workshop on Grammar-Based Approaches to Spoken Language Processing,0,"We present a development environment for Regulus, a toolkit for building unification grammar-based speech-enabled systems, focussing on new functionality added over the last year. In particular, we will show an initial version of a GUI-based top-level for the development environment, a tool that supports graphical debugging of unification grammars by cutting and pasting of derivation trees, and various functionalities that support systematic development of speech translation and spoken dialogue applications built using Regulus."
W07-0806,Adapting a Medical speech to speech translation system ({M}ed{SLT}) to {A}rabic,2007,8,3,3,0,2866,pierrette bouillon,Proceedings of the 2007 Workshop on Computational Approaches to {S}emitic Languages: Common Issues and Resources,0,"We describe the adaptation for Arabic of the grammar-based MedSLT medical speech system. The system supports simple medical diagnosis questions about headaches using vocabulary of 322 words. We show that the MedSLT architecture based on motivated general grammars produces very good results, with a limited effort. Based on the grammars for other languages covered by the system, it is in fact very easy to develop an Arabic grammar and to specialize it efficiently for the different system tasks. In this paper, we focus on generation."
2007.jeptalnrecital-poster.5,Les ellipses dans un syst{\\`e}me de traduction automatique de la parole,2007,-1,-1,2,0,2866,pierrette bouillon,Actes de la 14{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Dans tout dialogue, les phrases elliptiques sont tr{\`e}s nombreuses. Dans cet article, nous {\'e}valuons leur impact sur la reconnaissance et la traduction dans le syst{\`e}me de traduction automatique de la parole MedSLT. La r{\'e}solution des ellipses y est effectu{\'e}e par une m{\'e}thode robuste et portable, emprunt{\'e}e aux syst{\`e}mes de dialogue homme-machine. Cette derni{\`e}re exploite une repr{\'e}sentation s{\'e}mantique plate et combine des techniques linguistiques (pour construire la repr{\'e}sentation) et bas{\'e}es sur les exemples (pour apprendre sur la base d{'}un corpus ce qu{'}est une ellipse bien form{\'e}e dans un sous-domaine donn{\'e} et comment la r{\'e}soudre)."
W06-3702,Evaluating Task Performance for a Unidirectional Controlled Language Medical Speech Translation System,2006,10,17,3,0.784314,48239,nikos chatzichrisafis,Proceedings of the First International Workshop on Medical Speech Translation,0,"We present a task-level evaluation of the French to English version of MedSLT, a medium-vocabulary unidirectional controlled language medical speech translation system designed for doctor-patient diagnosis interviews. Our main goal was to establish task performance levels of novice users and compare them to expert users. Tests were carried out on eight medical students with no previous exposure to the system, with each student using the system for a total of three sessions. By the end of the third session, all the students were able to use the system confidently, with an average task completion time of about 4 minutes."
W06-3707,{M}ed{SLT}: A Limited-Domain Unidirectional Grammar-Based Medical Speech Translator,2006,7,3,1,1,11421,manny rayner,Proceedings of the First International Workshop on Medical Speech Translation,0,"MedSLT is a unidirectional medical speech translation system intended for use in doctor-patient diagnosis dialogues, which provides coverage of several different language pairs and subdomains. Vocabulary ranges from about 350 to 1000 surface words, depending on the language and subdomain. We will demo both the system itself and the development environment, which uses a combination of rule-based and data-driven methods to construct efficient recognisers, generators and transfer rule sets from small corpora."
rayner-etal-2006-regulus,{REGULUS}: A Generic Multilingual Open Source Platform for Grammar-Based Speech Applications,2006,13,3,1,1,11421,manny rayner,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"We present an overview of Regulus, an Open Source platform that supports corpus-based derivation of efficient domain-specific speech recognisers from general linguistically motivated unification grammars. We list available Open Source resources, which include compilers, resource grammars for various languages, documentation and a development environment. The greater part of the paper presents a series of experiments carried out using a medium-vocabulary medical speech translation application and a corpus of 801 recorded domain utterances, designed to investigate the impact on speech understanding performance of vocabulary size, grammatical coverage, presence or absence of various linguistic features, degree of generality of thegrammar and use or otherwise of probabilistic weighting in the CFGlanguage model. In terms of task accuracy, the most significant factors were the use of probabilistic weighting, the degree of generality of the grammar and the inclusion of features which model sortal restrictions."
2006.jeptalnrecital-long.6,Une grammaire multilingue partag{\\'e}e pour la traduction automatique de la parole,2006,-1,-1,2,0.368188,2866,pierrette bouillon,Actes de la 13{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Aujourd{'}hui, l{'}approche la plus courante en traitement de la parole consiste {\`a} combiner un reconnaisseur statistique avec un analyseur robuste. Pour beaucoup d{'}applications cependant, les reconnaisseurs linguistiques bas{\'e}s sur les grammaires offrent de nombreux avantages. Dans cet article, nous pr{\'e}sentons une m{\'e}thodologie et un ensemble de logiciels libres (appel{\'e} Regulus) pour d{\'e}river rapidement des reconnaisseurs linguistiquement motiv{\'e}s {\`a} partir d{'}une grammaire g{\'e}n{\'e}rale partag{\'e}e pour le catalan et le fran{\c{c}}ais."
P05-3008,A Voice Enabled Procedure Browser for the International Space Station,2005,6,17,1,1,11421,manny rayner,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"Clarissa, an experimental voice enabled procedure browser that has recently been deployed on the International Space Station (ISS), is to the best of our knowledge the first spoken dialog system in space. This paper gives background on the system and the ISS procedures, then discusses the research developed to address three key problems: grammar-based speech recognition using the Regulus toolkit; SVM based methods for open microphone speech recognition; and robust side-effect free dialogue management for handling undos, corrections and confirmations."
H05-2014,{J}apanese Speech Understanding using Grammar Specialization,2005,6,5,1,1,11421,manny rayner,Proceedings of {HLT}/{EMNLP} 2005 Interactive Demonstrations,0,"The most common speech understanding architecture for spoken dialogue systems is a combination of speech recognition based on a class N-gram language model, and robust parsing. For many types of applications, however, grammar-based recognition can offer concrete advantages. Training a good class N-gram language model requires substantial quantities of corpus data, which is generally not available at the start of a new project. Head-to-head comparisons of class N-gram/robust and grammar-based systems also suggest that users who are familiar with system coverage get better results from grammar-based architectures (Knight et al., 2001). As a consequence, deployed spoken dialogue systems for real-world applications frequently use grammar-based methods. This is particularly the case for speech translation systems. Although leading research systems like Verbmobil and NE-SPOLE! (Wahlster, 2000; Lavie et al., 2001) usually employ complex architectures combining statistical and rule-based methods, successful practical examples like Phraselator and S-MINDS (Phraselator, 2005; Sehda, 2005) are typically phrasal translators with grammar-based recognizers."
2005.mtsummit-papers.25,Practicing Controlled Language through a Help System integrated into the Medical Speech Translation System ({M}ed{SLT}),2005,9,13,5,1,37884,marianne starlander,Proceedings of Machine Translation Summit X: Papers,0,"In this paper, we present evidence that providing users of a speech to speech translation system for emergency diagnosis (MedSLT) with a tool that helps them to learn the coverage greatly improves their success in using the system. In MedSLT, the system uses a grammar-based recogniser that provides more predictable results to the translation component. The help module aims at addressing the lack of robustness inherent in this type of approach. It takes as input the result of a robust statistical recogniser that performs better for out-of-coverage data and produces a list of in-coverage example sentences. These examples are selected from a defined list using a heuristic that prioritises sentences maximising the number of N-grams shared with those extracted from the recognition result."
2005.jeptalnrecital-long.17,Representational and architectural issues in a limited-domain medical speech translator,2005,10,6,1,1,11421,manny rayner,Actes de la 12{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"We present an overview of MedSLT, a medium-vocabulary medical speech translation system, focussing on the representational issues that arise when translating temporal and causal concepts. Although flat key/value structures are strongly preferred as semantic representations in speech understanding systems, we argue that it is infeasible to handle the necessary range of concepts using only flat structures. By exploiting the specific nature of the task, we show that it is possible to implement a solution which only slightly extends the representational complexity of the semantic representation language, by permitting an optional single nested level representing a subordinate clause construct. We sketch our solutions to the key problems of producing minimally nested representations using phrase-spotting methods, and writing cleanly structured rule-sets that map temporal and phrasal representations into a canonical interlingual form."
2005.eamt-1.8,A generic multi-lingual open source platform for limited-domain medical speech translation,2005,9,42,2,0.368188,2866,pierrette bouillon,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,"We present an overview of MedSLT, an Open Source platform for developing limited-domain medical speech translation systems. We focus in particular on the speech understanding architecture, which uses grammar-based language models derived using cor- pus-based specialisation methods from a single linguistically motivated grammar, and summarise the results of two evaluations which investigate the appropriateness of these de- sign choices. Other sections describe the interlingua and its relationship with the recogni- tion architecture, and the current demo system."
2004.tmi-1.3,Comparing rule-based and statistical approaches to speech understanding in a limited domain speech translation system,2004,14,15,1,1,11421,manny rayner,Proceedings of the 10th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,"The paper directly compares two versions of a medical speech translation system, one with a grammar based language model (GLM) recognizer and the other with a statistical language model (SLM) recognizer. We construct the GLM using a corpus-based method, so that both the GLM and the SLM can be derived from the same corpus; evaluation is carried out with respect to performance on the speech translation task. Despite using a very small training set for both the GLM and the SLM, the SLM delivers much better word error rates on unseen test material. Nonetheless, evaluating both systems on translation performance rather than word error rates, the GLM-based version of the system outperforms the SLM on the actual translation task."
W03-2125,"A procedure assistant for astronauts in a functional programming architecture, with step previewing and spoken correction of dialogue moves",2003,3,0,2,0,43381,gregory aist,Proceedings of the Fourth {SIG}dial Workshop of Discourse and Dialogue,0,"We present a demonstration of a prototype system aimed at providing support with procedural tasks for astronauts on board the International Space Station. Current functionality includes navigation within the procedure, previewing steps, requesting a list of images or a particular image, recording voice notes and spoken alarms, setting parameters such as audio volume. Dialogue capabilities include handling spoken corrections for an entire dialogue move, reestablishing context in response to a user request, responding to user barge-in, and help on demand. The current system has been partially reimplemented for better efficiency and in response to feedback from astronauts and astronaut training personnel. Added features include visual and spoken step previewing, and spoken correction of dialogue moves. The intention is to introduce the system into astronaut training as a prelude to flight on board the International Space Station."
P03-2024,A Limited-Domain {E}nglish to {J}apanese Medical Speech Translator Built Using {REGULUS} 2,2003,5,12,1,1,11421,manny rayner,The Companion Volume to the Proceedings of 41st Annual Meeting of the Association for Computational Linguistics,0,"We argue that verbal patient diagnosis is a promising application for limited-domain speech translation, and describe an architecture designed for this type of task which represents a compromise between principled linguistics-based processing on the one hand and efficient phrasal translation on the other. We propose to demonstrate a prototype system instantiating this architecture, which has been built on top of the Open Source REGULUS 2 platform. The prototype translates spoken yes-no questions about headache symptoms from English to Japanese, using a vocabulary of about 200 words."
P03-2038,An Intelligent Procedure Assistant Built Using {REGULUS} 2 and {ALTERF},2003,7,8,1,1,11421,manny rayner,The Companion Volume to the Proceedings of 41st Annual Meeting of the Association for Computational Linguistics,0,"We will demonstrate the latest version of an ongoing project to create an intelligent procedure assistant for use by astronauts on the International Space Station (ISS). The system functionality includes spoken dialogue control of navigation, coordinated display of the procedure text, display of related pictures, alarms, and recording and playback of voice notes. The demo also exemplifies several interesting component technologies. Speech recognition and language understanding have been developed using the Open Source REGULUS 2 toolkit. This implements an approach to portable grammar-based language modelling in which all models are derived from a single linguistically motivated unification grammar. Domain-specific CFG language models are produced by first specialising the grammar using an automatic corpus-based method, and then compiling the resulting specialised grammars into CFG form. Translation between language centered and domain centered semantic representations is carried out by ALTERF, another Open Source toolkit, which combines rule-based and corpus-based processing in a transparent way."
E03-2010,An Open-Source Environment for Compiling Typed Unification Grammars into Speech Recognisers,2003,10,21,1,1,11421,manny rayner,Demonstrations,0,"We present REGULUS, an Open Source environment which compiles typed unification grammars into context free grammar language models compatible with the Nuance Toolkit. The environment includes a large general unification grammar of English and corpus-based tools for creating efficient domain-specific recognisers from it. We will demo applications built using the system, including a speech translator and a command and control system for a simulated robotic domain, and show how the development environment can be used to edit and extend them."
E03-1078,Transparent combination of rule-based and data-driven approaches in speech understanding,2003,0,5,1,1,11421,manny rayner,10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,None
W02-0710,A Flexible Speech to Speech Phrasebook Translator,2002,4,10,1,1,11421,manny rayner,Proceedings of the {ACL}-02 Workshop on Speech-to-Speech Translation: Algorithms and Systems,0,"We describe a simple speech translation architecture intended for medical and other safety-critical applications, which is intended to represent a compromise between fixed-phrase translation on one hand and complex transfer-based translation on the other. Recognition is guided by an annotated CFG-based language model compiled from a unification grammar; transfer and generation use a minimal list-oriented semantic representation language. We present an evaluation of an initial prototype, which translates yes/no questions about hypoglycaemia from spoken French into spoken English using a vocabulary of about 200 words."
W01-1617,Plug and Play Speech Understanding,2001,11,33,1,1,11421,manny rayner,Proceedings of the Second {SIG}dial Workshop on Discourse and Dialogue,0,Plug and Play is an increasingly important concept in system and network architectures. We introduce and describe a spoken language dialogue system architecture which supports Plug and Playable networks of objects in its domain. Each device in the network carries the linguistic and dialogue management information which is pertinent to it and uploads it dynamically to the relevant language processing components in the spoken language interface. We describe the current state of our plug and play demonstrator and discuss theoretical issues that arise from our work. Plug and Play forms a central topic for the DHomme project.
N01-1030,Do {CFG}-Based Language Models Need Agreement Constraints?,2001,10,7,1,1,11421,manny rayner,Second Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Many people are now routinely building grammar-based language models for interactive spoken language applications; these language models are typically ad hoc semantic grammars which ignore many standard linguistic constraints, in particular grammatical agreement. We describe a series of experiments in which we took three CFG-based language models from non-trivial implemented systems, and in each case contrasted the performance of a version which included agreement constraints against a version which ignored them. Our findings suggest that inclusion of agreement constraints significantly improves performance in terms of both word error rate and semantic error rate."
W00-2026,A comparison of the {XTAG} and {CLE} Grammars for {E}nglish,2000,6,0,1,1,11421,manny rayner,Proceedings of the Fifth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+5),0,"When people develop something intended as a large broad-coverage grammar, they usually have a more specific goal in mind. Sometimes this goal is covering a corpus; sometimes the developers have theoretical ideas they wish to investigate; most often, work is driven by a combination of these two main types of goal. What tends to happen after a while is that the community of people working with the grammar starts thinking of some phenomena as xe2x80x9ccentralxe2x80x9d, and makes serious efforts to deal with them; other phenomena are labelled xe2x80x9cmarginalxe2x80x9d, and ignored. Before long, the distinction between xe2x80x9ccentralxe2x80x9d and xe2x80x9cmarginalxe2x80x9d becomes so ingrained that it is automatic, and people virtually stop thinking about the xe2x80x9cmarginalxe2x80x9d phenomena. In practice, the only way to bring the marginal things back into focus is to look at what other people are doing and compare it with onexe2x80x99s own work. In this paper, we will take two large grammars, XTAG and CLE, and examine each of them from the otherxe2x80x99s point of view. We will find in both cases not only that important things are missing, but that the perspective offered by the other grammar suggests simple and practical ways of filling in the holes. It turns out that there is a pleasing symmetry to the picture. XTAG has a very good treatment of complement structure, which the CLE to some extent lacks; conversely, the CLE offers a powerful and general account of adjuncts, which the XTAG grammar does not fully duplicate. If we examine the way in which each grammar does the thing it is good at, we find that the relevant methods are quite easy to port to the other framework, and in fact only involve generalization and systematization of existing mechanisms. The paper is structured as follows. Section 2 presents a very brief overview of the CLE and XTAG grammars. In Section 3, we describe the CLE grammar from the XTAG grammarxe2x80x99s point of view, following which Section 4 describes the XTAG grammar from a CLE perspective. Section 5 concludes."
W00-0311,A Compact Architecture for Dialogue Management Based on Scripts and Meta-Outputs,2000,12,0,1,1,11421,manny rayner,ANLP-NAACL 2000 Workshop: Conversational Systems,0,"We describe an architecture for spoken dialogue interfaces to semi-autonomous systems that transforms speech signals through successive representations of linguistic, dialogue, and domain knowledge. Each step produces an output, and a meta-output describing the transformation, with an executable program in a simple scripting language as the final result. The output/meta-output distinction permits perspicuous treatment of diverse tasks such as resolving pronouns, correcting user misconceptions, and optimizing scripts."
C00-2097,Compiling Language Models from a Linguistically Motivated Unification Grammar,2000,8,11,1,1,11421,manny rayner,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"Systems now exist which are able to compile unification grammars into language models that can be included in a speech recognizer, but it is so far unclear whether non-trivial linguistically principled grammars can be used for this purpose. We describe a series of experiments which investigate the question empirically, by incrementally constructing a grammar and discovering what problems emerge when successively larger versions are compiled into finite state graph representations and used as language models for a medium-vocabulary recognition task."
A00-1016,A Compact Architecture for Dialogue Management Based on Scripts and Meta-Outputs,2000,12,0,1,1,11421,manny rayner,Sixth Applied Natural Language Processing Conference,0,"We describe an architecture for spoken dialogue interfaces to semi-autonomous systems that transforms speech signals through successive representations of linguistic, dialogue, and domain knowledge. Each step produces an output, and a meta-output describing the transformation, with an executable program in a simple scripting language as the final result. The output/meta-output distinction permits perspicuous treatment of diverse tasks such as resolving pronouns, correcting user misconceptions, and optimizing scripts."
W97-0910,Recycling Lingware in a Multilingual {MT} System,1997,8,0,1,1,11421,manny rayner,From Research to Commercial Applications: Making {NLP} Work in Practice,0,"We describe two methods relevant to multi-lingual machine translation systems, which can be used to port linguistic data (grammars, lexicons and transfer rules) between systems used for processing related languages. The methods are fully implemented within the Spoken Language Translator system, and were used to create versions of the system for two new language pairs using only a month of expert effort."
W97-0411,Translation Methodology in the Spoken Language Translator: An Evaluation,1997,15,4,3,0.234818,55475,david carter,Spoken Language Translation,0,In this paper we describe how the translation methodology adopted fro the Spoken Language Translator (SLT) addresses the characteristics of the speech translation task in a context where it is esse ...
P96-1030,Fast Parsing Using Pruning and Grammar Specialization,1996,25,18,1,1,11421,manny rayner,34th Annual Meeting of the Association for Computational Linguistics,1,"We show how a general grammar may be automatically adapted for fast parsing of utterances from a specific domain by means of constituent pruning and grammar specialization based on explanation-based learning. These methods together give an order of magnitude increase in speed, and the coverage loss entailed by grammar specialization is reduced to approximately half that reported in previous work. Experiments described here suggest that the loss of coverage has been reduced to the point where it no longer causes significant performance degradation in the context of a real application."
1995.tc-1.11,Using corpora to develop limited-domain speech translation systems,1995,-1,-1,1,1,11421,manny rayner,Proceedings of Translating and the Computer 17,0,None
H94-1040,Combining Knowledge Sources to Reorder N-Best Speech Hypothesis Lists,1994,11,74,1,1,11421,manny rayner,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop held at {P}lainsboro, {N}ew {J}ersey, {M}arch 8-11, 1994",0,"A simple and general method is described that can combine different knowledge sources to reorder N-best lists of hypotheses produced by a speech recognizer. The method is automatically trainable, acquiring information from both positive and negative examples. In experiments, the method was tested on a 1000-utterance sample of unseen ATIS data."
H93-1042,A Speech to Speech Translation System Built From Standard Components,1993,16,24,1,1,11421,manny rayner,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993",0,"This paper describes a speech to speech translation system using standard components and a suite of generalizable customization techniques. The system currently translates air travel planning queries from English to Swedish. The modular architecture is designed to be easy to port to new domains and languages, and consists of a pipelined series of processing phases. The output of each phase consists of multiple hypotheses; statistical preference mechanisms, the data for which is derived from automatic processing of domain corpora, are used between each pair of phases to filter hypotheses. Linguistic knowledge is represented throughout the system in declarative form. We summarize the architectures of the component systems and the interfaces between them, and present initial performance results."
A92-1001,Deriving Database Queries from Logical Forms by Abductive Definition Expansion,1992,9,162,1,1,11421,manny rayner,Third Conference on Applied Natural Language Processing,0,"The paper describes a principled approach to the problem of deriving database queries from logical forms produced by a general NL interface. Our method attempts to construct a database query and a set of plausible assumptions, such that the logical form is equivalent to the query given the assumptions. The domain information needed is provided as declarative meaning postulates, including definitional equivalences. The technical basis for the approach is that a definition of the form Head xe2x88xa7 Conditions xe2x86x94 Body can be read procedurally as Expand Head to Body if it occurs in an environment where Conditions can be inferred. The environment is provided by the other conjuncts occurring together with Head in the original logical form, together with other meaning postulates and the contents of the database. The method has been implemented in CLARE, a language and reasoning system whose linguistic component is the SRI Core Language Engine."
1992.tc-1.14,{E}nglish-{S}wedish translation of dialogue software,1992,9,2,4,0.952381,41856,hiyan alshawi,Proceedings of Translating and the Computer 14: Quality standards and the implementation of technology in translation,0,"The paper describes the BCI, a prototype interactive machine-translation system, constructed by connecting English and Swedish versions of the SRI Core Language Engine through a transfer component. Transfer takes place at the level of Quasi Logical Form (QLF), a contextually sensitive logical form representation which is deep enough for dealing with cross-linguistic differences. Theoretical arguments are presented to support the claim that QLF transfer represents a good compromise between the opposing paradigms of syntactic transfer and semantic interlinguabased MT. An annotated example dialogue is shown. A follow-on project, in which the BCI is used as the core of a spoken-language translation system, is briefly described."
P91-1021,Translation by Quasi Logical Form Transfer,1991,11,40,3,0.952381,41856,hiyan alshawi,29th Annual Meeting of the Association for Computational Linguistics,1,"The paper describes work on applying a general purpose natural language processing system to transfer-based interactive translation. Transfer takes place at the level of Quasi Logical Form (QLF), a contextually sensitive logical form representation which is deep enough for dealing with cross-linguistic differences. Theoretical arguments and experimental results are presented to support the claim that this framework has good properties in terms of modularity, compositionality, reversibility and monotonicity."
J90-2003,An Implementable Semantics for Comparative Constructions,1990,23,16,1,1,11421,manny rayner,Computational Linguistics,0,"We describe a comprehensive treatment of the syntax and semantics of comparative constructions based on theoretical work by Pinkham, which can be implemented in a relatively straightforward fashion within a feature-based phrase-structure grammar. Comparatives are divided up into clausal and phrasal constructions; in contrast to most previous theories, however, phrasals are not regarded as reduced forms of clausals. We begin by defining a Montagovian semantics for phrasal comparatives that directly links interpretation rules to the surface syntactic structure; we then show how this solution can be made computationally more efficient by factoring the interpretation through an intermediate level of representation, using a method similar to that used for dealing with scoping phenomena. Detailed examples are provided, showing how the method can correctly describe the semantics of a variety of superficially widely different comparative constructions. The ideas have all been implemented within a large-scale grammar for Swedish, a toy version of which is presented, along with examples of the output."
H90-1051,Using Explanation-Based Learning to Increase Performance in a Large-Scale {NL} Query System,1990,5,4,1,1,11421,manny rayner,"Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",0,"Explanation-based learning (EBL) is a machine-learning technique, closely connected to other techniques like macro-operator learning, chunking, and partial evaluation; a phrase we have found useful for describing the method to logic programmers is example-guided partial evaluation. The basic ideas of the method are well-described in an overview article which recently appeared in Artificial Intelligence [1], to which we refer the reader who wants to understand the theoretical principles; here, we will only summarize briefly what EBL means in the context of natural-language processing. A detailed presentation can be found in [3] and [4]."
P88-1007,Parsing and Interpreting Comparatives,1988,6,4,1,1,11421,manny rayner,26th Annual Meeting of the Association for Computational Linguistics,1,"We describe a fairly comprehensive handling of the syntax and semantics of comparative constructions. The analysis is largely based on the theory developed by Pinkham, but we advance arguments to support a different handling of phrasal comparatives - in particular, we use direct interpretation instead of C-ellipsis. We explain the reasons for dividing comparative sentences into different categories, and for each category we give an example of the corresponding Montague semantics. The ideas have all been implemented within a large-scale grammar for Swedish."
C88-2111,Using a Logic Grammar to Learn a Lexicon,1988,6,8,1,1,11421,manny rayner,{C}oling {B}udapest 1988 Volume 2: {I}nternational {C}onference on {C}omputational {L}inguistics,0,"It is suggested that the concept of logic grammar as relation between a string and a parse-tree can be extended by admitting the lexicon as part of the relation. This makes it possible to give a simple and elegant formulation of the process of infering a lexicon from example sentences in conjunction with a grammar. Various problems arising from implementation and complexity factors are considered, and examples are shown to support the claim that the method shows potential as a practical tool for automatic lexicon acquisition."
