2004.iwslt-evaluation.13,J90-2002,0,0.494047,"Missing"
2004.iwslt-evaluation.13,W99-0604,1,0.657673,"Missing"
2004.iwslt-evaluation.13,E99-1010,0,0.0439985,"Missing"
2004.iwslt-evaluation.13,W02-1021,1,0.117557,"Missing"
2004.iwslt-evaluation.13,N04-1021,0,0.0547991,"Missing"
2004.iwslt-evaluation.13,C04-1030,1,0.594268,"Missing"
2004.iwslt-evaluation.13,J97-3002,0,0.0526216,"Missing"
2004.iwslt-evaluation.13,takezawa-etal-2002-toward,0,0.0402389,"Missing"
2004.iwslt-evaluation.13,2003.mtsummit-papers.51,0,0.0619504,"Missing"
2004.iwslt-evaluation.13,P02-1040,0,\N,Missing
2004.iwslt-evaluation.13,P02-1038,1,\N,Missing
2004.iwslt-evaluation.13,P03-1021,0,\N,Missing
2004.iwslt-papers.7,J90-2002,0,0.250978,"some of the presented techniques. 2. Statistical Machine Translation 2.1. Word Alignment In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we choose the sentence with the highest probability:  eˆI1 = argmax P r(eI1 |f1J ) (1) eI1 = argmax eI1  P r(eI1 ) · P r(f1J |eI1 ) (2) The decomposition into two knowledge sources in Equation 2 is known as the source-channel approach to statistical machine translation [3]. It allows an independent modeling of the target language model P r(eI1 ) and translation model P r(f1J |eI1 ). The target language model describes the wellformedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The word alignment A is introduced into the translation model as a hidden variable: X P r(f1J |eI1 ) = P r(f1J , A|eI1 ) (3) A Usually, restricted alignments are used in the sense that each source word is aligned to at most one target word. Thus, an alignment A is a mapping from source sentence positions to"
2004.iwslt-papers.7,J93-2003,0,0.0389305,"ment A is introduced into the translation model as a hidden variable: X P r(f1J |eI1 ) = P r(f1J , A|eI1 ) (3) A Usually, restricted alignments are used in the sense that each source word is aligned to at most one target word. Thus, an alignment A is a mapping from source sentence positions to target sentence positions A = a1 ...aj ...aJ , (aj ∈ {0, . . . , I}). The alignment aJ1 may contain alignments aj = 0 with the ‘empty’ word e0 to account for source sentence words that are not aligned to any target word at all. A detailed comparison of the commonly used translation models IBM-1 to IBM-5 [4], as well as the Hidden-Markov alignment model (HMM) [5] can be found in [6]. All these models include parameters p(f |e) for the single-word based lexicon. They differ in the alignment model. All of the model parameters are trained iteratively with the EM-Algorithm. We follow the alignment template translation approach of [9], where a phrase tranlation model is used as one of the main features. The key elements of this translation approach are the alignment templates. These are pairs of source and target language phrases together with an alignment within the phrases. The phrases are extracted"
2004.iwslt-papers.7,C96-2141,1,0.642373,"den variable: X P r(f1J |eI1 ) = P r(f1J , A|eI1 ) (3) A Usually, restricted alignments are used in the sense that each source word is aligned to at most one target word. Thus, an alignment A is a mapping from source sentence positions to target sentence positions A = a1 ...aj ...aJ , (aj ∈ {0, . . . , I}). The alignment aJ1 may contain alignments aj = 0 with the ‘empty’ word e0 to account for source sentence words that are not aligned to any target word at all. A detailed comparison of the commonly used translation models IBM-1 to IBM-5 [4], as well as the Hidden-Markov alignment model (HMM) [5] can be found in [6]. All these models include parameters p(f |e) for the single-word based lexicon. They differ in the alignment model. All of the model parameters are trained iteratively with the EM-Algorithm. We follow the alignment template translation approach of [9], where a phrase tranlation model is used as one of the main features. The key elements of this translation approach are the alignment templates. These are pairs of source and target language phrases together with an alignment within the phrases. The phrases are extracted from the automatically estimated word alignments. The a"
2004.iwslt-papers.7,J03-1002,1,0.143593,"f1J |eI1 ) = P r(f1J , A|eI1 ) (3) A Usually, restricted alignments are used in the sense that each source word is aligned to at most one target word. Thus, an alignment A is a mapping from source sentence positions to target sentence positions A = a1 ...aj ...aJ , (aj ∈ {0, . . . , I}). The alignment aJ1 may contain alignments aj = 0 with the ‘empty’ word e0 to account for source sentence words that are not aligned to any target word at all. A detailed comparison of the commonly used translation models IBM-1 to IBM-5 [4], as well as the Hidden-Markov alignment model (HMM) [5] can be found in [6]. All these models include parameters p(f |e) for the single-word based lexicon. They differ in the alignment model. All of the model parameters are trained iteratively with the EM-Algorithm. We follow the alignment template translation approach of [9], where a phrase tranlation model is used as one of the main features. The key elements of this translation approach are the alignment templates. These are pairs of source and target language phrases together with an alignment within the phrases. The phrases are extracted from the automatically estimated word alignments. The alignment templates a"
2004.iwslt-papers.7,P02-1038,1,0.627781,"word penalty and alignment template penalty feature functions. To model the alignment template reorderings, we use a feature function that penalizes reorderings linear in the jump width. We use a dynamic programming beam search algorithm to generate the translation hypothesis with maximum probability. This search algorithm allows for arbitrary reorderings at the level of alignment templates. Within the alignment templates, the word order is learned in training and kept fix during the search process. This is only a brief description of the alignment template approach. For further details, see [9, 7]. 3. Acquiring Additional Training Data 2.2. Translation: Alignment Template Approach The argmax operation in Eq. 2 denotes the search problem, i.e. the generation of the output sentence in the target language. We have to maximize over all possible target language sentences. For the search, we choose an alternative to the classical source-channel approach and model the posterior probability P r(eI1 |f1J ) directly. Using a log-linear model [7], we obtain: ! M X I J J I J P r(e1 |f1 ) = Z(f1 ) · exp λm hm (e1 , f1 ) m=1 Here, Z(f1J ) denotes the appropriate normalization constant, hm are the fe"
2004.iwslt-papers.7,P03-1021,0,0.0274503,"h and model the posterior probability P r(eI1 |f1J ) directly. Using a log-linear model [7], we obtain: ! M X I J J I J P r(e1 |f1 ) = Z(f1 ) · exp λm hm (e1 , f1 ) m=1 Here, Z(f1J ) denotes the appropriate normalization constant, hm are the feature functions and λm are the corresponding scaling factors. We thus arrive at the decision rule: ( M ) X I I J eˆ1 = argmax λm hm (e1 , f1 ) eI1 to the maximum entropy principle, e.g. using the Generalized Iterative Scaling (GIS) algorithm. Alternatively, one can train them with respect to the final translation quality measured by some error criterion [8]. m=1 This approach has the advantage that additional models or feature functions can be easily integrated into the overall system. The model scaling factors λM 1 are trained according 140 When only a small corpus of sentence pairs is available for training of the statistical translation models, it may be reasonable to include additional bilingual training data from other sources. Since this additional data may come from another domain and substantially differ from the original training corpus, a method for selecting relevant sentences is desirable. In our experiments, we use a relevance measu"
2004.iwslt-papers.7,W99-0604,1,0.944144,"...aj ...aJ , (aj ∈ {0, . . . , I}). The alignment aJ1 may contain alignments aj = 0 with the ‘empty’ word e0 to account for source sentence words that are not aligned to any target word at all. A detailed comparison of the commonly used translation models IBM-1 to IBM-5 [4], as well as the Hidden-Markov alignment model (HMM) [5] can be found in [6]. All these models include parameters p(f |e) for the single-word based lexicon. They differ in the alignment model. All of the model parameters are trained iteratively with the EM-Algorithm. We follow the alignment template translation approach of [9], where a phrase tranlation model is used as one of the main features. The key elements of this translation approach are the alignment templates. These are pairs of source and target language phrases together with an alignment within the phrases. The phrases are extracted from the automatically estimated word alignments. The alignment templates are build at the level of word classes, which improves their generalization capability. Besides the alignment template translation model probabilities, we use additional feature functions. These are the word translation model and two language models: a"
2004.iwslt-papers.7,2001.mtsummit-papers.68,0,0.0231131,"and substantially differ from the original training corpus, a method for selecting relevant sentences is desirable. In our experiments, we use a relevance measure of ngram coverage. To this end, we compute the set C of ngrams occurring in the source part of the initial training corpus (n = 1, 2, 3, 4). Then, for each candidate source sentence in the additional corpus, we compute a score based on the occurrence of the n-grams from C in that sentence. The score is defined as the geometric mean of n-gram precisions and is therefore similar to the BLEU score used in machine translation evaluation [10]. Such score provides a quantitative measure of how “out-of-domain” or “in-domain” the additional training data may be. We add only those sentence pairs to the initial training corpus, for which this score is sufficiently high. 4. Morphological Information for Word Alignments 4.1. Lexicon Smoothing Existing statistical translation systems usually treat different derivations of the same base form as they were independent of each other. In our approach, the dependencies between such derivations are taken into account during the EM training of the statistical alignment models. Typically, the stat"
2004.iwslt-papers.7,P00-1056,1,0.650352,"word alignment quality on the Verbmobil task. The German– English Verbmobil task [13] is a speech translation task in the domain of appointment scheduling, travel planning and hotel reservation. The corpus statistics are shown in Table 1. The number of running words and the vocabularies are based on full-form words including punctuation marks. As in [6], the first 100 sentences of the alignment test corpus are used as a development corpus to optimize model parameters that are not trained via the EM algorithm, e.g. the smoothing parameters. We use the same evaluation criterion as described in [14]. The generated word alignment is compared to a reference alignment which is produced by human experts. The obtained reference alignment may contain many-to-one and one-to-many relationships and includes sure (S) and possible (P) alignment points. The quality of an alignment A is computed as appropriately redefined precision and recall measures. We also use the alignment error rate (AER), which is derived from the well-known F-measure. |A ∩ S| |A ∩ P | , precision = |S| |A| |A ∩ S |+ |A ∩ P | AER(S, P ; A) = 1 − |A |+ |S| recall = With these definitions a recall error can only occur if a S(ure"
2004.iwslt-papers.7,W01-1407,1,\N,Missing
2004.iwslt-papers.7,P02-1040,0,\N,Missing
2005.eamt-1.25,W00-0508,0,0.0457912,"Missing"
2005.eamt-1.25,P04-1065,1,0.890111,"Missing"
2005.eamt-1.25,knight-al-onaizan-1998-translation,0,0.0852462,"Missing"
2005.eamt-1.25,N03-1019,0,0.113584,"Missing"
2005.eamt-1.25,C04-1032,1,0.835675,"ed with one target word (e. g. translating an English noun phrase into a German compound). The second case usually involves non-literal phrase-to-phrase translations, when translating individual source words does not convey the meaning of the source phrase. An example of the source sentence reordering, as well as of the three described bilingual corpus representations, labeled with (A),(B), and (C), respectively, is given in Figure 1. In our approach, we can avoid various heuristics and learn these and other types of corpus representations by using a flexible alignment framework presented in (Matusov et al., 2004). Following this work, we efficiently compute optimal, minimumcost alignments which satisfy certain constraints. The constraints may include the requirement for each word to be aligned at least once, functional form or full monotonicity. Local alignment costs between a source word fj and a target word ei are estimated statistically using state occupation probabilities of the HMM and IBM-4 models as trained by the GIZA++ toolkit (Och et al., 2003). 2.3 Optimization Criterion Using one of the corpus representations (f˜, e˜) via a certain (constrained) alignment A, we rewrite the joint translatio"
2005.eamt-1.25,J03-1002,1,0.01143,"Missing"
2005.eamt-1.25,J04-4002,1,0.719465,"Missing"
2005.eamt-1.25,P02-1040,0,0.0940792,"r the BTEC corpus are given in Table 1. We evaluate the impact of the proposed reordering restrictions on the CSTAR 2003 test set with 506 Chinese sentences and 16 reference translations. We also present results on the Verbmobil task (Wahlster, 2000). The domain of this corpus is appointment scheduling, travel planning, and hotel reservation. It consists of transcriptions of spontaneous speech. Table 2 shows the statistics of this corpus. 5.2 Evaluation Criteria For the automatic evaluation, we used the word error rate (WER), position-independent word error 186 rate (PER), and the BLEU score (Papineni et al., 2002). This score measures accuracy, i. e. larger scores are better. The three measures were computed with respect to multiple reference translations, when they were available. To indicate this, we will label the error rate acronyms with an m. On the Chinese-to-English BTEC task, both training and evaluation were performed using corpora and references in lowercase and without punctuation marks. 5.3 Experiments As described in Sec. 2.2, we reordered the source sentences in training. We then created a bilingual corpus of tuples (fj , e˜j ) (i. e. representation (B) in Figure 1) based on a fully monot"
2005.iwslt-1.18,P03-1021,0,0.0418797,"0]. A phrase is a contiguous sequence of words. The pairs of source and target phrases are extracted from the training corpus and used in the translation. The phrase translation probability P r(eI1 |f1J ) is modeled directly using a weighted log-linear combination of a trigram language model and various translation models: a phrase translation model and a word-based lexicon model. These translation models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The model scaling factors are optimized with respect to some evaluation criterion [11]. 1 The notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). 3. Segmentation methods 3.1. Conventional segmentation methods In this section, we give a short overview of the current Chinese word segmentation methods in statistical machine translation, most of these methods can be classified into three categories: • The training and test texts are segmented with an automatic segmentation tool. Many segmentation to"
2005.iwslt-1.18,W04-1118,1,0.652012,"may contain some errors, and we also found that a much more accurate word segmentation does not always lead to a large improvement in the translation performance. • The training and test texts are segmented manually. Manual segmentation avoids segmentation errors but requires a human effort. Moreover, the correct segmentation will not result in the best translation result, if the segmentations in the test and training sets are inconsistent. • Each Chinese character is treated as a word Training and translation at the Chinese character level do not require additional tool or human effort. But [1] showed that the translation results are not so good as the results obtained when translation is at the word level. To minimize the number of lexicon entries and to ensure the consistency of the segmentations in the training and in the translation, we developed a new segmentation method, which uses the training text at the word level and translate the test text at the character level. 3.2. Idea Figure 1 shows the translation procedures. With the conventional method, only a single-best word segmentation is transferred to the search for the best translation. This approach is not ideal because th"
2005.iwslt-1.18,P02-1040,0,0.101372,"ed word segmentation in the translation, we only need to read segmentation lattice in Figure 3 instead of the manual segmented sentence. 4.2. Evaluation criteria ?:? xu:xu shou:shou ji:ji deng:deng li:li na:nali ban:ban li:eps li:li na:na ban:banli zai:zai li:eps 0 deng:dengji ji:eps shou:shouxu xu:eps 1 2 3 4 Figure 5: Segmentation transducer. So far, in machine translation research, a single generally accepted criterion for the evaluation of the experimental results does not exist. Therefore, we used different criteria: WER (word error rate), PER (position-independent word error rate), BLEU [12] and NIST [13]. For the evaluation corpus, we have sixteen references available. The four criteria are computed with respect to multiple references. The evaluation was case-insensitive. The BLEU and NIST scores measure accuracy, i.e. larger scores are better. 4.3. Evaluation results We present the translation results on the IWSLT 2005 task [4] described in Section 4.1. The experiments are based on two translation systems: • Finite-state transducer-based translation 3.5. Weighting with language model costs A problem of translation with the lattice in Figure 3 is that shorter paths are usually p"
2005.iwslt-1.18,P96-1019,0,0.0862748,"Missing"
2005.iwslt-1.18,J90-2002,0,0.555513,"on 4. 2. Statistical machine translation system 2.1. Bayes decision rule In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª ˆ eˆI1 = argmax P r(eI1 |f1J ) (1) eI1 ,I = argmax eI1 ,I © P r(eI1 ) · P r(f1J |eI1 ) ª (2) The decomposition into two knowledge sources in Equation 2 is known as the source-channel approach to statistical machine translation [5]. It allows an independent modelSingle-best segmentation: T ext / Segmentation: Equation 3 Segmentation lattice: T ext / Global decision: Equation 6 / Decision: Equation 5 / T ranslation / T ranslation Figure 1: Segmentation methods ing of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . In our system, the translation model is trained on a bilingual corpus using GIZA++ [6], and the language model is trained with the SRILM toolkit [7]. 2.2. Weighted finite-state transducer-based translation We use the weighted finite-state tool by [8]. A weighted finite-state tran"
2005.iwslt-1.18,J03-1002,1,0.011191,") eI1 ,I = argmax eI1 ,I © P r(eI1 ) · P r(f1J |eI1 ) ª (2) The decomposition into two knowledge sources in Equation 2 is known as the source-channel approach to statistical machine translation [5]. It allows an independent modelSingle-best segmentation: T ext / Segmentation: Equation 3 Segmentation lattice: T ext / Global decision: Equation 6 / Decision: Equation 5 / T ranslation / T ranslation Figure 1: Segmentation methods ing of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . In our system, the translation model is trained on a bilingual corpus using GIZA++ [6], and the language model is trained with the SRILM toolkit [7]. 2.2. Weighted finite-state transducer-based translation We use the weighted finite-state tool by [8]. A weighted finite-state transducer (Q, Σ ∪ {}, Ω ∪ {}, K, E, i, F, λ, ρ) is a structure with a set of states Q, an alphabet of input symbols Σ, an alphabet of output symbols Ω, a weight semiring K, a set of arcs E, a single initial state i with weight λ and a set of final states F weighted by the function ρ : F → K. A weighted finite-state acceptor is a weighted finite-state transducer without the output alphabet. A composition"
2005.iwslt-1.18,P04-1065,1,0.420284,"atistical machine translation [5]. It allows an independent modelSingle-best segmentation: T ext / Segmentation: Equation 3 Segmentation lattice: T ext / Global decision: Equation 6 / Decision: Equation 5 / T ranslation / T ranslation Figure 1: Segmentation methods ing of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . In our system, the translation model is trained on a bilingual corpus using GIZA++ [6], and the language model is trained with the SRILM toolkit [7]. 2.2. Weighted finite-state transducer-based translation We use the weighted finite-state tool by [8]. A weighted finite-state transducer (Q, Σ ∪ {}, Ω ∪ {}, K, E, i, F, λ, ρ) is a structure with a set of states Q, an alphabet of input symbols Σ, an alphabet of output symbols Ω, a weight semiring K, a set of arcs E, a single initial state i with weight λ and a set of final states F weighted by the function ρ : F → K. A weighted finite-state acceptor is a weighted finite-state transducer without the output alphabet. A composition algorithm is defined as: Let T1 : Σ∗ × Ω → K and T2 : Ω∗ × Γ∗ → K be two transducers defined over the same semiring K. Their composition T1 ◦T2 realizes the functio"
2005.iwslt-1.18,N04-1033,1,0.737334,"by the function ρ : F → K. A weighted finite-state acceptor is a weighted finite-state transducer without the output alphabet. A composition algorithm is defined as: Let T1 : Σ∗ × Ω → K and T2 : Ω∗ × Γ∗ → K be two transducers defined over the same semiring K. Their composition T1 ◦T2 realizes the function T : Σ∗ × Γ∗ → K. ∗ By using the structure of the weighted finite-state transducers, the translation model is simply estimated as the language model on a bilanguage of source phrase/target phrase tuples, see [9]. 2.3. Phrase-based translation The phrase-based translation model is described in [10]. A phrase is a contiguous sequence of words. The pairs of source and target phrases are extracted from the training corpus and used in the translation. The phrase translation probability P r(eI1 |f1J ) is modeled directly using a weighted log-linear combination of a trigram language model and various translation models: a phrase translation model and a word-based lexicon model. These translation models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The model scaling factors are optimized with respect to some evaluation criterion [1"
2005.iwslt-1.19,2001.mtsummit-papers.68,0,0.136167,"h the human judgement at least as well as the evaluation measures which are based on manual sentence boundaries. 1. Introduction Evaluation of the produced results is crucial for natural language processing (NLP) research in general and, in particular for machine translation (MT). Human evaluation of MT system output is a time consuming and expensive task. This is why automatic evaluation is preferred to human evaluation in the research community. A variety of automatic evaluation measures have been proposed and studied over the last years. All of the wide-spread evaluation measures like BLEU [1], NIST [2], and word error rate compare translation hypotheses with human reference translations. Since a human translator usually translates one sentence of a source language text at a time, all of these measures include the concept of sentences, or more generally, segments1 . Each evaluation algorithm expects that a machine translation system will produce exactly one target language segment for each source language segment. Thus, the total number of segments in the automatically translated document must be equal to the number of reference segments in the manually translated document. In case"
2005.iwslt-1.19,W05-0903,1,0.810929,"same number of segments, where each segment is a translation of the “correct” segmentation of the manually transcribed speech input2 . If the segmentation of the MT output corresponds to the segmentation of the manual reference translations, then for each candidate segerk . Let Ik denote ment Ek , we have R reference sentences E the length of a candidate segment Ek , and Nrk the reference erk . From the reference lengths of each reference segment E lengths, an optimal reference segment length Nk∗ is selected as the length of the reference with the lowest segment-level error rate or best score [4]. With this, we write P the total candidate length over the document as I := k Ik , and the total reference length as P N ∗ := k Nk∗ . 2.1. W ER The segment-level word error rate is defined as the Levenerk ) between a candidate segment shtein distance dL (Ek , E erk , divided by the reference Ek and a reference segment E length Nk∗ for normalization. For a whole candidate corpus with multiple references, the segment-level scores are combined, and the W ER is defined to be: ¡ ¢ 1 X erk W ER := ∗ min dL Ek , E r N (1) k In this paper, we also evaluate MT output at document level. When evaluating"
2005.iwslt-1.19,2004.iwslt-evaluation.1,0,0.0265168,"ndaries from the candidate translations and determined the segmentation automatically using the Levenshtein distance based algorithm as described in Section 3. As a consequence of the alignment procedure we obtained the AS-WER. In addition, using the resulting automatic segmentation which corresponds to the segmentation of the reference documents, we recomputed the other evaluation measures. In the following, we denote these measures by AS-PER, AS-BLEU, and AS-NIST. We calculated the evaluation measures on two different tasks. The first task is the IWSLT BTEC 2004 Chinese-toEnglish evaluation [8]. Here, we evaluated translation output of twenty MT systems which had participated in this public evaluation. The evaluation was case-insensitive, and the translation hypotheses and references did not include punctuation marks. Additionally, we scored the translations of four MT systems from different research groups which took part in the first MT evaluation in the framework of the European research project TC-STAR [9]. We addressed only the condition of translating verbatim (exactly transcribed) speech from Spanish to English. Here, the evaluation was case-sensitive, but again without consi"
2005.iwslt-1.19,P02-1040,0,\N,Missing
2005.iwslt-1.20,1998.amta-tutorials.6,0,0.566661,"Missing"
2005.iwslt-1.20,J90-2002,0,0.695619,". Additionally, we translated Chinese ASR lattices. 1.1. Source-channel approach to SMT In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª ˆ eˆI1 = argmax P r(eI1 |f1J ) (1) I,eI1 = argmax I,eI1 © P r(eI1 ) · P r(f1J |eI1 ) ª (2) This decomposition into two knowledge sources is known as the source-channel approach to statistical machine translation [1]. It allows an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. 1.2. Log-linear model 1. Introduction We give an overview of the RWTH phrase-based statistical machine translation system that was used in the evaluation campaign of the International W"
2005.iwslt-1.20,P02-1038,1,0.79314,"ll review the statistical approach to machine translation and introduce the notation that we will use in the later sections. Then, we will describe the models and algorithms that are used for generating the N -best lists, i.e., the first pass. In Section 4, we will describe the models that are used to rescore and rerank this N -best list, i.e., the second pass. Afterward, we will give an overview of the tasks and discuss the experimental results. An alternative to the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model [2], we obtain: ´ P M J I ) , f exp λ h (e m m 1 1 m=1 P ´ P r(eI1 |f1J ) = P (3) M J 0I0 exp m=1 λm hm (e 1 , f1 ) e0 I1 0 The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X ˆ eˆI1 = argmax λm hm (eI1 , f1J ) (4) I,eI1 1 The m=1 notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p"
2005.iwslt-1.20,P03-1021,0,0.0758006,"follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). This approach is a generalization of the source-channel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion [3]. For the IWSLT evaluation campaign, we optimized the scaling factors with respect to a linear interpolation of WER, PER, BLEU and NIST using the Downhill Simplex algorithm from [4]. 1.3. Phrase-based approach The basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and finally compose the target sentence from these phrase translations. This idea is illustrated in Figure 1. Formally, we define a segmentation of a given sentence pair (f1J , eI1 ) into K blocks: k → sk := (ik ; bk , jk ), for k = 1 . . . K. (5) Here, ik denotes t"
2005.iwslt-1.20,2002.tmi-tutorials.2,0,0.161904,"get sentence are covered by exactly one phrase. Thus, there are no gaps and there is no overlap. For a given sentence pair (f1J , eI1 ) and a given segmentation sK 1 , we define the bilingual phrases as: e˜k f˜k := eik−1 +1 . . . eik (6) := fbk . . . fjk (7) target positions I = i4 i3 2. Search algorithms The RWTH phrase-based system supports two alternative search strategies that will be described in this section. Translating a source language word graph. The first search strategy that our system supports takes a source language word graph as input and translates this graph in a monotone way [5]. The input graph can represent different reorderings of the input sentence so that the overall search can generate nonmonotone translations. Using this approach, it is very simple to experiment with various reordering constraints, e.g., the constraints proposed in [6]. Alternatively, we can use ASR lattices as input and translate them without changing the search algorithm, cf. [7]. A disadvantage when translating lattices with this method is that the search is monotone. To overcome this problem, we extended the monotone search algorithm from [5, 7] so that it is possible to reorder the target"
2005.iwslt-1.20,W05-0831,1,0.219539,"itions I = i4 i3 2. Search algorithms The RWTH phrase-based system supports two alternative search strategies that will be described in this section. Translating a source language word graph. The first search strategy that our system supports takes a source language word graph as input and translates this graph in a monotone way [5]. The input graph can represent different reorderings of the input sentence so that the overall search can generate nonmonotone translations. Using this approach, it is very simple to experiment with various reordering constraints, e.g., the constraints proposed in [6]. Alternatively, we can use ASR lattices as input and translate them without changing the search algorithm, cf. [7]. A disadvantage when translating lattices with this method is that the search is monotone. To overcome this problem, we extended the monotone search algorithm from [5, 7] so that it is possible to reorder the target phrases. We implemented the following idea: while traversing the input graph, a phrase can be skipped and processed later. Source cardinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceed"
2005.iwslt-1.20,J03-1005,1,0.786355,"s, e.g., the constraints proposed in [6]. Alternatively, we can use ASR lattices as input and translate them without changing the search algorithm, cf. [7]. A disadvantage when translating lattices with this method is that the search is monotone. To overcome this problem, we extended the monotone search algorithm from [5, 7] so that it is possible to reorder the target phrases. We implemented the following idea: while traversing the input graph, a phrase can be skipped and processed later. Source cardinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [9]. Word graphs and N -best lists. The two described search algorithms generate a word graph containing the most likely translation hypotheses. Out of this word graph we extract N -best lists. For more details on word graphs and N best list extraction, see [10, 11]. 3. Models used during search i2 i1 0 = i0 0 = j 0 j2 b2 b1 only on the sentence pair (f1J"
2005.iwslt-1.20,C04-1030,1,0.855321,"To overcome this problem, we extended the monotone search algorithm from [5, 7] so that it is possible to reorder the target phrases. We implemented the following idea: while traversing the input graph, a phrase can be skipped and processed later. Source cardinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [9]. Word graphs and N -best lists. The two described search algorithms generate a word graph containing the most likely translation hypotheses. Out of this word graph we extract N -best lists. For more details on word graphs and N best list extraction, see [10, 11]. 3. Models used during search i2 i1 0 = i0 0 = j 0 j2 b2 b1 only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). j1 j3 j4 = J b3 b4 source positions Figure 1: Illustration of the phrase segmentation. Note that the segmentation sK 1 contains the information on the phra"
2005.iwslt-1.20,W05-0834,1,0.835929,"rdinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [9]. Word graphs and N -best lists. The two described search algorithms generate a word graph containing the most likely translation hypotheses. Out of this word graph we extract N -best lists. For more details on word graphs and N best list extraction, see [10, 11]. 3. Models used during search i2 i1 0 = i0 0 = j 0 j2 b2 b1 only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). j1 j3 j4 = J b3 b4 source positions Figure 1: Illustration of the phrase segmentation. Note that the segmentation sK 1 contains the information on the phrase-level reordering. The segmentation sK 1 is introduced as a hidden variable in the translation model. Therefore, it would be theoretically correct to sum over all possible segmentations. In practice, we use the maximum approximation for this sum. As a result, t"
2005.iwslt-1.20,W02-1021,1,0.799925,"rdinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [9]. Word graphs and N -best lists. The two described search algorithms generate a word graph containing the most likely translation hypotheses. Out of this word graph we extract N -best lists. For more details on word graphs and N best list extraction, see [10, 11]. 3. Models used during search i2 i1 0 = i0 0 = j 0 j2 b2 b1 only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). j1 j3 j4 = J b3 b4 source positions Figure 1: Illustration of the phrase segmentation. Note that the segmentation sK 1 contains the information on the phrase-level reordering. The segmentation sK 1 is introduced as a hidden variable in the translation model. Therefore, it would be theoretically correct to sum over all possible segmentations. In practice, we use the maximum approximation for this sum. As a result, t"
2005.iwslt-1.20,N04-1033,1,0.843447,"tion. Note that the segmentation sK 1 contains the information on the phrase-level reordering. The segmentation sK 1 is introduced as a hidden variable in the translation model. Therefore, it would be theoretically correct to sum over all possible segmentations. In practice, we use the maximum approximation for this sum. As a result, the models h(·) depend not We use a log-linear combination of several models (also called feature functions). In this section, we will describe the models that are used in the first pass, i.e., during search. This is an improved version of the system described in [12]. More specifically the models are: a phrase translation model, a word-based translation model, a deletion model, word and phrase penalty, a target language model and a reordering model. 3.1. Phrase-based model The phrase-based translation model is the main component of our translation system. The hypotheses are generated by concatenating target language phrases. The pairs of source and corresponding target phrases are extracted from the wordaligned bilingual training corpus. The phrase extraction algorithm is described in detail in [5]. The main idea is to extract phrase pairs that are consis"
2005.iwslt-1.20,W99-0604,1,0.92093,"del The phrase-based translation model is the main component of our translation system. The hypotheses are generated by concatenating target language phrases. The pairs of source and corresponding target phrases are extracted from the wordaligned bilingual training corpus. The phrase extraction algorithm is described in detail in [5]. The main idea is to extract phrase pairs that are consistent with the word alignment. Thus, the words of the source phrase are aligned only to words in the target phrase and vice versa. This criterion is identical to the alignment template criterion described in [13]. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = N (f˜, e˜) N (˜ e) (8) Here, the number of co-occurrences of a phrase pair (f˜, e˜) that are consistent with the word alignment is denoted as N (f˜, e˜). If one occurrence of a target phrase e˜ has N &gt; 1 possible translations, each of them contributes to N (f˜, e˜) with 1/N . The marginal count N (˜ e) is the number of occurrences of the target phrase e˜ in the training corpus. The resulting feature function is: hPhr (f1J , eI1 , sK 1 ) = log K Y p(f˜k |˜ ek ) (9) The word translation probabilities p(f"
2005.iwslt-1.20,2004.iwslt-evaluation.13,1,0.873901,", eI1 , sK 1 ) = log jk K Y Y ik X p(fj |ei ) (10) k=1 j=bk i=ik−1 +1 The word translation probabilities p(f |e) are estimated as relative frequencies from the word-aligned training corpus. The word-based lexicon model is also used in both directions p(f |e) and p(e|f ). 3.3. Deletion model The deletion model [14] is designed to penalize hypotheses that miss the translation of a word. For each source word, we check if a target word with a probability higher than a given threshold τ exists. If not, this word is considered a deletion. The feature simply counts the number of deletions. Last year [15], we used this model during rescoring only, whereas this year, we integrated a within-phrase variant of the deletion model into the search: hDel (f1J , eI1 , sK 1 )= jk K X X ik Y k=1 j=bk i=ik−1 +1 [ p(fj |ei ) &lt; τ ] (11) 3.5. Target language model We use the SRI language modeling toolkit [17] to train a standard n-gram language model. The smoothing technique we apply is the modified Kneser-Ney discounting with interpolation. The order of the language model depends on the translation direction. For most tasks, we use a trigram model, except for Chinese-English, where we use a fivegram languag"
2005.iwslt-1.20,2005.eamt-1.17,1,0.801958,"techniques need specialized tools which traverse the graph appropriately. Additionally, because a node within a word graph allows for many histories, one can only apply local rescoring techniques, whereas for N -best lists, techniques can be used that consider properties of the whole target sentence. In the next sections, we will present several rescoring techniques. 4.1. Clustered language models One of the first ideas in rescoring is to use additional language models that were not used in the generation procedure. In our system, we use clustered language models based on regular expressions [18]. Each hypothesis is classified by matching it to regular expressions that identify the type of the sentence. Then, a cluster-specific (or sentence-type-specific) language model is interpolated into a global language model to compute the score of the sentence: hCLM (f1J , eI1 ) = (17) X£ ¤¡ ¢ I I I log Rc (e1 ) αc pc (e1 ) + (1 − αc )pg (e1 ) , c pg (eI1 ) I where is the global language ¤ pc (e1 ) the £ model, I cluster-specific language model, and Rc (e1 ) denotes the true-or-false statement (cf. Equation 12) which is 1 if the cth regular expression Rc (·) matches the target sentence eI1 and"
2005.iwslt-1.20,J03-1002,1,0.116578,"τ . In the experiments, τ was chosen between 10−1 and 10−4 . 4.4. Hidden Markov alignment model The next step after IBM model 1 rescoring is HMM rescoring. We use the HMM to compute the log-likelihood of a 2 The clusters are disjunct, thus only one regular expression matches. sentence pair (f1J , eI1 ): hHMM (f1J , eI1 ) = log J XY ¡ p(aj |aj−1 , I) · p(fj |eaj ) ¢ j=1 aJ 1 (20) In our experiments, we use a refined alignment probability p(aj − aj−1 |G(eaj ), I) that conditions the jump widths of the alignment positions aj − aj−1 on the word class G(eaj ). This is the so-called homogeneous HMM [19]. 4.5. Word penalties Several word penalties are used in the rescoring step:  (a)  I I/J (b) hWP (f1J , eI1 ) =  2|I − J|/(I + J) (c) (21) The word penalties are heuristics that affect the generated hypothesis length. In general, sentences that are too short should be avoided. 5. Integrating ASR and MT In the experiments on coupling speech recognition and machine translation, we used the phrase-based MT system described in Section 2 to translate ASR lattices. In addition to the models described in Section 3, we use the acoustic model and the source language model of the ASR system in the lo"
2005.iwslt-1.20,takezawa-etal-2002-toward,0,0.0815201,"g speech recognition and translation is the mismatch between the vocabularies of the ASR and MT system. For the Chinese-English task, the number of out-of-vocabulary (OOV) words was rather high. Ideally, the vocabulary of the recognition system should be a subset of the translation system source vocabulary. In the IWSLT evaluation, we had no control over the recognition experiments. For this reason, the reported improvements might have been larger with a proper handling of the vocabularies. 6. Tasks and corpora The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task [20]. This is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. The corpus statistics are shown in Table 1. For the supplied data track, 20 000 sentences training corpus and two test sets (C-Star’03 and IWSLT’04) were made available for each language pair. As additional training resources for the C-Star track, we used the full BTEC for Japanese-English and the Spoken Language DataBase (SLDB) [21], which consists of transcriptions of spoken dialogs in the domain of hotel reservations3 . 3 The Japanese-English training corpora (BTE"
2005.iwslt-1.20,P02-1040,0,0.119193,"Missing"
2005.iwslt-1.20,W05-0909,0,0.0806623,"Missing"
2005.iwslt-1.20,2003.mtsummit-papers.51,0,0.106807,"Missing"
2005.mtsummit-papers.34,J93-2003,0,0.0128844,"uation results. 1 The structure of the paper is as follows: In Section 2 we will describe the statistical approach to machine translation and in Section 3 further methods used in our translation system. The EPPS databases and experimental results will be presented in Section 4. We will draw conclusions in the last Section. 2 Statistical Machine Translation In a machine translation framework we are given a sentence f1J = f1 . . . fJ in a source language that is to be translated as sentence eI1 = e1 . . . eI into a target language (f and e stand for ‘French’ and ‘English’ in the original paper (Brown et al., 1993)). For the statistical approach, we use Bayes decision rule which states that we should choose the sentence that maximizes the posterior probability eˆI1 = argmax p(eI1 |f1J ) (1) eI1 = argmax p(eI1 )p(f1J |eI1 ) , (2) eI1 Introduction Speech-to-speech translation is an outstanding reasearch goal in the machine translation community. Up to now, most of the projects dealing with this issue have dealt only with artiﬁcial or very limited tasks (Wahlster, 2000; EuTransProject, 2000; Lavie et al., 2001; Ueﬃng and Ney, 2005). The goal of the TC-Star project is to build a speech-to-speech translation"
2005.mtsummit-papers.34,2005.eamt-1.17,1,0.776963,"IBM1 Rescoring Although the IBM1 model is the easiest one of the single-word based translation models and the phrase based models clearly outperform this approach, the inclusion of the scores of this 261 model, i.e. hIBM1 (f1J |eI1 ) = I J   1 p(fj |ei ) (I + 1)J (6) j=1 i=0 has been shown experimentally to improve the performance of a machine translation system (Och et al., 2003). 3.5 LM Rescoring During the generation process, a single language model is used. However, additional language models speciﬁc to each sentence to be translated can help to improve the machine translation quality (Hasan and Ney, 2005). The motivation behind this lies in the following observation: the syntactic structure of a sentence is inﬂuenced by its type. It is obvious that an interrogative sentence has a diﬀerent structure from a declarative one due to non-local dependencies arising e.g. from wh-extraction. As an example, let us consider the syntax of the following sentences: “Is the commissioner ready to give an undertaking?” and “The commissioner is ready to give an undertaking.” If we look closer at the ﬁrst four words of each sentence (is, the, commissioner and ready), the trigrams observed are quite diﬀerent, lea"
2005.mtsummit-papers.34,H01-1007,0,0.0254038,". . . eI into a target language (f and e stand for ‘French’ and ‘English’ in the original paper (Brown et al., 1993)). For the statistical approach, we use Bayes decision rule which states that we should choose the sentence that maximizes the posterior probability eˆI1 = argmax p(eI1 |f1J ) (1) eI1 = argmax p(eI1 )p(f1J |eI1 ) , (2) eI1 Introduction Speech-to-speech translation is an outstanding reasearch goal in the machine translation community. Up to now, most of the projects dealing with this issue have dealt only with artiﬁcial or very limited tasks (Wahlster, 2000; EuTransProject, 2000; Lavie et al., 2001; Ueﬃng and Ney, 2005). The goal of the TC-Star project is to build a speech-to-speech translation system that can deal with real life data. For this purpose we have collected data from parliamentary speeches held in the European Parliament Plenary Sessions (EPPS) to build an open domain corpus. There are three different versions of the data, the oﬃcial version of the speeches as available on the web page of the European Parliament, the actual exact transcription of the speeches produced by human transcribers and the output of an automatic speech recognition system. We evaluate our system unde"
2005.mtsummit-papers.34,P02-1038,1,0.542956,"ord based models2 in both directions (source-totarget and target-to-source) and combining the two obtained alignments (Och and Ney, 2003). Given this alignment an extraction of contiguous phrases is carried out and their probabilities are computed by mean of relative frequencies (Zens and Ney, 2004). An example of an alignment between two sentences and a (possible) set of phrases to be extracted is shown in Figure 2. 3.2 Log-linear Model As an alternative to the traditional sourcechannel approach given in Equation (2) we can model the translation probability directly using a log-linear model (Och and Ney, 2002):   M I, fJ) exp λ h (e m m 1 1 m=1  , p(eI1 |f1J ) =  M I, fJ) exp λ h (˜ e m=1 m m 1 1 I e˜1 (5) 2 Usually the used models are IBM-1, HMM and IBM-4. with hm diﬀerent models, λm scaling factors and the denominator a normalization factor that can be ignored in the maximization process. We choose the λm by optimizing a performance measure over a development corpus using the downhill simplex algorithm as presented in (Press et al., 2002). The source-channel model (2) is a special case of (5) with appropriate feature functions. The log-linear model, however, has the advantage that addition"
2005.mtsummit-papers.34,J03-1002,1,0.010911,"context into the translation model is to learn translations for whole phrases instead of single words. Here, a phrase is simply a sequence of words, no other linguistic meaning is required. So, the basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and ﬁnally compose the target sentence from these phrase translations. First an alignment between source and target sentence is found by using a chain of single-word based models2 in both directions (source-totarget and target-to-source) and combining the two obtained alignments (Och and Ney, 2003). Given this alignment an extraction of contiguous phrases is carried out and their probabilities are computed by mean of relative frequencies (Zens and Ney, 2004). An example of an alignment between two sentences and a (possible) set of phrases to be extracted is shown in Figure 2. 3.2 Log-linear Model As an alternative to the traditional sourcechannel approach given in Equation (2) we can model the translation probability directly using a log-linear model (Och and Ney, 2002):   M I, fJ) exp λ h (e m m 1 1 m=1  , p(eI1 |f1J ) =  M I, fJ) exp λ h (˜ e m=1 m m 1 1 I e˜1 (5) 2 Usually the"
2005.mtsummit-papers.34,P02-1040,0,0.0715923,"ion. Sentence pairs Running Words Running Words without Punct. Marks Vocabulary Singletons Spanish English 1 207 740 34 851 423 33 335 048 31 360 260 30 049 355 139 587 93 995 48 631 33 891 Table 2: Statistics of the EPPS training corpus. order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. The PER compares the words in the two sentences ignoring the word order. • BLEU and NIST scores: These scores are a weighted n-gram precision in combination with a penalty for sentences which are too short, and were deﬁned in (Papineni et al., 2002) and (Doddington, 2002). Both measure accuracy, i.e. large scores are better. All of these metrics can be extended to the case where we have multiple references by calculating the value for each of the reference translations and choosing the best one among them. In our case we had two references per sentence. 4.4 Results The results for the FTE corpus are given in Table 4. The baseline results refer to the output of the translation system, as described in Section 3.1, without any of the further improvements discussed in Section 3. It can be seen that the log-linear combination of models signiﬁ"
2005.mtsummit-papers.34,W02-1021,1,0.821509,"rom being perfect. For eﬃciency reasons in most tasks, the whole search space can not be treated directly. So some pruning has to be carried out in the search process, which can lead to the rejection of valid translations (socalled search errors). The state-of-the-art algorithms used in current systems, however, allow to minimize these kinds of errors, so the main source of errors still lies in the probability models, i.e. sentences which are better translations do not get a better score (a higher probability). In order to alleviate this eﬀect, we can make use of word graphs and n-best lists (Ueﬃng et al., 2002). These are representations of diﬀerent possible translations for a given sentence. Once we have this representation we can use further models in order to compute an additional score for each of the possible candidates and then choose the one with the best score. Ideally these additional models would be integrated into the generation algorithm, but most of them are too costly to include in the search procedure or do not have a structure which allows this kind of coupling. How to eﬃciently compute n-best lists and word graphs for the phrase-based approach is presented in (Zens and Ney, 2005). 3"
2005.mtsummit-papers.34,C96-2141,1,0.629724,"the output of an automatic speech recognition system. We evaluate our system under these three conditions. 259 where the argmax operator denotes the search process. The transformation from (1) to (2) using Bayes rule allows us to use two sources of information, the translation model p(f1J |eI1 ) and the target language model p(eI1 ). The translation model can be further decomposed into a lexicon model, which gives the probability for word translations, and an alignment model, which connects the words in the source and target sentences. Let us consider the HMM Alignment model as presented in (Vogel et al., 1996) in order to illustrate this decomposition. This model decomposes the translation probability as follows: J  pϑ (f1J |eI1 ) = [pϑ (aj |aj−1 , I, J)pϑ (fj |eaj )] , j=1 aJ 1 (3) where the term pϑ (aj |aj−1 , I, J) is a ﬁrstorder model for the alignment, and the term Source Language Text Transformation f1J Pr(f1J |eI1 ) Global Search: maximize Pr(eI1 ) · Pr(f1J |eI1 ) over eI1 Lexicon model Alignment model Pr(eI1 ) Language model Transformation Target Language Text Figure 1: Architecture of the translation approach based on Bayes decision rule. pϑ (fj |eaj ) is the lexicon model1 , both depend"
2005.mtsummit-papers.34,N04-1033,1,0.844315,"guistic meaning is required. So, the basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and ﬁnally compose the target sentence from these phrase translations. First an alignment between source and target sentence is found by using a chain of single-word based models2 in both directions (source-totarget and target-to-source) and combining the two obtained alignments (Och and Ney, 2003). Given this alignment an extraction of contiguous phrases is carried out and their probabilities are computed by mean of relative frequencies (Zens and Ney, 2004). An example of an alignment between two sentences and a (possible) set of phrases to be extracted is shown in Figure 2. 3.2 Log-linear Model As an alternative to the traditional sourcechannel approach given in Equation (2) we can model the translation probability directly using a log-linear model (Och and Ney, 2002):   M I, fJ) exp λ h (e m m 1 1 m=1  , p(eI1 |f1J ) =  M I, fJ) exp λ h (˜ e m=1 m m 1 1 I e˜1 (5) 2 Usually the used models are IBM-1, HMM and IBM-4. with hm diﬀerent models, λm scaling factors and the denominator a normalization factor that can be ignored in the maximizati"
2005.mtsummit-papers.34,W05-0834,1,0.828788,"s (Ueﬃng et al., 2002). These are representations of diﬀerent possible translations for a given sentence. Once we have this representation we can use further models in order to compute an additional score for each of the possible candidates and then choose the one with the best score. Ideally these additional models would be integrated into the generation algorithm, but most of them are too costly to include in the search procedure or do not have a structure which allows this kind of coupling. How to eﬃciently compute n-best lists and word graphs for the phrase-based approach is presented in (Zens and Ney, 2005). 3.4 IBM1 Rescoring Although the IBM1 model is the easiest one of the single-word based translation models and the phrase based models clearly outperform this approach, the inclusion of the scores of this 261 model, i.e. hIBM1 (f1J |eI1 ) = I J   1 p(fj |ei ) (I + 1)J (6) j=1 i=0 has been shown experimentally to improve the performance of a machine translation system (Och et al., 2003). 3.5 LM Rescoring During the generation process, a single language model is used. However, additional language models speciﬁc to each sentence to be translated can help to improve the machine translation qual"
2006.iwslt-evaluation.15,P02-1038,1,0.675938,"tion [2]. It allows for an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. 1.2. Log-linear model A generalization of the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model [3], we obtain: P ´ M exp λm hm (eI1 , f1J ) m=1 P ´ P r(eI1 |f1J ) = P (3) M J 0I0 exp m=1 λm hm (e 1 , f1 ) e0 I1 0 1 The notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). 103 The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X Iˆ I J eˆ1 = argmax λm hm (e1 , f1 ) (4) targe"
2006.iwslt-evaluation.15,P03-1021,0,0.0724362,"that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X Iˆ I J eˆ1 = argmax λm hm (e1 , f1 ) (4) target positions I,eI1 I = i4 m=1 This is a generalization of the source-channel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion [4]. For the IWSLT evaluation campaign, we optimized the scaling factors with respect to the BLEU measure, using the Downhill Simplex algorithm from [5]. i3 i2 i1 0 = i0 0 = j0 j2 b2 b1 j4 = J j3 j1 b4 b3 source positions Figure 1: Illustration of the phrase segmentation. 1.3. Phrase-based approach The basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and finally compose the target sentence from these phrase translations. This idea is illustrated in Figure 1. Formally, we define a segmentation of a given sentence pair (f1J , eI"
2006.iwslt-evaluation.15,2005.iwslt-1.20,1,0.136382,"ation and introduce the notation that we will use in the later sections. Then, we will describe the models and algorithms that are used for generating the N -best list, i.e., the first pass. In Section 3, we will describe the models that are used to rescore and rerank this N -best list, i.e., the second pass. Afterwards, we will give an overview of the tasks and discuss the experimental results. This paper will also include a section describing the method used for the system combination of the TC-Star project partners. The overall system is similar to the one used in the 2005 IWSLT evaluation [1]. However, it contains novel features for the first pass, as well as for the second pass. In the first pass, we use phrase count features (cf. 2.2) to smooth the phrase probabiliies. In the second pass, we used sentence mixture language models 3.2 as a new model for rescoring. 1.1. Source-channel approach to SMT In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest pro"
2006.iwslt-evaluation.15,J03-1005,1,0.669481,". . fjk (7) Note that the segmentation sK 1 contains the information on the phrase-level reordering. The segmentation sK 1 is introduced as a hidden variable in the translation model. Therefore, it would be theoretically correct to sum over all possible segmentations. In practice, we use the maximum approximation for this sum. As a result, the models h(·) depend not only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). 1.4. Source cardinality synchronous search For single-word based models, this search strategy is described in [6]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [7]. 2. Models used during search When searching for the best translation for a given input sentence, we use a log-linear combination of several models (also called feature functions) as decision criterion. In this section, we will describe the models that are used in the first pass, i.e., during N best list generation. More specifically the models are: a"
2006.iwslt-evaluation.15,C04-1030,1,0.839059,"ossible segmentations. In practice, we use the maximum approximation for this sum. As a result, the models h(·) depend not only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). 1.4. Source cardinality synchronous search For single-word based models, this search strategy is described in [6]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [7]. 2. Models used during search When searching for the best translation for a given input sentence, we use a log-linear combination of several models (also called feature functions) as decision criterion. In this section, we will describe the models that are used in the first pass, i.e., during N best list generation. More specifically the models are: a phrase translation model, a word-based translation model, word and phrase penalty, a target language model and a reordering model. We will now describe the models in detail. 2.1. Phrase-based model The phrase-based translation model is the main"
2006.iwslt-evaluation.15,2002.tmi-tutorials.2,0,0.0348216,", i.e., during N best list generation. More specifically the models are: a phrase translation model, a word-based translation model, word and phrase penalty, a target language model and a reordering model. We will now describe the models in detail. 2.1. Phrase-based model The phrase-based translation model is the main component of our translation system. The hypotheses are generated by concatenating target language phrases. The pairs of source and corresponding target phrases are extracted from the wordaligned bilingual training corpus by the phrase extraction algorithm described in detail in [8]. The main idea is to extract phrase pairs that are consistent with the word alignment, meaning that the words of the source phrase are aligned only to words in the target phrase and vice versa. This criterion is identical to the alignment template criterion described in [9]. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = N (f˜, e˜) N (˜ e) (8) Here, the number of co-occurrences of a phrase pair (f˜, e˜) that are consistent with the word alignment is denoted as N (f˜, e˜). If one occurrence of a target phrase e˜ has N > 1 possible translations, each o"
2006.iwslt-evaluation.15,W99-0604,1,0.875186,"e phrase-based translation model is the main component of our translation system. The hypotheses are generated by concatenating target language phrases. The pairs of source and corresponding target phrases are extracted from the wordaligned bilingual training corpus by the phrase extraction algorithm described in detail in [8]. The main idea is to extract phrase pairs that are consistent with the word alignment, meaning that the words of the source phrase are aligned only to words in the target phrase and vice versa. This criterion is identical to the alignment template criterion described in [9]. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = N (f˜, e˜) N (˜ e) (8) Here, the number of co-occurrences of a phrase pair (f˜, e˜) that are consistent with the word alignment is denoted as N (f˜, e˜). If one occurrence of a target phrase e˜ has N > 1 possible translations, each of them contributes to N (f˜, e˜) 104 with 1/N . The marginal count N (˜ e) is the number of occurrences of the target phrase e˜ in the training corpus. The resulting feature function is: hPhr (f1J , eI1 , sK 1 ) = log K Y p(f˜k |˜ ek ) 2.4. Word and phrase penalty model In a"
2006.iwslt-evaluation.15,2004.iwslt-evaluation.13,1,0.815761,"sentence and phrase lengths. The model scaling factors can be adjusted to prefer longer sentences and longer phrases. 2.5. Target language model We use the SRI language modeling toolkit [11] to train a standard n-gram language model. The resulting feature function is: I Y hLM (f1J , eI1 , sK p(ei |ei−1 (14) 1 ) = log i−n+1 ) i=1 The smoothing technique we apply is the modified KneserNey discounting with interpolation. We used a 6-gram language model for all tasks. [N (f˜k , e˜k ) ≤ τ ] jk K Y Y I K 2.6. Reordering model We use a very simple reordering model that is also used in, for instance, [9, 12]. It assigns costs based on the jump width: hRM (f1J , eI1 , sK 1 )= K X |bk − jk−1 − 1 |+ J − jK (15) k=1 3. Rescoring models In this section, we describe the second pass of our system, the rescoring of N -best lists. N -best lists are suitable for easily applying several rescoring techniques because the hypotheses are already fully generated. In comparison, word graph rescoring techniques need specialized tools which traverse the graph appropriately. Additionally, because a node within a word graph allows for many histories, one can only apply local rescoring techniques, whereas for N -best"
2006.iwslt-evaluation.15,2005.eamt-1.17,1,0.888573,"Missing"
2006.iwslt-evaluation.15,W06-3110,1,0.184162,"se of another rescoring technique that benefits from the IBM model 1 lexical probabilities: hDel (f1J , eI1 ) = J Y I X [ p(fj |ei ) < τ ] (19) j=1 i=0 We call this the IBM1 deletion model. It counts all source words whose lexical probability given each target word is below a threshold τ . In the experiments, τ was chosen between 10−1 and 10−4 . 3.5. Sentence length model Sentence length is crucial for the evaluation of machine translation output, especially when using automatic evalua106 tion measures. Therefore we explicitly modeled the target sentence length I using the method described in [16]: X hSL (f1J , eI1 ) = log p(eI1 |f1J ) Table 2: Progress over time: comparison of the RWTH systems of the years 2004 to 2006 for the supplied data track on the IWSLT 2005 test set. eI1 Translation Direction Chin.-Engl. The sum is carried out only over those target hypotheses that have length I. 4. Tasks and corpora The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task [17]. This is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. The corpus statistics are shown in Table 1. For the open data trac"
2006.iwslt-evaluation.15,takezawa-etal-2002-toward,0,0.0460057,"the evaluation of machine translation output, especially when using automatic evalua106 tion measures. Therefore we explicitly modeled the target sentence length I using the method described in [16]: X hSL (f1J , eI1 ) = log p(eI1 |f1J ) Table 2: Progress over time: comparison of the RWTH systems of the years 2004 to 2006 for the supplied data track on the IWSLT 2005 test set. eI1 Translation Direction Chin.-Engl. The sum is carried out only over those target hypotheses that have length I. 4. Tasks and corpora The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task [17]. This is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. The corpus statistics are shown in Table 1. For the open data track a 40 000 sentences training corpus and four test sets were made available for each language pair. Other resources, despite proprietary data were permitted, but were not used in this system. As the BTEC is a rather clean corpus, the preprocessing consisted mainly of tokenization, i.e., separating punctuation marks from words. Additionally, we expanded contractions such as it’s or I’m in the English co"
2006.iwslt-evaluation.15,J03-1002,1,0.094442,"Missing"
2006.iwslt-evaluation.15,P02-1040,0,0.123176,"Missing"
2006.iwslt-evaluation.15,W05-0909,0,0.0606975,"Missing"
2006.iwslt-evaluation.15,E06-1005,1,0.51274,"Missing"
2006.iwslt-evaluation.15,W02-1021,1,\N,Missing
2006.iwslt-evaluation.15,J90-2002,0,\N,Missing
2006.iwslt-evaluation.15,W05-0834,1,\N,Missing
2006.iwslt-evaluation.15,W05-0831,1,\N,Missing
2006.iwslt-papers.1,P02-1038,1,0.362963,"y of a comma given the context exceeds a certain threshold. We are not aware of any other published work dealing with the detection of SU boundaries and punctuation in the context of machine translation. 158 3. Phrase-based MT system of RWTH speech In this section we will briefly present the statistical MT system which we use in the experiments for this work. We will denote the (given) source sentence with f1J = f1 . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . eI . Our baseline system maximizes the translation probability directly using a log-linear model [9]: P ´ M exp λm hm (eI1 , f1J ) m=1 P ´ , (1) p(eI1 |f1J ) = X M I, fJ) exp λ h (˜ e m m 1 1 m=1 I SUs e˜1 with a set of different features hm , scaling factors λm and the denominator a normalization factor that can be ignored in the maximization process. We choose the λm by optimizing an MT performance measure on a development corpus using the downhill simplex algorithm. The most important models in equation (1) are phrasebased models in both source to target and target to source directions. In order to extract these models, an alignment between a source sentence and its target language tran"
2006.iwslt-papers.1,J03-1002,1,0.00605234,"λm and the denominator a normalization factor that can be ignored in the maximization process. We choose the λm by optimizing an MT performance measure on a development corpus using the downhill simplex algorithm. The most important models in equation (1) are phrasebased models in both source to target and target to source directions. In order to extract these models, an alignment between a source sentence and its target language translation is found for all sentence pairs in the training corpus using the IBM-1, HMM and IBM-4 models in both directions and combining the two obtained alignments [10]. Given this alignment, an extraction of contiguous phrases is carried out and their probabilities are computed by means of relative frequencies [13]. Additionally we use single word based lexica in source to target and target to source direction. This has the effect of smoothing the relative frequencies used as estimates of the phrase probabilities. The phrase-based and single word based probabilities thus yield 4 features of the log-linear model. Another important feature in the log-linear model is the language model, an n-gram language model with KneserNey smoothing. A length and a phrase p"
2006.iwslt-papers.1,P02-1040,0,0.111881,"Missing"
2006.iwslt-papers.1,N04-1033,1,0.84139,"re on a development corpus using the downhill simplex algorithm. The most important models in equation (1) are phrasebased models in both source to target and target to source directions. In order to extract these models, an alignment between a source sentence and its target language translation is found for all sentence pairs in the training corpus using the IBM-1, HMM and IBM-4 models in both directions and combining the two obtained alignments [10]. Given this alignment, an extraction of contiguous phrases is carried out and their probabilities are computed by means of relative frequencies [13]. Additionally we use single word based lexica in source to target and target to source direction. This has the effect of smoothing the relative frequencies used as estimates of the phrase probabilities. The phrase-based and single word based probabilities thus yield 4 features of the log-linear model. Another important feature in the log-linear model is the language model, an n-gram language model with KneserNey smoothing. A length and a phrase penalty are the last models in the set of the seven basic models which are used in the system. 4. Sentence Segmentation and Punctuation Prediction in"
2006.iwslt-papers.1,2005.iwslt-1.19,1,0.886348,"Missing"
2008.iwslt-evaluation.16,2002.tmi-tutorials.2,0,0.032515,"Model The basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and finally compose the target sentence from these phrase translations. Phrases are defined as nonempty contiguous sequences of words. We constrain the segmentations so that all words in the source and the target sentence are covered by exactly one phrase. Thus, there are no gaps and there is no overlap. The pairs of source and corresponding target phrases are extracted from the word-aligned bilingual training corpus by the phrase extraction algorithm described in [2]. The main idea is to extract phrase pairs that are consistent with the word alignment, meaning that the words of the source phrase are aligned only to words in the target phrase and vice versa. Proceedings of IWSLT 2008, Hawaii - U.S.A. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = N (f˜, e˜) N (˜ e) (2) Here, the number of co-occurrences of a phrase pair (f˜, e˜) that are consistent with the word alignment is denoted as N (f˜, e˜). If one occurrence of a target phrase e˜ has N &gt; 1 possible translations, each of them contributes to N (f˜, e˜) with 1"
2008.iwslt-evaluation.16,W99-0604,1,0.584043,"3.3.1. Word-based Lexicon Model hPhr (f1J , eI1 , sK 1 ) = log K Y p(f˜k |˜ ek ) (3) k=1 To obtain a more symmetric model, we use the phrase-based model in both directions p(f˜|˜ e) and p(˜ e|f˜). Depending on the language pair, we used a different type of reordering model: • IBM Reordering For the Arabic-to-English language pair a word-based reordering constrained by the IBM restrictions [3] is often enough and obtains the best results. • Jump Reordering For the Chinese-to-English translation direction we use a very simple reordering model at phrase level that is also used in, for instance, [4, 5]. It assigns costs based only on the jump width. The phrase translation models estimate their probabilities by relative frequencies. Most of the longer phrases or translation units however occur only once in the training corpus. Therefore, pure relative frequencies overestimate the probability of those phrases. To overcome this problem, we use a word-based lexicon model to smooth the phrase translation probabilities. The score of a phrase pair is computed similar to the IBM model 1, but here, we are summing only within a phrase pair and not over the whole target language sentence. In the case"
2008.iwslt-evaluation.16,2004.iwslt-evaluation.13,1,0.818237,"3.3.1. Word-based Lexicon Model hPhr (f1J , eI1 , sK 1 ) = log K Y p(f˜k |˜ ek ) (3) k=1 To obtain a more symmetric model, we use the phrase-based model in both directions p(f˜|˜ e) and p(˜ e|f˜). Depending on the language pair, we used a different type of reordering model: • IBM Reordering For the Arabic-to-English language pair a word-based reordering constrained by the IBM restrictions [3] is often enough and obtains the best results. • Jump Reordering For the Chinese-to-English translation direction we use a very simple reordering model at phrase level that is also used in, for instance, [4, 5]. It assigns costs based only on the jump width. The phrase translation models estimate their probabilities by relative frequencies. Most of the longer phrases or translation units however occur only once in the training corpus. Therefore, pure relative frequencies overestimate the probability of those phrases. To overcome this problem, we use a word-based lexicon model to smooth the phrase translation probabilities. The score of a phrase pair is computed similar to the IBM model 1, but here, we are summing only within a phrase pair and not over the whole target language sentence. In the case"
2008.iwslt-evaluation.16,J07-2003,0,0.0522557,"ation probabilities p(f |e) are estimated as relative frequencies from the word-aligned training corpus. The word-based lexicon model is also used in both directions p(f |e) and p(e|f ). 3.3.2. Target Language Model 3.2. Hierarchical Model The hierarchical phrase-based approach can be considered as an extension of the standard phrase-based model. In this model we allow the phrases to have “gaps”, i.e. we allow non-contiguous parts of the source sentence to be translated into possibly non-contiguous parts of the target sentence. The model can be formalized as a synchronous context-free grammar [6]. The bilingual rules are of the form X → hγ, α, ∼i , (4) where X is a non-terminal, γ and α are strings of terminals and non-terminals, and ∼ is a one-to-one correspondence between the non-terminals of α and γ. Two examples of this kind of rules for the Chinese-to-English translation direction are X→h We use the SRI language modeling toolkit [7] to train a standard n-gram language model. The smoothing technique we apply is the modified Kneser-Ney discounting with interpolation. In our case we used a 6-gram language model. 3.3.3. Phrase Count Features The reliability of the phrase probability"
2008.iwslt-evaluation.16,2008.iwslt-papers.7,1,0.828609,"and NP, respectively), therefore the corresponding hierarchical rule gets a count of 1 for the syntax feature in the target part. Similarly for the source part. These counts are added up for all occurrences of a hierarchical rule (which may be extracted from different sentences and perhaps with different syntactic properties) and normalized with the total count of the phrase. We tried different ways of smoothing the counts, for the case where the phrases do not correspond to the yield of a node completely, but a binary count seemed to work best for the IWSLT data. More details can be found in [9]. 4.2. Chunk-based Reordering for Chinese For the standard phrase-based model we also tried and improved reordering model based on an extended version of the method described in [10]. The Chinese input sentence is reordered by a set of syntactic chunk-level rules, which are automatically learned from the training data. The method is described in [11]. In contrast to previous work, the reordered sentences are represented as an n-best list instead of a lattice. The size of the n-best list is kept small. This method has two advantages. On the one hand, not all reorderings are translated, which im"
2008.iwslt-evaluation.16,2007.iwslt-1.3,1,0.793315,"ed up for all occurrences of a hierarchical rule (which may be extracted from different sentences and perhaps with different syntactic properties) and normalized with the total count of the phrase. We tried different ways of smoothing the counts, for the case where the phrases do not correspond to the yield of a node completely, but a binary count seemed to work best for the IWSLT data. More details can be found in [9]. 4.2. Chunk-based Reordering for Chinese For the standard phrase-based model we also tried and improved reordering model based on an extended version of the method described in [10]. The Chinese input sentence is reordered by a set of syntactic chunk-level rules, which are automatically learned from the training data. The method is described in [11]. In contrast to previous work, the reordered sentences are represented as an n-best list instead of a lattice. The size of the n-best list is kept small. This method has two advantages. On the one hand, not all reorderings are translated, which improves system performance. The concept is similar to performing an aggressive pruning on the reordering lattice, where only the most promising reorderings alternatives are kept. On t"
2008.iwslt-evaluation.16,W07-0401,1,0.828669,"total count of the phrase. We tried different ways of smoothing the counts, for the case where the phrases do not correspond to the yield of a node completely, but a binary count seemed to work best for the IWSLT data. More details can be found in [9]. 4.2. Chunk-based Reordering for Chinese For the standard phrase-based model we also tried and improved reordering model based on an extended version of the method described in [10]. The Chinese input sentence is reordered by a set of syntactic chunk-level rules, which are automatically learned from the training data. The method is described in [11]. In contrast to previous work, the reordered sentences are represented as an n-best list instead of a lattice. The size of the n-best list is kept small. This method has two advantages. On the one hand, not all reorderings are translated, which improves system performance. The concept is similar to performing an aggressive pruning on the reordering lattice, where only the most promising reorderings alternatives are kept. On the other hand, there is not need for a translation system that can handle lattice based input, and thus this reordering method can be easily adapted to any translation sy"
2008.iwslt-evaluation.16,C08-1128,1,0.831022,"le used in the translation process is the composed from the standard phrase table expanded with the new phrases extracted from the reordered training sentences. The training data was parsed by the tree parser from Purdue University [12], extracting the basic chunks from the tree structure. Each chunk has 1.7 words on average. The size of the source reordered n-best list is 5. We additionally use the jump reordering model. 4.3. Source Preprocessing 4.3.1. Chinese Chinese word segmentation is one of the crucial steps in the Chinese text preprocessing. We compared various segmentation methods in [13] and found out that the unigram segmenter performs better translation results in many cases than the ictclas tool [14], which we use as baseline. Our unigram segmentation is an LDC-like segmentation without text Proceedings of IWSLT 2008, Hawaii - U.S.A. S S VP WHADVP WRB Where VP P NP 洗手间 PP PN VV AUX NP is DT JJ NN the public toilet 在 哪里 X → h X ∼0 在 哪里 , Where is X ∼0 i Figure 1: Example of a syntax-enhanced hierarchical rule. normalization. Given a manually compiled lexicon, i.e. an LDC lexicon that contains words and their relative frequencies Ps (f 0 j ), the best segmentation is the one"
2008.iwslt-evaluation.16,W03-1730,0,0.0114191,"ted from the reordered training sentences. The training data was parsed by the tree parser from Purdue University [12], extracting the basic chunks from the tree structure. Each chunk has 1.7 words on average. The size of the source reordered n-best list is 5. We additionally use the jump reordering model. 4.3. Source Preprocessing 4.3.1. Chinese Chinese word segmentation is one of the crucial steps in the Chinese text preprocessing. We compared various segmentation methods in [13] and found out that the unigram segmenter performs better translation results in many cases than the ictclas tool [14], which we use as baseline. Our unigram segmentation is an LDC-like segmentation without text Proceedings of IWSLT 2008, Hawaii - U.S.A. S S VP WHADVP WRB Where VP P NP 洗手间 PP PN VV AUX NP is DT JJ NN the public toilet 在 哪里 X → h X ∼0 在 哪里 , Where is X ∼0 i Figure 1: Example of a syntax-enhanced hierarchical rule. normalization. Given a manually compiled lexicon, i.e. an LDC lexicon that contains words and their relative frequencies Ps (f 0 j ), the best segmentation is the one that maximizes the joint probability of all words in the sentence, with the assumption that words are independent of"
2008.iwslt-evaluation.16,2005.eamt-1.37,1,0.896906,"Missing"
2008.iwslt-evaluation.16,W06-3111,1,0.903734,"Missing"
2008.iwslt-evaluation.16,P06-1001,0,0.0484133,"Missing"
2008.iwslt-evaluation.16,P05-1071,0,0.1017,"Missing"
2008.iwslt-evaluation.16,W07-0813,0,0.0393414,"Missing"
2008.iwslt-evaluation.16,E06-1005,1,0.776328,"del trained only on 20K sentence pairs was to weak to differentiate between good and bad ASR hypotheses. The expansion of the lattices using alternative word segmentations introduces additional ambiguity: so far we have not used probabilities for the segmentation alternatives. Nevertheless, examples show that in many cases the ASR errors can be avoided when word lattices are translated (see Table 1). 4.5. System Combination For system combination we used our approach from last year’s evaluation campaign [8], which is based on an enhanced version of the system combination approach described in [24]. The method is based on the generation of - 112 - Table 1: Examples of improved speech translation quality when ASR word lattices are used as input for translation. single-best lattice reference single-best lattice reference single-best lattice reference Hurry up. Can you. Some? It is too expensive. Can you make it cheaper? Too expensive. Can you make it cheaper? Where is the bus stop? The bus stop here, please. Here is the bus stop. How long time? How long will it take to get there? How much time will it take? a consensus translation out of the output of different translation systems. The co"
2008.iwslt-evaluation.16,N07-1029,0,0.0278975,"systems. The core of the method consists in building a confusion network for each sentence by aligning and combining the (single-best) translation hypothesis from one MT system with the translations produced by the other MT systems (and the other translations from the same system, if n-best lists are used in combination). For each sentence, each MT system is selected once as “primary” system, and the other hypotheses are aligned to this hypothesis. The resulting confusing networks are combined into one word graph, which is then weighted with system-specific factors, similar to the approach of [25], and a trigram LM trained on the MT hypotheses. The translation with the best total score within this word graph is selected as consensus translation. The scaling factors of these models are optimized using the Condor toolkit [26] to achieve optimal BLEU score on the dev set. 5. Experimental Results In this year’s evaluation RWTH participated in the Arabic-toEnglish and Chinese-to-English translation directions. For this last language pair, we participated in both evaluation tasks, BTEC and Challenge. As training data we used the provided training data and additionally a part of the HITcorpus"
2009.eamt-1.31,J90-2002,0,0.756696,"Missing"
2009.eamt-1.31,J93-2003,0,0.0364369,"226–233, Barcelona, May 2009 226 aJ1 := a1 , . . . , aj , . . . , aJ is introduced for aligning the source sentence f1J to the target sentence eI1 . The source word at position j is aligned to the target word at position i = aj . The alignment aJ1 may contain special alignment aj = 0, which means that the source word at index j is not aligned to any target word. Because a word in the source sentence cannot be aligned to multiple words in the target sentence, the alignment is trained in both translation directions: source to target and target to source. For each direction, a Viterbi alignment (Brown et al., 1993) is computed: A1 = {(aj , j)|aj ≥ 0} and A2 = {(i, bi )|bi ≥ 0}. Here, aJ1 is the alignment from the source language to the target language and bI1 is the alignment from the target language to the source language. To obtain more symmetrized alignments, A1 and A2 can be combined into one alignment matrix A with the following combination methods. More details are described in (Och and Ney, 2004): Figure 1: An alignment example with unaligned words. ? that is why w  • union: A = A1 ∪ A2 • ref ined: extend from the intersection. intersect ⊆ ref ined ⊆ union 1 LDC2006E93: LDC GALE Y1 Q4 Release -"
2009.eamt-1.31,N03-1017,0,0.0415861,"Missing"
2009.eamt-1.31,P07-1039,0,0.0127158,") and implemented by e. g. (Koehn et al., 2003). Since this widely used phrase extraction method depends on word alignments, it is often assumed that the quality c 2009 European Association for Machine Translation. of word alignment is critical to the success of translation. However, some research have shown that the large gains in alignment accuracy often lead to, at best, minor gains in translation performance (Lopez and Resnik, 2006). They concluded that it could be more useful to directly investigate ways to reduce the noise in phrase extraction than improving word alignment. The work by (Ma et al., 2007) shows that a good phrase segmentation is important for translation result. Encouraged by the work, this paper explores the influence of the unaligned words on the phrase extraction and machine translation results. We show that the presence of unaligned words causes extraction of “noisy” phrases which can lead to insertion and deletion errors in the translation output. Furthermore, we propose approaches for “hard” and “soft” deletion of the unaligned words on the source language side. We then show that better way to deal with unaligned words can substantially improve translation quality, on bo"
2009.eamt-1.31,W99-0604,1,0.705124,"ngs of words between each source sentence and its target language translation. Because of the difference in the structure of the involved languages, not all words in the source language have a corresponding word in the target language. So in the alignments, no matter manually created or automatically learned, some words are aligned, some are not. Current state-of-the-art statistical machine translation is based on phrases. First the word alignments for the training corpus are generated. Then phrase alignments are inferred heuristically from the word alignments. This approach was presented by (Och et al., 1999) and implemented by e. g. (Koehn et al., 2003). Since this widely used phrase extraction method depends on word alignments, it is often assumed that the quality c 2009 European Association for Machine Translation. of word alignment is critical to the success of translation. However, some research have shown that the large gains in alignment accuracy often lead to, at best, minor gains in translation performance (Lopez and Resnik, 2006). They concluded that it could be more useful to directly investigate ways to reduce the noise in phrase extraction than improving word alignment. The work by (M"
2009.eamt-1.31,J03-1002,1,0.0135217,"a. The large vocabulary GALE data were all provided by LDC. The test data has four genres: broadcast news (BN), broadcast conversations (BC), newswire (NW) and webtext (WT). The first two genres are for speech translation and the last two are for text translation. Here, we only carried out experiments on NW. The sentences of the GALE task are longer (around 30 words per sentence) and more difficult to translate. The corpus statistics for both tasks are shown in Table 4: 5.2 Baseline System Our baseline system is a standard phrase-based SMT system. Word alignments are obtained by using GIZA++ (Och and Ney, 2003) with IBM model 4 3 . We symmetrized bidirectional alignments using the refined heuristic (Och and Ney, 2004). The phrase-based translation model is a log-linear model that include phrase translation probabilities and word-based translation probabilities in both translation directions, phrase count models, word and phrase penalty, target language model (LM) and a distortion model. Language models were built using the SRI language mod3 Specifically, on GALE data we performed 5 iterations of Model 1, 5 iterations of HMM, 2 iterations of Model 4. On BTEC data we performed 4 iterations of Model 1,"
2009.eamt-1.31,P07-1090,0,0.0155861,"unction words and content words, we could find that the correct unaligned words are roughly function words, while the wrong unaligned words are usually content words. The function words have little lexical meaning, but instead serve to express grammatical relationships with other words within a sentence On the contrary, the content words usually carry meaning, which are “natural units” of translation between languages. If we just focus on the disambiguation of multiple phrases and not consider applying grammatical information in function words to the translation system, like the work done by (Setiawan et al., 2007), the simplest way of reducing the multiple phrases is to delete the ’correct’ unaligned words: the function words. The function words at the target side should not be touched, since they are necessary to complete a good sentence. However, the function words at the source side could be removed, when they have no corresponding translations. 4.1 Deletion Candidates Not all unaligned words should be removed. Besides the content words, a source function word could also have correct mappings to the target words in some sentences. We have used two constraints to filter out the words which can be del"
2009.eamt-1.31,takezawa-etal-2002-toward,0,0.0198983,"nments by merging the phrase counts and rewhich means that they were deleted wrongly. compute the phrase probabilities. 229 5 Experimental Setup BTEC Train: Sentences Running words Dev: Sentences Running words Test: Sentences Running words GALE Train: Sentences Running words Dev08: Sentences Running words Test08: Sentences Running words 5.1 Data We carried out MT experiments for translation from Chinese to English on two data sets: BTEC08 and GALE08. The BTEC08 data was provided within the IWSLT 2008 evaluation campaign (Paul, 2008), extracted from the Basic Traveling Expression Corpus(BTEC) (Takezawa et al., 2002). The data is a multilingual speech corpus which contains sentences which are usually found in books for tourists. The sentences are short, with less than 10 words on average. The parallel training data is relatively small. We added the official IWSLT08 training data, the IWSLT06 dev data and IWSLT06 evaluation data and their references to the training data. The development and test sets in the experiments below are from the IWSLT04 and IWSLT05 evaluation data. We found that the two data sets are not similar, so we took the first half of each and combine them as dev data. The remaining two hal"
2009.eamt-1.31,J04-4002,1,\N,Missing
2009.eamt-1.31,2008.iwslt-evaluation.1,0,\N,Missing
2009.eamt-1.31,2006.amta-papers.11,0,\N,Missing
2010.amta-papers.29,P06-1067,0,0.0225489,"experimental results. It is followed by our conclusions. 2 Related work The distance-based penalty model is used in many statistical phrase-based decoders, including the open-source decoder MOSES (Koehn et al., 2007). In (Zens and Ney, 2006), additionally a maximumentropy reordering model is used to predict the orientation of a phrase (left or right of the previously translated phrase). The words or word classes in the concerned phrase pairs are utilized as model features. Similar orientation or lexicalized reordering models have been proposed also in (Nagata et al., 2006; Koehn et al., 2005; Al-Onaizan and Papineni, 2006). However, they were almost always used in combination with the distance-based model. Other researchers tried to include reordering rules which either have been defined manually (Wang et al., 2007), or have been learned statistically from the reordering patterns in the parallel training data (Chen et al., 2006). In many cases the rules utilize POS tags (Rottmann and Vogel, 2007) or parses (Collins et al., 2005). The rules were either applied before SMT, or defined a reordering search space for SMT by representing reordering alternatives in a word graph (Zhang et al., 2007; Li et al., 2007). Pr"
2010.amta-papers.29,C00-2142,0,0.035543,"sed model. Other researchers tried to include reordering rules which either have been defined manually (Wang et al., 2007), or have been learned statistically from the reordering patterns in the parallel training data (Chen et al., 2006). In many cases the rules utilize POS tags (Rottmann and Vogel, 2007) or parses (Collins et al., 2005). The rules were either applied before SMT, or defined a reordering search space for SMT by representing reordering alternatives in a word graph (Zhang et al., 2007; Li et al., 2007). Previous work on Farsi MT is limited. The rule-based MT system described in (Amtrup et al., 2000) is one of the first systems that translates from Farsi to English. The authors introduce a toolkit and its application to Farsi. Saedi et al. (2009) gives an overview of a bidirectional English Farsi MT system containing rule-based, knowledgebased and corpus-based components. In (Deng and Zhou, 2009), the authors present a method for word alignment symmetrization and combination and test on a Farsi-to-English task. Several small vocabulary Farsi-to-English systems have been developed within the TransTac project for real-time dialogue applications (Kathol and Zheng, 2008; Kao et al., 2008). We"
2010.amta-papers.29,2006.iwslt-papers.4,0,0.016513,"of a phrase (left or right of the previously translated phrase). The words or word classes in the concerned phrase pairs are utilized as model features. Similar orientation or lexicalized reordering models have been proposed also in (Nagata et al., 2006; Koehn et al., 2005; Al-Onaizan and Papineni, 2006). However, they were almost always used in combination with the distance-based model. Other researchers tried to include reordering rules which either have been defined manually (Wang et al., 2007), or have been learned statistically from the reordering patterns in the parallel training data (Chen et al., 2006). In many cases the rules utilize POS tags (Rottmann and Vogel, 2007) or parses (Collins et al., 2005). The rules were either applied before SMT, or defined a reordering search space for SMT by representing reordering alternatives in a word graph (Zhang et al., 2007; Li et al., 2007). Previous work on Farsi MT is limited. The rule-based MT system described in (Amtrup et al., 2000) is one of the first systems that translates from Farsi to English. The authors introduce a toolkit and its application to Farsi. Saedi et al. (2009) gives an overview of a bidirectional English Farsi MT system contai"
2010.amta-papers.29,P05-1066,0,0.0597821,"concerned phrase pairs are utilized as model features. Similar orientation or lexicalized reordering models have been proposed also in (Nagata et al., 2006; Koehn et al., 2005; Al-Onaizan and Papineni, 2006). However, they were almost always used in combination with the distance-based model. Other researchers tried to include reordering rules which either have been defined manually (Wang et al., 2007), or have been learned statistically from the reordering patterns in the parallel training data (Chen et al., 2006). In many cases the rules utilize POS tags (Rottmann and Vogel, 2007) or parses (Collins et al., 2005). The rules were either applied before SMT, or defined a reordering search space for SMT by representing reordering alternatives in a word graph (Zhang et al., 2007; Li et al., 2007). Previous work on Farsi MT is limited. The rule-based MT system described in (Amtrup et al., 2000) is one of the first systems that translates from Farsi to English. The authors introduce a toolkit and its application to Farsi. Saedi et al. (2009) gives an overview of a bidirectional English Farsi MT system containing rule-based, knowledgebased and corpus-based components. In (Deng and Zhou, 2009), the authors pre"
2010.amta-papers.29,P09-2058,0,0.0133603,"007) or parses (Collins et al., 2005). The rules were either applied before SMT, or defined a reordering search space for SMT by representing reordering alternatives in a word graph (Zhang et al., 2007; Li et al., 2007). Previous work on Farsi MT is limited. The rule-based MT system described in (Amtrup et al., 2000) is one of the first systems that translates from Farsi to English. The authors introduce a toolkit and its application to Farsi. Saedi et al. (2009) gives an overview of a bidirectional English Farsi MT system containing rule-based, knowledgebased and corpus-based components. In (Deng and Zhou, 2009), the authors present a method for word alignment symmetrization and combination and test on a Farsi-to-English task. Several small vocabulary Farsi-to-English systems have been developed within the TransTac project for real-time dialogue applications (Kathol and Zheng, 2008; Kao et al., 2008). We are not aware of any work on Farsi-toArabic MT. 3 3.1 Reordering in phrase-based statistical MT Baseline MT system The baseline MT system is a state-of-the-art phrasebased translation system similar to (Koehn et al., 2007) and (Zens, 2008). In this system, a target language translation eI1 = e1 . . ."
2010.amta-papers.29,2008.iwslt-papers.4,0,0.0128817,"(Amtrup et al., 2000) is one of the first systems that translates from Farsi to English. The authors introduce a toolkit and its application to Farsi. Saedi et al. (2009) gives an overview of a bidirectional English Farsi MT system containing rule-based, knowledgebased and corpus-based components. In (Deng and Zhou, 2009), the authors present a method for word alignment symmetrization and combination and test on a Farsi-to-English task. Several small vocabulary Farsi-to-English systems have been developed within the TransTac project for real-time dialogue applications (Kathol and Zheng, 2008; Kao et al., 2008). We are not aware of any work on Farsi-toArabic MT. 3 3.1 Reordering in phrase-based statistical MT Baseline MT system The baseline MT system is a state-of-the-art phrasebased translation system similar to (Koehn et al., 2007) and (Zens, 2008). In this system, a target language translation eI1 = e1 . . . ei . . . eI for the source language sentence f1J = f1 . . . fj . . . fJ is found by maximizing the posterior probability P r(eI1 |f1J ). This probability is modeled directly using a loglinear combination of several models. The best translation is found with the following decision rule: ( ˆ eˆ"
2010.amta-papers.29,2005.iwslt-1.8,0,0.0198566,"tion 5 presents the experimental results. It is followed by our conclusions. 2 Related work The distance-based penalty model is used in many statistical phrase-based decoders, including the open-source decoder MOSES (Koehn et al., 2007). In (Zens and Ney, 2006), additionally a maximumentropy reordering model is used to predict the orientation of a phrase (left or right of the previously translated phrase). The words or word classes in the concerned phrase pairs are utilized as model features. Similar orientation or lexicalized reordering models have been proposed also in (Nagata et al., 2006; Koehn et al., 2005; Al-Onaizan and Papineni, 2006). However, they were almost always used in combination with the distance-based model. Other researchers tried to include reordering rules which either have been defined manually (Wang et al., 2007), or have been learned statistically from the reordering patterns in the parallel training data (Chen et al., 2006). In many cases the rules utilize POS tags (Rottmann and Vogel, 2007) or parses (Collins et al., 2005). The rules were either applied before SMT, or defined a reordering search space for SMT by representing reordering alternatives in a word graph (Zhang et"
2010.amta-papers.29,P07-2045,0,0.0341594,"stical MT, as well as on translation from Farsi in general. In Section 3, we first describe our baseline SMT system and then focus on the novel reordering models we propose. Section 4 describes how the hand-crafted reordering rules, which are used as soft constraints in the SMT, have been designed. Information on the Farsi part-of-speech tagger and the parser is also included. Section 5 presents the experimental results. It is followed by our conclusions. 2 Related work The distance-based penalty model is used in many statistical phrase-based decoders, including the open-source decoder MOSES (Koehn et al., 2007). In (Zens and Ney, 2006), additionally a maximumentropy reordering model is used to predict the orientation of a phrase (left or right of the previously translated phrase). The words or word classes in the concerned phrase pairs are utilized as model features. Similar orientation or lexicalized reordering models have been proposed also in (Nagata et al., 2006; Koehn et al., 2005; Al-Onaizan and Papineni, 2006). However, they were almost always used in combination with the distance-based model. Other researchers tried to include reordering rules which either have been defined manually (Wang et"
2010.amta-papers.29,koen-2004-pharaoh,0,0.246321,"Missing"
2010.amta-papers.29,P07-1091,0,0.0158179,"and Papineni, 2006). However, they were almost always used in combination with the distance-based model. Other researchers tried to include reordering rules which either have been defined manually (Wang et al., 2007), or have been learned statistically from the reordering patterns in the parallel training data (Chen et al., 2006). In many cases the rules utilize POS tags (Rottmann and Vogel, 2007) or parses (Collins et al., 2005). The rules were either applied before SMT, or defined a reordering search space for SMT by representing reordering alternatives in a word graph (Zhang et al., 2007; Li et al., 2007). Previous work on Farsi MT is limited. The rule-based MT system described in (Amtrup et al., 2000) is one of the first systems that translates from Farsi to English. The authors introduce a toolkit and its application to Farsi. Saedi et al. (2009) gives an overview of a bidirectional English Farsi MT system containing rule-based, knowledgebased and corpus-based components. In (Deng and Zhou, 2009), the authors present a method for word alignment symmetrization and combination and test on a Farsi-to-English task. Several small vocabulary Farsi-to-English systems have been developed within the"
2010.amta-papers.29,P06-1090,0,0.0186146,"is also included. Section 5 presents the experimental results. It is followed by our conclusions. 2 Related work The distance-based penalty model is used in many statistical phrase-based decoders, including the open-source decoder MOSES (Koehn et al., 2007). In (Zens and Ney, 2006), additionally a maximumentropy reordering model is used to predict the orientation of a phrase (left or right of the previously translated phrase). The words or word classes in the concerned phrase pairs are utilized as model features. Similar orientation or lexicalized reordering models have been proposed also in (Nagata et al., 2006; Koehn et al., 2005; Al-Onaizan and Papineni, 2006). However, they were almost always used in combination with the distance-based model. Other researchers tried to include reordering rules which either have been defined manually (Wang et al., 2007), or have been learned statistically from the reordering patterns in the parallel training data (Chen et al., 2006). In many cases the rules utilize POS tags (Rottmann and Vogel, 2007) or parses (Collins et al., 2005). The rules were either applied before SMT, or defined a reordering search space for SMT by representing reordering alternatives in a"
2010.amta-papers.29,J03-1002,0,0.00989248,"Missing"
2010.amta-papers.29,P03-1021,0,0.0202577,"ystem similar to (Koehn et al., 2007) and (Zens, 2008). In this system, a target language translation eI1 = e1 . . . ei . . . eI for the source language sentence f1J = f1 . . . fj . . . fJ is found by maximizing the posterior probability P r(eI1 |f1J ). This probability is modeled directly using a loglinear combination of several models. The best translation is found with the following decision rule: ( ˆ eˆI1 = argmax I,eI1 M X ) λm hm (eI1 , f1J ) (1) m=1 The model scaling factors λm for the features hm are trained with respect to the final translation quality measured by an error criterion (Och, 2003). The baseline system includes an n-gram language model, a phrase translation model, and a wordbased lexicon model as the main features. The latter two models are used in both directions: p(f |e) and p(e|f ). Further log-linear model features include a word penalty and a phrase penalty. Finally, reordering models are also used as features. The phrase-based search consists of two parts. First, those contiguous phrases in the source sentence are identified which have translation candidates in the phrase table. This phrase matching is done efficiently using an algorithm based on the work of (Zens"
2010.amta-papers.29,P02-1040,0,0.0809762,"s. We divided the corpus at random into two 268-sentence-long parts, with the goal of using one of the parts as the development set for optimization of the log-linear model scaling factors. In order to avoid over-fitting, we did separate optimizations on each of the two halves, and then extracted the hypotheses for the other half using the optimized parameters. The results reported in this section are obtained by automatically scoring the concatenation of the two sets of translation hypotheses obtained in this way. The evaluation was performed using the wellestablished automatic measure BLEU (Papineni et al., 2002). In addition, we computed the multiplereference word error rate (WER). WER penalizes wrong word order in translations. That is why it is a good choice to rate any improvement caused by new reordering models. The evaluation was caseinsensitive. The objective function for the parameter optimization described above was chosen to be the average between 1−BLEU and WER. 5.2 Farsi-to-English MT The experimental results for the Farsi-to-English MT system are shown in Table 2. There are two Table 3: Examples of improved translation quality using the run-based penalty vs. the jump-based penalty model."
2010.amta-papers.29,2007.tmi-papers.21,0,0.0287252,"e). The words or word classes in the concerned phrase pairs are utilized as model features. Similar orientation or lexicalized reordering models have been proposed also in (Nagata et al., 2006; Koehn et al., 2005; Al-Onaizan and Papineni, 2006). However, they were almost always used in combination with the distance-based model. Other researchers tried to include reordering rules which either have been defined manually (Wang et al., 2007), or have been learned statistically from the reordering patterns in the parallel training data (Chen et al., 2006). In many cases the rules utilize POS tags (Rottmann and Vogel, 2007) or parses (Collins et al., 2005). The rules were either applied before SMT, or defined a reordering search space for SMT by representing reordering alternatives in a word graph (Zhang et al., 2007; Li et al., 2007). Previous work on Farsi MT is limited. The rule-based MT system described in (Amtrup et al., 2000) is one of the first systems that translates from Farsi to English. The authors introduce a toolkit and its application to Farsi. Saedi et al. (2009) gives an overview of a bidirectional English Farsi MT system containing rule-based, knowledgebased and corpus-based components. In (Deng"
2010.amta-papers.29,2009.mtsummit-caasl.8,0,0.038661,"stically from the reordering patterns in the parallel training data (Chen et al., 2006). In many cases the rules utilize POS tags (Rottmann and Vogel, 2007) or parses (Collins et al., 2005). The rules were either applied before SMT, or defined a reordering search space for SMT by representing reordering alternatives in a word graph (Zhang et al., 2007; Li et al., 2007). Previous work on Farsi MT is limited. The rule-based MT system described in (Amtrup et al., 2000) is one of the first systems that translates from Farsi to English. The authors introduce a toolkit and its application to Farsi. Saedi et al. (2009) gives an overview of a bidirectional English Farsi MT system containing rule-based, knowledgebased and corpus-based components. In (Deng and Zhou, 2009), the authors present a method for word alignment symmetrization and combination and test on a Farsi-to-English task. Several small vocabulary Farsi-to-English systems have been developed within the TransTac project for real-time dialogue applications (Kathol and Zheng, 2008; Kao et al., 2008). We are not aware of any work on Farsi-toArabic MT. 3 3.1 Reordering in phrase-based statistical MT Baseline MT system The baseline MT system is a state"
2010.amta-papers.29,D07-1077,0,0.022251,", 2007). In (Zens and Ney, 2006), additionally a maximumentropy reordering model is used to predict the orientation of a phrase (left or right of the previously translated phrase). The words or word classes in the concerned phrase pairs are utilized as model features. Similar orientation or lexicalized reordering models have been proposed also in (Nagata et al., 2006; Koehn et al., 2005; Al-Onaizan and Papineni, 2006). However, they were almost always used in combination with the distance-based model. Other researchers tried to include reordering rules which either have been defined manually (Wang et al., 2007), or have been learned statistically from the reordering patterns in the parallel training data (Chen et al., 2006). In many cases the rules utilize POS tags (Rottmann and Vogel, 2007) or parses (Collins et al., 2005). The rules were either applied before SMT, or defined a reordering search space for SMT by representing reordering alternatives in a word graph (Zhang et al., 2007; Li et al., 2007). Previous work on Farsi MT is limited. The rule-based MT system described in (Amtrup et al., 2000) is one of the first systems that translates from Farsi to English. The authors introduce a toolkit an"
2010.amta-papers.29,W06-3108,0,0.018476,"translation from Farsi in general. In Section 3, we first describe our baseline SMT system and then focus on the novel reordering models we propose. Section 4 describes how the hand-crafted reordering rules, which are used as soft constraints in the SMT, have been designed. Information on the Farsi part-of-speech tagger and the parser is also included. Section 5 presents the experimental results. It is followed by our conclusions. 2 Related work The distance-based penalty model is used in many statistical phrase-based decoders, including the open-source decoder MOSES (Koehn et al., 2007). In (Zens and Ney, 2006), additionally a maximumentropy reordering model is used to predict the orientation of a phrase (left or right of the previously translated phrase). The words or word classes in the concerned phrase pairs are utilized as model features. Similar orientation or lexicalized reordering models have been proposed also in (Nagata et al., 2006; Koehn et al., 2005; Al-Onaizan and Papineni, 2006). However, they were almost always used in combination with the distance-based model. Other researchers tried to include reordering rules which either have been defined manually (Wang et al., 2007), or have been"
2010.amta-papers.29,2007.iwslt-1.3,0,0.016285,"l., 2005; Al-Onaizan and Papineni, 2006). However, they were almost always used in combination with the distance-based model. Other researchers tried to include reordering rules which either have been defined manually (Wang et al., 2007), or have been learned statistically from the reordering patterns in the parallel training data (Chen et al., 2006). In many cases the rules utilize POS tags (Rottmann and Vogel, 2007) or parses (Collins et al., 2005). The rules were either applied before SMT, or defined a reordering search space for SMT by representing reordering alternatives in a word graph (Zhang et al., 2007; Li et al., 2007). Previous work on Farsi MT is limited. The rule-based MT system described in (Amtrup et al., 2000) is one of the first systems that translates from Farsi to English. The authors introduce a toolkit and its application to Farsi. Saedi et al. (2009) gives an overview of a bidirectional English Farsi MT system containing rule-based, knowledgebased and corpus-based components. In (Deng and Zhou, 2009), the authors present a method for word alignment symmetrization and combination and test on a Farsi-to-English task. Several small vocabulary Farsi-to-English systems have been dev"
2010.iwslt-evaluation.2,2009.mtsummit-caasl.7,1,0.749199,"at is trained for the BTEC evaluation tasks. In section 4, we discuss the experiments and their evaluations. Finally, we conclude the paper in section 5. 1 Using a single core of a 3.0 GHz CPU. In the following, we describe our approach to the morphological analysis of both languages. We use the same inhouse developed morphology analysis toolkit for this purpose. Following the language-independent explanations, we discuss the language-specific details in the preprocessing steps for Arabic and Turkish. 2.1. Morphological analysis Our approach to morphological analysis is explained in detail in [1] with focus on Arabic. However, the same approach and toolkit is used for all languages that we deal with. The approach employs finite-state transducers (FST) enriched with unification of feature structures. The FST is not visible to the grammar developer who writes the morphological analysis rules in Lexical Functional Grammar (LFG) formalism. Manually crafted rules similar to regular expression patterns are compiled into FST. The exploited LFG formalism allows the declaration and formulation of linguistic knowledge in a concise manner. The system also includes an expressive Boolean formalism"
2010.iwslt-evaluation.2,2009.iwslt-evaluation.2,1,0.848137,"ar constructions can appear in a single word. Moreover, distinctive morphophonemic rules, e.g. harmony, epenthesis, duplication, etc., contribute further to the complexity of word formation. Inflectional and derivational productions introduce a big growth in the number of possible word forms. Naturally, only inflectional morphology is aimed to be analyzed. The richness in morphology introduces many challenges to the translation problem both to and from Turkish. The grammatical categories handled in the morphological analysis are similar to the categories handled in our system of previous year [3]. Morphological disambiguation is performed by syntactic analysis of the sentence. At the end of the syntactic analysis, the parser outputs the MA hypotheses that are selected in the winning parse tree. The morpheme boundaries are marked in the parser output with symbol “ ”. The morphemes are detached from each other to reduce the outof-vocabulary (OOV) rate and to achieve better alignments. The detached suffixes are normalized in order to reduce the number of different forms that result because of the morphophonemic rules in Turkish. 3. Baseline MT system 3.1. Statistical phrase-based approac"
2010.iwslt-evaluation.2,N04-1021,0,0.0348638,"ypotheses, except for making each letter that started a sentence an uppercase letter. In Section 4.1 it will be described how the best n-gram size for the LM was chosen experimentally. 3.6. Additional system features Besides the models described above, we also experimented with a number of other enhancements to our system. In order to facilitate better word choice, we added the sentence-level inverse IBM model 1 scores as additional feature. The model is expressed with the following equation:   J I X Y 1 J I  p(ei |fj ) (2) hinv-ibm1 (f1 , e1 ) = J j=1 i=1 This model has been used also by [15, 16]. The advantage of the model as compared to the standard IBM model 1 is that it Table 1: Examples of improved sentence structure when OOV words are disambiguated with their POS tags. Baseline + OOV handling Reference May I have another UNK green? May I have another green UNK N? Baseline UNK dangerous this project is quite as the economy that depends quickly. This project is quite dangerous to as that depends economy is UNK V quickly. The project is quite risky as economic circumstances change quickly. + OOV handling Reference May I have some more green beans? can be used to score partial hypot"
2010.iwslt-evaluation.2,P03-1021,0,0.0601425,"translation system similar to [4] and [5]. In this system, a target language translation eI1 = e1 . . . ei . . . eI for the source language sentence f1J = f1 . . . fj . . . fJ is found by maximizing the posterior probability P r(eI1 |f1J ). This probability is modeled directly using a log-linear combination of several models. The best translation is found with the following decision rule: ( M ) X Iˆ I J λm hm (e1 , f1 ) (1) eˆ1 = argmax I,eI1 m=1 The model scaling factors λm for the features hm are trained with respect to the final translation quality measured by an automatic error criterion [6]. The baseline system includes an n-gram language model, a phrase translation model, and a word-based lexicon model as the main features. The latter two models are used in both directions: p(f |e) and p(e|f ). The phrase-based and word-based models are estimated from the training data using word alignments trained with GIZA++ [7]. For phrase extraction, we use the implementation in the Moses statistical MT toolkit [4]. Further log-linear model features include a word penalty and a phrase penalty, as well as the target n-gram language model (LM). Finally, reordering models are also used as feat"
2010.iwslt-evaluation.2,J03-1002,0,0.0131732,"e best translation is found with the following decision rule: ( M ) X Iˆ I J λm hm (e1 , f1 ) (1) eˆ1 = argmax I,eI1 m=1 The model scaling factors λm for the features hm are trained with respect to the final translation quality measured by an automatic error criterion [6]. The baseline system includes an n-gram language model, a phrase translation model, and a word-based lexicon model as the main features. The latter two models are used in both directions: p(f |e) and p(e|f ). The phrase-based and word-based models are estimated from the training data using word alignments trained with GIZA++ [7]. For phrase extraction, we use the implementation in the Moses statistical MT toolkit [4]. Further log-linear model features include a word penalty and a phrase penalty, as well as the target n-gram language model (LM). Finally, reordering models are also used as features. The phrase-based search consists of two parts. First, those contiguous phrases in the source sentence are identified which have translation candidates in the phrase table. This phrase matching is done efficiently using an al30 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd a"
2010.iwslt-evaluation.2,2010.amta-papers.29,1,0.913061,"nous search (SCSS) implemented with dynamic programming. The goal of the search is to find the most probable segmentation of the source sentence into K non-empty non-overlapping contiguous blocks, select the most probable permutation of those blocks, and choose the best phrasal translations for each of the blocks at the same time. The concatenation of the translations of the permuted blocks yields a translation of the whole sentence. 3.2. Reordering penalty model In a recent attempt to improve the word order of the generated translations, we introduced a run-based penalty model for reordering [8]. In related work, the basic costs for reordering a phrase in the SMT search are usually linear in the distance [9]. More complex models have been introduced, but in most cases they extend the simple distance-based distortion model. In [8], we argue that the distance-based model is not the best choice even for the basic reordering model in statistical MT. The absolute distance is usually not a good indicator if a reordering should take place or not. Also, the distance-based model can penalize linguistically very improbable reorderings less than the other, more reasonable reorderings. For insta"
2010.iwslt-evaluation.2,koen-2004-pharaoh,0,0.384296,"tation of the source sentence into K non-empty non-overlapping contiguous blocks, select the most probable permutation of those blocks, and choose the best phrasal translations for each of the blocks at the same time. The concatenation of the translations of the permuted blocks yields a translation of the whole sentence. 3.2. Reordering penalty model In a recent attempt to improve the word order of the generated translations, we introduced a run-based penalty model for reordering [8]. In related work, the basic costs for reordering a phrase in the SMT search are usually linear in the distance [9]. More complex models have been introduced, but in most cases they extend the simple distance-based distortion model. In [8], we argue that the distance-based model is not the best choice even for the basic reordering model in statistical MT. The absolute distance is usually not a good indicator if a reordering should take place or not. Also, the distance-based model can penalize linguistically very improbable reorderings less than the other, more reasonable reorderings. For instance, the model penalizes “jumps” back to the monotonic translation path, which is not reasonable in most situations"
2010.iwslt-evaluation.2,N09-2005,0,0.0312695,"ypotheses, except for making each letter that started a sentence an uppercase letter. In Section 4.1 it will be described how the best n-gram size for the LM was chosen experimentally. 3.6. Additional system features Besides the models described above, we also experimented with a number of other enhancements to our system. In order to facilitate better word choice, we added the sentence-level inverse IBM model 1 scores as additional feature. The model is expressed with the following equation:   J I X Y 1 J I  p(ei |fj ) (2) hinv-ibm1 (f1 , e1 ) = J j=1 i=1 This model has been used also by [15, 16]. The advantage of the model as compared to the standard IBM model 1 is that it Table 1: Examples of improved sentence structure when OOV words are disambiguated with their POS tags. Baseline + OOV handling Reference May I have another UNK green? May I have another green UNK N? Baseline UNK dangerous this project is quite as the economy that depends quickly. This project is quite dangerous to as that depends economy is UNK V quickly. The project is quite risky as economic circumstances change quickly. + OOV handling Reference May I have some more green beans? can be used to score partial hypot"
2010.iwslt-evaluation.2,P02-1040,0,0.0843719,"Missing"
2010.iwslt-evaluation.2,2006.amta-papers.25,0,0.0285449,"d BLEU scores for the Turkish system. n-gram Opt. BLEU Test BLEU 3 4 5 6 7 8 9 57.15 57.73 57.31 57.66 57.76 57.58 57.61 59.56 60.67 61.55 60.81 60.96 60.74 59.86 4.1.2. Word Alignment Experiments AppTek participated in Arabic-to-English and Turkish-toEnglish BTEC tasks, using the supplied training data of 20K sentence pairs only. As the criterion for optimization we used the the well-established automatic measure BLEU [17]. We computed BLEU without considering case, but considering punctuation. On the test data, we report results in terms of case-sensitive BLEU and translation edit rate (TER,[18]), and the punctuation marks are included in the evaluation. In post-processing, we detokenized the MT output. We also restored most of contractions (e. g. “do not” → “don’t”). It turned out that the restoration of contractions has a very large influence on the automatic MT error measures, since most of the reference translations use them very often. 4.1. Turkish-to-English BTEC task For the Turkish-to-English task, we used devset2 (500 sentences) for the optimization of model scaling factors in the experiments. The other development data devset1 (506 sentences) is used as the test set. Each d"
2010.iwslt-evaluation.2,P07-1003,0,0.0245463,"table indicates the system where only the best 5 alignments are merged into a single system. This system achieved the best optimized BLEU score, however, it is outperformed by the ’all merged’ system on the test data. The heuristic names in Table 3 indicate the combination of IBM model 4 alignments with ACL [7], “grow-diag-final” [9], “intersection”, “intersectionunion” and “unify” heuristics, respectively. The “left” and “right” heuristics indicate the standard and inverse direction of the GIZA++ IBM model 4 alignment, respectively. The “berkeley” alignment is obtained with Berkeley Aligner [19]. The best individual BLEU score is obtained with the “acl” heuristic. Finally, we tested the sentence-level inverse IBM model 1 on the development data. The optimization BLEU score was 57.73 and test BLEU score was 60.59 which is almost 1 point below what we have obtained in the ’all merged’ system. 33 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3rd, 2010 Table 3: BLEU scores for different methods on symmetrization of word alignments in the Turkish to English BTEC task. Method Optimized BLEU Test BLEU acl gdf intersection iu unify left"
2012.amta-commercial.11,2004.iwslt-papers.2,0,0.0607947,"Missing"
2012.amta-commercial.11,D09-1074,0,0.0129481,"anslation probabilities are computed in the SAIC system on the fly as relative frequencies from the bilingual and marginal counts. This allows us to linearly interpolate the actual counts when multiple phrase table are used, so that more reliable probability estimates can be obtained. Thus, our phrase table combination technique is similar to the adaptation described by (Foster and Kuhn, 2007) and (Yasuda et al., 2008). The difference is that we linearly interpolate raw counts, not probabilities. Thus, our method can also be considered as an on-line corpus weighting technique in the style of (Koehn and Senellart, 2009). The customer phrase table is generated based on 1 http://www.statmt.org/wmt11/translation-task.html a fast word alignment algorithm mentioned in Section 3. The customer can choose whether the TM match features should be used for the entries in the phrase table. Thus, either the (possibly more noisy) in-domain parallel corpus or a real TM can be used in on-line adaptation. Typically, it makes sense to use the on-line adaptation for customer data of less than 1M running words. In such cases, the adaptation time is 1-2 minutes on a single CPU core. To perform incremental updates (i. e. to add a"
2012.amta-commercial.11,2010.amta-papers.2,0,0.0121637,"et sentence) by rules are URLs, e-mail addresses, company names with trademark signs, document numbers, etc. SAIC offers its customers the possibility to specify rule-based translation using special tags in the input documents. Besides the actual rule-based translation of content, many customers use this possibility to pass formatting information such as XML tags through the translation system. 3 Translation Memory Integration In addition to rule-based translation integration, the SAIC MT system is able to use translation memory (TM) when generating translations. In contrast to previous work (Koehn and Senellart, 2010), we decided not to apply approximate string matching to find the best and longest TM match for each input sentence. Instead, multiple partial TM matches are integrated in a “soft” way. When a new TM is uploaded to the system, each pair of source/target segments of the TM are word-aligned with a fast statistical alignment algorithm that employs probabilistic word lexica as its main knowledge source. Then, phrase pairs are extracted from the word-aligned segment pairs based on alignment constraints in the usual fashion (Och and Ney, 2003). The partial TM matches obtained in this way, as well as"
2012.amta-commercial.11,2010.amta-papers.29,1,0.703222,"Missing"
2012.amta-commercial.11,J03-1002,0,0.00273545,"ting translations. In contrast to previous work (Koehn and Senellart, 2010), we decided not to apply approximate string matching to find the best and longest TM match for each input sentence. Instead, multiple partial TM matches are integrated in a “soft” way. When a new TM is uploaded to the system, each pair of source/target segments of the TM are word-aligned with a fast statistical alignment algorithm that employs probabilistic word lexica as its main knowledge source. Then, phrase pairs are extracted from the word-aligned segment pairs based on alignment constraints in the usual fashion (Och and Ney, 2003). The partial TM matches obtained in this way, as well as the full matches are assigned special partial TM/full TM match flags, respectively. These flags are then used in the search to define binary TM features. In the actual search, each phrase pair for which the full TM match feature has fired is used with a very high cost bonus that is quadratically proportional to the source length of the phrase. This means that this phrase pair is always selected for translation if there are no other competing phrase pairs which also originate from full TM matches. When such phrase pairs exist, then the l"
2012.amta-commercial.11,P02-1040,0,0.0828322,"ecoder to produce the French version with the dollar sign following the number: “500 $”. We also implemented postprocessing rules for adjusting the number representations (e.g. “1234.15” to “1 234,15”). All of these adjustments do not have a significant effect on automatic measures of MT quality, but very much increase the readability and acceptance of the MT output by humans. In addition, they further reduce the human post-editing effort. 6 Experimental Results 6.1 Automatic Evaluation The first part of the experimental evaluation involved computing the established automatic MT measure BLEU (Papineni et al., 2002) on several in-domain and out-of-domain test sets, using a single reference translation. The evaluation was caseinsensitive. The test sets were: • TM set (185 sentences): entries from the translation memory - 85 full-sentence matches and 100 partial matches created manually by introducing slight modifications to the original TM sentences and the corresponding reference translations. • Main set (710 sentences): customer data representing marketing material about the customer products, as well as employee manuals. The domain of the sentences corresponds to the domain of the majority of the custo"
2012.amta-commercial.11,tiedemann-2012-parallel,0,0.0121834,"language model trained on the customer data. For the particular case of English-to-French translation, we had very large parallel corpora available. They included the English-French Gigaword corpus crawled from the web, the proceedings of European and Canadian parliaments, news and news commentary articles, English-to-French movie titles, computer software manuals, etc. All of the background data we used is publicly available. We downloaded the Gigaword corpus from the Workshop on Machine Translation (WMT) web page1 . The other data was downloaded from the OPUS collection of parallel corpora (Tiedemann, 2012). From all of these sources, we selected a total of 1.7M sentence pairs (44M tokens), for which the corresponding French sentence had the lowest perplexity w.r.t. the 3-gram French language model trained on the 80K tokens of the French side of the parallel customer data. Then, we used the sampled data to train the baseline phrase table of the customer English-to-French MT system. The same approach was used to obtain an even larger amount of French monolingual data (186M tokens) for training of the 5-gram language model. 4.2 On-line adaptation The second possibility for adaptation is on-line (a"
2012.amta-commercial.11,I08-2088,0,0.0147545,"table is generated from the customer TM and other parallel data. The phrase pairs from this customer phrase table compete with the phrase pairs from the (larger) baseline phrase table. The phrase translation probabilities are computed in the SAIC system on the fly as relative frequencies from the bilingual and marginal counts. This allows us to linearly interpolate the actual counts when multiple phrase table are used, so that more reliable probability estimates can be obtained. Thus, our phrase table combination technique is similar to the adaptation described by (Foster and Kuhn, 2007) and (Yasuda et al., 2008). The difference is that we linearly interpolate raw counts, not probabilities. Thus, our method can also be considered as an on-line corpus weighting technique in the style of (Koehn and Senellart, 2009). The customer phrase table is generated based on 1 http://www.statmt.org/wmt11/translation-task.html a fast word alignment algorithm mentioned in Section 3. The customer can choose whether the TM match features should be used for the entries in the phrase table. Thus, either the (possibly more noisy) in-domain parallel corpus or a real TM can be used in on-line adaptation. Typically, it makes"
2016.amta-researchers.10,J93-2003,0,0.0493281,"additional meta-information as an extra signal in the neural network. To the best of our knowledge, this is the ﬁrst work where the additional information about the text topic is embedded into the vector space and used to directly inﬂuence NMT decisions. In an NMT system, the attention mechanism introduced in Luong et al. (2014) is important both for decoding as well as for restoration of placeholder content and insertion of unknown words in the right positions in the target sentence. To improve the estimation of the soft alignment, we propose to use the Viterbi alignments of the IBM model 4 Brown et al. (1993) as an additional source of knowledge during NMT training. The additional alignment information helps the current system to bias the attention mechanism towards the Viterbi alignment. This paper is structured as follows. After an overview of related NMT work in Section 2, we propose a novel approach in Section 3 on using statistical word alignemt to bias the training of neural MT attention mechanism, we call it guided alignment training. In Section 4, we describe in more detail how topic information can beneﬁt NMT. Section 5 and Section 6 describes our domain adaptation approach. Experimental"
2016.amta-researchers.10,2012.eamt-1.60,0,0.0157757,"and news commentary corpora) for two epochs to get the best result on a development set, and then we continue training the same model on the in-domain training set for a few more epochs. In contrast to Luong and Manning (2015), however, we use the vocabularies of the most frequent 52K source/target words in the in-domain data (instead of the out-of-domain data vocabularies). This causes NMT to focus on translation of the most relevant in-domain words. 7 7.1 Experimental Results Data Sets and Preprocessing We performed MT experiments on the German-to-English IWLST 2015 speech translation task Cettolo et al. (2012) and on an in-house English-to-French e-commerce translation task. As part of data preprocessing, we tokenized and lowercased the corpora, as well as replaced numbers, product speciﬁcations, and other special symbols with placeholders such as $num. We only keep these placeholders in training, but preserve their content as XML markups in the dev/test sets, which we try to restore using attention mechanism. This content is inserted for the 3URFHHGLQJVRI$07$YRO075HVHDUFKHUV 7UDFN $XVWLQ2FW1RY_S generated placeholders on the target side based on the attent"
2016.amta-researchers.10,W14-4012,0,0.0229676,"Missing"
2016.amta-researchers.10,D14-1179,0,0.01576,"Missing"
2016.amta-researchers.10,N16-1102,0,0.0324233,"ality. Since the source and target language vocabularies for a neural network have to be limited, the rare words problem deteriorates translation quality signiﬁcantly. The rare word replacement technique using soft alignment proposed by Luong et al. (2014) gives a promising solution for the problem. Both encoder-decoder architecture and insertion of unknown words into NMT output highly rely on the quality of the attention mechanism, thus it becomes the crucial part of NMT. Some research has been done to reﬁne it by Luong et al. (2015), who proposed global and local attention-based models, and Cohn et al. (2016), who used biases, fertility and symmetric bilingual structure to improve the 3URFHHGLQJVRI$07$YRO075HVHDUFKHUV 7UDFN $XVWLQ2FW1RY_S attention model mechanism. The most recent work done by Mi et al. (2016) is highly parallel with our guided alignment training, Section 3. They use statistical alignment to supervise the NMT in a similar fashion as we do, the difference is that they smooth the statistical alignment and apply Euclidean distance directly to the objective function, while we try with different divergence function and also re-weight it before"
2016.amta-researchers.10,J15-2001,0,0.0609165,"Missing"
2016.amta-researchers.10,E14-1035,0,0.0255725,"KHUV 7UDFN $XVWLQ2FW1RY_S attention model mechanism. The most recent work done by Mi et al. (2016) is highly parallel with our guided alignment training, Section 3. They use statistical alignment to supervise the NMT in a similar fashion as we do, the difference is that they smooth the statistical alignment and apply Euclidean distance directly to the objective function, while we try with different divergence function and also re-weight it before adding to the overall objective function. Research on topic adaptation most closely related to our work was performed by Hasler et al. (2014), but the features proposed there were added to the log-linear model of a phrasebased system. Here, we use the topic information as part of the input to the NMT system. Another difference is that we primarily work with human-labeled topics, whereas in Hasler et al. (2014) the topic distribution is inferred automatically from data. When translating e-commerce content, we are faced with a situation when only a few product titles and descriptions were manually translated, resulting in a small in-domain parallel corpus, but a large general-domain parallel corpus is available. In such situations, d"
2016.amta-researchers.10,P07-2045,0,0.0100143,"the highest score as hard alignment for each word. We drew the alignment in Figure 4 to compare baseline NMT and alignment-guided NMT. It can be seen from the graph that the guided alignment training truly improves the alignment correspondence. 7.5 Overall Results The overall results on the e-commerce translation task and IWSLT task are shown in Table 5 and Table 7, respectively. We observed consistency on both tasks, in a sense that a feature that improves BLEU/TER results on one task is also beneﬁcial for the other. For comparison, we trained phrase-based SMT models using the Moses toolkit Koehn et al. (2007) on both translation tasks. We used the standard Moses features, including a 4gram LM trained on the target side of the bilingual data, word-level and phrase-level translation probabilities, as well as the distortion model with the maximum distortion of 6. Our stronger phrase-based baseline included additional 5 features of a 4-gram operation sequence model – OSM Durrani et al. (2015). On the e-commerce task, which is more challenging due to a high number of OOV words and placeholders, we observed that NMT translation output had many errors related to incorrect attention weights. To improve th"
2016.amta-researchers.10,W07-0733,0,0.0365236,"f a phrasebased system. Here, we use the topic information as part of the input to the NMT system. Another difference is that we primarily work with human-labeled topics, whereas in Hasler et al. (2014) the topic distribution is inferred automatically from data. When translating e-commerce content, we are faced with a situation when only a few product titles and descriptions were manually translated, resulting in a small in-domain parallel corpus, but a large general-domain parallel corpus is available. In such situations, domain adaption techniques have been used both in phrase-based systems Koehn and Schroeder (2007) and NMT Luong and Manning (2015). In addition, while diverse NMT models using different features and techniques are trained, an ensemble decoder can be used to combine them together to make a more robust model. This approach was used by Luong et al. (2015) to outperform the state-of-art phrase-based system with their NMT approach in the WMT 2015 evaluation. 3 Guided Alignment Training When using the attention-based NMT Bahdanau et al. (2014), we observed that the attention mechanism sometimes fails to yield appropriate soft alignments, especially with increasing length of the input sentence a"
2016.amta-researchers.10,2015.iwslt-evaluation.11,0,0.637993,"ansfer certain entities from the source sentence to the generated target sentence “in-context” without translating them. Such entities can include numbers, product speciﬁcations such as “5S” or brand names such as “Samsung” or “Lenovo”. In training, these entities can be replaced with placeholders to reduce the vocabulary size. However, NMT approaches are more powerful at capturing context beyond phrase boundaries and were shown to better exploit available training data. They also successfully adapt themselves to a domain, for which only a limited amount of parallel training data is available Luong and Manning (2015). Also, previous research Mathur et al. (2015) has shown that it is difﬁcult to obtain translation quality improvements with topic adaptation in phrase-based SMT because of data sparseness and a large number of topics (e. g. corresponding to product categories), which may or may not be relevant for disambiguating between alternative translations or solving other known MT problems. In contrast, we expected NMT to better solve the topic adaptation problem by using the additional meta-information as an extra signal in the neural network. To the best of our knowledge, this is the ﬁrst work where t"
2016.amta-researchers.10,D15-1166,0,0.766822,"earns to attend to different parts of source sentence to improve translation quality. Since the source and target language vocabularies for a neural network have to be limited, the rare words problem deteriorates translation quality signiﬁcantly. The rare word replacement technique using soft alignment proposed by Luong et al. (2014) gives a promising solution for the problem. Both encoder-decoder architecture and insertion of unknown words into NMT output highly rely on the quality of the attention mechanism, thus it becomes the crucial part of NMT. Some research has been done to reﬁne it by Luong et al. (2015), who proposed global and local attention-based models, and Cohn et al. (2016), who used biases, fertility and symmetric bilingual structure to improve the 3URFHHGLQJVRI$07$YRO075HVHDUFKHUV 7UDFN $XVWLQ2FW1RY_S attention model mechanism. The most recent work done by Mi et al. (2016) is highly parallel with our guided alignment training, Section 3. They use statistical alignment to supervise the NMT in a similar fashion as we do, the difference is that they smooth the statistical alignment and apply Euclidean distance directly to the objective function,"
2016.amta-researchers.10,2015.mtsummit-papers.21,0,0.0621163,"Missing"
2016.amta-researchers.10,D16-1249,0,0.139863,"(2014) gives a promising solution for the problem. Both encoder-decoder architecture and insertion of unknown words into NMT output highly rely on the quality of the attention mechanism, thus it becomes the crucial part of NMT. Some research has been done to reﬁne it by Luong et al. (2015), who proposed global and local attention-based models, and Cohn et al. (2016), who used biases, fertility and symmetric bilingual structure to improve the 3URFHHGLQJVRI$07$YRO075HVHDUFKHUV 7UDFN $XVWLQ2FW1RY_S attention model mechanism. The most recent work done by Mi et al. (2016) is highly parallel with our guided alignment training, Section 3. They use statistical alignment to supervise the NMT in a similar fashion as we do, the difference is that they smooth the statistical alignment and apply Euclidean distance directly to the objective function, while we try with different divergence function and also re-weight it before adding to the overall objective function. Research on topic adaptation most closely related to our work was performed by Hasler et al. (2014), but the features proposed there were added to the log-linear model of a phrasebased system. Here, we use"
2016.amta-researchers.10,J03-1002,0,0.0601976,"ormation it provides for calculating the attention weights for the current word is neither sufﬁcient nor reliable anymore. This leads to incorrect target word prediction, and the error propagates to the future steps due to feedback loop. The problem is even larger in the case of e-commerce data where the number of OOVs and placeholders is considerably higher. To improve the estimation of the soft alignment, we propose to use the Viterbi alignments of the IBM model 4 as an additional source of knowledge during the NMT training. Therefore, we ﬁrst extract Viterbi alignments using GIZA++ toolkit Och and Ney (2003), then we use them to bias the attention mechanism. Our approach is to optimize on both the decoder cost and the divergence between the attention weights and the alignment connections generated by statistical alignments. The multi-objective optimization task is then expressed as a single-objective function, which is a linear combination of two loss functions: original and new guided-alignment. 3.1 Decoder Cost NMT proposed by Bahdanau et al. (2014) maximizes the conditional log-likelihood of target sentence y1 , . . . , yT given the source sentence x1 , . . . , xT : HD (y, x) = − N 1  log pθ"
2016.amta-researchers.10,P02-1040,0,0.11528,"ds and top 30k English words as vocabularies for the IWSLT task, and most frequent 52k English/French words for the e-commerce task. The optimization of the objective function was performed by using AdaDelta algorithm Zeiler (2012). We set the beam size to 10 for dev/test set beam search translation. For training implementation, we use stochastic gradient descent with batch size of 100, saving model parameters after a certain number of epochs. We saved around 30 consecutive model parameters. We selected the best parameter set according to the sum of the established MT evaluation measures BLEU Papineni et al. (2002) and 1-TER Snover et al. (2006) on the development set. After model selection, we evaluated the best model on the test set. We report the test set BLEU and TER scores in Table 5 and Table 7. We use TITAN X GPUs with 12GB of RAM to run experiments on Ubuntu Linux 14.04. The training converges in less than 24 hours on the IWSLT talk task and around 30 hours on the e-commerce task. The beam search on the test set for both tasks takes around 10 minutes, the exact time depends on the vocabulary size and beam size. 7.3 Effect of Topic-aware NMT We tested different approaches to ﬁnd out where topic i"
2016.amta-researchers.10,2006.amta-papers.25,0,0.018325,"ocabularies for the IWSLT task, and most frequent 52k English/French words for the e-commerce task. The optimization of the objective function was performed by using AdaDelta algorithm Zeiler (2012). We set the beam size to 10 for dev/test set beam search translation. For training implementation, we use stochastic gradient descent with batch size of 100, saving model parameters after a certain number of epochs. We saved around 30 consecutive model parameters. We selected the best parameter set according to the sum of the established MT evaluation measures BLEU Papineni et al. (2002) and 1-TER Snover et al. (2006) on the development set. After model selection, we evaluated the best model on the test set. We report the test set BLEU and TER scores in Table 5 and Table 7. We use TITAN X GPUs with 12GB of RAM to run experiments on Ubuntu Linux 14.04. The training converges in less than 24 hours on the IWSLT talk task and around 30 hours on the e-commerce task. The beam search on the test set for both tasks takes around 10 minutes, the exact time depends on the vocabulary size and beam size. 7.3 Effect of Topic-aware NMT We tested different approaches to ﬁnd out where topic information ﬁts best into NMT, s"
2020.amta-user.10,2016.amta-researchers.10,1,0.887981,"ase of genre prediction, assuming 20 different genres, the additional input can be a 20-dimensional vector with probabilities for each genre given the input source sentence or document. This dense representation can then be associated with a genre embedding and included in the NMT architecture in a variety of ways, e.g. via a separate attention component to the genre/topic embedding. A stronger influence of meta-information on the decoder can be achieved by concatenating each current state with the genre/topic embedding before the next decoder state is predicted. Details can be found e.g. in (Chen et al., 2016). At inference time, we assume that the extra meta-data is provided by the user/customer or is automatically generated by an upstream component (such as speaker gender classifier or a topic classifier). At training time, the meta-information can also be already available (e.g. domain of a document or a whole collection of documents, language or language variety, or even style). This is especially true of recent customer-specific data, since a lot of companies, language service providers in particular, have started to pay attention to consistent storage of meta-data that accompanies their trans"
2020.amta-user.10,D17-1148,1,0.793028,"glossary entry in postprocessing. The obvious disadvantage of this approach is that the context in the form of the glossary entry itself is lost during translation, since it is generalized to the placeholder token. More complex algorithms involve encoding of the desired target translation in the source sentence using special markers (Dinu et al., 2019). Other methods try to use constrained decoding (Hasler et al., 2018) or NMT-internal attention mechanisms to override the translation of the next word if the current focus of the attention is on the corresponding matched source glossary entry (Dahlmann et al., 2017). With such approaches it is not guaranteed that the desired translation from the glossary will be used, but at the same time, it is possible that the system will learn that the glossary translation has to be used in a morphological form that is different from the (base) form present in the glossary because of the surrounding context. To illustrate the basic approach and the challenges that the more advanced approaches can rarely master, we present two examples. In the first one, the sentence Jack, when are you going back to Vienna? is correctly translated into German as Jack, wann fahren Sie"
2020.amta-user.10,P19-1294,0,0.0231105,"sing, and then the same token in the generated translation is 10 Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 2: MT User Track Page 213 replaced with the target side of the corresponding glossary entry in postprocessing. The obvious disadvantage of this approach is that the context in the form of the glossary entry itself is lost during translation, since it is generalized to the placeholder token. More complex algorithms involve encoding of the desired target translation in the source sentence using special markers (Dinu et al., 2019). Other methods try to use constrained decoding (Hasler et al., 2018) or NMT-internal attention mechanisms to override the translation of the next word if the current focus of the attention is on the corresponding matched source glossary entry (Dahlmann et al., 2017). With such approaches it is not guaranteed that the desired translation from the glossary will be used, but at the same time, it is possible that the system will learn that the glossary translation has to be used in a morphological form that is different from the (base) form present in the glossary because of the surrounding conte"
2020.amta-user.10,D19-5203,0,0.035997,"Missing"
2020.amta-user.10,N16-1101,0,0.023196,"nslator noted that the shorter automatic translation versions “are mostly great, exactly what a subtitler would do”. In very few cases, they do change the meaning, which is not acceptable, but can usually be fixed by quick post-editing. Table 6 shows examples of translations shortened with the above approach, for which the meaning of the translation did not change. 3.6 Language Variety and Multilinguality Multilingual NMT systems have shown to be effective in using parallel training data from highresource language pairs to improve the quality of translation from or to a low-resource language (Firat et al., 2016; Johnson et al., 2017). In case of multiple target languages, it is often sufficient to use a pseudo-token at the beginning of the source sentence that signals to what language it should be translated. With this 1 The reading speed is defined as the subtitle length in characters (e.g. a maximum of 2 lines with a maximum of 42 characters per line) divided by the subtitle duration (usually 2-5 seconds). 9 Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 2: MT User Track Page 212 simple approach, already an acceptable level"
2020.amta-user.10,N18-2081,0,0.0286244,"Missing"
2020.amta-user.10,Q17-1024,0,0.134037,"slation quality. We will also provide tips for a practical implementation of metadata-based “switches” in MT applications such as post-editing tools. 2 Using Meta-information for NMT Customization The meta-information accompanying a source sentence or document can be incorporated into the NMT training in different ways. The most straightforward way that does not require any changes to the NMT architecture is the use of source-side pseudo-tokens, usually in the beginning of a sentence, that correspond to a (discrete) meta-information. Pseudo-tokens are most widely used in multilingual systems (Johnson et al., 2017; Ha et al., 2016) with multiple target languages: the pseudo-token with the language code, such as @es@, signals that a translation into a particular language, in this case Spanish, is desired. Pseudo tokens were also successfully used for specifying the translation style (Sennrich et al., 2016) and for domain adaptation (Tars and Fishel, 2018). Alternatively, pseudo-tokens can be used as prefix constraints in the beginning of the (generated) target sentence (Takeno et al., 2017). The disadvantage of pseudo-tokens is that they only encode one piece of information, and their influence on the p"
2020.amta-user.10,W19-5321,0,0.0506854,"Missing"
2020.amta-user.10,D16-1140,0,0.0252877,"tiré incómodo ni tengo problema en verla. There’s no way I’m gonna feel uncomfortable and I don’t have a problem seeing her. There’s no way I’ll feel uncomfortable or have a problem seeing her. Table 6: Examples of translations shortened by N-best list rescoring aimed at penalizing long translations (Spanish-to-English subtitles). nent. There, the maximum length may be technically limited by the width of the menu or a text field. A number of research publications appeared recently which target length control, starting with the seminal work on length control in encoder-decoder architectures by Kikuchi et al. (2016). In (Lakew et al., 2019), the pseudo-tokens for short, medium, and long translations are assigned at training time. These labels are derived from the length ratios between each training source sentence and its target language translation. At inference time, the user provides the desired label, e.g. requesting a short translation. An approach with length constraints learned end-to-end in an unsupervised way is presented by (Niehues, 2020). Another method that we tested tailored specifically to subtitle translation is to re-score the N-best output of the NMT system using a linear combination of"
2020.amta-user.10,D19-6503,0,0.0407044,"Missing"
2020.amta-user.10,kobus-etal-2017-domain,0,0.0452931,"Missing"
2020.amta-user.10,W19-5209,1,0.842721,"formation about the used dialect is available, and automatic dialect prediction is a hard task. Following a pragmatic approach for English-to-Spanish translation of movie subtitles, we labeled those film subtitles in the training data as European Spanish which contained words and phrases used only in Spain. The rest was labeled as Latin American Spanish. We then trained a multilingual system with the two labels. Our customers can choose the language variety via an API parameter and obtain a possibly different translation for a given sentence using the same system. More details can be found in Matusov et al. (2019). In case of multilingual, dialectal, or even mixed-language input, it is possible to train an NMT model which is sensitive to the meta-information about the input language or dialect. Again, in practical applications, such as computer-assisted translation from Arabic to English, a general translation can be generated prior to post-editing (assuming e.g. Modern Standard Arabic or MSA), together with translations for (a subset of) the Arabic dialects. Then, the professional translator can change the MT in the post-editing window when she or he notices that the language switched from MSA to a di"
2020.amta-user.10,W18-6307,0,0.041106,"Missing"
2020.amta-user.10,2020.amta-research.3,0,0.021108,"Missing"
2020.amta-user.10,P02-1040,0,0.107307,"erated translations are correct for these examples. for each sentence, we assigned the whole document to the formal/informal class if the majority of its target sentences contained the formal/informal pronoun. This is a simple, yet effective rule-based approach; for a more sophisticated method, cf. (Niu and Carpuat, 2019). We experimented with two language pairs: English-to-German and English-to-Greek. In both cases we used state-of-the-art NMT systems trained with Transformer architectures using millions of sentence pairs. For English-to-Greek, the MT quality as measured with the BLEU score (Papineni et al., 2002) on a held-out test set of movie subtitles (Table 1) shows that our systems compare favorably to two major online translation providers. The style information was provided to the system as a pseudo-token (one of 3) both at training and at inference time. At inference time, we always used either the formal or the informal pseudo-token for all sentences in the test set. Since the test set mostly includes popular movies with informal style, the improvement in BLEU when using the informal style token was expected. We let a professional Greek-native translator check the output of the baseline syste"
2020.amta-user.10,N16-1005,0,0.182471,"raining in different ways. The most straightforward way that does not require any changes to the NMT architecture is the use of source-side pseudo-tokens, usually in the beginning of a sentence, that correspond to a (discrete) meta-information. Pseudo-tokens are most widely used in multilingual systems (Johnson et al., 2017; Ha et al., 2016) with multiple target languages: the pseudo-token with the language code, such as @es@, signals that a translation into a particular language, in this case Spanish, is desired. Pseudo tokens were also successfully used for specifying the translation style (Sennrich et al., 2016) and for domain adaptation (Tars and Fishel, 2018). Alternatively, pseudo-tokens can be used as prefix constraints in the beginning of the (generated) target sentence (Takeno et al., 2017). The disadvantage of pseudo-tokens is that they only encode one piece of information, and their influence on the produced NMT output is limited, especially in cases where the differentiating power of the additional meta-information is small, e.g. when the meta-information encodes domains/topics which are similar. In such cases it is advisable to use factored machine translation and encode the extra meta-info"
2020.amta-user.10,W17-5702,0,0.0167262,"nce, that correspond to a (discrete) meta-information. Pseudo-tokens are most widely used in multilingual systems (Johnson et al., 2017; Ha et al., 2016) with multiple target languages: the pseudo-token with the language code, such as @es@, signals that a translation into a particular language, in this case Spanish, is desired. Pseudo tokens were also successfully used for specifying the translation style (Sennrich et al., 2016) and for domain adaptation (Tars and Fishel, 2018). Alternatively, pseudo-tokens can be used as prefix constraints in the beginning of the (generated) target sentence (Takeno et al., 2017). The disadvantage of pseudo-tokens is that they only encode one piece of information, and their influence on the produced NMT output is limited, especially in cases where the differentiating power of the additional meta-information is small, e.g. when the meta-information encodes domains/topics which are similar. In such cases it is advisable to use factored machine translation and encode the extra meta-information as an additional factor for each source word (García-Martínez et al., 2016; Wilken and Matusov, 2019). In this way, the meta-information will have a stronger influence, since the N"
2020.amta-user.10,J82-2005,0,0.546118,"Missing"
2020.amta-user.10,W17-4811,0,0.0602984,"Missing"
2020.amta-user.10,D18-1334,0,0.0127159,"n appear again and again throughout a given text or speech that, for instance, is a first-person narrative with many forms starting with the pronoun “I”. To explicitly use the information about the speaker or the author, we again propose to partition the training data into “male”, “female”, and “neutral” sentence pairs depending whether or not the corresponding male or female word forms are used throughout the target sentence (almost) exclusively. We realize that such a method requires many heuristics, but in the absence of data labeled with speaker gender that was used in related research of Vanmassenhove et al. (2018) it is difficult to come up with a better solution. So far, we conducted only preliminary experiments for English-to-Czech, using 3 types of pseudo-tokens as described above. Table 5 shows an example where the correct gender forms are used in the Czech translation when the information about gender is provided to the system. This is a step in the right direction. We envision that especially for applications involving speech translation, speaker gender can be automatically predicted with high confidence and passed on to NMT for use as an additional signal. Also, in personalized translation appli"
2020.amta-user.10,D18-1325,0,0.0538526,"Missing"
2020.amta-user.10,D18-1041,0,0.0210089,"r propagation, the vector of posterior probabilities for all the predicted classes can be directly used in NMT as opposed to the first-best predicted label. For example, the genre and topic of a document can be predicted automatically with a trained classifier, but also e.g. its dialect or language variety. External monolingual labeled data can be used to select the label set and train the classifier. Usually, the classifier is trained for the source language so that it can be applied both at training time and at inference time as described above. More elaborate approaches such as the work of Zeng et al. (2018) jointly model NMT with monolingual attention-based classification tasks (in this particular case, domain classification). 3 3.1 Types of Customization Style The style or tone of a translation is very important for its acceptance. Thus, it is not appropriate to use an informal style in legal documents, etc. At the same time, a formal, polite style can not be used in translations of movie dialogs, chat messages, and other cases with colloquial language. A single NMT system can be trained to support multiple styles. In what style the translation is generated depends on the additional input (sele"
2020.iwslt-1.29,D18-1337,0,0.0329688,"1/P17 2 Related Work Oda et al. (2014) formulate segmentation as an optimization problem solved using dynamic programming to optimize translation quality. The approach is applied to phrase-based machine translation. Our chunking approach is conceptually simpler, and we explore its use with neural machine translation. Cho and Esipova (2016) devise a greedy decoding algorithm for simultaneous neural machine translation. They use a model that is trained on full sentences. In contrast, we train our models on chunked sentences to be consistent with the decoding condition. Satija and Pineau (2016), Alinejad et al. (2018), and Gu et al. (2017) follow a reinforcement learning approach to make decisions as to when to read source words or to write target words. Zheng et al. (2019) propose the simpler approach to use the position of the reference target word in the beam of an existing MT system to generate training examples of read/write decisions. We extract such decisions from statistical word alignment instead. In Ma et al. (2019); Dalvi et al. (2018), a wait-k policy is proposed to delay the first target word until k source words are read. The model alternates between generating s target words and reading s so"
2020.iwslt-1.29,P19-1126,0,0.107657,"Missing"
2020.iwslt-1.29,2021.eacl-main.233,0,0.0755401,"Missing"
2020.iwslt-1.29,2020.iwslt-1.3,1,0.873815,"Missing"
2020.iwslt-1.29,N18-2079,0,0.10332,"ating partial translations before observing the entire source sentence. The task fits scenarios such as live captioning and speech-to-speech translation, where the user expects a translation before the speaker finishes the sentence. Simultaneous MT has to balance between latency and translation quality. If more input is consumed before translation, quality is likely to improve due to increased context, but latency also increases. On the other hand, consuming limited input decreases latency, but degrades quality. There have been several approaches to solve simultaneous machine translation. In (Dalvi et al., 2018; Ma et al., 2019), a fixed policy is introduced 1 The International Conference on Spoken Language Translation, http://iwslt.org. • We introduce a source chunk boundary detection component and train it jointly with the NMT model. Unlike in (Arivazhagan et al., 2019), our component is trained using hard decisions, which is consistent with inference. • We propose a method based on word alignment to generate the source and target chunk boundaries, which are needed for training. • We study the use of bidirectional vs unidirectional encoder layers for simultaneous machine translation. Previous work"
2020.iwslt-1.29,N19-1202,0,0.0438667,"Missing"
2020.iwslt-1.29,E17-1099,0,0.0346153,"al. (2014) formulate segmentation as an optimization problem solved using dynamic programming to optimize translation quality. The approach is applied to phrase-based machine translation. Our chunking approach is conceptually simpler, and we explore its use with neural machine translation. Cho and Esipova (2016) devise a greedy decoding algorithm for simultaneous neural machine translation. They use a model that is trained on full sentences. In contrast, we train our models on chunked sentences to be consistent with the decoding condition. Satija and Pineau (2016), Alinejad et al. (2018), and Gu et al. (2017) follow a reinforcement learning approach to make decisions as to when to read source words or to write target words. Zheng et al. (2019) propose the simpler approach to use the position of the reference target word in the beam of an existing MT system to generate training examples of read/write decisions. We extract such decisions from statistical word alignment instead. In Ma et al. (2019); Dalvi et al. (2018), a wait-k policy is proposed to delay the first target word until k source words are read. The model alternates between generating s target words and reading s source words, until the"
2020.iwslt-1.29,P82-1020,0,0.674367,"Missing"
2020.iwslt-1.29,N03-1017,0,0.116214,"rd decoder is initialized with a zero state for each chunk. 6 Alignment-Based Chunking 6.1 Baseline Approach We aimed at a meaningful segmentation of sentence pairs into bilingual chunks which could then be translated in monotonic sequence and each chunk is – in terms of aligned words – translatable without consuming source words from succeeding chunks. We extract such a segmentation from unsupervised word alignments in source-to-target and target-tosource directions that we trained using the Eflo¨ mal toolkit (Ostling and Tiedemann, 2016) and combined using the grow-diag-final-and heuristic (Koehn et al., 2003). Then, for each training sentence pair, we extract a sequence of “minimallength” monotonic phrase pairs, i.e. a sequence of the smallest possible bilingual chunks which do not violate the alignment constraints2 and at the same time are conform with the segmentation constraints in Equation 1. By this we allow word reordering between the two languages to happen only within the chunk boundaries. The method roughly follows the approach of (Mari˜no et al., 2005), who extracted similar chunks as units for n-gram based statistical MT. For fully monotonic word alignments, only chunks of length 1 eith"
2020.iwslt-1.29,D18-2012,0,0.0606541,"Missing"
2020.iwslt-1.29,2005.mtsummit-papers.36,0,0.126427,"Missing"
2020.iwslt-1.29,P14-2090,0,0.0262807,"ource and target chunk boundaries, which are needed for training. • We study the use of bidirectional vs unidirectional encoder layers for simultaneous machine translation. Previous work focuses mostly on the use of unidirectional encoders. • We provide results using text and speech input. This is in contrast to previous work that only simulates simultaneous NMT on text input. 237 Proceedings of the 17th International Conference on Spoken Language Translation (IWSLT), pages 237–246 c July 9-10, 2020. 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 2 Related Work Oda et al. (2014) formulate segmentation as an optimization problem solved using dynamic programming to optimize translation quality. The approach is applied to phrase-based machine translation. Our chunking approach is conceptually simpler, and we explore its use with neural machine translation. Cho and Esipova (2016) devise a greedy decoding algorithm for simultaneous neural machine translation. They use a model that is trained on full sentences. In contrast, we train our models on chunked sentences to be consistent with the decoding condition. Satija and Pineau (2016), Alinejad et al. (2018), and Gu et al."
2020.iwslt-1.29,P02-1040,0,0.105934,"Missing"
2020.iwslt-1.29,2006.amta-papers.25,0,0.111601,"Missing"
2020.iwslt-1.29,P18-4022,1,0.869669,"Work Oda et al. (2014) formulate segmentation as an optimization problem solved using dynamic programming to optimize translation quality. The approach is applied to phrase-based machine translation. Our chunking approach is conceptually simpler, and we explore its use with neural machine translation. Cho and Esipova (2016) devise a greedy decoding algorithm for simultaneous neural machine translation. They use a model that is trained on full sentences. In contrast, we train our models on chunked sentences to be consistent with the decoding condition. Satija and Pineau (2016), Alinejad et al. (2018), and Gu et al. (2017) follow a reinforcement learning approach to make decisions as to when to read source words or to write target words. Zheng et al. (2019) propose the simpler approach to use the position of the reference target word in the beam of an existing MT system to generate training examples of read/write decisions. We extract such decisions from statistical word alignment instead. In Ma et al. (2019); Dalvi et al. (2018), a wait-k policy is proposed to delay the first target word until k source words are read. The model alternates between generating s target words and reading s so"
2020.iwslt-1.29,D19-1137,0,0.0622812,"roach is applied to phrase-based machine translation. Our chunking approach is conceptually simpler, and we explore its use with neural machine translation. Cho and Esipova (2016) devise a greedy decoding algorithm for simultaneous neural machine translation. They use a model that is trained on full sentences. In contrast, we train our models on chunked sentences to be consistent with the decoding condition. Satija and Pineau (2016), Alinejad et al. (2018), and Gu et al. (2017) follow a reinforcement learning approach to make decisions as to when to read source words or to write target words. Zheng et al. (2019) propose the simpler approach to use the position of the reference target word in the beam of an existing MT system to generate training examples of read/write decisions. We extract such decisions from statistical word alignment instead. In Ma et al. (2019); Dalvi et al. (2018), a wait-k policy is proposed to delay the first target word until k source words are read. The model alternates between generating s target words and reading s source words, until the source words are exhausted. Afterwards, the rest of the target words are generated. In addition, Dalvi et al. (2018) convert the training"
2020.iwslt-1.3,N19-4009,0,0.0269487,"e transcriber comments and emulate the ASR output using the preprocessing described in Section 2.2. As heldout tuning sets, we use the concatenation of the TED dev2010, tst2014, and MuST-C dev corpora. As heldout test data, we use TED tst2015, MuST-C tst-HE and MuST-C tst-COMMON. We report case-sensitive B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) scores. For simultaneous NMT, also the average lagging (AL) metric (Ma et al., 2019) is reported. To measure AL, we have integrated our online decoder into the server-client implementation of IWSLT 2020 within the fairseq framework (Ott et al., 2019). English Speech Figure 1: Overview of the DST model with pretraining and an adaptor. Shallow grey blocks correspond to pre-trained components, and dark grey blocks are finetuned on the DST task. training, we explore various strategies to augment the data by leveraging weakly supervised data, i.e. ASR and MT training data. Our high-quality Transformer big model has been employed to generate synthetic DST training data by automatically translating the correct transcripts of ASR training data (Jia et al., 2019). SYNTH TRANS refers to machinetranslated ASR training data. As listed in Table 1, we"
2020.iwslt-1.3,P02-1040,0,0.106427,"as defined in Section 2.3. On the other hand, BT denotes the parallel data obtained through back-translating the filtered monolingual data (see also Section 2.3). When the concatenation of MT and BT is used for training, we over-sample the indomain and clean part of MT 5 times. We remove transcriber comments and emulate the ASR output using the preprocessing described in Section 2.2. As heldout tuning sets, we use the concatenation of the TED dev2010, tst2014, and MuST-C dev corpora. As heldout test data, we use TED tst2015, MuST-C tst-HE and MuST-C tst-COMMON. We report case-sensitive B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) scores. For simultaneous NMT, also the average lagging (AL) metric (Ma et al., 2019) is reported. To measure AL, we have integrated our online decoder into the server-client implementation of IWSLT 2020 within the fairseq framework (Ott et al., 2019). English Speech Figure 1: Overview of the DST model with pretraining and an adaptor. Shallow grey blocks correspond to pre-trained components, and dark grey blocks are finetuned on the DST task. training, we explore various strategies to augment the data by leveraging weakly supervised data, i.e. ASR and MT training"
2020.iwslt-1.3,P82-1020,0,0.812338,"Missing"
2020.iwslt-1.3,D14-1162,0,0.0823965,"Missing"
2020.iwslt-1.3,D18-2012,0,0.0291357,"odels are trained on a single GPU and increased the effective batch size by accumulating gradient updates before applying them with a factor of 2 and 8 for the base and big Transformer respectively. All models are trained using Adam optimizer with an initial learning rate of 0.0003 and 1M lines per checkpoint. We apply a learning rate scheduling based on the perplexity on the validation set for a few consecutive evaluation checkpoints. Label smoothing (Pereyra et al., 2017) and dropout rates of 0.1 are used. The source and target sentences are segmented into subwords using SentencePiece (SP) (Kudo and Richardson, 2018) with a vocabulary size of 20K and 30K respectively. 3 Simultaneous Translation In simultaneous translation a stream of source words is translated into a stream of target words without relying on the context of a full sentence. In this process, the system has to make decisions on when to read further input and when to produce partial translations. Hence, there is an inherent compromise between latency and MT quality. 3.1 Alignment-based Chunking We develop a novel model architecture, based on offline LSTM models which are similar to Bahdanau et al. (2015). The approach is described in full det"
2020.iwslt-1.3,D18-2015,0,0.0542892,"tract overview is shown in Figure 1. German Text ST decoder Pre-trained MT decoder LSTM/Self-Attention ×Ld Attention ST encoder Adaptor 5 Pre-trained ASR encoder BiLSTM ×Le Experimental Results In this section we report results for offline cascaded and direct speech translation, as well as for simultaneous NMT under various training data conditions. Acoustic training of the baseline model and the HMM decoding have been performed with the RWTH ASR toolkit (Wiesler et al., 2014). All neural models have been built with RETURNN (Doetsch et al., 2017; Zeyer et al., 2018a) using Sisyphus framework (Peter et al., 2018). The number of running words of all training corpora is presented in Table 1. The data used for training the NMT models is referred to as MT and contains the in-domain, clean, and filtered bilingual data as defined in Section 2.3. On the other hand, BT denotes the parallel data obtained through back-translating the filtered monolingual data (see also Section 2.3). When the concatenation of MT and BT is used for training, we over-sample the indomain and clean part of MT 5 times. We remove transcriber comments and emulate the ASR output using the preprocessing described in Section 2.2. As heldo"
2020.iwslt-1.3,P16-1009,0,0.0697018,"Missing"
2020.iwslt-1.3,P16-1162,0,0.335,"Missing"
2020.iwslt-1.3,2006.amta-papers.25,0,0.0977849,"other hand, BT denotes the parallel data obtained through back-translating the filtered monolingual data (see also Section 2.3). When the concatenation of MT and BT is used for training, we over-sample the indomain and clean part of MT 5 times. We remove transcriber comments and emulate the ASR output using the preprocessing described in Section 2.2. As heldout tuning sets, we use the concatenation of the TED dev2010, tst2014, and MuST-C dev corpora. As heldout test data, we use TED tst2015, MuST-C tst-HE and MuST-C tst-COMMON. We report case-sensitive B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) scores. For simultaneous NMT, also the average lagging (AL) metric (Ma et al., 2019) is reported. To measure AL, we have integrated our online decoder into the server-client implementation of IWSLT 2020 within the fairseq framework (Ott et al., 2019). English Speech Figure 1: Overview of the DST model with pretraining and an adaptor. Shallow grey blocks correspond to pre-trained components, and dark grey blocks are finetuned on the DST task. training, we explore various strategies to augment the data by leveraging weakly supervised data, i.e. ASR and MT training data. Our high-quality Transfo"
2020.iwslt-1.3,2020.iwslt-1.29,1,0.912058,"vocabulary size of 20K and 30K respectively. 3 Simultaneous Translation In simultaneous translation a stream of source words is translated into a stream of target words without relying on the context of a full sentence. In this process, the system has to make decisions on when to read further input and when to produce partial translations. Hence, there is an inherent compromise between latency and MT quality. 3.1 Alignment-based Chunking We develop a novel model architecture, based on offline LSTM models which are similar to Bahdanau et al. (2015). The approach is described in full detail in Wilken et al. (2020). Our model consists of a multi-layer BiLSTM encoder, a unidirectional decoder and an attention mechanism. We expand the forward encoder with an additional binary output trained to predict chunk boundaries in the incoming source word stream. These chunk boundaries mark positions where enough context for translation is present to trigger a translation. We generate training examples for such chunks based on staNeural Machine Translation We employ the base and big Transformer model with multi-head attention. The base Transformer 46 tistical word alignment, created using the Eflomal ¨ Toolkit (Ost"
2020.iwslt-1.3,P18-4022,1,0.932318,"a linear bottleneck layer onto 512 dimensions. We use the frequency sorted log-uniform distribution to sample 1024 negative examples for NCE loss calculation. This training approach results in a self-normalized model (Gerstenberger et al., 2020), which allows for an efficient, single-pass decoding with the neural LM (Beck et al., 2019). The streaming recognizer implements a version of chunked processing (Chen and Huo, 2016; Zeyer et al., 2016), which allows to use the same BiLSTM-based acoustic model in both offline and online speech translation applications. pre-training strategy similar to (Zeyer et al., 2018b) is applied during training for a more stable and faster initial convergence. We start with a small encoder (small in depth and width, i.e. number of layers and hidden dimensions) and then grow it over time. It means, we add layer by layer till the 6th layer, and increase the dimension till 1024 nodes. With each pre-training epoch, we grow the network in terms of both the number of layers and the number of hidden dimensions. Moreover, connectionist temporal classification (CTC) (Graves et al., 2006) as an additional loss is used on top of the speech encoder during training. The models are tr"
2021.iwslt-1.5,2020.emnlp-main.206,0,0.0650253,"Missing"
2021.iwslt-1.5,2020.iwslt-1.3,1,0.937975,"ined condition and divide the allowed bilingual training data into indomain (the TED and MuST-C v2 corpora), clean (the NewsCommentary, Europarl, and WikiTitles corpora), and out-of-domain (the rest). The concatenation of MuST-C dev and IWSLT tst2014 is used as our dev set for all experiments. Our data preparation includes two main steps: data filtering and text conversion. We filter the out-of-domain data based on similarity to the in-domain data in the embedding space, reducing the size from 62.5M to 30.0M lines. For the details on data filtering, please refer to our last year’s submission (Bahar et al., 2020). For a tighter coupling between ASR and MT in the cascade system, we apply additional text normalization (TN) to the English side of the data. It lowercases the text, removes all punctuation In this paper, we describe the AppTek speech translation systems that participate in the offline and simultaneous tracks of the IWSLT 2021 evaluation campaign. This paper is organized as follows: In Section 2, we briefly address our data preparation. Section 3 describes our offline ST models followed by the experimental results in Section 3.6. For the offline end-to-end translation task, we train deep Tra"
2021.iwslt-1.5,2020.emnlp-demos.19,0,0.0658798,"Missing"
2021.iwslt-1.5,2005.iwslt-1.19,1,0.52726,"ames to form a speech segment is 100. Besides improving audio segmentation, following the idea by Gaido et al. (2020a), we fine-tune the direct model on automatically segmented data to increase its robustness against sub-optimal nonhomogeneous utterances. To resegment the German reference translations, we first use the baseline direct model to generate the German MT output for the automatically determined English segments. Then, we align this MT output with the reference translations and resegment the latter using a variant of the edit distance algorithm implemented in the mwerSegmenter tool (Matusov et al., 2005). Posterior Tight Integration The posterior model is inspired by Bahar et al. (2021) where the cascade components, i.e. the endto-end ASR and MT models, are collapsed into a single end-to-end trainable model. The idea is to benefit from all types of available data, i.e. the ASR, MT, and direct ST corpora, and optimize all parameters jointly. To this end, we concatenate the trained Transformer-based ASR and MT models, but instead of passing the one-hot vectors for the source words to the MT model, we pass on the word posteriors as a soft decision. We sharpen the source word distribution by an e"
2021.iwslt-1.5,2020.iwslt-1.8,1,0.875467,"Missing"
2021.iwslt-1.5,P02-1040,0,0.123019,"and the MT input must have the same vocabulary. Therefore, we need to train a new MT model with the appropriate English vocabulary with 5K subwords. The ASR model is trained with SpecAugment, the Adam optimizer with an initial learning rate of 1 × 10−4 , and gradient accumulation of 20 steps. We also apply 10 steps of learning warm-up. We employ beam search with a size of 12 to generate the best recognized word sequence and then pass it to MT with the corresponding word posterior vectors. 3.6 Offline Speech Translation Results The offline speech translation systems results in terms of B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) are presented in Table 2. The first group of results shows the text translation using the ASR-like processing. By comparing lines 1 and 3, we see an improvement in our MT develop54 # System TED tst2015 B LEU T ER MuST-C tst-HE B LEU T ER MuST-C tst-COMMON B LEU T ER Text MT (ASR-like source processing) 1 AppTek 2020 submission 2 Transformer 3 + fine-tuning 32.7 32.4 33.8 57.3 57.8 56.5 31.0 30.8 32.0 59.4 60.0 58.6 32.7 33.1 34.5 55.0 54.5 53.1 Cascaded ASR → MT 4 AppTek 2020 submission (single) 5 AppTek 2020 submission (ensemble) 6 Transformer 30.9 31.0 31.4 61"
2021.iwslt-1.5,P18-4022,0,0.103821,"developed for IWSLT 2020, which is based on splitting the stream of input words into chunks learned from statistical word alignment. Most notably, we can implement a flexible quality/latency trade-off by simulating different latencies at training time. We also meet this year’s requirement to support unsegmented input by developing a neural sentence segmenter that splits the ASR output into suitable translation units, using a varying number of future words as context which minimizes the latency added by this component. The experiments have been done using RASR (Wiesler et al., 2014), RETURNN (Zeyer et al., 2018a), and Sisyphus (Peter et al., 2018). This paper describes the offline and simultaneous speech translation (ST) systems developed at AppTek for IWSLT 2021. Our offline ST submission includes the direct endto-end system and the so-called posterior tight integrated model, which is akin to the cascade system but is trained in an end-to-end fashion, where all the cascaded modules are end-to-end models themselves. For simultaneous ST, we combine hybrid automatic speech recognition (ASR) with a machine translation (MT) approach whose translation policy decisions are learned from statistical word al"
2021.iwslt-1.5,D18-2015,0,0.0281974,"based on splitting the stream of input words into chunks learned from statistical word alignment. Most notably, we can implement a flexible quality/latency trade-off by simulating different latencies at training time. We also meet this year’s requirement to support unsegmented input by developing a neural sentence segmenter that splits the ASR output into suitable translation units, using a varying number of future words as context which minimizes the latency added by this component. The experiments have been done using RASR (Wiesler et al., 2014), RETURNN (Zeyer et al., 2018a), and Sisyphus (Peter et al., 2018). This paper describes the offline and simultaneous speech translation (ST) systems developed at AppTek for IWSLT 2021. Our offline ST submission includes the direct endto-end system and the so-called posterior tight integrated model, which is akin to the cascade system but is trained in an end-to-end fashion, where all the cascaded modules are end-to-end models themselves. For simultaneous ST, we combine hybrid automatic speech recognition (ASR) with a machine translation (MT) approach whose translation policy decisions are learned from statistical word alignments. Compared to last year, we i"
2021.iwslt-1.5,P16-1162,0,0.0375899,"the in-domain data plus TED-LIUM. As shown in Table 1, the models obtain low word error rates without using an external language model (LM). These attention-based models also outperform the hybrid LSTM/HMM model used in our simultaneous speech translation task. 3 3.3 2.2 3.1 Speech Data Offline Speech Translation Neural Machine Translation The ST models are trained using all the speech translation English→German corpora i.e. IWSLT TED, MuST-C, EuroParl ST, and CoVoST. After removing the off-limits talks from the training data, we end up with 740k segments. 5k and 32k bytepair-encoding (BPE) (Sennrich et al., 2016) is applied to the English and German texts, respectively. We have done the data processing as described in Section 2. We also fine-tune on the in-domain data, using a lower learning rate of 8 × 10−5 . Our MT model for the offline task is based on the big Transformer model (Vaswani et al., 2017). Both self-attentive encoder and decoder are composed of 6 stacked layers with 16 attention heads. The model size is 1024 with a ReLu layer equipped with 4096 nodes. The effective batch size has been increased by accumulating gradient with a factor of 8. Adam is used with an initial learning rate of 0."
2021.iwslt-1.5,2006.amta-papers.25,0,0.139419,"ame vocabulary. Therefore, we need to train a new MT model with the appropriate English vocabulary with 5K subwords. The ASR model is trained with SpecAugment, the Adam optimizer with an initial learning rate of 1 × 10−4 , and gradient accumulation of 20 steps. We also apply 10 steps of learning warm-up. We employ beam search with a size of 12 to generate the best recognized word sequence and then pass it to MT with the corresponding word posterior vectors. 3.6 Offline Speech Translation Results The offline speech translation systems results in terms of B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) are presented in Table 2. The first group of results shows the text translation using the ASR-like processing. By comparing lines 1 and 3, we see an improvement in our MT develop54 # System TED tst2015 B LEU T ER MuST-C tst-HE B LEU T ER MuST-C tst-COMMON B LEU T ER Text MT (ASR-like source processing) 1 AppTek 2020 submission 2 Transformer 3 + fine-tuning 32.7 32.4 33.8 57.3 57.8 56.5 31.0 30.8 32.0 59.4 60.0 58.6 32.7 33.1 34.5 55.0 54.5 53.1 Cascaded ASR → MT 4 AppTek 2020 submission (single) 5 AppTek 2020 submission (ensemble) 6 Transformer 30.9 31.0 31.4 61.0 61.2 59.3 29.3 29.5 30.1 61."
2021.iwslt-1.5,W16-4613,0,0.0190139,"ly increases translation performance. 4.4.2 Speech Input For the speech-to-text translation task, sentence segmentation is a much harder problem. Our streaming ASR system does not require segmentation of the input; however, its output is lower-cased and punctuation-free text. In the literature, the problem of segmenting ASR output into sentences has been approached using count-based language models (Stolcke and Shriberg, 1996), conditional random fields (Liu et al., 2005), and other classical models. Recently, recurrent neural networks have been applied, either in the form of language models (Wang et al., 2016) or sequence labeling (Iranzo-S´anchez et al., 2020). These methods either are meant for offline segmentation or require a fixed context of future words, thus increasing the overall latency of the system. Wang et al. (2019) predict sentence boundaries with a various number of future words as context within the same model, allowing for dynamic segmentation decisions at inference time depending on the necessary context. We adopt the proposed model, which is a 3-layer LSTM with a hidden size of 512, generating softmax distributions over the labels y (k) , k ∈ {0, . . . , m}, where m is the 4.5 Si"
2021.iwslt-1.5,W19-6601,0,0.118459,"its output is lower-cased and punctuation-free text. In the literature, the problem of segmenting ASR output into sentences has been approached using count-based language models (Stolcke and Shriberg, 1996), conditional random fields (Liu et al., 2005), and other classical models. Recently, recurrent neural networks have been applied, either in the form of language models (Wang et al., 2016) or sequence labeling (Iranzo-S´anchez et al., 2020). These methods either are meant for offline segmentation or require a fixed context of future words, thus increasing the overall latency of the system. Wang et al. (2019) predict sentence boundaries with a various number of future words as context within the same model, allowing for dynamic segmentation decisions at inference time depending on the necessary context. We adopt the proposed model, which is a 3-layer LSTM with a hidden size of 512, generating softmax distributions over the labels y (k) , k ∈ {0, . . . , m}, where m is the 4.5 Simultaneous MT Experiments 4.5.1 MT Model Training We use the data described in Section 2.1 to train the simultaneous MT models. For the text input condition, no ASR-like preprocessing is applied as the input is natural text"
C04-1006,J93-2003,0,0.0180943,"Missing"
C04-1006,P03-1012,0,0.0604065,"Missing"
C04-1006,P03-1011,0,0.0257173,"Missing"
C04-1006,J00-2004,0,0.217992,"Missing"
C04-1006,P00-1056,1,0.699934,"hereas in language modeling typically integer counts are used. Additionally, we want to allow for discounting values d greater than one. The backing-off distribution β(f, e¯) is estimated using relative frequencies: β(f, e¯) = N (f, e¯) P N (f˜, e¯) f˜ Here, N (f, e¯) denotes the count of the event that the source language word f and the target language base form e¯ occur together. These counts are computed by summing the lexicon counts N (f, e) over all full-form words e which share the same base form e¯. 5 Results 5.1 Evaluation Criteria We use the same evaluation criterion as described in (Och and Ney, 2000). The generated word alignment is compared to a reference alignment which is produced by human experts. The annotation scheme explicitly takes the ambiguity of the word alignment into account. There are two different kinds of alignments: sure alignments (S) which are used for alignments that are unambiguous and possible alignments (P ) which are used for alignments that might or might not exist. The P relation is used especially to align words within idiomatic expressions, free translations, and missing function words. It is guaranteed that the sure alignments are a subset of the possible alig"
C04-1006,J03-1002,1,0.114909,"l language processing. Obvious applications are the extraction of bilingual word or phrase lexica (Melamed, 2000; Och and Ney, 2000). These applications depend heavily on the quality of the word alignment (Och and Ney, 2000). Word alignment models were first introduced in statistical machine translation (Brown et al., 1993). The alignment describes the mapping from source sentence words to target sentence words. Using the IBM translation models IBM-1 to IBM-5 (Brown et al., 1993), as well as the Hidden-Markov alignment model (Vogel et al., 1996), we can produce alignments of good quality. In (Och and Ney, 2003), it is shown that the statistical approach performs very well compared to alternative approaches, e.g. based on the Dice coefficient or the competitive linking algorithm (Melamed, 2000). A central component of the statistical translation models is the lexicon. It models the word translation probabilities. The standard training procedure of the statistical models uses the EM algorithm. Typically, the models are trained for one translation direction only. Here, we will perform a simultaneous training of both translation directions, source-to-target and target-to-source. After each iteration of"
C04-1006,W02-1012,0,0.215898,"Missing"
C04-1006,C96-2141,1,0.951397,"l corpora are an important knowledge source for many tasks in natural language processing. Obvious applications are the extraction of bilingual word or phrase lexica (Melamed, 2000; Och and Ney, 2000). These applications depend heavily on the quality of the word alignment (Och and Ney, 2000). Word alignment models were first introduced in statistical machine translation (Brown et al., 1993). The alignment describes the mapping from source sentence words to target sentence words. Using the IBM translation models IBM-1 to IBM-5 (Brown et al., 1993), as well as the Hidden-Markov alignment model (Vogel et al., 1996), we can produce alignments of good quality. In (Och and Ney, 2003), it is shown that the statistical approach performs very well compared to alternative approaches, e.g. based on the Dice coefficient or the competitive linking algorithm (Melamed, 2000). A central component of the statistical translation models is the lexicon. It models the word translation probabilities. The standard training procedure of the statistical models uses the EM algorithm. Typically, the models are trained for one translation direction only. Here, we will perform a simultaneous training of both translation directio"
C04-1006,J97-3002,0,0.190502,"Missing"
C04-1032,J93-2003,0,0.0320223,"particular the state occupation probabilities, will be used to determine the costs of aligning a specific source word to a target word. We will evaluate the suggested alignment methods on the German–English Verbmobil task and the French–English Canadian Hansards task. We will show statistically significant improvements compared to state-ofthe-art results in (Och and Ney, 2003). 2 Statistical Word Alignment Models In this section, we will give an overview of the commonly used statistical word alignment techniques. They are based on the sourcechannel approach to statistical machine translation (Brown et al., 1993). We are given a source language sentence f1J := f1 ...fj ...fJ which has to be translated into a target language sentence eI1 := e1 ...ei ...eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª eˆI1 = argmax P r(eI1 |f1J ) eI1 = argmax eI1 © ª P r(eI1 ) · P r(f1J |eI1 ) This decomposition into two knowledge sources allows for an independent modeling of target language model P r(eI1 ) and translation model P r(f1J |eI1 ). Into the translation model, the word alignment A is introduced as a hidden variable: X P r(f1J |eI1 ) = P r(f1J ,"
C04-1032,P03-1012,0,0.0477676,"Missing"
C04-1032,P03-1011,0,0.0400771,"Missing"
C04-1032,J00-2004,0,0.0627208,"Missing"
C04-1032,P00-1056,1,0.805812,"the alignment are minimal. Using state occupation probabilities for word alignment modeling results in a number of advantages. First of all, in calculation of these probabilities with the models IBM-1, IBM-2 and HMM the EM-algorithm is performed exact, i.e. the summation over all alignments is efficiently performed in the Estep. For the HMM this is done using the Baum-Welch algorithm (Baum, 1972). So far, an efficient algorithm to compute the sum over all alignments in the fertility models IBM-3 to IBM-5 is not known. Therefore, this sum is approximated using a subset of promising alignments (Och and Ney, 2000). In both cases, the resulting estimates are more precise than the ones obtained by the maximum approximation, i. e. by considering only the Viterbi alignment. Instead of using the state occupation probabilities from only one training direction as costs (Equation 1), we can interpolate the state occupation probabilities from the sourceto-target and the target-to-source training for each pair (i,j) of positions in a sentence pair (f1J , eI1 ). This will improve the estimation of the local alignment costs. Having such symmetrized costs, we can employ the graph alignment algorithms (cf. Section 4"
C04-1032,J03-1002,1,0.261441,"which avoids this constraint and produces symmetric word alignments. This algorithm considers the alignment problem as a task of finding the edge cover with minimal costs in a bipartite graph. The parameters of the IBM models and HMM, in particular the state occupation probabilities, will be used to determine the costs of aligning a specific source word to a target word. We will evaluate the suggested alignment methods on the German–English Verbmobil task and the French–English Canadian Hansards task. We will show statistically significant improvements compared to state-ofthe-art results in (Och and Ney, 2003). 2 Statistical Word Alignment Models In this section, we will give an overview of the commonly used statistical word alignment techniques. They are based on the sourcechannel approach to statistical machine translation (Brown et al., 1993). We are given a source language sentence f1J := f1 ...fj ...fJ which has to be translated into a target language sentence eI1 := e1 ...ei ...eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª eˆI1 = argmax P r(eI1 |f1J ) eI1 = argmax eI1 © ª P r(eI1 ) · P r(f1J |eI1 ) This decomposition into two"
C04-1032,C96-2141,1,0.935974,"aligned bilingual corpora provide important knowledge for many natural language processing tasks, such as the extraction of bilingual word or phrase lexica (Melamed, 2000; Och and Ney, 2000). The solutions of these problems depend heavily on the quality of the word alignment (Och and Ney, 2000). Word alignment models were first introduced in statistical machine translation (Brown et al., 1993). An alignment describes a mapping from source sentence words to target sentence words. Using the IBM translation models IBM-1 to IBM-5 (Brown et al., 1993), as well as the Hidden-Markov alignment model (Vogel et al., 1996), we can produce alignments of good quality. However, all these models constrain the alignments so that a source word can be aligned to at most one target word. This constraint is useful to reduce the computational complexity of the model training, but makes it hard to align phrases in the target language (English) such as ‘the day after tomorrow’ to one word in the source language (German) ‘¨ ubermorgen’. We will present a word alignment algorithm which avoids this constraint and produces symmetric word alignments. This algorithm considers the alignment problem as a task of finding the edge c"
C04-1032,J97-3002,0,0.0795518,"Missing"
C08-1115,E06-1005,1,\N,Missing
C08-1115,W07-0728,1,\N,Missing
C08-1115,W03-1729,1,\N,Missing
C08-1115,P07-1040,0,\N,Missing
C08-1115,W07-0732,1,\N,Missing
C08-1115,W07-0724,1,\N,Missing
C08-1115,W07-0718,0,\N,Missing
C08-1115,P07-1019,0,\N,Missing
C08-1115,W07-0717,1,\N,Missing
C08-1115,P03-1021,0,\N,Missing
D08-1088,P08-2007,0,0.0303576,"rror rate (PER) on a slightly augmented variant of CNs which allows for edges to carry multiple symbols. The concatenation of symbols corresponds to the interdependency of decisions in the case of bigram matches above. NP-hard problems are quite common in machine 839 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 839–847, c Honolulu, October 2008. 2008 Association for Computational Linguistics translation; for example, Knight (1999) has shown that even for a simple form of statistical MT models, the decoding problem is NP-complete. More recently, DeNero and Klein (2008) have proven the NP-completeness of the phrase alignment problem. But even a simple, common procedure as BLEU scoring, which can be performed in linear time on single sentences, becomes a potentially intractable problem as soon as it has to be performed on a slightly more powerful representation, such as confusion networks. This rather surprising result is the motivation of this paper. The problem of finding the best unigram BLEU score in an unaugmented variant of CNs is not NPcomplete, as we show in Section 4. We present an algorithm that finds such a unigram BLEU-best path in polynomial time"
D08-1088,W07-0414,0,0.182865,"rsity, Germany {leusch,matusov,ney}@cs.rwth-aachen.de Abstract (2002), current research in MT uses more sophisticated measures, like the BLEU score (Papineni et al., 2001). Zens and Ney (2005) first described this task on general word graphs, and sketched a complete algorithm for calculating the maximum BLEU score in a word graph. While they do not give an estimate on the complexity of their algorithm, they note that already a simpler algorithm for calculating the Position independent Error Rate (PER) has an exponential worst-case complexity. The same can be expected for their BLEU algorithm. Dreyer et al (2007) examined a special class of word graphs, namely those that denote constrained reorderings of single sentences. These word graphs have some properties which simplify the calculation; for example, no edge is labeled with the empty word, and all paths have the same length and end in the same node. Even then, their decoder does not optimize the true BLEU score, but an approximate version which uses a language-model-like unmodified precision. We give a very short introduction to CNs and the BLEU score in Section 2. Confusion networks are a simple representation of multiple speech recognition or tr"
D08-1088,N07-2017,1,0.79118,"Missing"
D08-1088,J99-4005,0,0.050177,"h itself can influence the decisions after that. We also show that this also holds for unigram BLEU and the position independent error rate (PER) on a slightly augmented variant of CNs which allows for edges to carry multiple symbols. The concatenation of symbols corresponds to the interdependency of decisions in the case of bigram matches above. NP-hard problems are quite common in machine 839 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 839–847, c Honolulu, October 2008. 2008 Association for Computational Linguistics translation; for example, Knight (1999) has shown that even for a simple form of statistical MT models, the decoding problem is NP-complete. More recently, DeNero and Klein (2008) have proven the NP-completeness of the phrase alignment problem. But even a simple, common procedure as BLEU scoring, which can be performed in linear time on single sentences, becomes a potentially intractable problem as soon as it has to be performed on a slightly more powerful representation, such as confusion networks. This rather surprising result is the motivation of this paper. The problem of finding the best unigram BLEU score in an unaugmented va"
D08-1088,C04-1072,0,0.202386,"path hypotheses with the same number of empty edges, and ending in the same position in the confusion network. This idea is illustrated in Figure 6: We compare only the partial precision of path hypotheses ending in the same node. Due to the simple nature of this search graph, it can easily be traversed in a left-to-right, top-to-bottom manner. With regard to a node currently being expanded, only the next node in the same row, and the corresponding columns in the next row need to be kept active. When implementing this algorithm, Hypotheses should be compared on the modified BLEUS precision by Lin and Och (2004) because the original BLEU precision equals zero as long as there are no higher n-gram matches in the partial hypotheses, which renders meaningful comparison hard or impossible. In the rightmost column, all path hypotheses within a node have the same hypothesis length. Consequently, we can select the hypothesis with the best (brevity-penalized) BLEU score by multiplying the appropriate brevity penalty to the precision of the best path ending in each of these nodes. If we always expand all possible path hypotheses within the nodes, and basically run a full search, we will always find the BLEU-b"
D08-1088,E06-1005,1,0.855334,"how that even small generalizations of this data structure render the problem to be NP-hard again. Since finding the optimal solution is thus not always feasible, we introduce an approximating algorithm based on a multi-stack decoder, which finds a (not necessarily optimal) solution for n-gram BLEU in polynomial time. 1 Introduction In machine translation (MT), confusion networks (CNs) are commonly used to represent alternative versions of sentences. Typical applications include translation of different speech recognition hypotheses (Bertoldi et al., 2007) or system combination (Fiscus, 1997; Matusov et al., 2006). A typical operation on a given CN is to find the path which minimizes or maximizes a certain evaluation metric. This operation can be used in applications like Minimum Error Rate Training (Och, 2003), or optimizing system combination as described by Hillard et al. (2007). Whereas this is easily achievable for simple metrics like the Word Error Rate (WER) as described by Mohri and Riley In Section 3 we show that finding the best BLEU score is an NP-hard problem, even for a simplified variant of BLEU which only scores unigrams and bigrams. The main reason for this problem to become NP-hard is"
D08-1088,P03-1021,0,0.0891499,"a multi-stack decoder, which finds a (not necessarily optimal) solution for n-gram BLEU in polynomial time. 1 Introduction In machine translation (MT), confusion networks (CNs) are commonly used to represent alternative versions of sentences. Typical applications include translation of different speech recognition hypotheses (Bertoldi et al., 2007) or system combination (Fiscus, 1997; Matusov et al., 2006). A typical operation on a given CN is to find the path which minimizes or maximizes a certain evaluation metric. This operation can be used in applications like Minimum Error Rate Training (Och, 2003), or optimizing system combination as described by Hillard et al. (2007). Whereas this is easily achievable for simple metrics like the Word Error Rate (WER) as described by Mohri and Riley In Section 3 we show that finding the best BLEU score is an NP-hard problem, even for a simplified variant of BLEU which only scores unigrams and bigrams. The main reason for this problem to become NP-hard is that by looking at bigrams, we allow for one decision to also influence the following decision, which itself can influence the decisions after that. We also show that this also holds for unigram BLEU a"
D08-1088,2001.mtsummit-papers.68,0,0.0364375,"th from the start node to the end node visits each node of the graph in canonical order. Usually, we represent unlabeled edges by labeling them with the empty word ε. Within this paper, we represent a CN by a list of lists of words {wi,j }, where each wi,j corresponds to a symbol on an edge between nodes i and i + 1. A path in this CN can be written as a string of integers, an1 = a1 , . . . , an , such that the path is labeled w1,a1 w2,a2 . . . wn,an . Note that there can be a different number of possible words, j, for different positions i. 2.1 BLEU and variants The BLEU score, as defined by Papineni et al. (2001), is the modified n-gram precision of a hy840 pothesis, with 1 ≤ n ≤ N , given a set of reference translations R. “Modified precision” here means that for each n-gram, its maximum number of occurrences within the reference sentences is counted, and only up to that many occurrences in the hypothesis are considered to be correct. The geometric mean over the precisions for all n is calculated, and multiplied by a brevity penalty bp. This brevity penalty is 1.0 if the hypothesis sentence is at least as long as the reference sentence (special cases occur if multiple reference sentences with differe"
D08-1088,W05-0834,1,0.932221,"– in many cases, having a good, but not necessarily optimum path is preferable to having no good path at all. A simple approach would be to walk the CN from the start node to the end node, keeping track of ngrams visited so far, and choosing the word next which maximizes the n-gram precision up to this word. Track is kept by keeping n-gram count vectors for the hypothesis path and the reference sentences, and update those in each step. The main problem with this approach is that often the local optimum is suboptimal on the global scale, for example if a word occurs on a later position again. Zens and Ney (2005) on the other hand propose to keep all n-gram count vectors instead, and only recombine path hypotheses with identical count vectors. As they suspect, the search space can become exponentially large. In this paper, we suggest a compromise between these two extremes, namely keeping active a sufficiently large number of “path hypotheses” in terms of n-gram precision, instead of only the first best, or of all. But even then, edges with empty words pose a problem, as stepping along an empty edge will never decrease the precision of the local path. In certain cases, steps along empty edges may affe"
D08-1088,P02-1040,0,\N,Missing
D17-1148,D16-1162,0,0.0371874,"recurrent neural network LMs and translation models which take all previously generated target words into account. That is why, for instance, the attention-based NMT models were usually applied only in rescoring (Peter et al., 2016). In (Stahlberg et al., 2017), a two-step translation process is used, where in the first step a SMT translation lattice is generated, and in the second step the NMT decoder combines NMT scores with the Bayes-risk of the translations according to the lattice. In contrast, we explicitly use phrasal translations and language model scores in an integrated search. In (Arthur et al., 2016), a statistical word lexicon is used to influence NMT hypotheses, also based on the attention mechanism. (G¨ulc¸ehre et al., 2015) combine target n-gram LM scores with NMT scores to find the best translation. (He et al., 2016) also use a target LM, but add further SMT features such as word penalty and word lexica to the NMT beam search. To the best of our knowledge, no previous work extends the beam search with phrasal translation hypotheses of PBMT, like we propose in this paper. In (Tang et al., 2016), the NMT decoder is modified to switch between using externally defined phrases and standar"
D17-1148,D16-1025,0,0.0317185,"Missing"
D17-1148,D14-1179,0,0.148224,"Missing"
D17-1148,P14-1129,0,0.0414423,"are taken based only on the states of the NMT decoder. This paper is structured as follows. We review related work in Section 1.1. The baseline NMT model we use is described in Section 2, where we also recap the log-linear model combination used in PBMT. Section 3 presents the details of the proposed hybrid search. Experimental results are presented in Section 4, followed by conclusions and outlook in Section 5. 1.1 Related Work In the line of research closely related to our approach, neural models are used as additional features in vanilla phrase-based systems. Examples include the work of (Devlin et al., 2014), (JunczysDowmunt et al., 2016), etc. Such approaches have certain limitations: first, the search space of the model is still restricted by what can be produced using a phrase table extracted from parallel data based on word alignments. Second, the organization of the search, in which only a limited target word history (e.g. 4 last target words) is available for each partial hypothesis, makes it difficult to integrate recurrent neural network LMs and translation models which take all previously generated target words into account. That is why, for instance, the attention-based NMT models were"
D17-1148,D15-1165,0,0.0145051,"arl, Common Crawl, and others). We use the WMT 2015 evaluation data as development set, and the evaluation is performed on two sets from the WMT evaluations in 2014 and 2016. Only a single human reference translation is provided. For the phrase-based baselines, we use an inhouse phrase-decoder (Matusov and K¨opr¨u, 2010) which is similar to the Moses decoder (Koehn et al., 2007). We use standard SMT features, including word-level and phrase-level translation probabilities, the distortion model, 5-gram LMs, and a 7-gram joint translation and reordering model reimplemented based on the work of (Guta et al., 2015). The language model for the ecommerce task is trained on additional monolingual Russian item description data containing 28.2M words. For the WMT task, we use the English News Crawl data containing 3.8B words for additional language model data. The tuning is performed using MERT (Och, 2003) to increase the BLEU score on the development set. To stabilize the optimization on the English→Russian task, we detach Russian morphological suffixes from the word stems both in hypotheses and references using a context-independent “poor man’s” morphological analysis. We prefix each suffix with a special"
D17-1148,P15-1001,0,0.0452687,"100 sentences. The learning rate is initialized to 0.0002, decaying by 0.9 each epoch. For regularization we use L2 loss with weight 10−7 and dropout following Gal and Ghahramani (2016). We set the dropout probability for input and recurrent connections of the RNN to 0.2 and word embedding dropout probability to 0.1. On the English→Russian task, the model is then fine-tuned on in-domain data for 10 epochs. The vocabulary is limited using byte pair encoding (BPE) (Sennrich et al., 2016b) with 40K splits separately for each language. To speed up training we use approximate loss as described in (Jean et al., 2015). For pure NMT experiments, we employ length normalization (Wu et al., 2016), as otherwise short translations would be favored. For the hybrid approach, we use the same trained end-to-end model as in the NMT baseline. We use all the phrase-based model features plus the NMT score and run MERT as described in Section 3.1. Language models are trained on the level of BPE tokens. We consider at most 100 translation options for each source phrase. If not specified otherwise, we use a beam size of 96 for phrase hypotheses and a beam size of 32 for word hypotheses, resulting in a combined beam size of"
D17-1148,W16-2316,0,0.0786006,"Missing"
D17-1148,P16-1008,0,0.0235711,"word penalty and word lexica to the NMT beam search. To the best of our knowledge, no previous work extends the beam search with phrasal translation hypotheses of PBMT, like we propose in this paper. In (Tang et al., 2016), the NMT decoder is modified to switch between using externally defined phrases and standard NMT word hypotheses. However, only one target phrase per source phrase is considered, and the reported improvements are significant only when manually selected phrase pairs (mostly for rare named entities) are used. Somewhat related to our work is the concept of coverage-based NMT (Tu et al., 2016), where the model architecture is changed to explicitly account for source coverage. In our work, we use a standard NMT architecture, but track coverage with accumulated attention weights. 2 Background 2.1 Neural MT Neural MT proposed by (Bahdanau et al., 2014) maximizes the conditional log-likelihood of the target sentence E : e1 , . . . , eI given the source sentence F : f1 , . . . , fJ : HD = − N 1 X log pθ (En |Fn ) N n=1 where (En , Fn ) refers to the n-th training sentence pair in a dataset D, and N denotes the total number of sentence pairs in the training corpus. When using the encoder"
D17-1148,P07-2045,0,0.0063533,"evaluate on separate product/item description test sets. For development and test sets, two reference translations are used. The German→English system is trained on parallel corpora provided for the constrained WMT 2017 evaluation (Europarl, Common Crawl, and others). We use the WMT 2015 evaluation data as development set, and the evaluation is performed on two sets from the WMT evaluations in 2014 and 2016. Only a single human reference translation is provided. For the phrase-based baselines, we use an inhouse phrase-decoder (Matusov and K¨opr¨u, 2010) which is similar to the Moses decoder (Koehn et al., 2007). We use standard SMT features, including word-level and phrase-level translation probabilities, the distortion model, 5-gram LMs, and a 7-gram joint translation and reordering model reimplemented based on the work of (Guta et al., 2015). The language model for the ecommerce task is trained on additional monolingual Russian item description data containing 28.2M words. For the WMT task, we use the English News Crawl data containing 3.8B words for additional language model data. The tuning is performed using MERT (Och, 2003) to increase the BLEU score on the development set. To stabilize the op"
D17-1148,2010.iwslt-evaluation.2,1,0.878723,"Missing"
D17-1148,2008.iwslt-papers.8,0,0.0176765,"ties and phrase penalties are combined as features. 3 Hybrid Approach In this section we describe our proposed hybrid NMT approach. The algorithm allows translations to be generated partially by phrases1 and partially by words. Section 3.1 describes the models we use to score hypotheses. The search algorithm is presented in Section 3.2. 3.1 Log-linear Combination We use a log-linear model combination to introduce SMT models into the NMT search. Since translations can be partially generated by phrases, we introduce the phrase segmentation sK 1 as a hidden variable into the models similarly to (Zens and Ney, 2008), where K is the number of phrases used in the translation. Note that, unlike standard PBMT, sK 1 does not need to cover the whole source sentence, as parts of the translation can be generated by words. Using the maximum approximation, the search criterion then is ( ˆ eˆI1 = arg max max I,eI1 sK 1 M X m=1 ) λm hm (f1J , eI1 , sK 1 ) . (1) Let f˜k , e˜k be the chosen phrase pairs in the segmentation sK 1 for k = 1, . . . , K. In our experiments with the proposed hybrid search, we use the following features: 1. The NMT feature hNMT . 1 2. The word penalty feature hWP counts the number of target"
D17-1148,P03-1021,0,0.0136173,"le token. k=1 The purpose of this feature is to control the usage of phrases. 4. The phrase penalty feature hPP counts the number of phrases used. Together with the word penalty and the source word coverage feature, the phrase penalty can control the length of chosen phrases. 5. The n-gram language model feature hLM . 6. The bidirectional phrase features hPhr and hiPhr . Note that these features are only applied for those parts of the translation that are generated by phrases. The other parts get a phrase score of zero. The scaling factors λm are tuned with minimum error rate training (MERT) (Och, 2003) on n-best lists of the development set. 3.2 Search The algorithm is based on the beam search for NMT, which generates translations one word per time step in a left-to-right fashion. We modify this search to allow hypothesizing phrases in addition to normal word hypotheses. The phrases are suggested based on the neural attention, starting from the source position with the maximal current attention. We only suggest phrases if a source position is focused. We check that suggested phrases do not overlap with already translated source words by keeping track of the sum of attention in previous time"
D17-1148,P02-1038,0,0.123753,"ci that is a weighted summary over a sequence of annotations (h1 , . . . , hJ ), and hj contains information about the whole input sentence, but with a strong focus on the parts surrounding the j-th word (Bahdanau et al., 2014). Then, the context vector can be defined as: ci = J X j αij hj where exp(rij ) αij = PJ . j=1 exp(rij ) Therefore, αij is normalized over all source positions j. Also, rij = a(si−1 , hj ) is the attention model used to calculate the log-likelihood of 1412 aligning the i-th target word to the j-th source word. 2.2 Phrase-based MT The log-linear model, as introduced in (Och and Ney, 2002), allows decomposing the translation probability P r(eI1 |f1J ) by using an arbitrary number of features hm (f1J , eI1 ). Each feature is multiplied by a corresponding scaling factor λm :  P M J , eI ) λ h (f exp m m 1 1 m=1 . P P r(eI1 |f1J ) = P M I˜) J, e ˜ λ h (f ˜ exp m m I 1 1 m=1 e˜ 1 The standard PBMT approach uses a log-linear model in which bidirectional phrasal and lexical scores, language model scores, distortion scores, word penalties and phrase penalties are combined as features. 3 Hybrid Approach In this section we describe our proposed hybrid NMT approach. The algorithm all"
D17-1148,P16-1009,0,0.18807,"rd/phrase hypotheses, respectively. First, we generate the attention vector αh,j and the distribution over target words pˆh (e) for each hypothesis h ∈ B and word e in the NMT target vocabulary VT using the NMT model in batched scoring 2 . 0 , B 0 ] = [∅, ∅]. 2. Initialize new beam [Bw p 3. Generate new word hypotheses: find the maximal Nw pairs (h, e) with h ∈ Bw and e ∈ VT according to the score Q(h) + λNMT · 2 If a target word e is not in VT , set pˆh (e) = pˆh (UNK) where UNK is a special token denoting unknowns. Note that this almost never happens when using a word segmentation like BPE (Sennrich et al., 2016b). 1414 log pˆh (e). For the top pairs h0 = (h, e), set Q(h0 ) = Q(h) + λN M T · log pˆh (e) + λLM · log pLM (e|E(h)) + λW P 0 . Update the soft coverand insert h0 into Bw age C(h0 , j) = C(h, j)+αh,j for 1 ≤ j ≤ J. 4. Generate new phrase hypotheses: for each previous word hypothesis h ∈ Bw , convert the soft attention C(h, ·) into a binary coverage set C, such that j ∈ C iff. C(h, j) > τcov . Identify the current NMT focus as ˆj = arg max 1≤j≤J, αh,j >τfocus αh,j . If there is no such j with αh,j > τfocus , no phrase hypotheses are generated from h in this step. Otherwise, for each source ph"
D17-1148,P16-1162,0,0.524932,"rd/phrase hypotheses, respectively. First, we generate the attention vector αh,j and the distribution over target words pˆh (e) for each hypothesis h ∈ B and word e in the NMT target vocabulary VT using the NMT model in batched scoring 2 . 0 , B 0 ] = [∅, ∅]. 2. Initialize new beam [Bw p 3. Generate new word hypotheses: find the maximal Nw pairs (h, e) with h ∈ Bw and e ∈ VT according to the score Q(h) + λNMT · 2 If a target word e is not in VT , set pˆh (e) = pˆh (UNK) where UNK is a special token denoting unknowns. Note that this almost never happens when using a word segmentation like BPE (Sennrich et al., 2016b). 1414 log pˆh (e). For the top pairs h0 = (h, e), set Q(h0 ) = Q(h) + λN M T · log pˆh (e) + λLM · log pLM (e|E(h)) + λW P 0 . Update the soft coverand insert h0 into Bw age C(h0 , j) = C(h, j)+αh,j for 1 ≤ j ≤ J. 4. Generate new phrase hypotheses: for each previous word hypothesis h ∈ Bw , convert the soft attention C(h, ·) into a binary coverage set C, such that j ∈ C iff. C(h, j) > τcov . Identify the current NMT focus as ˆj = arg max 1≤j≤J, αh,j >τfocus αh,j . If there is no such j with αh,j > τfocus , no phrase hypotheses are generated from h in this step. Otherwise, for each source ph"
D17-1148,E17-2058,0,0.169713,"Missing"
E06-1005,A94-1016,0,0.788909,"speech recognition (ASR). Voting schemes like the ROVER approach of (Fiscus, 1997) use edit distance alignment and time information to create confusion networks from the output of several ASR systems. Some research on multi-engine machine translation has also been performed in recent years. The most straightforward approaches simply select, for each sentence, one of the provided hypotheses. The selection is made based on the scores of translation, language, and other models (Nomoto, 2004; Paul et al., 2005). Other approaches combine lattices or N -best lists from several different MT systems (Frederking and Nirenburg, 1994). To be successful, such approaches require compatible lattices and comparable scores of the (word) hypotheses in the lattices. However, the scores of most statistical machine translation (SMT) systems are not normalized and therefore not directly comparable. For some other MT systems (e.g. knowledge-based systems), the lattices and/or scores of hypotheses may not be even available. (Bangalore et al., 2001) used the edit distance alignment extended to multiple sequences to construct a confusion network from several translation hypotheses. This algorithm produces monotone alignments only (i. e."
E06-1005,C04-1032,1,0.483303,"n, we add a fraction of a count for words with identical prefixes. The initialization could be furthermore improved by using word classes, part-of-speech tags, or a list of synonyms. The model parameters are trained iteratively in an unsupervised manner with the EM algorithm using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions En → Em and Em → En . The updated lexicon tables from the two directions are interpolated after each iteration. The final alignments are determined using cost matrices defined by the state occupation probabilities of the trained HMM (Matusov et al., 2004). The alignments are used for reordering each secondary translation En and for computing the confusion network. 34 Figure 1: Example of creating a confusion network from monotone one-to-one word alignments (denoted with symbol |). The words of the primary hypothesis are printed in bold. The symbol $ denotes a null alignment or an ε-arc in the corresponding part of the confusion network. original hypotheses alignment and reordering confusion network 1. would you like coffee or tea 2. would you have tea or coffee 3. would you like your coffee or 4. I have some coffee tea would you like would|wou"
E06-1005,P04-1063,0,0.507184,"ple machine translation systems. Combining outputs from different systems was shown to be quite successful in automatic speech recognition (ASR). Voting schemes like the ROVER approach of (Fiscus, 1997) use edit distance alignment and time information to create confusion networks from the output of several ASR systems. Some research on multi-engine machine translation has also been performed in recent years. The most straightforward approaches simply select, for each sentence, one of the provided hypotheses. The selection is made based on the scores of translation, language, and other models (Nomoto, 2004; Paul et al., 2005). Other approaches combine lattices or N -best lists from several different MT systems (Frederking and Nirenburg, 1994). To be successful, such approaches require compatible lattices and comparable scores of the (word) hypotheses in the lattices. However, the scores of most statistical machine translation (SMT) systems are not normalized and therefore not directly comparable. For some other MT systems (e.g. knowledge-based systems), the lattices and/or scores of hypotheses may not be even available. (Bangalore et al., 2001) used the edit distance alignment extended to multi"
E06-1005,2001.mtsummit-papers.46,1,0.82518,"Missing"
E06-1005,J03-1002,1,0.0266526,"he single-word based lexicon probabilities p(en |em ) are initialized with normalized lexicon counts collected over the sentence pairs (En , Em ) on this corpus. Since all of the hypotheses are in the same language, we count co-occurring equal words, i. e. if en is the same word as em . In addition, we add a fraction of a count for words with identical prefixes. The initialization could be furthermore improved by using word classes, part-of-speech tags, or a list of synonyms. The model parameters are trained iteratively in an unsupervised manner with the EM algorithm using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions En → Em and Em → En . The updated lexicon tables from the two directions are interpolated after each iteration. The final alignments are determined using cost matrices defined by the state occupation probabilities of the trained HMM (Matusov et al., 2004). The alignments are used for reordering each secondary translation En and for computing the confusion network. 34 Figure 1: Example of creating a confusion network from monotone one-to-one word alignments (denoted with symbol |). The words of the primary hypothesis are printed in bold. The symbol"
E06-1005,P02-1040,0,0.115404,"TC-STAR evaluation (verbatim condition) was used for the EPPS task. In Table 1, the number of running words in English is the average number of running words in the hypotheses, from which the consensus translation was computed; the vocabulary of English is the merged vocabulary of these hypotheses. For the BTEC IWSLT04 corpus, the statistics for English is given for the experiments described in Sections 3.3 and 3.5, respectively. 3.2 Evaluation Criteria Well-established objective evaluation measures like the word error rate (WER), positionindependent word error rate (PER), and the BLEU score (Papineni et al., 2002) were used to assess the translation quality. All measures were computed with respect to multiple reference translations. The evaluation (as well as the alignment training) was case-insensitive, without considering the punctuation marks. 36 3.3 Chinese-English Translation Different applications of the proposed combination method have been evaluated. First, we focused on combining different MT systems which have the same source and target language. The initial experiments were performed on the BTEC Chinese-English task. We combined translations produced by 5 different MT systems. Table 2 shows"
E06-1005,2005.iwslt-1.5,0,0.0435604,"anslation systems. Combining outputs from different systems was shown to be quite successful in automatic speech recognition (ASR). Voting schemes like the ROVER approach of (Fiscus, 1997) use edit distance alignment and time information to create confusion networks from the output of several ASR systems. Some research on multi-engine machine translation has also been performed in recent years. The most straightforward approaches simply select, for each sentence, one of the provided hypotheses. The selection is made based on the scores of translation, language, and other models (Nomoto, 2004; Paul et al., 2005). Other approaches combine lattices or N -best lists from several different MT systems (Frederking and Nirenburg, 1994). To be successful, such approaches require compatible lattices and comparable scores of the (word) hypotheses in the lattices. However, the scores of most statistical machine translation (SMT) systems are not normalized and therefore not directly comparable. For some other MT systems (e.g. knowledge-based systems), the lattices and/or scores of hypotheses may not be even available. (Bangalore et al., 2001) used the edit distance alignment extended to multiple sequences to con"
E06-1005,C96-2141,1,\N,Missing
E06-1005,2004.iwslt-evaluation.1,0,\N,Missing
E17-2101,W16-3210,0,0.179052,"Missing"
E17-2101,N16-1101,0,0.0298551,"been successfully tackled by different groups using the sequence-to-sequence framework (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014). However, multi-modal MT has just recently been addressed by the MT community in a shared task (Specia et al., 2016). In NMT, Bahdanau et al. (2015) first proposed to use an attention mechanism in the decoder. Their decoder learns to attend to the relevant source-language words as it generates each word of the target sentence. Since then, many authors have proposed different ways to incorporate attention into MT (Luong et al., 2015; Firat et al., 2016; Tu et al., 2016). In the context of image description generation (IDG), Vinyals et al. (2015) proposed an influential neural IDG model based on the sequence-to-sequence framework and trained end-to-end. Elliott et al. (2015) put forward a model to generate multilingual descriptions of images by learning and transferring features between two independent, non-attentive neural image description models. Finally, Xu et al. (2015) proposed an attention-based model where a model learns to attend to specific areas of an image representation as it Acknowledgements The ADAPT Centre for Digital Content"
E17-2101,D16-1025,0,0.137277,"efore, we explore the potential of multi-modal, multilingual MT of auction listings’ titles and product images from English into German. To that end, we compare eBay’s production system, due to service-level agreements a classic phrase-based statistical MT (PBSMT) system, with two neural MT (NMT) systems. One of the NMT models is a text-only attentional NMT and the other is a multi-modal attentional NMT model trained using the product images as additional data. PBSMT still outperforms both text-only and multimodal NMT models in the translation of product listings, contrary to recent findings (Bentivogli et al., 2016). Under the hypothesis that the amount of training data could be the culprit and since curated multilingual, multi-modal in-domain data is very expensive to obtain, we back-translate monolingual listings and incorporate them as additional synthetic training data. Utilising synthetic data leads to big gains in performance and ultimately brings NMT models closer to bridging the gap with an optimized PBSMT system. We also use multi-modal NMT models to rescore the output of a PBSMT system and show significant improvements in TER (Snover et al., 2006). This paper is structured as follows. In §2 we"
E17-2101,P13-2121,0,0.0541374,"Missing"
E17-2101,W15-3001,0,0.0299657,"tion of the English description into German. Translating user-generated product listings has particular challenges; they are often ungrammatical and can be difficult to interpret in isolation even by a native speaker of the language, as can be seen in the examples in Table 1. To further demonstrate this issue, in Table 2 we show the number of running words as well as the perplexity scores obtained with LMs trained on three sets of different German corpora: the Multi30k, eBay’s in-domain data and a concatenation of the WMT 20152 Europarl (Koehn, 2005), Common Crawl and News Commentary corpora (Bojar et al., 2015).3 LM training #words Perplexity (×1000) corpus (×1000) eBay Multi30k WMT’15 Multi30k eBay 4310.0 29.0 99.0 60.1 25.2 1.8 0.5 0.05 4.2 Table 2: Perplexity on eBay and Multi30k’s test sets for LMs trained on different corpora. WMT’15 is the concatenation of the Europarl, Common Crawl and News Commentary corpora (the German side of the parallel English–German corpora). We see that different LM perplexities on eBay’s test set are high even for an LM trained on eBay in-domain data. LMs trained on mixed-domain corpora such as the WMT 2015 corpora or the Multi30k have perplexities below 500 on the M"
E17-2101,P16-1227,0,0.110564,"duct Listings Iacer Calixto1 , Daniel Stein2 , Evgeny Matusov2 , Pintu Lohar1 , Sheila Castilho1 and Andy Way1 1 ADAPT Centre, School of Computing, Dublin City University, Dublin, Ireland 2 eBay Inc., Aachen, Germany {iacer.calixto,pintu.lohar,sheila.castilho,andy.way}@adaptcentre.ie {danstein,ematusov}@ebay.com Abstract metric. Nevertheless, when presenting humans with images of the product which come along with the auction titles, the listings are perceived as somewhere between “easy” and “neutral” to understand. Images can bring useful complementary information to MT (Calixto et al., 2012; Hitschler et al., 2016; Huang et al., 2016). Therefore, we explore the potential of multi-modal, multilingual MT of auction listings’ titles and product images from English into German. To that end, we compare eBay’s production system, due to service-level agreements a classic phrase-based statistical MT (PBSMT) system, with two neural MT (NMT) systems. One of the NMT models is a text-only attentional NMT and the other is a multi-modal attentional NMT model trained using the product images as additional data. PBSMT still outperforms both text-only and multimodal NMT models in the translation of product listings, co"
E17-2101,W16-2358,0,0.397223,"Missing"
E17-2101,W16-2360,0,0.312031,"xto1 , Daniel Stein2 , Evgeny Matusov2 , Pintu Lohar1 , Sheila Castilho1 and Andy Way1 1 ADAPT Centre, School of Computing, Dublin City University, Dublin, Ireland 2 eBay Inc., Aachen, Germany {iacer.calixto,pintu.lohar,sheila.castilho,andy.way}@adaptcentre.ie {danstein,ematusov}@ebay.com Abstract metric. Nevertheless, when presenting humans with images of the product which come along with the auction titles, the listings are perceived as somewhere between “easy” and “neutral” to understand. Images can bring useful complementary information to MT (Calixto et al., 2012; Hitschler et al., 2016; Huang et al., 2016). Therefore, we explore the potential of multi-modal, multilingual MT of auction listings’ titles and product images from English into German. To that end, we compare eBay’s production system, due to service-level agreements a classic phrase-based statistical MT (PBSMT) system, with two neural MT (NMT) systems. One of the NMT models is a text-only attentional NMT and the other is a multi-modal attentional NMT model trained using the product images as additional data. PBSMT still outperforms both text-only and multimodal NMT models in the translation of product listings, contrary to recent find"
E17-2101,D13-1176,0,0.052574,"xplore in future work. We also found that NMT models trained on small in-domain data sets can still be successfully used to rescore a standard PBSMT system with significant improvements in TER. Since we know from our experiments with LM perplexities that these are very high for e-commerce data. i.e. fluency is quite low, it seems fitting that BLEU scores do not improve as much. In future work, we will also conduct a human evaluation of the translations generated by the various systems. Related work NMT has been successfully tackled by different groups using the sequence-to-sequence framework (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014). However, multi-modal MT has just recently been addressed by the MT community in a shared task (Specia et al., 2016). In NMT, Bahdanau et al. (2015) first proposed to use an attention mechanism in the decoder. Their decoder learns to attend to the relevant source-language words as it generates each word of the target sentence. Since then, many authors have proposed different ways to incorporate attention into MT (Luong et al., 2015; Firat et al., 2016; Tu et al., 2016). In the context of image description generation (IDG), Vinyals et al. (2015) propo"
E17-2101,W16-2359,1,0.899956,"s listed on the eBay main site1 . Product listings contain extremely high trigram perplexities even if trained (and applied) on in-domain data, which is a challenge not only for proper language models but also for automatic evaluation metrics such as the n-gram precision-based BLEU (Papineni et al., 2002) 1 2 Model We first briefly introduce the two text-only baselines used in this work: a PBSMT model (§2.1) and a textonly attentive NMT model (§2.2). We then discuss the doubly-attentive multi-modal NMT model that we use in our experiments (§2.3), which is comparable to the model introduced by Calixto et al. (2016). http://www.ebay.com/ 637 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 637–643, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics Figure 1: Decoder RNN with attention over source sentence and image features. This decoder learns to independently attend to image patches and source-language words when generating translations. 2.1 Statistical Machine Translation (SMT) tion mechanism. The attention mechanism computes a context vector ct for each time step t of the decoder"
E17-2101,W14-4012,0,0.177509,"Missing"
E17-2101,P07-2045,0,0.00850619,"uistics: Volume 2, Short Papers, pages 637–643, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics Figure 1: Decoder RNN with attention over source sentence and image features. This decoder learns to independently attend to image patches and source-language words when generating translations. 2.1 Statistical Machine Translation (SMT) tion mechanism. The attention mechanism computes a context vector ct for each time step t of the decoder where this vector is a weighted sum of the source annotation vectors C: We use a PBSMT model built with the Moses SMT Toolkit (Koehn et al., 2007). The language model (LM) is a 5-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995). We use minimum error rate training (Och, 2003) for tuning the model parameters for BLEU scores. 2.2 src T src src esrc t,i = (va ) tanh(Ua st−1 + Wa hi ), αsrc t,i = Text-only Neural Machine Translation (NMTt ) ct = We use the attentive NMT model introduced by Bahdanau et al. (2015) as our text-only NMT baseline. It is based on the encoder–decoder framework and it implements an attention mechanism over the sourcesentence words. Being X = (x1 , x2 , · · · , xN ) and Y = (y1 , y2 , · · · , yM ) a"
E17-2101,P11-2031,0,0.169281,"s in different languages. Altogether, we have a strong indication that images can indeed help an MT model translate product listings, especially for translations into German. 4 Model Table 4: Comparative results with PBSMT, NMTt and multi-modal models NMTm evaluated on eBay’s test set. Best PBSMT and NMT results in bold. best lists to be able to evaluate these two scenarios independently. We evaluate our models quantitatively using BLEU4 (Papineni et al., 2002) and TER (Snover et al., 2006) and report statistical significance computed using approximate randomisation with the Multeval toolkit (Clark et al., 2011). 5 Results In Table 4 we present quantitative results obtained with the two text-only baselines SMT and NMTt and one multi-modal model NMTm . It is clear that the gains from adding more data are much more apparent to the multi-modal NMTm model than to the two text-only ones. This can be attributed to the fact that this model has access to more data, i.e. image features, and consequently can learn better representations derived from them. The PBSMT model’s improvements are inconsistent; its TER score even deteriorates by 0.5 with the additional data. The same does not happen with the NMT model"
E17-2101,2005.mtsummit-papers.11,0,0.0574817,"Flickr, one description in English and one human translation of the English description into German. Translating user-generated product listings has particular challenges; they are often ungrammatical and can be difficult to interpret in isolation even by a native speaker of the language, as can be seen in the examples in Table 1. To further demonstrate this issue, in Table 2 we show the number of running words as well as the perplexity scores obtained with LMs trained on three sets of different German corpora: the Multi30k, eBay’s in-domain data and a concatenation of the WMT 20152 Europarl (Koehn, 2005), Common Crawl and News Commentary corpora (Bojar et al., 2015).3 LM training #words Perplexity (×1000) corpus (×1000) eBay Multi30k WMT’15 Multi30k eBay 4310.0 29.0 99.0 60.1 25.2 1.8 0.5 0.05 4.2 Table 2: Perplexity on eBay and Multi30k’s test sets for LMs trained on different corpora. WMT’15 is the concatenation of the Europarl, Common Crawl and News Commentary corpora (the German side of the parallel English–German corpora). We see that different LM perplexities on eBay’s test set are high even for an LM trained on eBay in-domain data. LMs trained on mixed-domain corpora such as the WMT 20"
E17-2101,W16-2361,0,0.129799,"Missing"
E17-2101,D15-1166,0,0.0619019,"Related work NMT has been successfully tackled by different groups using the sequence-to-sequence framework (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014). However, multi-modal MT has just recently been addressed by the MT community in a shared task (Specia et al., 2016). In NMT, Bahdanau et al. (2015) first proposed to use an attention mechanism in the decoder. Their decoder learns to attend to the relevant source-language words as it generates each word of the target sentence. Since then, many authors have proposed different ways to incorporate attention into MT (Luong et al., 2015; Firat et al., 2016; Tu et al., 2016). In the context of image description generation (IDG), Vinyals et al. (2015) proposed an influential neural IDG model based on the sequence-to-sequence framework and trained end-to-end. Elliott et al. (2015) put forward a model to generate multilingual descriptions of images by learning and transferring features between two independent, non-attentive neural image description models. Finally, Xu et al. (2015) proposed an attention-based model where a model learns to attend to specific areas of an image representation as it Acknowledgements The ADAPT Centre"
E17-2101,P03-1021,0,0.0568175,"th attention over source sentence and image features. This decoder learns to independently attend to image patches and source-language words when generating translations. 2.1 Statistical Machine Translation (SMT) tion mechanism. The attention mechanism computes a context vector ct for each time step t of the decoder where this vector is a weighted sum of the source annotation vectors C: We use a PBSMT model built with the Moses SMT Toolkit (Koehn et al., 2007). The language model (LM) is a 5-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995). We use minimum error rate training (Och, 2003) for tuning the model parameters for BLEU scores. 2.2 src T src src esrc t,i = (va ) tanh(Ua st−1 + Wa hi ), αsrc t,i = Text-only Neural Machine Translation (NMTt ) ct = We use the attentive NMT model introduced by Bahdanau et al. (2015) as our text-only NMT baseline. It is based on the encoder–decoder framework and it implements an attention mechanism over the sourcesentence words. Being X = (x1 , x2 , · · · , xN ) and Y = (y1 , y2 , · · · , yM ) a one-hot representation of a sentence in a source language and its translation into a target language, respectively, the model is trained to maximi"
E17-2101,Q14-1006,0,0.016563,"t sets used in our experiments consist of 480 and 444 triples, respectively. The curation of parallel product listings with an accompanying product image is costly and timeconsuming, so the in-domain data is rather small. More easily accessible are monolingual German listings accompanied by the product image where the source text input can be emulated by back-translating the target listing. For this set of experiments, we use 83, 832 tuples, henceforth mono. Finally, we also use the publicly available Multi30k dataset (Elliott et al., 2016), a multilingual expansion of the original Flickr30k (Young et al., 2014) with ∼30k pictures from Flickr, one description in English and one human translation of the English description into German. Translating user-generated product listings has particular challenges; they are often ungrammatical and can be difficult to interpret in isolation even by a native speaker of the language, as can be seen in the examples in Table 1. To further demonstrate this issue, in Table 2 we show the number of running words as well as the perplexity scores obtained with LMs trained on three sets of different German corpora: the Multi30k, eBay’s in-domain data and a concatenation of"
E17-2101,P02-1040,0,0.102634,"slation (MT). Among the challenges in automatic processing are the specialized language and grammar for listing titles, as well as a high percentage of user-generated content for nonbusiness sellers, who often are not native speakers themselves. We investigate the nature of user-generated auction listings’ titles as listed on the eBay main site1 . Product listings contain extremely high trigram perplexities even if trained (and applied) on in-domain data, which is a challenge not only for proper language models but also for automatic evaluation metrics such as the n-gram precision-based BLEU (Papineni et al., 2002) 1 2 Model We first briefly introduce the two text-only baselines used in this work: a PBSMT model (§2.1) and a textonly attentive NMT model (§2.2). We then discuss the doubly-attentive multi-modal NMT model that we use in our experiments (§2.3), which is comparable to the model introduced by Calixto et al. (2016). http://www.ebay.com/ 637 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 637–643, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics Figure 1: Decoder RNN with"
E17-2101,P16-1009,0,0.0443197,"tt et al., 2016) data sets. We also did not use any additional parallel, but out-of-domain data that had been used to train eBay’s PBSMT production system (see Section 5). Training our text-only NMTt baseline on this large corpus would not help shed more light on how multi-modality helps MT, since it has no images available and thus cannot be used to train the multimodal model NMTm . Rather, we report results of reranking experiments using n-best lists generated by eBay’s best-performing PBSMT production system. In order to measure the impact of the training data size on MT quality, we follow Sennrich et al. (2016) and back-translate the mono German product listings using our baseline NMTt model trained on the original 23, 697 German→English corpus (- images). These additional synthetic data (including images) are added to the original’s 23, 697 triples and used in our translation experiments. We do not include the back-translated data set when training NMT models for re-ranking n640 Model Training data baseline N BLEU oracle TER oracle Translation length — 29.0 — 53.0 — 13.60 ±2.59 NMTt NMTm 100k in-domain orig. + Multi30k 10 10 29.3 ↑ 0.3 29.4 ↑ 0.4 35.4 35.4 52.4 † ↓ 0.6 52.1 † ↓ 0.9 46.4 46.4 13.48"
E17-2101,W16-2363,0,0.0802193,"no significant difference between the length of translations for the baseline and the reranked models. 6 generates its description in natural language with a softattention mechanism. Although no purely neural multi-modal model to date has significantly improved on both text-only NMT and SMT models on the Multi30k data set (Specia et al., 2016), different research groups have proposed to include images in re-ranking n-best lists generated by an SMT system or directly in a NMT framework with some success (Caglayan et al., 2016; Calixto et al., 2016; Huang et al., 2016; Libovick´y et al., 2016; Shah et al., 2016). To the best of our knowledge, we are the first to study multi-modal NMT applied to the translation of product listings, i.e. for the e-commerce domain. 7 Conclusions and Future work In this paper, we investigate the potential impact of multi-modal NMT in the context of e-commerce product listings. With only a limited amount of multimodal and multilingual training data available, both text-only and multi-modal NMT models still fail to outperform a productive SMT system, contrary to recent findings (Bentivogli et al., 2016). However, the introduction of back-translated data leads to substantia"
E17-2101,2006.amta-papers.25,0,0.423403,"duct listings, contrary to recent findings (Bentivogli et al., 2016). Under the hypothesis that the amount of training data could be the culprit and since curated multilingual, multi-modal in-domain data is very expensive to obtain, we back-translate monolingual listings and incorporate them as additional synthetic training data. Utilising synthetic data leads to big gains in performance and ultimately brings NMT models closer to bridging the gap with an optimized PBSMT system. We also use multi-modal NMT models to rescore the output of a PBSMT system and show significant improvements in TER (Snover et al., 2006). This paper is structured as follows. In §2 we describe the text-only and multi-modal MT models we evaluate and in §3 the data sets we used, also introducing and discussing interesting findings. In §4 we discuss how we structure our quantitative evaluation, and in §5 we analyse and discuss our results. In §6 we discuss some relevant related work and in §7 we draw conclusions and devise future work. In this paper we study the impact of using images to machine-translate user-generated ecommerce product listings. We study how a multi-modal Neural Machine Translation (NMT) model compares to two t"
E17-2101,W16-2346,0,0.347903,"Missing"
I13-1167,P08-2039,0,0.0175651,"i and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008; Shilon et al., 2010). Most of these efforts are focused on syntactic and morphological processing. There have been a growing number of publications that consider translation into Arabic. Sarikaya and Deng (2007) use joint morphological-lexical language models to re-rank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limited to few studies. For example, Kathol and Zheng (2008) use unsupervised morpheme segmentation for Persian. They show that hierarchical phrase-based models can improve Persian-English translation. There are also other attempts to improve Persian-English SMT by working on syntactic reordering (Gupta et al., 2012) and rule-based post editing (Mohaghegh et al., 2012). There is also some work done on showing the effect of different orthographic and morphological processing for Persian on Persian-English translation (Raso"
I13-1167,2008.iwslt-papers.1,0,0.233477,"eve a large reduction of pivot translation model size. This paper is organized as follows. Section 2 briefly discusses some related work. Section 3 presents linguistic challenges and differences between Arabic and Persian. In Section 4, we discuss our pivoting strategies. Then Section 5 discusses our approach for selective combination. In Section 6, we present our experimental results. 2 2.1 Related Work Pivoting Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The core idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivoting strategies have been presented in the literature. The following two are perhaps the most commonly used.1 1 Another notable strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing piv"
I13-1167,P07-1092,0,0.142752,"arget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). A new source-target model is built from the new corpus. 1174 International Joint Conference on Natural Language Processing, pages 1174–1180, Nagoya, Japan, 14-18 October 2013. The first strategy is sentence pivoting in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (Khalilov et al., 2008). The second strategy is phrase pivoting (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009). In phrase pivoting, a new source-target phrase table (translation model) is induced from source-pivot and pivot-target phrase tables. We compute the lexical weights and translation probabilities from the two phrase tables. In this paper, we utilize the phrase pivoting strategy as our baseline, which is shown to be better in performance compared to sentence pivoting (El Kholy et al., 2013). 2.2 Domain Adaptation We propose a selective combination approach of pivot and direct SMT models to improve the translation quality. Our approach is similar to domain adaptation techniq"
I13-1167,eck-etal-2004-language,0,0.04032,"to sentence pivoting (El Kholy et al., 2013). 2.2 Domain Adaptation We propose a selective combination approach of pivot and direct SMT models to improve the translation quality. Our approach is similar to domain adaptation techniques where training data from many diverse sources are combined to build a single translation model which is used to translate sentences in a new domain. Domain adaptation has been explored in the field through different methods. Some methods involve information retrieval (IR) techniques to retrieve sentence pairs related to the target domain from a training corpus (Eck et al., 2004; Hildebrand et al., 2005). Other domain adaptation methods are based on distinguishing between general and domain specific examples (Daum´e III and Marcu, 2006). In a similar approach, Koehn and Schroeder (2007) use multiple alternative decoding paths to combine different translation models and the weights are set with minimum error rate training (Och and Ney, 2003). In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and co"
I13-1167,2010.jeptalnrecital-long.29,1,0.859126,"Missing"
I13-1167,P13-2073,1,0.467086,"Missing"
I13-1167,W09-0809,1,0.887405,"ith minimum error rate training (Och and Ney, 2003). In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008; Shilon et al., 2010). Most of these efforts are focused on syntactic and morphological processing. There have been a growing number of publications that consider translation into Arabic. Sarikaya and Deng (2007) use joint morphological-lexical language models to re-rank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010"
I13-1167,W12-5905,0,0.229138,"ank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limited to few studies. For example, Kathol and Zheng (2008) use unsupervised morpheme segmentation for Persian. They show that hierarchical phrase-based models can improve Persian-English translation. There are also other attempts to improve Persian-English SMT by working on syntactic reordering (Gupta et al., 2012) and rule-based post editing (Mohaghegh et al., 2012). There is also some work done on showing the effect of different orthographic and morphological processing for Persian on Persian-English translation (Rasooli et al., 2013a). To our knowledge, there hasn’t been a lot of work on Persian and Arabic as a language pair. One example is an effort based on improving the reordering models for Persian-Arabic SMT (Matusov and K¨opr¨u, 2010). Another recent effort improved the quality of Persian-Arabic by pivoting through English and adding additional features to reflect the quality of projected align"
I13-1167,W09-0431,1,0.896525,"f pivot translation model size. This paper is organized as follows. Section 2 briefly discusses some related work. Section 3 presents linguistic challenges and differences between Arabic and Persian. In Section 4, we discuss our pivoting strategies. Then Section 5 discusses our approach for selective combination. In Section 6, we present our experimental results. 2 2.1 Related Work Pivoting Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The core idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivoting strategies have been presented in the literature. The following two are perhaps the most commonly used.1 1 Another notable strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Berto"
I13-1167,P05-1071,1,0.669182,"+ È@ Al+ ‘the’, and the class of pronominal enclitics, e.g., Ñë+ +hm ‘their/them’. Beyond these clitics, Arabic words inflect for person, gender, number, 1175 aspect, mood, voice, state and case.2 This morphological richness leads to thousands of inflected forms per lemma and a high degree of ambiguity: about 12 analyses per word, typically corresponding to two lemmas on average (Habash, 2010). We follow El Kholy and Habash (2010a) and use the PATB tokenization scheme (Maamouri et al., 2004) in our experiments which separates all clitics except for the determiner clitic Al+. We use MADA v3.1 (Habash and Rambow, 2005; Habash et al., 2009) to tokenize the Arabic text. We only evaluate on detokenized and orthographically correct (enriched) output following the work of El Kholy and Habash (2010b). 4 Persian on the other hand has a relatively simple nominal system. There is no case system and words do not inflect with gender except for a few animate Arabic loanwords. Unlike Arabic, Persian shows only two values for number, just singular and plural (no dual), which are usually marked by + +An, either the suffix Aë+ +hA and sometimes à@ or one of the Arabic plural markers. Persian also possess a closed set of f"
I13-1167,N06-2013,1,0.802285,"In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008; Shilon et al., 2010). Most of these efforts are focused on syntactic and morphological processing. There have been a growing number of publications that consider translation into Arabic. Sarikaya and Deng (2007) use joint morphological-lexical language models to re-rank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limite"
I13-1167,A00-1002,0,0.114119,"Missing"
I13-1167,W11-2123,0,0.0397642,"ic parallel corpus is about 2.8M sentences (≈60M words) available from LDC5 and GALE6 constrained data. We use an in-house Persian-English parallel corpus of about 170K sentences and 4M words. Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). For English language modeling, we use the English Gigaword Corpus with 5-gram LM using the KenLM toolkit (Heafield, 2011). All experiments are conducted using Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weights optimization. For Persian-English translation model, weights are optimized using a set 1000 sentences randomly sampled from the parallel corpus while the English-Arabic translation model weights are optimized using a set of 500 sentences from the 2004 NIST MT evaluation test set 5 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56, LDC2008G"
I13-1167,2005.eamt-1.19,0,0.0268703,"ing (El Kholy et al., 2013). 2.2 Domain Adaptation We propose a selective combination approach of pivot and direct SMT models to improve the translation quality. Our approach is similar to domain adaptation techniques where training data from many diverse sources are combined to build a single translation model which is used to translate sentences in a new domain. Domain adaptation has been explored in the field through different methods. Some methods involve information retrieval (IR) techniques to retrieve sentence pairs related to the target domain from a training corpus (Eck et al., 2004; Hildebrand et al., 2005). Other domain adaptation methods are based on distinguishing between general and domain specific examples (Daum´e III and Marcu, 2006). In a similar approach, Koehn and Schroeder (2007) use multiple alternative decoding paths to combine different translation models and the weights are set with minimum error rate training (Och and Ney, 2003). In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct t"
I13-1167,2008.iwslt-evaluation.17,0,0.0182215,"ve side effect, we achieve a large reduction of pivot translation model size. This paper is organized as follows. Section 2 briefly discusses some related work. Section 3 presents linguistic challenges and differences between Arabic and Persian. In Section 4, we discuss our pivoting strategies. Then Section 5 discusses our approach for selective combination. In Section 6, we present our experimental results. 2 2.1 Related Work Pivoting Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The core idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivoting strategies have been presented in the literature. The following two are perhaps the most commonly used.1 1 Another notable strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target languag"
I13-1167,W07-0733,0,0.662668,"r to domain adaptation techniques where training data from many diverse sources are combined to build a single translation model which is used to translate sentences in a new domain. Domain adaptation has been explored in the field through different methods. Some methods involve information retrieval (IR) techniques to retrieve sentence pairs related to the target domain from a training corpus (Eck et al., 2004; Hildebrand et al., 2005). Other domain adaptation methods are based on distinguishing between general and domain specific examples (Daum´e III and Marcu, 2006). In a similar approach, Koehn and Schroeder (2007) use multiple alternative decoding paths to combine different translation models and the weights are set with minimum error rate training (Och and Ney, 2003). In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has b"
I13-1167,P07-2045,0,0.0204444,"n Persian. Each verb has a past and present root and many verbs have attached prefix that is regarded part of the root. A verb in Persian inflects for 14 different tense, mood, aspect, person, number and voice combination values (Rasooli et al., 2013b). In phrase pivoting (sometimes called triangulation or phrase table multiplication), we train a Persianto-Arabic and an English-Arabic translation models, such as those used in the sentence pivoting technique. Based on these two models, we induce a new Persian-Arabic translation model. Since we build our models are based Moses phrase-based SMT (Koehn et al., 2007), we provide the basic set of phrase translation probability distributions.3 We follow Utiyama and Isahara (2007) in computing the probability distributions. The following are the set of equations used to compute the lexical probabilities (φ) and the phrase translation probabilities (pw ) P φ(f |a) = φ(f |e)φ(e|a) e P φ(a|f ) = φ(a|e)φ(e|f ) Pe pw (f |a) = pw (f |e)pw (e|a) e P pw (a|f ) = pw (a|e)pw (e|f ) We follow El Kholy et al. (2013) and tokenize Persian text using Perstem (Jadidinejad et al., 2010) which is a deterministic rule based approach for segmentation of Persian. English, our pi"
I13-1167,2009.mtsummit-papers.7,0,0.118623,"tion 5 discusses our approach for selective combination. In Section 6, we present our experimental results. 2 2.1 Related Work Pivoting Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The core idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivoting strategies have been presented in the literature. The following two are perhaps the most commonly used.1 1 Another notable strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). A new source-target model is built from the new corpus. 1174 International Joint Conference on Natural Language Processing, pages 1174–1180, Nagoya, Japan, 14-18 October 2013. The first strategy is sentence pivoting in which we first tra"
I13-1167,2010.amta-papers.29,1,0.9262,"Missing"
I13-1167,C12-2085,0,0.114063,"her efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limited to few studies. For example, Kathol and Zheng (2008) use unsupervised morpheme segmentation for Persian. They show that hierarchical phrase-based models can improve Persian-English translation. There are also other attempts to improve Persian-English SMT by working on syntactic reordering (Gupta et al., 2012) and rule-based post editing (Mohaghegh et al., 2012). There is also some work done on showing the effect of different orthographic and morphological processing for Persian on Persian-English translation (Rasooli et al., 2013a). To our knowledge, there hasn’t been a lot of work on Persian and Arabic as a language pair. One example is an effort based on improving the reordering models for Persian-Arabic SMT (Matusov and K¨opr¨u, 2010). Another recent effort improved the quality of Persian-Arabic by pivoting through English and adding additional features to reflect the quality of projected alignments between the source and target phrases in the pi"
I13-1167,J03-1002,0,0.0354178,"in a new domain. Domain adaptation has been explored in the field through different methods. Some methods involve information retrieval (IR) techniques to retrieve sentence pairs related to the target domain from a training corpus (Eck et al., 2004; Hildebrand et al., 2005). Other domain adaptation methods are based on distinguishing between general and domain specific examples (Daum´e III and Marcu, 2006). In a similar approach, Koehn and Schroeder (2007) use multiple alternative decoding paths to combine different translation models and the weights are set with minimum error rate training (Och and Ney, 2003). In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a"
I13-1167,P03-1021,0,0.0703291,"ouse Persian-English parallel corpus of about 170K sentences and 4M words. Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). For English language modeling, we use the English Gigaword Corpus with 5-gram LM using the KenLM toolkit (Heafield, 2011). All experiments are conducted using Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weights optimization. For Persian-English translation model, weights are optimized using a set 1000 sentences randomly sampled from the parallel corpus while the English-Arabic translation model weights are optimized using a set of 500 sentences from the 2004 NIST MT evaluation test set 5 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56, LDC2008G05, LDC2009E16, LDC2009G01. 6 Global Autonomous Language Exploitation, or GALE, is a DARPA-funded research projec"
I13-1167,P02-1040,0,0.0926472,"odel weights are optimized using a set of 500 sentences from the 2004 NIST MT evaluation test set 5 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56, LDC2008G05, LDC2009E16, LDC2009G01. 6 Global Autonomous Language Exploitation, or GALE, is a DARPA-funded research project. 1177 (MT04). We use a maximum phrase length of size 8 across all models. We report results on an inhouse Persian-Arabic evaluation set of 536 sentences with three references. We evaluate using BLEU-4 (Papineni et al., 2002). For the combination experiments, Moses allows the use of multiple translation tables (Koehn and Schroeder, 2007). Different combination techniques are available. We use the “Either” combination technique where the translation options are collected from one table, and additional options are collected from the other tables. If the same translation option (identical source and target phrases) is found in multiple tables, separate translation options are created for each occurrence, but with different scores. 6.2 Baseline Evaluation We compare the performance of sentence pivoting against phrase"
I13-1167,I13-1144,1,0.852517,"Missing"
I13-1167,N13-1031,0,0.116805,"2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limited to few studies. For example, Kathol and Zheng (2008) use unsupervised morpheme segmentation for Persian. They show that hierarchical phrase-based models can improve Persian-English translation. There are also other attempts to improve Persian-English SMT by working on syntactic reordering (Gupta et al., 2012) and rule-based post editing (Mohaghegh et al., 2012). There is also some work done on showing the effect of different orthographic and morphological processing for Persian on Persian-English translation (Rasooli et al., 2013a). To our knowledge, there hasn’t been a lot of work on Persian and Arabic as a language pair. One example is an effort based on improving the reordering models for Persian-Arabic SMT (Matusov and K¨opr¨u, 2010). Another recent effort improved the quality of Persian-Arabic by pivoting through English and adding additional features to reflect the quality of projected alignments between the source and target phrases in the pivot phrase table (El Kholy et al., 2013). 3 Arabic and Persian Linguistic Issues In this section we present our motivation and choice for preprocessing Arabic, Persian and"
I13-1167,N07-2037,0,0.0224418,"them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008; Shilon et al., 2010). Most of these efforts are focused on syntactic and morphological processing. There have been a growing number of publications that consider translation into Arabic. Sarikaya and Deng (2007) use joint morphological-lexical language models to re-rank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limited to few studies. For example, Kathol and Zheng (2008) use unsupervised morpheme segmentation for Persian. They show that hierarchical phrase-based models can improve Persian-English translation. There are also other attempts to improve"
I13-1167,2010.amta-srw.4,1,0.854875,"new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008; Shilon et al., 2010). Most of these efforts are focused on syntactic and morphological processing. There have been a growing number of publications that consider translation into Arabic. Sarikaya and Deng (2007) use joint morphological-lexical language models to re-rank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008; El Kholy and Habash, 2010b). On the other hand, work on Persian SMT is limited to few studies. For example, Kathol and Zhen"
I13-1167,N07-1061,0,0.718603,"ly when the source and target languages are morphologically rich. Morphological richness comes with many challenges and the severity of these challenges increases when the richness and morphological complexity are expressed differently in the source and target languages. A common SMT solution to the lack of parallel data is to pivot the translation through a third language (called pivot or bridge language) for which there exist abundant parallel corpora with the source and target languages. The literature covers many pivoting techniques. One of the best performing techniques, phrase pivoting (Utiyama and Isahara, 2007), builds an induced new phrase table between the source and target. One of the problems of this technique is that the size of the newly created pivot phrase table is very large (Utiyama and Isahara, 2007). Given a parallel corpus between the source and target language, combining a direct model based on this parallel corpus with a pivot model could lead to better coverage and overall translation quality. However, the combination approach needs to be optimized in order to maximize the information gain. In this paper, we propose a selective combination approach of pivot and direct SMT models. The"
I13-1167,P09-1018,0,0.198898,"sizes). As a positive side effect, we achieve a large reduction of pivot translation model size. This paper is organized as follows. Section 2 briefly discusses some related work. Section 3 presents linguistic challenges and differences between Arabic and Persian. In Section 4, we discuss our pivoting strategies. Then Section 5 discusses our approach for selective combination. In Section 6, we present our experimental results. 2 2.1 Related Work Pivoting Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The core idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivoting strategies have been presented in the literature. The following two are perhaps the most commonly used.1 1 Another notable strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpu"
I13-1167,P10-1047,0,0.0220506,"els and the weights are set with minimum error rate training (Och and Ney, 2003). In contrast to domain adaptation, we generate a new source-target translation model by phrase pivoting technique from two models. We then use domain adaptation approach to select relevant portions of the pivot phrase table and combine them with a direct translation model to improve the overall translation quality. 2.3 Morphologically Rich Languages Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008; Shilon et al., 2010). Most of these efforts are focused on syntactic and morphological processing. There have been a growing number of publications that consider translation into Arabic. Sarikaya and Deng (2007) use joint morphological-lexical language models to re-rank the output of English-dialectal Arabic MT. Other efforts report results on the value of morphological tokenization of Arabic during training and describe different techniques for detokenizing Arabic output (Badr et al., 2008;"
I13-1167,H05-1021,0,\N,Missing
mauser-etal-2006-training,J93-2003,0,\N,Missing
mauser-etal-2006-training,C04-1006,1,\N,Missing
mauser-etal-2006-training,knight-al-onaizan-1998-translation,0,\N,Missing
mauser-etal-2006-training,W05-0801,0,\N,Missing
mauser-etal-2006-training,P03-1006,0,\N,Missing
mauser-etal-2006-training,J00-2004,0,\N,Missing
mauser-etal-2006-training,W05-0831,1,\N,Missing
mauser-etal-2006-training,J03-1002,1,\N,Missing
mauser-etal-2006-training,P04-1065,1,\N,Missing
N18-3012,P15-1001,0,0.103239,"Missing"
N18-3012,D14-1181,0,0.00705475,"Missing"
N18-3012,P07-2045,0,0.00510222,"s a standard subword-based encoder-decoder architecture with attention (Bahdanau et al., 2015), implemented with TensorFlow (Abadi et al., 2015). The model is trained with MLE on 2.7M parallel sentences of out-of-domain data until the early stopping point which is determined on a small in-domain dev set of 1,619 product title translations. A beam of size 12 and length normalization (Wu et al., 2016) are used for beam search decoding. For significance tests we used approximate randomization (Clark et al., 2011), for BLEU score evaluation (lowercased) the multi-bleu script of the Moses decoder (Koehn et al., 2007), for TER computation the tercom tool (Snover et al., 2006). For MRT, DC and (W)MIX models we set k = 5, for (W-)MIX models λ = 0.5 and α = 0.05. For all NMT models involving random sampling, we report average results and standard deviation (in subscript) over two runs. Further details about training data and hyperparameters settings are described in Appendix D.  ) (7) As for MRT, the expectation over the full output space is approximated with a subset of k sample translations S(x) ⊂ Y(x). Relative Rewards. With the objectives as defined above, gradient steps are dependent on the magnitude of"
N18-3012,P17-1138,1,0.805866,"d constitutes the “bandit feedback” scenario where the name is inspired by “one-armed bandit” slot machines. 92 Proceedings of NAACL-HLT 2018, pages 92–105 c New Orleans, Louisiana, June 1 - 6, 2018. 2017 Association for Computational Linguistics 2 Related Work Sokolov et al. (2016a,b) introduced learning from bandit feedback for SMT models in an interactive online learning scenario: the MT model receives a source sentence from the user, provides a translation, receives feedback from the user for this translation, and performs a stochastic gradient update proportional to the feedback quality. Kreutzer et al. (2017) showed that the objectives proposed for log-linear models can be transferred to neural sequence learning and found that standard control variate techniques do not only reduce variance but also help to produce best BLEU results. Nguyen et al. (2017) proposed a very similar approach using a learned word-based critic in an advantage actor-critic reinforcement learning framework. A comparison of current approaches was recently performed in a shared task where participants had to build translation models that learn from the interaction with a service that provided e-commerce product descriptions a"
N18-3012,E17-2101,1,0.847328,"an feedback is usually only available for one translation per input, learning from direct user rewards requires the use of bandit learning algorithms. In our setup, human bandit feedback has been collected for translations of a historic MT system different from the target system to be optimized. This restricts the learning setup to offline learning from logged bandit feedback. 2. Reward Scoring Function: A possibility to use human bandit feedback to obtain rewards for more than a single translation per input is 2 Most titles consist of a sequence of keywords rather than a fluent sentence. See Calixto et al. (2017) for a fluency analysis of product titles. 94 Query Translated Query Title Translated Title Recall candado bicicleta bicycle lock New Bicycle Vibration Code Moped Lock Bike Cycling Security Alarm Sound Lock Nuevo c´odigo de vibraci´on Bicicleta Ciclomotor alarma de seguridad de bloqueo Bicicleta Ciclismo Cerradura De Sonido 0.5 Table 2: Example for query and product title translation. ‘candado’ is translated to ‘lock’ in the query, but then translated back to ‘cerradura’ in the title. The recall metric would prefer a title translation with ‘candado’, as it was specified by the user. NMT from r"
N18-3012,P11-2031,0,0.0616966,"el that has not seen in-domain data (i.e., no product title translations). The NMT baseline model (BL) is a standard subword-based encoder-decoder architecture with attention (Bahdanau et al., 2015), implemented with TensorFlow (Abadi et al., 2015). The model is trained with MLE on 2.7M parallel sentences of out-of-domain data until the early stopping point which is determined on a small in-domain dev set of 1,619 product title translations. A beam of size 12 and length normalization (Wu et al., 2016) are used for beam search decoding. For significance tests we used approximate randomization (Clark et al., 2011), for BLEU score evaluation (lowercased) the multi-bleu script of the Moses decoder (Koehn et al., 2007), for TER computation the tercom tool (Snover et al., 2006). For MRT, DC and (W)MIX models we set k = 5, for (W-)MIX models λ = 0.5 and α = 0.05. For all NMT models involving random sampling, we report average results and standard deviation (in subscript) over two runs. Further details about training data and hyperparameters settings are described in Appendix D.  ) (7) As for MRT, the expectation over the full output space is approximated with a subset of k sample translations S(x) ⊂ Y(x)."
N18-3012,D17-1272,1,0.4516,"research is the fact that we assume a counterfactual learning scenario where human feedback has been given to a historic system different from the target system. Learning is done offline from logged data, which is desirable in commercial settings where system updates need to be tested before deployment and the risk of showing inferior translations to users needs to be avoided. Our offline learning algorithms range from a simple bandit-to-supervised conversion (i.e., using translations with good feedback for supervised tuning) to transferring the counterfactual learning techniques presented by Lawrence et al. (2017b) from statistical machine translation (SMT) to NMT models. To our surprise, the bandit-to-supervised conversion proved to be very hard to beat, despite theoretical indications of poor generalization for exploration-free learning from logged data (Langford et al., 2008; Strehl et al., 2010). However, we show that we can further improve over this method by computing a task-specific reward scoring function, resulting in significant improvements in both BLEU and in task-specific metrics. Introduction In commercial scenarios of neural machine translation (NMT), the one-best translation of a text"
N18-3012,2015.iwslt-evaluation.11,0,0.254138,"Missing"
N18-3012,D17-1153,0,0.118132,"Missing"
N18-3012,W16-2323,0,0.0429844,"Missing"
N18-3012,1983.tc-1.13,0,0.520197,"Missing"
N18-3012,P16-1009,0,0.0712429,"Missing"
N18-3012,P16-1162,0,0.255495,"Missing"
N18-3012,P16-1159,0,0.034768,"red. The second option uses logged queries to obtain a matching score as in Equation 2. R RW-MRT (θ) = Maximum Likelihood Estimation by Banditto-Supervised Conversion. Most commonly, NMT models are trained with Maximum Likelihood Estimation (MLE, Equation 3) on a given parallel corpus of source and target sequences D = {(x(s) , y(s) )}Ss=1 s=1 log pθ (y(s) |x(s) ). X qθα (˜ y|x(s) ) ∆(˜ y), (4) where sample probabilities are renormalized over a subset of translation samples S(x) ⊂ Y(x): α qθα (˜ y|x) = P 0 pθ (˜y|x) The hyper0 |x)α . p (y y ∈S(x) θ parameter α controls the sharpness of q (see Shen et al. (2016)). With sequence-level rewards, all words of a translation of length T are reinforced to the same extent and are treated as if they contributed equally to the translation quality. A word-based reward function, such as the match with a given query (Equation 1), allows the words to have individual weights. The following modification of the sequence-level MRT objective (Equation 4) accounts for word-based rewards ∆(yt ): In the following, we present how rewards can be integrated in various objectives for NMT training. S X (θ) = S X s=1 y ˜∈S(x(s) ) 3. Estimated Reward: Another option to extend ba"
N18-3012,2006.amta-papers.25,0,0.121633,"th attention (Bahdanau et al., 2015), implemented with TensorFlow (Abadi et al., 2015). The model is trained with MLE on 2.7M parallel sentences of out-of-domain data until the early stopping point which is determined on a small in-domain dev set of 1,619 product title translations. A beam of size 12 and length normalization (Wu et al., 2016) are used for beam search decoding. For significance tests we used approximate randomization (Clark et al., 2011), for BLEU score evaluation (lowercased) the multi-bleu script of the Moses decoder (Koehn et al., 2007), for TER computation the tercom tool (Snover et al., 2006). For MRT, DC and (W)MIX models we set k = 5, for (W-)MIX models λ = 0.5 and α = 0.05. For all NMT models involving random sampling, we report average results and standard deviation (in subscript) over two runs. Further details about training data and hyperparameters settings are described in Appendix D.  ) (7) As for MRT, the expectation over the full output space is approximated with a subset of k sample translations S(x) ⊂ Y(x). Relative Rewards. With the objectives as defined above, gradient steps are dependent on the magnitude of the reward for the current training instance. In reinforce"
N18-3012,P16-1152,1,0.806228,"achine translation (NMT), the one-best translation of a text is shown to multiple users who can reinforce highquality (or penalize low-quality) translations by explicit feedback (e.g., on a Likert scale) or implicit feedback (by clicking on a translated page). In such settings this type of feedback can be easily collected in large amounts. While bandit feedback1 in form of user clicks on displayed ads is the standard learning signal for response prediction in online advertising (Bottou et al., 2013), bandit learning for machine translation has so far been restricted to simulation experiments (Sokolov et al., 2016b; Lawrence et al., 2017b; ∗ The work for this paper was done while the first author was an intern at eBay. 1 The fact that only feedback for a single translation is collected constitutes the “bandit feedback” scenario where the name is inspired by “one-armed bandit” slot machines. 92 Proceedings of NAACL-HLT 2018, pages 92–105 c New Orleans, Louisiana, June 1 - 6, 2018. 2017 Association for Computational Linguistics 2 Related Work Sokolov et al. (2016a,b) introduced learning from bandit feedback for SMT models in an interactive online learning scenario: the MT model receives a source sentence"
P13-2073,2008.iwslt-papers.1,0,0.666324,"determine the quality of the pivot phrase pairs between source and target. We show positive results (0.6 BLEU points) on Persian-Arabic SMT. Next, we briefly discuss some related work. We then review two common pivoting strategies and how we use them in Section 3. This is followed by our approach to using connectivity strength features in Section 4. We present our experimental results in Section 5. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to"
P13-2073,P07-1092,0,0.588006,"t-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (Khalilov et al., 2008). The second strategy is based on phrase pivoting (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009). In phrase pivoting, a new source-target phrase table (translation model) is induced from source-pivot and pivottarget phrase tables. Lexical weights and translation probabilities are computed from the two translation models. The third strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). In this paper, we build on the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007). We e"
P13-2073,2010.jeptalnrecital-long.29,1,0.887227,"Missing"
P13-2073,W09-0809,1,0.77596,"e a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). In this paper, we build on the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007). We extend phrase table scores with two other features that are language independent. Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve the quality of translation. To our knowledge, there hasn’t been a lot of work on Persian and Arabic as a language pair. The only effort that we are aware of is based on improving the reordering models for PersianArabic SMT (Matusov and K¨opr¨u, 2010). 3 Pivoting Strategies In this section, we review the two pivoting strategies that are our baselines. We also discuss how we overcome the large expansion of source-totarget phrase pai"
P13-2073,W09-0431,1,0.571964,"f the pivot phrase pairs between source and target. We show positive results (0.6 BLEU points) on Persian-Arabic SMT. Next, we briefly discuss some related work. We then review two common pivoting strategies and how we use them in Section 3. This is followed by our approach to using connectivity strength features in Section 4. We present our experimental results in Section 5. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (K"
P13-2073,P05-1071,1,0.76893,"e.g., Ñë+ +hm ‘their/them’. Beyond these clitics, Arabic words inflect for person (P ER), gender (G EN), number (N UM), aspect (A SP), mood (M OD), voice (VOX), state (S TT) and case (C AS). This morphological richness leads to thousands of inflected forms per lemma and a high degree of ambiguity: about 12 analyses per word, typically corresponding to two lemmas on average (Habash, 2010) We follow El Kholy and Habash (2010a) and use the PATB tokenization scheme (Maamouri et al., 2004) in our experiments. which separates all clitics except for the determiner clitic Al+(D ET) We use MADA v3.1 (Habash and Rambow, 2005; Habash et al., 2009) to tokenize the Arabic text. We only evaluate on detokenized and orthographically correct (enriched) output following the work of El Kholy and Habash (2010b). Persian on the other hand has a relatively simple nominal system. There is no case system and words do not inflect with gender except for a few animate Arabic loanwords. Unlike Arabic, Persian shows only two values for number, just singular and plural (no dual), which are usually marked by + +An, either the suffix Aë+ +hA and sometimes à@ or one of the Arabic plural markers. Persian also possess a closed set of few"
P13-2073,N06-2013,1,0.877582,"pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). In this paper, we build on the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007). We extend phrase table scores with two other features that are language independent. Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve the quality of translation. To our knowledge, there hasn’t been a lot of work on Persian and Arabic as a language pair. The only effort that we are aware of is based on improving the reordering models for PersianArabic SMT (Matusov and K¨opr¨u, 2010). 3 Pivoting Strategies In this section, we review the two pivoting strategies that are our baselines. We also discuss how we overcome the large expansion of source-totarget phrase pairs in the process of creating a pivot phrase table."
P13-2073,A00-1002,0,0.293724,"Missing"
P13-2073,W11-2123,0,0.0150908,"Arabic parallel corpus is about 2.8M sentences (≈60M words) available from LDC4 and GALE5 constrained data. We use an in-house Persian-English parallel corpus of about 170K sentences and 4M words. Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). For English language modeling, we use English Gigaword Corpus with 5-gram LM using the KenLM toolkit (Heafield, 2011). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight 4 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56, LDC2008G05, LDC2009E16, LDC2009G01. 5 Global Autonomous Language Exploitation, or GALE, is a DARPA-funded research project. optimization. For Persian-English translation model, weights are optimized using a set 1000 sentences randomly sampled from the parallel corpus while the English"
P13-2073,2008.iwslt-evaluation.17,0,0.361269,"ndependent features to determine the quality of the pivot phrase pairs between source and target. We show positive results (0.6 BLEU points) on Persian-Arabic SMT. Next, we briefly discuss some related work. We then review two common pivoting strategies and how we use them in Section 3. This is followed by our approach to using connectivity strength features in Section 4. We present our experimental results in Section 5. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivo"
P13-2073,P07-2045,0,0.0309558,"between two separate phrase-based MT systems; Persian-English direct system and EnglishArabic direct system. Given a Persian sentence, we first translate the Persian sentence from Persian to English, and then from English to Arabic. 3.2 Phrase Pivoting In phrase pivoting (sometimes called triangulation or phrase table multiplication), we train a Persianto-Arabic and an English-Arabic translation models, such as those used in the sentence pivoting technique. Based on these two models, we induce a new Persian-Arabic translation model. Since we build our models on top of Moses phrase-based SMT (Koehn et al., 2007), we need to provide the same set of phrase translation probability distributions.1 We follow Utiyama and Isahara (2007) in computing the probability distributions. The following are the set of equations used to compute the lexical probabilities (φ) and the phrase probabilities (pw ) P φ(f |a) = φ(f |e)φ(e|a) e P φ(a|f ) = φ(a|e)φ(e|f ) Pe pw (f |a) = pw (f |e)pw (e|a) e P pw (a|f ) = pw (a|e)pw (e|f ) e where f is the Persian source phrase. e is the English pivot phrase that is common in both Persian-English translation model and EnglishArabic translation model. a is the Arabic target phrase."
P13-2073,2009.mtsummit-papers.7,0,0.0443296,"by our approach to using connectivity strength features in Section 4. We present our experimental results in Section 5. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (Khalilov et al., 2008). The second strategy is based on phrase pivoting (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009). In phrase pivoting, a new source-target phrase table (translation model) is induced from source-pivot and pivottar"
P13-2073,W04-3250,0,0.221711,"Missing"
P13-2073,W07-0734,0,0.0565513,"ct. optimization. For Persian-English translation model, weights are optimized using a set 1000 sentences randomly sampled from the parallel corpus while the English-Arabic translation model weights are optimized using a set of 500 sentences from the 2004 NIST MT evaluation test set (MT04). The optimized weights are used for ranking and filtering (discussed in Section 3.3). We use a maximum phrase length of size 8 across all models. We report results on an inhouse Persian-Arabic evaluation set of 536 sentences with three references. We evaluate using BLEU-4 (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007). 5.2 Linguistic Preprocessing In this section we present our motivation and choice for preprocessing Arabic, Persian, English data. Both Arabic and Persian are morphologically complex languages but they belong to two different language families. They both express richness and linguistic complexities in different ways. One aspect of Arabic’s complexity is its various attachable clitics and numerous morphological features (Habash, 2010). which include conjunction proclitics, e.g., +ð w+ ‘and’, particle proclitics, e.g., + È l+ ‘to/for’, the definite article + È@ Al+ ‘the’, and the class of pron"
P13-2073,2010.amta-papers.29,1,0.90408,"Missing"
P13-2073,J03-1002,0,0.0163657,"he&quot;country’&quot; Figure 2: An example of weakly connected Persian-Arabic phrase pairs through English. Only one Persian word is connected to an Arabic word. SCS=0.25 and TCS=0.2. 5.1 Experimental Setup In our pivoting experiments, we build two SMT models. One model to translate from Persian to English and another model to translate from English to Arabic. The English-Arabic parallel corpus is about 2.8M sentences (≈60M words) available from LDC4 and GALE5 constrained data. We use an in-house Persian-English parallel corpus of about 170K sentences and 4M words. Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). For English language modeling, we use English Gigaword Corpus with 5-gram LM using the KenLM toolkit (Heafield, 2011). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight 4 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E"
P13-2073,P03-1021,0,0.0355814,"ouse Persian-English parallel corpus of about 170K sentences and 4M words. Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). For English language modeling, we use English Gigaword Corpus with 5-gram LM using the KenLM toolkit (Heafield, 2011). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight 4 LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56, LDC2008G05, LDC2009E16, LDC2009G01. 5 Global Autonomous Language Exploitation, or GALE, is a DARPA-funded research project. optimization. For Persian-English translation model, weights are optimized using a set 1000 sentences randomly sampled from the parallel corpus while the English-Arabic translation model weights are optimized using a set of 500 sentences from the 2004 NIST MT evaluation test se"
P13-2073,P02-1040,0,0.0995031,"E, is a DARPA-funded research project. optimization. For Persian-English translation model, weights are optimized using a set 1000 sentences randomly sampled from the parallel corpus while the English-Arabic translation model weights are optimized using a set of 500 sentences from the 2004 NIST MT evaluation test set (MT04). The optimized weights are used for ranking and filtering (discussed in Section 3.3). We use a maximum phrase length of size 8 across all models. We report results on an inhouse Persian-Arabic evaluation set of 536 sentences with three references. We evaluate using BLEU-4 (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007). 5.2 Linguistic Preprocessing In this section we present our motivation and choice for preprocessing Arabic, Persian, English data. Both Arabic and Persian are morphologically complex languages but they belong to two different language families. They both express richness and linguistic complexities in different ways. One aspect of Arabic’s complexity is its various attachable clitics and numerous morphological features (Habash, 2010). which include conjunction proclitics, e.g., +ð w+ ‘and’, particle proclitics, e.g., + È l+ ‘to/for’, the definite article"
P13-2073,N13-1031,0,0.0210977,"n’t have separate forms for singular and plural. When a noun is modified by one or more adjective, the indefinite article is attached to the last adjective. Persian adjectives are similar to English in expressing comparative and superlative constructions just by adding suffixes QK+ +tar QK+ +taryn ‘+est’ respectively. Verbal ‘+er’ and áK morphology is very complex in Persian. Each verb has a past and present root and many verbs have attached prefix that is regarded part of the root. A verb in Persian inflects for 14 different tense, mood, aspect, person, number and voice combination values (Rasooli et al., 2013). We use Perstem (Jadidinejad et al., 2010) for segmenting Persian text. English, our pivot language, is quite different from both Arabic and Persian. English is poor in morphology and barely inflects for number and tense, and for person in a limited context. English preprocessing simply includes down-casing, separating punctuation and splitting off “’s”. 5.3 Baseline Evaluation We compare the performance of sentence pivoting against phrase pivoting with different filtering thresholds. The results are presented in Table 2. In general, the phrase pivoting outperforms the sentence pivoting even"
P13-2073,N07-1061,0,0.900714,"ults (0.6 BLEU points) on Persian-Arabic SMT as a case study. 1 Introduction One of the main issues in statistical machine translation (SMT) is the scarcity of parallel data for many language pairs especially when the source and target languages are morphologically rich. A common SMT solution to the lack of parallel data is to pivot the translation through a third language (called pivot or bridge language) for which there exist abundant parallel corpora with the source and target languages. The literature covers many pivoting techniques. One of the best performing techniques, phrase pivoting (Utiyama and Isahara, 2007), builds an induced new phrase table between the source and target. One of the main issues of this technique is that the size of the newly created pivot phrase table is very large (Utiyama and Isahara, 2007). Moreover, many of the produced phrase pairs are of low quality which affects the translation choices during decoding and the overall translation quality. In this paper, we introduce language independent features to determine the quality of the pivot phrase pairs between source and target. We show positive results (0.6 BLEU points) on Persian-Arabic SMT. Next, we briefly discuss some relat"
P13-2073,P09-1018,0,0.190156,"ntroduce language independent features to determine the quality of the pivot phrase pairs between source and target. We show positive results (0.6 BLEU points) on Persian-Arabic SMT. Next, we briefly discuss some related work. We then review two common pivoting strategies and how we use them in Section 3. This is followed by our approach to using connectivity strength features in Section 4. We present our experimental results in Section 5. 2 Related Work Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajiˇc et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are perhaps the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and"
P13-2073,P10-1047,0,0.02119,"he third strategy is to create a synthetic sourcetarget corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). In this paper, we build on the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007). We extend phrase table scores with two other features that are language independent. Since both Persian and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010a; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve the quality of translation. To our knowledge, there hasn’t been a lot of work on Persian and Arabic as a language pair. The only effort that we are aware of is based on improving the reordering models for PersianArabic SMT (Matusov and K¨opr¨u, 2010). 3 Pivoting Strategies In this section, we review the two pivoting strategies that are our baselines. We also discuss how we overcome the large expansion of s"
P13-2073,H05-1021,0,\N,Missing
P18-2052,W17-3205,0,0.106544,"T errors in a given translated sentence, sometimes with the help of e.g. an accompanying image, video, or simply prior knowledge. A common approach to get user feedback for MT is explicit ratings of translations on an n-point 326 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 326–331 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics incorrect. They modify NMT model to also accept the marked target sentence as input and train it to produce similar sentences that do not contain marked words. (Chen et al., 2017; Wang et al., 2017) have proposed sentence level weighting method for domain adaptation in NMT. The rest of this paper is structured as follows. In Section 2 we review related work. We describe our partial feedback approach in Section 3. Next we present our experimental results in Section 4, followed by the conclusion in Section 5. 2 Related work Integrating user ratings in NMT has been studied in (Kreutzer et al., 2017), who view this as a bandit structured prediction task. They demonstrate how the user feedback can be integrated into NMT training and perform a series of experiments using GL"
P18-2052,N18-3012,1,0.842375,"vely generate the translation, their goal is to minimize the required human involvement. They performed simulated experiments using chrF (Popovic, 2015) as simulated feedback. In all previous works feedback needs to be generated on-line during the training process, however in this paper we focus on the case where there might be a significant time lag between generation of translation and acquiring of the feedback. Lawrence et al. (2017) have proposed a method to leverage user feedback that is available only for logged translated data for a phrase-based statistical machine translation system. (Kreutzer et al., 2018) have experimented with sentence level star ratings collected from real users of an e-commerce site for logged translation data, but found the feedback to be too noisy to gain improvements. They also proposed using implicit word level task feedback based on query matching in an e-commerce application to improve both translation quality and task specific metrics. Marie and Max (2015) have proposed an interactive framework which iteratively improves translation generated by the phrase-based system by asking users to select correct parts. Domingo et al. (2016) extended this idea to also include w"
P18-2052,P17-1138,0,0.0642404,"Missing"
P18-2052,2006.amta-papers.25,0,0.0898167,"sentence level weighting method (Chen et al., 2017; Wang et al., 2017). The special case of sentence level weight can be expressed as wi = w, ∀i , where w is the weight for sentence e˜I1 . 327 of-domain data and 800K sentence pairs sampled from back-translated monolingual and unused parallel corpora as in-domain data. For En-Es we have 2.7M out-of-domain and 1.5M in-domain sentence pairs. We evaluate our models on newstest2016 (2999 sentence pairs) for the De-En task and an in-house test set of 1000 sentence pairs for the En-Es task using case-insensitive BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). We have implemented our NMT model using TensorFlow (Abadi et al., 2015) library. Our encoder is a bidirectional LSTM with a layer size of 512; our decoder is an LSTM with 2 layers of the same size. We also use embedding size of 512 and MLP attention layer. We train our networks using SGD with a learning rate schedule that starts gradually decaying to 0.01 after the initial 4 epochs. As regularization we use dropout on the RNN inputs with dropping probability of 0.2. We differentiate between two practical methods of obtaining the partial feedback data. First, gathering the feedback from human"
P18-2052,D18-1397,0,0.050232,"Next we present our experimental results in Section 4, followed by the conclusion in Section 5. 2 Related work Integrating user ratings in NMT has been studied in (Kreutzer et al., 2017), who view this as a bandit structured prediction task. They demonstrate how the user feedback can be integrated into NMT training and perform a series of experiments using GLEU (Wu et al., 2016) to simulate user feedback. Nguyen et al. (2017) have also studied this problem and adapted an actor-critic approach (Mnih et al., 2016) which has shown to be robust to skewed, high variance feedback from real users. (Lam et al., 2018) extended the work of (Nguyen et al., 2017) by asking users to provide feedback for partial hypotheses to iteratively generate the translation, their goal is to minimize the required human involvement. They performed simulated experiments using chrF (Popovic, 2015) as simulated feedback. In all previous works feedback needs to be generated on-line during the training process, however in this paper we focus on the case where there might be a significant time lag between generation of translation and acquiring of the feedback. Lawrence et al. (2017) have proposed a method to leverage user feedba"
P18-2052,D17-1272,0,0.0184362,"to skewed, high variance feedback from real users. (Lam et al., 2018) extended the work of (Nguyen et al., 2017) by asking users to provide feedback for partial hypotheses to iteratively generate the translation, their goal is to minimize the required human involvement. They performed simulated experiments using chrF (Popovic, 2015) as simulated feedback. In all previous works feedback needs to be generated on-line during the training process, however in this paper we focus on the case where there might be a significant time lag between generation of translation and acquiring of the feedback. Lawrence et al. (2017) have proposed a method to leverage user feedback that is available only for logged translated data for a phrase-based statistical machine translation system. (Kreutzer et al., 2018) have experimented with sentence level star ratings collected from real users of an e-commerce site for logged translation data, but found the feedback to be too noisy to gain improvements. They also proposed using implicit word level task feedback based on query matching in an e-commerce application to improve both translation quality and task specific metrics. Marie and Max (2015) have proposed an interactive fra"
P18-2052,2015.iwslt-evaluation.11,0,0.108885,"Missing"
P18-2052,D17-1155,0,0.0989618,"translated sentence, sometimes with the help of e.g. an accompanying image, video, or simply prior knowledge. A common approach to get user feedback for MT is explicit ratings of translations on an n-point 326 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 326–331 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics incorrect. They modify NMT model to also accept the marked target sentence as input and train it to produce similar sentences that do not contain marked words. (Chen et al., 2017; Wang et al., 2017) have proposed sentence level weighting method for domain adaptation in NMT. The rest of this paper is structured as follows. In Section 2 we review related work. We describe our partial feedback approach in Section 3. Next we present our experimental results in Section 4, followed by the conclusion in Section 5. 2 Related work Integrating user ratings in NMT has been studied in (Kreutzer et al., 2017), who view this as a bandit structured prediction task. They demonstrate how the user feedback can be integrated into NMT training and perform a series of experiments using GLEU (Wu et al., 2016)"
P18-2052,D15-1120,0,0.285388,"and acquiring of the feedback. Lawrence et al. (2017) have proposed a method to leverage user feedback that is available only for logged translated data for a phrase-based statistical machine translation system. (Kreutzer et al., 2018) have experimented with sentence level star ratings collected from real users of an e-commerce site for logged translation data, but found the feedback to be too noisy to gain improvements. They also proposed using implicit word level task feedback based on query matching in an e-commerce application to improve both translation quality and task specific metrics. Marie and Max (2015) have proposed an interactive framework which iteratively improves translation generated by the phrase-based system by asking users to select correct parts. Domingo et al. (2016) extended this idea to also include word deletions and substitutions with the goal of reducing human effort in translation. Grangier and Auli (2017) have studied the task of paraphrasing an already generated translation by excluding words that the user has marked as 3 Method In this work we use the encoder-decoder NMT architecture with attention, proposed by (Bahdanau et al., 2014; Sutskever et al., 2014). NMT model is"
P18-2052,D17-1153,0,0.0394366,"Missing"
P18-2052,P02-1040,0,0.101907,"be seen as a generalization of sentence level weighting method (Chen et al., 2017; Wang et al., 2017). The special case of sentence level weight can be expressed as wi = w, ∀i , where w is the weight for sentence e˜I1 . 327 of-domain data and 800K sentence pairs sampled from back-translated monolingual and unused parallel corpora as in-domain data. For En-Es we have 2.7M out-of-domain and 1.5M in-domain sentence pairs. We evaluate our models on newstest2016 (2999 sentence pairs) for the De-En task and an in-house test set of 1000 sentence pairs for the En-Es task using case-insensitive BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). We have implemented our NMT model using TensorFlow (Abadi et al., 2015) library. Our encoder is a bidirectional LSTM with a layer size of 512; our decoder is an LSTM with 2 layers of the same size. We also use embedding size of 512 and MLP attention layer. We train our networks using SGD with a learning rate schedule that starts gradually decaying to 0.01 after the initial 4 epochs. As regularization we use dropout on the RNN inputs with dropping probability of 0.2. We differentiate between two practical methods of obtaining the partial feedback data. First, gat"
P18-2052,W15-3049,0,0.0135755,"user feedback can be integrated into NMT training and perform a series of experiments using GLEU (Wu et al., 2016) to simulate user feedback. Nguyen et al. (2017) have also studied this problem and adapted an actor-critic approach (Mnih et al., 2016) which has shown to be robust to skewed, high variance feedback from real users. (Lam et al., 2018) extended the work of (Nguyen et al., 2017) by asking users to provide feedback for partial hypotheses to iteratively generate the translation, their goal is to minimize the required human involvement. They performed simulated experiments using chrF (Popovic, 2015) as simulated feedback. In all previous works feedback needs to be generated on-line during the training process, however in this paper we focus on the case where there might be a significant time lag between generation of translation and acquiring of the feedback. Lawrence et al. (2017) have proposed a method to leverage user feedback that is available only for logged translated data for a phrase-based statistical machine translation system. (Kreutzer et al., 2018) have experimented with sentence level star ratings collected from real users of an e-commerce site for logged translation data, b"
P18-2052,P16-1162,0,0.114634,"Missing"
P18-2052,W17-4717,0,\N,Missing
W05-0831,W00-0508,0,0.172433,"Missing"
W05-0831,2004.iwslt-evaluation.13,1,0.903041,"the reordering problem from the view of the model. Without reordering both in training and during search, sentences can only be translated properly into a language with similar word order. In (Bangalore et al., 2000) weighted reordering has been applied to target sentences since defining a permutation model on the source side is impractical in combination with speech recognition. In order to reduce the computational complexity, this approach considers only a set of plausible reorderings seen on training data. Most other phrase-based statistical approaches like the Alignment Template system of Bender et al. (2004) rely on (local) reorderings which are implicitly memorized with each pair of source and target phrases in training. Additional reorderings on phrase level are fully integrated into the decoding process, which increases the complexity of the system and makes it hard to modify. Zens et al. (2003) reviewed two types of reordering constraints for this type of translation systems. In our work we follow a phrase-based translation approach, applying source sentence reordering on word level. We compute a reordering graph ondemand and take it as input for monotonic translation. This approach is modula"
W05-0831,P04-1065,1,0.437186,"Missing"
W05-0831,knight-al-onaizan-1998-translation,0,0.507961,"Missing"
W05-0831,N03-1019,0,0.120471,"Missing"
W05-0831,C04-1032,1,0.655504,"he empty phrase. Therefore, for language pairs with big differences in word order, probability estimates may be poor. This problem can be solved by reordering either source or target training sentences such that alignments become monotonic for all sentences. We suggest the following consistent source sentence reordering and alignment monotonization approach in which we compute optimal, minimum-cost alignments. First, we estimate a cost matrix C for each sentence pair (f1J , eI1 ). The elements of this matrix cij are the local costs of aligning a source word fj to a target word ei . Following (Matusov et al., 2004), we compute these local costs by interpolating state occupation probabilities from the source-to-target and target-to-source training of the HMM and IBM-4 models as trained by the GIZA++ toolkit (Och et al., 2003). For a given alignment A ⊆ I × J, we define the costs of this alignment c(A) as the sum of the local costs of all aligned word pairs: X c(A) = cij (1) A∈A ∼ = argmax max e˜J 1 (fj , e˜j ). Mapping the bilingual language model to a WFST T is canonical and it has been shown in (Kanthak et al., 2004) that the search problem can then be rewritten using finite-state terminology: j−1 p(fj"
W05-0831,J03-1002,1,0.0715111,"Missing"
W05-0831,P02-1040,0,0.119703,"Missing"
W05-0831,J97-3002,0,0.168153,"well-known in the field of machine translation and were first described in (Berger et al., 1996). The idea behind these constraints is to deviate from monotonic translation by postponing translations of a limited number of words. More specifically, at each state we can translate any of the first l yet uncovered word positions. The implementation using a bit vector is straightforward. For consistency, we associate window size with the parameter l for all constraints presented here. 4.3 1000 ITG Constraints Another type of reordering can be obtained using Inversion Transduction Grammars (ITG) (Wu, 1997). These constraints are inspired by bilingual bracketing. They proved to be quite useful for machine translation, e.g. see (Bender et al., 2004). Here, we interpret the input sentence as a sequence of segments. In the beginning, each word is a segment of its own. Longer segments are constructed by recursively combining two adjacent segments. At each 1 both covered and uncovered train dev test sentences words singletons vocabulary sentences words sentence length (avg/max) sentences words sentence length (avg/max) Chinese English 20 000 182 904 160 523 3 525 2 948 7 643 6 982 506 3 515 3 595 6.9"
W05-0831,2002.tmi-tutorials.2,0,0.0628056,"ermutations as a finite-state automaton requires at least 2J states. Therefore, we opt for computing the permutation automaton on-demand while applying beam pruning in the search. 4.1 Lazy Permutation Automata For on-demand computation of an automaton in the flavor described in (Kanthak et al., 2004) it is sufficient to specify a state description and an algorithm that calculates all outgoing arcs of a state from the state description. In our case, each state represents a permutation of a subset of the source words f1J , which are already translated. This can be described by a bit vector bJ1 (Zens et al., 2002). Each bit of the state bit vector corresponds to an arc of the linear input automaton and is set to one if the arc has been used on any path from the initial to the current state. The bit vectors of two states connected by an arc differ only in a single bit. Note that bit vectors elegantly solve the problem of recombining paths in the automaton as states with the same bit vectors can be merged. As a result, a fully minimized permutation automaton has only a single initial and final state. Even with on-demand computation, complexity using full permutations is unmanagable for long sentences. We"
W05-0831,P03-1019,1,0.772763,"Missing"
W05-0831,J04-2004,0,\N,Missing
W05-0831,2004.iwslt-evaluation.1,0,\N,Missing
W09-0407,J03-1002,1,0.0116554,"etween the hypotheses are calculated. The hypotheses are then reordered to match the word order of a selected primary hypothesis. From this, we create a confusion network (CN), which we then rescore using 1 A test corpus can be used directly because the alignment training is unsupervised and only automatically produced translations are considered. Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 51–55, c Athens, Greece, 30 March – 31 March 2009. 2009 Association for Computational Linguistics 51 The model parameters are trained iteratively using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions Em → En and En → Em . After each iteration, the updated lexicon tables from the two directions are interpolated. The final alignments are determined using a cost matrix C for each sentence pair (Em , En ). Elements of this matrix are the local costs C(j, i) of aligning a word em,j from Em to a word en,i from En . Following Matusov et al. (2004), we compute these local costs by interpolating the negated logarithms of the state occupation probabilities from the “source-to-target” and “target-tosource” training of the HMM model. Two different alignmen"
W09-0407,P02-1040,0,0.0861447,"Missing"
W09-0407,P07-1040,0,0.109336,"dd a fraction of a count for words with identical prefixes. Introduction The RWTH approach to MT system combination is a refined version of the ROVER approach in ASR (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using the prior probabilities for each system as well as other statistical models such as a special n-gram language model. 2 System Combination Algorithm In this section we present the details of our system combination method. Figure 1 gives an overview of the system combination architecture described in this section. After preprocessing the MT hypotheses, pairwise alignments between th"
W09-0407,J93-2003,0,0.0100691,"its translations En , n = 1, . . . , M, as the primary hypothesis. Then we align the secondary hypotheses Em (m = 1, . . . , M ; n 6= m) with En to match the word order in En . Since it is not clear which hypothesis should be primary, i. e. has the “best” word order, we let every hypothesis play the role of the primary translation, and align all pairs of hypotheses (En , Em ); n 6= m. The word alignment is trained in analogy to the alignment training procedure in statistical MT. The difference is that the two sentences that have to be aligned are in the same language. We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) to estimate the alignment model. The alignment training corpus is created from a test corpus1 of effectively M · (M − 1) · N sentences translated by the involved MT engines. The single-word based lexicon probabilities p(e|e0 ) are initialized from normalized lexicon counts collected over the sentence pairs (Em , En ) on this corpus. Since all of the hypotheses are in the same language, we count co-occurring identical words, i. e. whether em,j is the same word as en,i for some i and j. In addition, we add a fraction of a count for words w"
W09-0407,2006.amta-papers.25,0,0.222309,"Missing"
W09-0407,C96-2141,1,0.705159,"hypothesis. Then we align the secondary hypotheses Em (m = 1, . . . , M ; n 6= m) with En to match the word order in En . Since it is not clear which hypothesis should be primary, i. e. has the “best” word order, we let every hypothesis play the role of the primary translation, and align all pairs of hypotheses (En , Em ); n 6= m. The word alignment is trained in analogy to the alignment training procedure in statistical MT. The difference is that the two sentences that have to be aligned are in the same language. We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) to estimate the alignment model. The alignment training corpus is created from a test corpus1 of effectively M · (M − 1) · N sentences translated by the involved MT engines. The single-word based lexicon probabilities p(e|e0 ) are initialized from normalized lexicon counts collected over the sentence pairs (Em , En ) on this corpus. Since all of the hypotheses are in the same language, we count co-occurring identical words, i. e. whether em,j is the same word as en,i for some i and j. In addition, we add a fraction of a count for words with identical prefixes. Introduction The RWTH approach"
W09-0407,D08-1011,0,0.0662824,"his matrix are the local costs C(j, i) of aligning a word em,j from Em to a word en,i from En . Following Matusov et al. (2004), we compute these local costs by interpolating the negated logarithms of the state occupation probabilities from the “source-to-target” and “target-tosource” training of the HMM model. Two different alignments are computed using the cost matrix C: the alignment e a used for reordering each secondary translation Em , and the alignment a ¯ used to build the confusion network. In addition to the GIZA++ alignments, we have also conducted preliminary experiments following He et al. (2008) to exploit character-based similarity, as well as estimating p(e|e0 ) := P p(e|f )p(f |e0 ) directly from a bilingual lexif con. But we were not able to find improvements over the GIZA++ alignments so far. al., 2007). Weighted majority voting on a single confusion network is straightforward and analogous to ROVER (Fiscus, 1997). We sum up the probabilities of the arcs which are labeled with the same word and have the same start state and the same end state. To exploit the true casing abilities of the input MT systems, we sum up the scores of arcs bearing the same word but in different cases."
W09-0407,P05-3026,0,0.114538,"i and j. In addition, we add a fraction of a count for words with identical prefixes. Introduction The RWTH approach to MT system combination is a refined version of the ROVER approach in ASR (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using the prior probabilities for each system as well as other statistical models such as a special n-gram language model. 2 System Combination Algorithm In this section we present the details of our system combination method. Figure 1 gives an overview of the system combination architecture described in this section. After preprocessing the MT hypotheses, pairwise"
W09-0407,C04-1032,1,0.895843,"tatistical Machine Translation , pages 51–55, c Athens, Greece, 30 March – 31 March 2009. 2009 Association for Computational Linguistics 51 The model parameters are trained iteratively using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions Em → En and En → Em . After each iteration, the updated lexicon tables from the two directions are interpolated. The final alignments are determined using a cost matrix C for each sentence pair (Em , En ). Elements of this matrix are the local costs C(j, i) of aligning a word em,j from Em to a word en,i from En . Following Matusov et al. (2004), we compute these local costs by interpolating the negated logarithms of the state occupation probabilities from the “source-to-target” and “target-tosource” training of the HMM model. Two different alignments are computed using the cost matrix C: the alignment e a used for reordering each secondary translation Em , and the alignment a ¯ used to build the confusion network. In addition to the GIZA++ alignments, we have also conducted preliminary experiments following He et al. (2008) to exploit character-based similarity, as well as estimating p(e|e0 ) := P p(e|f )p(f |e0 ) directly from a bi"
W09-0407,E06-1005,1,0.896436,"over the sentence pairs (Em , En ) on this corpus. Since all of the hypotheses are in the same language, we count co-occurring identical words, i. e. whether em,j is the same word as en,i for some i and j. In addition, we add a fraction of a count for words with identical prefixes. Introduction The RWTH approach to MT system combination is a refined version of the ROVER approach in ASR (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using the prior probabilities for each system as well as other statistical models such as a special n-gram language model. 2 System Combination Algorithm In this secti"
W09-0407,mauser-etal-2008-automatic,1,0.811005,"as well: Neither in FR→EN nor in ES→EN we were able to achieve an improvement over the Google system. For this reason, we did not submit consensus translations for these two language pairs. On the other hand, we would have achieved significant improvements over all (remaining) systems leaving out Google. publicly available CONDOR optimization toolkit (Berghen and Bersini, 2005). For the WMT 2009 Workshop, we selected a linear combination of B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) as optimization criterion, ˆ := argmaxΘ {(2 · B LEU) − T ER}, based on Θ previous experience (Mauser et al., 2008). We used the whole dev set as a tuning set. For more stable results, we used the case-insensitive variants for both measures, despite the explicit use of case information in our approach. 4 Experimental results Due to the large number of submissions (71 in total for the language pairs DE→EN, ES→EN, FR→EN), we had to select a reasonable number of systems to be able to tune the parameters in a reliable way. Based on previous experience, we manually selected the systems with the best B LEU/T ER score, and tried different variations of this selection, e.g. by removing systems which had low weight"
W09-0407,D09-1022,1,\N,Missing
W09-0407,W06-3110,1,\N,Missing
W09-0407,2005.eamt-1.20,0,\N,Missing
W09-0407,D08-1039,1,\N,Missing
W09-0410,E06-1005,1,0.803237,"st participles, but there are many cases when other verb forms also occur at the clause end. For the translation from German into English, following verb types were moved towards the beginning of a clause: infinitives, infinitives+zu, finite verbs, past participles and negative particles. For the translation from English to German, infinitives and past participles were moved to the end of a clause, where punctuation marks, subordinate conjunctions and finite verbs are considered as the beginning of the next clause. 4 System combination For system combination we used the approach described in (Matusov et al., 2006). The method is based on the generation of a consensus translation out of the output of different translation systems. The core of the method consists in building a confusion network for each sentence by aligning and combining the (single-best) translation hypothesis from one MT system with the translations produced by the other MT systems (and the other translations from the same system, if n-best lists are used in combination). For each sentence, each MT system is selected once as “primary” system, and the other hypotheses are aligned to this hypothesis. The resulting confusion networks are"
W09-0410,popovic-ney-2006-pos,1,0.894671,"Missing"
W09-0410,N07-1029,0,0.0191149,"s. The core of the method consists in building a confusion network for each sentence by aligning and combining the (single-best) translation hypothesis from one MT system with the translations produced by the other MT systems (and the other translations from the same system, if n-best lists are used in combination). For each sentence, each MT system is selected once as “primary” system, and the other hypotheses are aligned to this hypothesis. The resulting confusion networks are combined into a signle word graph, which is then weighted with system-specific factors, similar to the approach of (Rosti et al., 2007), and a trigram LM trained on the MT hypotheses. The translation with the best total score within this word graph is selected as consensus translation. The scaling factors of these models are optimized using the Condor toolkit (Berghen and Bersini, 2005) to achieve optimal B LEU score on the dev set. 5 5.1 Experimental results Experimental settings For all translation directions, we used the provided EuroParl and News parallel corpora to train the translation models and the News monolingual corpora to train the language models. All systems were optimised for the B LEU score on the development"
W09-0410,2008.iwslt-papers.7,1,0.894714,"Missing"
W09-0410,A00-1031,0,0.0616954,"Missing"
W09-0410,carreras-etal-2004-freeling,0,0.0349781,"Missing"
W09-0410,2005.iwslt-1.18,1,\N,Missing
W09-0410,W99-0604,1,\N,Missing
W09-0410,C04-1006,1,\N,Missing
W09-0410,E03-1076,0,\N,Missing
W09-0410,W07-0813,0,\N,Missing
W09-0410,C08-1128,1,\N,Missing
W09-0410,J90-2002,0,\N,Missing
W09-0410,P05-1071,0,\N,Missing
W09-0410,P02-1040,0,\N,Missing
W09-0410,W03-1709,0,\N,Missing
W09-0410,W06-3111,1,\N,Missing
W09-0410,J04-2004,0,\N,Missing
W09-0410,W07-0401,1,\N,Missing
W09-0410,J06-4004,0,\N,Missing
W09-0410,W05-0831,1,\N,Missing
W09-0410,J03-1002,1,\N,Missing
W09-0410,P06-1001,0,\N,Missing
W09-0410,takezawa-etal-2002-toward,0,\N,Missing
W09-0410,2005.eamt-1.37,1,\N,Missing
W09-0410,2006.iwslt-papers.1,1,\N,Missing
W09-0410,2007.iwslt-1.25,1,\N,Missing
W09-0410,2004.iwslt-evaluation.13,1,\N,Missing
W09-0410,2007.iwslt-1.3,1,\N,Missing
W09-0410,J07-2003,0,\N,Missing
W09-0410,2006.iwslt-evaluation.15,1,\N,Missing
W09-0410,P03-1021,0,\N,Missing
W09-0410,2007.iwslt-1.10,0,\N,Missing
W13-2219,W11-2123,0,0.0158615,"ng binary topic/genre/phrase type indicators and translation memory match features (Matusov, 2012). 3.2 Monolingual Data For the French language model, we trained separate 5-gram models on the two GigaWord corpora AFP and APW, on the provided StatMT data for 2007–2012 (3 models), on the EuroParl data, and on the French side of the bilingual data. LMs were estimated and pruned using the IRSTLM toolkit (Federico et al., 2008). We then tuned a linear combination of these seven individual parts to optimum perplexity on WMT test sets 2009 and 2010 and converted them for use with the KenLM library (Heafield, 2011). Similarly, our English LM was a linear combination of separate LMs built for GigaWord AFP, APW, NYT, and the other parts, StatMT 2007–2012, Europarl/News Commentary, and the Yandex data, which was tuned for best perplexity on the WMT 2010-2013 test sets. The Omnifluent system also allows for partial or full rule-based translations. Specific source language entities can be identified prior to the search, and rule-based translations of these entities can be either forced to be chosen by the MT system, or can compete with phrase translation candidates from the phrase translation model. In both"
W13-2219,koen-2004-pharaoh,0,0.0601948,"ing set for N-best list MERT optimization (Och, 2003). We used the second part as a test set to measure progress; the results on it are reported below. We computed case-insensitive BLEU score (Papineni et al., 2002) for optimization and evaluation. Only one reference translation was available. 7.2 English-to-French System The baseline system for the English-to-French translation direction was trained on Europarl and News Commentary corpora. The word alignment was obtained by training HMM and IBM Model 3 alignment models and combining their two directions using the “grow-diag-final” heuristic (Koehn, 2004). The first line in Table 1 shows the result for this system when we only use the standard features (phrase translation and word lexicon costs in both directions, the base reorder7.3 Russian-to-English System The first experiment with the Russian-to-English system was to show the positive effect of the morphological transformations described in Section 5. Table 2 shows the result of the baseline system, trained using full forms of the Russian 162 words on the News Commentary, truecased Yandex and Wiki Headlines data. When applying the morphological transformations described in Section 5 both i"
W13-2219,2010.iwslt-evaluation.2,1,0.874028,"Missing"
W13-2219,2010.amta-papers.29,1,0.845419,"Missing"
W13-2219,2012.amta-commercial.11,1,0.8893,"cally translates both text and audio content. SAIC’s technology leverages hybrid machine translation, combining features of both rule-based machine and statistical machine translation for improved consistency, fluency, and accuracy of translation output. In the WMT 2013 evaluation campaign, we trained and tested the Omnifluent system on the English-to-French and Russian-to-English tasks. We chose the En–Fr task because Omnifluent En– Fr systems are already extensively used by SAIC’s commercial customers: large human translation service providers, as well as a leading fashion designer company (Matusov, 2012). Our Russian-toEnglish system also produces high-quality translations and is currently used by a US federal government customer of SAIC. Our experimental efforts focused mainly on the effective use of the provided parallel and monolingual data, document-level models, as well using 2 Core System Capabilities The Omnifluent system is a state-of-the-art hybrid MT system that originates from the AppTek technology acquired by SAIC (Matusov and K¨opr¨u, 2010a). The core of the system is a statistical search that employs a combination of multiple 1 2 Using a single core of a 2.8 GHz Intel Xeon CPU."
W13-2219,P03-1021,0,0.031313,"documentlevel phrase table are linearly combined with the counts from the background phrase table trained on the whole training data. The document-level LM is combined log-linearly with the general LM and all the other models and features. The scaling factors for the document-level LMs and phrase tables are not document-specific; neither is the linear interpolation factor for a document-level phrase table which we tuned manually on a development set. The scaling factor for the documentlevel LM was optimized together with the other scaling factors using Minimum Error Rate Training (MERT, see (Och, 2003)). For English-to-French translation, we used both document-level phrase tables and document-level LMs; the background data for them contained the sub-sampled Gigaword corpus (see Section 3.3). We used only the document-level LMs for the Russian-to-English translation. They were extracted from the same data that was used to train the background phrase table. 4 5 Document-level Models As mentioned in the introduction, the Omnifluent system loads a whole source document at once. Thus, it is possible to leverage document context by using document-level models which score the Morphological Transfo"
W13-2219,P02-1040,0,0.0923982,"Missing"
W13-2219,D11-1033,0,0.0610764,"Missing"
W13-2219,P07-2045,0,\N,Missing
W13-2219,2010.iwslt-evaluation.10,0,\N,Missing
W17-2004,W14-3348,0,0.107156,"Missing"
W17-2004,W16-3210,0,0.0970905,"Missing"
W17-2004,D16-1025,0,0.0343357,"Missing"
W17-2004,N16-1101,0,0.0938844,"Missing"
W17-2004,W16-2358,0,0.172904,"Missing"
W17-2004,P13-2121,0,0.0480622,"Missing"
W17-2004,W16-2359,1,0.854604,"of product listings, which is in 4 digit numbers even for language models (LMs) trained on in-domain data, as we discuss in §3. This is not only a challenge for LMs but also for automatic evaluation metrics such as the n-gram precisionbased BLEU metric (Papineni et al., 2002). 1 2 MT Models evaluated in this work We first introduce the two text-only baselines used in this work: a PBSMT model (§2.1) and a text-only attention-based NMT model (§2.2). We then briefly discuss the doubly-attentive multi-modal NMT model we use in our experiments (§2.3), which is comparable to the model evaluated by Calixto et al. (2016) and further detailed and analysed in Calixto et al. (2017a). http://www.ebay.com/ 31 Proceedings of the 6th Workshop on Vision and Language, pages 31–37, c Valencia, Spain, April 4, 2017. 2017 Association for Computational Linguistics The decoder is also an RNN, more specifically a neural LM (Bengio et al., 2003) conditioned upon its past predictions via its previous hidden state st−1 and the word emitted in the previous time step yt−1 , as well as the source sentence via an attention mechanism. The attention computes a context vector ct for each time step t of the decoder where this vector i"
W17-2004,P16-1227,0,0.120661,"Missing"
W17-2004,P17-1175,1,0.422189,"Missing"
W17-2004,E17-2101,1,0.556858,"eural Machine Translation: a Case Study on E-commerce Listing Titles Iacer Calixto1 , Daniel Stein2 , Evgeny Matusov2 , Sheila Castilho1 and Andy Way1 1 ADAPT Centre, School of Computing, Dublin City University, Dublin, Ireland 2 eBay Inc., Aachen, Germany {iacer.calixto,sheila.castilho,andy.way}@adaptcentre.ie {danstein,ematusov}@ebay.com Abstract The majority of listings are accompanied by a product image, often (but not always) a user-generated shot. Moreover, images are known to bring useful complementary information to MT (Calixto et al., 2012; Hitschler et al., 2016; Huang et al., 2016; Calixto et al., 2017b). Therefore, in order to explore whether product images can benefit the machine translation of auction titles, we evaluate a multi-modal neural MT (NMT) system to eBay’s production system, specifically a phrase-based statistical MT (PBSMT) one. We additionally train a text-only attention-based NMT baseline, so as to be able to measure eventual gains from the additional multi-modal data independently of the MT architecture. According to a quantitative evaluation using a combination of four automatic MT evaluation metrics, a PBSMT system outperforms both text-only and multimodal NMT models in"
W17-2004,W16-2360,0,0.141847,"ion of Multi-modal Neural Machine Translation: a Case Study on E-commerce Listing Titles Iacer Calixto1 , Daniel Stein2 , Evgeny Matusov2 , Sheila Castilho1 and Andy Way1 1 ADAPT Centre, School of Computing, Dublin City University, Dublin, Ireland 2 eBay Inc., Aachen, Germany {iacer.calixto,sheila.castilho,andy.way}@adaptcentre.ie {danstein,ematusov}@ebay.com Abstract The majority of listings are accompanied by a product image, often (but not always) a user-generated shot. Moreover, images are known to bring useful complementary information to MT (Calixto et al., 2012; Hitschler et al., 2016; Huang et al., 2016; Calixto et al., 2017b). Therefore, in order to explore whether product images can benefit the machine translation of auction titles, we evaluate a multi-modal neural MT (NMT) system to eBay’s production system, specifically a phrase-based statistical MT (PBSMT) one. We additionally train a text-only attention-based NMT baseline, so as to be able to measure eventual gains from the additional multi-modal data independently of the MT architecture. According to a quantitative evaluation using a combination of four automatic MT evaluation metrics, a PBSMT system outperforms both text-only and mul"
W17-2004,W14-4012,0,0.131326,"Missing"
W17-2004,P11-2031,0,0.247347,"Missing"
W17-2004,W16-2361,0,0.080277,"Missing"
W17-2004,D15-1166,0,0.0819838,". In their model, local visual features were used instead. In both cases, as well as in this work and in most of the state-of-the-art models in the field, models transferred learning from CNNs pre-trained for image classification on ImageNet (Russakovsky et al., 2015). In NMT, Bahdanau et al. (2015) was the first to propose to use an attention mechanism in the decoder. Their decoder learns to attend to the relevant source-language words as it generates a sentence in the target language, again word by word. Since then, many authors have proposed different ways to incorporate attention into MT. Luong et al. (2015) proposed among other things a local attention mechanism that was less costly than the original global attention; Firat et al. (2016) proposed a model to translate from many source and into many target languages, which involved a shared attention mechanism strategy; Tu et al. (2016) proposed an attention coverage strategy, so that 7 Conclusions and Future Work In this paper, we investigate the potential impact of multi-modal NMT in the context of e-commerce product listings. Images bring important information to NMT models in this context; in fact, translations obtained with a multi-modal NMT"
W17-2004,P03-1021,0,0.0188721,"on about that specific area of the image. The visual attention mechanism computes a context vector it for each time step t of the decoder similarly to the textual attention mechanism described in §2.2: Figure 1: Decoder RNN with attention over source sentence and image features. This decoder learns to independently attend to image patches and source-language words when generating translations. 2.1 Statistical Machine Translation (SMT) We use a PBSMT model where the language model (LM) is a 5–gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995). We use minimum error rate training (Och, 2003) for tuning the model parameters using BLEU as the objective function. 2.2 Multi-modal NMT (NMTm ) img T img img eimg t,l = (va ) tanh(Ua st−1 + Wa al ), Text-only NMT (NMTt ) We use the attention-based NMT model introduced by Bahdanau et al. (2015) as our text-only NMT baseline. It is based on the encoder–decoder framework and it implements an attention mechanism over the source-sentence words X = (x1 , x2 , · · · , xN ), where Y = (y1 , y2 , · · · , yM ) is its target-language translation. A model is trained to maximise the log-likelihood of the target given the source. The encoder is a bidi"
W17-2004,P02-1040,0,0.0997019,"listings’ titles as listed on the eBay main site1 . Among the challenges for MT are the specialized language and grammar for listing titles, as well as a high percentage of user-generated content for non-business sellers, who are often not native speakers themselves. This is reflected on the data by means of extremely high trigram perplexities of product listings, which is in 4 digit numbers even for language models (LMs) trained on in-domain data, as we discuss in §3. This is not only a challenge for LMs but also for automatic evaluation metrics such as the n-gram precisionbased BLEU metric (Papineni et al., 2002). 1 2 MT Models evaluated in this work We first introduce the two text-only baselines used in this work: a PBSMT model (§2.1) and a text-only attention-based NMT model (§2.2). We then briefly discuss the doubly-attentive multi-modal NMT model we use in our experiments (§2.3), which is comparable to the model evaluated by Calixto et al. (2016) and further detailed and analysed in Calixto et al. (2017a). http://www.ebay.com/ 31 Proceedings of the 6th Workshop on Vision and Language, pages 31–37, c Valencia, Spain, April 4, 2017. 2017 Association for Computational Linguistics The decoder is also"
W17-2004,Q14-1006,0,0.0228342,"ch containing (i) a product listing in English, (ii) a product listing in German and (iii) a product image. In ∼6k training tuples, the original user-generated product listing was given in English and was manually translated into German by in-house experts. The same holds for validation and test sets, which contain 480 and 444 triples, respectively. In the remaining training tuples (∼18k), the original listing was given in German and manually translated into English. We also use the publicly available Multi30k dataset (Elliott et al., 2016), a multilingual expansion of the original Flickr30k (Young et al., 2014) with ∼30k pictures from Flickr, each accompanied by one description in English and one human translation of the English description into German. Although the curation of in-domain parallel product listings with an associated product image is costly and time-consuming, monolingual German listings with an image are far simpler to obtain. In order to increase the small amount of training data, we train the text-only model NMTt on the German–English eBay24k and Multi30k data sets (without images) and back-translate 83, 832 German in-domain product listings into English. We use the synthetic Engli"
W17-2004,W15-3049,0,0.11233,"Missing"
W17-2004,P16-1162,0,0.0703878,"Missing"
W17-2004,W16-2363,0,0.12724,"aluation of translations generated with the different text-only and multi-modal models. To the best of our knowledge, along with Calixto et al. (2017b) we are the first to study multi-modal NMT applied to the translation of product listings, i.e. for the e-commerce domain. Multi-modal MT has just recently been addressed by the MT community in a shared task (Specia et al., 2016), where many different groups proposed techniques for multi-modal translation using different combinations of NMT and SMT models (Caglayan et al., 2016; Calixto et al., 2016; Huang et al., 2016; Libovick´y et al., 2016; Shah et al., 2016). In the multimodal translation task, participants are asked to train models to translate image descriptions from one natural language into another, while also taking the image itself into consideration. This effectively bridges the gap between two well-established tasks: image description generation (IDG) and MT. There is an important body of research conducted in IDG. We highlight the work of Vinyals et al. (2015), who proposed an influential neural IDG model based on the sequence-to-sequence framework. They used global visual features to initialise an RNN LM decoder, used to generate the im"
W17-2004,2006.amta-papers.25,0,0.343206,"Missing"
W17-2004,W16-2346,0,0.210848,"Missing"
W17-2004,P16-1008,0,0.0758416,"Missing"
W18-6530,W14-3346,0,0.012966,"ty predictor training data described above, analyzing the different dimensions of a title that can lead to poor product titles (laid out in Section 4 and finegrained in the quality prediction data description, above). 5.2 5.3 Parameter Settings The most important parameter of the title generation system is the beam size, which was set to 3 (the one giving the best performance in terms of BLEU score during the development of the model). We used sentence-level BLEU to compute the labels for training the regression model, set to 4-grams over cased titles and the smoothing mechanism described in (Chen and Cherry, 2014). The hyper-parameters of the LSTM-based and RF-based title quality prediction models were respectively optimized with 300 and 600 iterations of random search with an inner 3-fold crossvalidation over the training data. With RFs, we were able to explore the hyper-parameter search space more than with the neural-network-based models due to its faster training time. 6 Results and Discussion In this Section, we report and discuss the results obtained for each task. We start with the quality prediction problem. It can work as a method for selecting good candidate product titles that complements th"
W18-6530,2016.amta-researchers.10,1,0.856723,"edict the posterior probability p(y|x) (in our case, the posterior probability of a generated title y given the initial list of user-created titles x), which can also be viewed as a sequence quality score. Since quality scores are used to rank the partial sequences, an accurate scoring function would yield the highest quality outputs. Decoding can be seen in Minimum Bayes’ Risk Combination (Gonz´alez-Rubio et al., 2011; Gonz´alez-Rubio and Casacuberta, 2013), abstractive summarization (Rush et al., 2015; Chopra et al., 2016), and Neural Machine Translation (NMT) models (Bahdanau et al., 2014; Chen et al., 2016; Vaswani et al., 2017). State-ofthe-art approaches utilize encoder-decoder models that extract a feature representation of a variablelength input sentence before generating an output. However, the bottleneck of this approach is its dependence on the size of quality data; it often performs poorly when annotated data is noisy and/or insufficient (Koehn, 2017). 3 Title Generation This system’s purpose is to provide hypotheses of product titles. It receives as input a list of item titles for listings previously aggregated into one product (like the titles at the bottom of Figure 1) and product-re"
W18-6530,N16-1012,0,0.053356,"be robust to noises present in seller-created titles. generative process that learns to predict the posterior probability p(y|x) (in our case, the posterior probability of a generated title y given the initial list of user-created titles x), which can also be viewed as a sequence quality score. Since quality scores are used to rank the partial sequences, an accurate scoring function would yield the highest quality outputs. Decoding can be seen in Minimum Bayes’ Risk Combination (Gonz´alez-Rubio et al., 2011; Gonz´alez-Rubio and Casacuberta, 2013), abstractive summarization (Rush et al., 2015; Chopra et al., 2016), and Neural Machine Translation (NMT) models (Bahdanau et al., 2014; Chen et al., 2016; Vaswani et al., 2017). State-ofthe-art approaches utilize encoder-decoder models that extract a feature representation of a variablelength input sentence before generating an output. However, the bottleneck of this approach is its dependence on the size of quality data; it often performs poorly when annotated data is noisy and/or insufficient (Koehn, 2017). 3 Title Generation This system’s purpose is to provide hypotheses of product titles. It receives as input a list of item titles for listings previously"
W18-6530,D15-1122,0,0.0125857,". In this approach, a confusion network is generated by first selecting a listing title as backbone, and then by aligning it to all the other listings. The network is then traversed to obtain the product title with the highest consensus among the input hypotheses. This title can be decoded with decoding units that include either phrase-level (Feng et al., 2009; Du and Way, 2010) or word-level (Barrault, 2010; Rosti et al., 2007; Fiscus, 1997). Systems can choose between 1to-1 mappings (Barrault, 2010; Rosti et al., 2007; Du and Way, 2010) or many-to-many mappings (lattice) (Feng et al., 2009; Ma and McKeown, 2015; Matusov et al., 2006) in hypothesis alignment. The main drawbacks of these solutions are: (1) final output quality is highly dependent on the quality of the selected backbone (aligning hypotheses to a poor-quality listing can result in outputs that are far from being usable in real industrial settings), and (2) lattice creation becomes computationally expensive as the number of initial hypotheses grows, potentially O(n2 ). This makes approaches based on CN unsuitable for our working scenario where there is the need of generating titles for millions of products where each product consists of"
W18-6530,N12-1059,0,0.0265296,"marization, such as Maximal Marginal Relevance (MMR), to prune and select from the set of titles (Carbonell and Goldstein, 1998; Gillick, 2011). Alternatively, systems can also learn how to pick the candidate title that is closest to the reference title. This approach can rely on ranking scores produced by models trained on listing titles and the corresponding human-curated reference product titles, with automatic metrics such as BLEU (Papineni et al., 2002) or TER (Snover et al., 2006) as labels. Some of these techniques are employed in system combination (Rosti et al., 2007; Barrault, 2010; Devlin and Matsoukas, 2012; Suzuki, 2011). However, this approach limits the number of possible generated titles and can potentially introduce seller-biases when a single seller’s title is selected as the product title. Re-decoding Approaches. Re-decoding is a • An approach that generates product titles taking seller-provided listing titles as input and that scales to millions of products. The method is based on a stack decoder search algorithm that recombines frequent n-grams observed in the listing titles to form a product title hypothesis. • An approach to estimating the quality of titles based on supervised machine"
W18-6530,W17-3525,1,0.786816,"to assess whether the generated titles are good enough for publishing, in order to avoid bad user experience. For example, in Figure 1, if a generated title has a brand other than “ACME”, it would not be an appropriate title for that specific product. In this paper we present approaches to both problems: (i) generating e-commerce product titles and (ii) predicting their quality. Our main contributions are: 2 Related Work Prior work on title generation for e-commerce focused on browse pages and has only explored a hybrid approach combining rule-based and statistical machine translation models (Mathur et al., 2017). The input to this approach consists of structured information about products in terms of slot/value pairs (e.g. Watch Type: wrist watch). Although the task is similar to ours, hand-crafting and encoding product-specific rules is a time-consuming endeavour which does not scale to the hundreds of slot-value pairs and millions of products in the catalog. Below, we discuss three approaches that can either be directly applied or adapted to product title generation. The first approach is selection-based, while the last two are generation-based. Hypothesis Selection. The most intuitive approach is"
W18-6530,2010.amta-papers.9,0,0.0163469,"on computed in the first step. Hypothesis Fusion. An alternative approach is neither to select nor to generate, but to ‘fuse’ already generated hypotheses. This, for instance, can be done using Confusion Network (CN) decoding (Ma, 2014). In this approach, a confusion network is generated by first selecting a listing title as backbone, and then by aligning it to all the other listings. The network is then traversed to obtain the product title with the highest consensus among the input hypotheses. This title can be decoded with decoding units that include either phrase-level (Feng et al., 2009; Du and Way, 2010) or word-level (Barrault, 2010; Rosti et al., 2007; Fiscus, 1997). Systems can choose between 1to-1 mappings (Barrault, 2010; Rosti et al., 2007; Du and Way, 2010) or many-to-many mappings (lattice) (Feng et al., 2009; Ma and McKeown, 2015; Matusov et al., 2006) in hypothesis alignment. The main drawbacks of these solutions are: (1) final output quality is highly dependent on the quality of the selected backbone (aligning hypotheses to a poor-quality listing can result in outputs that are far from being usable in real industrial settings), and (2) lattice creation becomes computationally expen"
W18-6530,E06-1005,1,0.601487,"confusion network is generated by first selecting a listing title as backbone, and then by aligning it to all the other listings. The network is then traversed to obtain the product title with the highest consensus among the input hypotheses. This title can be decoded with decoding units that include either phrase-level (Feng et al., 2009; Du and Way, 2010) or word-level (Barrault, 2010; Rosti et al., 2007; Fiscus, 1997). Systems can choose between 1to-1 mappings (Barrault, 2010; Rosti et al., 2007; Du and Way, 2010) or many-to-many mappings (lattice) (Feng et al., 2009; Ma and McKeown, 2015; Matusov et al., 2006) in hypothesis alignment. The main drawbacks of these solutions are: (1) final output quality is highly dependent on the quality of the selected backbone (aligning hypotheses to a poor-quality listing can result in outputs that are far from being usable in real industrial settings), and (2) lattice creation becomes computationally expensive as the number of initial hypotheses grows, potentially O(n2 ). This makes approaches based on CN unsuitable for our working scenario where there is the need of generating titles for millions of products where each product consists of a potentially large num"
W18-6530,D09-1115,0,0.0584192,"Missing"
W18-6530,P02-1040,0,0.104004,"sting titles, the one that most “appropriately” describes the product. This can be achieved by applying diversitybased ranking techniques used in extractive summarization, such as Maximal Marginal Relevance (MMR), to prune and select from the set of titles (Carbonell and Goldstein, 1998; Gillick, 2011). Alternatively, systems can also learn how to pick the candidate title that is closest to the reference title. This approach can rely on ranking scores produced by models trained on listing titles and the corresponding human-curated reference product titles, with automatic metrics such as BLEU (Papineni et al., 2002) or TER (Snover et al., 2006) as labels. Some of these techniques are employed in system combination (Rosti et al., 2007; Barrault, 2010; Devlin and Matsoukas, 2012; Suzuki, 2011). However, this approach limits the number of possible generated titles and can potentially introduce seller-biases when a single seller’s title is selected as the product title. Re-decoding Approaches. Re-decoding is a • An approach that generates product titles taking seller-provided listing titles as input and that scales to millions of products. The method is based on a stack decoder search algorithm that recombin"
W18-6530,J18-3002,0,0.0250927,"wanted tokens (Bluetooth Lines on Display) Table 4: Output examples generated by the systems evaluated in the human evaluation. Third column lists the issues in each output. proach in order to improve the overall generation and quality prediction accuracy. tems outputs. In the first block of outputs, for example, some titles do not present the specification of the type of the product (what is the product). The observation that BLEU alone is not appropriate for evaluating natural language generation systems is not new and corroborates previous work on the field, most notably the recent work by Reiter (2018). Another important trend observed in Table 3 is that using the quality prediction system as a rescorer of the generated and seller titles does not improve over generation alone. We hypothesize this is due to the fact that both systems are trained separately and therefore do not leverage from the signals and features both systems explore. As future work we would like to experiment with joint training of the generation and quality prediction systems, in order to cope with this gap. 7 References Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learn"
W18-6530,P07-1040,0,0.169758,"ng techniques used in extractive summarization, such as Maximal Marginal Relevance (MMR), to prune and select from the set of titles (Carbonell and Goldstein, 1998; Gillick, 2011). Alternatively, systems can also learn how to pick the candidate title that is closest to the reference title. This approach can rely on ranking scores produced by models trained on listing titles and the corresponding human-curated reference product titles, with automatic metrics such as BLEU (Papineni et al., 2002) or TER (Snover et al., 2006) as labels. Some of these techniques are employed in system combination (Rosti et al., 2007; Barrault, 2010; Devlin and Matsoukas, 2012; Suzuki, 2011). However, this approach limits the number of possible generated titles and can potentially introduce seller-biases when a single seller’s title is selected as the product title. Re-decoding Approaches. Re-decoding is a • An approach that generates product titles taking seller-provided listing titles as input and that scales to millions of products. The method is based on a stack decoder search algorithm that recombines frequent n-grams observed in the listing titles to form a product title hypothesis. • An approach to estimating the q"
W18-6530,D15-1044,0,0.0666797,"near time and must be robust to noises present in seller-created titles. generative process that learns to predict the posterior probability p(y|x) (in our case, the posterior probability of a generated title y given the initial list of user-created titles x), which can also be viewed as a sequence quality score. Since quality scores are used to rank the partial sequences, an accurate scoring function would yield the highest quality outputs. Decoding can be seen in Minimum Bayes’ Risk Combination (Gonz´alez-Rubio et al., 2011; Gonz´alez-Rubio and Casacuberta, 2013), abstractive summarization (Rush et al., 2015; Chopra et al., 2016), and Neural Machine Translation (NMT) models (Bahdanau et al., 2014; Chen et al., 2016; Vaswani et al., 2017). State-ofthe-art approaches utilize encoder-decoder models that extract a feature representation of a variablelength input sentence before generating an output. However, the bottleneck of this approach is its dependence on the size of quality data; it often performs poorly when annotated data is noisy and/or insufficient (Koehn, 2017). 3 Title Generation This system’s purpose is to provide hypotheses of product titles. It receives as input a list of item titles f"
W18-6530,2013.iwslt-papers.4,0,0.0466445,"Missing"
W18-6530,P11-1127,0,0.042489,"Missing"
W18-6530,2006.amta-papers.25,0,0.0289261,"“appropriately” describes the product. This can be achieved by applying diversitybased ranking techniques used in extractive summarization, such as Maximal Marginal Relevance (MMR), to prune and select from the set of titles (Carbonell and Goldstein, 1998; Gillick, 2011). Alternatively, systems can also learn how to pick the candidate title that is closest to the reference title. This approach can rely on ranking scores produced by models trained on listing titles and the corresponding human-curated reference product titles, with automatic metrics such as BLEU (Papineni et al., 2002) or TER (Snover et al., 2006) as labels. Some of these techniques are employed in system combination (Rosti et al., 2007; Barrault, 2010; Devlin and Matsoukas, 2012; Suzuki, 2011). However, this approach limits the number of possible generated titles and can potentially introduce seller-biases when a single seller’s title is selected as the product title. Re-decoding Approaches. Re-decoding is a • An approach that generates product titles taking seller-provided listing titles as input and that scales to millions of products. The method is based on a stack decoder search algorithm that recombines frequent n-grams observed"
W18-6530,2011.mtsummit-papers.16,0,0.0181385,"Marginal Relevance (MMR), to prune and select from the set of titles (Carbonell and Goldstein, 1998; Gillick, 2011). Alternatively, systems can also learn how to pick the candidate title that is closest to the reference title. This approach can rely on ranking scores produced by models trained on listing titles and the corresponding human-curated reference product titles, with automatic metrics such as BLEU (Papineni et al., 2002) or TER (Snover et al., 2006) as labels. Some of these techniques are employed in system combination (Rosti et al., 2007; Barrault, 2010; Devlin and Matsoukas, 2012; Suzuki, 2011). However, this approach limits the number of possible generated titles and can potentially introduce seller-biases when a single seller’s title is selected as the product title. Re-decoding Approaches. Re-decoding is a • An approach that generates product titles taking seller-provided listing titles as input and that scales to millions of products. The method is based on a stack decoder search algorithm that recombines frequent n-grams observed in the listing titles to form a product title hypothesis. • An approach to estimating the quality of titles based on supervised machine learning metho"
W18-6530,W17-4123,0,0.0310258,"mum Bayes’ Risk Combination (Gonz´alez-Rubio et al., 2011; Gonz´alez-Rubio and Casacuberta, 2013), abstractive summarization (Rush et al., 2015; Chopra et al., 2016), and Neural Machine Translation (NMT) models (Bahdanau et al., 2014; Chen et al., 2016; Vaswani et al., 2017). State-ofthe-art approaches utilize encoder-decoder models that extract a feature representation of a variablelength input sentence before generating an output. However, the bottleneck of this approach is its dependence on the size of quality data; it often performs poorly when annotated data is noisy and/or insufficient (Koehn, 2017). 3 Title Generation This system’s purpose is to provide hypotheses of product titles. It receives as input a list of item titles for listings previously aggregated into one product (like the titles at the bottom of Figure 1) and product-related data in the form of slot-value pairs (as the name-value pairs shown under “Product Details” in Figure 1). In addition to these, a human-curated reference product title is required during training time. The process of generating titles can be roughly summarized into two steps. The first is computing different statistics about the item titles: n-gram cou"
W18-6530,P97-1047,0,0.444443,"gation of titles into products, which means some of the pairs can present noise. In order to filter out noisy slot-value pairs and to understand which pairs are important, we derive an importance score for each pair. This score is computed by dividing the number of times a value appears at least once in the listing titles by the number of listing titles aggregated to the product. The top-k pairs according to this score are kept. The second step consists of performing the recombination of n-grams found in the titles using an heuristic stack-based search algorithm, also known as stack decoding (Wang and Waibel, 1997) using all the information computed in the first step. Hypothesis Fusion. An alternative approach is neither to select nor to generate, but to ‘fuse’ already generated hypotheses. This, for instance, can be done using Confusion Network (CN) decoding (Ma, 2014). In this approach, a confusion network is generated by first selecting a listing title as backbone, and then by aligning it to all the other listings. The network is then traversed to obtain the product title with the highest consensus among the input hypotheses. This title can be decoded with decoding units that include either phrase-le"
W19-5209,P16-5005,0,0.0580328,"Missing"
W19-5209,L16-1147,0,0.214217,"ted to what we use in our work, but we deal with subtitle segmentation that is more complex and less well-defined than prediction of punctuation, as we show in Section 5. 3 4 NMT Adaptation 4.1 Domain and style adaptation Film content covers a large variety of genres, thus it is not easy to characterize the domain of these type of data. However, subtitles typically have shorter sentences than general texts (e.g. news articles), and brief utterances abound in many films. To create a customized system for subtitles, we used the OpenSubtitles parallel data2 , downloaded from the OPUS collection (Lison and Tiedemann, 2016), as the main training corpus. The corpus was filtered by running FastText based language identification (Joulin et al., 2016) and other heuristics (e.g. based on source/target lengths and length ratios in tokens and characters). In addition, we used other conversational corpora, such as GlobalVoices, transcribed TED talks and in-house crawled English-Spanish transcripts of the EU TV as parallel training data. We also added Europarl and News Commentary data to the main training corpus as sources of clean and well-aligned sentence pairs. Neural MT systems often have problems translating rare wo"
W19-5209,2010.jec-1.7,0,0.55973,"Missing"
W19-5209,2015.iwslt-evaluation.11,0,0.121092,"Missing"
W19-5209,D17-1301,0,0.0447264,"Missing"
W19-5209,D18-1325,0,0.0245255,"threshold of K = 20 tokens was reached and then translated the resulting test set. Thus, each sentence was translated only once, either as part of a spliced sentence sequence or as an individual (long) sentence. A possibly better, but more redundant approach would have been to cut out the translation of only the last sentence in a spliced sequence, and then re-send the corresponding source sentence as context for translating the next sentence. However, for time reasons we did not test this approach. In the future, we also plan to expand on the existing research on document-level translation (Miculicich et al., 2018; Wang et al., 2017) and encode the previous inter-sentence context in a separate neural component. Even the first step towards expanding context beyond a single sentence described above led to some improvements in translation, and in particular pronoun disambiguation, as will be seen in Section 6. 5 depends on syntax and semantics. We therefore employ a neural model to predict segment boundaries. It consists of a 128dimensional word embedding layer and two 256dimensional bi-directional LSTM layers, followed by a softmax. The output is a binary decision, i.e. we generate two probabilities per"
W19-5209,W16-2342,0,0.0435353,"Missing"
W19-5209,P18-4022,0,0.0299815,"em, we developed a novel data augmentation technique. First, we computed word frequency statistics for the main training corpus described above. Then, we defined auxiliary out-of-domain training data from which we wanted to extract only specific sentence pairs. These data included all other publicly available training data, including ParaCrawl, CommonCrawl, EUbookshop, JRCAcquis, EMEA, and other corpora from the OPUS collection. We computed word frequencies for each of these auxiliary corpora individually. Next, Baseline NMT Architecture We trained our NMT models using an open-source toolkit (Zeyer et al., 2018) that is based on TensorFlow (Abadi et al., 2015). We trained an attention-based RNN model similar to Bahdanau et al. (2015) with additive attention. The attention model projects both the source and the target words into a 620-dimensional embedding space. The bidirectional encoder consists of 4 layers, each of which uses LSTM cells with 1000 units. We used a unidirectional decoder with the same number of units. In the initial (sub)epochs, we employed a layer-wise pretraining scheme that resulted in better convergence and faster overall training speed (Zeyer et al., 2018). We also enhanced the"
W19-5209,D18-1103,0,0.0210301,"ilarly to Firat et al. (2016). We do not change the neural architecture, but add a special token at the beginning of the source sentence to signal LA Spanish output for all training sentence pairs which we labeled as translations into LA Spanish with the rule-based method described above. This is also similar to using tokens for domain control as in the work of Kobus et al. (2016). We used a development set labeled as having translations into LA Spanish to track convergence and for selection of the final training epoch. An alternative approach that was applied to lowresource language pairs by Neubig and Hu (2018) would have been to pre-train the model on all English-Spanish data, and then continue training on sentence pairs with LA Spanish targets. However, we did not follow this approach to avoid overfitting to the style of the OpenSubtitles corpus instead of adapting to the LA Spanish language variety. for each sentence pair in each auxiliary corpus we checked that: • either the source or the target sentence has at least one word that is rare in the main corpus, and • neither the source sentence, nor the target sentence includes any word that is out-ofvocabulary for the main training corpus and at t"
W19-5209,P02-1040,0,0.103735,"Missing"
W19-7302,W15-0713,0,0.478722,"Missing"
W19-7302,W15-0706,0,0.0504767,"Missing"
W19-7302,D10-1016,0,0.382039,"h Catalan novels are translated using a phrase-based system into English. In contrast, in our work we use the latest and best NMT architecture both for back-translation of large volumes of novels, and for the actual MT experiments; with only a very small parallel fiction corpus we are still able to obtain improvements over a strong general-domain NMT baseline. 3 AppTek’s Neural Machine Translation System This work focuses on translation of prose; however, there have also been attempts to automatically translate poetry, with rhyming and rhythmical constraints, starting from the seminal work of Genzel et al. (2010) for phrase-based SMT. Recently, neural architectures were also proposed for this task (Ghazvininejad et al., 2018). AppTek’s NMT system is based on the the RETURNN toolkit (Zeyer et al., 2018) that implements training and inference in TensorFlow (Abadi et al., 2015). We trained two different architectures of NMT models: an attention-based RNN model similar to (Bahdanau et al., 2015) with additive attention for English-to-Russian and a Transformer model (Vaswani et al., 2017) with multi-head attention for German-to-English. In the RNN-based attention model, both the source and the target words"
W19-7302,N18-2011,0,0.122395,"Missing"
W19-7302,W19-7300,0,0.171402,"Missing"
W19-7302,D18-2012,0,0.0413432,"Missing"
W19-7302,2006.amta-papers.25,0,0.0505654,"Missing"
W19-7302,tiedemann-2012-parallel,0,0.0591267,"AppTek’s NMT had to be adapted to the style and diverse vocabulary of literary translations. In our experiments, we selected 2.3M sentences (23.5M running words) from books in Russian1 and translated them using AppTek’s general domain Russian-to-English NMT system. Following the approach of (Sennrich et al., 2016a), we then used the resulting parallel corpus as synthetic data, mixing it with the data that was used to train AppTek’s general domain system from English to Russian. As parallel in-domain data, we used a small corpus of sentence-aligned texts2 and the OPUS Books collection corpus3 (Tiedemann, 2012), with a total of 270K sentence pairs and 5.2M running words on the English side. We followed the same back-translation procedure for German-to-English, randomly selecting 10M sentences (155M running words) from English literature that we downloaded from the Gutenberg4 project. Again, AppTek’s highly competitive English-to-German general-domain Transformer model (Matusov et al., 2018) was used to translate these sentences, so that a synthetic parallel corpus could be used together with the other parallel data in NMT training of the reverse translation direction that was of interest to us. The"
W19-7302,W19-3807,0,0.0180716,"trainings. The dropout rate ranged from 0.1 to 0.3. AppTek’s general domain English-to-Russian system was trained for roughly 3 epochs on 25 million sentence pairs (265M words on the English side). The corresponding German-to-English system was trained on 47M sentence pairs (752M running words on the English side) for less than 2 epochs. The Qualities of Literary Machine Translation Dublin, Aug. 19-23, 2019 |p. 11 Other related work important to literary translation include style transfer (Korotkova et al., 2018) and personalization (Rabinovich et al., 2016), number and gender disambiguation (Moryossef et al., 2019), document-level translation (Wang et al., 2017). 4 Adaptation to Literary Content First, AppTek’s NMT had to be adapted to the style and diverse vocabulary of literary translations. In our experiments, we selected 2.3M sentences (23.5M running words) from books in Russian1 and translated them using AppTek’s general domain Russian-to-English NMT system. Following the approach of (Sennrich et al., 2016a), we then used the resulting parallel corpus as synthetic data, mixing it with the data that was used to train AppTek’s general domain system from English to Russian. As parallel in-domain data,"
W19-7302,W12-2503,0,0.597402,"Missing"
W19-7302,P02-1040,0,0.10684,"Missing"
W19-7302,D17-1301,0,0.0225706,"ppTek’s general domain English-to-Russian system was trained for roughly 3 epochs on 25 million sentence pairs (265M words on the English side). The corresponding German-to-English system was trained on 47M sentence pairs (752M running words on the English side) for less than 2 epochs. The Qualities of Literary Machine Translation Dublin, Aug. 19-23, 2019 |p. 11 Other related work important to literary translation include style transfer (Korotkova et al., 2018) and personalization (Rabinovich et al., 2016), number and gender disambiguation (Moryossef et al., 2019), document-level translation (Wang et al., 2017). 4 Adaptation to Literary Content First, AppTek’s NMT had to be adapted to the style and diverse vocabulary of literary translations. In our experiments, we selected 2.3M sentences (23.5M running words) from books in Russian1 and translated them using AppTek’s general domain Russian-to-English NMT system. Following the approach of (Sennrich et al., 2016a), we then used the resulting parallel corpus as synthetic data, mixing it with the data that was used to train AppTek’s general domain system from English to Russian. As parallel in-domain data, we used a small corpus of sentence-aligned text"
W19-7302,P18-4022,0,0.0690283,"s, and for the actual MT experiments; with only a very small parallel fiction corpus we are still able to obtain improvements over a strong general-domain NMT baseline. 3 AppTek’s Neural Machine Translation System This work focuses on translation of prose; however, there have also been attempts to automatically translate poetry, with rhyming and rhythmical constraints, starting from the seminal work of Genzel et al. (2010) for phrase-based SMT. Recently, neural architectures were also proposed for this task (Ghazvininejad et al., 2018). AppTek’s NMT system is based on the the RETURNN toolkit (Zeyer et al., 2018) that implements training and inference in TensorFlow (Abadi et al., 2015). We trained two different architectures of NMT models: an attention-based RNN model similar to (Bahdanau et al., 2015) with additive attention for English-to-Russian and a Transformer model (Vaswani et al., 2017) with multi-head attention for German-to-English. In the RNN-based attention model, both the source and the target words are projected into a 620-dimensional embedding space. The models are equipped with 4 layers of bidirectional encoder using LSTM cells with 1000 units. A unidirectional decoder with the same nu"
W19-7302,J11-4002,0,0.0219964,"Missing"
W19-7302,P16-1009,0,0.159845,"2019 |p. 11 Other related work important to literary translation include style transfer (Korotkova et al., 2018) and personalization (Rabinovich et al., 2016), number and gender disambiguation (Moryossef et al., 2019), document-level translation (Wang et al., 2017). 4 Adaptation to Literary Content First, AppTek’s NMT had to be adapted to the style and diverse vocabulary of literary translations. In our experiments, we selected 2.3M sentences (23.5M running words) from books in Russian1 and translated them using AppTek’s general domain Russian-to-English NMT system. Following the approach of (Sennrich et al., 2016a), we then used the resulting parallel corpus as synthetic data, mixing it with the data that was used to train AppTek’s general domain system from English to Russian. As parallel in-domain data, we used a small corpus of sentence-aligned texts2 and the OPUS Books collection corpus3 (Tiedemann, 2012), with a total of 270K sentence pairs and 5.2M running words on the English side. We followed the same back-translation procedure for German-to-English, randomly selecting 10M sentences (155M running words) from English literature that we downloaded from the Gutenberg4 project. Again, AppTek’s hig"
W19-7302,P16-1162,0,0.305167,"2019 |p. 11 Other related work important to literary translation include style transfer (Korotkova et al., 2018) and personalization (Rabinovich et al., 2016), number and gender disambiguation (Moryossef et al., 2019), document-level translation (Wang et al., 2017). 4 Adaptation to Literary Content First, AppTek’s NMT had to be adapted to the style and diverse vocabulary of literary translations. In our experiments, we selected 2.3M sentences (23.5M running words) from books in Russian1 and translated them using AppTek’s general domain Russian-to-English NMT system. Following the approach of (Sennrich et al., 2016a), we then used the resulting parallel corpus as synthetic data, mixing it with the data that was used to train AppTek’s general domain system from English to Russian. As parallel in-domain data, we used a small corpus of sentence-aligned texts2 and the OPUS Books collection corpus3 (Tiedemann, 2012), with a total of 270K sentence pairs and 5.2M running words on the English side. We followed the same back-translation procedure for German-to-English, randomly selecting 10M sentences (155M running words) from English literature that we downloaded from the Gutenberg4 project. Again, AppTek’s hig"
