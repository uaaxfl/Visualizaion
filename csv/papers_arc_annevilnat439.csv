2020.semeval-1.172,{LIMSI}{\\_}{UPV} at {S}em{E}val-2020 Task 9: Recurrent Convolutional Neural Network for Code-mixed Sentiment Analysis,2020,-1,-1,4,0,8790,somnath banerjee,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"This paper describes the participation of LIMSI{\_}UPV team in SemEval-2020 Task 9: Sentiment Analysis for Code-Mixed Social Media Text. The proposed approach competed in SentiMix HindiEnglish subtask, that addresses the problem of predicting the sentiment of a given Hindi-English code-mixed tweet. We propose Recurrent Convolutional Neural Network that combines both the recurrent neural network and the convolutional network to better capture the semantics of the text, for code-mixed sentiment analysis. The proposed system obtained 0.69 (best run) in terms of F1 score on the given test data and achieved the 9th place (Codalab username: somban) in the SentiMix Hindi-English subtask."
2020.lrec-1.496,Building an {E}nglish-{C}hinese Parallel Corpus Annotated with Sub-sentential Translation Techniques,2020,-1,-1,5,1,17661,yuming zhai,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Human translators often resort to different non-literal translation techniques besides the literal translation, such as idiom equivalence, generalization, particularization, semantic modulation, etc., especially when the source and target languages have different and distant origins. Translation techniques constitute an important subject in translation studies, which help researchers to understand and analyse translated texts. However, they receive less attention in developing Natural Language Processing (NLP) applications. To fill this gap, one of our long term objectives is to have a better semantic control of extracting paraphrases from bilingual parallel corpora. Based on this goal, we suggest this hypothesis: it is possible to automatically recognize different sub-sentential translation techniques. For this original task, since there is no dedicated data set for English-Chinese, we manually annotated a parallel corpus of eleven genres. Fifty sentence pairs for each genre have been annotated in order to consolidate our annotation guidelines. Based on this data set, we conducted an experiment to classify between literal and non-literal translations. The preliminary results confirm our hypothesis. The corpus and code are available. We hope that this annotated corpus will be useful for linguistic contrastive studies and for fine-grained evaluation of NLP tasks, such as automatic word alignment and machine translation."
2020.jeptalnrecital-taln.37,La r{\\'e}{\\'e}criture monolingue ou bilingue facilite-t-elle la compr{\\'e}hension ? (Does monolingual or bilingual rewriting facilitate comprehension ?),2020,-1,-1,3,1,17661,yuming zhai,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 2 : Traitement Automatique des Langues Naturelles",0,"La capacit{\'e} en compr{\'e}hension {\'e}crite est importante {\`a} d{\'e}velopper pour les apprenants de langues {\'e}trang{\`e}res. Cet article pr{\'e}sente une exp{\'e}rience pour v{\'e}rifier si les paraphrases fournies en contexte facilitent la compr{\'e}hension des apprenants. Les paraphrases ont {\'e}t{\'e} extraites automatiquement d{'}un corpus parall{\`e}le bilingue. Suite {\`a} l{'}analyse des r{\'e}sultats, nous proposons des pistes d{'}enrichissement d{'}un outil con{\c{c}}u pr{\'e}alablement, pour automatiser la s{\'e}lection de r{\'e}{\'e}critures dans un futur travail, tout en caract{\'e}risant mieux diff{\'e}rents types de r{\'e}{\'e}critures."
2020.coling-main.522,Detecting Non-literal Translations by Fine-tuning Cross-lingual Pre-trained Language Models,2020,-1,-1,3,1,17661,yuming zhai,Proceedings of the 28th International Conference on Computational Linguistics,0,"Human-generated non-literal translations reflect the richness of human languages and are sometimes indispensable to ensure adequacy and fluency. Non-literal translations are difficult to produce even for human translators, especially for foreign language learners, and machine translations are still on the way to simulate human ones on this aspect. In order to foster the study on appropriate and creative non-literal translations, automatically detecting them in parallel corpora is an important step, which can benefit downstream NLP tasks or help to construct materials to teach translation. This article demonstrates that generic sentence representations produced by a pre-trained cross-lingual language model could be fine-tuned to solve this task. We show that there exists a moderate positive correlation between the prediction probability of being human translation and the non-literal translations{'} proportion in a sentence. The fine-tuning experiments show an accuracy of 80.16{\%} when predicting the presence of non-literal translations in a sentence and an accuracy of 85.20{\%} when distinguishing literal and non-literal translations at phrase level. We further conduct a linguistic error analysis and propose directions for future work."
2019.jeptalnrecital-court.6,Classification automatique des proc{\\'e}d{\\'e}s de traduction (Automatic Classification of Translation Processes),2019,-1,-1,3,1,17661,yuming zhai,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. Volume II : Articles courts,0,"En vue de distinguer la traduction litt{\'e}rale des autres proc{\'e}d{\'e}s de traduction, des traducteurs et linguistes ont propos{\'e} plusieurs typologies pour caract{\'e}riser les diff{\'e}rents proc{\'e}d{\'e}s de traduction, tels que l{'}{\'e}quivalence idiomatique, la g{\'e}n{\'e}ralisation, la particularisation, la modulation s{\'e}mantique, etc. En revanche, les techniques d{'}extraction de paraphrases {\`a} partir de corpus parall{\`e}les bilingues n{'}ont pas exploit{\'e} ces informations. Dans ce travail, nous proposons une classification automatique des proc{\'e}d{\'e}s de traduction en nous basant sur des exemples annot{\'e}s manuellement dans un corpus parall{\`e}le (anglais-fran{\c{c}}ais) de TED Talks. M{\^e}me si le jeu de donn{\'e}es est petit, les r{\'e}sultats exp{\'e}rimentaux sont encourageants, et les exp{\'e}riences montrent la direction {\`a} suivre dans les futurs travaux."
W18-3814,Construction of a Multilingual Corpus Annotated with Translation Relations,2018,-1,-1,3,1,17661,yuming zhai,Proceedings of the First Workshop on Linguistic Resources for Natural Language Processing,0,"Translation relations, which distinguish literal translation from other translation techniques, constitute an important subject of study for human translators (Chuquet and Paillard, 1989). However, automatic processing techniques based on interlingual relations, such as machine translation or paraphrase generation exploiting translational equivalence, have not exploited these relations explicitly until now. In this work, we present a categorisation of translation relations and annotate them in a parallel multilingual (English, French, Chinese) corpus of oral presentations, the TED Talks. Our long term objective will be to automatically detect these relations in order to integrate them as important characteristics for the search of monolingual segments in relation of equivalence (paraphrases) or of entailment. The annotated corpus resulting from our work will be made available to the community."
garcia-fernandez-etal-2014-construction,Construction and Annotation of a {F}rench Folkstale Corpus,2014,22,0,3,1,39320,anne garciafernandez,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper, we present the digitization and annotation of a tales corpus - which is to our knowledge the only French tales corpus available and classified according to the Aarne{\&}Thompson classification - composed of historical texts (with old French parts). We first studied whether the pre-processing tools, namely OCR and PoS-tagging, have good enough accuracies to allow automatic analysis. We also manually annotated this corpus according to several types of information which could prove useful for future work: character references, episodes, and motifs. The contributions are the creation of an corpus of French tales from classical anthropology material, which will be made available to the community; the evaluation of OCR and NLP tools on this corpus; and the annotation with anthropological information."
asadullah-etal-2014-bidirectionnal,"Bidirectionnal converter between syntactic annotations : from {F}rench Treebank Dependencies to {PASSAGE} annotations, and back",2014,16,0,3,1,23742,munshi asadullah,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We present here part of a bidirectional converter between the French Tree-bank Dependency (FTB - DEP) annotations into the PASSAGE format. FTB - DEP is the representation used by several freely available parsers and the PASSAGE annotation was used to hand-annotate a relatively large sized corpus, used as gold-standard in the PASSAGE evaluation campaigns. Our converter will give the means to evaluate these parsers on the PASSAGE corpus. We shall illustrate the mapping of important syntactic phenomena using the corpus made of the examples of the FTB - DEP annotation guidelines, which we have hand-annotated with PASSAGE annotations and used to compute quantitative performance measures on the FTB - DEP guidelines.n this paper we will briefly introduce the two annotation formats. Then, we detail the two converters, and the rules which have been written. The last part will detail the results we obtained on the phenomenon we mostly study, the passive forms. We evaluate the converters by a double conversion, from PASSAGE to CoN LL and back to PASSAGE. We will detailed in this paper the linguistic phenomenon we detail here, the passive form."
F14-2011,User evaluation of a multiple answer extraction system on the Web ({\\'E}valuation d{'}un syst{\\`e}me d{'}extraction de r{\\'e}ponses multiples sur le Web par comparaison {\\`a} des humains) [in {F}rench],2014,0,0,3,1,40007,mathieuhenri falco,Proceedings of TALN 2014 (Volume 2: Short Papers),0,None
F14-1001,Study of Domain Dependant Multi-Polarity Words for Document Level Opinion Mining (Influence des marqueurs multi-polaires d{\\'e}pendant du domaine pour la fouille d{'}opinion au niveau du texte) [in {F}rench],2014,-1,-1,4,0,33233,morgane marchand,Proceedings of TALN 2014 (Volume 1: Long Papers),0,None
F13-2022,Converting dependencies for syntactic analysis of {F}rench into {PASSAGE} functional relations (Convertir des analyses syntaxiques en d{\\'e}pendances vers les relations fonctionnelles {PASSAGE}) [in {F}rench],2013,-1,-1,3,0,5615,patrick paroubek,Proceedings of TALN 2013 (Volume 2: Short Papers),0,None
arnulphy-etal-2012-event,Event Nominals: Annotation Guidelines and a Manually Annotated Corpus in {F}rench,2012,9,2,3,1,42890,beatrice arnulphy,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Within the general purpose of information extraction, detection of event descriptions is an important clue. A word refering to an event is more powerful than a single word, because it implies a location, a time, protagonists (persons, organizations{\textbackslash}dots). However, if verbal designations of events are well studied and easier to detect than nominal ones, nominal designations do not claim as much definition effort and resources. In this work, we focus on nominals desribing events. As our application domain is information extraction, we follow a named entity approach to describe and annotate events. In this paper, we present a typology and annotation guidelines for event nominals annotation. We applied them to French newswire articles and produced an annotated corpus. We present observations about the designations used in our manually annotated corpus and the behavior of their triggers. We provide statistics concerning word ambiguity and context of use of event nominals, as well as machine learning experiments showing the difficulty of using lexicons for extracting events."
falco-etal-2012-kitten,{K}itten: a tool for normalizing {HTML} and extracting its textual content,2012,10,4,3,1,40007,mathieuhenri falco,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The web is composed of a gigantic amount of documents that can be very useful for information extraction systems. Most of them are written in HTML and have to be rendered by an HTML engine in order to display the data they contain on a screen. HTML file thus mix both informational and rendering content. Our goal is to design a tool for informational content extraction. A linear extraction with only a basic filtering of rendering content would not be enough as objects such as lists and tables are linearly coded but need to be read in a non-linear way to be well interpreted. Besides these HTML pages are often incorrectly coded from an HTML point of view and use a segmentation of blocks based on blank space that cannot be transposed in a text filewithout confusing syntactic parsers. For this purpose, we propose the Kitten tool that first normalizes HTML file into unicode XHTML file, then extracts the informational content into a text filewith a special processing for sentences, lists and tables."
bouamor-etal-2012-contrastive,A contrastive review of paraphrase acquisition techniques,2012,20,3,4,1,516,houda bouamor,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper addresses the issue of what approach should be used for building a corpus of sententential paraphrases depending on one's requirements. Six strategies are studied: (1) multiple translations into a single language from another language; (2) multiple translations into a single language from different other languages; (3) multiple descriptions of short videos; (4) multiple subtitles for the same language; (5) headlines for similar news articles; and (6) sub-sentential paraphrasing in the context of a Web-based game. We report results on French for 50 paraphrase pairs collected for all these strategies, where corpora were manually aligned at the finest possible level to define oracle performance in terms of accessible sub-sentential paraphrases. The differences observed will be used as criteria for motivating the choice of a given approach before attempting to build a new paraphrase corpus."
F12-2015,Validation sur le Web de reformulations locales: application {\\`a} la Wikip{\\'e}dia (Assisted Rephrasing for {W}ikipedia Contributors through Web-based Validation) [in {F}rench],2012,0,0,4,1,516,houda bouamor,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
F12-2020,"Une {\\'e}tude en 3{D} de la paraphrase: types de corpus, langues et techniques (A Study of Paraphrase along 3 Dimensions : Corpus Types, Languages and Techniques) [in {F}rench]",2012,-1,-1,3,1,516,houda bouamor,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
E12-1073,Validation of sub-sentential paraphrases acquired from parallel monolingual corpora,2012,28,4,3,1,516,houda bouamor,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"The task of paraphrase acquisition from related sentences can be tackled by a variety of techniques making use of various types of knowledge. In this work, we make the hypothesis that their performance can be increased if candidate paraphrases can be validated using information that characterizes paraphrases independently of the set of techniques that proposed them. We implement this as a bi-class classification problem (i.e. paraphrase vs. not paraphrase), allowing any paraphrase acquisition technique to be easily integrated into the combination system. We report experiments on two languages, English and French, with 5 individual techniques on parallel monolingual parallel corpora obtained via multiple translation, and a large set of classification features including surface to contextual similarity measures. Relative improvements in F-measure close to 18% are obtained on both languages over the best performing techniques."
D12-1066,Generalizing Sub-sentential Paraphrase Acquisition across Original Signal Type of Text Pairs,2012,39,7,3,0.293689,28247,aurelien max,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,0,"This paper describes a study on the impact of the original signal (text, speech, visual scene, event) of a text pair on the task of both manual and automatic sub-sentential paraphrase acquisition. A corpus of 2,500 annotated sentences in English and French is described, and performance on this corpus is reported for an efficient system combination exploiting a large set of features for paraphrase recognition. A detailed quantified typology of sub-sentential paraphrases found in our corpus types is given."
W11-1602,Web-based Validation for Contextual Targeted Paraphrasing,2011,39,4,4,1,516,houda bouamor,Proceedings of the Workshop on Monolingual Text-To-Text Generation,0,"In this work, we present a scenario where contextual targeted paraphrasing of sub-sentential phrases is performed automatically to support the task of text revision. Candidate paraphrases are obtained from a preexisting repertoire and validated in the context of the original sentence using information derived from the Web. We report on experiments on French, where the original sentences to be rewritten are taken from a rewriting memory automatically extracted from the edit history of Wikipedia."
P11-2069,Monolingual Alignment by Edit Rate Computation on Sentential Paraphrase Pairs,2011,17,6,3,1,516,houda bouamor,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"In this paper, we present a novel way of tackling the monolingual alignment problem on pairs of sentential paraphrases by means of edit rate computation. In order to inform the edit rate, information in the form of subsentential paraphrases is provided by a range of techniques built for different purposes. We show that the tunable TER-PLUS metric from Machine Translation evaluation can achieve good performance on this task and that it can effectively exploit information coming from complementary sources."
2011.jeptalnrecital-long.38,Combinaison d{'}informations pour l{'}alignement monolingue (Information combination for monolingual alignment),2011,-1,-1,3,1,516,houda bouamor,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans cet article, nous d{\'e}crivons une nouvelle m{\'e}thode d{'}alignement automatique de paraphrases d{'}{\'e}nonc{\'e}s. Nous utilisons des m{\'e}thodes d{\'e}velopp{\'e}es pr{\'e}c{\'e}demment afin de produire diff{\'e}rentes approches hybrides (hybridations). Ces diff{\'e}rentes m{\'e}thodes permettent d{'}acqu{\'e}rir des {\'e}quivalences textuelles {\`a} partir d{'}un corpus monolingue parall{\`e}le. L{'}hybridation combine des informations obtenues par diverses techniques : alignements statistiques, approche symbolique, fusion d{'}arbres syntaxiques et alignement bas{\'e} sur des distances d{'}{\'e}dition. Nous avons {\'e}valu{\'e} l{'}ensemble de ces r{\'e}sultats et nous constatons une am{\'e}lioration sur l{'}acquisition de paraphrases sous-phrastiques."
2011.jeptalnrecital-court.7,S{\\'e}lection de r{\\'e}ponses {\\`a} des questions dans un corpus Web par validation (Selection of answers to questions in a web corpus by validation),2011,-1,-1,6,1,42529,arnaud grappy,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,Les syst{\`e}mes de questions r{\'e}ponses recherchent la r{\'e}ponse {\`a} une question pos{\'e}e en langue naturelle dans un ensemble de documents. Les collectionsWeb diff{\`e}rent des articles de journaux de par leurs structures et leur style. Pour tenir compte de ces sp{\'e}cificit{\'e}s nous avons d{\'e}velopp{\'e} un syst{\`e}me fond{\'e} sur une approche robuste de validation o{\`u} des r{\'e}ponses candidates sont extraites {\`a} partir de courts passages textuels puis ordonn{\'e}es par apprentissage. Les r{\'e}sultats montrent une am{\'e}lioration du MRR (Mean Reciprocal Rank) de 48{\%} par rapport {\`a} la baseline.
2011.jeptalnrecital-court.9,Un lexique pond{\\'e}r{\\'e} des noms d{'}{\\'e}v{\\'e}nements en fran{\\c{c}}ais (A weighted lexicon of event names in {F}rench),2011,-1,-1,3,1,42890,beatrice arnulphy,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Cet article d{\'e}crit une {\'e}tude sur l{'}annotation automatique des noms d{'}{\'e}v{\'e}nements dans les textes en fran{\c{c}}ais. Plusieurs lexiques existants sont utilis{\'e}s, ainsi que des r{\`e}gles syntaxiques d{'}extraction, et un lexique compos{\'e} de fa{\c{c}}on automatique, permettant de fournir une valeur sur le niveau d{'}ambigu{\""\i}t{\'e} du mot en tant qu{'}{\'e}v{\'e}nement. Cette nouvelle information permettrait d{'}aider {\`a} la d{\'e}sambigu{\""\i}sation des noms d{'}{\'e}v{\'e}nements en contexte."
quintard-etal-2010-question,Question Answering on Web Data: The {QA} Evaluation in Qu{\\ae}ro,2010,10,24,9,0,42953,ludovic quintard,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In the QA and information retrieval domains progress has been assessed via evaluation campaigns(Clef, Ntcir, Equer, Trec).In these evaluations, the systems handle independent questions and should provide one answer to each question, extracted from textual data, for both open domain and restricted domain. Qu{\ae}ro is a program promoting research and industrial innovation on technologies for automatic analysis and classification of multimedia and multilingual documents. Among the many research areas concerned by Qu{\ae}ro. The Quaero project organized a series of evaluations of Question Answering on Web Data systems in 2008 and 2009. For each language, English and French the full corpus has a size of around 20Gb for 2.5M documents. We describe the task and corpora, and especially the methodologies used in 2008 to construct the test of question and a new one in the 2009 campaign. Six types of questions were addressed, factual, Non-factual(How, Why, What), List, Boolean. A description of the participating systems and the obtained results is provided. We show the difficulty for a question-answering system to work with complex data and questions."
garcia-fernandez-etal-2010-macaq,{MACAQ} : A Multi Annotated Corpus to Study how we Adapt Answers to Various Questions,2010,5,3,3,1,39320,anne garciafernandez,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper presents a corpus of human answers in natural language collected in order to build a base of examples useful when generating natural language answers. We present the corpus and the way we acquired it. Answers correspond to questions with fixed linguistic form, focus, and topic. Answers to a given question exist for two modalities of interaction: oral and written. The whole corpus of answers was annotated manually and automatically on different levels including words from the questions being reused in the answer, the precise element answering the question (or information-answer), and completions. A detailed description of the annotations is presented. Two examples of corpus analyses are described. The first analysis shows some differences between oral and written modality especially in terms of length of the answers. The second analysis concerns the reuse of the question focus in the answers."
paroubek-etal-2010-second,The Second Evaluation Campaign of {PASSAGE} on Parsing of {F}rench,2010,-1,-1,5,0.552503,5615,patrick paroubek,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,None
grappy-etal-2010-corpus,A Corpus for Studying Full Answer Justification,2010,7,6,8,1,42529,arnaud grappy,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Question answering (QA) systems aim at retrieving precise information from a large collection of documents. To be considered as reliable by users, a QA system must provide elements to evaluate the answer. This notion of answer justification can also be useful when developping a QA system in order to give criteria for selecting correct answers. An answer justification can be found in a sentence, a passage made of several consecutive sentences or several passages of a document or several documents. Thus, we are interesting in pinpointing the set of information that allows to verify the correctness of the answer in a candidate passage and the question elements that are missing in this passage. Moreover, the relevant information is often given in texts in a different form from the question form: anaphora, paraphrases, synonyms. In order to have a better idea of the importance of all the phenomena we underlined, and to provide enough examples at the QA developer's disposal to study them, we decided to build an annotated corpus."
vilnat-etal-2010-passage,{PASSAGE} Syntactic Representation: a Minimal Common Ground for Evaluation,2010,14,9,1,1,15243,anne vilnat,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The current PASSAGE syntactic representation is the result of 9 years of constant evolution with the aim of providing a common ground for evaluating parsers of French whatever their type and supporting theory. In this paper we present the latest developments concerning the formalism and show first through a review of basic linguistic phenomena that it is a plausible minimal common ground for representing French syntax in the context of generic black box quantitative objective evaluation. For the phenomena reviewed, which include: the notion of syntactic head, apposition, control and coordination, we explain how PASSAGE representation relates to other syntactic representation schemes for French and English, slightly extending the annotation to address English when needed. Second, we describe the XML format chosen for PASSAGE and show that it is compliant with the latest propositions in terms of linguistic annotation standard. We conclude discussing the influence that corpus-based evaluation has on the characteristics of syntactic representation when willing to assess the performance of any kind of parser."
2010.jeptalnrecital-long.27,Comment formule-t-on une r{\\'e}ponse en langue naturelle ?,2010,-1,-1,3,1,39320,anne garciafernandez,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article pr{\'e}sente l{'}{\'e}tude d{'}un corpus de r{\'e}ponses formul{\'e}es par des humains {\`a} des questions factuelles. Des observations qualitatives et quantitatives sur la reprise d{'}{\'e}l{\'e}ments de la question dans les r{\'e}ponses sont expos{\'e}es. La notion d{'}information-r{\'e}ponse est introduite et une {\'e}tude de la pr{\'e}sence de cet {\'e}l{\'e}ment dans le corpus est propos{\'e}e. Enfin, les formulations des r{\'e}ponses sont {\'e}tudi{\'e}es."
2010.jeptalnrecital-court.18,Acquisition de paraphrases sous-phrastiques depuis des paraphrases d{'}{\\'e}nonc{\\'e}s,2010,-1,-1,3,1,516,houda bouamor,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Dans cet article, nous pr{\'e}sentons la t{\^a}che d{'}acquisition de paraphrases sous-phrastiques (impliquant des paires de mots ou de groupes de mots), et d{\'e}crivons plusieurs techniques op{\'e}rant {\`a} diff{\'e}rents niveaux. Nous d{\'e}crivons une {\'e}valuation visant {\`a} comparer ces techniques et leurs combinaisons sur deux corpus de paraphrases d{'}{\'e}nonc{\'e}s obtenus par traduction multiple. Les conclusions que nous tirons peuvent servir de guide pour am{\'e}liorer des techniques existantes."
2010.jeptalnrecital-court.25,Les entit{\\'e}s nomm{\\'e}es {\\'e}v{\\'e}nement et les verbes de cause-cons{\\'e}quence,2010,-1,-1,3,1,42890,beatrice arnulphy,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"L{'}extraction des {\'e}v{\'e}nements d{\'e}sign{\'e}s par des noms est peu {\'e}tudi{\'e}e dans des corpus g{\'e}n{\'e}ralistes. Si des lexiques de noms d{\'e}clencheurs d{'}{\'e}v{\'e}nements existent, les probl{\`e}mes de polys{\'e}mie sont nombreux et beaucoup d{'}{\'e}v{\'e}nements ne sont pas introduits par des d{\'e}clencheurs. Nous nous int{\'e}ressons dans cet article {\`a} une hypoth{\`e}se selon laquelle les verbes induisant la cause ou la cons{\'e}quence sont de bons indices quant {\`a} la pr{\'e}sence d{'}{\'e}v{\'e}nements nominaux dans leur cotexte."
R09-1053,Unsupervised Word Sense Induction from Multiple Semantic Spaces with Locality Sensitive Hashing,2009,20,4,4,0,46131,claire mouton,Proceedings of the International Conference {RANLP}-2009,0,"Word Sense Disambiguation is the task dedicated to the problem of finding out the sense of a word in context, from all of its many possible senses. Solving this problem requires to know the set of possible senses for a given word, which can be acquired from human knowledge, or from automatic discovery, called Word Sense Induction. In this article, we adapt two existing meta-methods of Word Sense Induction for the automatic construction of a disambiguation lexicon. Our adaptation is based on multiple semantic spaces (also called Word Space Models) produced from a syntactic analysis of a very large number of web pages. These adaptations and the results presented in this article dier from the original methods in that they use a combination of several high dimensional spaces instead of one single representation. Each of these competing semantic spaces takes part in a clustering phase in which they vote on sense induction."
2009.jeptalnrecital-demonstration.2,Amener des utilisateurs {\\`a} cr{\\'e}er et {\\'e}valuer des paraphrases par le jeu,2009,-1,-1,3,1,516,houda bouamor,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. D{\\'e}monstrations,0,"Dans cet article, nous pr{\'e}sentons une application sur le web pour l{'}acquisition de paraphrases phrastiques et sous-phrastiques sous forme de jeu. L{'}application permet l{'}acquisition {\`a} la fois de paraphrases et de jugements humains multiples sur ces paraphrases, ce qui constitue des donn{\'e}es particuli{\`e}rement utiles pour les applications du TAL bas{\'e}es sur les ph{\'e}nom{\`e}nes paraphrastiques."
2009.jeptalnrecital-court.26,Collecte et analyses de r{\\'e}ponses naturelles pour les syst{\\`e}mes de questions-r{\\'e}ponses,2009,-1,-1,3,1,39320,anne garciafernandez,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,Notre travail se situe dans le cadre des syst{\`e}mes de r{\'e}ponse a une question et {\`a} pour but de fournir une r{\'e}ponse en langue naturelle aux questions pos{\'e}es en langue naturelle. Cet article pr{\'e}sente une exp{\'e}rience permettant d{'}analyser les r{\'e}ponses de locuteurs du fran{\c{c}}ais {\`a} des questions que nous leur posons. L{'}exp{\'e}rience se d{\'e}roule {\`a} l{'}{\'e}crit comme {\`a} l{'}oral et propose {\`a} des locuteurs fran{\c{c}}ais des questions relevant de diff{\'e}rents types s{\'e}mantiques et syntaxiques. Nous mettons en valeur une large variabilit{\'e} dans les formes de r{\'e}ponses possibles en langue fran{\c{c}}aise. D{'}autre part nous {\'e}tablissons un certain nombre de liens entre formulation de question et formulation de r{\'e}ponse. Nous proposons d{'}autre part une comparaison des r{\'e}ponses selon la modalit{\'e} oral / {\'e}crit. Ces r{\'e}sultats peuvent {\^e}tre int{\'e}gr{\'e}s {\`a} des syst{\`e}mes existants pour produire une r{\'e}ponse en langue naturelle de fa{\c{c}}on dynamique.
W08-1306,Large Scale Production of Syntactic Annotations to Move Forward,2008,19,1,1,1,15243,anne vilnat,Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation,0,"This article presents the methodology of the PASSAGE project, aiming at syntactically annotating large corpora by composing annotations. It introduces the annotation format and the syntactic annotation specifications. It describes an important component of the methodolgy, namely an WEB-based evaluation service, deployed in the context of the first PASSAGE parser evaluation campaign."
paroubek-etal-2008-easy,"{EASY}, Evaluation of Parsers of {F}rench: what are the Results?",2008,10,9,3,1,5615,patrick paroubek,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper presents EASY, which has been the first campaign evaluating syntactic parsers on all the common syntactic phenomena and a large set of dependency relations. The language analyzed was French. During this campaign, an annotation scheme has been elaborated with the different actors: participants and corpus providers; then a corpus made of several syntactic materials has been built and annotated: it reflects a great variety of linguistic styles (from literature to oral transcriptions, and from newspapers to medical texts). Both corpus and annotation scheme are here briefly presented. Moreover, evaluation measures are explained and detailed results are given. The results of the 15 parsers coming from 12 teams are analyzed. To conclude, a first experiment aiming to combine the outputs of the different systems is shown."
villemonte-de-la-clergerie-etal-2008-passage,{PASSAGE}: from {F}rench Parser Evaluation to Large Sized Treebank,2008,11,23,6,0,17825,eric clergerie,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this paper we present the PASSAGE project which aims at building automatically a French Treebank of large size by combining the output of several parsers, using the EASY annotation scheme. We present also the results of the of the first evaluation campaign of the project and the preliminary results we have obtained with our ROVER procedure for combining parsers automatically."
2007.jeptalnrecital-poster.17,Syst{\\`e}mes de questions-r{\\'e}ponses : vers la validation automatique des r{\\'e}ponses,2007,-1,-1,4,1,864,annelaure ligozat,Actes de la 14{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Les syst{\`e}mes de questions-r{\'e}ponses (SQR) ont pour but de trouver une information pr{\'e}cise extraite d{'}une grande collection de documents comme le Web. Afin de pouvoir comparer les diff{\'e}rentes strat{\'e}gies possibles pour trouver une telle information, il est important d{'}{\'e}valuer ces syst{\`e}mes. L{'}objectif d{'}une t{\^a}che de validation de r{\'e}ponses est d{'}estimer si une r{\'e}ponse donn{\'e}e par un SQR est correcte ou non, en fonction du passage de texte donn{\'e} comme justification. En 2006, nous avons particip{\'e} {\`a} une t{\^a}che de validation de r{\'e}ponses, et dans cet article nous pr{\'e}sentons la strat{\'e}gie que nous avons utilis{\'e}e. Celle-ci est fond{\'e}e sur notre propre syst{\`e}me de questions-r{\'e}ponses. Le principe est de comparer nos r{\'e}ponses avec les r{\'e}ponses {\`a} valider. Nous pr{\'e}sentons les r{\'e}sultats obtenus et montrons les extensions possibles. {\`A} partir de quelques exemples, nous soulignons les difficult{\'e}s que pose cette t{\^a}che."
2007.jeptalnrecital-poster.24,Les r{\\'e}sultats de la campagne {EASY} d{'}{\\'e}valuation des analyseurs syntaxiques du fran{\\c{c}}ais,2007,-1,-1,2,1,5615,patrick paroubek,Actes de la 14{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Dans cet article, nous pr{\'e}sentons les r{\'e}sultats de la campagne d{'}{\'e}valuation EASY des analyseurs syntaxiques du fran{\c{c}}ais. EASY a {\'e}t{\'e} la toute premi{\`e}re campagne d{'}{\'e}valuation comparative des analyseurs syntaxiques du fran{\c{c}}ais en mode bo{\^\i}te noire utilisant des mesures objectives quantitatives. EASY fait partie du programme TECHNOLANGUE du Minist{\`e}re d{\'e}l{\'e}gu{\'e} {\`a} la Recherche et {\`a} l{'}{\'E}ducation, avec le soutien du minist{\`e}re de d{\'e}l{\'e}gu{\'e} {\`a} l{'}industrie et du minist{\`e}re de la culture et de la communication. Nous exposons tout d{'}abord la position de la campagne par rapport aux autres projets d{'}{\'e}valuation en analyse syntaxique, puis nous pr{\'e}sentos son d{\'e}roulement, et donnons les r{\'e}sultats des 15 analyseurs participants en fonction des diff{\'e}rents types de corpus et des diff{\'e}rentes annotations (constituants et relations). Nous proposons ensuite un ensemble de le{\c{c}}ons {\`a} tirer de cette campagne, en particulier {\`a} propos du protocole d{'}{\'e}valuation, de la d{\'e}finition de la segmentation en unit{\'e}s linguistiques, du formalisme et des activit{\'e}s d{'}annotation, des crit{\`e}res de qualit{\'e} des donn{\'e}es, des annotations et des r{\'e}sultats, et finalement de la notion de r{\'e}f{\'e}rence en analyse syntaxique. Nous concluons en pr{\'e}sentant comment les r{\'e}sultats d{'}EASY se prolongent dans le projet PASSAGE (ANR-06-MDCA-013) qui vient de d{\'e}buter et dont l{'}objectif est d{'}{\'e}tiqueter un grand corpus par plusieurs analyseurs en les combinant selon des param{\`e}tres issus de l{'}{\'e}valuation."
W06-1904,Evaluation and Improvement of Cross-Lingual Question {A}nswering{S}trategies,2006,18,9,4,1,864,annelaure ligozat,Proceedings of the Workshop on Multilingual Question Answering - {MLQA} {`}06,0,"This article presents a bilingual question answering system, which is able to process questions and documents both in French and in English. Two cross-lingual strategies are described and evaluated. First, we study the contribution of biterms translation, and the influence of the completion of the translation dictionaries. Then, we propose a strategy for transferring the question analysis from one language to the other, and we study its influence on the performance of our system."
paroubek-etal-2006-data,"Data, Annotations and Measures in {EASY} the Evaluation Campaign for Parsers of {F}rench.",2006,15,31,3,1,5615,patrick paroubek,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper presents the protocol of EASY the evaluation campaign for syntactic parsers of French in the EVALDA project of the TECHNOLANGUE program. We describe the participants, the corpus and its genre partitioning, the annotation scheme, which allows for the annotation of both constituents and relations, the evaluation methodology and, as an illustration, the results obtained by one participant on half of the corpus."
ayache-etal-2006-equer,{EQ}ue{R}: the {F}rench Evaluation campaign of Question-Answering Systems,2006,2,19,3,0,46352,christelle ayache,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper describes the EQueR-EVALDA Evaluation Campaign, the French evaluation campaign of Question-Answering (QA) systems. The EQueR Evaluation Campaign included two tasks of automatic answer retrieval: the first one was a QA task over a heterogeneous collection of texts - mainly newspaper articles, and the second one a specialised one in the Medical field over a corpus of medical texts. In total, seven groups participated in the General task and five groups participated in the Medical task. For the General task, the best system obtained 81.46{\%} of correct answers during the evalaution of the passages, while it obtained 67.24{\%} during the evaluation of the short answers. We describe herein the specifications, the corpora, the evaluation, the phase of judgment of results, the scoring phase and the results for the two different types of evaluation."
grau-etal-2006-frasques,{FRASQUES}: A Question Answering system in the {EQ}ue{R} evaluation campaign,2006,3,8,4,1,2112,brigitte grau,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Question-answering (QA) systems aim at providing either a small passage or just the answer to a question in natural language. We have developed several QA systems that work on both English and French. This way, we are able to provide answers to questions given in both languages by searching documents in both languages also. In this article, we present our French monolingual system FRASQUES which participated in the EQueR evaluation campaign of QA systems for French in 2004. First, the QA architecture common to our systems is shown. Then, for every step of the QA process, we consider which steps are language-independent, and for those that are language-dependent, the tools or processes that need to be adapted to switch for one language to another. Finally, our results at EQueR are given and commented; an error analysis is conducted, and the kind of knowledge needed to answer a question is studied."
2006.jeptalnrecital-long.20,L{'}extraction des r{\\'e}ponses dans un syst{\\`e}me de question-r{\\'e}ponse,2006,-1,-1,4,1,864,annelaure ligozat,Actes de la 13{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Les syst{\`e}mes de question-r{\'e}ponse sont la plupart du temps compos{\'e}s de trois grands modules : l{'}analyse de la question, la s{\'e}lection des documents et l{'}extraction de la r{\'e}ponse. Dans cet article, nous nous int{\'e}ressons au troisi{\`e}me module, plus particuli{\`e}rement dans le cas plus d{\'e}licat o{\`u} la r{\'e}ponse attendue n{'}est pas du type entit{\'e}e nomm{\'e}e. Nous d{\'e}crivons comment l{'}analyseur Cass est employ{\'e} pour marquer la r{\'e}ponse dans les phrases candidates et nous {\'e}valuons les r{\'e}sultats de cette approche. Au pr{\'e}alable, nous d{\'e}crivons et {\'e}valuons le module d{\'e}di{\'e} {\`a} l{'}analyse de la question, car les informations qui en sont issues sont n{\'e}cessaires {\`a} notre {\'e}tape finale d{'}extraction."
vilnat-etal-2004-ongoing,The Ongoing Evaluation Campaign of Syntactic Parsing of {F}rench: {EASY},2004,5,10,1,1,15243,anne vilnat,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper presents EASY (Evaluation of Analyzers of SYntax), an ongoing evaluation campaign of syntactic parsing of French, a subproject of EVALDA in the French TECHNOLANGUE program. After presenting the elaboration of the annotation formalism, we describe the corpus building steps, the annotation tools, the evaluation measures and finally, plans to produce a validated large linguistic resource, syntactically annotated"
2004.jeptalnrecital-long.32,Annoter en constituants pour {\\'e}valuer des analyseurs syntaxiques,2004,-1,-1,1,1,15243,anne vilnat,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article pr{\'e}sente l{'}annotation en constituants men{\'e}e dans le cadre d{'}un protocole d{'}{\'e}valuation des analyseurs syntaxiques (mis au point dans le pr{\'e}-projet PEAS, puis dans le projet EASY). Le choix des constituants est d{\'e}crit en d{\'e}tail et une premi{\`e}re {\'e}valuation effectu{\'e}e {\`a} partir des r{\'e}sultats de deux analyseurs est donn{\'e}e."
E03-1085,"{PEAS}, the first instantiation of a comparative framework for evaluating parsers of {F}rench",2003,9,11,7,1,52094,veronique gendner,10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"This paper presents PEAS, the first comparative evaluation framework for parsers of French whose annotation formalism allows the annotation of both constituents and functional relations. A test corpus containing an assortment of different text types has been built and part of it has been manually annotated. Precision/Recall and crossing brackets metrics will be adapted to our formalism and applied to the parses produced by one parser from academia and another one from industry in order to validate the framework."
2003.jeptalnrecital-long.9,Confronter des sources de connaissances diff{\\'e}rentes pour obtenir une r{\\'e}ponse plus fiable,2003,-1,-1,8,0.952381,16752,gael chalendar,Actes de la 10{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"La fiabilit{\'e} des r{\'e}ponses qu{'}il propose, ou un moyen de l{'}estimer, est le meilleur atout d{'}un syst{\`e}me de question-r{\'e}ponse. A cette fin, nous avons choisi d{'}effectuer des recherches dans des ensembles de documents diff{\'e}rents et de privil{\'e}gier des r{\'e}sultats qui sont trouv{\'e}s dans ces diff{\'e}rentes sources. Ainsi, le syst{\`e}me QALC travaille {\`a} la fois sur une collection finie d{'}articles de journaux et sur le Web."
2003.jeptalnrecital-long.20,{MULTI}-{ANALYSE} vers une analyse syntaxique plus fiable,2003,-1,-1,2,0,30967,laura monceaux,Actes de la 10{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans cet article, nous proposons de montrer que la combinaison de plusieurs analyses syntaxiques permet d{'}extraire Panalyse la plus fiable pour une phrase donn{\'e}e. De plus, chaque information syntaxique sera affect{\'e}e d{'}un score de confiance d{\'e}termin{\'e} selon le nombre d{'}analyseurs syntaxiques la confirmant. Nous verrons que cette approche implique l{'}{\'e}tude des diff{\'e}rents analyseurs syntaxiques existants ainsi que leur {\'e}valuation."
gendner-etal-2002-protocol,A Protocol for Evaluating Analyzers of Syntax ({PEAS}),2002,17,3,7,0,52094,veronique gendner,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"Providing a comparative framework for parsers is a task that has already been tried in the past, e.g. (Abeille, 1991), (Atwell and Sutcliffe, 1997), (Black et al., 1991), and studied in the literature (Black, 1993), (Black, 1994), (Carroll et al., 1998), (Gaizauskas et al., 1998), (WEPS-98, ), (Mengel and Lezius, 2000), but mainly for English. In this paper, we present PEAS: a Protocol for Evaluating Analyzers of Syntax (in French: Protocole dxe2x80x99Evaluation pour les Analyseurs Syntaxiques), based on an ongoing experiment at LIMSI which aims at developing and testing a generic quantitative black-box evaluation protocol for parsers of French. Two fully operational parsers will be used to test the evaluation protocol; they are: the parser (Giguet and Vergne, 1997) developed at GREYC (Caen University) and the latest version of the parser developed at Rank Xerox Research Center in Grenoble (Ait-Mokhtar and Chanod, 1997)"
2002.jeptalnrecital-long.28,Recherche de la r{\\'e}ponse fond{\\'e}e sur la reconnaissance du focus de la question,2002,-1,-1,7,0,5589,olivier ferret,Actes de la 9{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Le syst{\`e}me de question-r{\'e}ponse QALC utilise les documents s{\'e}lectionn{\'e}s par un moteur de recherche pour la question pos{\'e}e, les s{\'e}pare en phrases afin de comparer chaque phrase avec la question, puis localise la r{\'e}ponse soit en d{\'e}tectant l{'}entit{\'e} nomm{\'e}e recherch{\'e}e, soit en appliquant des patrons syntaxiques d{'}extraction de la r{\'e}ponse, sortes de sch{\'e}mas fig{\'e}s de r{\'e}ponse pour un type donn{\'e} de question. Les patrons d{'}extraction que nous avons d{\'e}finis se fondent sur la notion de focus, qui est l{'}{\'e}l{\'e}ment important de la question, celui qui devra se trouver dans la phrase r{\'e}ponse. Dans cet article, nous d{\'e}crirons comment nous d{\'e}terminons le focus dans la question, puis comment nous l{'}utilisons dans l{'}appariement question-phrase et pour la localisation de la r{\'e}ponse dans les phrases les plus pertinentes retenues."
