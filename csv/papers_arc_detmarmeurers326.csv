2021.nlp4call-1.2,Automatic annotation of curricular language targets to enrich activity models and support both pedagogy and adaptive systems,2021,-1,-1,4,0,3010,marti quixal,Proceedings of the 10th Workshop on NLP for Computer Assisted Language Learning,0,None
2021.nlp4call-1.4,Using Broad Linguistic Complexity Modeling for Cross-Lingual Readability Assessment,2021,-1,-1,3,1,3015,zarah weiss,Proceedings of the 10th Workshop on NLP for Computer Assisted Language Learning,0,None
2021.inlg-1.3,Exploring Input Representation Granularity for Generating Questions Satisfying Question-Answer Congruence,2021,-1,-1,5,1,5911,madeeswaran kannan,Proceedings of the 14th International Conference on Natural Language Generation,0,"In question generation, the question produced has to be well-formed and meaningfully related to the answer serving as input. Neural generation methods have predominantly leveraged the distributional semantics of words as representations of meaning and generated questions one word at a time. In this paper, we explore the viability of form-based and more fine-grained encodings, such as character or subword representations for question generation. We start from the typical seq2seq architecture using word embeddings presented by De Kuthy et al. (2020), who generate questions from text so that the answer given in the input text matches not just in meaning but also in form, satisfying question-answer congruence. We show that models trained on character and subword representations substantially outperform the published results based on word embeddings, and they do so with fewer parameters. Our approach eliminates two important problems of the word-based approach: the encoding of rare or out-of-vocabulary words and the incorrect replacement of words with semantically-related ones. The character-based model substantially improves on the published results, both in terms of BLEU scores and regarding the quality of the generated question. Going beyond the specific task, this result adds to the evidence weighing different form- and meaning-based representations for natural language processing tasks."
2021.bea-1.3,Employing distributional semantics to organize task-focused vocabulary learning,2021,-1,-1,2,1,5912,haemanth ponnusamy,Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications,0,"How can a learner systematically prepare for reading a book they are interested in? In this paper, we explore how computational linguistic methods such as distributional semantics, morphological clustering, and exercise generation can be combined with graph-based learner models to answer this question both conceptually and in practice. Based on highly structured learner models and concepts from network analysis, the learner is guided to efficiently explore the targeted lexical space. They practice using multi-gap learning activities generated from the book. In sum, the approach combines computational linguistic methods with concepts from network analysis and tutoring systems to support learners in pursuing their individual reading task goals."
2021.bea-1.5,Broad Linguistic Complexity Analysis for {G}reek Readability Classification,2021,-1,-1,3,0,12218,savvas chatzipanagiotidis,Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications,0,"This paper explores the linguistic complexity of Greek textbooks as a readability classification task. We analyze textbook corpora for different school subjects and textbooks for Greek as a Second Language, covering a very wide spectrum of school age groups and proficiency levels. A broad range of quantifiable linguistic complexity features (lexical, morphological and syntactic) are extracted and calculated. Conducting experiments with different feature subsets, we show that the different linguistic dimensions contribute orthogonal information, each contributing towards the highest result achieved using all linguistic feature subsets. A readability classifier trained on this basis reaches a classification accuracy of 88.16{\%} for the Greek as a Second Language corpus. To investigate the generalizability of the classification models, we also perform cross-corpus evaluations. We show that the model trained on the most varied text collection (for Greek as a school subject) generalizes best. In addition to advancing the state of the art for Greek readability analysis, the paper also contributes insights on the role of different feature sets and training setups for generalizable readability classification."
2020.coling-main.509,Towards automatically generating Questions under Discussion to link information and discourse structure,2020,-1,-1,4,1,5913,kordula kuthy,Proceedings of the 28th International Conference on Computational Linguistics,0,"Questions under Discussion (QUD; Roberts, 2012) are emerging as a conceptually fruitful approach to spelling out the connection between the information structure of a sentence and the nature of the discourse in which the sentence can function. To make this approach useful for analyzing authentic data, Riester, Brunetti {\&} De Kuthy (2018) presented a discourse annotation framework based on explicit pragmatic principles for determining a QUD for every assertion in a text. De Kuthy et al. (2018) demonstrate that this supports more reliable discourse structure annotation, and Ziai and Meurers (2018) show that based on explicit questions, automatic focus annotation becomes feasible. But both approaches are based on manually specified questions. In this paper, we present an automatic question generation approach to partially automate QUD annotation by generating all potentially relevant questions for a given sentence. While transformation rules can concisely capture the typical question formation process, a rule-based approach is not sufficiently robust for authentic data. We therefore employ the transformation rules to generate a large set of sentence-question-answer triples and train a neural question generation model on them to obtain both systematic question type coverage and robustness."
W19-6305,Integrating large-scale web data and curated corpus data in a search engine supporting {G}erman literacy education,2019,-1,-1,4,0,23655,sabrina dittrich,Proceedings of the 8th Workshop on NLP for Computer Assisted Language Learning,0,None
W19-6310,The Impact of Spelling Correction and Task Context on Short Answer Assessment for Intelligent Tutoring Systems,2019,-1,-1,5,1,3018,ramon ziai,Proceedings of the 8th Workshop on NLP for Computer Assisted Language Learning,0,None
W19-4404,Computationally Modeling the Impact of Task-Appropriate Language Complexity and Accuracy on Human Grading of {G}erman Essays,2019,0,0,4,1,3015,zarah weiss,Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications,0,"Computational linguistic research on the language complexity of student writing typically involves human ratings as a gold standard. However, educational science shows that teachers find it difficult to identify and cleanly separate accuracy, different aspects of complexity, contents, and structure. In this paper, we therefore explore the use of computational linguistic methods to investigate how task-appropriate complexity and accuracy relate to the grading of overall performance, content performance, and language performance as assigned by teachers. Based on texts written by students for the official school-leaving state examination (Abitur), we show that teachers successfully assign higher language performance grades to essays with higher task-appropriate language complexity and properly separate this from content scores. Yet, accuracy impacts teacher assessment for all grading rubrics, also the content score, overemphasizing the role of accuracy. Our analysis is based on broad computational linguistic modeling of German language complexity and an innovative theory- and data-driven feature aggregation method inferring task-appropriate language complexity."
W19-4440,Analyzing Linguistic Complexity and Accuracy in Academic Language Development of {G}erman across Elementary and Secondary School,2019,-1,-1,2,1,3015,zarah weiss,Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications,0,"We track the development of writing complexity and accuracy in German students{'} early academic language development from first to eighth grade. Combining an empirically broad approach to linguistic complexity with the high-quality error annotation included in the Karlsruhe Children{'}s Text corpus (Lavalley et al. 2015) used, we construct models of German academic language development that successfully identify the student{'}s grade level. We show that classifiers for the early years rely more on accuracy development, whereas development in secondary school is better characterized by increasingly complex language in all domains: linguistic system, language use, and human sentence processing characteristics. We demonstrate the generalizability and robustness of models using such a broad complexity feature set across writing topics."
W18-7109,A Linguistically-Informed Search Engine to Identifiy Reading Material for Functional Illiteracy Classes,2018,0,0,3,1,3015,zarah weiss,Proceedings of the 7th workshop on {NLP} for Computer Assisted Language Learning,0,None
W18-7110,Feedback Strategies for Form and Meaning in a Real-life Language Tutoring System,2018,-1,-1,5,1,3018,ramon ziai,Proceedings of the 7th workshop on {NLP} for Computer Assisted Language Learning,0,None
W18-0504,Automatic Input Enrichment for Selecting Reading Material: An Online Study with {E}nglish Teachers,2018,0,1,3,1,28636,maria chinkina,Proceedings of the Thirteenth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"Input material at the appropriate level is crucial for language acquisition. Automating the search for such material can systematically and efficiently support teachers in their pedagogical practice. This is the goal of the computational linguistic task of automatic input enrichment (Chinkina {\&} Meurers, 2016): It analyzes and re-ranks a collection of texts in order to prioritize those containing target linguistic forms. In the online study described in the paper, we collected 240 responses from English teachers in order to investigate whether they preferred automatic input enrichment over web search when selecting reading material for class. Participants demonstrated a general preference for the material provided by an automatic input enrichment system. It was also rated significantly higher than the texts retrieved by a standard web search engine with regard to the representation of linguistic forms and equivalent with regard to the relevance of the content to the topic. We discuss the implications of the results for language teaching and consider the potential strands of future research."
W18-0509,{COAST} - Customizable Online Syllable Enhancement in Texts. A flexible framework for automatically enhancing reading materials,2018,0,1,4,0,28639,heiko holz,Proceedings of the Thirteenth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"This paper presents COAST, a web-based application to easily and automatically enhance syllable structure, word stress, and spacing in texts, that was designed in close collaboration with learning therapists to ensure its practical relevance. Such syllable-enhanced texts are commonly used in learning therapy or private tuition to promote the recognition of syllables in order to improve reading and writing skills. In a state of the art solutions for automatic syllable enhancement, we put special emphasis on syllable stress and support specific marking of the primary syllable stress in words. Core features of our tool are i) a highly customizable text enhancement and template functionality, and ii) a novel crowd-sourcing mechanism that we employ to address the issue of data sparsity in language resources. We successfully tested COAST with real-life practitioners in a series of user tests validating the concept of our framework."
W18-0513,Generating Feedback for {E}nglish Foreign Language Exercises,2018,0,2,6,1,3011,bjorn rudzewitz,Proceedings of the Thirteenth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"While immediate feedback on learner language is often discussed in the Second Language Acquisition literature (e.g., Mackey 2006), few systems used in real-life educational settings provide helpful, metalinguistic feedback to learners. In this paper, we present a novel approach leveraging task information to generate the expected range of well-formed and ill-formed variability in learner answers along with the required diagnosis and feedback. We combine this offline generation approach with an online component that matches the actual student answers against the pre-computed hypotheses. The results obtained for a set of 33 thousand answers of 7th grade German high school students learning English show that the approach successfully covers frequent answer patterns. At the same time, paraphrases and content errors require a more flexible alignment approach, for which we are planning to complement the method with the CoMiC approach successfully used for the analysis of reading comprehension answers (Meurers et al., 2011)."
N18-1011,Automatic Focus Annotation: Bringing Formal Pragmatics Alive in Analyzing the Information Structure of Authentic Data,2018,0,1,2,1,3018,ramon ziai,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"Analyzing language in context, both from a theoretical and from a computational perspective, is receiving increased interest. Complementing the research in linguistics on discourse and information structure, in computational linguistics identifying discourse concepts was also shown to improve the performance of certain applications, for example, Short Answer Assessment systems (Ziai and Meurers, 2014). Building on the research that established detailed annotation guidelines for manual annotation of information structural concepts for written (Dipper et al., 2007; Ziai and Meurers, 2014) and spoken language data (Calhoun et al., 2010), this paper presents the first approach automating the analysis of focus in authentic written data. Our classification approach combines a range of lexical, syntactic, and semantic features to achieve an accuracy of 78.1{\%} for identifying focus."
C18-1026,Modeling the Readability of {G}erman Targeting Adults and Children: An empirically broad analysis and its cross-corpus validation,2018,0,0,2,1,3015,zarah weiss,Proceedings of the 27th International Conference on Computational Linguistics,0,"We analyze two novel data sets of German educational media texts targeting adults and children. The analysis is based on 400 automatically extracted measures of linguistic complexity from a wide range of linguistic domains. We show that both data sets exhibit broad linguistic adaptation to the target audience, which generalizes across both data sets. Our most successful binary classification model for German readability robustly shows high accuracy between 89.4{\%}{--}98.9{\%} for both data sets. To our knowledge, this comprehensive German readability model is the first for which robust cross-corpus performance has been shown. The research also contributes resources for German readability assessment that are externally validated as successful for different target audiences: we compiled a new corpus of German news broadcast subtitles, the Tagesschau/Logo corpus, and crawled a GEO/GEOlino corpus substantially enlarging the data compiled by Hancke et al. 2012."
W17-5038,Question Generation for Language Learning: From ensuring texts are read to supporting learning,2017,21,6,2,1,28636,maria chinkina,Proceedings of the 12th Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"In Foreign Language Teaching and Learning (FLTL), questions are systematically used to assess the learner{'}s understanding of a text. Computational linguistic approaches have been developed to generate such questions automatically given a text (e.g., Heilman, 2011). In this paper, we want to broaden the perspective on the different functions questions can play in FLTL and discuss how automatic question generation can support the different uses. Complementing the focus on meaning and comprehension, we want to highlight the fact that questions can also be used to make learners notice form aspects of the linguistic system and their interpretation. Automatically generating questions that target linguistic forms and grammatical categories in a text in essence supports incidental focus-on-form (Loewen, 2005) in a meaning-focused reading task. We discuss two types of questions serving this purpose, how they can be generated automatically; and we report on a crowd-sourcing evaluation comparing automatically generated to manually written questions targeting particle verbs, a challenging linguistic form for learners of English."
W17-0302,Challenging learners in their individual zone of proximal development using pedagogic developmental benchmarks of syntactic complexity,2017,0,1,2,1,3016,xiaobin chen,Proceedings of the joint workshop on {NLP} for Computer Assisted Language Learning and {NLP} for Language Acquisition,0,None
W17-0305,Developing a web-based workbook for {E}nglish supporting the interaction of students and teachers,2017,-1,-1,4,1,3011,bjorn rudzewitz,Proceedings of the joint workshop on {NLP} for Computer Assisted Language Learning and {NLP} for Language Acquisition,0,None
W16-4105,Towards grounding computational linguistic approaches to readability: Modeling reader-text interaction for easy and difficult texts,2016,0,0,2,1,830,sowmya vajjala,Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity ({CL}4{LC}),0,"Computational approaches to readability assessment are generally built and evaluated using gold standard corpora labeled by publishers or teachers rather than being grounded in observations about human performance. Considering that both the reading process and the outcome can be observed, there is an empirical wealth that could be used to ground computational analysis of text readability. This will also support explicit readability models connecting text complexity and the reader{'}s language proficiency to the reading process and outcomes. This paper takes a step in this direction by reporting on an experiment to study how the relation between text complexity and reader{'}s language proficiency affects the reading process and performance outcomes of readers after reading We modeled the reading process using three eye tracking variables: fixation count, average fixation count, and second pass reading duration. Our models for these variables explained 78.9{\%}, 74{\%} and 67.4{\%} variance, respectively. Performance outcome was modeled through recall and comprehension questions, and these models explained 58.9{\%} and 27.6{\%} of the variance, respectively. While the online models give us a better understanding of the cognitive correlates of reading with text complexity and language proficiency, modeling of the offline measures can be particularly relevant for incorporating user aspects into readability models."
W16-4113,{CTAP}: A Web-Based Tool Supporting Automatic Complexity Analysis,2016,0,5,2,1,3016,xiaobin chen,Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity ({CL}4{LC}),0,"Informed by research on readability and language acquisition, computational linguists have developed sophisticated tools for the analysis of linguistic complexity. While some tools are starting to become accessible on the web, there still is a disconnect between the features that can in principle be identified based on state-of-the-art computational linguistic analysis, and the analyses a second language acquisition researcher, teacher, or textbook writer can readily obtain and visualize for their own collection of texts. This short paper presents a web-based tool development that aims to meet this challenge. The Common Text Analysis Platform (CTAP) is designed to support fully configurable linguistic feature extraction for a wide range of complexity analyses. It features a user-friendly interface, modularized and reusable analysis component integration, and flexible corpus and feature management. Building on the Unstructured Information Management framework (UIMA), CTAP readily supports integration of state-of-the-art NLP and complexity feature extraction maintaining modularization and reusability. CTAP thereby aims at providing a common platform for complexity analysis, encouraging research collaboration and sharing of feature extraction components{---}to jointly advance the state-of-the-art in complexity analysis in a form that readily supports real-life use by ordinary users."
W16-1713,Focus Annotation of Task-based Data: Establishing the Quality of Crowd Annotation,2016,12,1,3,1,5913,kordula kuthy,Proceedings of the 10th Linguistic Annotation Workshop held in conjunction with {ACL} 2016 ({LAW}-X 2016),0,None
W16-0509,Characterizing Text Difficulty with Word Frequencies,2016,0,6,2,1,3016,xiaobin chen,Proceedings of the 11th Workshop on Innovative Use of {NLP} for Building Educational Applications,0,None
W16-0521,Linguistically Aware Information Retrieval: Providing Input Enrichment for Second Language Learners,2016,28,10,2,1,28636,maria chinkina,Proceedings of the 11th Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"How can second language teachers retrieve texts that are rich in terms of the grammatical constructions to be taught, but also address the content of interest to the learners? We developed an Information Retrieval system that identifies the 87 grammatical constructions spelled out in the official English language curriculum of schools in Baden-Wxc2xa8 urttemberg (Germany) and reranks the search results based on the selected (de)prioritization of grammatical forms. In combination with a visualization of the characteristics of the search results, the approach effectively supports teachers in prioritizing those texts that provide the targeted forms. The approach facilitates systematic input enrichment for language learners as a complement to the established notion of input enhancement: while input enrichment aims at richly representing the selected forms and categories in a text, input enhancement targets their presentation to make them more salient and support noticing."
S16-2026,Approximating Givenness in Content Assessment through Distributional Semantics,2016,23,2,3,1,3018,ramon ziai,Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics,0,"Givenness (Schwarzschild, 1999) is one of the central notions in the formal pragmatic literature discussing the organization of discourse. In this paper, we explore where distributional semantics can help address the gap between the linguistic insights into the formal pragmatic notion of Givenness and its implementation in computational linguistics. As experimental testbed, we focus on short answer assessment, in which the goal is to assess whether a student response correctly answers the provided reading comprehension question or not. Current approaches only implement a very basic, surface-based perspective on Givenness: A word of the answer that appears as such in the question counts as GIVEN. We show that an approach approximating Givenness using distributional semantics to check whether a word in a sentence is similar enough to a word in the context to count as GIVEN is more successful quantitatively and supports interesting qualitative insights into the data and the limitations of a basic distributional semantic approach identifying Givenness at the lexical level."
P16-4002,Online Information Retrieval for Language Learning,2016,15,6,3,1,28636,maria chinkina,Proceedings of {ACL}-2016 System Demonstrations,0,"The reading material used in a language learning classroom should ideally be rich in terms of the grammatical constructions and vocabulary to be taught and in line with the learnerxe2x80x99s interests. We developed an online Information Retrieval system that helps teachers search for texts appropriate in form, content, and reading level. It identifies the 87 grammatical constructions spelled out in the official English language curriculum of schools in Baden-Wurttemberg, Germany. The tool incorporates a classical efficient algorithm for reranking the results by assigning weights to selected constructions and prioritizing the documents containing them. Supplemented by an interactive visualization module, it allows for a multifaceted presentation and analysis of the retrieved documents."
L16-1621,Focus Annotation of Task-based Data: A Comparison of Expert and Crowd-Sourced Annotation in a Reading Comprehension Corpus,2016,0,1,3,1,5913,kordula kuthy,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"While the formal pragmatic concepts in information structure, such as the focus of an utterance, are precisely defined in theoretical linguistics and potentially very useful in conceptual and practical terms, it has turned out to be difficult to reliably annotate such notions in corpus data. We present a large-scale focus annotation effort designed to overcome this problem. Our annotation study is based on the tasked-based corpus CREG, which consists of answers to explicitly given reading comprehension questions. We compare focus annotation by trained annotators with a crowd-sourcing setup making use of untrained native speakers. Given the task context and an annotation process incrementally making the question form and answer type explicit, the trained annotators reach substantial agreement for focus annotation. Interestingly, the crowd-sourcing setup also supports high-quality annotation â for specific subtypes of data. Finally, we turn to the question whether the relevance of focus annotation can be extrinsically evaluated. We show that automatic short-answer assessment significantly improves for focus annotated data. The focus annotated CREG corpus is freely available and constitutes the largest such resource for German."
C16-1071,Advancing Linguistic Features and Insights by Label-informed Feature Grouping: An Exploration in the Context of Native Language Identification,2016,0,0,2,1,35714,serhiy bykh,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"We propose a hierarchical clustering approach designed to group linguistic features for supervised machine learning that is inspired by variationist linguistics. The method makes it possible to abstract away from the individual feature occurrences by grouping features together that behave alike with respect to the target class, thus providing a new, more general perspective on the data. On the one hand, it reduces data sparsity, leading to quantitative performance gains. On the other, it supports the formation and evaluation of hypotheses about individual choices of linguistic structures. We explore the method using features based on verb subcategorization information and evaluate the approach in the context of the Native Language Identification (NLI) task."
W14-4922,Focus Annotation in Reading Comprehension Data,2014,22,4,2,1,3018,ramon ziai,Proceedings of {LAW} {VIII} - The 8th Linguistic Annotation Workshop,0,"When characterizing the information structure of sentences, the so-called focus identifies the part of a sentence addressing the current question under discussion in the discourse. While this notion is precisely defined in formal semantics and potentially very useful in theoretical and practical terms, it has turned out to be difficult to reliably annotate focus in corpus data. We present a new focus annotation effort designed to overcome this problem. On the one hand, it is based on a task-based corpus providing more explicit context. The annotation study is based on the CREG corpus (Ott et al., 2012), which consists of answers to explicitly given reading comprehension questions. On the other hand, we operationalize focus annotation as an incremental process including several substeps which provide guidance, such as explicit answer typing. We evaluate the focus annotation both intrinsically by calculating agreement between annotators and extrinsically by showing that the focus information substantially improves the automatic meaning assessment of answers in the CoMiC system (Meurers et al., 2011)."
W14-3508,A {VIEW} of {R}ussian: Visual Input Enhancement and Adaptive Feedback,2014,20,1,3,0,34083,robert reynolds,Proceedings of the third workshop on {NLP} for computer-assisted language learning,0,"We explore the challenges and opportunities which arise in developing automatic visual input enhancement activities for Russian with a focus on target selection and adaptive feedback. Russian, a language with a rich fusional morphology, has many syntactically relevant forms that are not transparent to the language learner, which makes it a good candidate for visual input enhancement (VIE). VIE essentially supports incidental focus on form by increasing the salience of language forms to support noticing by the learner. The freely available VIEW system (Meurers et al., 2010) was designed to automatically generate VIE activities from any web content. We extend VIEW to Russian and discuss connected research issues regarding target selection, ambiguity management, prompt generation, and distractor generation. We show that the same information and techniques used for target selection can often be repurposed for adaptive feedback. Authentic Text ICALL (ATICALL) systems incorporating only native-language NLP, without the NLP analysis specific to learner language that is characteristic of Intelligent Language Tutoring Systems (ILTS), thus can support some forms of adaptive feedback. ATICALL and ILTS represent a spectrum of possibilities rather than two categorically distinct enterprises."
W14-1203,Exploring Measures of {``}Readability{''} for Spoken Language: Analyzing linguistic features of subtitles to identify age-specific {TV} programs,2014,23,5,2,1,830,sowmya vajjala,Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations ({PITR}),0,"We investigate whether measures of readability can be used to identify age-specific TV programs. Based on a corpus of BBC TV subtitles, we employ a range of linguistic readability features motivated by Second Language Acquisition and Psycholinguistics research. Our hypothesis that such readability features can successfully distinguish between spoken language targeting different age groups is fully confirmed. The classifiers we trained on the basis of these readability features achieve a classification accuracy of 95.9%. Investigating several feature subsets, we show that the authentic material targeting specific age groups exhibits a broad range of linguistics and psycholinguistic characteristics that are indicative of the complexity of the language used."
de-smedt-etal-2014-clara,{CLARA}: A New Generation of Researchers in Common Language Resources and Their Applications,2014,68,0,3,0,17515,koenraad smedt,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"CLARA (Common Language Resources and Their Applications) is a Marie Curie Initial Training Network which ran from 2009 until 2014 with the aim of providing researcher training in crucial areas related to language resources and infrastructure. The scope of the project was broad and included infrastructure design, lexical semantic modeling, domain modeling, multimedia and multimodal communication, applications, and parsing technologies and grammar models. An international consortium of 9 partners and 12 associate partners employed researchers in 19 new positions and organized a training program consisting of 10 thematic courses and summer/winter schools. The project has resulted in new theoretical insights as well as new resources and tools. Most importantly, the project has trained a new generation of researchers who can perform advanced research and development in language resources and technologies."
boyd-etal-2014-merlin,The {MERLIN} corpus: Learner language and the {CEFR},2014,32,11,4,1,27600,adriane boyd,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The MERLIN corpus is a written learner corpus for Czech, German,and Italian that has been designed to illustrate the Common European Framework of Reference for Languages (CEFR) with authentic learner data. The corpus contains 2,290 learner texts produced in standardized language certifications covering CEFR levels A1-C1. The MERLIN annotation scheme includes a wide range of language characteristics that enable research into the empirical foundations of the CEFR scales and provide language teachers, test developers, and Second Language Acquisition researchers with concrete examples of learner performance and progress across multiple proficiency levels. For computational linguistics, it provide a range of authentic learner data for three target languages, supporting a broadening of the scope of research in areas such as automatic proficiency classification or native language identification. The annotated corpus and related information will be freely available as a corpus resource and through a freely accessible, didactically-oriented online platform."
E14-1031,Assessing the relative reading level of sentence pairs for text simplification,2014,31,19,2,1,830,sowmya vajjala,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"While the automatic analysis of the readability of texts has a long history, the use of readability assessment for text simplification has received only little attention so far. In this paper, we explore readability models for identifying differences in the reading levels of simplified and unsimplified versions of sentences. Our experiments show that a relative ranking is preferable to an absolute binary one and that the accuracy of identifying relative simplification depends on the initial reading level of the unsimplified version. The approach is particularly successful in classifying the relative reading level of harder sentences. In terms of practical relevance, the approach promises to be useful for identifying particularly relevant targets for simplification and to evaluate simplifications given specific readability constraints."
C14-1185,Exploring Syntactic Features for Native Language Identification: A Variationist Perspective on Feature Encoding and Ensemble Optimization,2014,30,12,2,1,35714,serhiy bykh,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"In this paper, we systematically explore lexicalized and non-lexicalized local syntactic features for the task of Native Language Identification (NLI). We investigate different types of feature representations in single- and cross-corpus settings, including two representations inspired by a variationist perspective on the choices made in the linguistic system. To combine the different models, we use a probabilities-based ensemble classifier and propose a technique to optimize and tune it. Combining the best performing syntactic features with four types of n-grams outperforms the best approach of the NLI Shared Task 2013."
W13-2907,On The Applicability of Readability Models to Web Texts,2013,38,16,2,1,830,sowmya vajjala,Proceedings of the Second Workshop on Predicting and Improving Text Readability for Target Reader Populations,0,"An increasing range of features is being used for automatic readability classification. The impact of the features typically is evaluated using reference corpora containing graded reading material. But how do the readability models and the features they are based on perform on real-world web texts? In this paper, we want to take a step towards understanding this aspect on the basis of a broad range of lexical and syntactic features and several web datasets we collected. Applying our models to web search results, we find that the average reading level of the retrieved web documents is relatively high. At the same time, documents at a wide range of reading levels are identified and even among the Top-10 search results one finds documents at the lower levels, supporting the potential usefulness of readability ranking for the web. Finally, we report on generalization experiments showing that the features we used generalize well across different web sources."
W13-1726,Combining Shallow and Linguistically Motivated Features in Native Language Identification,2013,24,7,4,1,35714,serhiy bykh,Proceedings of the Eighth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"We explore a range of features and ensembles for the task of Native Language Identification as part of the NLI Shared Task (Tetreault et al., 2013). Starting with recurring word-based ngrams (Bykh and Meurers, 2012), we tested different linguistic abstractions such as partof-speech, dependencies, and syntactic trees as features for NLI. We also experimented with features encoding morphological properties, the nature of the realizations of particular lemmas, and several measures of complexity developed for proficiency and readability classification (Vajjala and Meurers, 2012). Employing an ensemble classifier incorporating all of our features we achieved an accuracy of 82.2% (rank 5) in the closed task and 83.5% (rank 1) in the open-2 task. In the open-1 task, the word-based recurring ngrams outperformed the ensemble, yielding 38.5% (rank 2). Overall, across all three tasks, our best accuracy of 83.5% for the standard TOEFL11 test set came in second place."
S13-2102,{C}o{M}e{T}: Integrating different levels of linguistic modeling for meaning assessment,2013,29,13,4,0,41253,niels ott,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"This paper describes the CoMeT system, our contribution to the SemEval 2013 Task 7 challenge, focusing on the task of automatically assessing student answers to factual questions. CoMeT is based on a meta-classifier that uses the outputs of the sub-systems we developed: CoMiC, CoSeC, and three shallower bag approaches. We sketch the functionality of all sub-systems and evaluate their performance against the official test set of the challenge. CoMeT obtained the best result (73.1% accuracy) for the 3-way unseen answers in Beetle among all challenge participants. We also discuss possible improvements and directions for future research."
W12-2019,On Improving the Accuracy of Readability Classification using Insights from Second Language Acquisition,2012,37,78,2,1,830,sowmya vajjala,Proceedings of the Seventh Workshop on Building Educational Applications Using {NLP},0,"We investigate the problem of readability assessment using a range of lexical and syntactic features and study their impact on predicting the grade level of texts. As empirical basis, we combined two web-based text sources, Weekly Reader and BBC Bitesize, targeting different age groups, to cover a broad range of school grades. On the conceptual side, we explore the use of lexical and syntactic measures originally designed to measure language development in the production of second language learners. We show that the developmental measures from Second Language Acquisition (SLA) research when combined with traditional readability features such as word length and sentence length provide a good indication of text readability across different grades. The resulting classifiers significantly outperform the previous approaches on readability classification, reaching a classification accuracy of 93.3%."
W12-2022,Short Answer Assessment: Establishing Links Between Research Strands,2012,27,19,3,1,3018,ramon ziai,Proceedings of the Seventh Workshop on Building Educational Applications Using {NLP},0,"A number of different research subfields are concerned with the automatic assessment of student answers to comprehension questions, from language learning contexts to computer science exams. They share the need to evaluate free-text answers but differ in task setting and grading/evaluation criteria, among others.n n This paper has the intention of fostering synergy between the different research strands. It discusses the different research strands, details the crucial differences, and explores under which circumstances systems can be compared given publicly available data. To that end, we present results with the CoMiC-EN Content Assessment system (Meurers et al., 2011a) on the dataset published by Mohler et al. (2011) and outline what was necessary to perform this comparison. We conclude with a general discussion on comparability and evaluation of short answer assessment systems."
W12-2024,Informing Determiner and Preposition Error Correction with Hierarchical Word Clustering,2012,7,2,3,1,27600,adriane boyd,Proceedings of the Seventh Workshop on Building Educational Applications Using {NLP},0,None
W12-2039,Evaluating the Meaning of Answers to Reading Comprehension Questions: A Semantics-Based Approach,2012,25,23,2,0.952381,10213,michael hahn,Proceedings of the Seventh Workshop on Building Educational Applications Using {NLP},0,"There is a rise in interest in the evaluation of meaning in real-life applications, e.g., for assessing the content of short answers. The approaches typically use a combination of shallow and deep representations, but little use is made of the semantic formalisms created by theoretical linguists to represent meaning.n n In this paper, we explore the use of the underspecified semantic formalism LRS, which combines the capability of precisely representing semantic distinctions with the robustness and modularity needed to represent meaning in real-life applications.n n We show that a content-assessment approach built on LRS outperforms a previous approach on the CREG data set, a freely available corpus of answers to reading comprehension exercises by learners of German. The use of such a formalism also readily supports the integration of notions building on semantic distinctions, such as the information structuring in discourse, which we show to be useful for content assessment."
C12-1027,Native Language Identification using Recurring $n$-grams {--} Investigating Abstraction and Domain Dependence,2012,22,24,2,1,35714,serhiy bykh,Proceedings of {COLING} 2012,0,"Native Language Identification tackles the problem of determining the native language of an author based on a text the author has written in a second language. In this paper, we discuss the systematic use of recurring n-grams of any length as features for training a native language classifier. Starting with surface n-grams, we investigate two degrees of abstraction incorporating parts-of-speech. The approach outperforms previous work employing a comparable data setup, reaching 89.71% accuracy for a task with seven native languages using data from the International Corpus of Learner English (ICLE). We then investigate the claim by Brooke and Hirst (2011) that a content bias in ICLE seems to result in an easy classification by topic instead of by native language characteristics. We show that training our model on ICLE and testing it on three other, independently compiled learner corpora dealing with other topics still results in high accuracy classification."
C12-1065,"Readability Classification for {G}erman using Lexical, Syntactic, and Morphological Features",2012,36,41,3,0,43754,julia hancke,Proceedings of {COLING} 2012,0,"We investigate the problem of reading level assessment for German texts on a newly compiled corpus of freely available easy and difficult articles, targeted at adult and child readers respectively. We adapt a wide range of syntactic, lexical and language model features from previous research on English and combined them with new features that make use of the rich morphology of German. We show that readability classification for German based on these features is highly successful, reaching 89.7% accuracy, with the new morphological features making an important contribution."
W11-2844,Data-Driven Correction of {F}unction{W}ords in Non-Native {E}nglish,2011,5,2,2,1,27600,adriane boyd,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,None
W11-2401,Evaluating Answers to Reading Comprehension Questions in Context: Results for {G}erman and the Role of Information Structure,2011,22,32,1,1,3013,detmar meurers,Proceedings of the {T}ext{I}nfer 2011 Workshop on Textual Entailment,0,"Reading comprehension activities are an authentic task including a rich, language-based context, which makes them an interesting real-life challenge for research into automatic content analysis. For textual entailment research, content assessment of reading comprehension exercises provides an interesting opportunity for extrinsic, real-purpose evaluation, which also supports the integration of context and task information into the analysis.n n In this paper, we discuss the first results for content assessment of reading comprehension activities for German and present results which are competitive with the current state of the art for English. Diving deeper into the results, we provide an analysis in terms of the different question types and the ways in which the information asked for is encoded in the text.n n We then turn to analyzing the role of the question and argue that the surface-based account of information that is given in the question should be replaced with a more sophisticated, linguistically informed analysis of the information structuring of the answer in the context of the question that it is a response to."
W11-1714,Automatic Sentiment Classification of Product Reviews Using Maximal Phrases Based Analysis,2011,10,3,3,0,44308,maria tchalakova,Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis ({WASSA} 2.011),0,"In this paper we explore the use of phrases occurring maximally in text as features for sentiment classification of product reviews. The goal is to find in a statistical way representative words and phrases used typically in positive and negative reviews. The approach does not rely on predefined sentiment lexicons, and the motivation for this is that potentially every word could be considered as expressing something positive and/or negative in different situations, and that the context and the personal attitude of the opinion holder should be taken into account when determining the polarity of the phrase, instead of doing this out of particular context."
W10-1002,Enhancing Authentic Web Pages for Language Learners,2010,34,42,1,1,3013,detmar meurers,Proceedings of the {NAACL} {HLT} 2010 Fifth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"Second language acquisition research since the 90s has emphasized the importance of supporting awareness of language categories and forms, and input enhancement techniques have been proposed to make target language features more salient for the learner.n n We present an NLP architecture and web-based implementation providing automatic visual input enhancement for web pages. Learners freely choose the web pages they want to read and the system displays an enhanced version of the pages. The current system supports visual input enhancement for several language patterns known to be problematic for English language learners, as well as fill-in-the-blank and clickable versions of such pages supporting some learner interaction."
W10-0212,Emotional Perception of Fairy Tales: Achieving Agreement in Emotion Annotation of Text,2010,23,14,3,0,45573,ekaterina volkova,Proceedings of the {NAACL} {HLT} 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text,0,"Emotion analysis (EA) is a rapidly developing area in computational linguistics. An EA system can be extremely useful in fields such as information retrieval and emotion-driven computer animation. For most EA systems, the number of emotion classes is very limited and the text units the classes are assigned to are discrete and predefined. The question we address in this paper is whether the set of emotion categories can be enriched and whether the units to which the categories are assigned can be more flexibly defined. We present an experiment showing how an annotation task can be set up so that untrained participants can perform emotion analysis with high agreement even when not restricted to a predetermined annotation unit and using a rich set of emotion categories. As such it sets the stage for the development of more complex EA systems which are closer to the actual human emotional perception of text."
C10-2031,Exploring the Data-Driven Prediction of Prepositions in {E}nglish,2010,13,17,2,0,46193,anas elghafari,Coling 2010: Posters,0,"Prepositions in English are a well-known challenge for language learners, and the computational analysis of preposition usage has attracted significant attention. Such research generally starts out by developing models of preposition usage for native English based on a range of features, from shallow surface evidence to deep linguistically-informed properties.n n While we agree that ultimately a combination of shallow and deep features is needed to balance the preciseness of exemplars with the usefulness of generalizations to avoid data sparsity, in this paper we explore the limits of a purely surface-based prediction of prepositions.n n Using a web-as-corpus approach, we investigate the classification based solely on the relative number of occurrences for target n-grams varying in preposition usage. We show that such a surface-based approach is competitive with the published state-of-the-art results relying on complex feature sets.n n Where enough data is available, in a surprising number of cases it thus is possible to obtain sufficient information from the relatively narrow window of context provided by n-grams which are small enough to frequently occur but large enough to contain enough predictive information about preposition usage."
W08-1004,Revisiting the Impact of Different Annotation Schemes on {PCFG} Parsing: A Grammatical Dependency Evaluation,2008,14,10,2,0.951017,27600,adriane boyd,Proceedings of the Workshop on Parsing {G}erman,0,"Recent parsing research has started addressing the questions a) how parsers trained on different syntactic resources differ in their performance and b) how to conduct a meaningful evaluation of the parsing results across such a range of syntactic representations. Two German treebanks, Negra and TuBa-D/Z, constitute an interesting testing ground for such research given that the two treebanks make very different representational choices for this language, which also is of general interest given that German is situated between the extremes of fixed and free word order. We show that previous work comparing PCFG parsing with these two treebanks employed PARSEVAL and grammatical function comparisons which were skewed by differences between the two corpus annotation schemes. Focusing on the grammatical dependency triples as an essential dimension of comparison, we show that the two very distinct corpora result in comparable parsing performance."
W08-0913,Diagnosing Meaning Errors in Short Answers to Reading Comprehension Questions,2008,24,48,2,0,46663,stacey bailey,Proceedings of the Third Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"A common focus of systems in Intelligent Computer-Assisted Language Learning (ICALL) is to provide immediate feedback to language learners working on exercises. Most of this research has focused on providing feedback on the form of the learner input. Foreign language practice and second language acquisition research, on the other hand, emphasizes the importance of exercises that require the learner to manipulate meaning.n n The ability of an ICALL system to diagnose and provide feedback on the meaning conveyed by a learner response depends on how well it can deal with the response variation allowed by an activity. We focus on short-answer reading comprehension questions which have a clearly defined target response but the learner may convey the meaning of the target in multiple ways. As empirical basis of our work, we collected an English as a Second Language (ESL) learner corpus of short-answer reading comprehension questions, for which two graders provided target answers and correctness judgments. On this basis, we developed a Content-Assessment Module (CAM), which performs shallow semantic analysis to diagnose meaning errors. It reaches an accuracy of 88% for semantic error detection and 87% on semantic error diagnosis on a held-out test data set."
W05-0103,{``}Language and {C}omputers{''}: Creating an Introduction for a General Undergraduate Audience,2005,3,1,3,0,22390,chris brew,Proceedings of the Second {ACL} Workshop on Effective Tools and Methodologies for Teaching {NLP} and {CL},0,"This paper describes the creation of Language and Computers, a new course at the Ohio State University designed to be a broad overview of topics in computational linguistics, focusing on applications which have the most immediate relevance to students. This course satisfies the mathematical and logical analysis requirement at Ohio State by using natural language systems to motivate students to exercise and develop a range of basic skills in formal and computational analysis. In this paper we discuss the design of the course, focusing on the success we have had in offering it, as well as some of the difficulties we have faced."
P05-1040,Detecting Errors in Discontinuous Structural Annotation,2005,15,26,2,1,28642,markus dickinson,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"Consistency of corpus annotation is an essential property for the many uses of annotated corpora in computational and theoretical linguistics. While some research addresses the detection of inconsistencies in positional annotation (e.g., part-of-speech) and continuous structural annotation (e.g., syntactic constituency), no approach has yet been developed for automatically detecting annotation errors in discontinuous structural annotation. This is significant since the annotation of potentially discontinuous stretches of material is increasingly relevant, from tree-banks for free-word order languages to semantic and discourse annotation.In this paper we discuss how the variation n-gram error detection approach (Dickinson and Meurers, 2003a) can be extended to discontinuous structural annotation. We exemplify the approach by showing how it successfully detects errors in the syntactic annotation of the German TIGER corpus (Brants et al., 2002)."
C04-1025,A Grammar Formalism and Parser for Linearization-based {HPSG},2004,13,10,2,0,50785,michael daniels,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"Linearization-based HPSG theories are widely used for analyzing languages with relatively free constituent order. This paper introduces the Generalized ID/LP (GIDLP) grammar format, which supports a direct encoding of such theories, and discusses key aspects of a parser that makes use of the dominance, precedence, and linearization domain information explicitly encoded in this grammar format. We show that GIDLP grammars avoid the explosion in the number of rules required under a traditional phrase structure analysis of free constituent order. As a result, GIDLP grammars support more modular and compact grammar encodings and require fewer edges in parsing."
E03-1068,Detecting Errors in Part-of-Speech Annotation,2003,17,85,2,1,28642,markus dickinson,10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We propose a new method for detecting errors in gold-standard part-of-speech annotation. The approach locates errors with high precision based on n-grams occurring in the corpus with multiple taggings. Two further techniques, closed-class analysis and finite-state tagging guide patterns, are discussed. The success of the three approaches is illustrated for the Wall Street Journal corpus as part of the Penn Tree-bank."
W02-0103,A Web-based Instructional Platform for Contraint-Based Grammar Formalisms and Parsing,2002,4,45,1,1,3013,detmar meurers,Proceedings of the {ACL}-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics,0,"We propose the creation of a web-based training framework comprising a set of topics that revolve around the use of feature structures as the core data structure in linguistic theory, its formal foundations, and its use in syntactic processing."
P97-1001,Interleaving Universal Principles and Relational Constraints over Typed Feature Logic,1997,10,8,2,0,38281,thilo gotz,35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,1,"We introduce a typed feature logic system providing both universal implicational principles as well as definite clauses over feature terms. We show that such an architecture supports a modular encoding of linguistic theories and allows for a compact representation using underspecification. The system is fully implemented and has been used as a workbench to develop and test large HPSG grammars. The techniques described in this paper are not restricted to a specific implementation, but could be added to many current feature-based grammar development systems."
J97-4003,A Computational Treatment of Lexical Rules in {HPSG} as Covariation in Lexical Entries,1997,36,26,1,1,3013,detmar meurers,Computational Linguistics,0,"This paper proposes a new computational treatment of lexical rules as used in the HPSG framework. A complier is described which translates a set of lexical rules and their interaction into a definite clause encoding, which is called by the base lexical entries in the lexicon. This way, the disjunctive possibilities arising from lexical rule application are encoded as systematic covariation in the specification of lexical entries. The compiler ensures the automatic transfer of properties not changed by a lexical rule. Program transformation techniques are used to advance the encoding. The final output of the compiler constitutes an efficient computational counterpart of the linguistic generalizations captured by lexical rules and allows on-the-fly application of lexical rules."
