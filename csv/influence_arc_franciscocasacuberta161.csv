2001.mtsummit-papers.22,J93-2003,0,0.0227649,"Missing"
2001.mtsummit-papers.22,P98-2158,0,0.576952,"Missing"
2001.mtsummit-papers.22,C00-2163,0,0.0668485,"he models proposed in (Brown et al., 1993). For example, to deal with IBM-Model 3, we only need to compute the Viterbi alignment score for this model in step 1 of the previous algorithm instead of the IBM-Model 2 Viterbi alignment score. We could proceed in the same why for the IBM-Model 4 and IBM-Model 51 . As is stated in (Brown et al., 1993) and in (Al-Onaizan et al., 1999) it is not possible to compute as exactly the best Viterbi alignment for IBM-Model 3 to IBM-Model 5, as in models IBM-Model 1 and IBM-Model 2. In the training process, the Viterbi alignment for IBM-Model 3 to IBMModel 5 (Och and Ney, 2000a) is computed by first computing the Viterbi alignment according to IBM-Model 2 and afterwards making slight changes in the alignment (called moves and swaps) in order to get a neighborhood of possible alignments. Once this neighborhood has been obtained, the Viterbi alignment is computed using the HillClimbing algorithm introduced in (Al-Onaizan et al., 1999). This algorithm is also used in the translation process when the Viterbi alignment for IBM-Model 3 to IBM-Model 5 is computed. This is why the search procedure (or construction of the search trellis) is still based on the parameters of"
2001.mtsummit-papers.22,P00-1056,0,0.167918,"he models proposed in (Brown et al., 1993). For example, to deal with IBM-Model 3, we only need to compute the Viterbi alignment score for this model in step 1 of the previous algorithm instead of the IBM-Model 2 Viterbi alignment score. We could proceed in the same why for the IBM-Model 4 and IBM-Model 51 . As is stated in (Brown et al., 1993) and in (Al-Onaizan et al., 1999) it is not possible to compute as exactly the best Viterbi alignment for IBM-Model 3 to IBM-Model 5, as in models IBM-Model 1 and IBM-Model 2. In the training process, the Viterbi alignment for IBM-Model 3 to IBMModel 5 (Och and Ney, 2000a) is computed by first computing the Viterbi alignment according to IBM-Model 2 and afterwards making slight changes in the alignment (called moves and swaps) in order to get a neighborhood of possible alignments. Once this neighborhood has been obtained, the Viterbi alignment is computed using the HillClimbing algorithm introduced in (Al-Onaizan et al., 1999). This algorithm is also used in the translation process when the Viterbi alignment for IBM-Model 3 to IBM-Model 5 is computed. This is why the search procedure (or construction of the search trellis) is still based on the parameters of"
2001.mtsummit-papers.22,P97-1037,0,0.45016,"urce word position. One of the open problems with SMT is the design of efficient algorithms for searching the translation of a given input string, that is to solve the global search maximization problem. Interesting translation models were proposed in (Brown et al., 1993). However, the corresponding search algorithms for the IBM-Model 1 to IBM-Model 5 in (Brown et al., 1993) are based on a certain type of the () algorithm (Brown et al., 1990) or on the stack decoding approach (Al-Onaizan et al., 1999; Wang and Waibel, 1997). There are also dynamic-programming-based search algorithms such as (Tillmann et al., 1997a; Tillmann et al., 1997b) for the first-order models proposed in (Vogel et al., 1996) and the algorithm proposed in (Tillmann, 2001) for the IBM-Model 4 which is inspired on the Traveler Salesman problem. A dynamic-programming search algorithm for the IBM-Model 2 is also proposed in (Garc´ıa-Varea et al., 1998). In this paper we present how to deal with the most complex IBM models (IBM-Model 3 to IBM-Model 5) using the algorithm proposed in (Garc´ıa-Varea et al., 1998) and an alignment-based pruning technique in order to reduce the high computational cost. For better understanding, in the fol"
2001.mtsummit-papers.22,C96-2141,0,0.0559775,"hms for searching the translation of a given input string, that is to solve the global search maximization problem. Interesting translation models were proposed in (Brown et al., 1993). However, the corresponding search algorithms for the IBM-Model 1 to IBM-Model 5 in (Brown et al., 1993) are based on a certain type of the () algorithm (Brown et al., 1990) or on the stack decoding approach (Al-Onaizan et al., 1999; Wang and Waibel, 1997). There are also dynamic-programming-based search algorithms such as (Tillmann et al., 1997a; Tillmann et al., 1997b) for the first-order models proposed in (Vogel et al., 1996) and the algorithm proposed in (Tillmann, 2001) for the IBM-Model 4 which is inspired on the Traveler Salesman problem. A dynamic-programming search algorithm for the IBM-Model 2 is also proposed in (Garc´ıa-Varea et al., 1998). In this paper we present how to deal with the most complex IBM models (IBM-Model 3 to IBM-Model 5) using the algorithm proposed in (Garc´ıa-Varea et al., 1998) and an alignment-based pruning technique in order to reduce the high computational cost. For better understanding, in the following section we review the search algorithm proposed in (Garc´ıa-Varea et al., 1998)"
2001.mtsummit-papers.22,J90-2002,0,0.264959,"by (Brown et al., 1993): The correspondence between the words in the source and the target string is described by alignments that assign one target word position to each source word position. One of the open problems with SMT is the design of efficient algorithms for searching the translation of a given input string, that is to solve the global search maximization problem. Interesting translation models were proposed in (Brown et al., 1993). However, the corresponding search algorithms for the IBM-Model 1 to IBM-Model 5 in (Brown et al., 1993) are based on a certain type of the () algorithm (Brown et al., 1990) or on the stack decoding approach (Al-Onaizan et al., 1999; Wang and Waibel, 1997). There are also dynamic-programming-based search algorithms such as (Tillmann et al., 1997a; Tillmann et al., 1997b) for the first-order models proposed in (Vogel et al., 1996) and the algorithm proposed in (Tillmann, 2001) for the IBM-Model 4 which is inspired on the Traveler Salesman problem. A dynamic-programming search algorithm for the IBM-Model 2 is also proposed in (Garc´ıa-Varea et al., 1998). In this paper we present how to deal with the most complex IBM models (IBM-Model 3 to IBM-Model 5) using the al"
2001.mtsummit-papers.22,C98-2153,0,\N,Missing
2001.mtsummit-papers.22,J03-1005,0,\N,Missing
2001.mtsummit-papers.55,J96-1003,0,\N,Missing
2001.mtsummit-papers.55,J93-2003,0,\N,Missing
2001.mtsummit-papers.55,J90-2002,0,\N,Missing
2001.mtsummit-papers.55,P97-1008,0,\N,Missing
2001.mtsummit-papers.55,J95-2004,0,\N,Missing
2001.mtsummit-papers.64,J93-2003,0,0.101961,"nization of the paper is as follows. First we review the statistical approach to machine translation. Second, we introduce our new translation model. Then, we show the training procedure and propose a search strategy based on stack decoding. Finally, we report some experimental results and compare our models with other conventional models. The system was tested translating a newspaper from to Catalan into Spanish. Stochastic Translation. The goal of statistical translation is to translate a given source language sentence f = f1 ..f|f|, to a target sentence e = e1 ..e|e|. The methodology used (Brown et al, 1993), is based on the definition of a function Pr(e|f) that returns the probability of translating the input sentence f into the output sentence e. Once this function is estimated, the problem can be formulated to compute a sentence e that maximizes the probability Pr(e|f) for a given f. Using Bayes’ theorem, we can write: Pr(e |f ) = Pr(e)Pr(f |e) Pr(f ) (1) And therefore, statistical translation can be presented as: e&apos; = arg m ax Pr(e) Pr(f |e) (2) e Equation (2) summarizes the three following matters to be solved: Se requerirá É necessária Sarà necessaria Une action Action una acción uma acção"
2001.mtsummit-papers.64,P97-1022,0,0.0463262,"Missing"
2001.mtsummit-papers.64,P98-2158,0,0.0188813,"the beginning, all thresholds are set to infinite. When a new complete hypothesis has been generated, if its score is greater than the best one so far, then, the thresholds are recalculated. The new threshold of a stack i is obtained dividing the score of the new best translation by the value S|f|-i. The value Sj estimates the maximum probability contribution of a suffix of j words in any source sentence. These parameters can be precalculated with a parallel training set. The sequential nature of a translation model make the use of a dynamic programming search algorithm (Tillmann et al, 1997; Garcia-Varea et al, 1998). We are interested in exploring this possibility in future work. Evaluation MonWG t( del |del ) = 0.79 t( de l’ |del ) = 0.18 In order to evaluate our model, we carried out some experiments. We used the corpus “El Periódico” obtained from the electronic edition of a general newspaper published daily in Catalan and Spanish. Table 2: Translation probabilities for “del” word. The training corpus was made up of 10 months of the newspaper. We detected some kinds of words with special properties. If we considered a word was a number, an abbreviation, an acronym or a proper name, we substituted this"
2001.mtsummit-papers.64,W99-0604,0,0.0512618,"s). Conclusion: Despite the small number of not completely correct translated sentence in French, translating the languages tested using monotone translation is feasible. We are interested in taking advantage of this property in our translation model. The two main contributions are: the translation probabilities are calculated between groups of words and the alignment is monotone constrained. Other works use similar approaches. In (Vogel et al., 1996) the concept of monotone alignment is used to improve the search. Alignment models based on word groups are introduced in (Epstein et al., 1996; Och et al., 1999; Wang & Waibel, 1997). But, unlike our approach, the lexical model is based on word-to-word correspondence. The organization of the paper is as follows. First we review the statistical approach to machine translation. Second, we introduce our new translation model. Then, we show the training procedure and propose a search strategy based on stack decoding. Finally, we report some experimental results and compare our models with other conventional models. The system was tested translating a newspaper from to Catalan into Spanish. Stochastic Translation. The goal of statistical translation is to"
2001.mtsummit-papers.64,P98-2162,0,0.011669,"1 |eˆ| |eˆ| ∑ ˆ∑ ∏t(fˆi |eˆi )∑δ ( fˆ, fˆi )/(eˆ, eˆ i ) ˆ ê:ê=e f : f =f ; i=1 |ê|=|fˆ| i =1 (10) The parameters that we are interested in estimating t( fˆ |eˆ )) appear on both sides of equation 10. Thus, we need to use the EM algorithm in an iterative procedure (Brown et al, 1993). We chose as initials values for t( fˆ |eˆ ), 1/ |Fˆ |. We can calculate equation 10, using an efficient algorithm based on dynamic programming. Identifying Word Groups. In recent years, some works have been presented to identify word groups in bilingual corpora (Maynard & Ananiadou, 1999; Ahrenberg et al., 1997; Och & Weber, 1998). Our approach to this problem is simple but efficient. We have taken advantage of the fact that almost all of sentence pairs of our corpus had been sequentially translated. We take a sentence pair from the training set, and we attempt to find the best sequential alignment (e and f), that minimizes equation 4. At this point, we do not have the parameters of our model. Thus, we need to redefine equation 5. Model 1 presented in (Brown et al, 1993) is used for this purpose: |ê| Pr( fˆ |ê) = ∏ i 1 PrIBM-1(f |e) = = PrIBM-1( fˆ i |êi) |f | |e| = = ∑ t (f j |ei ) ∏ j 1 i 1 (12) (13) Where, t(fj|ei)"
2001.mtsummit-papers.64,P97-1037,0,0.0644152,"Missing"
2001.mtsummit-papers.64,P97-1047,0,0.0848494,"spite the small number of not completely correct translated sentence in French, translating the languages tested using monotone translation is feasible. We are interested in taking advantage of this property in our translation model. The two main contributions are: the translation probabilities are calculated between groups of words and the alignment is monotone constrained. Other works use similar approaches. In (Vogel et al., 1996) the concept of monotone alignment is used to improve the search. Alignment models based on word groups are introduced in (Epstein et al., 1996; Och et al., 1999; Wang & Waibel, 1997). But, unlike our approach, the lexical model is based on word-to-word correspondence. The organization of the paper is as follows. First we review the statistical approach to machine translation. Second, we introduce our new translation model. Then, we show the training procedure and propose a search strategy based on stack decoding. Finally, we report some experimental results and compare our models with other conventional models. The system was tested translating a newspaper from to Catalan into Spanish. Stochastic Translation. The goal of statistical translation is to translate a given sou"
2001.mtsummit-papers.64,C96-2141,0,\N,Missing
2001.mtsummit-papers.64,P98-1004,0,\N,Missing
2001.mtsummit-papers.64,C98-1004,0,\N,Missing
2001.mtsummit-papers.64,P98-2221,0,\N,Missing
2001.mtsummit-papers.64,C98-2216,0,\N,Missing
2003.eamt-1.6,J90-2002,0,0.879303,"T Programme (IST2001-32091). 1 Introduction The aim of the TransType2 project (TT2) (SchlumbergerSema S.A. et al., 2001) is to develop a Computer Assisted Translation (CAT) system that will help to solve a very pressing social problem: how to meet the growing demand for high-quality translation. The innovative solution proposed by TT2 is to embed a data driven Machine Translation (MT) engine within an interactive translation environment. In this way, the system combines the best of two paradigms: the CAT paradigm, in which the human translator ensures high-quality output, and the MT paradigm (Brown et al., 1990), in which the machine ensures significant productivity gains. Until now, translation technology has not been able to keep pace with the demands for highquality translation. TT2 has the ability to significantly increase translator productivity and thus has enormous commercial potential. Six different versions of the system will be developed for translation between English and French, Spanish or German. To ensure that TT2 meets the needs of translators, two professional translation agencies are in charge of evaluation of the successive prototypes. Stochastic finite-state transducers (SFST) have"
2003.eamt-1.6,J93-2003,0,0.0189828,"nto a transducer. The symbols associated to the grammar rules are transformed into input/output symbols by applying an adequate transformation, thereby transforming the grammar inferred in the previous step into a transducer. The transformation of a parallel corpus into a string corpus is performed using statistical alignments (a function from the set of positions in the target sentence to the set of positions in the source sentence). These alignments are obtained using the GIZA software (Och and Ney, 2000; Al-Onaizan et al., 1999), which implements IBM statistical models (Brown et al., 1990; Brown et al., 1993). queue+cola+activada an+una 0 1 the+la 2 enabled 3 enabled application+aplicación+activada queue+cola queue+cola 4 is+es 5 is+es 7 disabled+desactivada 8 6 Figure 1: A non-smoothed bigram inferred from the training sentences of the example A training string is built by assigning the corresponding aligned word from the source sentence to each word from the target sentence (Casacuberta, 2000). This assignment must not violate the order in the target sentence. Using this type of transformation from a pair of strings into a string of extended symbols, the transformation from a grammar to a finite"
2003.eamt-1.6,P00-1056,0,0.0213883,"d from the sample of strings obtained in the previous step. 3. Transforming the inferred regular grammar into a transducer. The symbols associated to the grammar rules are transformed into input/output symbols by applying an adequate transformation, thereby transforming the grammar inferred in the previous step into a transducer. The transformation of a parallel corpus into a string corpus is performed using statistical alignments (a function from the set of positions in the target sentence to the set of positions in the source sentence). These alignments are obtained using the GIZA software (Och and Ney, 2000; Al-Onaizan et al., 1999), which implements IBM statistical models (Brown et al., 1990; Brown et al., 1993). queue+cola+activada an+una 0 1 the+la 2 enabled 3 enabled application+aplicación+activada queue+cola queue+cola 4 is+es 5 is+es 7 disabled+desactivada 8 6 Figure 1: A non-smoothed bigram inferred from the training sentences of the example A training string is built by assigning the corresponding aligned word from the source sentence to each word from the target sentence (Casacuberta, 2000). This assignment must not violate the order in the target sentence. Using this type of transforma"
2003.mtsummit-papers.40,J93-2003,0,0.0185558,"ng to Bayes’ decision rule, we stored in a stack and ordered by their score. In our have to choose the target string that maximizes the case, this measure is a probability value given by product of the target language model P r(eI1 ) and the both the translation and the language models. The string translation model P r(f1J |eI1 ). decoder follows a sequence of steps for achieving Many existing systems for statistical machine transan optimal hypothesis: lation make use of a special way of structuring the 1. Initialize the stack with an empty hypothesis. string translation model as proposed by (Brown et al., 1993): The correspondence between the words in 2. Iterate the source and the target string is described by align(a) Pop h (the best hypothesis) off the stack. ments that assign one target word position to each (b) If h is a complete sentence, output h and source word position. The lexicon probability p(f |e) terminate. of a certain target word e occurring in the target string is assumed to depend basically only on the (c) Expand h. source. (d) Go to step 2a. These alignment models are similar to the conThe search is started from a null string and obcept of Hidden Markov models (HMM) in speech tains"
2003.mtsummit-papers.40,P01-1030,0,0.0138324,"P r(f1J , aJ1 |eI1 ), the alignment aJ1 volves de£ning a set of operators to be applied over every hypothesis as well as the way in which they is introduced as a hidden variable. Typically, the search is performed using the so- are combined in the expansion process. Both the operators and the expansion algorithm depend on the called maximum approximation: translation model that we use. In our case, we used   X I I J J I IBM Model 3 and IBM Model 4. eˆ1 = arg max P r(e1 ) · P r(f1 , a1 |e1 ) eI1 The operators used in the implementation are aJ 1   those de£ned in (Berger et al., 1996) and (Germann et al., 2001) for the IBM Model 3 and IBM Model ≈ arg max P r(eI1 ) · max P r(f1J , aJ1 |eI1 ) aJ eI1 1 4. The expansion we used in each iteration is strongly The search space consists of the set of all possiI inspired on the expansion given in (Berger et al., ble target language strings e1 and all possible alignJ 1996) for the IBM Model 3, and was presented in (Orments a1 . tiz et al., 2003). This algorithm had been previously In this work, we used IBM Model 1 and IBM adapted for the IBM Model 4, and additionaly has Model 4 (Brown et al., 1993) as translation models. With respect to the language models, w"
2005.mtsummit-papers.19,J93-2003,0,0.110371,"l P r(f1J |eI1 ) must be chosen. The equation that models this process is: eˆI1 = arg max{P r(eI1 ) · P r(f1J |eI1 )} (1) eI1 Diﬀerent translation models (TMs) have been proposed depending on how the relation between the source and the target languages is structured; that is, the way a target sentence is generated from a source sentence. This relation is summarized using the concept of alignment; that is, how the words of a pair of sentences are aligned to each other. Diﬀerent statistical alignment models (SAMs) have been proposed. The well-known IBM and HMM alignment models were proposed in (Brown et al., 1993) and in (Ney et al., 2000) respectively. All these models fall into the category of singleword-based (SWB) SAM. Recent research in the ﬁeld has demonstrated that phrase-based or context-based translation models outperform the ﬁrst propose word-based statistical translation models (Brown et al., 1993). Since then, some useful tools have been made to help researchers in the ﬁeld improve their own machine translation systems. These tools range from software for training single word-based translation models (as the Giza++ software (Och, 2000)) and some speciﬁc word-based decoders, to a recently av"
2005.mtsummit-papers.19,J04-2004,1,0.922921,"used. The most immediate application of the phrase-based models is in the ﬁeld of machine translation. For this purpose an appropriate search engine is required, such us Pharaoh. A second application is to obtain a bisegmentation for a given corpus. The usefulness of this application is two fold: • With this bisegmentation, can be evaluated the quality of the phrase model when it is compared with a test corpus that is manually aligned by experts. • The bisegmentation of a given test corpus can be used as a preprocessing step to other machine translation systems, such as the one presented in (Casacuberta and Vidal, 2004), which is based on ﬁnite-state technology. In addition other NLP applications can take advantage of phrase-based translation models. Some of them are: document classiﬁcation, information retrieval, word-sense disambiguation, question-answering systems, etc. 4 Experiments and results In this section, we present some experimental results using the most important features of the Thot toolkit. The corpora we have used in the experiments are outlined in Table 2 for the two well-known EuTrans-I and Hansards tasks, respectively. 145 4.1 Bilingual segmentation experiments For the bilingual segmentati"
2005.mtsummit-papers.19,P01-1030,0,0.0236593,"EuTrans-I task. 4.2.3 Translation quality experiments Finally, we carried out a translation quality experiment adjusting both the Thot toolkit parameters and the Pharaoh parameters appropiately. Speciﬁcally, a RF model was estimated from symmetrized word alignment matrices. The maximum phrase length parameter was set to 6. Table 8 shows the WER and PER error measures for the EuTrans-I corpus. We compared the Pharaoh translation quality with the quality obtained by two other translation tools: the ISI ReWrite Decoder, a publicly available translation tool that implements a greedy decoder (see (Germann et al., 2001)), and GIATI, a stochastic ﬁnite state transductor (see (Casacuberta and Vidal, 2004)). The results obtained by Pharaoh and GIATI were very similar and clearly outperformed the results of the greedy decoder. Decoder Greedy Pharaoh GIATI WER 25.2 6.7 6.6 PER 22.3 5.3 - Bleu 0.55 0.90 0.91 Table 8: Translation quality results for the EuTrans-I task. A similar experimentation is shown in Table 9 for the Hansards task. In this case, the results obtained by the greedy decoder are closer to the results obtained by Pharaoh. (In Table 9 147 results with the GIATI technique are not available since they"
2005.mtsummit-papers.19,N03-1017,0,0.437211,"per we presented a publicly available toolkit to train phrase-based SMT models. Diﬀerent models that deal with structures or phrases instead of single words have also been proposed: the 1 Note that the expression should also be maximized by I; however, for the sake of simplicity we suppose that it is known. syntax translation models are described in (Yamada and Knight, 2001) , alignment templates are used in (Och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (PBT) in (Tom´ as and Casacuberta, 2001; Marcu and Wong, 2002; Zens et al., 2002; Koehn et al., 2003). In (Venugopal et al., 2003), two methods of phrase extractions are proposed (based on source n-grams and HMM alignments respectively). They improve a translation lexicon, instead of deﬁning a phrase-based model, which is also used within a word-based decoder. In the same line, a method to produce phrase-based alignments from wordbased alignments is proposed in (Lambert and Castell., 2004). Casacuberta, 2001) the following model is proposed: 2 In both cases the model parameters that have to be estimated are the translation probabilities between phrase pairs (θ = {p(f˜|˜ e)}). Phrase Based Tra"
2005.mtsummit-papers.19,W02-1018,0,0.202816,"rder to continue the research. In this paper we presented a publicly available toolkit to train phrase-based SMT models. Diﬀerent models that deal with structures or phrases instead of single words have also been proposed: the 1 Note that the expression should also be maximized by I; however, for the sake of simplicity we suppose that it is known. syntax translation models are described in (Yamada and Knight, 2001) , alignment templates are used in (Och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (PBT) in (Tom´ as and Casacuberta, 2001; Marcu and Wong, 2002; Zens et al., 2002; Koehn et al., 2003). In (Venugopal et al., 2003), two methods of phrase extractions are proposed (based on source n-grams and HMM alignments respectively). They improve a translation lexicon, instead of deﬁning a phrase-based model, which is also used within a word-based decoder. In the same line, a method to produce phrase-based alignments from wordbased alignments is proposed in (Lambert and Castell., 2004). Casacuberta, 2001) the following model is proposed: 2 In both cases the model parameters that have to be estimated are the translation probabilities between phrase p"
2005.mtsummit-papers.19,nevado-etal-2004-translation,1,0.827003,"nformation retrieval, word-sense disambiguation, question-answering systems, etc. 4 Experiments and results In this section, we present some experimental results using the most important features of the Thot toolkit. The corpora we have used in the experiments are outlined in Table 2 for the two well-known EuTrans-I and Hansards tasks, respectively. 145 4.1 Bilingual segmentation experiments For the bilingual segmentation experiments, we selected a subset of the EuTrans-I test corpus consisting of 40 randomly selected pairs of sentences. This corpus was bilingually segmented by human experts (Nevado et al., 2004). Table 3 shows the well-known Recall, Precision, and F-measure bisegmentation-quality measures for three diﬀerent bisegmentation techniques including the one provided by the Thot toolkit. The other two techniques are the recursive alignments (RECalign) and the GIATI alignments (GIATIalign) that are described and tested in (Nevado et al., 2004). As table 3 shows, the bisegmentation quality for the Thot toolkit outperforms the other two. Technique RECalign GIATIalign Thot Recall 52.96 39.99 72.58 Precision 79.01 85.52 65.49 F-measure 63.41 54.50 68.85 Table 3: Bisegmentation results for 40 rand"
2005.mtsummit-papers.19,2001.mtsummit-papers.64,1,0.833869,"Missing"
2005.mtsummit-papers.19,P03-1041,0,0.0184444,"ly available toolkit to train phrase-based SMT models. Diﬀerent models that deal with structures or phrases instead of single words have also been proposed: the 1 Note that the expression should also be maximized by I; however, for the sake of simplicity we suppose that it is known. syntax translation models are described in (Yamada and Knight, 2001) , alignment templates are used in (Och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (PBT) in (Tom´ as and Casacuberta, 2001; Marcu and Wong, 2002; Zens et al., 2002; Koehn et al., 2003). In (Venugopal et al., 2003), two methods of phrase extractions are proposed (based on source n-grams and HMM alignments respectively). They improve a translation lexicon, instead of deﬁning a phrase-based model, which is also used within a word-based decoder. In the same line, a method to produce phrase-based alignments from wordbased alignments is proposed in (Lambert and Castell., 2004). Casacuberta, 2001) the following model is proposed: 2 In both cases the model parameters that have to be estimated are the translation probabilities between phrase pairs (θ = {p(f˜|˜ e)}). Phrase Based Translation One important disadv"
2005.mtsummit-papers.19,P01-1067,0,0.380146,"Giza++ software (Och, 2000)) and some speciﬁc word-based decoders, to a recently available phrase-based decoder, like Pharaoh (Koehn, 2003). For SMT software, a tool to train phrase-based is essential in order to continue the research. In this paper we presented a publicly available toolkit to train phrase-based SMT models. Diﬀerent models that deal with structures or phrases instead of single words have also been proposed: the 1 Note that the expression should also be maximized by I; however, for the sake of simplicity we suppose that it is known. syntax translation models are described in (Yamada and Knight, 2001) , alignment templates are used in (Och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (PBT) in (Tom´ as and Casacuberta, 2001; Marcu and Wong, 2002; Zens et al., 2002; Koehn et al., 2003). In (Venugopal et al., 2003), two methods of phrase extractions are proposed (based on source n-grams and HMM alignments respectively). They improve a translation lexicon, instead of deﬁning a phrase-based model, which is also used within a word-based decoder. In the same line, a method to produce phrase-based alignments from wordbased alignments is propo"
2005.mtsummit-papers.19,2002.tmi-tutorials.2,0,0.281486,"esearch. In this paper we presented a publicly available toolkit to train phrase-based SMT models. Diﬀerent models that deal with structures or phrases instead of single words have also been proposed: the 1 Note that the expression should also be maximized by I; however, for the sake of simplicity we suppose that it is known. syntax translation models are described in (Yamada and Knight, 2001) , alignment templates are used in (Och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (PBT) in (Tom´ as and Casacuberta, 2001; Marcu and Wong, 2002; Zens et al., 2002; Koehn et al., 2003). In (Venugopal et al., 2003), two methods of phrase extractions are proposed (based on source n-grams and HMM alignments respectively). They improve a translation lexicon, instead of deﬁning a phrase-based model, which is also used within a word-based decoder. In the same line, a method to produce phrase-based alignments from wordbased alignments is proposed in (Lambert and Castell., 2004). Casacuberta, 2001) the following model is proposed: 2 In both cases the model parameters that have to be estimated are the translation probabilities between phrase pairs (θ = {p(f˜|˜ e"
2006.eamt-1.5,2005.eamt-1.6,0,0.0610547,"Missing"
2006.eamt-1.5,J93-2003,0,0.0192467,"Missing"
2006.eamt-1.5,J04-2004,1,0.788756,"2) t t It should be noted that the maximisation problem stated above is NP-hard (Casacuberta & Higuera, 2000). Nevertheless, adequate approximations can be obtained by neans of efficient search algorithms, like Viterbi (Viterbi, 1967) for the best path and the Recursive Enumeration Algorithm (REA) (Jim´enez & Marzal, 1999) for the nbest paths. SFSTs have been successfully applied to many translation tasks (Amengual et al., 2000; Casacuberta et al., 2004). A possible way of learning SFSTs from training data is the Grammatical Inference and Alignments for Transducer Inference (GIATI) technique (Casacuberta & Vidal, 2004). Given a finite sample of source-target sentence pairs, it works in three steps: 1. Building training strings: Each training pair is transformed into a single string from an extended alphabet to obtain a new sample of strings. The “extended alphabet” contains words or substrings from source and target sentences coming from training pairs. 2. Inferring a (stochastic) regular grammar: Typically, a smoothed n-gram is inferred from the sample of strings obtained in the previous step. 3. Transforming the inferred regular grammar into a transducer: The symbols associated to the grammar rules are ad"
2006.eamt-1.5,W04-3245,1,0.856195,"Missing"
2006.eamt-1.5,knight-al-onaizan-1998-translation,0,0.0768119,"Missing"
2006.eamt-1.5,P00-1056,0,0.055128,"is to find a target sentence ˆt that: ˆt = argmax Pr(t |s) = argmax Pr(t, s). (1) t t The joint distribution Pr(t, s) can be modelled by a SFST T (Pic´o & Casacuberta, 2001): The transformation of a parallel corpus into a corpus of single sentences is performed with the help of statistical alignments: each word is joined with its translation in the output sentence, creating an “extended word”. This joining is done taking care not to invert the order of the output words. The third step is trivial with this arrangement. In our experiments, the alignments are obtained using the GIZA++ software (Och & Ney, 2000), which implements IBM statistical models (Brown et al., 1993). 3 ˆt = argmax Pr(t, s) ≈ argmax PrT (t, s). (2) t t It should be noted that the maximisation problem stated above is NP-hard (Casacuberta & Higuera, 2000). Nevertheless, adequate approximations can be obtained by neans of efficient search algorithms, like Viterbi (Viterbi, 1967) for the best path and the Recursive Enumeration Algorithm (REA) (Jim´enez & Marzal, 1999) for the nbest paths. SFSTs have been successfully applied to many translation tasks (Amengual et al., 2000; Casacuberta et al., 2004). A possible way of learning SFST"
2006.eamt-1.5,2005.eamt-1.35,0,0.0320493,"Missing"
2007.iwslt-1.19,J04-2004,1,0.826449,"ut penalty a 0.8 c 0.8 T Figure 2: Word lattice after the frame posterior probabilities are computed. 3.2.4. Output language model In order to help the fluency an output language model has been added: hOL (eI1 , f1J , ~xT1 ) = log P r(eI1 ) 3.2.2. Statistical finite-state transducers 3.3. Phrase-based local reordering model The joint probability distribution P r(eI1 , f1J ) in Eq. 4 can be adequately modelled by means of a statistical finite-state transducer (SFST). SFSTs have been thoroughly studied [9, 10] and several approaches to infer SFSTs from corpora have been proposed in recent years [11, 12, 13]. We have used the Grammatical Inference and Alignments for Transducer Inference (GIATI) technique for inferring the SFST [14]. This technique uses a finite sample of bilingual pairs (parallel corpus) for inferring the SFST in three steps: The GIATI technique described above is known to have limited capability to model non-monotonous translations. Hopefully, the languages for the task we approached are very monotonous for non-local relationships. However, they may have many local inversions. We have addressed this problem by reordering the target sentence in a similar fashion to the work by [1"
2007.iwslt-1.19,takezawa-etal-2002-toward,0,0.0882579,"manner. This is possible since each transition of I,er I1 m=1 ˆ The output sentence eˆr I1 resulting from the maximization is not in the appropriate order. Hence, the reordering problem can be defined as follows: ˆ ˆ ˆ ˆ eˆI1 = arg max P r(eI1 )P r(ˆ er I1 |eI1 ) (13) ˆ eI1 ˆ ˆ ˆ where P r(eI1 ) is a target language model, and P r(ˆ er I1 |eI1 ) is the reordering model. Therefore, the reordering model is applied to the best translation from the log-linear model in a serial manner. 4. IWSLT07 evaluation campaign The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task [16] for the Italian-English language pair. BTEC is a multilingual corpus which contains sentences related to travel expressions similar to those that are found in traveler’s phrase books. The statistics for this task are shown in Table 1. The corpus consists of six development sets. However, the experiments were conducted with three of them: dev4, dev5b. and dev5b. The development sets were not added to the training data as they did not show to improve the results. No additional data was exploited during the experiments. Table 1: Corpus statistics for training, development, and test. OOV stands f"
2007.iwslt-1.19,2005.iwslt-1.2,0,0.0268764,"ntence, affecting negatively the additive combination of posteriors. In our experiments, this parameter was adjusted to minimize the word error rate of the source sentence on the development set. 4.1.4. Lattice pruning One important aspect to keep in mind when translating word lattices is that the computational cost increases enormously. However, most of the hypotheses have very low probability and are not worth being explored. In fact, it has been observed that an appropriate pruning can even benefit translation results since very unlikely hypothesis will never succeed. As it has be shown in [19], lattice pruning by confidence measures achieve good results. It is for that reason, that we pruned the word lattices to reduce lattice density by removing paths which do not reach a threshold. We selected the threshold that, while keeping the translation performance, had a reasonable lattice density. 4.2. Experimental results 4.1. Practical aspects 4.1.1. Punctuation and case restoration The evaluation is case sensitive and with punctuation marks. We followed the approach1 given by the IWSLT06 organizers instead. First, punctuation and case were removed from the training. Next, in the postpr"
2007.iwslt-1.19,2001.mtsummit-papers.68,0,0.0319066,"best results in our experiments. 4.1.2. Sentence splitting in training Several samples in the training set consist of two or more sentences. Occasionally, after the alignment estimation, some alignments have crossed sentence boundaries. In principle, 1 http://www.slc.atr.jp/IWSLT2006/downloads/ case+punc tool using SRILM.instructions.txt define a sentence boundary as the beginning of the sentence or any of these punctuation marks: .?! 2 We As mentioned at the beginning of this section, we participated in the Italian-English track. For all experiments, two accuracy measures are reported: BLEU [20] and NIST [21]. The parameters for the development sets were optimized for BLEU. For the test set, the parameters of the dev5b were used owing to the similar conditions of both data sets. Furthermore, we found out later that parameters from dev5b performed better. The results presented in this section were obtained after the official submission period was over. Table 2 shows the results for the development and test sets depending on which features were added to the model for the clean input. The baseline model is a GIATI transducer. The feature codes are the following: WP, output word insertio"
2007.iwslt-1.19,P02-1040,0,\N,Missing
2007.iwslt-1.19,P02-1038,0,\N,Missing
2007.iwslt-1.19,2006.iwslt-plenaries.1,0,\N,Missing
2007.iwslt-1.2,J90-2002,0,0.423624,"and, phrase-based approach, and on the other hand, categorization. For both approaches, both statistical and linguistic alternatives are explored. As for translation framework, finite-state transducers are considered. These are versatile models that can be easily integrated on-the-fly with acoustic models for speech translation purposes. In what the experimental framework concerns, all the models presented were evaluated and compared taking confidence intervals into account. 1. Introduction Stochastic finite-state transducers (SFST) [1] consist of a sub-set of probabilistic translation models [2]. They are versatile models that count on efficient algorithms for inference from training samples [3], composition with other finite-state models [4, 5] that allows for a hierarchical structure of several knowledge sources, minimization and decoding [6]. The main goal of this paper is to carry out a comparative study on the benefits of additional knowledge sources within finite-state framework constrained to GIATI methodology [7]. We aim at comparing the classical GIATI approach, where the source sentence to be translated is analyzed word-by-word, with category-based and phrase-based approach"
2007.iwslt-1.2,J97-2003,0,0.0388077,"for translation framework, finite-state transducers are considered. These are versatile models that can be easily integrated on-the-fly with acoustic models for speech translation purposes. In what the experimental framework concerns, all the models presented were evaluated and compared taking confidence intervals into account. 1. Introduction Stochastic finite-state transducers (SFST) [1] consist of a sub-set of probabilistic translation models [2]. They are versatile models that count on efficient algorithms for inference from training samples [3], composition with other finite-state models [4, 5] that allows for a hierarchical structure of several knowledge sources, minimization and decoding [6]. The main goal of this paper is to carry out a comparative study on the benefits of additional knowledge sources within finite-state framework constrained to GIATI methodology [7]. We aim at comparing the classical GIATI approach, where the source sentence to be translated is analyzed word-by-word, with category-based and phrase-based approaches, where either the analysis of the source sentence or the generation of target sentence is driven by other kind of tokens. We intend to find out wether"
2007.iwslt-1.2,J04-2004,1,0.899148,"red taking confidence intervals into account. 1. Introduction Stochastic finite-state transducers (SFST) [1] consist of a sub-set of probabilistic translation models [2]. They are versatile models that count on efficient algorithms for inference from training samples [3], composition with other finite-state models [4, 5] that allows for a hierarchical structure of several knowledge sources, minimization and decoding [6]. The main goal of this paper is to carry out a comparative study on the benefits of additional knowledge sources within finite-state framework constrained to GIATI methodology [7]. We aim at comparing the classical GIATI approach, where the source sentence to be translated is analyzed word-by-word, with category-based and phrase-based approaches, where either the analysis of the source sentence or the generation of target sentence is driven by other kind of tokens. We intend to find out wether it is worth or not to create more complex models such as class-based or phrasebased models within this finite-state framework. In previous works we studied such models taking just linguistic approach into account. The contribution of this paper is to tackle those models under pur"
2007.iwslt-1.2,2005.mtsummit-papers.19,1,0.77441,"the target phrase tj+J j and it has associated a probability p. (b) The left-to-right word-based model keeps the general structure given by the phrase-based model, since neither the probability nor the input/output change. λ stands for the empty word. As previously mentioned, the inference starts from a given segmented training corpus. This segmentation might be carried out taking the bilingual corpus into account or just from isolated monolingual parts, there is no restriction on this respect. Monolingual segmentation was tested in this work, nevertheless, other methods such as T HOT toolkit [20] might be explored in order to obtain bilingual segmentations. Needless to say, segmentation plays an important role in this approach, thus, two possibilities are explored, linguistic and statistically motivated one in turn. 4.1. Linguistically motivated segmentation Linguistic phrases were identified by Ametzaga˜na group following the next steps: 1. First of all, a morpho-semantic parsing allows to assign one or more tags to each word of the corpus. These tags include information about linguistic categories such as number, declension case, verb tense and aspect, etc. Besides, the stem and mor"
2007.iwslt-1.2,J03-1002,0,0.00244336,"1 s2 |λ 1 q2 On the other hand, P (t, s) represents the probability of (t, s) to be a translation pair. The joint probability translation model might be modeled with an SFST (τ ), P (t, s) ' Pτ (t, s). Such a model might be used for either speech translation (as shown before) or by itself for text translation. Example 1: Let us show how GIATI carries out the inference of an SFST given a couple of bilingual training samples: s1 s2 s3 ↔ t1 t2 t3 s1 s2 s4 ↔ t1 t2 t4 • Obtain the alignments. Let us note that in this work the involved statistical alignments were obtained with G IZA ++ free toolkit [10]. Assume that for the given bilingual training set, the alignments drawn in Figure 1 were obtained (despite the fact that G IZA ++ would not have given these pathologic alignments as a result). • Get a monotonic bilingual segmentation. On the basis of those alignments, zero or more target words are assigned to each source word, in such a way that a monotonic bilingual segmentation is obtained. Monotonicity keeps the word order of both the source and the s4 |t2 t4 q3 0.5 (5) i s3 |t2 t3 0.5 Figure 2: SFST 3. Category-based finite-state transducers In the framework of statistical language proces"
2007.iwslt-1.2,J92-4003,0,0.0313956,"ation, in many cases, the words belonging to the same class have similarities regarding their morphologic or semantic role as shown in the following example. Example 2: some of these statistically motivated categories of the task under consideration. Figure 3: Category-based approach. class-1: arinduko, bihurtuko, finkatuko, handituko, helduko, nabarituko, pasatuko. In order to avoid the loss of information associated with the use of classical class-based models, some authors have proposed alternative approaches in speech recognition such as interpolation between word and class-based grammars [11, 12]. In our case, for speech translation the SFST itself entails a relation between classes and words. There are related works including categorization for speech translation within finite-state framework [13, 14] which significantly differ from our approach (for further details on this approach turn to [15]). Regarding the nature of the categories, they might be either linguistically or statistically motivated, and the aim of this work is to determine if it makes a difference to use one or the other within a specific task and corpus. On the following we give some details on each categorization t"
2007.iwslt-1.2,W97-0407,0,0.0486932,"egories of the task under consideration. Figure 3: Category-based approach. class-1: arinduko, bihurtuko, finkatuko, handituko, helduko, nabarituko, pasatuko. In order to avoid the loss of information associated with the use of classical class-based models, some authors have proposed alternative approaches in speech recognition such as interpolation between word and class-based grammars [11, 12]. In our case, for speech translation the SFST itself entails a relation between classes and words. There are related works including categorization for speech translation within finite-state framework [13, 14] which significantly differ from our approach (for further details on this approach turn to [15]). Regarding the nature of the categories, they might be either linguistically or statistically motivated, and the aim of this work is to determine if it makes a difference to use one or the other within a specific task and corpus. On the following we give some details on each categorization technique used in this work. 3.1. Linguistically motivated categories As for linguistic categories, many criteria could have been selected, such as POS-tagging, distinguishing nouns, verbs, adjectives, gender, n"
2007.iwslt-1.2,E99-1010,0,0.102249,"rds in the same class share the lemma, which is in fact the main contribution in what comes to rendering the meaning. For the task under consideration (latter commented in section 5) there were 1,135 running words in Basque and they were classified in 561 classes (as they were found 561 different lemmas). Let us not that the lemmatization was carried out by Ametzaga˜na group1 (a non-profit organization working on I+D) since there are not still free parsing toolkits for Basque. 3.2. Statistically motivated categories A set of 561 statistical classes was automatically obtained by means of mkcls [16], a free toolkit designed to train word classes on the basis of a maximum likelihood criterion. The 1 http://ametza.com class-2: orduetara, orduetaraino, orduetarako, ordutan. class-3: 11, 12, 13, 15, 16, 17, 18, 19, 24, 26, 27. class-4: 1500, 1600, 1700. class-5: goradakada, igoera. All the words gathered in class-1 are verbs (“arindu”, “bihurtu”, ...) and all of them have a suffix (”-ko”) representing the future tense. The class-2 assembles different declension cases of the same stem (“ordu”). Class-3 brings together numbers related to temperature, while the numbers in class-4 are related to"
2007.iwslt-1.2,carreras-etal-2004-freeling,0,0.0283545,"Missing"
2007.iwslt-1.2,2004.tmi-1.9,0,0.105355,"Missing"
2007.iwslt-1.2,W04-3250,0,0.0333005,"Missing"
2007.iwslt-1.2,W02-0706,1,0.823721,"nces turned out that class-based approach outperformed the baseline regarding the meaning transfer but there was almost no difference in what fluency concerned. Regarding the linguistic and statistical approaches, the linguistic one has resulted in slightly better translation results than the statistical one for both class-based and phrase-based models. With respect to the speech translation results, note that each translation model is accompanied with a recognition score (see Table 2). This is due to the fact that speech translation was carried out using the so-called integrated architecture [27], which involves a tight on-the-fly integration between acoustic and translation model. Both the recognized string in the source language and its translation are jointly obtained in a single decoding. As a matter of comparison, the speech recognition score for this task using a 3-TSS language model is WER = 7.9. Therefore, some translation systems not only improve the translation scores (respect to the baseline) but also the recognition scores respect to a classical speech recognition system. 6. Concluding remarks and future work In this work we have made an overview of one approach of the cla"
2007.mtsummit-papers.2,J04-2004,1,0.82046,"mpute the conditional probability of the acoustic signal given a source hypothesis: P r(xT1 |f1J ) = J Y P ([wj , sj , ej ]|xT1 ) (9) j=1 where sj and ej are the starting and the ending time, respectively, of the source word wj . 3.2 Stochastic Finite-State Transducers The joint probability distribution P r(eI1 , f1J ) in Eq. 4 can be adequately modelled by means of a statistical finite-state transducer (SFST). SFSTs have been thoroughly studied (Vidal et al., 2005a; Vidal et al., 2005b) and several approaches to infer SFSTs from corpora have been proposed in recent years (Kumar et al., 2005; Casacuberta and Vidal, 2004; Allauzen et al., 2004). a subset of possible f1J , i.e. those belonging to the word lattice G and the SFST. The search algorithm process corresponds to the following equation: We have used the Grammatical Inference and Alignments for Transducer Inference (GIATI) technique for inferring the SFST (Pic´o, 2005). This technique uses a finite sample of bilingual pairs (parallel corpus) for inferring the SFST in three steps: ˆ 1. Building training strings. Each training pair is transformed into a single string from an extended alphabet to obtain a new sample of strings. The transformation of a par"
2007.mtsummit-papers.2,W04-3250,0,0.0741818,"Missing"
2007.mtsummit-papers.2,2001.mtsummit-papers.68,0,0.0288556,"134922 Vocabulary 686 513 Sentences 336 # words 2828 2940 Perplexity 8.6 6.3 ASR WER 13.3 – FUB Italian English 3038 61232 72446 2459 1701 278 5381 6198 31 25 29.4 – Table 1: Corpus statistics for Eutrans-I and FUB. 4.2 Evaluation Measures The experiments have been assessed through several different evaluation measures. To measure the translation performance, we have used Translation Word Error Rate (TWER) and Position-Independent Word Error Rate (PER), which inherit from speech WER, as they have been the traditional translation measures. Nevertheless, new measures have arisen recently: BLEU (Papineni et al., 2001) and NIST (Doddington, 2002). Both measure the n-gram co-occurrences and are said to be well correlated with human evaluation. We also present the results with these measures because currently they are the most used in machine translation. In all the experiments, punctuation marks have been removed, while capital letters have been kept. 4.3 Parameter Tunning One important question regarding performance is to adjust the model parameters. In our case, given that probabilities in Eq. 10 are not true distributions, it is necessary to find an interpolation lambda parameter for the word lattice prob"
2007.tmi-papers.2,N03-1017,0,0.0140835,"ned in the eral sear h algorithms have been proposed in paper. Con lusions are ondensed in the se - the literature to solve this ill-posed problem tion 5. ba k: e iently (Brown and others, 1990; Wang and Waibel, 1997; Yaser and others, 1999; Ger2 Bayes De ision Theory mann and others, 2001; Jelinek, 1969; Gar íaA lassi ation problem su h as the SMT Varea and Casa uberta, 2001; Tillmann and problem an be seen as an instan e of a De ision Problem (DP). From this point of view, Ney, 2003). In order to alleviate this drawba k, many of the urrent SMT systems (O h et al., 1999; O h and Ney, 2004; Koehn et al., 2003; Zens et al., 2002) have proposed the use of the translation rule dire t a lassi ation problem is omposed of three dierent items: 1. A set of (DTR): ˆ = arg max{p(e) · p(e|f )} e (3) 2. A set of lasses (Ω the ITR (Eq. (2)), where 3 p(f |e) is substituted The method for solving the maximisation (or the sear h) of the optimal eˆ in the set E∗ , i.e. arg maxe∈E∗ = {ω1 , . . . , ωC }) in whi h the system has to lassify ea h obe∈E∗ whi h an be seen as an heuristi version of Obje ts (X ) the system might observe and has to lassify (i.e., translate). served obje t x ∈ X. 4 Given two senten es e an"
2007.tmi-papers.2,J06-4004,0,0.0601805,"Missing"
2007.tmi-papers.2,P03-1021,0,0.0152538,"Missing"
2007.tmi-papers.23,2005.eamt-1.25,0,0.114741,"ons being applied to the set of possible permutations of the output sentence. Hence, the search performed turns sub-optimal, and an important loss in the representational power of the distortion models takes place. On the other hand, dealing with arbitrary word reordering and choosing the one which best scores given a translation model has been shown not to be a viable solution, since when allowing all possible word permutations the search is NP-hard (Knight, 1999). In the present work we develop a new approach to the problem, based on the work of Zens, Matusov and Kanthak (Zens et al., 2004; Matusov et al., 2005; Kanthak et al., 2005), who introduced the idea of monotonizing a corpus. A very preliminary result of our work was published in a Spanish workshop (Sanchis and Casacuberta, 2006). The key idea behind this concept is to use the IBM alignment models to efficiently reorder the input sentence s and produce a new bilingual, monotone pair, composed by the reordered input sentence s′ and the output sentence t. Hence, once this new bilingual pair has been produced, the translation model to be applied will not have to tackle with the problems derived from different word reorderings, since this proble"
2007.tmi-papers.23,P00-1056,0,0.189355,"Missing"
2007.tmi-papers.23,W05-0831,0,0.278725,"he set of possible permutations of the output sentence. Hence, the search performed turns sub-optimal, and an important loss in the representational power of the distortion models takes place. On the other hand, dealing with arbitrary word reordering and choosing the one which best scores given a translation model has been shown not to be a viable solution, since when allowing all possible word permutations the search is NP-hard (Knight, 1999). In the present work we develop a new approach to the problem, based on the work of Zens, Matusov and Kanthak (Zens et al., 2004; Matusov et al., 2005; Kanthak et al., 2005), who introduced the idea of monotonizing a corpus. A very preliminary result of our work was published in a Spanish workshop (Sanchis and Casacuberta, 2006). The key idea behind this concept is to use the IBM alignment models to efficiently reorder the input sentence s and produce a new bilingual, monotone pair, composed by the reordered input sentence s′ and the output sentence t. Hence, once this new bilingual pair has been produced, the translation model to be applied will not have to tackle with the problems derived from different word reorderings, since this problem will not be present a"
2007.tmi-papers.23,J99-4005,0,0.12627,"stortion models are usually implemented within the decoding algorithms and imply serious computational problems, leading ultimately to restrictions being applied to the set of possible permutations of the output sentence. Hence, the search performed turns sub-optimal, and an important loss in the representational power of the distortion models takes place. On the other hand, dealing with arbitrary word reordering and choosing the one which best scores given a translation model has been shown not to be a viable solution, since when allowing all possible word permutations the search is NP-hard (Knight, 1999). In the present work we develop a new approach to the problem, based on the work of Zens, Matusov and Kanthak (Zens et al., 2004; Matusov et al., 2005; Kanthak et al., 2005), who introduced the idea of monotonizing a corpus. A very preliminary result of our work was published in a Spanish workshop (Sanchis and Casacuberta, 2006). The key idea behind this concept is to use the IBM alignment models to efficiently reorder the input sentence s and produce a new bilingual, monotone pair, composed by the reordered input sentence s′ and the output sentence t. Hence, once this new bilingual pair has"
2007.tmi-papers.23,N03-1017,0,0.00811465,"and the (inverse) translation model P r(s|t). Although it might seem odd to model the probability of the source sentence given the target sentence, this decomposition has a very intuitive interpretation: the translation model P r(s|t) will capture the word relations 191 between both input and output language, whereas the language model P r(t) will ensure that the output sentence is a well-formed sentence belonging to the target language. In the last years, SMT systems have evolved to become the present state of the art, two of the most representative techniques being the phrase based models (Koehn et al., 2003; Och and Ney, 2004) and the Weighted Finite State Transducers for Machine Translation (Casacuberta and Vidal, 2004; Kumar and Byrne, 2003). Both of these frameworks typically rely on word-aligned corpora, which often lead them to incur in word ordering related errors. Although there have been different efforts aiming towards enabling them to deal with non-monotonicity, the algorithms developed often only account for very limited reorderings, being unable to tackle with the more complex reorderings that e.g. some Asian languages introduce with respect to european languages. Because of this, no"
2007.tmi-papers.23,N03-1019,0,0.0151293,"get sentence, this decomposition has a very intuitive interpretation: the translation model P r(s|t) will capture the word relations 191 between both input and output language, whereas the language model P r(t) will ensure that the output sentence is a well-formed sentence belonging to the target language. In the last years, SMT systems have evolved to become the present state of the art, two of the most representative techniques being the phrase based models (Koehn et al., 2003; Och and Ney, 2004) and the Weighted Finite State Transducers for Machine Translation (Casacuberta and Vidal, 2004; Kumar and Byrne, 2003). Both of these frameworks typically rely on word-aligned corpora, which often lead them to incur in word ordering related errors. Although there have been different efforts aiming towards enabling them to deal with non-monotonicity, the algorithms developed often only account for very limited reorderings, being unable to tackle with the more complex reorderings that e.g. some Asian languages introduce with respect to european languages. Because of this, not only will monotone systems present incorrectly ordered translations, but, in addition, the parameters of such models will be incorrectly"
2007.tmi-papers.23,H05-1021,0,0.0123359,"proaches Three main possibilities exist when trying to solve the reordering problem: input sentence reordering, output sentence reordering, or reordering both. The latter is, to the best of our knowledge, as yet unexplored. Vilar et al. (1996), tried to partially solve the problem by monotonizing the most probable non-monotone alignment patterns and 192 adding a mark in order to be able to remember the original word order. This being done, a new output language has been defined and a new language and translation model can be trained, making the translation process now monotone. More recently, Kumar and Byrne (2005) learned weighted finite state transducers accounting for local reorderings of two or three positions. These models were applied to phrase reordering, but the training of the models did not yield statistically significant results with respect to the introduction of the models with fixed probabilities. When dealing with input sentence reordering (Zens et al., 2004; Matusov et al., 2005; Kanthak et al., 2005), the main idea is to reorder the input sentence in such a way that the translation model will not need to account for possible word reorderings. To achieve this, alignment models are used,"
2007.tmi-papers.23,J04-4002,0,0.0154826,"ranslation model P r(s|t). Although it might seem odd to model the probability of the source sentence given the target sentence, this decomposition has a very intuitive interpretation: the translation model P r(s|t) will capture the word relations 191 between both input and output language, whereas the language model P r(t) will ensure that the output sentence is a well-formed sentence belonging to the target language. In the last years, SMT systems have evolved to become the present state of the art, two of the most representative techniques being the phrase based models (Koehn et al., 2003; Och and Ney, 2004) and the Weighted Finite State Transducers for Machine Translation (Casacuberta and Vidal, 2004; Kumar and Byrne, 2003). Both of these frameworks typically rely on word-aligned corpora, which often lead them to incur in word ordering related errors. Although there have been different efforts aiming towards enabling them to deal with non-monotonicity, the algorithms developed often only account for very limited reorderings, being unable to tackle with the more complex reorderings that e.g. some Asian languages introduce with respect to european languages. Because of this, not only will monotone"
2007.tmi-papers.23,2005.mtsummit-papers.19,1,0.836594,"Missing"
2007.tmi-papers.23,P02-1040,0,0.0770406,"Missing"
2007.tmi-papers.23,C04-1030,0,0.0832866,"mately to restrictions being applied to the set of possible permutations of the output sentence. Hence, the search performed turns sub-optimal, and an important loss in the representational power of the distortion models takes place. On the other hand, dealing with arbitrary word reordering and choosing the one which best scores given a translation model has been shown not to be a viable solution, since when allowing all possible word permutations the search is NP-hard (Knight, 1999). In the present work we develop a new approach to the problem, based on the work of Zens, Matusov and Kanthak (Zens et al., 2004; Matusov et al., 2005; Kanthak et al., 2005), who introduced the idea of monotonizing a corpus. A very preliminary result of our work was published in a Spanish workshop (Sanchis and Casacuberta, 2006). The key idea behind this concept is to use the IBM alignment models to efficiently reorder the input sentence s and produce a new bilingual, monotone pair, composed by the reordered input sentence s′ and the output sentence t. Hence, once this new bilingual pair has been produced, the translation model to be applied will not have to tackle with the problems derived from different word reorderi"
2008.eamt-1.14,P07-2046,0,0.0300395,"Missing"
2008.eamt-1.14,P06-2117,0,0.0377855,"Missing"
2008.eamt-1.14,J93-2003,0,0.0108208,"Missing"
2008.eamt-1.14,W02-1018,0,0.0561164,"Missing"
2008.eamt-1.14,2002.tmi-tutorials.2,0,0.0606803,"Missing"
2008.eamt-1.14,N03-1017,0,0.0467982,"Missing"
2008.eamt-1.14,P07-2045,0,0.0105912,"Missing"
2008.eamt-1.14,P03-1021,0,0.0604851,"Missing"
2008.eamt-1.14,2005.mtsummit-papers.11,0,0.0792265,"Missing"
2008.eamt-1.14,W06-3114,0,0.0653552,"Missing"
2008.eamt-1.14,W04-3250,0,0.212513,"Missing"
2008.eamt-1.14,D07-1029,0,0.0422694,"Missing"
2008.eamt-1.22,2002.tmi-tutorials.2,0,0.280275,"re can be easily adapted to deal with this problem. 2 Phrase-based SMT Different translation models have been proposed depending on how the relation between the source and the target languages is structured; that is, the way a target sentence is generated from a source sentence. This relation is summarized using the concept of alignment; that is, how the constituents (typically words or groups-of-words) of a pair of sentences are aligned with each other. For the translation model, P r(f |e), in Eq. (1), Phrase-based Translation (PBT) can be explained from a generative point of view as follows [3]: 1. The target sentence e is segmented into K phrases (˜ eK 1 ). 2. Each target phrase e˜k is translated into a source phrase f˜. 3. Finally, the source phrases are reordered in order to compose the source sentence f˜1K = f . In PBT, it is assumed that the relations between the words of the source and target sentences can be explained by means of the hidden variable a ˜K 1 , which contains all the decisions made during the generative story. X X ˜K aK , e˜K ) P r(f |e) = P r(f˜1K , a ˜K eK P r(˜ aK eK (2) 1 |˜ 1 )= 1 |˜ 1 )P r(f1 |˜ 1 1 K,˜ aK 1 K,˜ aK 1 where each a ˜k ∈ {1 . . . K} denotes t"
2008.eamt-1.22,2001.mtsummit-papers.64,1,0.933668,"In PBT, it is assumed that the relations between the words of the source and target sentences can be explained by means of the hidden variable a ˜K 1 , which contains all the decisions made during the generative story. X X ˜K aK , e˜K ) P r(f |e) = P r(f˜1K , a ˜K eK P r(˜ aK eK (2) 1 |˜ 1 )= 1 |˜ 1 )P r(f1 |˜ 1 1 K,˜ aK 1 K,˜ aK 1 where each a ˜k ∈ {1 . . . K} denotes the index of the target phrase e˜ that is aligned with the k-th source phrase f˜k . Different assumptions can be made from the previous equation. For example, in [3] all possible segmentations have the same probability, and in [4], it is also assumed that the alignments must be monotonic. In both cases the model parameters that have to be estimated are the translation probabilities between phrase pairs ({p(f˜|˜ e)}), which typically are estimated via relative frequencies as p(f˜|˜ e) = N (f˜, e˜)/N (˜ e), where N (f˜|˜ e) is the number of times that f˜ has been seen as a translation of e˜ within the training corpus. According to Eq. (2), and following a maximum approximation, the problem stated in Eq. (1) can be reframed as: ˆ ≈ arg max{p(e) · p(f , a|e)} e e,a 161 (3) 12th EAMT conference, 22-23 September 2008, Hambur"
2008.eamt-1.22,P02-1038,0,0.13931,"ated are the translation probabilities between phrase pairs ({p(f˜|˜ e)}), which typically are estimated via relative frequencies as p(f˜|˜ e) = N (f˜, e˜)/N (˜ e), where N (f˜|˜ e) is the number of times that f˜ has been seen as a translation of e˜ within the training corpus. According to Eq. (2), and following a maximum approximation, the problem stated in Eq. (1) can be reframed as: ˆ ≈ arg max{p(e) · p(f , a|e)} e e,a 161 (3) 12th EAMT conference, 22-23 September 2008, Hamburg, Germany State-of-the-art statistical machine translation systems model p(f , a|e) following a loglinear approach [5], that is: X  p(f , a|e) ∝ exp λi fi (f , e, a) (4) i where each fi (f , e, a) is a feature function, and weights λi are optimized using a minimun error rate training (MERT) criteria [6] to optimize a particular quality metric (for example maximize the BLEU metric for translation quality, or minimize the Alignment Error Rate (AER) for alignment quality) on a development corpus. 3 Phrase-based alignments The problem of finding the best alignment at phrase level has not been extensively addressed in the literature. A first attempt can be found in [1]. The concept of phrase-based alignment can"
2008.eamt-1.22,P03-1021,0,0.0252731,"number of times that f˜ has been seen as a translation of e˜ within the training corpus. According to Eq. (2), and following a maximum approximation, the problem stated in Eq. (1) can be reframed as: ˆ ≈ arg max{p(e) · p(f , a|e)} e e,a 161 (3) 12th EAMT conference, 22-23 September 2008, Hamburg, Germany State-of-the-art statistical machine translation systems model p(f , a|e) following a loglinear approach [5], that is: X  p(f , a|e) ∝ exp λi fi (f , e, a) (4) i where each fi (f , e, a) is a feature function, and weights λi are optimized using a minimun error rate training (MERT) criteria [6] to optimize a particular quality metric (for example maximize the BLEU metric for translation quality, or minimize the Alignment Error Rate (AER) for alignment quality) on a development corpus. 3 Phrase-based alignments The problem of finding the best alignment at phrase level has not been extensively addressed in the literature. A first attempt can be found in [1]. The concept of phrase-based alignment can be stated formally as follows: Let f ≡ f1 , f2 , . . . , fJ be a source sentence and e ≡ e1 , e2 , . . . , eI the corresponding target sentence in a bilingual corpus. A phrase-alignment be"
2008.eamt-1.22,2005.mtsummit-papers.19,1,0.945161,"ts phrase-table in order to obtain those translations of f that are compatible with e. In spite of its simplicity, this technique has no practical interest when applied on regular tasks. Specifically, the technique is not applicable when the alignments 162 12th EAMT conference, 22-23 September 2008, Hamburg, Germany cannot be generated due to coverage problems of the phrase-based alignment model (i.e. one or more phrase pairs required to compose a given alignment have not been seen during the training process). This problem cannot be easily solved, since standard estimation tools such as THOT [7] and MOSES [8] do not guarantee the complete coverage of sentence pairs even if they are included in the training set; this is due to the great number of heuristic decisions involved in the estimation process. One possible way to overcome the above-mentioned coverage problems requires the definition of an alternative technique that is able to consider every source phrase of f as a possible translation of every target phrase of e. Such a technique requires the following two elements: 1. A general mechanism to assign probabilities to phrase pairs, no matter if they are contained in the phrase-ta"
2008.eamt-1.22,P07-2045,0,0.00785518,"e in order to obtain those translations of f that are compatible with e. In spite of its simplicity, this technique has no practical interest when applied on regular tasks. Specifically, the technique is not applicable when the alignments 162 12th EAMT conference, 22-23 September 2008, Hamburg, Germany cannot be generated due to coverage problems of the phrase-based alignment model (i.e. one or more phrase pairs required to compose a given alignment have not been seen during the training process). This problem cannot be easily solved, since standard estimation tools such as THOT [7] and MOSES [8] do not guarantee the complete coverage of sentence pairs even if they are included in the training set; this is due to the great number of heuristic decisions involved in the estimation process. One possible way to overcome the above-mentioned coverage problems requires the definition of an alternative technique that is able to consider every source phrase of f as a possible translation of every target phrase of e. Such a technique requires the following two elements: 1. A general mechanism to assign probabilities to phrase pairs, no matter if they are contained in the phrase-table or not 2."
2008.eamt-1.22,W06-1607,0,0.198544,"of an alternative technique that is able to consider every source phrase of f as a possible translation of every target phrase of e. Such a technique requires the following two elements: 1. A general mechanism to assign probabilities to phrase pairs, no matter if they are contained in the phrase-table or not 2. A search algorithm that enables efficient exploration of the set of possible phrase-alignments for a sentence pair The general mechanism for assigning probabilities to phrase pairs can be implemented by means of the application of smoothing techniques over the phrasetable. As shown in [9], well-known language model smoothing techniques can be imported into the PBT framework. As will be shown in section 4, the PBT smoothing techniques described in [9] can also be adapted to the generation of phrase-based alignments. Regarding the search algorithm to be used, different search strategies can be adopted, as for example dynamic-programming-based or branch-and-bound algorithms. In this study, a branch-and-bound search strategy has been adopted. Our branch-and-bound search algorithm attempts to iteratively expand partial solutions, called hypotheses, until a complete phrase-alignment"
2008.eamt-1.22,J81-4005,0,0.584578,", and second, we translate the unaligned portion of f (if any). The formalism presented at the beginning of this section requires few modifications to allow the generation of partial alignments. Specifically, given f and p we have to obtain the set S ′ of ordered pairs that contains all the words of p and only a subset of the words of f . 4 Smoothing techniques As was mentioned in section 3, the application of smoothing techniques is crucial in the generation of phrase-alignments. Although smoothing is an important issue in language modeling and other areas of statistical NLP (see for example [10] for more details), it has not received much attention from the SMT community. However, most of the well-known language model smoothing techniques can be imported to the SMT field and specifically to the PBT framework, as it is shown in [9]. In spite of the fact that PBT and the generation of phrase-alignments are similar tasks, it should be noted that the two problems differ in a key aspect. 164 12th EAMT conference, 22-23 September 2008, Hamburg, Germany While in PBT the probabilities of unseen events are not important (since the decoder only proposes phrase translations that are contained i"
2008.eamt-1.22,J93-2003,0,0.0328572,"dition, we have implemented a very simple estimation technique (labeled as SD) which works in a similar way to AD estimation but it subtracts a fixed probability mass instead of a fixed count. Lexical distributions A good way to tackle the problem of unseen events is the use of probability distributions that decompose phrases into words. Two different techniques are mentioned in [9] for this purpose: the noisy-or and an alternative technique which is based on alignment matrices. In our work we have applied another technique which consists in obtaining the IBM 1 model probability as defined in [11] for phrase pairs instead of sentence pairs (this distribution will be referred to as LEX). 4.2 Combining estimators The statistical estimators described in the previous subsection can be combined in the hope of producing better models. In our work we have chosen three different techniques for combining estimators: 165 12th EAMT conference, 22-23 September 2008, Hamburg, Germany – Linear interpolation – Backing-off – Log-linear interpolation The linear interpolation technique consists of making a linear combination of different estimators, ensuring that the weights of such combination determin"
2008.eamt-1.22,W03-0301,0,0.059394,"near model as score components. In this case, only GT estimation was implemented. 5 Experimental Results Different experiments were carried out in order to assess the proposed phraseto-phrase alignment smoothing techniques. 5.1 Corpora and evaluation The experiments consisted of obtaining phrase-to-phrase alignments between pairs of sentences following the different smoothing techniques described in the previous section. Specifically, a test set containing several sentence pairs to be aligned was used. The test set was taken from the shared tasks in word alignments developed in HLT/NAACL 2003 [12]. This shared task involved four different language pairs, but we only used English-French in our experiments. A subset of the Canadian Hansards corpus was used in the English-French task. The English-French corpus is composed of 447 English-French test sentences and about a million training sentences. We were interested in evaluating the quality of the phrase-to-phrase alignments obtained with the different phrase alignment smoothing techniques that we proposed. Unfortunately, there does not exist a gold standard for phrase alignments, so we needed to refine the obtained phrase alignments to"
2008.eamt-1.8,2001.mtsummit-papers.64,1,0.91447,"ed in different translation tasks. The goal of this work is to introduce a finite-state framework for a log-linear modelling approach in statistical machine translation. Results for a French-English technical translation task show the convenience of the proposed methods. 1 Introduction Statistical machine translation is a fascinating field of natural language processing where models can be learned automatically from training bilingual text using efficient estimation procedures. Initial, word-based alignment models were quickly overcome by the use of the so called phrase-based alignment models [1]. However, the performance of machine translation systems increases significantly when additional models are used in a log-linear modelling approach [2]. These models are typically: phrase-based translation models, language models, sentence-length models, statistical dictionaries, etc. This approach represents the state-of-the art in statistical machine translation [3]. Given a source sentence s, the statistical machine translation problem can be expressed by means of a log-linear approach in this manner: X ˆt = argmax Pr(t|s) = argmax λi fi (s, t) t t i Finite-state transducers constitute a s"
2008.eamt-1.8,J03-1002,0,0.00739613,"hine translation. Results for a French-English technical translation task show the convenience of the proposed methods. 1 Introduction Statistical machine translation is a fascinating field of natural language processing where models can be learned automatically from training bilingual text using efficient estimation procedures. Initial, word-based alignment models were quickly overcome by the use of the so called phrase-based alignment models [1]. However, the performance of machine translation systems increases significantly when additional models are used in a log-linear modelling approach [2]. These models are typically: phrase-based translation models, language models, sentence-length models, statistical dictionaries, etc. This approach represents the state-of-the art in statistical machine translation [3]. Given a source sentence s, the statistical machine translation problem can be expressed by means of a log-linear approach in this manner: X ˆt = argmax Pr(t|s) = argmax λi fi (s, t) t t i Finite-state transducers constitute a special type of statistical translation model whose interest in statistical machine translation has been proved in different translation tasks [4, 5]. Ho"
2008.eamt-1.8,C69-0101,0,0.506447,"source-target phrase pairs, can be employed to estimate the probability of a monotonous bilingual segmentation. 2.2 Learning phrase-based finite-state models A set of three different models, which are implemented by means of stochastic finite-state transducers, will be integrated into a log-linear framework. A language model for monotonous bilingual segmentations together with two translation models (a direct and an inverse model) in order to score the relations between the source and the target words in a phrase pair will be considered. A language model of phrase-pairs. The GIATI philosophy [6, 7] has been revealed as an interesting approach to infer stochastic finite-state transducers through the modelling of languages. Rather than learning relations from a bilingual corpus, GIATI converts every sentence pair into an extended-symbol string, which is directly derived from a monotonous bilingual segmentation, in order to, straight afterwards, infer a language model from. In fact, the ideas of GIATI, which were introduced to be applied for finite state models, are actually extensive to any other language modelling techniques. Nevertheless, in our case, the GIATI algorithm will be put int"
2008.eamt-1.8,W06-3114,0,0.0605024,"efore to be considered only one symbol in a language modelling application, which will be put into practice through the estimation of n-gram backoff models together with their corresponding representation under a finite state framework. Translation models. Phrase-based translation models have proved to provide a very natural framework for statistical machine translation. Computing the translation probability of a given phrase and hence introducing information about context, these models seem to have mostly outperformed single-word models, quickly evolving into the predominant state-of-the-art [8]. In the last years, a wide variety of techniques to generate phrase-based dictionaries have been researched and implemented. Here, however, phrase-based dictionary entries would be built from the same vocabulary set of bilingual phrase pairs as for the language model. Phrase translation probabilities will be computed under an approximation that is based on the IBM1 model [9], using a stochastic word-based dictionary to score the translation relationships and a Poisson probability distribution to weight the phrase lengths [10]: e−lt r (lt r)ls ls ! Pr(ls |lt ) = j i Y X ′ ′ ′ Pr(sjj |tii ) = P"
2008.eamt-1.8,J93-2003,0,0.0264647,"uting the translation probability of a given phrase and hence introducing information about context, these models seem to have mostly outperformed single-word models, quickly evolving into the predominant state-of-the-art [8]. In the last years, a wide variety of techniques to generate phrase-based dictionaries have been researched and implemented. Here, however, phrase-based dictionary entries would be built from the same vocabulary set of bilingual phrase pairs as for the language model. Phrase translation probabilities will be computed under an approximation that is based on the IBM1 model [9], using a stochastic word-based dictionary to score the translation relationships and a Poisson probability distribution to weight the phrase lengths [10]: e−lt r (lt r)ls ls ! Pr(ls |lt ) = j i Y X ′ ′ ′ Pr(sjj |tii ) = Pr(lsj ′ |lti′ ) i j ′ Pr(sj ′′ |ti′′ ) j ′′ =j i′′ =i provided that ls and lt are the corresponding source and target phrase lengths and r = ¯ls /¯lt is the ratio between their mean values. Similar equations are used for the estimation of direct translation models. Word-based dictionaries can also be estimated by means of the GIZA++ toolkit and they are obtained at the same t"
2008.eamt-1.9,J90-2002,0,0.12711,"language sentence. Among all possible target lanˆ = e1 . . . ei . . . eI which maximises guage sentences, we will choose the sentence e the posterior probability. Such statement is formalised in the Fundamental Equation of Machine Translation: ˆ = argmax{P r(e|f )} = argmax{P r(e) · P r(f |e)} . e e (1) e The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. The decomposition in Eq. (1) allows an independent modelling of the target language model P r(e) and the (inverse) translation model P r(f |e)1 , known as source-channel model [1]. This decomposition has a very intuitive interpretation: the translation model P r(f |e) will capture the word relations between both input and output languages, whereas the language model P r(e) will ensure that the output sentence is a well-formed sentence belonging to the target language. Many statistical translation models [2–5] try to model word-to-word correspondences between source and target words. Known as statistical alignment models, these models typically yield the following equation: X P r(f |e) = {P r(a|e) · P r(f |e, a)} . (2) a The alignment model in Eq. (2) introduces a ’hidd"
2008.eamt-1.9,C96-2141,0,0.260826,"Missing"
2008.eamt-1.9,P97-1037,0,0.108828,"ved word alignment [11] or extracting parallel sentences from comparable corpora [12]. Furthermore, at the 2003 John Hopkins summer workshop on statistical machine translation, a large number of features were tested to discover which ones could improve a state-of-the-art translation system, and the only feature that produced a ”truly significant improvement” was the IBM Model 1 score [13]. IBM Model 1 is defined as a particularly simple alignment model, where all wordto-word alignments have the same probability, i.e. P r(a|e) is modelled using a uniform distribution (which [2] show yields Eq. (4)). Hence, word order does not affect alignment probabilities. # "" I J Y 1 X p(fj |ei ) . (4) p(f |e) = I + 1 i=0 j=1 IBM Model 1 clearly has many shortcomings as a translation model due to its simplicity. The distortion problem and the fact that some words act as garbage collectors are some of them. The distortion problem is a structural limitation of the IBM Model 1 due to the fact that the position of any word in the target sentence is independent of the position of the corresponding word in the source sentence, or the positions of any other source language words or their translations. The o"
2008.eamt-1.9,P98-2158,0,0.192631,"e each segment Xk is a sequence of Γk words Xk = xk1 . . . xkk′ . . . xkΓk . This source sentence is to be translated into a target sentence Y which is divided into L segments Y = Y1 . . . Yl . . . YL , where each segment Yl is a sequence of Λl words Yl = yl1 . . . yll′ . . . ylΛl . The segmentation of the source and target sentences is given as input for our model and remains fixed throughout all the process. In order to take into account the segmentations of the input and output sentences, we modify the statistical alignment model in Eq. (2) as follows: X P r(X|Y) = P r(c|Y)P r(X, b|Y, c) . (5) c,b Instead of only considering one ’hidden’ word alignment a, as IBM Model 1 does, our proposal has two ’hidden’ alignments. First, we introduce a segment alignment c = c1 . . . ck . . . cK , which describes a mapping from a source segment k to a target segment l = ck . Once the segment alignment is determined, we include a word alignment b = b1 . . . bk . . . bK , ∀k bk = bk1 . . . bkk′ . . . bkΓk which describes a mapping from the k ′ th word of source segment k to the l′ th word of target segment l, with l′ = bkk′ . Hence, alignment c maps a given source segment into a specific target seg"
2008.eamt-1.9,2001.mtsummit-papers.64,1,0.807691,"target segment l = ck . Once the segment alignment is determined, we include a word alignment b = b1 . . . bk . . . bK , ∀k bk = bk1 . . . bkk′ . . . bkΓk which describes a mapping from the k ′ th word of source segment k to the l′ th word of target segment l, with l′ = bkk′ . Hence, alignment c maps a given source segment into a specific target segment, and then alignment b maps the words on the source segment into the words in the target segment. 3.1 Model assumptions Next, we describe the assumptions made in the derivation of our model. First, the second term on Eq. (5) is analysed, on Eq. (6) we assume that the alignment of a given segment 49 12th EAMT conference, 22-23 September 2008, Hamburg, Germany does not depend on the alignment of the previous segments, whereas on Eq. (7) we perform a similar assumption on the word level, i.e. the alignment of a given word does not depend on the previous word alignments. P r(X, b|Y, c) = K Y P r(Xk , bk |Y, c, X1k−1 , bk−1 ) ≈ 1 k=1 = K Y p(Xk , bk |Y, ck ) (6) k=1 Γk K Y Y ′ ′ p(xkk′ , bkk′ |Y, ck , xk k1 −1 , bk 1k −1 ) k=1 k′ =1 ≈ Γk K Y Y p(xkk′ , bkk′ |Y, ck ) . (7) k=1 k′ =1 The same assumption done on Eq. (6) can be applied to the fi"
2008.eamt-1.9,W02-1018,0,0.019494,"k ′ th word of source segment k to the l′ th word of target segment l, with l′ = bkk′ . Hence, alignment c maps a given source segment into a specific target segment, and then alignment b maps the words on the source segment into the words in the target segment. 3.1 Model assumptions Next, we describe the assumptions made in the derivation of our model. First, the second term on Eq. (5) is analysed, on Eq. (6) we assume that the alignment of a given segment 49 12th EAMT conference, 22-23 September 2008, Hamburg, Germany does not depend on the alignment of the previous segments, whereas on Eq. (7) we perform a similar assumption on the word level, i.e. the alignment of a given word does not depend on the previous word alignments. P r(X, b|Y, c) = K Y P r(Xk , bk |Y, c, X1k−1 , bk−1 ) ≈ 1 k=1 = K Y p(Xk , bk |Y, ck ) (6) k=1 Γk K Y Y ′ ′ p(xkk′ , bkk′ |Y, ck , xk k1 −1 , bk 1k −1 ) k=1 k′ =1 ≈ Γk K Y Y p(xkk′ , bkk′ |Y, ck ) . (7) k=1 k′ =1 The same assumption done on Eq. (6) can be applied to the first term on Eq. (5), yielding K K Y Y P r(c|Y) = P r(ck |Y, ck−1 ) ≈ p(ck |Y) . (8) 1 k=1 k=1 Lastly, we will perform the same assumption as IBM Model 1, modelling the mappings between input"
2008.eamt-1.9,W07-0718,0,0.035965,"e model-based probability distributions. 47 12th EAMT conference, 22-23 September 2008, Hamburg, Germany Word-based translation models were later on extended by phrase-based models [6– 8], which have proved to provide a very efficient framework for machine translation. Phrase-based models compute the translation probability of a given phrase, i.e. sequence of words, and hence they introduce information about context. Statistical machine translation systems implementing these models have mostly outperformed singleword models such as IBM Model 1 [2], becoming predominant in the state-of-the-art [9] nowadays. In order to combine the positive contributions of different approaches, statistical machine translation models can be merged using a log-linear combination [10]. In this framework, we have a set of M feature functions hm (e|f ), m = 1, . . . , M . For each feature function, there exists a model parameter λm , m = 1, . . . , M . The following decision rule is obtained: ˆ = argmax P e e PM M X exp[ m=1 λm hm (e|f )] = argmax λm hm (e|f ) . PM ′ e m=1 e′ exp[ m=1 λm hm (e |f )] (3) In this paper we present a novel word alignment model (Section 3) intended to overcome some of the proble"
2008.eamt-1.9,W03-2205,1,0.840539,"Section 3) intended to overcome some of the problems inherent to IBM Model 1 (Section 2). We will show that an improvement in translation quality, on the Europarl corpus, can be achieved when using our proposed model as one more feature function in a log-linear machine translation model (Sections 4 and 5). 2 IBM Model 1 IBM Model 1 [2], is a word alignment model which was originally developed to provide reasonable initial parameter estimates for more complex word alignment models, but it has subsequently found a host of additional uses, as segmenting long sentences for improved word alignment [11] or extracting parallel sentences from comparable corpora [12]. Furthermore, at the 2003 John Hopkins summer workshop on statistical machine translation, a large number of features were tested to discover which ones could improve a state-of-the-art translation system, and the only feature that produced a ”truly significant improvement” was the IBM Model 1 score [13]. IBM Model 1 is defined as a particularly simple alignment model, where all wordto-word alignments have the same probability, i.e. P r(a|e) is modelled using a uniform distribution (which [2] show yields Eq. (4)). Hence, word order"
2008.eamt-1.9,N04-1034,0,0.0207619,"to IBM Model 1 (Section 2). We will show that an improvement in translation quality, on the Europarl corpus, can be achieved when using our proposed model as one more feature function in a log-linear machine translation model (Sections 4 and 5). 2 IBM Model 1 IBM Model 1 [2], is a word alignment model which was originally developed to provide reasonable initial parameter estimates for more complex word alignment models, but it has subsequently found a host of additional uses, as segmenting long sentences for improved word alignment [11] or extracting parallel sentences from comparable corpora [12]. Furthermore, at the 2003 John Hopkins summer workshop on statistical machine translation, a large number of features were tested to discover which ones could improve a state-of-the-art translation system, and the only feature that produced a ”truly significant improvement” was the IBM Model 1 score [13]. IBM Model 1 is defined as a particularly simple alignment model, where all wordto-word alignments have the same probability, i.e. P r(a|e) is modelled using a uniform distribution (which [2] show yields Eq. (4)). Hence, word order does not affect alignment probabilities. # "" I J Y 1 X p(fj |"
2008.eamt-1.9,N04-1021,0,0.0156095,"ch was originally developed to provide reasonable initial parameter estimates for more complex word alignment models, but it has subsequently found a host of additional uses, as segmenting long sentences for improved word alignment [11] or extracting parallel sentences from comparable corpora [12]. Furthermore, at the 2003 John Hopkins summer workshop on statistical machine translation, a large number of features were tested to discover which ones could improve a state-of-the-art translation system, and the only feature that produced a ”truly significant improvement” was the IBM Model 1 score [13]. IBM Model 1 is defined as a particularly simple alignment model, where all wordto-word alignments have the same probability, i.e. P r(a|e) is modelled using a uniform distribution (which [2] show yields Eq. (4)). Hence, word order does not affect alignment probabilities. # "" I J Y 1 X p(fj |ei ) . (4) p(f |e) = I + 1 i=0 j=1 IBM Model 1 clearly has many shortcomings as a translation model due to its simplicity. The distortion problem and the fact that some words act as garbage collectors are some of them. The distortion problem is a structural limitation of the IBM Model 1 due to the fact th"
2008.eamt-1.9,H93-1039,0,0.0462681,"plicity. The distortion problem and the fact that some words act as garbage collectors are some of them. The distortion problem is a structural limitation of the IBM Model 1 due to the fact that the position of any word in the target sentence is independent of the position of the corresponding word in the source sentence, or the positions of any other source language words or their translations. The other problem with IBM Model 48 12th EAMT conference, 22-23 September 2008, Hamburg, Germany 1, as standardly trained, is that rare words in the source language tend to act as ”garbage collectors” [14, 13], aligning too many words in the target sentence. Our proposal attempts to reduce the shown problems of IBM Model 1 by including information about a given segmentation of the input and output sentences in the estimation process of the lexicon dictionary. Similar aims, but differently approached, are pursued by [15], which extends the word-to-word alignment approach allowing one-tomany alignments, or [16], that deals with problems related to the suboptimal performance of the standard training method for IBM Model 1. 3 Model Description Our alignment model is an enhancement of the IBM Model 1, w"
2008.eamt-1.9,W99-0604,0,0.0476778,"ce, or the positions of any other source language words or their translations. The other problem with IBM Model 48 12th EAMT conference, 22-23 September 2008, Hamburg, Germany 1, as standardly trained, is that rare words in the source language tend to act as ”garbage collectors” [14, 13], aligning too many words in the target sentence. Our proposal attempts to reduce the shown problems of IBM Model 1 by including information about a given segmentation of the input and output sentences in the estimation process of the lexicon dictionary. Similar aims, but differently approached, are pursued by [15], which extends the word-to-word alignment approach allowing one-tomany alignments, or [16], that deals with problems related to the suboptimal performance of the standard training method for IBM Model 1. 3 Model Description Our alignment model is an enhancement of the IBM Model 1, which takes into account a given segmentation of the input and output sentences to estimate a statistical dictionary. The aim of our model is to benefit those alignments which are coherent with a fixed given segmentation which is considered optimal. We expect to reduce the dispersion of the lexical probabilities, co"
2008.eamt-1.9,P04-1066,0,0.0247006,"oblem with IBM Model 48 12th EAMT conference, 22-23 September 2008, Hamburg, Germany 1, as standardly trained, is that rare words in the source language tend to act as ”garbage collectors” [14, 13], aligning too many words in the target sentence. Our proposal attempts to reduce the shown problems of IBM Model 1 by including information about a given segmentation of the input and output sentences in the estimation process of the lexicon dictionary. Similar aims, but differently approached, are pursued by [15], which extends the word-to-word alignment approach allowing one-tomany alignments, or [16], that deals with problems related to the suboptimal performance of the standard training method for IBM Model 1. 3 Model Description Our alignment model is an enhancement of the IBM Model 1, which takes into account a given segmentation of the input and output sentences to estimate a statistical dictionary. The aim of our model is to benefit those alignments which are coherent with a fixed given segmentation which is considered optimal. We expect to reduce the dispersion of the lexical probabilities, concentrating the probability mass in those words which are revealed by the segmentation as p"
2008.eamt-1.9,2005.mtsummit-papers.11,0,0.0251313,"ur formulation (equation (12)) the importance of each word alignment is weighted by the significance of the alignment of the segments the words belong to with respect to the rest of segment alignments. Hence, we benefit those alignments coherent with the given segmentation which is considered optimal. 4 Experimental setup In our experimentation we include scores derived from our model into a log-linear combination, as another feature functions, with the purpose of improving the translation quality of the log-linear model. We perform our experiments on the second version of the Europarl corpus [18], which is built from the proceedings of the European Parliament. This corpus is divided into three separate sets: one for training, one for development and one for test and was the corpus used in the 2006 Workshop on Machine Translation (WMT) of the ACL [19]. We focused on the German–English (De–En), French–English (Fr–En) and Spanish– English (Es–En) subcorpora of the Europarl corpus, as done in the 2006 WMT of the ACL. Sentences Run. words Training Avg. len. Voc. Sentences Run. words Development Avg. len. OoV Sentences Run. words Test Avg. len. OoV De En 751K 15.3M 16.1M 20.3 21.4 195K 66K"
2008.eamt-1.9,W06-3114,0,0.0173002,"n segmentation which is considered optimal. 4 Experimental setup In our experimentation we include scores derived from our model into a log-linear combination, as another feature functions, with the purpose of improving the translation quality of the log-linear model. We perform our experiments on the second version of the Europarl corpus [18], which is built from the proceedings of the European Parliament. This corpus is divided into three separate sets: one for training, one for development and one for test and was the corpus used in the 2006 Workshop on Machine Translation (WMT) of the ACL [19]. We focused on the German–English (De–En), French–English (Fr–En) and Spanish– English (Es–En) subcorpora of the Europarl corpus, as done in the 2006 WMT of the ACL. Sentences Run. words Training Avg. len. Voc. Sentences Run. words Development Avg. len. OoV Sentences Run. words Test Avg. len. OoV De En 751K 15.3M 16.1M 20.3 21.4 195K 66K 2000 55K 59K 27.6 29.3 432 125 2000 54K 58K 27.1 29.0 377 127 Es En 731K 15.7M 15.2M 21.5 20.8 103K 64K 2000 61K 59K 30.3 29.3 208 127 2000 60K 58K 30.2 29.0 207 125 Fr En 688K 15.6M 13.8M 22.7 20.1 80K 62K 2000 67K 59K 33.6 29.3 144 138 2000 66K 58K 33.1 29."
2008.eamt-1.9,1996.amta-1.14,0,0.233399,"Missing"
2008.eamt-1.9,J97-3002,0,0.16107,"Missing"
2008.eamt-1.9,2001.mtsummit-papers.68,0,0.0455555,"Missing"
2008.eamt-1.9,2004.tmi-1.9,0,0.102697,"Missing"
2008.eamt-1.9,1993.eamt-1.1,0,0.143503,"Missing"
2008.eamt-1.9,P07-2045,0,0.00944798,"r the discrepancy be52 12th EAMT conference, 22-23 September 2008, Hamburg, Germany tween the systems. Bisani and Ney present a similar method where instead of returning and interval they compute the Paired Probability of Improvement (PPoI) which is the relative number of times system X outperforms system Y and vice versa. 5 Experiments For each language pair, we trained two of our alignment models on the corresponding segmented training set, one model for each translation direction. These will be called, hereafter, our direct and inverse extended lexicalised models. We used the Moses toolkit [28] to train the phrase-based models from the training subcorpora of Europarl and the parameters of the log-linear models were optimised using the development subcorpora via the MERT procedure [29], using BLEU as the measure to be optimised. The standard Moses translation model includes five translation scores for each phrase pair in the phrase table [30]: two phrase translation scores (direct and inverse), based on counting the co-occurrences of each phrase pair and normalising the counts, two lexical weights, whose purpose is to assert the lexical soundness of each bilingual phrase pair, and a"
2008.eamt-1.9,P03-1021,0,0.0441266,"e the Paired Probability of Improvement (PPoI) which is the relative number of times system X outperforms system Y and vice versa. 5 Experiments For each language pair, we trained two of our alignment models on the corresponding segmented training set, one model for each translation direction. These will be called, hereafter, our direct and inverse extended lexicalised models. We used the Moses toolkit [28] to train the phrase-based models from the training subcorpora of Europarl and the parameters of the log-linear models were optimised using the development subcorpora via the MERT procedure [29], using BLEU as the measure to be optimised. The standard Moses translation model includes five translation scores for each phrase pair in the phrase table [30]: two phrase translation scores (direct and inverse), based on counting the co-occurrences of each phrase pair and normalising the counts, two lexical weights, whose purpose is to assert the lexical soundness of each bilingual phrase pair, and a constant value called phrase penalty. Similarly, we can obtain two lexical probabilities given by the likelihood of the phrase pair [Xk , Yl ] according to our direct and inverse extended lexica"
2008.eamt-1.9,N03-1017,0,0.043377,"ge pair, we trained two of our alignment models on the corresponding segmented training set, one model for each translation direction. These will be called, hereafter, our direct and inverse extended lexicalised models. We used the Moses toolkit [28] to train the phrase-based models from the training subcorpora of Europarl and the parameters of the log-linear models were optimised using the development subcorpora via the MERT procedure [29], using BLEU as the measure to be optimised. The standard Moses translation model includes five translation scores for each phrase pair in the phrase table [30]: two phrase translation scores (direct and inverse), based on counting the co-occurrences of each phrase pair and normalising the counts, two lexical weights, whose purpose is to assert the lexical soundness of each bilingual phrase pair, and a constant value called phrase penalty. Similarly, we can obtain two lexical probabilities given by the likelihood of the phrase pair [Xk , Yl ] according to our direct and inverse extended lexicalised models (equation (10)). Monotonic Baseline Extended Language Pair WER BLEU WER BLEU Es-En 58.25 31.01 57.87 31.27 En-Es 59.50 30.16 59.26 30.52 De-En 66.8"
2008.eamt-1.9,J93-2003,0,\N,Missing
2008.eamt-1.9,P02-1040,0,\N,Missing
2008.eamt-1.9,C98-2153,0,\N,Missing
2008.eamt-1.9,P02-1038,0,\N,Missing
2008.eamt-1.9,D08-1076,0,\N,Missing
2010.eamt-1.16,N07-2015,0,0.0235888,"Missing"
2010.eamt-1.16,W04-3250,0,0.0458708,"d from the ASR system. That is, both BLEU and WER are scores associated to the target language, while ASR-WER is associated to the errors in the source language which the translation system has to deal with. The results obtained with the N-best lists being N = 100 corresponds to the single-best hypothesis, in other words, these results correspond to the fully decoupled architecture. Note that as the number of explored hypotheses grow, better accuracy is obtained. Nevertheless, from N = 104 onwards the improvements are not statistically significant (Bisani and Ney, 2004; Zhang and Vogel, 2004; Koehn, 2004). That is, the benefits obtained are less and less important. In fact, the performance has its upper value in the results derived with the word-graphs. The graph-score defined in (Zens and Ney, 2005) is the score of the optimum sequence over all possibilities. Note that the most likely hypothesis, the single-best (that with N = 100 ), does not have the highest quality, meaning that other less-likely hypotheses could yield a better quality. In this regard, the results reported in Table 2 show the upper threshold of translation quality that the models can provide and permit us to evaluate the po"
2010.eamt-1.16,D08-1088,0,0.0154253,"ties. Note that the most likely hypothesis, the single-best (that with N = 100 ), does not have the highest quality, meaning that other less-likely hypotheses could yield a better quality. In this regard, the results reported in Table 2 show the upper threshold of translation quality that the models can provide and permit us to evaluate the potential quality of the translation system. We would like to mention that in the literature there are efficient algorithms to find the oracle BLEU (the hypothesis with the highest attainable BLEU score) under different constraints (Li and Khudanpur, 2009; Leusch et al., 2008). A further re-scoring criterion (Matusov et al., 2008a) would allow to re-rank the hypotheses and, hopefully, obtain improvements with respect to the most likely hypothesis. Yet, it is not the aim of this article to focus on re-scoring for either semidecoupled or integrated architectures. 4.2 Integrated architecture The integrated SFSTs allowed us to obtain both the translation of the speech utterance as well as its transcription, in a single decoding step. Hence, both speech transcription and translation results are jointly derived. The speech translation results in the target language, WER"
2010.eamt-1.16,N09-2003,0,0.0276959,"uence over all possibilities. Note that the most likely hypothesis, the single-best (that with N = 100 ), does not have the highest quality, meaning that other less-likely hypotheses could yield a better quality. In this regard, the results reported in Table 2 show the upper threshold of translation quality that the models can provide and permit us to evaluate the potential quality of the translation system. We would like to mention that in the literature there are efficient algorithms to find the oracle BLEU (the hypothesis with the highest attainable BLEU score) under different constraints (Li and Khudanpur, 2009; Leusch et al., 2008). A further re-scoring criterion (Matusov et al., 2008a) would allow to re-rank the hypotheses and, hopefully, obtain improvements with respect to the most likely hypothesis. Yet, it is not the aim of this article to focus on re-scoring for either semidecoupled or integrated architectures. 4.2 Integrated architecture The integrated SFSTs allowed us to obtain both the translation of the speech utterance as well as its transcription, in a single decoding step. Hence, both speech transcription and translation results are jointly derived. The speech translation results in the"
2010.eamt-1.16,W05-0834,0,0.0131463,"s to deal with. The results obtained with the N-best lists being N = 100 corresponds to the single-best hypothesis, in other words, these results correspond to the fully decoupled architecture. Note that as the number of explored hypotheses grow, better accuracy is obtained. Nevertheless, from N = 104 onwards the improvements are not statistically significant (Bisani and Ney, 2004; Zhang and Vogel, 2004; Koehn, 2004). That is, the benefits obtained are less and less important. In fact, the performance has its upper value in the results derived with the word-graphs. The graph-score defined in (Zens and Ney, 2005) is the score of the optimum sequence over all possibilities. Note that the most likely hypothesis, the single-best (that with N = 100 ), does not have the highest quality, meaning that other less-likely hypotheses could yield a better quality. In this regard, the results reported in Table 2 show the upper threshold of translation quality that the models can provide and permit us to evaluate the potential quality of the translation system. We would like to mention that in the literature there are efficient algorithms to find the oracle BLEU (the hypothesis with the highest attainable BLEU scor"
2010.eamt-1.16,2004.tmi-1.9,0,0.0377901,"ranscription WER derived from the ASR system. That is, both BLEU and WER are scores associated to the target language, while ASR-WER is associated to the errors in the source language which the translation system has to deal with. The results obtained with the N-best lists being N = 100 corresponds to the single-best hypothesis, in other words, these results correspond to the fully decoupled architecture. Note that as the number of explored hypotheses grow, better accuracy is obtained. Nevertheless, from N = 104 onwards the improvements are not statistically significant (Bisani and Ney, 2004; Zhang and Vogel, 2004; Koehn, 2004). That is, the benefits obtained are less and less important. In fact, the performance has its upper value in the results derived with the word-graphs. The graph-score defined in (Zens and Ney, 2005) is the score of the optimum sequence over all possibilities. Note that the most likely hypothesis, the single-best (that with N = 100 ), does not have the highest quality, meaning that other less-likely hypotheses could yield a better quality. In this regard, the results reported in Table 2 show the upper threshold of translation quality that the models can provide and permit us to e"
2010.eamt-1.18,J93-2003,0,0.0261143,"Missing"
2010.eamt-1.18,1997.mtsummit-papers.1,0,0.249054,"Missing"
2010.eamt-1.18,W02-1020,0,0.0696028,"Missing"
2010.eamt-1.18,1999.mtsummit-1.5,0,0.191454,"Missing"
2010.eamt-1.18,P07-2045,0,0.0072237,"Missing"
2010.eamt-1.18,J09-1002,1,0.909993,"Missing"
2010.eamt-1.18,P03-1021,0,0.0142808,"Missing"
2010.eamt-1.18,2005.mtsummit-papers.19,1,0.919151,"Missing"
2010.eamt-1.18,C04-1046,0,0.0362756,"Missing"
2010.eamt-1.18,quirk-2004-training,0,0.0350875,"Missing"
2010.eamt-1.18,2007.mtsummit-papers.54,0,0.0666892,"Missing"
2010.eamt-1.18,J85-1001,0,0.74557,"Missing"
2010.eamt-1.18,2006.amta-papers.25,0,0.0299675,"Missing"
2010.eamt-1.18,2009.mtsummit-papers.16,0,0.0350552,"Missing"
2010.eamt-1.18,P06-2107,1,0.83781,"Missing"
2010.eamt-1.18,2005.eamt-1.35,0,0.165865,"Missing"
2010.eamt-1.18,J07-1003,0,0.0266861,"Missing"
2010.eamt-1.18,W02-1021,0,0.0249499,"Missing"
2010.eamt-1.18,C86-1077,0,0.555522,"Missing"
2010.iwslt-evaluation.10,P02-1038,0,0.415269,"resources, which may be unnecessary. A phrase-based model is trained using the TED corpus and some data from the additional training corpora. This additional data is selected to maximize translation quality and coverage of the phrase-based model. Additionally, Bayesian adaptation of model parameters is performed in order to provide stability to the results obtained. Such stability problems are often present whenever the size of the development data set is not large enough. A direct modeling of the posterior probability P r(f |e) has been widely adopted, and, to this purpose, different authors [3, 4] proposed the use of log-linear models, where p(e|f ) = P exp e0 PK k=1 exp PK λk hk (f , e) k=1 λk hk (f , e0 ) , (2) and the decision rule is given by: ˆ = argmax e e K X λk hk (f , e) , (3) k=1 where hk (f , e) is a score function representing a feature for the translation of f into e, K is the number of features and Λ = [λ1 , . . . , λK ]T are the weights for the log-linear combination. The rest of the paper is organized as follows. Section 2 describes our approach for the Chinese–English DIALOG task. Section 3 presents our submission to the English– French TALK task. In Section 4, the sys"
2010.iwslt-evaluation.10,W06-1606,0,0.0348392,"The DIALOG task is carried out using the Spoken Language Databases (SLDB) 85 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3rd, 2010 corpus, a collection of human-mediated cross-lingual dialogs in travel situations. In addition, parts of the BTEC corpus are also provided to the participants of the DIALOG Task. In this section we describe the ITI-UPV machine translation system used in the DIALOG Task of the IWSLT 2010. Syntax-based SMT has been successfully used for translating syntactically different language pairs such as EnglishChinese [5]. For that reason, we used a syntax based decoder in this task. However, we did not want to loose the high coverage of the phrase-based systems so we combined the outputs of the syntax-based decoder with the outputs of a state of the art phrase-based system. Our submission is then, the result of combining the outputs of a syntax-based SMT system and a phrase-based SMT system. Additionally, for the ASR output condition, we add a third phrase-based SMT system trained on the ASR output lattices. The system combination approach is based on median string techniques [1]. 2.1. ITG-based decoding in S"
2010.iwslt-evaluation.10,J97-3002,0,0.0476178,"decoder in this task. However, we did not want to loose the high coverage of the phrase-based systems so we combined the outputs of the syntax-based decoder with the outputs of a state of the art phrase-based system. Our submission is then, the result of combining the outputs of a syntax-based SMT system and a phrase-based SMT system. Additionally, for the ASR output condition, we add a third phrase-based SMT system trained on the ASR output lattices. The system combination approach is based on median string techniques [1]. 2.1. ITG-based decoding in SMT Inversion Transduction Grammars (ITGs) [6] are a restricted set of Synchronous grammars. Standard ITGs use only wordto-word transduction, however, in order to use the advantages of phrasal translation the original formalism has been extended to allow direct phrasal transductions. An ITG with phrasal productions is a tuple (N, Σ, ∆, S, R) where N is the set of non-terminals, S ∈ N is the root non-terminal, Σ is the source language alphabet, ∆ is the target language alphabet, and R is a set of rules. Rules can be divided in two sets: syntactic rules and lexical rules. Syntactic Rules have the form: A → [BC] or A → hBCi, where A, B and C"
2010.iwslt-evaluation.10,2007.mtsummit-papers.2,1,0.735061,"ing strategies are parameterizable, so it can be chosen between a slow but precise search or a fast and more inaccurate one. In order to obtain an ITG with linguistic information from the bilingual corpus provided, we used the method explained in [8]. 2.2. Lattices for ASR error recovery A lattice L is a compact representation of the (pruned) search space of the speech recognizer. A lattice stores multiple hypotheses of the ASR system and provides a convenient representation for tight ASR and SMT coupling. Although there are several studies dealing with algorithms for translating ASR lattices [9, 10], their practical use is limited because of the computational resources they need. 86 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3rd, 2010 Conversely, Confusion Networks (CNs) are even a more compact representation of the hypothesis space for which efficient SMT decoding algorithms exist [11]. CNs attempt to minimize the expected number of word errors, computed as the number of substitutions, deletions and insertions needed to transform the hypothesis into the reference. They can be obtained from lattices by aligning words from the diff"
2010.iwslt-evaluation.10,P08-1115,0,0.0237021,"ing strategies are parameterizable, so it can be chosen between a slow but precise search or a fast and more inaccurate one. In order to obtain an ITG with linguistic information from the bilingual corpus provided, we used the method explained in [8]. 2.2. Lattices for ASR error recovery A lattice L is a compact representation of the (pruned) search space of the speech recognizer. A lattice stores multiple hypotheses of the ASR system and provides a convenient representation for tight ASR and SMT coupling. Although there are several studies dealing with algorithms for translating ASR lattices [9, 10], their practical use is limited because of the computational resources they need. 86 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3rd, 2010 Conversely, Confusion Networks (CNs) are even a more compact representation of the hypothesis space for which efficient SMT decoding algorithms exist [11]. CNs attempt to minimize the expected number of word errors, computed as the number of substitutions, deletions and insertions needed to transform the hypothesis into the reference. They can be obtained from lattices by aligning words from the diff"
2010.iwslt-evaluation.10,P07-2045,0,0.0342906,"ess to obtain the approximate median string. Different edit operations are applied over each position of the string e. The edited string with the lower accumulated distance to the set E is returned. The process is repeated until there is no improvement. 3. Sentence selection in resource-rich scenarios In this section, we describe the ITI-UPV machine translation system that has been designed for the IWSLT’10 TALK task. A state-of-the-art phrase-based SMT approach has been followed in order to translate English text subtitles into French. Specifically, our translation engine is the Moses system [15]. Within this task, the TED corpus is the in-domain data and is composed of a collection of English-French subtitles. However, the additional corpora are composed of sentences. In order to take advantage of the available extra training data, a homogeneous translation framework has then to be defined. We decided that our system would be based on sentences (rather than on subtitles) and so TED data were processed in that sense. Subtitle recovery is then needed as a post-process to SMT. All the steps are detailed in the next subsection. 3.1. Subtitle segmentation recovery The TED corpus is a corp"
2010.iwslt-evaluation.10,C10-2124,1,0.880386,"may alter significantly the probability distribution underlying the training data available. This is, in general, not a good idea, and for this reason it is only prudent to use the strategy presented here to introduce into the translation system only a small amount of bilingual samples. 3.4. Bayesian adaptation for model stabilization Log-linear weights are typically estimated by means of the MERT [4] algorithm. However, this approach often shows stability issues whenever the amount of development data is not big enough. For this reason, we analyzed the effect of applying Bayesian adaptation [17] for stabilizing the loglinear weights involved in the translation process. Under the Bayesian adaptation paradigm, model parameters (i.e. loglinear weights in this case) are viewed as random variables having some kind of a priori distribution. Following the derivation presented in [17], the decision rule in Section 1 is re-written as: ˆ = argmax Pr(e|f ; T, A) e (10) e where T is the training data and A the adaptation data. Then, Pr(e|f ; T, A) is computed as follows: Z 0 p(e|f ; T, A) = Z p(A|Λ; T )p(Λ|T )p(e|f , Λ) P Z Y exp k λk fk (fa , ea ) P P = Z0 0 e0 exp k λk fk (fa , e ) ∀a∈A   1"
2010.iwslt-evaluation.10,J03-1002,0,0.00236309,"and lowercased corpora, and after filtering sentences considered too long (i.e. more than 40 words). 4.1. Baseline system For building the initial SMT systems, the open-source SMT toolkit Moses [15] was used in its standard setup. The decoder features a log-linear model comprising a phrasebased translation model, a language model and a lexicalized distortion model. The translation model, in turn, comprises direct and inverse phrase-translation probabilities, lexicalized weights, and word and phrase penalties. Phrases were obtained from symmetrized word alignments generated by means of GIZA++ [18]. In the baseline setup, the weights of the log-linear interpolation were optimized by means of ME RT [4]. In addition, a 5-gram LM with KneserNey [19] smoothing and interpolation was built by means of the SRILM [20] toolkit. 4.2. DIALOG: Chinese–English system Table 1 shows the main statistics for the official training train and development dev partitions. Note that each of the translation directions has a different development set. In order to cope with this task, we used a combination of several systems. 89 Proceedings of the 7th International Workshop on Spoken Language Translation Paris,"
2010.iwslt-evaluation.10,P03-1056,0,0.0171263,"e development sets into the training data. Moreover, since the development sets are multi-reference, we decided to include all the references in the training for the phrase-based models but not for the language model since duplicating sentences distorts the LM estimates. The phrase-based models are not significantly distorted by this duplications and they are meaningfully enriched by synonym phrases. Based on previous experimentation [8], we decided to use linguistic information in the ITG-based system. In order to train the ITG, we used the Chinese and English versions of the Stanford Parser [21]. All the development sets were included in the training of the final system. The system for ASR and SMT coupling was created following the next procedure. To begin with, a phrase-based Moses system was trained for which the source was preprocessed to form sentences resembling the ASR input. To do that, the source was tokenized, then converted to lowercase and, finally, all punctuation marks were removed. In addition, several words were substituted to a normalised form since there was a mismatch between their training and ASR representations. Secondly, the lattices were preprocessed as well. A"
2012.eamt-1.5,J09-1002,1,0.806498,"Missing"
2012.eamt-1.5,N10-1078,0,0.465045,"Missing"
2013.iwslt-papers.4,D08-1065,0,0.34672,"nt ascent decoding, that, in our opinion, prevents the method from revealing its full potential. Here, we propose new decoding algorithms for MBRSC based on the dynamic programming [11] (DP) paradigm. We study two different approaches to compute the BLEU-based risk. On the one hand, we instantiate DP decoding to use the original BLEU risk over expected counts (§3) so our results are comparable to those in [3]. In practice, this approach is implemented as a beam search [12]. On the other hand, we implement an actual exact DP decoding using the linear approximation to the BLEU score proposed in [13] to compute the risk (§4). Then, we provide an extensive empirical study (§5) of the proposed decoding algorithms in comparison to the original MBRSC proposal. Finally, we conclude with a summary of our contributions. 2. Minimum Bayes’ Risk System Combination 2.1. MBRSC Model and Decision Function We now describe the original MBRSC proposal in [3]. Given K MT systems, MBRSC models the probability of a sentence y to be a translation of a source sentence x as a weighted ensemble [14]: P (y |x) = K X k=1 αk ·Pk (y |x) (1) where Pk (y |x) denotes the probability distribution over translations mode"
2013.iwslt-papers.4,P03-1021,0,0.0612223,"ric as loss function. The BLEU score B(y, y0 ) between a candidate translation y and a reference y0 is given by: 4 Y 0 B(y, y ) = ! 14 · φ(y, y0 ) 0 ρn (y, y ) (3) n=1 where ρn (y, y0 ) is the precision of n-grams of size n between y and y0 , and φ(y, y0 ) is a brevity penalty, that penalizes short translations: min(#w (y), #w (y0 )) P 0 ρn (y, y ) = w∈W n (y) P #w (y)   |y0 | 0 φ(y, y ) = min exp 1 − ,1 |y| translation not in the provided representation has zero probability of being generated by that system. Optimum values for scaling factors αk are estimated by minimum error rate training [16] optimizing BLEU on a separate development set. 2.2. MBRSC Decoding The direct implementation of Equation (6) has a high temporal complexity in O( |Y |2 ·I), where |Y |denotes the number of candidate translations, and I represents the maximum translation length given that B(y, y0 ) can be computed in O(max( |y |, |y0 |)) time. Since the number of candidate translations may be quite large, an exhaustive enumeration of all of them is often unfeasible. Gonz´alez-Rubio et. al [3] address this challenge by dividing Equation (6) into two sub-problems: the computation of the risk, namely the expected"
2013.iwslt-papers.4,P11-1127,1,0.195166,"uage processing systems. However, MT systems are still far from perfect [1]. The combination of multiple MT systems is a promising research direction to improve the quality of current MT technology. The key idea of system combination [2] is that it is often very difficult to find the real best system for the task at hand, while different systems can exhibit complementary strengths and limitations. Thus, a proper combination of systems could be more effective than using a single monolithic system. A simple, yet effective, system combination method for MT was proposed by Gonz´alez-Rubio et al., [3]. The authors describe minimum Bayes’ risk system combination (MBRSC), a method to combine the outputs of multiple MT systems into a consensus translation with maximum expected BLEU [4] score. Previous combination methods either implement sophisticated decision functions to select one of the provided translations [5, 6, 7], or generate new consensus translations by combining the best subsequences of the provided translations by means of a Viterbi-like search on a confusion network [8, 9, 10]. MBRSC aims at gathering together the advantages of sentence-selection and subsequence-combination meth"
2013.iwslt-papers.4,P09-1064,0,0.0175803,"ents the maximum translation length given that B(y, y0 ) can be computed in O(max( |y |, |y0 |)) time. Since the number of candidate translations may be quite large, an exhaustive enumeration of all of them is often unfeasible. Gonz´alez-Rubio et. al [3] address this challenge by dividing Equation (6) into two sub-problems: the computation of the risk, namely the expected BLEU score, of each translation, and the actual search for the optimal consensus translation (arg maxy∈Y ). Given that BLEU references the reference translation y0 only via its n-gram counts (see Equation (3)), MBRSC follows [17] to formalize an efficient alternative to the exact risk in Equation (6). Instead of computing the expected BLEU score of translation y, MBRSC computes the BLEU score of y with respect to the expected n-gram counts EP (y0 |x) [#w (y0 )] in the alternative candidate translations of x: R(y |x) = EP (y0 |x) [B(y, y0 )] e ≈ B(y, EP (y0 |x) [#w (y0 )]) (4) w∈W n (y)   (5) where W n (y) is the set of n-grams of size n in y, #w (y) is the count of n-gram w in y, and |y |denotes the length of translation y. BLEU is a percentage with a value of one denoting an exact match between y and y0 . Thus, we"
2013.iwslt-papers.4,P02-1040,0,0.100673,"T technology. The key idea of system combination [2] is that it is often very difficult to find the real best system for the task at hand, while different systems can exhibit complementary strengths and limitations. Thus, a proper combination of systems could be more effective than using a single monolithic system. A simple, yet effective, system combination method for MT was proposed by Gonz´alez-Rubio et al., [3]. The authors describe minimum Bayes’ risk system combination (MBRSC), a method to combine the outputs of multiple MT systems into a consensus translation with maximum expected BLEU [4] score. Previous combination methods either implement sophisticated decision functions to select one of the provided translations [5, 6, 7], or generate new consensus translations by combining the best subsequences of the provided translations by means of a Viterbi-like search on a confusion network [8, 9, 10]. MBRSC aims at gathering together the advantages of sentence-selection and subsequence-combination methods. In comparison to sentence-selection methods, MBRSC also implements a sophisticated minimum Bayes’ risk (MBR) classifier, and additionally, it is able to generate new consensus tran"
2013.iwslt-papers.4,N04-1022,0,0.253872,"tems share the same domain of translations (Y) which in practice it is not always true. In practice, MBRSC takes as input a representation, e.g. an N -best list, of the candidate translations of each system and assumes that any other = 4 Y ! 41 0 ρf n (y, EP (y0 |x) [#w (y )]) · n=1 e EP (y0 |x) [#w (y0 )]) φ(y, (7) where P (y0 |x) is the ensemble probability in Equation (1), and ρn (y, y0 ) and φ(y, y0 ) are reformulated as functions of expected n-gram counts. Regarding the actual search, MBRSC implements a two-step algorithm. First, it performs a conventional MBR sentence-selection decoding [18] to obtain an initial consensus translation. Then, a gradient ascent algorithm refines that initial solution by the iterative application of different edit operations (substitution, insertion, and deletion of single words) searching for an improvement in risk. Algorithm 1 depicts this gradient ascent decoding algorithm. Since the risk (R(y |x) in Equation (7)) can be computed in O(I)1 , the com1 Expected n-gram counts can be computed in advance. Algorithm 1: MBRSC gradient ascent search [3]. 5 6 7 8 9 10 : y0 (initial solution) Σ (target language vocabulary) I (maximum translation length) ˆ ,"
2013.iwslt-papers.4,P04-1063,0,0.0238026,"hand, while different systems can exhibit complementary strengths and limitations. Thus, a proper combination of systems could be more effective than using a single monolithic system. A simple, yet effective, system combination method for MT was proposed by Gonz´alez-Rubio et al., [3]. The authors describe minimum Bayes’ risk system combination (MBRSC), a method to combine the outputs of multiple MT systems into a consensus translation with maximum expected BLEU [4] score. Previous combination methods either implement sophisticated decision functions to select one of the provided translations [5, 6, 7], or generate new consensus translations by combining the best subsequences of the provided translations by means of a Viterbi-like search on a confusion network [8, 9, 10]. MBRSC aims at gathering together the advantages of sentence-selection and subsequence-combination methods. In comparison to sentence-selection methods, MBRSC also implements a sophisticated minimum Bayes’ risk (MBR) classifier, and additionally, it is able to generate new consensus translations that include the “best” subsequences from different individual translations. Regarding subsequence-combination methods, MBRSC can"
2013.iwslt-papers.4,N10-1141,0,0.0163318,"hand, while different systems can exhibit complementary strengths and limitations. Thus, a proper combination of systems could be more effective than using a single monolithic system. A simple, yet effective, system combination method for MT was proposed by Gonz´alez-Rubio et al., [3]. The authors describe minimum Bayes’ risk system combination (MBRSC), a method to combine the outputs of multiple MT systems into a consensus translation with maximum expected BLEU [4] score. Previous combination methods either implement sophisticated decision functions to select one of the provided translations [5, 6, 7], or generate new consensus translations by combining the best subsequences of the provided translations by means of a Viterbi-like search on a confusion network [8, 9, 10]. MBRSC aims at gathering together the advantages of sentence-selection and subsequence-combination methods. In comparison to sentence-selection methods, MBRSC also implements a sophisticated minimum Bayes’ risk (MBR) classifier, and additionally, it is able to generate new consensus translations that include the “best” subsequences from different individual translations. Regarding subsequence-combination methods, MBRSC can"
2013.iwslt-papers.4,C10-1036,0,0.0832847,"hand, while different systems can exhibit complementary strengths and limitations. Thus, a proper combination of systems could be more effective than using a single monolithic system. A simple, yet effective, system combination method for MT was proposed by Gonz´alez-Rubio et al., [3]. The authors describe minimum Bayes’ risk system combination (MBRSC), a method to combine the outputs of multiple MT systems into a consensus translation with maximum expected BLEU [4] score. Previous combination methods either implement sophisticated decision functions to select one of the provided translations [5, 6, 7], or generate new consensus translations by combining the best subsequences of the provided translations by means of a Viterbi-like search on a confusion network [8, 9, 10]. MBRSC aims at gathering together the advantages of sentence-selection and subsequence-combination methods. In comparison to sentence-selection methods, MBRSC also implements a sophisticated minimum Bayes’ risk (MBR) classifier, and additionally, it is able to generate new consensus translations that include the “best” subsequences from different individual translations. Regarding subsequence-combination methods, MBRSC can"
2013.iwslt-papers.4,N07-1029,0,0.0237707,"thic system. A simple, yet effective, system combination method for MT was proposed by Gonz´alez-Rubio et al., [3]. The authors describe minimum Bayes’ risk system combination (MBRSC), a method to combine the outputs of multiple MT systems into a consensus translation with maximum expected BLEU [4] score. Previous combination methods either implement sophisticated decision functions to select one of the provided translations [5, 6, 7], or generate new consensus translations by combining the best subsequences of the provided translations by means of a Viterbi-like search on a confusion network [8, 9, 10]. MBRSC aims at gathering together the advantages of sentence-selection and subsequence-combination methods. In comparison to sentence-selection methods, MBRSC also implements a sophisticated minimum Bayes’ risk (MBR) classifier, and additionally, it is able to generate new consensus translations that include the “best” subsequences from different individual translations. Regarding subsequence-combination methods, MBRSC can also generate new consensus translations different from the provided translations, and also, the final consensus translation has the best expected score with respect to the"
2013.iwslt-papers.4,D09-1125,0,0.0199053,"word y), ∆(y) (expansion words for hypothesis y), R(y |x) (complete score of y), Π(i, N ) (non-pruned states of size i) begin b ← 0; ˆ ← ””; Q Q(∅, ””) ← 0; y for i = 0 to I do forall (N p , yp ) ∈ Π(i, N ) do forall y ∈ ∆(yp ) do ye ← yp y; qe ← R(ye |x); if y == $ then b qˆ ← Q; if qe &gt; qˆ then b ← qe ; ˆ ← ye ; Q y input 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 else S N e ← N p Θ(yp , y); q ← Q(N e , ·); if qe &gt; q then Q(N e , ye ) ← qe ; b ˆ , Q; return y 17 end 16 is given by a combination of its score so far, and an estimate of the rest score to complete the translation. Similarly as done in [20], we perform a light decoding process (considering at each step only the single best expansion) to estimate the complete translation that can be obtained from each hypothesis. The score of these complete translations are then used as the complete scores R(y |x) of the partial hypotheses. Algorithm 2 shows the proposed beam search algorithm with pruning. It takes as input a source sentence x, the number of hypotheses to keep after pruning (M ), and the maximum translation length under consideration (I). We use some auxiliary functions: Θ(y, y) returns the set of new n-grams generated in the exp"
2013.iwslt-papers.4,2006.amta-papers.25,0,0.0381702,"carried out using uniform ensemble weights (αk in Equation (1)). This approach defines a controlled environment that assures a fair comparison between the different decoding algorithms. For each source sentence, we combined all the translation provided by the five individual systems, on average, about 450 translations. We used these translations to compute the expected n-gram counts EP (y0 |x) [#w (y0 )], and the n-grams expectations EP (y0 |x) [δw (y0 )] for each source sentence. 5.2. Assessment Measures We present translation quality results in terms of BLEU [4] (see Equation (3)), and TER [22]. TER measures the number of words that must be edited4 to convert the candidate translation into the reference translation. Since MBRSC is designed to optimize BLEU, we expect improvements in BLEU to be particularly important. TER scores are reported to independently assess BLEU results. We also measure the statistical significance of the results by bootstrap re-sampling [23]. 5.3. Preliminary Experiments We carried out a preliminary series of experiments to study how the number of hypotheses kept after pruning (M ) affects the performance of Algorithm 2 in terms of translation quality and de"
2013.iwslt-papers.4,2004.tmi-1.9,0,0.0634546,"counts EP (y0 |x) [#w (y0 )], and the n-grams expectations EP (y0 |x) [δw (y0 )] for each source sentence. 5.2. Assessment Measures We present translation quality results in terms of BLEU [4] (see Equation (3)), and TER [22]. TER measures the number of words that must be edited4 to convert the candidate translation into the reference translation. Since MBRSC is designed to optimize BLEU, we expect improvements in BLEU to be particularly important. TER scores are reported to independently assess BLEU results. We also measure the statistical significance of the results by bootstrap re-sampling [23]. 5.3. Preliminary Experiments We carried out a preliminary series of experiments to study how the number of hypotheses kept after pruning (M ) affects the performance of Algorithm 2 in terms of translation quality and decoding time5 . Figure 1 displays the quality of the generated consensus translations (on the left vertical axis) and the total decoding time (on the right vertical axis) as functions of M . We observed that decoding time increased linearly with M (note that M is log-scaled in Figure 1) while the quality of the consensus translations stayed approximately constant with slight im"
2013.iwslt-papers.4,W09-0401,0,\N,Missing
2013.iwslt-papers.5,2009.eamt-1.5,0,0.414993,"he soundness of our approach is assessed by the encouraging results obtained in an exhaustive experimentation with several feature sets. Moreover, the studied approach is highly-scalable allowing us to employ hundreds of features to predict translation quality. 1. Introduction Despite an intensive research in the last fifty years, machine translation (MT) systems are still far from perfect [1]. Hence, a desirable feature to improve their practical deployment is the capability of predicting at run-time1 the reliability of the generated translations. This task, referred to as quality estimation [2] (QE), is becoming a crucial component in practical MT systems [3, 1]. For instance, to decide if an automatic translation is worth being supervised by a translator or it should be translated from scratch. Quality can be estimated at the word, sentence, or document level. Here, we focus on the estimation of sentence-level quality. Sentence-level QE is typically addressed as a regression problem [4, 2]. Given a translation (and other sources of information), a set of features is extracted and used to build a model that predicts a quality score. This point of view provides a solid framework with"
2013.iwslt-papers.5,P10-2032,1,0.804658,"s obtained in an exhaustive experimentation with several feature sets. Moreover, the studied approach is highly-scalable allowing us to employ hundreds of features to predict translation quality. 1. Introduction Despite an intensive research in the last fifty years, machine translation (MT) systems are still far from perfect [1]. Hence, a desirable feature to improve their practical deployment is the capability of predicting at run-time1 the reliability of the generated translations. This task, referred to as quality estimation [2] (QE), is becoming a crucial component in practical MT systems [3, 1]. For instance, to decide if an automatic translation is worth being supervised by a translator or it should be translated from scratch. Quality can be estimated at the word, sentence, or document level. Here, we focus on the estimation of sentence-level quality. Sentence-level QE is typically addressed as a regression problem [4, 2]. Given a translation (and other sources of information), a set of features is extracted and used to build a model that predicts a quality score. This point of view provides a solid framework within which accurate predictors can be derived. However, several problem"
2013.iwslt-papers.5,C04-1046,0,0.0489425,"ce, a desirable feature to improve their practical deployment is the capability of predicting at run-time1 the reliability of the generated translations. This task, referred to as quality estimation [2] (QE), is becoming a crucial component in practical MT systems [3, 1]. For instance, to decide if an automatic translation is worth being supervised by a translator or it should be translated from scratch. Quality can be estimated at the word, sentence, or document level. Here, we focus on the estimation of sentence-level quality. Sentence-level QE is typically addressed as a regression problem [4, 2]. Given a translation (and other sources of information), a set of features is extracted and used to build a model that predicts a quality score. This point of view provides a solid framework within which accurate predictors can be derived. However, several problems arise when applying this approach to predict the quality of natural language sentences. For 1 That is, in the absence of reference translations. example, while the concept of translation quality is quite intuitive, the definition of features that reliably account for it has proven to be elusive [4, 1]. Thus, in practice, feature se"
2013.iwslt-papers.5,W12-3113,0,0.0944766,"linear and ambiguous features that hinder the learning process of the regression models, e.g., due to the “curse of dimensionality” [5]. An interesting approach to overcome these problems is to conceive QE as a two-step problem. In a first step, a dimensionality reduction (DR) process strips out the noise present in the original features returning a reduced set of (potentially new) features. Then, the actual quality prediction is made from this reduced set. Typically, QE systems reduce the dimensionality by simply selecting a subset of the original features according to some relevance measure [2, 6, 7]. However, a recent study [8] have shown that DR methods based on a projection of the original features may be more effective. The intuition for this is clear, the new features extracted by a projection-based DR method summarize the “information” contained in the all the original features, in contrast, the information contained in the features discarded by a feature selection method is inevitably lost. We work on the foundations of [8] and provide an exhaustive empirical study of the most successful QE approach described there. This approach (§2) involves a DR method based on a partial least s"
2013.iwslt-papers.5,W12-3118,0,0.257715,"linear and ambiguous features that hinder the learning process of the regression models, e.g., due to the “curse of dimensionality” [5]. An interesting approach to overcome these problems is to conceive QE as a two-step problem. In a first step, a dimensionality reduction (DR) process strips out the noise present in the original features returning a reduced set of (potentially new) features. Then, the actual quality prediction is made from this reduced set. Typically, QE systems reduce the dimensionality by simply selecting a subset of the original features according to some relevance measure [2, 6, 7]. However, a recent study [8] have shown that DR methods based on a projection of the original features may be more effective. The intuition for this is clear, the new features extracted by a projection-based DR method summarize the “information” contained in the all the original features, in contrast, the information contained in the features discarded by a feature selection method is inevitably lost. We work on the foundations of [8] and provide an exhaustive empirical study of the most successful QE approach described there. This approach (§2) involves a DR method based on a partial least s"
2013.iwslt-papers.5,W12-3117,0,0.0623879,"Missing"
2013.iwslt-papers.5,W12-3114,0,0.0202393,"by the organizers [1]. DCU-SYMC: [15] 308 features including features based on latent Dirichlet allocation; source grammatical features from the TreeTagger part-of-speech tagger, an English grammar, the XLE parser, and the Brown re-ranking parser; and target TreeTagger features. LORIA: [6] 66 features including the baseline features, and features based on cross-lingual triggers. SDLLW: [7] 15 features exhaustively selected from an original set of 45 features: the 17 baseline features, 8 features based on decoder information, and 20 features based on n-gram precisions and word alignments. TCD: [16] 43 features including the baseline features, and features based on similarity measures with respect to the Google n-grams data set. UEDIN: [17] 56 features including the baseline features and features based on named entities, morphological information, lexicon probabilities, wordalignments, and sentence and n-grams similarities. UPV: [18] 497 features including the baseline features and features based on word-level quality scores. UU: [19] 82 features computed from syntactic, constituency, and dependency trees. WLV-SHEF: [20] 147 features based on part-ofspeech information, subject-verb agree"
2013.iwslt-papers.5,W12-3109,0,0.0139756,"TreeTagger part-of-speech tagger, an English grammar, the XLE parser, and the Brown re-ranking parser; and target TreeTagger features. LORIA: [6] 66 features including the baseline features, and features based on cross-lingual triggers. SDLLW: [7] 15 features exhaustively selected from an original set of 45 features: the 17 baseline features, 8 features based on decoder information, and 20 features based on n-gram precisions and word alignments. TCD: [16] 43 features including the baseline features, and features based on similarity measures with respect to the Google n-grams data set. UEDIN: [17] 56 features including the baseline features and features based on named entities, morphological information, lexicon probabilities, wordalignments, and sentence and n-grams similarities. UPV: [18] 497 features including the baseline features and features based on word-level quality scores. UU: [19] 82 features computed from syntactic, constituency, and dependency trees. WLV-SHEF: [20] 147 features based on part-ofspeech information, subject-verb agreement, phrase constituency and target lexicon analysis. 3.3. Experimental Methodology For each feature set, a QE system was built following the t"
2013.iwslt-papers.5,W12-3111,1,0.840099,"eatures based on cross-lingual triggers. SDLLW: [7] 15 features exhaustively selected from an original set of 45 features: the 17 baseline features, 8 features based on decoder information, and 20 features based on n-gram precisions and word alignments. TCD: [16] 43 features including the baseline features, and features based on similarity measures with respect to the Google n-grams data set. UEDIN: [17] 56 features including the baseline features and features based on named entities, morphological information, lexicon probabilities, wordalignments, and sentence and n-grams similarities. UPV: [18] 497 features including the baseline features and features based on word-level quality scores. UU: [19] 82 features computed from syntactic, constituency, and dependency trees. WLV-SHEF: [20] 147 features based on part-ofspeech information, subject-verb agreement, phrase constituency and target lexicon analysis. 3.3. Experimental Methodology For each feature set, a QE system was built following the two-step methodology described in §2 and depicted Baseline RMSE #features Feature set DCU-SYMC LORIA SDLLW TCD UEDIN UPV UU WLV-SHEF 0.71±0.02 0.72±0.03 0.67±0.02 0.76±0.01 0.72±0.03 0.74±0.02 0.72±"
2013.iwslt-papers.5,W12-3112,0,0.0239649,"set of 45 features: the 17 baseline features, 8 features based on decoder information, and 20 features based on n-gram precisions and word alignments. TCD: [16] 43 features including the baseline features, and features based on similarity measures with respect to the Google n-grams data set. UEDIN: [17] 56 features including the baseline features and features based on named entities, morphological information, lexicon probabilities, wordalignments, and sentence and n-grams similarities. UPV: [18] 497 features including the baseline features and features based on word-level quality scores. UU: [19] 82 features computed from syntactic, constituency, and dependency trees. WLV-SHEF: [20] 147 features based on part-ofspeech information, subject-verb agreement, phrase constituency and target lexicon analysis. 3.3. Experimental Methodology For each feature set, a QE system was built following the two-step methodology described in §2 and depicted Baseline RMSE #features Feature set DCU-SYMC LORIA SDLLW TCD UEDIN UPV UU WLV-SHEF 0.71±0.02 0.72±0.03 0.67±0.02 0.76±0.01 0.72±0.03 0.74±0.02 0.72±0.02 0.71±0.02 308 49 15 43 56 497 82 147 RMSE 0.70±0.02 0.75±0.01 0.67±0.02 0.74±0.02 0.71±0.02 0.69±0"
2013.iwslt-papers.5,W12-3110,0,0.0368655,"Missing"
2013.iwslt-papers.5,2004.tmi-1.9,0,0.0549162,"previous QE works [2, 1], we calculate the root-meansquared error (RMSE) between them: v u n u1 X RMSE(ˆ y, y) = t (yi − yˆi )2 (5) n i=1 where n is the number of samples. RMSE quantifies the average error of the estimation with respect to the actual quality score. I.e. the lower the value, the better the performance of the QE system. Additionally, we perform different significance tests for the reported RMSE results. On the one hand, we obtain confidence intervals for the averaged crossvalidation test results with Student’s t-tests [21]. On the other hand, we use paired bootstrap re-sampling [22] to measure the significance of the RMSE differences observed between the different methods in the test sets. 4. Results We now present the results of the empirical evaluation of the studied QE approach. First, we predicted quality scores for each of the feature sets described in §3.2. Then, we took advantage of the scalability of the studied QE approach using jointly all the features in those sets to perform the prediction. 4.1. Results for the Individual Feature Sets Table 2 shows the cross-validation results (RMSE and number of LVs) obtained for the different feature sets. As a comparison,"
2013.mtsummit-user.9,2012.eamt-1.5,1,0.872324,"Missing"
2013.mtsummit-user.9,J09-1002,1,0.930598,"Missing"
2013.mtsummit-user.9,N10-1078,0,0.0353669,"Missing"
2013.mtsummit-user.9,J10-4005,0,0.0567722,"Missing"
2013.mtsummit-user.9,2012.tc-1.7,1,0.791077,"Missing"
2013.mtsummit-user.9,J93-2003,0,0.0199596,"the suggested translation. 3.4 Search and Replace Most of the computer-assisted translation tools provide the user with intelligent search and replace functions for fast text revision. The C AS M AC AT workbench also features a straightforward function to run search and replacement rules on the fly. Whenever a new replacement rule is created, it is automatically populated to the forthcoming predictions made by the system, so that the user only needs to specify them once. 3.5 Word Alignment Information Alignment of source and target information is an important part of the translation process (Brown et al., 1993). In order to display the correspondences between both the source and target words, this feature was implemented in a way that every time the user places the mouse (yellow) or the text cursor (cyan) on a word, the alignments made by the system are highlighted. ............................................. 3.6 Prediction Rejection With the purpose of easing user interaction, our prototype also supports a mouse wheel rejection feature (Sanchis-Trilles et al., 2008). By scrolling Figure 1: Screenshot of our workbench with all its features enabled. the mouse wheel over a word, the system invalidat"
2013.mtsummit-user.9,2010.eamt-1.19,0,0.0609977,"Missing"
2013.mtsummit-user.9,2010.eamt-1.18,1,0.86052,"Missing"
2013.mtsummit-user.9,D08-1051,1,0.805921,"Missing"
2013.mtsummit-user.9,J85-2003,0,0.371196,"Missing"
2013.mtsummit-user.9,W00-0507,0,\N,Missing
2013.mtsummit-wptp.7,2005.mtsummit-papers.19,1,0.838299,"Missing"
2013.mtsummit-wptp.7,2011.eamt-1.2,0,0.108581,"Missing"
2013.mtsummit-wptp.7,D08-1051,1,0.880745,"Missing"
2013.mtsummit-wptp.7,2011.eamt-1.7,0,0.022484,"Missing"
2013.mtsummit-wptp.7,2012.eamt-1.5,1,0.870892,"Missing"
2013.mtsummit-wptp.7,J09-1002,1,0.927174,"Missing"
2013.mtsummit-wptp.7,J93-2003,0,0.0316225,"user with intelligent search and replace functions for fast text revision. Our workbench features a straightforward function to run search and replacement rules on the fly. Whenever a new replacement rule is created, it is automatically populated to the forthcoming predictions made by the system, so that the Javascript ............................................ PHP HTTP GUI web server Figure 5: Visualization of Word Alignment HTTP web socket user only needs to specify them once. Word Alignment Information Alignment of source and target words is an important part of the translation process (Brown et al., 1993). In order to display the correspondences between both the source and target words, this feature was implemented in a way that every time the user places the mouse (yellow) or the text cursor (cyan) on a word, the alignments made by the system are highlighted. See Figure 5 for a screenshot. Prediction Rejection With the purpose of easing user interaction, our workbench also supports a one-click rejection feature (Sanchis-Trilles et al., 2008). This invalidates the current prediction for the sentence that is being translated, and provides the user with an alternate one, in which the first new w"
2013.mtsummit-wptp.7,2012.amta-papers.22,0,0.266531,"Missing"
2013.mtsummit-wptp.7,2010.eamt-1.18,1,0.875303,"Missing"
2013.mtsummit-wptp.7,N10-1078,1,0.886215,"Missing"
2013.mtsummit-wptp.7,P07-2045,1,0.00695691,"swapped out workbench may be use partially, for instance in the following fashion: • As part of a larger localization workflow with existing editing facilities, only the capabilities of the CASMACAT CAT server and CAS MACAT MT server are used. A legacy editing tool is extended to make calls to the CAT server and thus benefit from additional functionality. • If an existing customized MT translation solution is already in place, then the CASMACAT front-end and CAT server can connect to it. Already, the currently implemented CASMACAT workbench supports two different MT server components, Moses (Koehn et al., 2007) and Thot (Ortiz-Mart´ınez et al., 2005). 3.1 CAT Server The CAT server is implemented in Python with the Tornadio library. It uses socket.io to keep a web socket connection with the Javascript GUI. Keep in mind that especially interactive translation prediction requires very quick responses from the server. Establishing an HTTP connection through an Ajax call every time the user presses a key would cause significant overhead. A typical session with interactive translation prediction takes place as follows: • The user moves to a new segment in the GUI. • The GUI sends a startSession request to"
2013.mtsummit-wptp.7,W00-0507,0,0.528068,"Missing"
2014.amta-workshop.1,J09-1002,1,0.892052,"Missing"
2014.amta-workshop.1,2013.mtsummit-papers.5,0,0.0291651,"entence has been correctly translated. The C AS M AC AT workbench further extends the ITP approach by introducing two new features, namely, online and active learning. These two new features are designed to allow the system to take further advantage from user feedback. Specifically, the SMT models are updated in real time from the target translations validated by the user, preventing the system from repeating errors in the translation of similar sentences. Despite the strong potential of these features to improve the user experience (Ortiz-Mart´ınez et al., 2010; Gonz´alez-Rubio et al., 2012; Bertoldi et al., 2013; Denkowski et al., 2014), they are still not widely implemented in CAT systems. To the best of our knowledge, the only exception is (Ortiz-Mart´ınez et al., 2011) where the authors describe the implementation of online learning within an ITP system. The present study reports on the results and user evaluation of the C AS M AC AT workbench under three different conditions: 1) basic ITP, 2) ITP with online learning, and 3) ITP with active learning. The ultimate aim of testing these different configurations was to assess their potential in real world post-editing scenarios and decide which of th"
2014.amta-workshop.1,E14-1042,0,0.0148376,"tly translated. The C AS M AC AT workbench further extends the ITP approach by introducing two new features, namely, online and active learning. These two new features are designed to allow the system to take further advantage from user feedback. Specifically, the SMT models are updated in real time from the target translations validated by the user, preventing the system from repeating errors in the translation of similar sentences. Despite the strong potential of these features to improve the user experience (Ortiz-Mart´ınez et al., 2010; Gonz´alez-Rubio et al., 2012; Bertoldi et al., 2013; Denkowski et al., 2014), they are still not widely implemented in CAT systems. To the best of our knowledge, the only exception is (Ortiz-Mart´ınez et al., 2011) where the authors describe the implementation of online learning within an ITP system. The present study reports on the results and user evaluation of the C AS M AC AT workbench under three different conditions: 1) basic ITP, 2) ITP with online learning, and 3) ITP with active learning. The ultimate aim of testing these different configurations was to assess their potential in real world post-editing scenarios and decide which of them can be successfully in"
2014.amta-workshop.1,E12-1025,1,0.893795,"Missing"
2014.amta-workshop.1,E14-2012,1,0.760176,"Missing"
2014.amta-workshop.1,N10-1079,1,0.890321,"Missing"
2014.amta-workshop.1,P11-4012,1,0.887221,"Missing"
2014.eamt-1.5,P80-1024,0,0.543994,"Missing"
2014.eamt-1.5,J03-1002,0,0.00517672,"the default threshold and histogram pruning parameters, i.e., 200 for the histogram pruning (200 maximum stack size) and 0.00001 for threshold pruning (hypothesis with a score less than 0.00001 times the best hypothesis are discarded). The weights of the log-linear combination are optimised by means of the Minimum Error Rate Training (MERT) procedure (Och, 2003). The phrase-based translation model provides direct and inverted frequency-based and lexicalbased probabilities for each phrase pair in the phrase table. Phrase pairs are extracted from symmetrised word alignments generated by GIZA++ (Och and Ney, 2003). A 5-gram wordbased LM is estimated on the target side of the parallel corpora using the improved KneserNey smoothing (Chen and Goodman, 1999). 5.2 System Description For building the final ITP system, initial translation models were built by means of the open source Moses toolkit (Koehn et al., 2007)1 . Then, the Moses decoder was also used for generating the wordgraphs. For doing this, the standard decoder configuration was used, i.e. a statistical log-linear model including a phrase-based translation model, a language model, a distortion model and word 1 Sentences Run. words Vocabulary Sen"
2014.eamt-1.5,J09-1002,1,0.946416,"Missing"
2014.eamt-1.5,E03-1032,0,0.694815,"the user-defined prefix p and the hypothesised translation t, so that the unaligned words of t, in an appropriate order, constitute the suffix searched in ITP. This allows us to rewrite the error correction probability as follows: X Pr(p, a |t) (10) Pr(p |t) = (4) (5) (6) Note that, since p ts = t, this equation is very similar to Equation (2). The main difference is that now the search process is restricted to those target sentences t that contain p as prefix. This implies that we can use the same MT models (including the log-linear approach) if the search procedures are adequately modified (Och et al., 2003a). Finally, it should be noted that the statistical models are usually defined at word level, while the ITP process described in this section works at character level. To deal with this problem, during the search process it is necessary to verify the compatibility between t and p at character level. 2.3 (8) The following na¨ıve Bayes’ assumption is now made: the source sentence s and the user prefix p are statistically independent variables given the translation t, obtaining: which can be straightforwardly rewritten as: ˆts = arg max Pr(p, ts |s) (7) a To simplify things, we assume that p is"
2014.eamt-1.5,2005.eamt-1.6,0,0.51215,"hypothesis for that subset are removed. The specific percentage used corresponds to the pruning threshold parameter. Related Work The use of wordgraphs in SMT was introduced in (Ueffing et al., 2002) for single word models and later extended to phrase-based models in (Zens and Ney, 2005). However, in these works, wordgraphs were applied within a fully-automatic SMT context. The first study on wordgraphs for ITP was given in (Och et al., 2003b). In that work, wordgraph pruning is used to speed-up suffix generation in an early ITP system based on the alignment template formalism. Bender et al. (Bender et al., 2005) extended the same strategy to a phrase-based ITP system with ad-hoc error correction techniques (see Section 2.3). Here, we propose efficient wordgraph pruning techniques for a state-of-the-art ITP system with stochastic error correction. 4 Modifying Wordgraph Size in Decoding Time • Histogram Pruning: the idea behind histogram pruning is to order those hypotheses that share the same number of already aligned source words by descending order of their scores, keeping only a certain quantity of the best of them. 4.2 Wordgraph Pruning Threshold and histogram pruning constitute two possible techn"
2014.eamt-1.5,P03-1021,0,0.0265317,"un. words 79.4k 74.8k OoV words 444 537 Table 2: Statistics of the WMT 2011 test data used to evaluate the system. These statistics are computed in tokenised and de-truecased conditions. and phrase penalties. The baseline system was set up using the default threshold and histogram pruning parameters, i.e., 200 for the histogram pruning (200 maximum stack size) and 0.00001 for threshold pruning (hypothesis with a score less than 0.00001 times the best hypothesis are discarded). The weights of the log-linear combination are optimised by means of the Minimum Error Rate Training (MERT) procedure (Och, 2003). The phrase-based translation model provides direct and inverted frequency-based and lexicalbased probabilities for each phrase pair in the phrase table. Phrase pairs are extracted from symmetrised word alignments generated by GIZA++ (Och and Ney, 2003). A 5-gram wordbased LM is estimated on the target side of the parallel corpora using the improved KneserNey smoothing (Chen and Goodman, 1999). 5.2 System Description For building the final ITP system, initial translation models were built by means of the open source Moses toolkit (Koehn et al., 2007)1 . Then, the Moses decoder was also used f"
2014.eamt-1.5,E14-2012,1,0.87815,"Missing"
2014.eamt-1.5,J93-2003,0,0.0381959,"CBY-ND. 27 source (s): Para ver la lista de recursos desired translation (ˆt): To view a listing of resources the quality of the pruned wordgraphs and the response time associated. Finally, Section 6 presents the conclusions of the present work. 2 IT-0 p To view IT-1 k a ts Statistical Framework 2.1 Statistical Machine Translation p To view a IT-2 k ts Given a sentence s in a source language, the discipline of machine translation (MT) studies techniques to obtain its corresponding translation t in a target language by means of computer. Statistical MT (SMT) formalises this problem as follows (Brown et al., 1993): ˆt = arg max Pr(t |s) t = arg max Pr(t) · Pr(s |t) t (1) list list of resources list list i list i ng resources p To view a IT-3 k ts listing END p To view a listing o of resources of resources Figure 1: ITP session to translate a Spanish sentence into English. The desired translation is the translation the human user wants to obtain. At IT0, the system suggests a translation (ts ). At IT-1, the user moves the mouse to accept the first eight characters “To view ” and presses the a key (k), then the system suggests completing the sentence with “list of resources” (a new ts ). Iterations 2 and"
2014.eamt-1.5,2001.mtsummit-papers.68,0,0.0298335,"equired to amend the hypotheses, as measured by KSMR, does not increase, and even presents a slight improvement for threshold values of 0.2 and 0.4 (equivalent to 21.3k and 9.6k edges on average, respectively). However, such improvement is not statistically significant and might be due to the effect of the stochastic error correction described in 5.3 Assessment Metrics The results produced by the ITP systems associated to the different wordgraph size reduction strategies were evaluated both in terms of conventional SMT metrics and ITP metrics. More specifically, the metrics used were: • BLEU (Papineni et al., 2001) (Bilingual Language Evaluation Understudy) is an SMT precision metric that measures precision of unigrams, bigrams, trigrams and 4-grams, with a penalty for sentences that are too short. • TER (Snover et al., 2006) (Translation Edit Rate) is an SMT error metric that computes the minimum number of edits required to modify the system hypotheses so that they match the references. Possible edits include insertion, deletion, substitution of single words and shifts of word sequences. • KSMR (Barrachina et al., 2009) (Key Stroke Mouse-action Ratio) is an ITP error metric 2 Results Available from htt"
2014.eamt-1.5,D13-1025,1,0.896416,"Missing"
2014.eamt-1.5,2006.amta-papers.25,0,0.0290045,"r, such improvement is not statistically significant and might be due to the effect of the stochastic error correction described in 5.3 Assessment Metrics The results produced by the ITP systems associated to the different wordgraph size reduction strategies were evaluated both in terms of conventional SMT metrics and ITP metrics. More specifically, the metrics used were: • BLEU (Papineni et al., 2001) (Bilingual Language Evaluation Understudy) is an SMT precision metric that measures precision of unigrams, bigrams, trigrams and 4-grams, with a penalty for sentences that are too short. • TER (Snover et al., 2006) (Translation Edit Rate) is an SMT error metric that computes the minimum number of edits required to modify the system hypotheses so that they match the references. Possible edits include insertion, deletion, substitution of single words and shifts of word sequences. • KSMR (Barrachina et al., 2009) (Key Stroke Mouse-action Ratio) is an ITP error metric 2 Results Available from https://github.com/daormar/thot/ 32 tions was not parallelised (i.e., each ITP simulation was executed sequentially). As shown, the complete wordgraph presents response times which are too high for a system set for onl"
2014.eamt-1.5,N03-1017,0,0.0234538,"A given partial hypothesis aligns a certain number of source words with words of the target language, and the rest remain unaligned. These hypotheses are stored in a stack (or priority queue) and ordered by their score. Such a score is given by the loglinear combination of feature functions. n=1 where fn (t, s) can be any model that represents an important feature for the translation, N is the number of models (or features), and λn are the weights of the log-linear combination. One of the most popular instantiations of loglinear models is that including phrase-based models (Zens et al., 2002; Koehn et al., 2003) (Zens et al., 2002; Koehn et al., 2003). Phrase-based models allow to capture contextual information to learn translations for whole phrases instead of single words. The basic idea of phrase-based translation is to segment the source sentence into phrases, then to translate each source phrase into a target phrase, and finally to reorder the translated target phrases in order to compose the target sentence. Phrase-based models were employed throughout this work. In log-linear models, the maximisation problem stated by Equation 3 is typically solved by means of dynamic programming-based algorit"
2014.eamt-1.5,W02-1021,0,0.086551,"ystem, their size would be smaller if the search space is reduced as well. Another possibility to reduce the number of states contained in the wordgraph would be to apply pruning techniques directly over it. Common ITP implementations rely on a wordgraph data structure that represents possible translations of the given source sentence. A wordgraph is a weighted directed acyclic graph, in which each node represents a partial translation hypothesis and each edge is labelled with a word (or group of words) of the target sentence and is weighted according to the scores given by an SMT model (see (Ueffing et al., 2002) for more details). The use of wordgraphs in ITP has been studied in (Barrachina et al., 2009; Ortiz-Mart´ınez, 2011; Gonz´alez-Rubio et al., 2013) in combination with different translation techniques. The main advantage of wordgraph-based ITP systems is their efficiency in terms of the time cost per each interaction. This is due to the fact that the wordgraph is generated only once at the beginning of the interactive translation process of a given source sentence, and the suffixes required in ITP can be obtained by incrementally processing this wordgraph at each interaction. All of the experi"
2014.eamt-1.5,W05-0834,0,0.0393268,"ly, threshold pruning and histogram pruning (Och and Ney, 2002): • Threshold Pruning: threshold pruning is applied for the different subsets of partial hypotheses that share the same number of already aligned source words. For a given subset, all those hypotheses whose score is below a certain percentage of the score of the best hypothesis for that subset are removed. The specific percentage used corresponds to the pruning threshold parameter. Related Work The use of wordgraphs in SMT was introduced in (Ueffing et al., 2002) for single word models and later extended to phrase-based models in (Zens and Ney, 2005). However, in these works, wordgraphs were applied within a fully-automatic SMT context. The first study on wordgraphs for ITP was given in (Och et al., 2003b). In that work, wordgraph pruning is used to speed-up suffix generation in an early ITP system based on the alignment template formalism. Bender et al. (Bender et al., 2005) extended the same strategy to a phrase-based ITP system with ad-hoc error correction techniques (see Section 2.3). Here, we propose efficient wordgraph pruning techniques for a state-of-the-art ITP system with stochastic error correction. 4 Modifying Wordgraph Size i"
2014.eamt-1.5,P07-2045,0,0.0127786,"Missing"
2014.eamt-1.5,2002.tmi-tutorials.2,0,0.0514509,"solved separately. A given partial hypothesis aligns a certain number of source words with words of the target language, and the rest remain unaligned. These hypotheses are stored in a stack (or priority queue) and ordered by their score. Such a score is given by the loglinear combination of feature functions. n=1 where fn (t, s) can be any model that represents an important feature for the translation, N is the number of models (or features), and λn are the weights of the log-linear combination. One of the most popular instantiations of loglinear models is that including phrase-based models (Zens et al., 2002; Koehn et al., 2003) (Zens et al., 2002; Koehn et al., 2003). Phrase-based models allow to capture contextual information to learn translations for whole phrases instead of single words. The basic idea of phrase-based translation is to segment the source sentence into phrases, then to translate each source phrase into a target phrase, and finally to reorder the translated target phrases in order to compose the target sentence. Phrase-based models were employed throughout this work. In log-linear models, the maximisation problem stated by Equation 3 is typically solved by means of dynamic prog"
2014.eamt-1.5,P02-1038,0,0.653053,"” and presses the a key (k), then the system suggests completing the sentence with “list of resources” (a new ts ). Iterations 2 and 3 are similar. In the final iteration, the user accepts the current translation. (2) The terms in the latter equation are the language model probability Pr(t) that represents the well-formedness of t (n-gram models are usually adopted), and the translation model Pr(s |t) that represents the relationship between the source sentence and its translation. In practice, all of these models (and possibly others) are often combined into a log-linear model for Pr(t |s) (Och and Ney, 2002): (N ) X ˆt = arg max λn · log(fn (t, s)) (3) t p ts To view the resources solutions or hypotheses that are solved separately. A given partial hypothesis aligns a certain number of source words with words of the target language, and the rest remain unaligned. These hypotheses are stored in a stack (or priority queue) and ordered by their score. Such a score is given by the loglinear combination of feature functions. n=1 where fn (t, s) can be any model that represents an important feature for the translation, N is the number of models (or features), and λn are the weights of the log-linear com"
2020.eamt-1.34,C14-1106,0,0.0182717,".0 ,30.0 ) [30.0 [20.0 0 ,20.0 ) [10.0 ,90.0 ) >=90 .0 ) [80.0 ) ,80.0 ,70.0 [70.0 ) BLEU [60.0 ) ,60.0 ,50.0 [50.0 ) [40.0 ) ,40.0 ,30.0 [30.0 ) ,20.0 [20.0 [10.0 &lt;10. 0 0 &lt;10. Count 80 (b) Document 2. Figure 3: Histogram of sentence-level BLEU scores. The counts are distributed in buckets of range 10. to solve those particularities, their personal criteria may had an impact in the evaluation results. 4.3 On differences in the generation Next, we compare both adaptive and static systems in terms of the translations generated. To this end, we employed the discriminative language model method (Akabe et al., 2014) implemented in the compare-mt (Neubig et al., 2019) tool, comparing sentence-level BLEU and word n-grams. In terms of translation quality, we show a histogram of sentence-level BLEU scores in Fig. 3. For both documents, we observe similar trends: the static system generated low-scored sentences more frequently than the adaptive systems. The adaptive systems placed more hypotheses from bucket [50, 60) onward, for both test documents. Moreover, the differences in frequencies between adaptive and static systems were kept at a similar proportion along all high-score buckets. Hence, adaptive syste"
2020.eamt-1.34,aziz-etal-2012-pet,0,0.014741,"d that, in some cases, there were occurrences of some made-up words. In this work, we study the impact of this phenomenon. Additionally, we extend their user study by involving three more participants and providing additional measures for the increase in productivity gained with the adaptive system. 2 Related work Post-editing MT hypotheses is a practice that was adopted in the translation industry a long time ago (e.g., Vasconcellos and León, 1985). Its relevance grew as MT technology advanced and improved. The capabilities of MT post-editing have been demonstrated through many user studies (Aziz et al., 2012; Bentivogli et al., 2016; Castilho et al., 2017; Green et al., 2013a). Parallel to the rise of the post-editing protocol, using user post-edits to adapt MT systems has also attracted the attention of researches and industry. This was studied in the CasMaCAT (Alabau et al., 2013) and MateCAT (Federico et al., 2014) projects and phrase-based statistical MT systems based on online learning were developed (Ortiz-Martínez, 2016). With the breakthrough in neural MT (NMT) technology (Bahdanau et al., 2015; Wu et al., 2016; Vaswani et al., 2017), research shifted towards constructing adaptive systems"
2020.eamt-1.34,W19-6732,1,0.828897,"ues are the average between both evaluators. Adaptive Static 80 Adaptive Static 60 50 40 Count Count 60 40 30 20 20 10 (a) Document 1. 1 Fluency 2 3 4 1 Fluency 2 3 0 4 0 (b) Document 2. Figure 2: Sentence-level fluency scores. Count values are the average between both evaluators. human evaluation was conducted with the help of two professional translators—who had not taken part in the user study. In this evaluation, the evaluators were given a source sentence and the post-edits produced by each user—three of which had used the static system, and the other three the adaptive system. Following Castilho et al. (2019) and TAUS adequacy/fluency guidelines1 , they were asked to assess, on a 4-point scale, the adequacy (how much of the meaning is represented in the translation) and the fluency (the extent to which the translation is well-formed grammatically, has correct spellings, adheres to common use of terms, titles and names, is intuitively acceptable and can be sensibly interpreted by a native speaker) of each post-edit. In total, they evaluated 600 sentences: the post-edits of the first 50 sentences of Document 1 and the postedits from the first 50 sentences of Document 2 (see Section 3). To avoid bias"
2020.eamt-1.34,W14-3346,0,0.0263639,"the productivity metrics and user behavior. 3.1 Evaluation We evaluated two main aspects of the adaptation process: productivity of the post-editors and quality of the NMT systems. The former was assessed by computing the average post-editing time per sentence and the number of words generated by the post-editor per hour. For the latter, we employed two well-known MT metrics: (h)BLEU (Papineni et al., 2002) and (h)TER (Snover et al., 2006). In order to ensure consistent BLEU scores, we used sacreBLEU (Post, 2018). Since we computed per-sentence BLEU scores, we used exponential BLEU smoothing (Chen and Cherry, 2014). We applied approximate randomization tests (Riezler and Maxwell, 2005), with 10, 000 repetitions and a pvalue of 0.05, to determine whether two systems presented statistically significant differences. 3.2 Human post-editors Six professional translators were involved in the experiment. Some profiling details about them can be found in Table 2. User Sex Age Professional experience User 1 User 2 User 3 User 4 User 5 User 6 Male Female Female Female Female Male 24 25 30 24 22 48 1.5 years 5 years 5 years 1 month 1 year 22 years Table 2: Information about the human post-editors that took part in"
2020.eamt-1.34,E14-1042,0,0.0175731,"topic that Corpus Training Document 1 Document 2 #Sentences 23.4M 150 150 # Tokens En 702M 1.7K 2.6K Es 786M - # Types En 1.8M 618 752 Es 1.9M - Average length En 30.0 11.3 17.3 Es 33.6 - Table 1: Corpora statistics in terms of number of sentences, number of tokens, number of types (vocabulary size) and average sentence length. K denotes thousands and M, millions. is currently being actively researched (e.g., Toral, 2019; Freitag et al., 2020; Läubli et al., 2020). Several works conducted user studies for MT post-editing systems, either phrase-based (Alabau et al., 2013; Green et al., 2013b; Denkowski et al., 2014; Bentivogli et al., 2016) or NMT (Daems and Macken, 2019; Koponen et al., 2019; Jia et al., 2019). Moreover, two studies showed improvements in terms of productivity time and translation quality with the application of an online learning protocol (Karimova et al., 2018; Domingo et al., 2019b). This latter study is tightly related to ours. We extend it by performing a finer-grained evaluation of the outputs of the adaptive systems. 3 Experimental framework As we extended the work of Domingo et al. (2019b), we used their same data and systems. The task at hand consisted of a small medico-techni"
2020.eamt-1.34,P19-3012,1,0.87681,"Commons 3.0 licence, no derivative works, attribution, CCBY-ND. tem towards a given domain or the style of the posteditor. A common way of achieving this consists in following an online-learning paradigm (Ortiz-Martínez, 2016; Peris and Casacuberta, 2019). Each time the user validates a post-edit, the system’s models are updated incrementally with this new sample. Hence, when the system generates the next translation, it will consider the previous post-edits made by the user and it is expected to produce higher quality translations (or, at least, more suited to the post-editor’s preferences). Domingo et al. (2019b) conducted a preliminary user study for professional post-editors, who had a positive perception of the adaptive systems. However, they noticed that, in some cases, there were occurrences of some made-up words. In this work, we study the impact of this phenomenon. Additionally, we extend their user study by involving three more participants and providing additional measures for the increase in productivity gained with the adaptive system. 2 Related work Post-editing MT hypotheses is a practice that was adopted in the translation industry a long time ago (e.g., Vasconcellos and León, 1985). I"
2020.eamt-1.34,W19-6737,1,0.222078,"Commons 3.0 licence, no derivative works, attribution, CCBY-ND. tem towards a given domain or the style of the posteditor. A common way of achieving this consists in following an online-learning paradigm (Ortiz-Martínez, 2016; Peris and Casacuberta, 2019). Each time the user validates a post-edit, the system’s models are updated incrementally with this new sample. Hence, when the system generates the next translation, it will consider the previous post-edits made by the user and it is expected to produce higher quality translations (or, at least, more suited to the post-editor’s preferences). Domingo et al. (2019b) conducted a preliminary user study for professional post-editors, who had a positive perception of the adaptive systems. However, they noticed that, in some cases, there were occurrences of some made-up words. In this work, we study the impact of this phenomenon. Additionally, we extend their user study by involving three more participants and providing additional measures for the increase in productivity gained with the adaptive system. 2 Related work Post-editing MT hypotheses is a practice that was adopted in the translation industry a long time ago (e.g., Vasconcellos and León, 1985). I"
2020.eamt-1.34,C14-2028,0,0.0303499,"work Post-editing MT hypotheses is a practice that was adopted in the translation industry a long time ago (e.g., Vasconcellos and León, 1985). Its relevance grew as MT technology advanced and improved. The capabilities of MT post-editing have been demonstrated through many user studies (Aziz et al., 2012; Bentivogli et al., 2016; Castilho et al., 2017; Green et al., 2013a). Parallel to the rise of the post-editing protocol, using user post-edits to adapt MT systems has also attracted the attention of researches and industry. This was studied in the CasMaCAT (Alabau et al., 2013) and MateCAT (Federico et al., 2014) projects and phrase-based statistical MT systems based on online learning were developed (Ortiz-Martínez, 2016). With the breakthrough in neural MT (NMT) technology (Bahdanau et al., 2015; Wu et al., 2016; Vaswani et al., 2017), research shifted towards constructing adaptive systems via online learning in this post-editing scenario. The use of online learning to adapt an NMT system to a new domain with post-edited samples was proposed by Peris et al. (2017) and Turchi et al. (2017). Other works refined these adaptation techniques and applied them to new use cases (Kothur et al., 2018; Wuebker"
2020.eamt-1.34,2020.emnlp-main.5,0,0.0136778,"e adaptation techniques and applied them to new use cases (Kothur et al., 2018; Wuebker et al., 2018; Peris and Casacuberta, 2019). The evaluation of MT post-edits is a hard topic that Corpus Training Document 1 Document 2 #Sentences 23.4M 150 150 # Tokens En 702M 1.7K 2.6K Es 786M - # Types En 1.8M 618 752 Es 1.9M - Average length En 30.0 11.3 17.3 Es 33.6 - Table 1: Corpora statistics in terms of number of sentences, number of tokens, number of types (vocabulary size) and average sentence length. K denotes thousands and M, millions. is currently being actively researched (e.g., Toral, 2019; Freitag et al., 2020; Läubli et al., 2020). Several works conducted user studies for MT post-editing systems, either phrase-based (Alabau et al., 2013; Green et al., 2013b; Denkowski et al., 2014; Bentivogli et al., 2016) or NMT (Daems and Macken, 2019; Koponen et al., 2019; Jia et al., 2019). Moreover, two studies showed improvements in terms of productivity time and translation quality with the application of an online learning protocol (Karimova et al., 2018; Domingo et al., 2019b). This latter study is tightly related to ours. We extend it by performing a finer-grained evaluation of the outputs of the adaptiv"
2020.eamt-1.34,P13-1031,0,0.18118,". In this work, we study the impact of this phenomenon. Additionally, we extend their user study by involving three more participants and providing additional measures for the increase in productivity gained with the adaptive system. 2 Related work Post-editing MT hypotheses is a practice that was adopted in the translation industry a long time ago (e.g., Vasconcellos and León, 1985). Its relevance grew as MT technology advanced and improved. The capabilities of MT post-editing have been demonstrated through many user studies (Aziz et al., 2012; Bentivogli et al., 2016; Castilho et al., 2017; Green et al., 2013a). Parallel to the rise of the post-editing protocol, using user post-edits to adapt MT systems has also attracted the attention of researches and industry. This was studied in the CasMaCAT (Alabau et al., 2013) and MateCAT (Federico et al., 2014) projects and phrase-based statistical MT systems based on online learning were developed (Ortiz-Martínez, 2016). With the breakthrough in neural MT (NMT) technology (Bahdanau et al., 2015; Wu et al., 2016; Vaswani et al., 2017), research shifted towards constructing adaptive systems via online learning in this post-editing scenario. The use of onlin"
2020.eamt-1.34,W16-3420,0,0.0197491,"ords and the words that were expected. 1 Introduction Despite its improvements and obtaining admissible results in many tasks, machine translation (MT) is still very far from obtaining automatic high-quality translations (Dale, 2016; Toral et al., 2018). Thus, a human agent needs to supervise and correct the outputs generated by an MT system. This process is known as post-editing and is a common use case of MT in the industrial environment. As MT systems are continuously improving their capabilities, it has acquired major relevance in the translation market (Guerberof, 2008; Pym et al., 2012; Hu and Cadwell, 2016; Turovsky, 2016). Throughout the post-editing process, new data are continuously generated. These new data have valuable properties—they are domain-specific training samples. Thus, it can be leveraged to continuously adapt the sysc 2020 The authors. This article is licensed under a Creative  Commons 3.0 licence, no derivative works, attribution, CCBY-ND. tem towards a given domain or the style of the posteditor. A common way of achieving this consists in following an online-learning paradigm (Ortiz-Martínez, 2016; Peris and Casacuberta, 2019). Each time the user validates a post-edit, the sy"
2020.eamt-1.34,P17-4012,0,0.0360511,"their production scenario. It contains specific vocabulary from a very closed domain. It was conformed by two documents of 150 sentences, which contained 1.7 and 2.7 thousand words respectively. The translation direction was English to Spanish. The system was trained using the data from WMT’13’s translation task (Bojar et al., 2013) and samples selected by the feature decay selection technique (Biçici and Yuret, 2015). The data features are summarized in Table 1. We applied joint byte pair encoding (Sennrich et al., 2016), using 32, 000 merge operations. The system was built with OpenNMT-py (Klein et al., 2017), using a long short-term memory (Gers et al., 2000) recurrent encoder–decoder with attention (Bahdanau et al., 2015). All model dimensions were 512. The system was trained using Adam (Kingma and Ba, 2014) with a fixed learning rate of 0.0002 (Wu et al., 2016) and a batch size of 60. A label smoothing of 0.1 (Szegedy et al., 2015) was applied. At inference time, we used beam search with size 6. The adaptation process followed the findings from Peris and Casacuberta (2019). We tuned the hyperparameters for the adaptation process on our development set, under simulated conditions. For each new p"
2020.eamt-1.34,W18-2708,0,0.0175244,"eCAT (Federico et al., 2014) projects and phrase-based statistical MT systems based on online learning were developed (Ortiz-Martínez, 2016). With the breakthrough in neural MT (NMT) technology (Bahdanau et al., 2015; Wu et al., 2016; Vaswani et al., 2017), research shifted towards constructing adaptive systems via online learning in this post-editing scenario. The use of online learning to adapt an NMT system to a new domain with post-edited samples was proposed by Peris et al. (2017) and Turchi et al. (2017). Other works refined these adaptation techniques and applied them to new use cases (Kothur et al., 2018; Wuebker et al., 2018; Peris and Casacuberta, 2019). The evaluation of MT post-edits is a hard topic that Corpus Training Document 1 Document 2 #Sentences 23.4M 150 150 # Tokens En 702M 1.7K 2.6K Es 786M - # Types En 1.8M 618 752 Es 1.9M - Average length En 30.0 11.3 17.3 Es 33.6 - Table 1: Corpora statistics in terms of number of sentences, number of tokens, number of types (vocabulary size) and average sentence length. K denotes thousands and M, millions. is currently being actively researched (e.g., Toral, 2019; Freitag et al., 2020; Läubli et al., 2020). Several works conducted user studi"
2020.eamt-1.34,D18-1397,0,0.0420142,"ionally, we will integrate our adaptive systems together with other translation tools, such as translation memories or terminological dictionaries, with the aim of fostering the productivity of the post-editing process. With this feature-rich system, we would like to conduct additional experiments involving more diverse languages and domains, using domain-specialized NMT systems, testing other models (e.g., Transformer, Vaswani et al., 2017) and involving a larger number of professional post-editors. Finally, we also intend to implement the interactive–predictive machine translation protocol (Lam et al., 2018; Peris and Casacuberta, 2019) in our translation environment, and compare it with the regular post-editing process. Acknowledgements The authors wish to thank the anonymous reviewers for their careful reading and in-depth criticisms and suggestions. The research leading to these results has received funding from the Spanish Centre for Technological and Industrial Development (Centro para el Desarrollo Tecnológico Industrial) (CDTI); the European Union through Programa Operativo de Crecimiento Inteligente (Project IDI-20170964) and through Programa Operativo del Fondo Europeo de Desarrollo Reg"
2020.eamt-1.34,N19-4007,0,0.0167042,".0 ) [80.0 ) ,80.0 ,70.0 [70.0 ) BLEU [60.0 ) ,60.0 ,50.0 [50.0 ) [40.0 ) ,40.0 ,30.0 [30.0 ) ,20.0 [20.0 [10.0 &lt;10. 0 0 &lt;10. Count 80 (b) Document 2. Figure 3: Histogram of sentence-level BLEU scores. The counts are distributed in buckets of range 10. to solve those particularities, their personal criteria may had an impact in the evaluation results. 4.3 On differences in the generation Next, we compare both adaptive and static systems in terms of the translations generated. To this end, we employed the discriminative language model method (Akabe et al., 2014) implemented in the compare-mt (Neubig et al., 2019) tool, comparing sentence-level BLEU and word n-grams. In terms of translation quality, we show a histogram of sentence-level BLEU scores in Fig. 3. For both documents, we observe similar trends: the static system generated low-scored sentences more frequently than the adaptive systems. The adaptive systems placed more hypotheses from bucket [50, 60) onward, for both test documents. Moreover, the differences in frequencies between adaptive and static systems were kept at a similar proportion along all high-score buckets. Hence, adaptive systems were able to outperform the static one in these h"
2020.eamt-1.34,J16-1004,0,0.103099,"d major relevance in the translation market (Guerberof, 2008; Pym et al., 2012; Hu and Cadwell, 2016; Turovsky, 2016). Throughout the post-editing process, new data are continuously generated. These new data have valuable properties—they are domain-specific training samples. Thus, it can be leveraged to continuously adapt the sysc 2020 The authors. This article is licensed under a Creative  Commons 3.0 licence, no derivative works, attribution, CCBY-ND. tem towards a given domain or the style of the posteditor. A common way of achieving this consists in following an online-learning paradigm (Ortiz-Martínez, 2016; Peris and Casacuberta, 2019). Each time the user validates a post-edit, the system’s models are updated incrementally with this new sample. Hence, when the system generates the next translation, it will consider the previous post-edits made by the user and it is expected to produce higher quality translations (or, at least, more suited to the post-editor’s preferences). Domingo et al. (2019b) conducted a preliminary user study for professional post-editors, who had a positive perception of the adaptive systems. However, they noticed that, in some cases, there were occurrences of some made-up"
2020.eamt-1.34,P02-1040,0,0.106967,"esigned by Domingo et al. (2019a). It connects our adaptive NMT engine with the SDL Trados Studio interface, which is used by the post-editors in our production workflow. In addition, it also allowed us to trace the productivity metrics and user behavior. 3.1 Evaluation We evaluated two main aspects of the adaptation process: productivity of the post-editors and quality of the NMT systems. The former was assessed by computing the average post-editing time per sentence and the number of words generated by the post-editor per hour. For the latter, we employed two well-known MT metrics: (h)BLEU (Papineni et al., 2002) and (h)TER (Snover et al., 2006). In order to ensure consistent BLEU scores, we used sacreBLEU (Post, 2018). Since we computed per-sentence BLEU scores, we used exponential BLEU smoothing (Chen and Cherry, 2014). We applied approximate randomization tests (Riezler and Maxwell, 2005), with 10, 000 repetitions and a pvalue of 0.05, to determine whether two systems presented statistically significant differences. 3.2 Human post-editors Six professional translators were involved in the experiment. Some profiling details about them can be found in Table 2. User Sex Age Professional experience User"
2020.eamt-1.34,W18-6319,0,0.0121598,"sed by the post-editors in our production workflow. In addition, it also allowed us to trace the productivity metrics and user behavior. 3.1 Evaluation We evaluated two main aspects of the adaptation process: productivity of the post-editors and quality of the NMT systems. The former was assessed by computing the average post-editing time per sentence and the number of words generated by the post-editor per hour. For the latter, we employed two well-known MT metrics: (h)BLEU (Papineni et al., 2002) and (h)TER (Snover et al., 2006). In order to ensure consistent BLEU scores, we used sacreBLEU (Post, 2018). Since we computed per-sentence BLEU scores, we used exponential BLEU smoothing (Chen and Cherry, 2014). We applied approximate randomization tests (Riezler and Maxwell, 2005), with 10, 000 repetitions and a pvalue of 0.05, to determine whether two systems presented statistically significant differences. 3.2 Human post-editors Six professional translators were involved in the experiment. Some profiling details about them can be found in Table 2. User Sex Age Professional experience User 1 User 2 User 3 User 4 User 5 User 6 Male Female Female Female Female Male 24 25 30 24 22 48 1.5 years 5 ye"
2020.eamt-1.34,W05-0908,0,0.0897149,"ted two main aspects of the adaptation process: productivity of the post-editors and quality of the NMT systems. The former was assessed by computing the average post-editing time per sentence and the number of words generated by the post-editor per hour. For the latter, we employed two well-known MT metrics: (h)BLEU (Papineni et al., 2002) and (h)TER (Snover et al., 2006). In order to ensure consistent BLEU scores, we used sacreBLEU (Post, 2018). Since we computed per-sentence BLEU scores, we used exponential BLEU smoothing (Chen and Cherry, 2014). We applied approximate randomization tests (Riezler and Maxwell, 2005), with 10, 000 repetitions and a pvalue of 0.05, to determine whether two systems presented statistically significant differences. 3.2 Human post-editors Six professional translators were involved in the experiment. Some profiling details about them can be found in Table 2. User Sex Age Professional experience User 1 User 2 User 3 User 4 User 5 User 6 Male Female Female Female Female Male 24 25 30 24 22 48 1.5 years 5 years 5 years 1 month 1 year 22 years Table 2: Information about the human post-editors that took part in the experiment, regarding their sex, age and years of professional exper"
2020.eamt-1.34,P16-1162,0,0.0465262,"k at hand consisted of a small medico-technical (description of medical equipment) corpus from their production scenario. It contains specific vocabulary from a very closed domain. It was conformed by two documents of 150 sentences, which contained 1.7 and 2.7 thousand words respectively. The translation direction was English to Spanish. The system was trained using the data from WMT’13’s translation task (Bojar et al., 2013) and samples selected by the feature decay selection technique (Biçici and Yuret, 2015). The data features are summarized in Table 1. We applied joint byte pair encoding (Sennrich et al., 2016), using 32, 000 merge operations. The system was built with OpenNMT-py (Klein et al., 2017), using a long short-term memory (Gers et al., 2000) recurrent encoder–decoder with attention (Bahdanau et al., 2015). All model dimensions were 512. The system was trained using Adam (Kingma and Ba, 2014) with a fixed learning rate of 0.0002 (Wu et al., 2016) and a batch size of 60. A label smoothing of 0.1 (Szegedy et al., 2015) was applied. At inference time, we used beam search with size 6. The adaptation process followed the findings from Peris and Casacuberta (2019). We tuned the hyperparameters fo"
2020.eamt-1.34,2006.amta-papers.25,0,0.155795,"It connects our adaptive NMT engine with the SDL Trados Studio interface, which is used by the post-editors in our production workflow. In addition, it also allowed us to trace the productivity metrics and user behavior. 3.1 Evaluation We evaluated two main aspects of the adaptation process: productivity of the post-editors and quality of the NMT systems. The former was assessed by computing the average post-editing time per sentence and the number of words generated by the post-editor per hour. For the latter, we employed two well-known MT metrics: (h)BLEU (Papineni et al., 2002) and (h)TER (Snover et al., 2006). In order to ensure consistent BLEU scores, we used sacreBLEU (Post, 2018). Since we computed per-sentence BLEU scores, we used exponential BLEU smoothing (Chen and Cherry, 2014). We applied approximate randomization tests (Riezler and Maxwell, 2005), with 10, 000 repetitions and a pvalue of 0.05, to determine whether two systems presented statistically significant differences. 3.2 Human post-editors Six professional translators were involved in the experiment. Some profiling details about them can be found in Table 2. User Sex Age Professional experience User 1 User 2 User 3 User 4 User 5 Us"
2020.eamt-1.34,W19-6627,0,0.0206561,"refined these adaptation techniques and applied them to new use cases (Kothur et al., 2018; Wuebker et al., 2018; Peris and Casacuberta, 2019). The evaluation of MT post-edits is a hard topic that Corpus Training Document 1 Document 2 #Sentences 23.4M 150 150 # Tokens En 702M 1.7K 2.6K Es 786M - # Types En 1.8M 618 752 Es 1.9M - Average length En 30.0 11.3 17.3 Es 33.6 - Table 1: Corpora statistics in terms of number of sentences, number of tokens, number of types (vocabulary size) and average sentence length. K denotes thousands and M, millions. is currently being actively researched (e.g., Toral, 2019; Freitag et al., 2020; Läubli et al., 2020). Several works conducted user studies for MT post-editing systems, either phrase-based (Alabau et al., 2013; Green et al., 2013b; Denkowski et al., 2014; Bentivogli et al., 2016) or NMT (Daems and Macken, 2019; Koponen et al., 2019; Jia et al., 2019). Moreover, two studies showed improvements in terms of productivity time and translation quality with the application of an online learning protocol (Karimova et al., 2018; Domingo et al., 2019b). This latter study is tightly related to ours. We extend it by performing a finer-grained evaluation of the"
2020.eamt-1.34,W18-6312,0,0.0287098,"rm a user study involving professional, experienced post-editors, delving deeper on the aforementioned problems. Results show that adaptive systems were able to learn how to generate the correct translation for task-specific terms, resulting in an improvement of the user’s productivity. We also observed a close similitude, in terms of morphology, between made-up words and the words that were expected. 1 Introduction Despite its improvements and obtaining admissible results in many tasks, machine translation (MT) is still very far from obtaining automatic high-quality translations (Dale, 2016; Toral et al., 2018). Thus, a human agent needs to supervise and correct the outputs generated by an MT system. This process is known as post-editing and is a common use case of MT in the industrial environment. As MT systems are continuously improving their capabilities, it has acquired major relevance in the translation market (Guerberof, 2008; Pym et al., 2012; Hu and Cadwell, 2016; Turovsky, 2016). Throughout the post-editing process, new data are continuously generated. These new data have valuable properties—they are domain-specific training samples. Thus, it can be leveraged to continuously adapt the sysc"
2020.eamt-1.34,J85-2003,0,0.32781,"ferences). Domingo et al. (2019b) conducted a preliminary user study for professional post-editors, who had a positive perception of the adaptive systems. However, they noticed that, in some cases, there were occurrences of some made-up words. In this work, we study the impact of this phenomenon. Additionally, we extend their user study by involving three more participants and providing additional measures for the increase in productivity gained with the adaptive system. 2 Related work Post-editing MT hypotheses is a practice that was adopted in the translation industry a long time ago (e.g., Vasconcellos and León, 1985). Its relevance grew as MT technology advanced and improved. The capabilities of MT post-editing have been demonstrated through many user studies (Aziz et al., 2012; Bentivogli et al., 2016; Castilho et al., 2017; Green et al., 2013a). Parallel to the rise of the post-editing protocol, using user post-edits to adapt MT systems has also attracted the attention of researches and industry. This was studied in the CasMaCAT (Alabau et al., 2013) and MateCAT (Federico et al., 2014) projects and phrase-based statistical MT systems based on online learning were developed (Ortiz-Martínez, 2016). With t"
2020.eamt-1.34,D18-1104,0,0.0180283,", 2014) projects and phrase-based statistical MT systems based on online learning were developed (Ortiz-Martínez, 2016). With the breakthrough in neural MT (NMT) technology (Bahdanau et al., 2015; Wu et al., 2016; Vaswani et al., 2017), research shifted towards constructing adaptive systems via online learning in this post-editing scenario. The use of online learning to adapt an NMT system to a new domain with post-edited samples was proposed by Peris et al. (2017) and Turchi et al. (2017). Other works refined these adaptation techniques and applied them to new use cases (Kothur et al., 2018; Wuebker et al., 2018; Peris and Casacuberta, 2019). The evaluation of MT post-edits is a hard topic that Corpus Training Document 1 Document 2 #Sentences 23.4M 150 150 # Tokens En 702M 1.7K 2.6K Es 786M - # Types En 1.8M 618 752 Es 1.9M - Average length En 30.0 11.3 17.3 Es 33.6 - Table 1: Corpora statistics in terms of number of sentences, number of tokens, number of types (vocabulary size) and average sentence length. K denotes thousands and M, millions. is currently being actively researched (e.g., Toral, 2019; Freitag et al., 2020; Läubli et al., 2020). Several works conducted user studies for MT post-editing"
2020.eamt-1.35,D14-1179,0,0.0371812,"Missing"
2020.eamt-1.35,W19-5334,0,0.0595431,"Missing"
2020.eamt-1.35,W11-2107,0,0.0369513,"Missing"
2020.eamt-1.35,P02-1040,0,0.10677,"Missing"
2020.eamt-1.35,W18-6319,0,0.0283063,"Missing"
2020.eamt-1.35,K16-1029,0,0.0674278,"Missing"
2020.eamt-1.35,2014.eamt-1.22,0,0.116613,"Missing"
2020.eamt-1.35,2006.amta-papers.25,0,0.019367,"Missing"
2020.eamt-1.35,L16-1004,0,0.0182503,"f data. After such data preparation, a generic model (GEN) was trained using data from all available domains. Then, the generic model was fine-tuned with in-domain data (IND). After training the IND model, we tested it using fixed test sets, and with five standard metrics. After the automatic evaluation against high-quality references, human translators assessed another set of representative samples by applying predefined metrics at a segment level, such as adequacy and fluency (Koehn, 2006), and by post-editing the raw output to measure the potential productivity gains (Levenshtein distance (Marg, 2016)). All steps of NMT engine creation will be explained in the following sections. 2 Data available The available data for all language pairs belong to existing domains: IP, PH, other domains and generic material. Within each domain, the data was split into an extendable number of sets depending on the quality for the purpose, ordered from the most suitable (1) to the less suitable (5), with each number reflecting the relative and presumed quality of the set, as follows: 1. Validated translations from CdT translation memories. 2. Non-validated translations translation memories. from CdT 3. Verif"
2021.mtsummit-research.22,E14-2007,1,0.855192,"Missing"
2021.mtsummit-research.22,2012.eamt-1.5,1,0.858862,"Missing"
2021.mtsummit-research.22,J09-1002,1,0.805911,"Missing"
2021.mtsummit-research.22,J93-2003,0,0.146232,"ence, information that can be provided by the user easily with an interface like a mouse. For this reason, and to simplify, we are going to suppose that the feedback is provided with the mouse, although any other interface capable to provide a sentence position or make a click could be useful. 2 Related Work The reduction of the effort needed in the translation process is a problem that has been thoroughly studied, resulting in a large variety of approaches. Some projects have investigated which information and display are more useful to the users, like showing the word alignment information (Brown et al., 1993), setting a maximum length for the predictions displayed (Alabau et al., 2012) or just using touch-based actions (Wang et al., 2020). Other approaches reduce the effort that the user has to do more directly: using confidence measures to reduce the number of words to check (Gonz´alez-Rubio et al., 2010), autocompleting the predictions typed by the user (Barrachina et al., 2009), or adding new input information to the system reduces the human effort of generating a new prediction (Sanchis-Trilles et al., 2008a). There are also projects like Lam et al. (2018, 2019) that investigated how to reduce"
2021.mtsummit-research.22,W14-4012,0,0.170432,"Missing"
2021.mtsummit-research.22,P04-3001,0,0.250688,"Missing"
2021.mtsummit-research.22,C14-2028,0,0.0310947,"to use translations (Toral, 2020). Indeed, MT systems usually require human post-editing in order to achieve perfect translations. The Computer-Assisted Translation (CAT) tools aim to generate high-quality translations using the knowledge and experience of professional translators while reducing the effort that they need to do. There is a large variety of CAT tools approaches, among which we focus on the Interactive-Predictive Machine Translation (IPMT) systems. Some of the recent projects in this field are TransType (Langlais et al., 2000; Esteban et al., 2004; Cubel et al., 2003), Matecat (Federico et al., 2014), CasMacat (Alabau et al., 2014, 2013; Sanchis-Trilles et al., 2014) and MMPE (Herbig et al., 2020). They aim to create a workbench with an array of innovative features that were not available in other tools when they started. IPMT is one of the main paradigms that include these projects, where an expert translator provides feedback to the system, typically using the keyboard and mouse, to generate new predictions that correct previous errors. There are two main IPMT approaches, both use usually the keyboard and mouse as the main feedback interface, but the validation process changes between p"
2021.mtsummit-research.22,1997.mtsummit-papers.1,0,0.348129,"cat (Alabau et al., 2014, 2013; Sanchis-Trilles et al., 2014) and MMPE (Herbig et al., 2020). They aim to create a workbench with an array of innovative features that were not available in other tools when they started. IPMT is one of the main paradigms that include these projects, where an expert translator provides feedback to the system, typically using the keyboard and mouse, to generate new predictions that correct previous errors. There are two main IPMT approaches, both use usually the keyboard and mouse as the main feedback interface, but the validation process changes between prefix (Foster et al., 1997) and segments (Peris et al., 2017; Domingo et al., 2017). In this project, we use the validation by prefix approach. Figure 1 illustrates a conventional IPMT session. Initially, the user is provided with a source sentence x to be translated. At iteration 0, the IPMT system generates the first Proceedings of the 18th Biennial Machine Translation Summit Virtual USA, August 16 - 20, 2021, Volume 1: MT Research Track Page 270 SOURCE (x): REFERENCE (y): ITER-0 ITER-1 ITER-2 FINAL (p) (ˆ sh ) (p) (st ) (k) (ˆ sh ) ( p) (st ) (k) (ˆ sh ) (p ≡ y) Una versi´on traducida de un texto. A translated versio"
2021.mtsummit-research.22,P10-2032,1,0.804538,"Missing"
2021.mtsummit-research.22,2020.acl-main.155,0,0.0877241,"Missing"
2021.mtsummit-research.22,P17-4012,0,0.0338242,"lations. We apply and implement this technique on an Interactive-Predictive Neural Machine Translation (IPNMT) system, obtaining a higher reduction in the human effort. 3 Interactive-Predictive Neural MT In this section, we see briefly the IPNMT framework. First of all, we have to see the general framework of the Neural Machine Translation (NMT) models that we use to understand how the translations are created and how we later add human feedback to the equation. This framework was introduced by Casta˜no and Casacuberta (1997) and has demonstrated its power in the last years (Cho et al., 2014; Klein et al., 2017). Given a sentence xJ1 = x1 , ..., xJ from the source ˆ language X, to find the sentence yˆ1I = yˆ1 , ..., yˆIˆ from the target language Y , that has the highest probability of being the translation of xJ1 , the fundamental equation of the statistical approach to NMT would be: ˆ yˆ1I = arg max Pr(y1I |xJ1 ) ≈ arg max I,y1I I,y1I I Y b p(yi |y1i−1 , xJ1 ; Θ) (1) i=1 where Pr(yi |y1i−1 , xJ1 ) and p(yi |y1i−1 , xJ1 ), are the probability distribution and the probability that assigns the neural model to the next word given the source sentence and the previous ˆ are the parameters of the neural mo"
2021.mtsummit-research.22,2005.mtsummit-papers.11,0,0.173821,"y the first word of the suffix. Formally, uMAR is defined as follows: MAC − nWSC (7) MAC where Mouse Action Count (MAC) is the total number of MAs performed, Word Stroke Count (WSC) is the number of words typed and n is the maximum amount of MA allowed before the user types in a word. Note that in order to perform a word-stroke the user previously must have performed n MAs, so in Equation (7), we are removing from the total count of MAs those that were not useful and did not help to find the correct word. uMAR = 5.2 Corpora Test Dev. Training We conduct our experiments on the domain Europarl (Koehn, 2005). The Europarl corpus is built from the Proceedings of the European Parliament, which exists in all official languages of the European Union, and is publicly available on the internet. We use the pair of languages Deutch-English (De-En), Spanish-English (Es-En) and French-English (Fr-En) in both directions in all our experiments. Their characteristics are described in Table 1. All the corpora have been cleaned, lower-cased and tokenized using the scripts included in the toolkit Moses, developed by Koehn et al. (2007). Once we have them tokenized, we have applied the subword subdivision BPE, de"
2021.mtsummit-research.22,D18-1397,0,0.0656978,"ing the word alignment information (Brown et al., 1993), setting a maximum length for the predictions displayed (Alabau et al., 2012) or just using touch-based actions (Wang et al., 2020). Other approaches reduce the effort that the user has to do more directly: using confidence measures to reduce the number of words to check (Gonz´alez-Rubio et al., 2010), autocompleting the predictions typed by the user (Barrachina et al., 2009), or adding new input information to the system reduces the human effort of generating a new prediction (Sanchis-Trilles et al., 2008a). There are also projects like Lam et al. (2018, 2019) that investigated how to reduce the human effort in an IPMT system using Reinforcement Learning. This technique lets them use new kinds of feedback to the system that they use as a reward to adjust the parameters of the model and obtain better translations. Proceedings of the 18th Biennial Machine Translation Summit Virtual USA, August 16 - 20, 2021, Volume 1: MT Research Track Page 271 In the paper, we take the approach introduced by Sanchis-Trilles et al. (2008a,b), demonstrating that with only the error position, the Interactive-Predictive Statistical Machine Translation (IPSMT) sys"
2021.mtsummit-research.22,W19-6610,0,0.0316249,"Missing"
2021.mtsummit-research.22,W00-0507,0,0.438954,"e new advances, the MT systems are still not able to generate perfect ready to use translations (Toral, 2020). Indeed, MT systems usually require human post-editing in order to achieve perfect translations. The Computer-Assisted Translation (CAT) tools aim to generate high-quality translations using the knowledge and experience of professional translators while reducing the effort that they need to do. There is a large variety of CAT tools approaches, among which we focus on the Interactive-Predictive Machine Translation (IPMT) systems. Some of the recent projects in this field are TransType (Langlais et al., 2000; Esteban et al., 2004; Cubel et al., 2003), Matecat (Federico et al., 2014), CasMacat (Alabau et al., 2014, 2013; Sanchis-Trilles et al., 2014) and MMPE (Herbig et al., 2020). They aim to create a workbench with an array of innovative features that were not available in other tools when they started. IPMT is one of the main paradigms that include these projects, where an expert translator provides feedback to the system, typically using the keyboard and mouse, to generate new predictions that correct previous errors. There are two main IPMT approaches, both use usually the keyboard and mouse"
2021.mtsummit-research.22,W00-0500,0,0.602938,"Missing"
2021.mtsummit-research.22,D08-1051,1,0.764087,"Missing"
2021.mtsummit-research.22,P16-1162,0,0.0367651,"arl corpus is built from the Proceedings of the European Parliament, which exists in all official languages of the European Union, and is publicly available on the internet. We use the pair of languages Deutch-English (De-En), Spanish-English (Es-En) and French-English (Fr-En) in both directions in all our experiments. Their characteristics are described in Table 1. All the corpora have been cleaned, lower-cased and tokenized using the scripts included in the toolkit Moses, developed by Koehn et al. (2007). Once we have them tokenized, we have applied the subword subdivision BPE, described in Sennrich et al. (2016), with a maximum of 32000 merges. Sentences Avg. Length Run. Words Vocabulary Sentences Avg. Length Run. Words Sentences Avg. Length Run. Words De-En 751K 21 20 15M 16M 195K 65K 2000 29 27 59K 55K 2000 29 27 58K 54K Es-En 730K 20 21 15M 15M 102K 64K 2000 29 30 59K 60K 2000 29 30 58K 67K Fr-En 688K 20 22 15M 14M 80K 61K 2000 29 33 67K 59K 2000 29 33 66K 58K Table 1: Characteristics of the Europarl corpus. K and M stands for thousands and millions. Proceedings of the 18th Biennial Machine Translation Summit Virtual USA, August 16 - 20, 2021, Volume 1: MT Research Track Page 275 5.3 User Simulati"
2021.mtsummit-research.22,P16-1159,0,0.0250982,"the target language Y , that has the highest probability of being the translation of xJ1 , the fundamental equation of the statistical approach to NMT would be: ˆ yˆ1I = arg max Pr(y1I |xJ1 ) ≈ arg max I,y1I I,y1I I Y b p(yi |y1i−1 , xJ1 ; Θ) (1) i=1 where Pr(yi |y1i−1 , xJ1 ) and p(yi |y1i−1 , xJ1 ), are the probability distribution and the probability that assigns the neural model to the next word given the source sentence and the previous ˆ are the parameters of the neural model which are obtained from trying to words so far. Θ minimize the minus log-likelihood on a set of parallel corpus (Shen et al., 2016). The IPNMT framework adds the feedback generated by the human to Equation (1) to help with the translation process. When the expert translator finds an error in position p, moves the cursor and types the correct word, producing the feedback f1p = f1 , ..., fp where fp is the word that the user has typed to correct the error. We add the feedback with the last generated hypothesis to Equation (1): ˆ yˆ1I = arg max I,y1I subject to 1≤i<p Pr(y1I | ¯ xJ1 , y¯1I , f1p ) = arg max I,y1I I Y ¯ Pr(yi |y1i−1 , xJ1 , y¯1I , f1p ) (2) i=1 fi = yi = y¯i fp = yp 6= y¯p ¯ where y¯1I = y¯1 , ..., y¯I¯ is the"
2021.mtsummit-research.22,P06-2107,1,0.590227,"Missing"
2021.mtsummit-research.22,2020.eamt-1.20,0,0.0238835,"number of words that the translator needs to type in an IPMT session. In conclusion, this technique saves valuable time, and effort for translators. Moreover, its performance improves improves with the future advances in MT, so we recommend its application in the actuals IPMT systems. 1 Introduction In recent years there had been a large number of advances in the Machine Translation (MT) field that has led to a significant improvement in the quality of the translations. Currently, even with all the new advances, the MT systems are still not able to generate perfect ready to use translations (Toral, 2020). Indeed, MT systems usually require human post-editing in order to achieve perfect translations. The Computer-Assisted Translation (CAT) tools aim to generate high-quality translations using the knowledge and experience of professional translators while reducing the effort that they need to do. There is a large variety of CAT tools approaches, among which we focus on the Interactive-Predictive Machine Translation (IPMT) systems. Some of the recent projects in this field are TransType (Langlais et al., 2000; Esteban et al., 2004; Cubel et al., 2003), Matecat (Federico et al., 2014), CasMacat ("
2021.mtsummit-research.22,2020.aacl-main.1,0,0.0288417,"ing to suppose that the feedback is provided with the mouse, although any other interface capable to provide a sentence position or make a click could be useful. 2 Related Work The reduction of the effort needed in the translation process is a problem that has been thoroughly studied, resulting in a large variety of approaches. Some projects have investigated which information and display are more useful to the users, like showing the word alignment information (Brown et al., 1993), setting a maximum length for the predictions displayed (Alabau et al., 2012) or just using touch-based actions (Wang et al., 2020). Other approaches reduce the effort that the user has to do more directly: using confidence measures to reduce the number of words to check (Gonz´alez-Rubio et al., 2010), autocompleting the predictions typed by the user (Barrachina et al., 2009), or adding new input information to the system reduces the human effort of generating a new prediction (Sanchis-Trilles et al., 2008a). There are also projects like Lam et al. (2018, 2019) that investigated how to reduce the human effort in an IPMT system using Reinforcement Learning. This technique lets them use new kinds of feedback to the system t"
C02-1032,C00-2163,1,\N,Missing
C02-1032,J93-2003,0,\N,Missing
C02-1032,E99-1010,1,\N,Missing
C02-1032,J96-1002,0,\N,Missing
C02-1032,P01-1027,1,\N,Missing
C02-1032,W00-0707,0,\N,Missing
C10-2124,J09-1002,1,0.866673,"Missing"
C10-2124,W09-0432,0,0.0222599,"cal approximations applied before implementing the BA technique described. In Section 6, experimental design and results are detailed. Conclusions and future work are explained in Section 7. 2 Related work Adaptation in SMT is a research field that is receiving an increasing amount of attention. In (Nepveu et al., 2004), adaptation techniques were applied to IMT, following the ideas by (Kuhn and Mori, 1990) and adding cache language models (LM) and TMs to their system. In (Koehn and Schroeder, 2007), different ways to combine available data belonging to two different sources was explored; in (Bertoldi and Federico, 2009) similar experiments were performed, but considering only additional source data. In (Civera and Juan, 2007), alignment model mixtures were explored as a way of performing topic-specific adaptation. Other authors (Zhao et al., 2004; SanchisTrilles et al., 2009), have proposed the use of clustering in order to extract sub-domains of a large parallel corpus and build more specific LMs and TMs, which are re-combined in test time. With respect to BA in SMT, the authors are not aware of any work up to the date that follows such paradigm. Nevertheless, there have been some recent approaches towards"
C10-2124,P03-1021,0,0.0540256,"ingle words. The basic idea of PB translation is to segment the source sentence into phrases, then to translate each source phrase into a target phrase, and finally reorder the translated target phrases in order to compose the target sentence. For this purpose, phrase-tables are produced, in which a source phrase is listed together with several target phrases and the probability of translating the former into the latter. PB models were employed throughout this work. Typically, the weights of the log-linear combination in Equation 3 are optimised by means of Minimum Error Rate Training (MERT) (Och, 2003). Such algorithm consists of two basic steps. First, n-best hypotheses are extracted for each one of the sentences of a given development set. Next, the optimum Λ is computed so that the best hypotheses in the n-best list, according to a reference translation and a given metric, are ranked higher within such n-best list. These two steps are repeated until convergence. This approach has two main problems. On the 1078 one hand, that it heavily relies on having a fair amount of data available as development set. On the other hand, that it only relies on the data in the development set. These two"
C10-2124,2001.mtsummit-papers.68,0,0.0229107,"terms p(A|Λ; T ) and p(e|f ,Λ) on the one hand, and p(Λ|T ) on the other, may have very different numeric ranges. For this reason, and in order to weaken the influence of this fact, we introduce a leveraging term δ, such that p(e|f ; T, A) = X 1 (p(A|Λ; T )p(e|f ,Λ)) δ p(Λ|T ) (13) Λm ∈M C(ΛT ) Although there are other, more standard, ways of adding this leveraging term, we chose this one for numeric reasons. 6 6.1 Experiments Experimental setup Translation quality will be assessed by means of BLEU and TER scores. BLEU measures ngram precision with a penalty for sentences that are too short (Papineni et al., 2001), whereas TER (Snover et al., 2006) is an error metric that 1080 Training Development Sentences Run. words Vocabulary Sentences Run. words OoV words Spanish English 731K 15.7M 15.2M 103K 64K 2K 61K 59K 208 127 Table 1: Main figures of the Europarl corpus. OoV stands for Out of Vocabulary. K/M stands for thousands/millions of elements. Test 2008 Test 2010 Sentences Run. words OoV. words Sentences Run. words OoV. words Spanish English 2051 50K 53K 1247 1201 2489 62K 66K 1698 1607 Table 2: Main figures of the News-Commentary test sets. OoV stands for Out of Vocabulary words with respect to the Eu"
C10-2124,2009.iwslt-papers.5,1,0.796407,"Missing"
C10-2124,W07-0722,0,0.0242132,"esults are detailed. Conclusions and future work are explained in Section 7. 2 Related work Adaptation in SMT is a research field that is receiving an increasing amount of attention. In (Nepveu et al., 2004), adaptation techniques were applied to IMT, following the ideas by (Kuhn and Mori, 1990) and adding cache language models (LM) and TMs to their system. In (Koehn and Schroeder, 2007), different ways to combine available data belonging to two different sources was explored; in (Bertoldi and Federico, 2009) similar experiments were performed, but considering only additional source data. In (Civera and Juan, 2007), alignment model mixtures were explored as a way of performing topic-specific adaptation. Other authors (Zhao et al., 2004; SanchisTrilles et al., 2009), have proposed the use of clustering in order to extract sub-domains of a large parallel corpus and build more specific LMs and TMs, which are re-combined in test time. With respect to BA in SMT, the authors are not aware of any work up to the date that follows such paradigm. Nevertheless, there have been some recent approaches towards dealing with SMT from the Bayesian learning point of view. In (Zhang et al., 2008), Bayesian learning was ap"
C10-2124,2006.amta-papers.25,0,0.050244,"Missing"
C10-2124,W07-0733,0,0.103617,"esent the way in which we apply Bayesian adaptation (BA) to log-linear models in SMT. In Section 5, we describe the practical approximations applied before implementing the BA technique described. In Section 6, experimental design and results are detailed. Conclusions and future work are explained in Section 7. 2 Related work Adaptation in SMT is a research field that is receiving an increasing amount of attention. In (Nepveu et al., 2004), adaptation techniques were applied to IMT, following the ideas by (Kuhn and Mori, 1990) and adding cache language models (LM) and TMs to their system. In (Koehn and Schroeder, 2007), different ways to combine available data belonging to two different sources was explored; in (Bertoldi and Federico, 2009) similar experiments were performed, but considering only additional source data. In (Civera and Juan, 2007), alignment model mixtures were explored as a way of performing topic-specific adaptation. Other authors (Zhao et al., 2004; SanchisTrilles et al., 2009), have proposed the use of clustering in order to extract sub-domains of a large parallel corpus and build more specific LMs and TMs, which are re-combined in test time. With respect to BA in SMT, the authors are no"
C10-2124,2002.tmi-tutorials.2,0,0.0296152,"ustering in order to extract sub-domains of a large parallel corpus and build more specific LMs and TMs, which are re-combined in test time. With respect to BA in SMT, the authors are not aware of any work up to the date that follows such paradigm. Nevertheless, there have been some recent approaches towards dealing with SMT from the Bayesian learning point of view. In (Zhang et al., 2008), Bayesian learning was applied for estimating word-alignments within a synchronous grammar. 3 Phrase-based SMT One of the most popular instantiations of loglinear models in SMT are phrase-based (PB) models (Zens et al., 2002; Koehn et al., 2003). PB models allow to capture contextual information to learn translations for whole phrases instead of single words. The basic idea of PB translation is to segment the source sentence into phrases, then to translate each source phrase into a target phrase, and finally reorder the translated target phrases in order to compose the target sentence. For this purpose, phrase-tables are produced, in which a source phrase is listed together with several target phrases and the probability of translating the former into the latter. PB models were employed throughout this work. Typi"
C10-2124,P08-1012,0,0.0121009,"ional source data. In (Civera and Juan, 2007), alignment model mixtures were explored as a way of performing topic-specific adaptation. Other authors (Zhao et al., 2004; SanchisTrilles et al., 2009), have proposed the use of clustering in order to extract sub-domains of a large parallel corpus and build more specific LMs and TMs, which are re-combined in test time. With respect to BA in SMT, the authors are not aware of any work up to the date that follows such paradigm. Nevertheless, there have been some recent approaches towards dealing with SMT from the Bayesian learning point of view. In (Zhang et al., 2008), Bayesian learning was applied for estimating word-alignments within a synchronous grammar. 3 Phrase-based SMT One of the most popular instantiations of loglinear models in SMT are phrase-based (PB) models (Zens et al., 2002; Koehn et al., 2003). PB models allow to capture contextual information to learn translations for whole phrases instead of single words. The basic idea of PB translation is to segment the source sentence into phrases, then to translate each source phrase into a target phrase, and finally reorder the translated target phrases in order to compose the target sentence. For th"
C10-2124,C04-1059,0,0.0211791,"d that is receiving an increasing amount of attention. In (Nepveu et al., 2004), adaptation techniques were applied to IMT, following the ideas by (Kuhn and Mori, 1990) and adding cache language models (LM) and TMs to their system. In (Koehn and Schroeder, 2007), different ways to combine available data belonging to two different sources was explored; in (Bertoldi and Federico, 2009) similar experiments were performed, but considering only additional source data. In (Civera and Juan, 2007), alignment model mixtures were explored as a way of performing topic-specific adaptation. Other authors (Zhao et al., 2004; SanchisTrilles et al., 2009), have proposed the use of clustering in order to extract sub-domains of a large parallel corpus and build more specific LMs and TMs, which are re-combined in test time. With respect to BA in SMT, the authors are not aware of any work up to the date that follows such paradigm. Nevertheless, there have been some recent approaches towards dealing with SMT from the Bayesian learning point of view. In (Zhang et al., 2008), Bayesian learning was applied for estimating word-alignments within a synchronous grammar. 3 Phrase-based SMT One of the most popular instantiation"
C10-2124,N03-1017,0,0.0131963,"o extract sub-domains of a large parallel corpus and build more specific LMs and TMs, which are re-combined in test time. With respect to BA in SMT, the authors are not aware of any work up to the date that follows such paradigm. Nevertheless, there have been some recent approaches towards dealing with SMT from the Bayesian learning point of view. In (Zhang et al., 2008), Bayesian learning was applied for estimating word-alignments within a synchronous grammar. 3 Phrase-based SMT One of the most popular instantiations of loglinear models in SMT are phrase-based (PB) models (Zens et al., 2002; Koehn et al., 2003). PB models allow to capture contextual information to learn translations for whole phrases instead of single words. The basic idea of PB translation is to segment the source sentence into phrases, then to translate each source phrase into a target phrase, and finally reorder the translated target phrases in order to compose the target sentence. For this purpose, phrase-tables are produced, in which a source phrase is listed together with several target phrases and the probability of translating the former into the latter. PB models were employed throughout this work. Typically, the weights of"
C10-2124,P07-2045,0,0.0200965,"Missing"
C10-2124,2005.mtsummit-papers.11,0,0.0174314,"quences. For computing e∗ as described in Equation 12, TER was used, since BLEU implements a geometrical average which is zero whenever there is no common 4-gram between reference and hypothesis. Hence, it is not well suited for our purposes since the complete set of n-best candidates provided by the decoder can score zero. As a first baseline system, we trained a SMT system on the Europarl Spanish–English training data, in the partition established in the Workshop on SMT of the NAACL 2006 (Koehn and Monz, 2006), using the training and development data provided that year. The Europarl corpus (Koehn, 2005) is built from the transcription of European Parliament speeches published on the web. Statistics are provided in Table 1. We used the open-source MT toolkit Moses (Koehn et al., 2007)1 in its default monotonic setup, and estimated the weights of the log-linear combination using MERT on the Europarl development set. A 5-gram LM with interpolation and Kneser-Ney smoothing (Kneser and Ney, 1995) was also estimated. Since our purpose is to adapt the initial weight 1 Available from http://www.statmt.org/moses/ vector obtained during the training stage (i.e. the one obtained after running MERT on t"
C10-2124,W04-3225,0,0.0260784,"brief review of current approaches to adaptation and Bayesian learning in SMT. Section 3 describes the typical framework for phrase-based translation in SMT. In Section 4, we present the way in which we apply Bayesian adaptation (BA) to log-linear models in SMT. In Section 5, we describe the practical approximations applied before implementing the BA technique described. In Section 6, experimental design and results are detailed. Conclusions and future work are explained in Section 7. 2 Related work Adaptation in SMT is a research field that is receiving an increasing amount of attention. In (Nepveu et al., 2004), adaptation techniques were applied to IMT, following the ideas by (Kuhn and Mori, 1990) and adding cache language models (LM) and TMs to their system. In (Koehn and Schroeder, 2007), different ways to combine available data belonging to two different sources was explored; in (Bertoldi and Federico, 2009) similar experiments were performed, but considering only additional source data. In (Civera and Juan, 2007), alignment model mixtures were explored as a way of performing topic-specific adaptation. Other authors (Zhao et al., 2004; SanchisTrilles et al., 2009), have proposed the use of clust"
C10-2124,P02-1038,0,0.205533,"tems model the translation process as a log-linear combination of simpler models, we present the formal derivation of how to apply such paradigm to the weights of the log-linear combination. We show empirical results in which a small amount of adaptation data is able to improve both the non-adapted system and a system which optimises the abovementioned weights on the adaptation set only, while gaining both in reliability and speed. 1 e (1) Recently, a direct modelling of the posterior probability Pr(e|f ) has been widely adopted, and, to this purpose, different authors (Papineni et al., 1998; Och and Ney, 2002) proposed the use of the so-called log-linear models, where P exp K k=1 λk hk (f , e) p(e|f ) = P PK 0 k=1 λk hk (f , e ) e0 exp (2) and the decision rule is given by the expression ˆ = argmax e e Introduction The adaptation problem is a very common issue in statistical machine translation (SMT), where it is frequent to have very large collections of bilingual data belonging to e.g. proceedings from international entities such as the European Parliament or the United Nations. However, if we are currently interested in translating e.g. printer manuals or news data, we will need to find a way in"
C10-2124,J93-2003,0,\N,Missing
C10-2124,P02-1040,0,\N,Missing
C10-2124,D08-1076,0,\N,Missing
chinea-rios-etal-2014-online,N10-1079,1,\N,Missing
chinea-rios-etal-2014-online,J93-2003,0,\N,Missing
chinea-rios-etal-2014-online,J09-1002,1,\N,Missing
chinea-rios-etal-2014-online,P07-2045,0,\N,Missing
chinea-rios-etal-2014-online,D08-1076,0,\N,Missing
D08-1051,P04-3001,0,0.460838,"Missing"
D08-1051,W02-1020,0,0.505183,"Arnold, 2003). Indeed, MT systems are usually limited to specific semantic domains and the translations provided require human post-editing in order to achieve a correct high-quality translation. A way of taking advantage of MT systems is to combine them with the knowledge of a human translator, constituting the so-called Computer-Assisted Translation (CAT) paradigm. CAT offers different approaches in order to benefit from the synergy between humans and MT systems. An important contribution to interactive CAT technology was carried out around the TransType (TT) project (Langlais et al., 2002; Foster et al., 2002; Foster, 2002; Och et al., 2003). This project entailed an interesting focus shift in which interaction directly aimed at the production of the target text, rather than at the disambiguation of the source text, as in former interactive systems. The idea proposed was to embed data driven MT techniques within the interactive translation environment. Following these TT ideas, (Barrachina and others, 2008) propose the usage of fully-fledged statistical MT (SMT) systems to produce full target sentence hypotheses, or portions thereof, which can be partially or completely accepted and amended by a h"
D08-1051,1999.mtsummit-1.5,0,0.0438124,"e underlying system improves the productivity of the human translator involved. In addition, we also show that the initial translations that the MT system provides can be quickly improved by an expert by only performing additional Mouse Actions. In this work, we will be using word graphs as an efficient interface between a phrase-based MT system and the IP engine. 1 Introduction Information technology advances in modern society have led to the need of more efficient methods of translation. It is important to remark that current MT systems are not able to produce ready-to-use texts (Kay, 1997; Hutchins, 1999; Arnold, 2003). Indeed, MT systems are usually limited to specific semantic domains and the translations provided require human post-editing in order to achieve a correct high-quality translation. A way of taking advantage of MT systems is to combine them with the knowledge of a human translator, constituting the so-called Computer-Assisted Translation (CAT) paradigm. CAT offers different approaches in order to benefit from the synergy between humans and MT systems. An important contribution to interactive CAT technology was carried out around the TransType (TT) project (Langlais et al., 2002"
D08-1051,P07-2045,1,0.029189,"Missing"
D08-1051,N03-1017,0,0.00931411,"the posterior probability P r(y|x) has been widely adopted. To this purpose, different authors (Papineni et al., 1998; Och and Ney, 2002) propose the use of the so-called log-linear models, where the decision rule is given by the expression ˆ = argmax y y M X λm hm (x, y) (3) m=1 where hm (x, y) is a score function representing an important feature for the translation of x into y, M is the number of models (or features) and λm are the weights of the log-linear combination. One of the most popular instantiations of loglinear models is that including phrase-based (PB) models (Zens et al., 2002; Koehn et al., 2003). Phrase-based models allow to capture contextual information to learn translations for whole phrases instead of single words. The basic idea of phrasebased translation is to segment the source sentence into phrases, then to translate each source phrase into a target phrase, and finally to reorder the translated target phrases in order to compose the target sentence. Phrase-based models were employed throughout this work. In log-linear models, the maximisation problem stated in Eq. 3 is solved by means of the beam search algorithm1 which was initially introduced in (Lowerre, 1976) for its appl"
D08-1051,W04-3250,0,0.0410264,"Missing"
D08-1051,2005.mtsummit-papers.11,0,0.00825568,"1K Run. words 15.3M16.1M Avg. len. 20.3 21.4 Voc. 195K 66K Sentences 2000 Run. words 55K 59K Avg. len. 27.6 29.3 OoV 432 125 Sentences 2000 Run. words 54K 58K Avg. len. 27.1 29.0 OoV 377 127 Es En 731K 15.7M15.2M 21.5 20.8 103K 64K 2000 61K 59K 30.3 29.3 208 127 2000 60K 58K 30.2 29.0 207 125 Fr En 688K 15.6M13.8M 22.7 20.1 80K 62K 2000 67K 59K 33.6 29.3 144 138 2000 66K 58K 33.1 29.3 139 133 translation, which is ”corrected” by the IMT procedure into another equivalent translation, increasing WSR and MAR significantly by doing so. 5.2 Corpora Our experiments were carried out on the Europarl (Koehn, 2005) corpus, which is a corpus widely used in SMT and that has been used in several MT evaluation campaigns. Moreover, we performed our experiments on the partition established for the Workshop on Statistical Machine Translation of the NAACL 2006 (Koehn and Monz, 2006). The Europarl corpus (Koehn, 2005) is built from the proceedings of the European Parliament. Here, we will focus on the German–English, Spanish–English and French–English tasks, since these were the language pairs selected for the cited workshop. The corpus is divided into three separate sets: one for training, one for development,"
D08-1051,P02-1038,0,0.0335599,"te-of-the-art MT systems with little human effort, whenever adequate corpora are available (Hutchings and Somers, 1992). The fundamental equation of the statistical approach to MT is ˆ = argmax P r(y |x) y (1) y = argmax P r(x |y) P r(y) (2) y where P r(x |y) is the translation model modelling the correlation between source and target sentence and P r(y) is the language model representing the well-formedness of the candidate translation y. In practise, the direct modelling of the posterior probability P r(y|x) has been widely adopted. To this purpose, different authors (Papineni et al., 1998; Och and Ney, 2002) propose the use of the so-called log-linear models, where the decision rule is given by the expression ˆ = argmax y y M X λm hm (x, y) (3) m=1 where hm (x, y) is a score function representing an important feature for the translation of x into y, M is the number of models (or features) and λm are the weights of the log-linear combination. One of the most popular instantiations of loglinear models is that including phrase-based (PB) models (Zens et al., 2002; Koehn et al., 2003). Phrase-based models allow to capture contextual information to learn translations for whole phrases instead of singl"
D08-1051,J04-4002,0,0.0346211,"that we can use the same models if the search procedures are adequately modified (Barrachina and others, 2008). 1 Also known as stack decoding algorithm. 487 3 Phrase-based IMT The phrase-based approach presented above can be easily adapted for its use in an IMT scenario. The most important modification is to rely on a word graph that represents possible translations of the given source sentence. The use of word graphs in IMT has been studied in (Barrachina and others, 2008) in combination with two different translation techniques, namely, the Alignment Templates technique (Och et al., 1999; Och and Ney, 2004), and the Stochastic Finite State Transducers technique (Casacuberta and Vidal, 2007). 3.1 Generation of word graphs A word graph is a weighted directed acyclic graph, in which each node represents a partial translation hypothesis and each edge is labelled with a word of the target sentence and is weighted according to the scores given by an SMT model (see (Ueffing et al., 2002) for more details). In (Och et al., 2003), the use of a word graph is proposed as interface between an alignment-template SMT model and the IMT engine. Analogously, in this work we will be using a word graph built durin"
D08-1051,W99-0604,0,0.0933407,". 1). This implies that we can use the same models if the search procedures are adequately modified (Barrachina and others, 2008). 1 Also known as stack decoding algorithm. 487 3 Phrase-based IMT The phrase-based approach presented above can be easily adapted for its use in an IMT scenario. The most important modification is to rely on a word graph that represents possible translations of the given source sentence. The use of word graphs in IMT has been studied in (Barrachina and others, 2008) in combination with two different translation techniques, namely, the Alignment Templates technique (Och et al., 1999; Och and Ney, 2004), and the Stochastic Finite State Transducers technique (Casacuberta and Vidal, 2007). 3.1 Generation of word graphs A word graph is a weighted directed acyclic graph, in which each node represents a partial translation hypothesis and each edge is labelled with a word of the target sentence and is weighted according to the scores given by an SMT model (see (Ueffing et al., 2002) for more details). In (Och et al., 2003), the use of a word graph is proposed as interface between an alignment-template SMT model and the IMT engine. Analogously, in this work we will be using a wo"
D08-1051,E03-1032,0,0.72153,"re usually limited to specific semantic domains and the translations provided require human post-editing in order to achieve a correct high-quality translation. A way of taking advantage of MT systems is to combine them with the knowledge of a human translator, constituting the so-called Computer-Assisted Translation (CAT) paradigm. CAT offers different approaches in order to benefit from the synergy between humans and MT systems. An important contribution to interactive CAT technology was carried out around the TransType (TT) project (Langlais et al., 2002; Foster et al., 2002; Foster, 2002; Och et al., 2003). This project entailed an interesting focus shift in which interaction directly aimed at the production of the target text, rather than at the disambiguation of the source text, as in former interactive systems. The idea proposed was to embed data driven MT techniques within the interactive translation environment. Following these TT ideas, (Barrachina and others, 2008) propose the usage of fully-fledged statistical MT (SMT) systems to produce full target sentence hypotheses, or portions thereof, which can be partially or completely accepted and amended by a human translator. Each partial cor"
D08-1051,P03-1021,0,0.0915814,"Missing"
D08-1051,2005.mtsummit-papers.19,1,0.936041,"Missing"
D08-1051,P02-1040,0,0.0744419,"Missing"
D08-1051,W02-1021,0,0.0638797,"given source sentence. The use of word graphs in IMT has been studied in (Barrachina and others, 2008) in combination with two different translation techniques, namely, the Alignment Templates technique (Och et al., 1999; Och and Ney, 2004), and the Stochastic Finite State Transducers technique (Casacuberta and Vidal, 2007). 3.1 Generation of word graphs A word graph is a weighted directed acyclic graph, in which each node represents a partial translation hypothesis and each edge is labelled with a word of the target sentence and is weighted according to the scores given by an SMT model (see (Ueffing et al., 2002) for more details). In (Och et al., 2003), the use of a word graph is proposed as interface between an alignment-template SMT model and the IMT engine. Analogously, in this work we will be using a word graph built during the search procedure performed on a PB SMT model. During the search process performed by the above mentioned beam search algorithm, it is possible to create a segment graph. In such a graph, each node represents a state of the SMT model, and each edge a weighted transition between states labelled with a sequence of target words. Whenever a hypothesis is extended, we add a new"
D08-1051,2002.tmi-tutorials.2,0,0.0253972,"irect modelling of the posterior probability P r(y|x) has been widely adopted. To this purpose, different authors (Papineni et al., 1998; Och and Ney, 2002) propose the use of the so-called log-linear models, where the decision rule is given by the expression ˆ = argmax y y M X λm hm (x, y) (3) m=1 where hm (x, y) is a score function representing an important feature for the translation of x into y, M is the number of models (or features) and λm are the weights of the log-linear combination. One of the most popular instantiations of loglinear models is that including phrase-based (PB) models (Zens et al., 2002; Koehn et al., 2003). Phrase-based models allow to capture contextual information to learn translations for whole phrases instead of single words. The basic idea of phrasebased translation is to segment the source sentence into phrases, then to translate each source phrase into a target phrase, and finally to reorder the translated target phrases in order to compose the target sentence. Phrase-based models were employed throughout this work. In log-linear models, the maximisation problem stated in Eq. 3 is solved by means of the beam search algorithm1 which was initially introduced in (Lowerr"
D08-1051,J09-1002,1,\N,Missing
D08-1051,D08-1076,0,\N,Missing
D13-1025,J09-1002,1,0.909882,"Missing"
D13-1025,J93-2003,0,0.0416162,"ranslation task. The comparative results against the IMT approach described by Barrachina et al., (2009) and a conventional post-edition approach show that our IMT formalization for hierarchical SMT models indeed outperform other approaches (Sections 5 and 6). Moreover, it leads to large reductions in the human effort required to generate error-free translations. 2 2.1 Statistical Framework Statistical Machine Translation Assuming that we are given a sentence s in a source language, the translation problem can be stated as finding its translation t in a target language of maximum probability (Brown et al., 1993): ˆt = arg max Pr(t |s) (1) t = arg max Pr(t) · Pr(s |t) (2) t 245 source (s): Para ver la lista de recursos desired translation (ˆt): To view a listing of resources IT-0 p ts To view the resources p To view IT-1 k a ts p To view a IT-2 k ts list list of resources list list i list i ng resources p To view a IT-3 k ts listing END p To view a listing o of resources of resources Figure 1: IMT session to translate a Spanish sentence into English. The desired translation is the translation the human user wants to obtain. At IT-0, the system suggests a translation (ts ). At IT-1, the user moves the"
D13-1025,P05-1033,0,0.608414,"n to address prefix coverage problems. Moreover, we refine this formalization proposing an alternative error-correction formalization for the IMT framework (Section 2). Additionally, we also propose a specific error-correction model based on a statistical interpretation of the Levenshtein distance (Levenshtein, 1966). These formalizations provide a unified statistical framework for the IMT model in comparison to the ad-hoc heuristic error-correction methods previously used. In order to address the problem of properly deal with reordering in IMT, we introduce the use of hierarchical MT models (Chiang, 2005; Zollmann and Venugopal, 2006). These methods provide a natural approach to handle long range dependencies and allow the incorporation of reordering information into a consistent statistical framework. Here, we also describe how state-of-the-art hierarchical MT models can be extended to handle IMT (Sections 3 and 4). We evaluate the proposed IMT approach on two different translation task. The comparative results against the IMT approach described by Barrachina et al., (2009) and a conventional post-edition approach show that our IMT formalization for hierarchical SMT models indeed outperform"
D13-1025,2011.iwslt-evaluation.1,0,0.0906476,"Missing"
D13-1025,W02-1020,0,0.722773,"Missing"
D13-1025,P10-2032,1,0.927539,"Missing"
D13-1025,N03-1017,0,0.0211211,"ns. Alternatively, we can model the distance with a multinomial distribution and assign different probabilities to different types of edit operations. Nevertheless, we adhere to the binomial approximation due to its simplicity. Finally, we compute the error-correction probability between two strings from the total number of edits required to transform the candidate translation into the reference translation. Specifically, we define the error-correction distribution in Equation (11) as: Pr(p, a |t) ≈ Pr(s |t) ≈ λ1 · |t |+ λ2 · K+ Phrase-Based Translation Models Phrase-based translation models (Koehn et al., 2003) are an instance of the noisy-channel approach in Equation (2). The translation of a source sentence s is obtained through a generative process composed of three steps: first, the s is divided into K segments (phrases), next, each source phrase, ˜s, is translated into a target phrase ˜t, and finally the target phrases are reordered to compose the final translation. The usual phrase-based implementation of the translation probability takes a log-linear form: 248 where P (˜s |˜t) is the translation probability between source phrase ˜s and target phrase ˜t, and d(j) is a function (distortion mode"
D13-1025,P07-2045,0,0.0140563,"cifically, we used the dev2010 partition for development and the test2010 partition for test. We process the Spanish and English parts of the EU corpus to separate words and punctuation marks keeping sentences truecase. Regarding the TED corpus, we tokenized and lowercased the English part (Chinese has no case information), and split Chinese sentences into words with the Stanford word 4 www.ted.com segmenter (Tseng et al., 2005). Table 1 shows the main figures of the processed EU and TED corpora. 5.2 Model Estimation and User Simulation We used the standard configuration of the Moses toolkit (Koehn et al., 2007) to estimate one phrasebased and one hierarchical model for each corpus; log-linear weights were optimized by minimum error-rate training (Och, 2003) with the development partitions. Then, the optimized models were used to generate the word-graphs and hypergraphs with the translations of the development and test partitions. A direct evaluation of the proposed IMT procedures involving human users would have been slow and expensive. Thus, following previous works in the literature (Barrachina et al., 2009; Gonz´alezRubio et al., 2010), we used the references in the corpora to simulate the transl"
D13-1025,W04-3225,0,0.0926794,"ve IMT scenarios where the user is not bounded to correct translation errors in a leftto-right fashion. In such scenarios, the user will be allowed to correct errors at any position in the translation while the IMT system will be required to derive translations compatible with these isolated corrections. • Adaptive translation engines that take advantage of the user’s corrections to improve its statistical models. As the translator works and corrects the proposed translations, the translation engine will be able to make better predictions. One of the first works on this topic was proposed in (Nepveu et al., 2004). More recently, Ortiz-Mart´ınez et al. (2010) described a set of techniques to obtain an incrementally updateable IMT system, solving technical problems encountered in previous works. • More sophisticated measures to estimate the human effort. Specifically, measures that estimate the cognitive load involve in reading, understanding and detecting an error in a translation (Foster et al., 2002), in contrast KSMR simply considers a constant cost. This will lead to a more accurate estimation of the improvements that may be expected by a human user. 253 Acknowledgments Work supported by the Europe"
D13-1025,P02-1038,0,0.68036,"Missing"
D13-1025,E03-1032,0,0.6335,"he probability of the suffix given the available information. Formally, the best suffix of a given length will be: ˆts = arg max Pr(ts |s, p) (4) ts which can be straightforwardly rewritten as: ˆts = arg max Pr(p, ts |s) (5) ts = arg max Pr(p, ts ) · Pr(s |p, ts ) (6) ts Note that, since p ts = t, this equation is very similar to Equation (2). The main difference is that now the search process is restricted to those target sentences t that contains p as prefix. This implies that we can use the same MT models (including the log-linear approach) if the search procedures are adequately modified (Och et al., 2003). Finally, it should be noted that the statistical models are usually defined at word level, while the IMT process described in this section works at character level. To deal with this problem, during the search process it is necessary to verify the compatibility between t and p at character level. 246 2.3 IMT with Stochastic Error-Correction A common problem in IMT arises when the user sets a prefix which cannot be explained by the statistical models. To solve this problem, IMT systems typically include ad-hoc error-correction techniques to guarantee that the suffixes can be generated (Barrac"
D13-1025,P03-1021,0,0.153404,"arate words and punctuation marks keeping sentences truecase. Regarding the TED corpus, we tokenized and lowercased the English part (Chinese has no case information), and split Chinese sentences into words with the Stanford word 4 www.ted.com segmenter (Tseng et al., 2005). Table 1 shows the main figures of the processed EU and TED corpora. 5.2 Model Estimation and User Simulation We used the standard configuration of the Moses toolkit (Koehn et al., 2007) to estimate one phrasebased and one hierarchical model for each corpus; log-linear weights were optimized by minimum error-rate training (Och, 2003) with the development partitions. Then, the optimized models were used to generate the word-graphs and hypergraphs with the translations of the development and test partitions. A direct evaluation of the proposed IMT procedures involving human users would have been slow and expensive. Thus, following previous works in the literature (Barrachina et al., 2009; Gonz´alezRubio et al., 2010), we used the references in the corpora to simulate the translations that a human user would want to obtain. Each time the system suggested a new translation, it was compared to the reference and the longest com"
D13-1025,N10-1079,1,0.913042,"Missing"
D13-1025,P02-1040,0,0.0982499,"Missing"
D13-1025,J10-4005,0,0.0180046,"erence for hierarchical phrases over serial combination of phrases. Note that no distortion model is included in the previous equation. Here, reordering is defined at rule level by the one-to-one non-terminal correspondence. In other words, reordering is a property inherent to each rule and it is the individual score of each rule what defines, at each step of the derivation, the importance of reordering. It should be noted that the IMT formalizations presented in Section 2 can be applied to other hierarchical or syntax-based SMT models such as those described in (Zollmann and Venugopal, 2006; Shen et al., 2010). 4 Search In offline MT, the generation of the best translation for a given source sentence is carried out by incrementally generating the target sentence2 . This process fits nicely into a dynamic programming (DP) (Bellman, 1957) framework, as hypotheses which are indistinguishable by the models can be recombined. Since the DP search space grows exponentially with the size of the input, standard DP search is prohibitive, and search algorithms usually resort to a beam-search heuristic (Jelinek, 1997). 2 Phrase-based systems follow a left-to-right generation order while hierarchical systems re"
D13-1025,W02-1021,0,0.0592864,"ach ingoing hyperedge represents the rule with which the corresponding non-terminal was substituted. Moreover, hypergraphs can represent a whole set of possible translations. An example is shown in Figure 2. Two alternative translations are constructed from the leave nodes (1, 2 and 3) up to the root node (6) of the hypergraph. Additionally, hypernodes and hyperedges may be shared among different derivations if they represent the same information. Thus, we can achieve a compact representation of the translation space that allows us to derive efficient search algorithms. Note that word-graphs (Ueffing et al., 2002), which are used to represent the search space for phrase-based models, are a special case of hypergraphs in which the maximum arity is one. Thus, hypergraphs allow us to represent both phrase-based and hierarchical systems in a unified framework. 4.2 Suffix Search on Hypergraphs Now, we describe a unified search process to obtain the suffix ts that completes a prefix p given by the user according to the two IMT formulations (Equation (11) and Equation (17)) described in Section 2. Given an hypergraph, certain hypernodes define a possible solution to the maximization defined in the two IMT for"
D13-1025,2004.tmi-1.9,0,0.36221,"Missing"
D13-1025,W06-3119,0,0.220719,"refix coverage problems. Moreover, we refine this formalization proposing an alternative error-correction formalization for the IMT framework (Section 2). Additionally, we also propose a specific error-correction model based on a statistical interpretation of the Levenshtein distance (Levenshtein, 1966). These formalizations provide a unified statistical framework for the IMT model in comparison to the ad-hoc heuristic error-correction methods previously used. In order to address the problem of properly deal with reordering in IMT, we introduce the use of hierarchical MT models (Chiang, 2005; Zollmann and Venugopal, 2006). These methods provide a natural approach to handle long range dependencies and allow the incorporation of reordering information into a consistent statistical framework. Here, we also describe how state-of-the-art hierarchical MT models can be extended to handle IMT (Sections 3 and 4). We evaluate the proposed IMT approach on two different translation task. The comparative results against the IMT approach described by Barrachina et al., (2009) and a conventional post-edition approach show that our IMT formalization for hierarchical SMT models indeed outperform other approaches (Sections 5 an"
E12-1016,D10-1061,0,0.0188514,"ing (AL), both problems are essentially different. Since the AL strategies assume that the pool of sentences are not translated, they are usually interested in finding the best monolingual subset of sentences to be translated by a human annotator. In contrast, in BSS, it is assumed that a fairly large amount of bilingual corpora is readily available, and the main goal consists in selecting only those sentences which will maximise system performance. Some works have applied sentence selection in small scale AL frameworks. These works extend the training corpora at most with 5000 sentences. In (Ananthakrishnan et al., 2010), sentences are selected by means of discriminative techniques. In (Haffari et al., 2009) a technique is proposed for increasing the counts of phrases that are considered infrequent. Both works significantly differ from the current work not only on the framework, but also on the scale of the experiments, the 153 proposed techniques and the obtained improvements. Similar ideas applied to adaptation problems have been proposed in (Moore and Lewis, 2010; Axelrod et al., 2011). 3 Probabilistic Sampling As discussed in Section 2, BSS has inherently attached many meaningful links with AL techniques."
E12-1016,D11-1033,0,0.24908,"e selection in small scale AL frameworks. These works extend the training corpora at most with 5000 sentences. In (Ananthakrishnan et al., 2010), sentences are selected by means of discriminative techniques. In (Haffari et al., 2009) a technique is proposed for increasing the counts of phrases that are considered infrequent. Both works significantly differ from the current work not only on the framework, but also on the scale of the experiments, the 153 proposed techniques and the obtained improvements. Similar ideas applied to adaptation problems have been proposed in (Moore and Lewis, 2010; Axelrod et al., 2011). 3 Probabilistic Sampling As discussed in Section 2, BSS has inherently attached many meaningful links with AL techniques. Selecting samples for learning our models, incurs in a well-known difficulty in AL, the so-called sample bias problem (Dasgupta, 2009). This problem, which is spread to the BSS case, is summarised as the distortion introduced by the active strategy into the probability distribution underlying the training corpus. This bias forces the training algorithm to learn a distorted probability model which can significantly differ from the actual one. In order to further analyse th"
E12-1016,D10-1044,0,0.0664363,"Missing"
E12-1016,N09-1047,0,0.0724456,"f sentences are not translated, they are usually interested in finding the best monolingual subset of sentences to be translated by a human annotator. In contrast, in BSS, it is assumed that a fairly large amount of bilingual corpora is readily available, and the main goal consists in selecting only those sentences which will maximise system performance. Some works have applied sentence selection in small scale AL frameworks. These works extend the training corpora at most with 5000 sentences. In (Ananthakrishnan et al., 2010), sentences are selected by means of discriminative techniques. In (Haffari et al., 2009) a technique is proposed for increasing the counts of phrases that are considered infrequent. Both works significantly differ from the current work not only on the framework, but also on the scale of the experiments, the 153 proposed techniques and the obtained improvements. Similar ideas applied to adaptation problems have been proposed in (Moore and Lewis, 2010; Axelrod et al., 2011). 3 Probabilistic Sampling As discussed in Section 2, BSS has inherently attached many meaningful links with AL techniques. Selecting samples for learning our models, incurs in a well-known difficulty in AL, the"
E12-1016,P07-1034,0,0.0171138,"Missing"
E12-1016,P07-2045,0,0.0124708,"references are not used at any stage within the translation system for obtaining the hypotheses. Note that although we are not able to achieve such an improvement without an oracle, this result restates the BSS problem as an interesting approach not only for reducing computational effort but also for significantly boosting performance. To our knowledge, no previous work has quantified the room of improvement in which BSS techniques could incur. In order to assess the performance of the different BSS techniques, translation results are obtained by using a standard state-of-the-art SMT system (Koehn et al., 2007). The most recent literature defines the SMT problem (Papineni et al., 1998; Och and Ney, 2002) as follows: given an input sentence f from a certain source language, ˆ in a the purpose is to find an output sentence e certain target language such that ˆ = arg max e e K X λk hk (f , e) (1) k=1 where hk (f , e) is a score function representing an important feature for the translation of f into e, as for example the language model of the target language, a reordering model or several translation models. λk are the log-linear combination weights. The main contributions of this paper are: • A BSS te"
E12-1016,W10-1718,0,0.0122111,"a wise BSS technique can yield large improvements when compared with systems trained with all data available. The remaining of the paper is structured as follows. Section 2 summarises the related work. Sections 3 and 4 present two BSS techniques, namely, probabilistic sampling and recovery of infrequent n-grams. In Section 5 experimental results are reported. Finally, the main results of the work and several future work directions are discussed in Section 6. 2 Related Work Training data selection has been receiving an increasing amount of attention within the SMT community. For instance, in (Li et al., 2010; Gasc´o et al., 2010) several BSS techniques, similar to those analysed in this paper, have been applied for training MT systems when there are large training corpora available. However, neither such techniques have been formalised, nor its performance thoroughly analysed. A similar approach that gives weights to different subcorpora was proposed in (Matsoukas et al., 2009). In (Lu et al., 2007), information retrieval methods are used in order to produce different submodels which are then weighted according to the sentence to be translated. In such work, authors define the baseline as the res"
E12-1016,D07-1036,0,0.182634,"rk and several future work directions are discussed in Section 6. 2 Related Work Training data selection has been receiving an increasing amount of attention within the SMT community. For instance, in (Li et al., 2010; Gasc´o et al., 2010) several BSS techniques, similar to those analysed in this paper, have been applied for training MT systems when there are large training corpora available. However, neither such techniques have been formalised, nor its performance thoroughly analysed. A similar approach that gives weights to different subcorpora was proposed in (Matsoukas et al., 2009). In (Lu et al., 2007), information retrieval methods are used in order to produce different submodels which are then weighted according to the sentence to be translated. In such work, authors define the baseline as the result obtained training only with the corpus that share the same domain of the test. Afterwards they claim that they are able to improve baseline translation quality by adding new sentences retrieved with their method. However, they neither compare their technique with random sentence selection, nor with a model trained with all the corpora. Although the techniques that are applied for BSS are ofte"
E12-1016,D09-1074,0,0.152055,"y, the main results of the work and several future work directions are discussed in Section 6. 2 Related Work Training data selection has been receiving an increasing amount of attention within the SMT community. For instance, in (Li et al., 2010; Gasc´o et al., 2010) several BSS techniques, similar to those analysed in this paper, have been applied for training MT systems when there are large training corpora available. However, neither such techniques have been formalised, nor its performance thoroughly analysed. A similar approach that gives weights to different subcorpora was proposed in (Matsoukas et al., 2009). In (Lu et al., 2007), information retrieval methods are used in order to produce different submodels which are then weighted according to the sentence to be translated. In such work, authors define the baseline as the result obtained training only with the corpus that share the same domain of the test. Afterwards they claim that they are able to improve baseline translation quality by adding new sentences retrieved with their method. However, they neither compare their technique with random sentence selection, nor with a model trained with all the corpora. Although the techniques that are ap"
E12-1016,P10-2041,0,0.142946,"ks have applied sentence selection in small scale AL frameworks. These works extend the training corpora at most with 5000 sentences. In (Ananthakrishnan et al., 2010), sentences are selected by means of discriminative techniques. In (Haffari et al., 2009) a technique is proposed for increasing the counts of phrases that are considered infrequent. Both works significantly differ from the current work not only on the framework, but also on the scale of the experiments, the 153 proposed techniques and the obtained improvements. Similar ideas applied to adaptation problems have been proposed in (Moore and Lewis, 2010; Axelrod et al., 2011). 3 Probabilistic Sampling As discussed in Section 2, BSS has inherently attached many meaningful links with AL techniques. Selecting samples for learning our models, incurs in a well-known difficulty in AL, the so-called sample bias problem (Dasgupta, 2009). This problem, which is spread to the BSS case, is summarised as the distortion introduced by the active strategy into the probability distribution underlying the training corpus. This bias forces the training algorithm to learn a distorted probability model which can significantly differ from the actual one. In orde"
E12-1016,P02-1038,0,0.590142,". Note that although we are not able to achieve such an improvement without an oracle, this result restates the BSS problem as an interesting approach not only for reducing computational effort but also for significantly boosting performance. To our knowledge, no previous work has quantified the room of improvement in which BSS techniques could incur. In order to assess the performance of the different BSS techniques, translation results are obtained by using a standard state-of-the-art SMT system (Koehn et al., 2007). The most recent literature defines the SMT problem (Papineni et al., 1998; Och and Ney, 2002) as follows: given an input sentence f from a certain source language, ˆ in a the purpose is to find an output sentence e certain target language such that ˆ = arg max e e K X λk hk (f , e) (1) k=1 where hk (f , e) is a score function representing an important feature for the translation of f into e, as for example the language model of the target language, a reordering model or several translation models. λk are the log-linear combination weights. The main contributions of this paper are: • A BSS technique is analysed, which improves the results obtained with a random bilingual sentence selec"
E12-1016,J03-1002,0,0.00379078,"with Language English French English French English French |S| 47.5K 571 641 |W | 747K 793K 9.2K 10.3K 12.6K 12.8K |V | 24.6K 31.7K 1.9K 2.2K 2.4K 2.7K Table 2: TED corpus main figures. K denotes thousands of elements. |S |stands for number of sentences, |W |for number of running words, and |V |for vocabulary size. Subset train dev 08 test 09 test 10 Language English French English French English French English French |S| 77.2K 2.1K 2.5K 2.5K |W | 1.71M 1.99M 49.8K 55.4K 65.6K 72.5K 62K 70.5K |V | 29.9K 48K 8.7K 7.7K 8.9K 10.6K 8.9K 10.3K Table 3: News Commentary corpus main figures. GIZA++ (Och and Ney, 2003). The language model used was a 5-gram with modified KneserNey smoothing (Kneser and Ney, 1995), built with SRILM toolkit (Stolcke, 2002). The loglinear combination weights in Eq. (1) were optimised using Minimum Error Rate Training (Och and Ney, 2002) on the corresponding development sets. Experiments were carried out on two corpora: TED (Paul et al., 2010) and News Commentary (NC) (Callison-Burch et al., 2010). TED is an English-French corpus composed of subtitles for a collection of public speeches on a variety of topics. The same partitions as in the IWSLT2010 evaluation task (Paul et al.,"
E12-1016,2001.mtsummit-papers.68,0,0.0423191,"included results for a purely random sentence selection without replacement. In the plots, each point corresponding to random selection represent the average of 10 repetitions. Experiments using all data are also reported, although a 64GB machine was necessary, even with binarized phrase and distortion tables. Experiments were conducted by selecting a fixed amount of sentences according to each one of the techniques described above. Then, these sentences were included into the training data and subsequent SMT systems were built for translating the test set. Results are shown in terms of BLEU (Papineni et al., 2001), which is an accuracy metric that measures n-gram precision, with a penalty for sentences that are too short. Although it could be argued that improvements obtained might be due to a side effect of the brevity penalty, this was not found to be true: the BSS techniques (including random) and considering all data yielded very similar brevity penalties (±0.005), within each corpus. In addition, TER scores (Snover et al., 2006) were also computed, but are omitted for clarity purposes and since they were found to be coherent with BLEU. TER is an error metric that computes the minimum number of edi"
E12-1016,2006.amta-papers.25,0,0.0581549,"above. Then, these sentences were included into the training data and subsequent SMT systems were built for translating the test set. Results are shown in terms of BLEU (Papineni et al., 2001), which is an accuracy metric that measures n-gram precision, with a penalty for sentences that are too short. Although it could be argued that improvements obtained might be due to a side effect of the brevity penalty, this was not found to be true: the BSS techniques (including random) and considering all data yielded very similar brevity penalties (±0.005), within each corpus. In addition, TER scores (Snover et al., 2006) were also computed, but are omitted for clarity purposes and since they were found to be coherent with BLEU. TER is an error metric that computes the minimum number of edits required to modify the system hypotheses so that they match the references translations. 0 10 20 30 40 50 60 70 80 90 100 Combined sentence length Figure 2: Combined length relative frequency. 5.2 Results for Probabilistic Sampling In addition to the probabilistic sampling technique proposed in Section 3, we also analysed the effect of sampling only according to the combined source-reference length, with the purpose of es"
E12-1016,2010.amta-commercial.4,0,0.0173614,"Missing"
E12-1016,J93-2003,0,\N,Missing
E12-1016,P02-1040,0,\N,Missing
E12-1016,W09-0401,0,\N,Missing
E12-1016,W10-1703,0,\N,Missing
E12-1016,2010.iwslt-evaluation.1,0,\N,Missing
E12-1025,ambati-etal-2010-active,0,0.015141,"mpractical to batch-learn one single system from all previously translated sentences. Therefore, model training must be done in an incremental fashion. In this work, we present a proposal of AL for IMT specifically designed to work with stream data. In short, our proposal divides the data stream into blocks where AL techniques for static datasets are applied. Additionally, we implement an incremental learning technique to efficiently train the base SMT models as new data is available. 2 Related work A body of work has recently been proposed to apply AL techniques to SMT (Haffari et al., 2009; Ambati et al., 2010; Bloodgood and CallisonBurch, 2010). The aim of these works is to build one single optimal SMT model from manually translated data extracted from static datasets. None of them fit in the setting of data streams. Some of the above described challenges of AL from unbounded streams have been previously addressed in the MT literature. In order to deal with the evolutionary nature of the problem, Nepveu et al. (2004) propose an IMT system with dynamic adaptation via cache-based model extensions for language and translation models. Pursuing the same goal for SMT, Levenberg et al., (2010) study how"
E12-1025,J09-1002,1,0.924873,"Missing"
E12-1025,C04-1046,0,0.0517462,"h the last training data. 5.3 Dynamic confidence sampling Another technique is to consider that the most informative sentence is the one the current SMT model translates worst. The intuition behind this approach is that an SMT model can not generate good translations unless it has enough information to translate the sentence. The usual approach to compute the quality of a translation hypothesis is to compare it to a reference translation, but, in this case, it is not a valid option since reference translations are not available. Hence, we use confidence estimation (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007) to estimate the probability of correctness of the translations. Specifically, we estimate the quality of a translation from the confidence scores of their individual words. The confidence score of a word ei of the translation e = e1 . . . ei . . . eI generated from the source sentence f = f1 . . . fj . . . fJ is computed as described in (Ueffing and Ney, 2005): Cw (ei , f ) = max p(ei |fj ) 0≤j≤ |f | (6) where p(ei |fj ) is an IBM model 1 (Brown et al., 1993) bilingual lexicon probability and f0 is the empty source word. The confidence score for the full translation e"
E12-1025,P10-1088,0,0.358917,"Missing"
E12-1025,J93-2003,0,0.0680945,"unt previously supervised sentences. To efficiently retrain the underlying SMT models of the IMT system (challenge 3), we follow the online learning technique described in (Ortiz-Mart´ınez et al., 2010). Finally, we integrate all these elements to define an AL framework for IMT with an objective of obtaining an optimum balance between translation quality and human user effort. 3 Interactive machine translation IMT can be seen as an evolution of the SMT framework. Given a sentence f from a source language to be translated into a sentence e of a target language, the fundamental equation of SMT (Brown et al., 1993) is defined as follows: ˆ = arg max P r(e |f ) e (1) e where P r(e |f ) is usually approximated by a log linear translation model (Koehn et al., 2003). In this case, the decision rule is given by the expression: ( M ) X ˆ = arg max e λm hm (e, f ) (2) e m=1 where each hm (e, f ) is a feature function representing a statistical model and λm its weight. In the IMT framework, a human translator is introduced in the translation process to collaborate with an SMT model. For a given source sentence, the SMT model fully automatically generates an initial translation. The human user checks this transl"
E12-1025,W07-0718,0,0.0388928,"is because the sentences selected to be translated are more informative. 7.1 Training corpus and data stream The training data comes from the Europarl corpus as distributed for the shared task in the NAACL 2006 workshop on statistical machine translation (Koehn and Monz, 2006). We used this data to estimate the initial log-linear model used by our IMT system (see Section 6). The weights of the different feature functions were tuned by means of minimum error–rate training (Och, 2003) executed on the Europarl development corpus. Once the SMT model was trained, we use the News Commentary corpus (Callison-Burch et al., 2007) to simulate the data stream. The size of these corpora is shown in Table 1. The reasons to choose the News Commentary corpus to carry out our experiments are threefold: first, its size is large enough to simulate a data stream and test our AL techniques in the long term; second, it is out-of-domain data which allows us to simulate a real-world situation that may occur in a translation company, and, finally, it consists in editorials from eclectic domain: general politics, economics and science, which effectively represents the variations in the sentence distributions of the simulated data str"
E12-1025,N09-1047,0,0.227874,"nbounded which makes impractical to batch-learn one single system from all previously translated sentences. Therefore, model training must be done in an incremental fashion. In this work, we present a proposal of AL for IMT specifically designed to work with stream data. In short, our proposal divides the data stream into blocks where AL techniques for static datasets are applied. Additionally, we implement an incremental learning technique to efficiently train the base SMT models as new data is available. 2 Related work A body of work has recently been proposed to apply AL techniques to SMT (Haffari et al., 2009; Ambati et al., 2010; Bloodgood and CallisonBurch, 2010). The aim of these works is to build one single optimal SMT model from manually translated data extracted from static datasets. None of them fit in the setting of data streams. Some of the above described challenges of AL from unbounded streams have been previously addressed in the MT literature. In order to deal with the evolutionary nature of the problem, Nepveu et al. (2004) propose an IMT system with dynamic adaptation via cache-based model extensions for language and translation models. Pursuing the same goal for SMT, Levenberg et a"
E12-1025,W06-3114,0,0.0333051,"eated it as a data stream for AL. To simulate the interaction with the user, we used the reference translations in the data stream corpus as the translation the human user would like to obtain. Since each experiment is carried out under the same conditions, if one sampling strategy outperforms its peers, then we can safely conclude that this is because the sentences selected to be translated are more informative. 7.1 Training corpus and data stream The training data comes from the Europarl corpus as distributed for the shared task in the NAACL 2006 workshop on statistical machine translation (Koehn and Monz, 2006). We used this data to estimate the initial log-linear model used by our IMT system (see Section 6). The weights of the different feature functions were tuned by means of minimum error–rate training (Och, 2003) executed on the Europarl development corpus. Once the SMT model was trained, we use the News Commentary corpus (Callison-Burch et al., 2007) to simulate the data stream. The size of these corpora is shown in Table 1. The reasons to choose the News Commentary corpus to carry out our experiments are threefold: first, its size is large enough to simulate a data stream and test our AL techn"
E12-1025,N03-1017,0,0.0115282,"echnique described in (Ortiz-Mart´ınez et al., 2010). Finally, we integrate all these elements to define an AL framework for IMT with an objective of obtaining an optimum balance between translation quality and human user effort. 3 Interactive machine translation IMT can be seen as an evolution of the SMT framework. Given a sentence f from a source language to be translated into a sentence e of a target language, the fundamental equation of SMT (Brown et al., 1993) is defined as follows: ˆ = arg max P r(e |f ) e (1) e where P r(e |f ) is usually approximated by a log linear translation model (Koehn et al., 2003). In this case, the decision rule is given by the expression: ( M ) X ˆ = arg max e λm hm (e, f ) (2) e m=1 where each hm (e, f ) is a feature function representing a statistical model and λm its weight. In the IMT framework, a human translator is introduced in the translation process to collaborate with an SMT model. For a given source sentence, the SMT model fully automatically generates an initial translation. The human user checks this translation, from left to right, correcting the first 246 source (f ): Para ver la lista de recursos desired translation (ˆ e): To view a listing of resourc"
E12-1025,N10-1062,0,0.545175,"for a given translation quality the use of active learning allows us to greatly reduce the human effort required to translate the sentences in the stream. 1 Introduction Translation needs have greatly increased during the last years due to phenomena such as globalization and technologic development. For example, the European Parliament1 translates its proceedings to 22 languages in a regular basis or Project Syndicate2 that translates editorials into different languages. In these and many other examples, data can be viewed as an incoming unbounded stream since it grows continually with time (Levenberg et al., 2010). Manual translation of such streams of data is extremely expensive given the huge volume of translation required, 1 2 therefore various automatic machine translation methods have been proposed. However, automatic statistical machine translation (SMT) systems are far from generating error-free translations and their outputs usually require human post-editing in order to achieve high-quality translations. One way of taking advantage of SMT systems is to combine them with the knowledge of a human translator in the interactive-predictive machine translation (IMT) framework (Foster et al., 1998; L"
E12-1025,macklovitch-2006-transtype2,0,0.0594675,"he corresponding position of the translation hypothesis. Each character replacement, on the other hand, would correspond to a keystroke of the user. Bearing this in mind, we measure the user effort by means of the keystroke and mouse-action ratio (KSMR) (Barrachina et al., 2009). This measure has been extensively used to report results in the IMT literature. KSMR is calculated as the number of keystrokes plus the number of mouse movements divided by the total number of reference characters. From a user point of view the two types of actions are different and require different types of effort (Macklovitch, 2006). In any case, as an approximation, KSMR assumes that both actions require a similar effort. 7.3 Experimental results In this section, we report results for three different experiments. First, we studied the performance of the sampling strategies when dealing with the sampling bias problem. In the second experiment, we carried out a typical AL experiment measuring the performance of the sampling strategies as a function of the percentage of the corpus used to retrain the SMT model. Finally, we tested our AL implementation for IMT in order to study the tradeoff between required human effort and"
E12-1025,W04-3225,0,0.313442,"chnique to efficiently train the base SMT models as new data is available. 2 Related work A body of work has recently been proposed to apply AL techniques to SMT (Haffari et al., 2009; Ambati et al., 2010; Bloodgood and CallisonBurch, 2010). The aim of these works is to build one single optimal SMT model from manually translated data extracted from static datasets. None of them fit in the setting of data streams. Some of the above described challenges of AL from unbounded streams have been previously addressed in the MT literature. In order to deal with the evolutionary nature of the problem, Nepveu et al. (2004) propose an IMT system with dynamic adaptation via cache-based model extensions for language and translation models. Pursuing the same goal for SMT, Levenberg et al., (2010) study how to bound the space when processing (potentially) unbounded streams of parallel data and propose a method to incrementally retrain SMT models. Another method to efficiently retrain a SMT model with new data was presented in (Ortiz-Mart´ınez et al., 2010). In this work, the authors describe an application of the online learning paradigm to the IMT framework. To the best of our knowledge, the only previous work on A"
E12-1025,P02-1038,0,0.07948,"ncebased informativeness score as: |{ei |Cw (ei , f ) &gt; τw }| C(e, f ) = 1 − (7) |e| Finally, this sampling strategy works by selecting a given percentage of the highest scoring sentences. We dynamically update the confidence sampler each time a new sentence pair is added to the SMT model. The incremental version of the EM algorithm (Neal and Hinton, 1999) is used to incrementally train the IBM model 1. 6 Retraining of the SMT model To retrain the SMT model, we implement the online learning techniques proposed in (OrtizMart´ınez et al., 2010). In that work, a stateof-the-art log-linear model (Och and Ney, 2002) and a set of techniques to incrementally train this model were defined. The log-linear model is composed of a set of feature functions governing different aspects of the translation process, including a language model, a source sentence–length model, inverse and direct translation models, a target phrase–length model, a source phrase– length model and a distortion model. The incremental learning algorithm allows us to process each new training sample in constant time (i.e. the computational complexity of training a new sample does not depend on the number of previously seen training samples)."
E12-1025,P03-1021,0,0.0466815,"rried out under the same conditions, if one sampling strategy outperforms its peers, then we can safely conclude that this is because the sentences selected to be translated are more informative. 7.1 Training corpus and data stream The training data comes from the Europarl corpus as distributed for the shared task in the NAACL 2006 workshop on statistical machine translation (Koehn and Monz, 2006). We used this data to estimate the initial log-linear model used by our IMT system (see Section 6). The weights of the different feature functions were tuned by means of minimum error–rate training (Och, 2003) executed on the Europarl development corpus. Once the SMT model was trained, we use the News Commentary corpus (Callison-Burch et al., 2007) to simulate the data stream. The size of these corpora is shown in Table 1. The reasons to choose the News Commentary corpus to carry out our experiments are threefold: first, its size is large enough to simulate a data stream and test our AL techniques in the long term; second, it is out-of-domain data which allows us to simulate a real-world situation that may occur in a translation company, and, finally, it consists in editorials from eclectic domain:"
E12-1025,N10-1079,1,0.927402,"Missing"
E12-1025,P02-1040,0,0.0899008,"ough to simulate a data stream and test our AL techniques in the long term; second, it is out-of-domain data which allows us to simulate a real-world situation that may occur in a translation company, and, finally, it consists in editorials from eclectic domain: general politics, economics and science, which effectively represents the variations in the sentence distributions of the simulated data stream. 7.2 Assessment criteria We want to measure both the quality of the generated translations and the human effort required to obtain them. We measure translation quality with the wellknown BLEU (Papineni et al., 2002) score. To estimate human user effort, we simulate the actions taken by a human user in its interaction with the IMT system. The first translation hypothesis for each given source sentence is compared with a single reference translation and the longest common character prefix (LCP) is obtained. The first non-matching character is replaced by the corresponding reference character and then a new translation hypothesis is produced (see Figure 1). This process is iterated until a full match with the reference is obtained. Each computation of the LCP would correspond to the user looking for the nex"
E12-1025,2005.eamt-1.35,0,0.0438005,"ion hypothesis is to compare it to a reference translation, but, in this case, it is not a valid option since reference translations are not available. Hence, we use confidence estimation (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007) to estimate the probability of correctness of the translations. Specifically, we estimate the quality of a translation from the confidence scores of their individual words. The confidence score of a word ei of the translation e = e1 . . . ei . . . eI generated from the source sentence f = f1 . . . fj . . . fJ is computed as described in (Ueffing and Ney, 2005): Cw (ei , f ) = max p(ei |fj ) 0≤j≤ |f | (6) where p(ei |fj ) is an IBM model 1 (Brown et al., 1993) bilingual lexicon probability and f0 is the empty source word. The confidence score for the full translation e is computed as the ratio of its words classified as correct by the word confidence measure. Therefore, we define the confidencebased informativeness score as: |{ei |Cw (ei , f ) &gt; τw }| C(e, f ) = 1 − (7) |e| Finally, this sampling strategy works by selecting a given percentage of the highest scoring sentences. We dynamically update the confidence sampler each time a new sentence pair"
E12-1025,J07-1003,0,0.0341341,"data. 5.3 Dynamic confidence sampling Another technique is to consider that the most informative sentence is the one the current SMT model translates worst. The intuition behind this approach is that an SMT model can not generate good translations unless it has enough information to translate the sentence. The usual approach to compute the quality of a translation hypothesis is to compare it to a reference translation, but, in this case, it is not a valid option since reference translations are not available. Hence, we use confidence estimation (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007) to estimate the probability of correctness of the translations. Specifically, we estimate the quality of a translation from the confidence scores of their individual words. The confidence score of a word ei of the translation e = e1 . . . ei . . . eI generated from the source sentence f = f1 . . . fj . . . fJ is computed as described in (Ueffing and Ney, 2005): Cw (ei , f ) = max p(ei |fj ) 0≤j≤ |f | (6) where p(ei |fj ) is an IBM model 1 (Brown et al., 1993) bilingual lexicon probability and f0 is the empty source word. The confidence score for the full translation e is computed as the ratio"
E14-2007,J93-2003,0,0.0320766,"Missing"
E14-2007,2010.eamt-1.18,1,0.868591,"Missing"
E14-2007,2005.mtsummit-papers.19,1,0.793548,"Missing"
E14-2007,D08-1051,1,0.931323,"Missing"
E14-2007,J09-1002,1,\N,Missing
E14-2007,P07-2045,1,\N,Missing
E14-2007,2012.eamt-1.5,1,\N,Missing
E14-2012,P07-2045,0,0.0166772,"e Statistical Machine Translation Francisco Casacuberta Dpto. de Sist. Inf. y Comp. Univ. Polit´ec. de Valencia 46071 Valencia, Spain fcn@dsic.upv.es Daniel Ortiz-Mart´ınez Dpto. de Sist. Inf. y Comp. Univ. Polit´ec. de Valencia 46071 Valencia, Spain dortiz@dsic.upv.es Abstract tures provided by T HOT can be classified into advanced features and standard features. Advanced features correspond to sophisticated functionality that has received poor or no attention in existing SMT toolkits. By contrast, standard features correspond to functionality already provided by popular tools such as Moses (Koehn et al., 2007). In this regard, T HOT neither is based on Moses nor shares any source code with it. T HOT includes the following advanced features: We present the new T HOT toolkit for fullyautomatic and interactive statistical machine translation (SMT). Initial public versions of T HOT date back to 2005 and did only include estimation of phrase-based models. By contrast, the new version offers several new features that had not been previously incorporated. The key innovations provided by the toolkit are computeraided translation, including post-editing and interactive SMT, incremental learning and robust g"
E14-2012,2013.iwslt-papers.10,0,0.0576245,"SMT. In particular, IMT has been studied in numerous research papers during the last years. In spite of this, this application has not previously been implemented in open-source software tools. Incremental (or online) learning is a hot research topic in SMT due to the great interest of quickly incorporating incoming data into existing translation systems. In spite of the fact that the Moses toolkit already implements incremental learning techniques, such techniques are designed to work by incrementally processing large blocks of data and not in a sentence-wise manner, as it is pointed out in (Mirking and Cancedda, 2013). By Introduction Open-source software constitutes a valuable resource for researchers or companies. Due to the inherent difficulties of developing good quality software (correct, efficient, modular, extensible, well-documented, etc.), there are interesting research ideas that not always receive enough attention from the open-source software community. We present the T HOT toolkit for statistical machine translation (SMT). The first public version of T HOT was initially created in 2005 (Ortiz et al., 2005) and its functionality was restricted to train phrase-based models (Koehn et al., 2003)."
E14-2012,2005.mtsummit-papers.19,1,0.908648,"Missing"
E14-2012,2008.eamt-1.22,1,0.867869,"Missing"
E14-2012,N10-1079,1,0.921201,"Missing"
E14-2012,J09-1002,1,0.901437,"Missing"
E14-2012,N03-1017,0,\N,Missing
E14-4018,J90-2002,0,0.888963,"Missing"
E14-4018,2011.eamt-1.35,1,0.903072,"Missing"
E14-4018,W07-0718,0,0.0224017,"Missing"
E14-4018,W05-0835,0,0.0261369,"hat the length (in bits) of the encoded data is minimum and equal to − log2 (Pr(D)). In other words, searching for a minimum description length reduces to searching for a good probability distribution, and vice versa. Taking these considerations into account, MDL inference is formalized as: b = argmin DL(Φ, D) Φ 3.2 We now describe how to perform the maximization in Equation (2). In the case of PB models, this reduces to a search for the optimal phrase lexicon. Obviously, an exhaustive search over all possible sets of phrase pairs in the data is unfeasible in practice. Following the ideas in (Vilar and Vidal, 2005), we implement a search procedure that iteratively generalizes an initial PB model that perfectly fits the data. Let D = {f n , en }N n=1 be a data set with N sentence pairs, where f n are sentences in the source language and en are their corresponding translation in the target language. Our initial PB model will be as follows: (1) Φ = argmin DL(Φ) + DL(D |Φ) Φ (2) where DL(Φ) denotes the description length of the model, and DL(D |Φ) denotes the description length of the data given the model. A complete introductory tutorial of the MDL principle and methods can be found in (Gr¨unwald, 2004). 3"
E14-4018,C96-2141,0,0.313256,"DL inference procedure, described in Section 3, learns PB models by iteratively generalizing an initial model that perfectly overfits training data. An MDL objective is used to guide this process. MDL inference has the following desirable properties: Introduction Since their introduction at the beginning of the twenty-first century, phrase-based (PB) translation models (Koehn et al., 2003) have become the state-of-the-art for statistical machine translation (SMT). PB model provide a big leap in translation quality with respect to the previous word-based translation models (Brown et al., 1990; Vogel et al., 1996). However, despite their empirical success, inference procedures for PB models rely on a long pipeline of heuristics (Och and Ney, 2003) and mismatched learning models, such as the long outperformed word-based models. Latter stages of the pipeline cannot recover mistakes or omissions made in earlier stages which forces the individual stages to massively overgenerate hypotheses. This manifests as a huge redundancy in the inferred phrase lexicons, which in turn largely penalizes the efficiency of PB systems at run-time. The fact that PB models usually cannot generate the sentence pairs in which"
E14-4018,N03-1017,0,0.0473471,"previously used to infer monolingual grammars (Gr¨unwald, 1996) and inversion transduction grammars (Saers et al., 2013). Here, we adapt the basic principles described in the latter article to the inference of PB models. The MDL inference procedure, described in Section 3, learns PB models by iteratively generalizing an initial model that perfectly overfits training data. An MDL objective is used to guide this process. MDL inference has the following desirable properties: Introduction Since their introduction at the beginning of the twenty-first century, phrase-based (PB) translation models (Koehn et al., 2003) have become the state-of-the-art for statistical machine translation (SMT). PB model provide a big leap in translation quality with respect to the previous word-based translation models (Brown et al., 1990; Vogel et al., 1996). However, despite their empirical success, inference procedures for PB models rely on a long pipeline of heuristics (Och and Ney, 2003) and mismatched learning models, such as the long outperformed word-based models. Latter stages of the pipeline cannot recover mistakes or omissions made in earlier stages which forces the individual stages to massively overgenerate hypo"
E14-4018,P07-2045,0,0.0442772,"d for EuTransI due to its simplicity. Empirical Results We evaluated the proposed inference procedure on the EuTransI (Amengual et al., 2000) and the News Commentary (Callison-Burch et al., 2007) corpora. Table 1 shows their main figures. We inferred PB models (set of phrase pairs and their corresponding probabilities) with the training partitions as described in Section 3.2. Then, we included these MDL-based PB models in a conventional log-linear model optimized with the tuning partitions (Och, 2003). Finally, we generated translations for the test partitions using a conventional PB decoder (Koehn et al., 2007). Table 2 shows size (number of phrase pairs) of the inferred MDL-based PB models, and BLEU score (Papineni et al., 2002) of their translations of the tune and test partitions. As a comparison, we display results for a state-of-the-art (SotA) PB system (Koehn et al., 2007). These results show that MDL inference obtained much more concise models (less than one tenth the number of phrases) than the standard inference pipeline. Additionally, the translations of the simple EuTransI corpus were of a similar quality as the ones obtained by the SotA system. In contrast, the quality of the translation"
E14-4018,J03-1002,0,0.0133273,"ining data. An MDL objective is used to guide this process. MDL inference has the following desirable properties: Introduction Since their introduction at the beginning of the twenty-first century, phrase-based (PB) translation models (Koehn et al., 2003) have become the state-of-the-art for statistical machine translation (SMT). PB model provide a big leap in translation quality with respect to the previous word-based translation models (Brown et al., 1990; Vogel et al., 1996). However, despite their empirical success, inference procedures for PB models rely on a long pipeline of heuristics (Och and Ney, 2003) and mismatched learning models, such as the long outperformed word-based models. Latter stages of the pipeline cannot recover mistakes or omissions made in earlier stages which forces the individual stages to massively overgenerate hypotheses. This manifests as a huge redundancy in the inferred phrase lexicons, which in turn largely penalizes the efficiency of PB systems at run-time. The fact that PB models usually cannot generate the sentence pairs in which they have been trained in, or that it is even possible to improve the performance of a PB system by discarding most of the learned phras"
E14-4018,P02-1040,0,\N,Missing
E14-4018,P03-1021,0,\N,Missing
garcia-varea-etal-2002-efficient,C00-2163,1,\N,Missing
garcia-varea-etal-2002-efficient,J93-2003,0,\N,Missing
garcia-varea-etal-2002-efficient,E99-1010,1,\N,Missing
garcia-varea-etal-2002-efficient,J96-1002,0,\N,Missing
garcia-varea-etal-2002-efficient,P01-1027,1,\N,Missing
garcia-varea-etal-2002-efficient,W00-0707,0,\N,Missing
gonzalez-rubio-etal-2010-saturnalia,J93-1004,0,\N,Missing
gonzalez-rubio-etal-2010-saturnalia,J99-1003,0,\N,Missing
gonzalez-rubio-etal-2010-saturnalia,D07-1091,0,\N,Missing
gonzalez-rubio-etal-2010-saturnalia,P07-2045,0,\N,Missing
gonzalez-rubio-etal-2010-saturnalia,2008.eamt-1.9,1,\N,Missing
gonzalez-rubio-etal-2010-saturnalia,W07-0718,0,\N,Missing
gonzalez-rubio-etal-2010-saturnalia,N03-1017,0,\N,Missing
gonzalez-rubio-etal-2010-saturnalia,atserias-etal-2006-freeling,0,\N,Missing
gonzalez-rubio-etal-2010-saturnalia,P03-1021,0,\N,Missing
J04-2004,W00-0508,0,0.505042,"ation experiments within the framework of the EuTrans project. 1. Introduction Formal transducers give rise to an important framework in syntactic-pattern recognition (Fu 1982; Vidal, Casacuberta, and Garc´ıa 1995) and in language processing (Mohri 1997). Many tasks in automatic speech recognition can be viewed as simple translations from acoustic sequences to sublexical or lexical sequences (acoustic-phonetic decoding) or from acoustic or lexical sequences to query strings (for database access) or (robot control) commands (semantic decoding) (Vidal, Casacuberta, and Garc´ıa 1995; Vidal 1997; Bangalore and Ricardi 2000a, 2000b; Hazen, Hetherington, and Park 2001; Mou, Seneff, and Zue 2001; Segarra et al. 2001; Seward 2001). Another similar application is the recognition of continuous hand-written characters (Gonz´alez et al. 2000). Yet a more complex application of formal transducers is language translation, in which input and output can be text, speech, (continuous) handwritten text, etc. (Mohri 1997; Vidal 1997; Bangalore and Ricardi 2000b, 2001; Amengual et al. 2000). Rational transductions (Berstel 1979) constitute an important class within the field of formal translation. These transductions are realiz"
J04-2004,N01-1018,0,0.0401079,"Missing"
J04-2004,J93-2003,0,0.021193,"Missing"
J04-2004,knight-al-onaizan-1998-translation,0,0.438186,"Missing"
J04-2004,J97-2003,0,0.0159805,"training corpus of source-target pairs of sentences, the proposed approach uses statistical alignment methods to produce a set of conventional strings from which a stochastic rational grammar (e.g., an n-gram) is inferred. This grammar is finally converted into a finite-state transducer. The proposed methods are assessed through a series of machine translation experiments within the framework of the EuTrans project. 1. Introduction Formal transducers give rise to an important framework in syntactic-pattern recognition (Fu 1982; Vidal, Casacuberta, and Garc´ıa 1995) and in language processing (Mohri 1997). Many tasks in automatic speech recognition can be viewed as simple translations from acoustic sequences to sublexical or lexical sequences (acoustic-phonetic decoding) or from acoustic or lexical sequences to query strings (for database access) or (robot control) commands (semantic decoding) (Vidal, Casacuberta, and Garc´ıa 1995; Vidal 1997; Bangalore and Ricardi 2000a, 2000b; Hazen, Hetherington, and Park 2001; Mou, Seneff, and Zue 2001; Segarra et al. 2001; Seward 2001). Another similar application is the recognition of continuous hand-written characters (Gonz´alez et al. 2000). Yet a more"
J04-2004,P00-1056,0,0.0108056,"by an alignment a is Pr(t, a |s). Thus, an optimal alignment between s and t can be computed as ˆ a = argmax Pr(t, a |s) a∈A(s,t) 5 In previous work, this idea was often called morphic generator transducer inference. 210 (11) Casacuberta and Vidal Translation with Finite-State Transducers Different approaches for estimating Pr(t, a |s) were proposed in Brown et al. (1993). These approaches are known as models 1 through 5. Adequate software packages are publicly available for training these statistical models and for obtaining good alignments between pairs of sentences (Al-Onaizan et al. 1999; Och and Ney 2000). An example of Spanish-English sentence alignment is given below: Example 1 ¿ Cu´anto cuesta una habitaci´on individual por semana ? how (2) much (2) does (3) a (4) single (6) room (5) cost (3) per (7) week (8) ? (9) Each number within parentheses in the example represents the position in the source sentence that is aligned with the (position of the) preceding target word. A graphical representation of this alignment is shown in Figure 3. 4.2 First Step of the GIATI Methodology: Transformation of Training Pairs into Strings The first step of the proposed method consists in a labeling process"
J04-2004,2001.mtsummit-papers.68,0,0.0132318,"rd error rate (WER), the sentence error rate (SER), and the bilingual evaluation understudy (BLEU) metric for the translations were used as assessment criteria. The WER is the minimum number of substitution, insertion, and deletion operations needed to convert the word string hypothesized by the translation system into a given single reference word string (ITI et al. 2000). The SER is the result of a direct comparison between the hypothesized and reference word strings as a whole. The BLEU metric is based on the n-grams of the hypothesized translation that occur in the reference translations (Papineni et al 2001). The BLEU metric ranges from 0.0 (worst score) to 1.0 (best score). 5.1 The Spanish-English Translation Tasks A Spanish-English corpus was semi-automatically generated in the first phase of the EuTrans project (Vidal 1997). The domain of the corpus involved typical human-tohuman communication situations at a reception desk of a hotel. A summary of this corpus (EuTrans-0) is given in Table 1 (Amengual et al 2000; Casacuberta et al. 2001). From this (large) corpus, a small subset of ten thousand training sentence pairs (EuTrans-I) was randomly selected in order to approach more realistic traini"
J04-2004,P02-1040,0,\N,Missing
J04-2004,J97-1001,0,\N,Missing
J09-1002,2005.eamt-1.6,1,0.85769,"ulty of the selected tasks. The second aim is to assess the interactive MT (IPMT) approach proposed in this article. The results are presented in different subsections. The ﬁrst two subsections present the MT and IPMT results for the 1-best translation obtained by the different techniques in the Xerox and EU tasks, respectively. The third subsection presents further IPMT results for the 5-best translations on a single pair of languages. Some of these results may differ from results presented in previous works (Cubel et al. 2003; Och, Zens, and Ney 2003; Civera et al. 2004a; Cubel et al. 2004; Bender et al. 2005). The differences are due to variations in the pre-/post-processing procedures and/or recent improvements of the search techniques used by the different systems. 6.1 Experiments with the Xerox Corpora In this section, the translation results obtained using ATs, PBMs, and SFSTs for all six language pairs of the Xerox corpus are reported. Word-based trigram and class-based ﬁve-gram target-language models were used for the AT models (the parameters of the log-linear model are tuned so as to minimize WER on a development corpus); wordbased trigram target-language models were used for PBMs and trig"
J09-1002,J90-2002,0,0.670725,"the source sentence. The probability Pr(t) represents the well-formedness of t and it is generally called the language model probability (n-gram models are usually adopted [Jelinek 1998]). On the other hand, Pr(s|t) represents the relationship between the two sentences (the source and its translation). It should be of a high value if the source is a good translation of the target and of a low value otherwise. Note that the translation direction is inverted from what would be normally expected; correspondingly the models built around this equation are often called inverted translation models (Brown et al. 1990, 1993). As we will see in Section 3, these models are based on the notion of alignment. It is interesting to note that if we had perfect models, the use of Equation (1) would sufﬁce. Given that we have only approximations, the use of Equation (2) allows the language model to correct deﬁciencies in the translation model. In practice all of these models (and possibly others) are often combined into a loglinear model for Pr(t |s) (Och and Ney 2004):  ˆt = argmax t N   λi · log fi (t, s) (3) i=1 where fi (t, s) can be a model for Pr(s|t), a model for Pr(t|s), a target language model for Pr(t),"
J09-1002,J93-2003,0,0.0457488,"he situation with respect to ﬁnite-state models is similar. Now, Equation (5) is rewritten as ˆts = argmax Pr(tp , ts , s) (7) ts which allows the use of the same models as in Equation (4) as long as the search procedure is changed appropriately (Cubel et al. 2003, 2004; Civera et al. 2004a, 2004b). 3. Statistical and Finite-State Models The models used are presented in the following subsections: Section 3.1 for the conditional distribution Pr(s|t) in Equation (2) and Section 3.2 for the joint distribution Pr(s, t) in Equation (4). 3.1 Statistical Alignment Models The translation models which Brown et al. (1993) introduced to deal with Pr(s|t) in Equation (2) are based on the concept of alignment between the components of a pair (s, t) (thus they are called statistical alignment models). Formally, if the number of the source words in s is J and the number of target words in t is I, an alignment is a function a : {1, ..., J} → {0, ..., I}. The image of j by a will be denoted as aj , in which the particular case aj = 0 means that the position j in s is not aligned with any position of t. By introducing the alignment as a hidden variable in Pr(s|t), Pr(s|t) =  Pr(s, a|t) (8) a The alignment that maximi"
J09-1002,E06-1032,0,0.0363245,"Missing"
J09-1002,J04-2004,1,0.914,"to complete this preﬁx. We will refer to this process as interactive-predictive machine translation (IPMT). This approach introduces two important requirements: First, the models have to provide adequate completions and, second, this has to happen efﬁciently. Taking these requirements into account, stochastic ﬁnite-state transducers (SFSTs), alignment templates (ATs), and phrase-based models (PBMs) are compared in this work. In previous works these models have proven adequate for conventional MT (Vidal 1997; Amengual et al. 2000; Ney et al. 2000; Tom´as and Casacuberta 2001; Och and Ney 2003; Casacuberta and Vidal 2004; Och and Ney 2004; Vidal and Casacuberta 2004). This article shows that 1 The terms preﬁx and sufﬁx are used here to denote any substring at the beginning and end (respectively) of a string of characters (including spaces and punctuation), with no implication of morphological signiﬁcance as is usually implied by these terms in linguistics. 4 Barrachina et al. Statistical Computer-Assisted Translation existing efﬁcient searching algorithms can be adapted in order to provide completions (rather than full translations) also in a very efﬁcient way. The work presented here has been carried out in"
J09-1002,W04-3245,1,0.805366,"Missing"
J09-1002,2003.eamt-1.6,1,0.848014,"Missing"
J09-1002,W02-1020,0,0.464538,"rs in order to solve different types of (lexical, syntactic, or semantic) ambiguities (Slocum 1985; Whitelock et al. 1986). Other interaction strategies have been considered for updating user dictionaries or for searching through dictionaries (Slocum 1985; Whitelock et al. 1986). Speciﬁc proposals can be found in Tomita (1985), Zajac (1988), Yamron et al. (1993), and Sen, Zhaoxiong, and Heyan (1997), among others. An important contribution to CAT technology, carried out within the TransType project, is worth mentioning (Foster, Isabelle, and Plamondon 1997; Langlais, Foster, and Lapalme 2000; Foster 2002; Langlais, Lapalme, and Loranger 2002). It entailed an interesting focus shift in which interaction is directly aimed at the production of the target text, rather than at the disambiguation of the source text, as in earlier interactive systems. The idea proposed in that work was to embed data-driven MT techniques within the interactive translation environment. The hope was to combine the best of both paradigms: CAT, in which the human translator ensures high-quality output, and MT, in which the machine ensures a signiﬁcant gain in productivity. Following these TransType ideas, the innovative"
J09-1002,1997.mtsummit-papers.1,0,0.474006,"Missing"
J09-1002,W04-3250,0,0.0485459,"Missing"
J09-1002,N03-1017,0,0.0196276,"Missing"
J09-1002,W00-0507,0,0.93842,"Missing"
J09-1002,macklovitch-2006-transtype2,0,0.686113,"complete sentence hypotheses on which the human translator can work. This is an important difference to previous work, in which the use of basic MT techniques only allowed the prediction of single tokens (c.f., Section 2.2). Second, using fully ﬂedged SMT systems, we have performed systematic ofﬂine experiments to simulate the speciﬁc conditions of interactive translation and we report and study the results of these experiments. Thirdly, the IPMT systems presented in this article were successfully used in several ﬁeld trials with professional translators (Macklovitch, Nguyen, and Silva 2005; Macklovitch 2006). We should ﬁnally mention that the work developed in TT2 has gone beyond conventional keyboard-and-mouse interaction, leading to the development of advanced multi-modal interfaces. Speech is the most natural form of human communication and its use as feedback in the IPMT framework has been explored by Vidal et al. (2006). On the other hand, human translators can be faster dictating the translation text rather than typing it, thus it has also been investigated how to improve system performance and usability when the user dictates the translation ﬁrst and then edits the recognized text (Khadivi"
J09-1002,W02-1018,0,0.148046,"onto their 10 Barrachina et al. Statistical Computer-Assisted Translation classes. To reduce the memory requirements, only probabilities for phrases up to a maximal length are estimated, and phrases with a probability estimate below a certain threshold are discarded. The weights λi in Equation (10) are usually estimated using held-out data with respect to the automatic evaluation metric employed using the downhill simplex algorithm from Press et al. (2002). 3.1.2 Phrase-Based Models. A simple alternative to AT has been introduced in recent works: The PBM approach (Tom´as and Casacuberta 2001; Marcu and Wong 2002; Zens, Och, and Ney 2002; Tom´as and Casacuberta 2003; Zens and Ney 2004). These methods learn the probability that a sequence of contiguous words—the source phrase—(as a whole unit) in a source sentence is a translation of another sequence of contiguous words—the target phrase—(as a whole unit) in the target sentence. In this case, the statistical dictionaries of single word pairs are substituted by statistical dictionaries of bilingual phrases or bilingual segments. These models are simpler than ATs, because no alignments are assumed between word positions inside a bilingual segment and wor"
J09-1002,E99-1010,0,0.0131006,"on is used for target words, phrases, and sequences in target sentence t. 3.1.1 Alignment Templates. The ATs are based on the bilingual phrases but they are generalized by replacing words with word classes and by storing the alignment ina ), where S and formation for each phrase pair. Formally, an AT Z is a triple (S, T,  a is an T are a source class sequence and a target class sequence, respectively, and  alignment from the set of positions in S to the set of positions in T.4 Mapping of source and target words to bilingual word classes is automatically trained using the method described by Och (1999). The method is actually an unsupervised clustering method which partitions the source and target vocabularies, so that assigning words to classes is a deterministic operation. It is also possible to employ parts-of-speech or semantic categories instead of the unsupervised clustering method used here. More details can be found in Och (1999) and Och and Ney (2004). However, it should be mentioned that the whole AT approach (and similar PBM approaches as they are now called) is independent of the word clustering concept. In particular, for large training corpora, omitting the word clustering in"
J09-1002,J03-1002,1,0.080838,"lation sufﬁx(es)1 to complete this preﬁx. We will refer to this process as interactive-predictive machine translation (IPMT). This approach introduces two important requirements: First, the models have to provide adequate completions and, second, this has to happen efﬁciently. Taking these requirements into account, stochastic ﬁnite-state transducers (SFSTs), alignment templates (ATs), and phrase-based models (PBMs) are compared in this work. In previous works these models have proven adequate for conventional MT (Vidal 1997; Amengual et al. 2000; Ney et al. 2000; Tom´as and Casacuberta 2001; Och and Ney 2003; Casacuberta and Vidal 2004; Och and Ney 2004; Vidal and Casacuberta 2004). This article shows that 1 The terms preﬁx and sufﬁx are used here to denote any substring at the beginning and end (respectively) of a string of characters (including spaces and punctuation), with no implication of morphological signiﬁcance as is usually implied by these terms in linguistics. 4 Barrachina et al. Statistical Computer-Assisted Translation existing efﬁcient searching algorithms can be adapted in order to provide completions (rather than full translations) also in a very efﬁcient way. The work presented h"
J09-1002,J04-4002,1,0.860643,"ill refer to this process as interactive-predictive machine translation (IPMT). This approach introduces two important requirements: First, the models have to provide adequate completions and, second, this has to happen efﬁciently. Taking these requirements into account, stochastic ﬁnite-state transducers (SFSTs), alignment templates (ATs), and phrase-based models (PBMs) are compared in this work. In previous works these models have proven adequate for conventional MT (Vidal 1997; Amengual et al. 2000; Ney et al. 2000; Tom´as and Casacuberta 2001; Och and Ney 2003; Casacuberta and Vidal 2004; Och and Ney 2004; Vidal and Casacuberta 2004). This article shows that 1 The terms preﬁx and sufﬁx are used here to denote any substring at the beginning and end (respectively) of a string of characters (including spaces and punctuation), with no implication of morphological signiﬁcance as is usually implied by these terms in linguistics. 4 Barrachina et al. Statistical Computer-Assisted Translation existing efﬁcient searching algorithms can be adapted in order to provide completions (rather than full translations) also in a very efﬁcient way. The work presented here has been carried out in the TransType2 (TT"
J09-1002,E03-1032,1,0.925952,"Missing"
J09-1002,2001.mtsummit-papers.68,0,0.042139,"te the test word perplexity. (K and M denote thousands and millions, respectively.) Train Sent. pairs (K) Running words (M) Vocabulary (K) 214 5.2/5.9 84/97 223 5.7/5.4 86/153 215 5.3/6.0 84/91 Test English/Spanish English/German English/French Sentences (K) Running words (K) Running chars. (K) Perplexity 0.8 20/23 119/135 58/46 0.8 20/19 120/134 57/87 0.8 20/23 119/134 58/45 18 Barrachina et al. r Statistical Computer-Assisted Translation Bilingual evaluation understudy (BLEU): This is based on the coverage of n-grams of the hypothesized translation which occur in the reference translations (Papineni et al. 2001). Other assessment ﬁgures are aimed at estimating the effort needed by a human translator to produce correct translations using the interactive system. To this end, the target translations which a real user would have in mind are simulated by the given references. The ﬁrst translation hypothesis for each given source sentence is compared with a single reference translation and the longest common character preﬁx (LCP) is obtained. The ﬁrst non-matching character is replaced by the corresponding reference character and then a new system hypothesis is produced. This process is iterated until a fu"
J09-1002,J85-1001,0,0.718127,"vantage of the existing MT technologies is to use them in collaboration with human translators within a computer-assisted translation (CAT) or interactive framework (Isabelle and Church 1997). Historically, CAT and MT have been considered different but close technologies (Kay 1997) and more so for one of the most popular CAT technologies, namely, translation memories (Bowker 2002; Somers 2003). Interactivity in CAT has been explored for a long time. Systems have been designed to interact with human translators in order to solve different types of (lexical, syntactic, or semantic) ambiguities (Slocum 1985; Whitelock et al. 1986). Other interaction strategies have been considered for updating user dictionaries or for searching through dictionaries (Slocum 1985; Whitelock et al. 1986). Speciﬁc proposals can be found in Tomita (1985), Zajac (1988), Yamron et al. (1993), and Sen, Zhaoxiong, and Heyan (1997), among others. An important contribution to CAT technology, carried out within the TransType project, is worth mentioning (Foster, Isabelle, and Plamondon 1997; Langlais, Foster, and Lapalme 2000; Foster 2002; Langlais, Lapalme, and Loranger 2002). It entailed an interesting focus shift in whic"
J09-1002,2001.mtsummit-papers.64,1,0.270917,"Missing"
J09-1002,P06-2107,1,0.913773,"Missing"
J09-1002,1985.tmi-1.19,0,0.660886,"considered different but close technologies (Kay 1997) and more so for one of the most popular CAT technologies, namely, translation memories (Bowker 2002; Somers 2003). Interactivity in CAT has been explored for a long time. Systems have been designed to interact with human translators in order to solve different types of (lexical, syntactic, or semantic) ambiguities (Slocum 1985; Whitelock et al. 1986). Other interaction strategies have been considered for updating user dictionaries or for searching through dictionaries (Slocum 1985; Whitelock et al. 1986). Speciﬁc proposals can be found in Tomita (1985), Zajac (1988), Yamron et al. (1993), and Sen, Zhaoxiong, and Heyan (1997), among others. An important contribution to CAT technology, carried out within the TransType project, is worth mentioning (Foster, Isabelle, and Plamondon 1997; Langlais, Foster, and Lapalme 2000; Foster 2002; Langlais, Lapalme, and Loranger 2002). It entailed an interesting focus shift in which interaction is directly aimed at the production of the target text, rather than at the disambiguation of the source text, as in earlier interactive systems. The idea proposed in that work was to embed data-driven MT techniques w"
J09-1002,W02-1021,1,0.507109,"Missing"
J09-1002,C86-1077,0,0.329907,"e existing MT technologies is to use them in collaboration with human translators within a computer-assisted translation (CAT) or interactive framework (Isabelle and Church 1997). Historically, CAT and MT have been considered different but close technologies (Kay 1997) and more so for one of the most popular CAT technologies, namely, translation memories (Bowker 2002; Somers 2003). Interactivity in CAT has been explored for a long time. Systems have been designed to interact with human translators in order to solve different types of (lexical, syntactic, or semantic) ambiguities (Slocum 1985; Whitelock et al. 1986). Other interaction strategies have been considered for updating user dictionaries or for searching through dictionaries (Slocum 1985; Whitelock et al. 1986). Speciﬁc proposals can be found in Tomita (1985), Zajac (1988), Yamron et al. (1993), and Sen, Zhaoxiong, and Heyan (1997), among others. An important contribution to CAT technology, carried out within the TransType project, is worth mentioning (Foster, Isabelle, and Plamondon 1997; Langlais, Foster, and Lapalme 2000; Foster 2002; Langlais, Lapalme, and Loranger 2002). It entailed an interesting focus shift in which interaction is directl"
J09-1002,H93-1037,0,0.121423,"e technologies (Kay 1997) and more so for one of the most popular CAT technologies, namely, translation memories (Bowker 2002; Somers 2003). Interactivity in CAT has been explored for a long time. Systems have been designed to interact with human translators in order to solve different types of (lexical, syntactic, or semantic) ambiguities (Slocum 1985; Whitelock et al. 1986). Other interaction strategies have been considered for updating user dictionaries or for searching through dictionaries (Slocum 1985; Whitelock et al. 1986). Speciﬁc proposals can be found in Tomita (1985), Zajac (1988), Yamron et al. (1993), and Sen, Zhaoxiong, and Heyan (1997), among others. An important contribution to CAT technology, carried out within the TransType project, is worth mentioning (Foster, Isabelle, and Plamondon 1997; Langlais, Foster, and Lapalme 2000; Foster 2002; Langlais, Lapalme, and Loranger 2002). It entailed an interesting focus shift in which interaction is directly aimed at the production of the target text, rather than at the disambiguation of the source text, as in earlier interactive systems. The idea proposed in that work was to embed data-driven MT techniques within the interactive translation en"
J09-1002,C88-2160,0,0.52258,"erent but close technologies (Kay 1997) and more so for one of the most popular CAT technologies, namely, translation memories (Bowker 2002; Somers 2003). Interactivity in CAT has been explored for a long time. Systems have been designed to interact with human translators in order to solve different types of (lexical, syntactic, or semantic) ambiguities (Slocum 1985; Whitelock et al. 1986). Other interaction strategies have been considered for updating user dictionaries or for searching through dictionaries (Slocum 1985; Whitelock et al. 1986). Speciﬁc proposals can be found in Tomita (1985), Zajac (1988), Yamron et al. (1993), and Sen, Zhaoxiong, and Heyan (1997), among others. An important contribution to CAT technology, carried out within the TransType project, is worth mentioning (Foster, Isabelle, and Plamondon 1997; Langlais, Foster, and Lapalme 2000; Foster 2002; Langlais, Lapalme, and Loranger 2002). It entailed an interesting focus shift in which interaction is directly aimed at the production of the target text, rather than at the disambiguation of the source text, as in earlier interactive systems. The idea proposed in that work was to embed data-driven MT techniques within the inte"
J09-1002,N04-1033,1,0.604748,"words are taken into account. Moreover, in practice the summation operator is replaced with the maximization operator, which in turn reduces the contribution of each individual source word in generating a target word. On the other hand, modeling word sequences rather than single words in both the alignment and lexicon models cause signiﬁcant improvement in translation quality (Och and Ney 8 Barrachina et al. Statistical Computer-Assisted Translation 2004). In this work, we use two closely related models: ATs (Och and Ney 2004) and PBMs (Tom´as and Casacuberta 2001; Koehn, Och, and Marcu 2003; Zens and Ney 2004). Both models are based on bilingual phrases3 (pairs of segments or word sequences) in which all words within the source-language phrase are aligned only to words of the target-language phrase and vice versa. Note that at least one word in the sourcelanguage phrase must be aligned to one word of the target-language phrase, that is, there are no empty phrases similar to the empty word of the word-based models. In addition, no gaps and no overlaps between phrases are allowed. We introduce some notation to deal with phrases. As before, s denotes a sources denotes a generic phrase in s, and  sk t"
J09-1002,2002.tmi-tutorials.2,0,0.133044,"Missing"
J09-1002,2004.tmi-1.9,0,0.171592,"Missing"
J09-1002,P02-1040,0,\N,Missing
J09-1002,P06-2061,1,\N,Missing
J09-1002,H93-1087,0,\N,Missing
K16-1020,D14-1130,0,0.504773,"refix-based interaction where the user is forced to correct the errors in the sentence strictly according to the reading order. Our main contribution, described in Section 3, is a new proof-reading protocol focused on providing a more natural interaction between the user and the system. Specifically, we give complete freedom to the user to validate or to correct any part of the translation at any given interaction. As such, the user is no longer bound to correct the errors following the reading order as in previous prefix-based ITP works (Barrachina et al., 2009; Gonz´alez-Rubio et al., 2013; Green et al., 2014). Preffix-based interaction can be a frustrating and cognitively demanding limitation for the user, and may be a factor in the somehow disappointing Current automatic machine translation systems require heavy human proofreading to produce high-quality translations. We present a new interactive machine translation approach aimed at providing a natural collaboration between humans and translation systems. As such, we grant the user complete freedom to validate and correct any part of the translations suggested by the system. Our approach is then designed according to the requirements placed by t"
K16-1020,N03-1017,0,0.00878269,"solutions in the tail hypernodes, as such it has an associated probability P (ε). Figure 2 shows an example hypergraph2 . Two alternative translations are constructed from the leaf hypernodes (1, 2 and 3) up to the root hypernode (6). Hypergraphs provide a compact representation of the translation space that allows us to derive efficient search algorithms. Hypergraphs are the natural representation for hierarchical MT models (Chiang, 2005; Zollmann and Venugopal, 2006). Note, however, that wordgraphs (Ueffing et al., 2002), which are used to represent the search space for phrase-based models (Koehn et al., 2003), are a special case of hypergraphs in which hyperedges have at most one tail hypernode. train Sentences Tokens Vocabulary 214K 5.9M / 5.2M 97K / 84K 400 12K / 10K 3K / 3K test 800 23K / 20K 5K / 4K Table 1: Main figures of the EU corpus. K and M stand for thousands and millions of elements. where I(ν) are the ingoing hyperedges of ν, P (ε) is the probability of hyperedge ε, C(ε, [m, n]) is the set of valid combinations for hyperedge ε and coverage [m, n], and c ∈ C(ε, [m, n]) is one of such valid combinations Leaf hypernodes represent the base cases for this recursion. For simplicity, we rest"
K16-1020,P07-2045,0,0.0104106,"2013). We tokenized the corpus keeping the real case of the sentences. Table 1 shows the main figures of the corpus. We estimated a hierarchical MT model for the train partition with the standard configuration of 3 Preliminary experiments did not show a difference in the final results when relaxing this restriction. For simplicity, we do not show hyperedge probabilities. 202 user to “click” on the initial and final words of the segment4 . Each correction corresponds to an edit operation performed by the user. Specifically, we used the following measures in our experiments: the Moses toolkit (Koehn et al., 2007). Loglinear weighs were estimated by minimum errorrate training (Och, 2003) on the tune partition. Then, we automatically translated tune and test partitions using the optimized model to obtain the corresponding hypergraphs. Next, we optimized the single free parameter pe of the error correction model (see Section 3.2) on the tune partition. Finally, we interactively translated both partitions according to the unrestricted ITP approach proposed in Section 3. 4.2 Word stroke ratio (WSR): Proposed in (Tom´as and Casacuberta, 2006) as the quotient between the number of words edited by the user (w"
K16-1020,2013.mtsummit-user.9,1,0.906992,"Missing"
K16-1020,P14-2094,0,0.023016,"as focused on the development of fully automatic MT approaches. Despite that, except for a handful of very constrained domains, current automatic MT technology still only achieves results 1 We use the terms “human expert”, “human translator”, and ‘user” indistinctly. 198 Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning (CoNLL), pages 198–207, c Berlin, Germany, August 7-12, 2016. 2016 Association for Computational Linguistics ITP is a fruitful research field with diverse contributions for multiple authors: (Gonz´alez-Rubio et al., 2010; Alabau et al., 2013; Koehn et al., 2014) among others. We share with (SanchisTrilles et al., 2008) the idea of making a more sophisticated use of the mouse actions performed by the user while interacting with the system, and with (Gonz´alez-Rubio et al., 2013) the common ITP formulation for both phrase-based and hierarchical MT models. In particular, we significantly modify the prefix-based ITP implementation presented in the latter work to support the proposed unrestricted proof-reading protocol. User studies of prefix-based ITP versus PE have shown that while users tend to make less corrections, overall translation time tend to be"
K16-1020,J09-1002,1,0.953075,"Missing"
K16-1020,P05-1033,0,0.0350362,"nce between ˜fk and the segment ak = ˜tk of t aligned to it according to a. 201 represents the rule applied to generate the partial solution in the head from the partial solutions in the tail hypernodes, as such it has an associated probability P (ε). Figure 2 shows an example hypergraph2 . Two alternative translations are constructed from the leaf hypernodes (1, 2 and 3) up to the root hypernode (6). Hypergraphs provide a compact representation of the translation space that allows us to derive efficient search algorithms. Hypergraphs are the natural representation for hierarchical MT models (Chiang, 2005; Zollmann and Venugopal, 2006). Note, however, that wordgraphs (Ueffing et al., 2002), which are used to represent the search space for phrase-based models (Koehn et al., 2003), are a special case of hypergraphs in which hyperedges have at most one tail hypernode. train Sentences Tokens Vocabulary 214K 5.9M / 5.2M 97K / 84K 400 12K / 10K 3K / 3K test 800 23K / 20K 5K / 4K Table 1: Main figures of the EU corpus. K and M stand for thousands and millions of elements. where I(ν) are the ingoing hyperedges of ν, P (ε) is the probability of hyperedge ε, C(ε, [m, n]) is the set of valid combinations"
K16-1020,P02-1038,0,0.0614974,"tion models. PE (˜fk , ak ) |a |  Y nk 1 The probability of editing pe is the single free parameter of this model. Alternatively, we can use a model based on a multinomial distribution assigning different probabilities to different edit operations. Nevertheless, we adhere to the binomial approximation due to its simplicity. Models |a| Y 5 Figure 2: Example of a hypergraph encoding two different translations for the Spanish sentence: “Vi a un hombre con un telescopio”. In practice, we combine the probability distributions in Equation (2) in a log-linear fashion as it is typically done in MT (Och and Ney, 2002). 3.2 I saw a man with a telescope I saw with a telescope a man 6 pδek (1 − pe )(nk −δk ) where PE (˜fk , ak ) is the error correction probability for the k-th alignment link whose value is given by the probability mass function of the binomial distribution, nk = |˜fk |is the length in words of the k-th segment validated by the user (˜fk ), and δk is the edit distance between ˜fk and the segment ak = ˜tk of t aligned to it according to a. 201 represents the rule applied to generate the partial solution in the head from the partial solutions in the tail hypernodes, as such it has an associated"
K16-1020,P10-2032,1,0.849377,"Missing"
K16-1020,P03-1021,0,0.0203087,"s the main figures of the corpus. We estimated a hierarchical MT model for the train partition with the standard configuration of 3 Preliminary experiments did not show a difference in the final results when relaxing this restriction. For simplicity, we do not show hyperedge probabilities. 202 user to “click” on the initial and final words of the segment4 . Each correction corresponds to an edit operation performed by the user. Specifically, we used the following measures in our experiments: the Moses toolkit (Koehn et al., 2007). Loglinear weighs were estimated by minimum errorrate training (Och, 2003) on the tune partition. Then, we automatically translated tune and test partitions using the optimized model to obtain the corresponding hypergraphs. Next, we optimized the single free parameter pe of the error correction model (see Section 3.2) on the tune partition. Finally, we interactively translated both partitions according to the unrestricted ITP approach proposed in Section 3. 4.2 Word stroke ratio (WSR): Proposed in (Tom´as and Casacuberta, 2006) as the quotient between the number of words edited by the user (wordstrokes), and the number of words in the final translation. Word-strokes"
K16-1020,D13-1025,1,0.856506,"Missing"
K16-1020,P06-2107,1,0.82706,"Missing"
K16-1020,P02-1040,0,0.0973342,"a particular case of our user simulation with no segment validation. 4.3 Conceptually (Macklovitch et al., 2005), MAR can be seen as accounting for the cognitive part of the supervision process: undertanding the translation and identifying the errors in it, while WSR accounts for the actual physical effort required to type the corrections. As such, both metrics are complementary to express the total human effort involved in proof-reading a document. We also evaluated the quality of the initial automatic translations generated by the system: Bilingual evaluation understudy (BLEU): Proposed in (Papineni et al., 2002), it is based on the precision of n-grams between the suggested translation and the reference; it also includes a brevity penalty to penalize short translations. This score ranges between 0 and 100, with 100 denoting a perfect translation. Translation edit rate (TER): Proposed in (Snover et al., 2006), it measures the number of edit operations (substitution, insertion and deletion of single words, and swap of word sequences) divided by the number of words in the reference. Evaluation Metrics ITP systems are evaluated according to the effort needed to generate the desired translations. This eff"
K16-1020,D08-1051,1,0.823892,"Missing"
K16-1020,W02-1021,0,0.0310178,"01 represents the rule applied to generate the partial solution in the head from the partial solutions in the tail hypernodes, as such it has an associated probability P (ε). Figure 2 shows an example hypergraph2 . Two alternative translations are constructed from the leaf hypernodes (1, 2 and 3) up to the root hypernode (6). Hypergraphs provide a compact representation of the translation space that allows us to derive efficient search algorithms. Hypergraphs are the natural representation for hierarchical MT models (Chiang, 2005; Zollmann and Venugopal, 2006). Note, however, that wordgraphs (Ueffing et al., 2002), which are used to represent the search space for phrase-based models (Koehn et al., 2003), are a special case of hypergraphs in which hyperedges have at most one tail hypernode. train Sentences Tokens Vocabulary 214K 5.9M / 5.2M 97K / 84K 400 12K / 10K 3K / 3K test 800 23K / 20K 5K / 4K Table 1: Main figures of the EU corpus. K and M stand for thousands and millions of elements. where I(ν) are the ingoing hyperedges of ν, P (ε) is the probability of hyperedge ε, C(ε, [m, n]) is the set of valid combinations for hyperedge ε and coverage [m, n], and c ∈ C(ε, [m, n]) is one of such valid combin"
K16-1020,underwood-etal-2014-evaluating,1,0.901394,"Missing"
K16-1020,2004.tmi-1.9,0,0.229078,"Missing"
K16-1020,W06-3119,0,0.0225433,"k and the segment ak = ˜tk of t aligned to it according to a. 201 represents the rule applied to generate the partial solution in the head from the partial solutions in the tail hypernodes, as such it has an associated probability P (ε). Figure 2 shows an example hypergraph2 . Two alternative translations are constructed from the leaf hypernodes (1, 2 and 3) up to the root hypernode (6). Hypergraphs provide a compact representation of the translation space that allows us to derive efficient search algorithms. Hypergraphs are the natural representation for hierarchical MT models (Chiang, 2005; Zollmann and Venugopal, 2006). Note, however, that wordgraphs (Ueffing et al., 2002), which are used to represent the search space for phrase-based models (Koehn et al., 2003), are a special case of hypergraphs in which hyperedges have at most one tail hypernode. train Sentences Tokens Vocabulary 214K 5.9M / 5.2M 97K / 84K 400 12K / 10K 3K / 3K test 800 23K / 20K 5K / 4K Table 1: Main figures of the EU corpus. K and M stand for thousands and millions of elements. where I(ν) are the ingoing hyperedges of ν, P (ε) is the probability of hyperedge ε, C(ε, [m, n]) is the set of valid combinations for hyperedge ε and coverage ["
K16-1020,2006.amta-papers.25,0,0.0252895,"ort required to type the corrections. As such, both metrics are complementary to express the total human effort involved in proof-reading a document. We also evaluated the quality of the initial automatic translations generated by the system: Bilingual evaluation understudy (BLEU): Proposed in (Papineni et al., 2002), it is based on the precision of n-grams between the suggested translation and the reference; it also includes a brevity penalty to penalize short translations. This score ranges between 0 and 100, with 100 denoting a perfect translation. Translation edit rate (TER): Proposed in (Snover et al., 2006), it measures the number of edit operations (substitution, insertion and deletion of single words, and swap of word sequences) divided by the number of words in the reference. Evaluation Metrics ITP systems are evaluated according to the effort needed to generate the desired translations. This effort is usually estimated as the number of actions performed by the user while interacting with the system. In our user simulation, we describe two different actions: segment-validation, and wordcorrection. Each segment validation involves the In addition to be an MT quality metric, TER can also be see"
K18-1015,J09-1002,1,0.926511,"Missing"
K18-1015,C04-1046,0,0.0155764,"anslate(θ, x); 7 if x ∈ V then ˆ = INMT(θ, x, y); 8 y ˆ )); 9 θ = update(θ, (x, y 10 output(ˆ y); 11 else 12 output(y); 13 end 14 end 15 until S = 6 ∅; 16 end 5.1 The idea behind this family of methods is to select those instances for which the model has the least confidence to be properly translated. Therefore, all techniques compute, for each sample, an uncertainty score. The selected sentences will be those with the highest scores. Quality estimation sampling A common and effective way for measuring the uncertainty of a MT system is to use confidence estimation (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007). The idea is to estimate the quality of a translation according to confidence scores of the words. More specifically, given a source sentence x = x1 , . . . , xJ and a translation hypothesis y = y1 , . . . , yI , a word confidence score (Cw ) as computed as (Ueffing and Ney, 2005): Cw (x, yi ) = max p(yi |xj ) 0≤j≤J (3) where p(yi |xj ) is the alignment probability of yi and xj , given by an IBM Model 2 (Brown et al., 1993). x0 denotes the empty source word. The choice of the IBM Model 2 is twofold: on the one hand, it is a very fast method, which only requires to quer"
K18-1015,P10-1088,0,0.193648,"anslations. Therefore, it is mandatory to spare human effort, at the expense of some translation quality. Hence, when facing this situation, we have a twofold objective: on the one hand, we aim to obtain translations with the highest quality possible. On the other hand, we are constrained by the amount of human effort spent in the supervision and correction process of the translations proposed by an MT system. The active learning (AL) framework is wellsuited for these objectives. The application of AL techniques to MT involve to ask a human oracle to supervise a fraction of the incoming data (Bloodgood and Callison-Burch, 2010). Once the human has revised these samples, they are used for improving the MT system, via incremental learning. Therefore, a key element of AL is the so-called sampling strategy, which determines the sentences that should be corrected by the human. Aiming to reduce the human effort required during post-editing, other alternative frameworks have been study. A successful one is the interactive-predictive machine translation (IMT) paradigm (Foster et al., 1997; Barrachina et al., 2009). In IMT, human and MT system jointly collaborate for obtaining high-quality translations, while reducing the hu"
K18-1015,D17-1151,0,0.0188092,"keystrokes plus the number of mouse-actions required for obtaining the desired sentence, divided by the number of characters of such sentence. We add a final mouse-action, accounting for action of accepting the translation hypothesis. Although keystrokes and mouse-actions are different and require a different amount of effort (Macklovitch et al., 2005), KSMR makes an approximation and assumes that both actions require a similar effort. 6.2 Our NMT system was built using NMT-Keras (Peris and Casacuberta, 2018a) and featured a bidirectional LSTM encoder and a decoder with cLSTM units. Following Britz et al. (2017), we set the dimension of the LSTM, embeddings and attention model to 512. We applied batch normalizing transform (Ioffe and Szegedy, 2015) and Gaussian noise during training (Graves, 2011). The L2 norm of the gradients was clipped to 5, for avoiding the exploiting gradient effect (Pascanu et al., 2012). We applied joint byte pair encoding (BPE) (Sennrich et al., 2016) to all corpora. For training the system, we used Adam (Kingma and Ba, 2014), with a learning rate of 0.0002 and a batch size of 50. We early-stopped the training according to the BLEU on our development set. For decoding, we use"
K18-1015,J93-2003,0,0.064036,"mation sampling A common and effective way for measuring the uncertainty of a MT system is to use confidence estimation (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007). The idea is to estimate the quality of a translation according to confidence scores of the words. More specifically, given a source sentence x = x1 , . . . , xJ and a translation hypothesis y = y1 , . . . , yI , a word confidence score (Cw ) as computed as (Ueffing and Ney, 2005): Cw (x, yi ) = max p(yi |xj ) 0≤j≤J (3) where p(yi |xj ) is the alignment probability of yi and xj , given by an IBM Model 2 (Brown et al., 1993). x0 denotes the empty source word. The choice of the IBM Model 2 is twofold: on the one hand, it is a very fast method, which only requires to query in a dictionary. We are in an interactive framework, therefore speed becomes a crucial requirement. On the other hand, its performance is close to more complex methods (Blatz et al., 2004; Dyer et al., 2013). Following Gonz´alez-Rubio et al. (2012), the uncertainty score for the quality estimation sampling is defined as: θ from the NMT model, via SGD. This is done ˆ )). Therefore, with the function update(θ, (x, y the NMT system is incrementally"
K18-1015,N09-1047,0,0.22089,"process is done by means of an interactive-predictive NMT (INMT) system, which aims to reduce the human effort of this process. The supervised samples will be used for the NMT system to incrementally improve its models. To the best of our knowledge, this is the first work that introduces an INMT system into the scenario involving the translation of unbounded data. Our main contributions are: The translation of large volumes of data is a scenario very appropriate for the AL framework (Cohn et al., 1994; Olsson, 2009; Settles, 2009). The application of AL to SMT has been studied for pool-based (Haffari et al., 2009; Bloodgood and Callison-Burch, 2010) and stream-based (Gonz´alez-Rubio et al., 2011) setups. Later works (Gonz´alez-Rubio et al., 2012; Gonz´alez-Rubio and Casacuberta, 2014), combined AL together with IMT, showing that AL can effectively reduce the human effort required for achieving a certain translation quality. All these works were based on SMT systems. However, the recently introduced NMT paradigm (Sutskever et al., 2014; Bahdanau et al., 2015) has irrupted as the current state-of-the-art for MT (Bojar et al., 2017). Several works aimed at building more productive NMT systems. Related to"
K18-1015,W07-0718,0,0.016826,"g to Gonz´alez-Rubio et al. (2012), the performance is similar regardless the block size). For the quality estimation method, the IBM Model 2 was obtained with fast align (Dyer et al., 2013) and τw was set to 0.4 (Gonz´alez-Rubio et al., 2010). Corpora To ensure a fair comparison with the latter works of AL applied to IMT (Gonz´alez-Rubio and Casacuberta, 2014), we used the same datasets: our training data was the Europarl corpus (Koehn, 2005), with the development set provided at the 2006 workshop on machine translation (Koehn and Monz, 2006). As test set, we used the News Commentary corpus (Callison-Burch et al., 2007). This test set is suitable to our problem at hand because i. it contains data from different domains (politics, economics and science), which represent challenging out-of-domain samples, but account for a real-life situation in a translation agency; and ii. it is large enough to properly simulate longterm evolution of unbounded data streams. All data are publicly available. We conducted the experimentation in the Spanish to English language direction. Table 1 shows the main figures of our data. 7 of sentences (|S|), number of running words (|W |) and vocabulary size (|V |). k and M stand for"
K18-1015,P82-1020,0,0.784109,"Missing"
K18-1015,P17-1141,0,0.0271656,". Later works (Gonz´alez-Rubio et al., 2012; Gonz´alez-Rubio and Casacuberta, 2014), combined AL together with IMT, showing that AL can effectively reduce the human effort required for achieving a certain translation quality. All these works were based on SMT systems. However, the recently introduced NMT paradigm (Sutskever et al., 2014; Bahdanau et al., 2015) has irrupted as the current state-of-the-art for MT (Bojar et al., 2017). Several works aimed at building more productive NMT systems. Related to our work, studies on interactive NMT systems (Knowles and Koehn, 2016; Peris et al., 2017; Hokamp and Liu, 2017) proved the efficacy of this framework. A body of work has been done aiming to build adaptive NMT systems, which continuously learn from human corrections (Turchi et al., 2017; Peris and Casacuberta, 2018b). Recently, Lam et al. (2018) applied AL techniques to an INMT system, for deciding whether the user should revise a partial hypothesis or not. However, to our knowledge, a study on the use of AL for NMT in a scenario of translation of unbounded data streams is still missing. • We study the application of AL on an INMT framework when dealing with large data streams. We introduce two sampling"
K18-1015,E14-1042,0,0.0196746,"2015). Each element from the input sequence is projected into a continuous space by means of an embedding matrix. The sequence of embeddings is then processed by a bidirectional (Schuster and Paliwal, 1997) LSTM network, that concatenates the hidden states from forward and backward layers and produces a sequence of annotations. Related work The translation of large data streams is a problem that has been thoroughly studied. Most works aim to continuously modify the MT system as more data become available. These modifications are usually performed in an incremental way (Levenberg et al., 2010; Denkowski et al., 2014; Turchi et al., 2017), learning from user post-edits. This incremental learning has also been applied to IMT, either to phrase-based statistical machine translation (SMT) systems (Nepveu et al., 2004; OrtizMart´ınez, 2016) or NMT (Peris and Casacuberta, 2018b). 2 The source code can be found at: https: //github.com/lvapeab/nmt-keras/tree/ interactive_NMT. 152 The decoder is a conditional LSTM (cLSTM) network (Peris and Casacuberta, 2018b). A cLSTM network is composed of several LSTM transition blocks with an attention mechanism in between. We use two LSTM blocks. The output of the decoder is"
K18-1015,2016.amta-researchers.9,0,0.24563,"m-based (Gonz´alez-Rubio et al., 2011) setups. Later works (Gonz´alez-Rubio et al., 2012; Gonz´alez-Rubio and Casacuberta, 2014), combined AL together with IMT, showing that AL can effectively reduce the human effort required for achieving a certain translation quality. All these works were based on SMT systems. However, the recently introduced NMT paradigm (Sutskever et al., 2014; Bahdanau et al., 2015) has irrupted as the current state-of-the-art for MT (Bojar et al., 2017). Several works aimed at building more productive NMT systems. Related to our work, studies on interactive NMT systems (Knowles and Koehn, 2016; Peris et al., 2017; Hokamp and Liu, 2017) proved the efficacy of this framework. A body of work has been done aiming to build adaptive NMT systems, which continuously learn from human corrections (Turchi et al., 2017; Peris and Casacuberta, 2018b). Recently, Lam et al. (2018) applied AL techniques to an INMT system, for deciding whether the user should revise a partial hypothesis or not. However, to our knowledge, a study on the use of AL for NMT in a scenario of translation of unbounded data streams is still missing. • We study the application of AL on an INMT framework when dealing with la"
K18-1015,N13-1073,0,0.130421,"a translation hypothesis y = y1 , . . . , yI , a word confidence score (Cw ) as computed as (Ueffing and Ney, 2005): Cw (x, yi ) = max p(yi |xj ) 0≤j≤J (3) where p(yi |xj ) is the alignment probability of yi and xj , given by an IBM Model 2 (Brown et al., 1993). x0 denotes the empty source word. The choice of the IBM Model 2 is twofold: on the one hand, it is a very fast method, which only requires to query in a dictionary. We are in an interactive framework, therefore speed becomes a crucial requirement. On the other hand, its performance is close to more complex methods (Blatz et al., 2004; Dyer et al., 2013). Following Gonz´alez-Rubio et al. (2012), the uncertainty score for the quality estimation sampling is defined as: θ from the NMT model, via SGD. This is done ˆ )). Therefore, with the function update(θ, (x, y the NMT system is incrementally adapted with new data. The sentences considered unworthy to be supervised are automatically translated according to according Eq. (1), with the function translate(θ, x). Once we finish the translation of the current block B, we start the process again. Algorithm 1 details the full procedure. 5 Uncertainty sampling Sentence sampling strategies Cqe (x, y) ="
K18-1015,2005.mtsummit-papers.11,0,0.0471031,"on on the validation set. The rest of hyperparameters were set according to previous works. The blocks retrieved from the data stream contained 500 samples (according to Gonz´alez-Rubio et al. (2012), the performance is similar regardless the block size). For the quality estimation method, the IBM Model 2 was obtained with fast align (Dyer et al., 2013) and τw was set to 0.4 (Gonz´alez-Rubio et al., 2010). Corpora To ensure a fair comparison with the latter works of AL applied to IMT (Gonz´alez-Rubio and Casacuberta, 2014), we used the same datasets: our training data was the Europarl corpus (Koehn, 2005), with the development set provided at the 2006 workshop on machine translation (Koehn and Monz, 2006). As test set, we used the News Commentary corpus (Callison-Burch et al., 2007). This test set is suitable to our problem at hand because i. it contains data from different domains (politics, economics and science), which represent challenging out-of-domain samples, but account for a real-life situation in a translation agency; and ii. it is large enough to properly simulate longterm evolution of unbounded data streams. All data are publicly available. We conducted the experimentation in the S"
K18-1015,1997.mtsummit-papers.1,0,0.535554,"tives. The application of AL techniques to MT involve to ask a human oracle to supervise a fraction of the incoming data (Bloodgood and Callison-Burch, 2010). Once the human has revised these samples, they are used for improving the MT system, via incremental learning. Therefore, a key element of AL is the so-called sampling strategy, which determines the sentences that should be corrected by the human. Aiming to reduce the human effort required during post-editing, other alternative frameworks have been study. A successful one is the interactive-predictive machine translation (IMT) paradigm (Foster et al., 1997; Barrachina et al., 2009). In IMT, human and MT system jointly collaborate for obtaining high-quality translations, while reducing the human effort spent in this process. In this work, we explore the application of NMT to the translation of unbounded data streams. We apply AL techniques for selecting the instances to Abstract We study the application of active learning techniques to the translation of unbounded data streams via interactive neural machine translation. The main idea is to select, from an unbounded stream of source sentences, those worth to be supervised by a human agent. The us"
K18-1015,D18-1397,0,0.0542607,"ks were based on SMT systems. However, the recently introduced NMT paradigm (Sutskever et al., 2014; Bahdanau et al., 2015) has irrupted as the current state-of-the-art for MT (Bojar et al., 2017). Several works aimed at building more productive NMT systems. Related to our work, studies on interactive NMT systems (Knowles and Koehn, 2016; Peris et al., 2017; Hokamp and Liu, 2017) proved the efficacy of this framework. A body of work has been done aiming to build adaptive NMT systems, which continuously learn from human corrections (Turchi et al., 2017; Peris and Casacuberta, 2018b). Recently, Lam et al. (2018) applied AL techniques to an INMT system, for deciding whether the user should revise a partial hypothesis or not. However, to our knowledge, a study on the use of AL for NMT in a scenario of translation of unbounded data streams is still missing. • We study the application of AL on an INMT framework when dealing with large data streams. We introduce two sampling strategies for obtaining the most useful samples to be supervised by the human. We compare these techniques with other classical, wellperforming strategies. • We conduct extensive experiments, analyzing the different sampling strategi"
K18-1015,N10-1062,0,0.030412,"anism (Bahdanau et al., 2015). Each element from the input sequence is projected into a continuous space by means of an embedding matrix. The sequence of embeddings is then processed by a bidirectional (Schuster and Paliwal, 1997) LSTM network, that concatenates the hidden states from forward and backward layers and produces a sequence of annotations. Related work The translation of large data streams is a problem that has been thoroughly studied. Most works aim to continuously modify the MT system as more data become available. These modifications are usually performed in an incremental way (Levenberg et al., 2010; Denkowski et al., 2014; Turchi et al., 2017), learning from user post-edits. This incremental learning has also been applied to IMT, either to phrase-based statistical machine translation (SMT) systems (Nepveu et al., 2004; OrtizMart´ınez, 2016) or NMT (Peris and Casacuberta, 2018b). 2 The source code can be found at: https: //github.com/lvapeab/nmt-keras/tree/ interactive_NMT. 152 The decoder is a conditional LSTM (cLSTM) network (Peris and Casacuberta, 2018b). A cLSTM network is composed of several LSTM transition blocks with an attention mechanism in between. We use two LSTM blocks. The o"
K18-1015,P10-2032,1,0.820174,"Missing"
K18-1015,E12-1025,1,0.910783,"Missing"
K18-1015,W04-3225,0,0.145369,"97) LSTM network, that concatenates the hidden states from forward and backward layers and produces a sequence of annotations. Related work The translation of large data streams is a problem that has been thoroughly studied. Most works aim to continuously modify the MT system as more data become available. These modifications are usually performed in an incremental way (Levenberg et al., 2010; Denkowski et al., 2014; Turchi et al., 2017), learning from user post-edits. This incremental learning has also been applied to IMT, either to phrase-based statistical machine translation (SMT) systems (Nepveu et al., 2004; OrtizMart´ınez, 2016) or NMT (Peris and Casacuberta, 2018b). 2 The source code can be found at: https: //github.com/lvapeab/nmt-keras/tree/ interactive_NMT. 152 The decoder is a conditional LSTM (cLSTM) network (Peris and Casacuberta, 2018b). A cLSTM network is composed of several LSTM transition blocks with an attention mechanism in between. We use two LSTM blocks. The output of the decoder is combined together with the attended representation of the input sentence and with the word embedding of the word previously generated in a deep output layer (Pascanu et al., 2014). Finally, a softmax"
K18-1015,D17-1153,0,0.0837161,"Missing"
K18-1015,P16-1008,0,0.033252,"dom sampling strategy: sentences are randomly selected from the data stream S. Although simple, this strategy usually works well in practice. In the rest of this section, we describe the sampling strategies used in |{yi ∈ y|Cw (x, yi ) &gt; τw }| (4) |y| where τw is a word confidence threshold, adjusted according to a development corpus. |· |denotes the size of a sequence or set. Coverage sampling One of the main issues suffered by NMT systems is the lack of coverage: the NMT system may not translate all words from a source sentence. This results in over-translation or undertranslation problems (Tu et al., 2016). We propose to use the translation coverage as a measure of the uncertainty suffered by the NMT 154 system when translating a sentence. Therefore, we modify the coverage penalty proposed by Wu et al. (2016), for obtaining a coverage-based uncertainty score: to the vote-entropy function (Dagan and Engelson, 1995): Cqbc (x) = − P|x| Ccov (x, y) = j=1 log  P|y| min( i=1 αi,j , 1) (5) where αi,j is attention probability of the i-th target word and the j-th source word. Attention distraction sampling When generating a target word, an attentional NMT system should attend on meaningful parts of the"
K18-1015,J16-1004,0,0.603929,"Missing"
K18-1015,P02-1040,0,0.101642,"e i-th target word. Note that, by construc1 tion of the attention model, |x| is equivalent to the mean of the attention weights of the word yi . Since we want to obtain samples with heavy tails, we average the minus kurtosis values for all words in the target sentence, obtaining the attention distraction score Cad : 6.1 5.2 i=1 −Kurt(yi ) |y| Evaluation An IMT scenario with AL requires to assess two different criteria: translation quality of the system and human effort spent during the process. For evaluating the quality of the translations, we used the BLEU (bilingual evaluation understudy) (Papineni et al., 2002) score. BLEU computes an average mean of the precision of the n-grams (up to order 4) from the hypothesis that appear in the reference sentence. It also has a brevity penalty for short translations. For estimating the human effort, we simulated the actions that the human user would perform when using the IMT system. Therefore, at each iteration the user must search in the hypothesis the next error, and position the mouse pointer on it. P|y| Cad (x, y) = Experimental framework In order to assess the effectiveness of AL for INMT, we conducted a similar experimentation than the latter works in AL"
K18-1015,2005.eamt-1.35,0,0.112765,"Missing"
K18-1015,J07-1003,0,0.0162961,"x ∈ V then ˆ = INMT(θ, x, y); 8 y ˆ )); 9 θ = update(θ, (x, y 10 output(ˆ y); 11 else 12 output(y); 13 end 14 end 15 until S = 6 ∅; 16 end 5.1 The idea behind this family of methods is to select those instances for which the model has the least confidence to be properly translated. Therefore, all techniques compute, for each sample, an uncertainty score. The selected sentences will be those with the highest scores. Quality estimation sampling A common and effective way for measuring the uncertainty of a MT system is to use confidence estimation (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007). The idea is to estimate the quality of a translation according to confidence scores of the words. More specifically, given a source sentence x = x1 , . . . , xJ and a translation hypothesis y = y1 , . . . , yI , a word confidence score (Cw ) as computed as (Ueffing and Ney, 2005): Cw (x, yi ) = max p(yi |xj ) 0≤j≤J (3) where p(yi |xj ) is the alignment probability of yi and xj , given by an IBM Model 2 (Brown et al., 1993). x0 denotes the empty source word. The choice of the IBM Model 2 is twofold: on the one hand, it is a very fast method, which only requires to query in a dictionary. We ar"
K18-1015,P16-1009,0,0.0324958,"n approximation and assumes that both actions require a similar effort. 6.2 Our NMT system was built using NMT-Keras (Peris and Casacuberta, 2018a) and featured a bidirectional LSTM encoder and a decoder with cLSTM units. Following Britz et al. (2017), we set the dimension of the LSTM, embeddings and attention model to 512. We applied batch normalizing transform (Ioffe and Szegedy, 2015) and Gaussian noise during training (Graves, 2011). The L2 norm of the gradients was clipped to 5, for avoiding the exploiting gradient effect (Pascanu et al., 2012). We applied joint byte pair encoding (BPE) (Sennrich et al., 2016) to all corpora. For training the system, we used Adam (Kingma and Ba, 2014), with a learning rate of 0.0002 and a batch size of 50. We early-stopped the training according to the BLEU on our development set. For decoding, we used a beam of 6. We incrementally update the system (Line 9 in Algorithm 1), with vanilla SGD, with a learning rate of 0.0005. We chose this configuration according to an exploration on the validation set. The rest of hyperparameters were set according to previous works. The blocks retrieved from the data stream contained 500 samples (according to Gonz´alez-Rubio et al."
N07-2034,J93-2003,0,0.00734788,"here ti denotes the translation of the source sentence s (formed by words of the input vocabulary Σ) into the i-th target language, which, in its turn, has a vocabulary ∆i , the GIAMTI method can be outlined as follows: 1. Each multilingual sample is transformed into a single string from an extended vocabulary (Γ ⊆ Σ × ∆∗1 × · · · × ∆∗m ) using a labelling function (Lm ). This transformation searches an adequate monotonous segmentation for each of the m source-target language pairs. A monotonous segmentation copes with monotonous alignments, that is, j < k ⇒ aj < ak following the notation of (Brown et al., 1993). Each source word is then joined with a target phrase of each language as the corresponding segmentation suggests. Each extended symbol consists of a word from the source language plus zero or more words from each target language. 2. Once the set of multilingual samples has been converted into a set of single extended strings (z ∈ Γ∗ ), a stochastic regular grammar can be inferred. s (1) Making use of Bayes’ rule, the former expression turns into: X m = arg max tc P (tm , s)P (x|tm , s) (2) m t s Empirically, there is no loss of generality if we assume that the acoustic signal representation"
N07-2034,J04-2004,1,0.826044,"ard monotarget speech transducer. 1 Introduction Finite-state models constitute an important framework both in syntactic pattern recognition and in language processing. Specifically, stochastic finitestate transducers (SFSTs) have proved to be useful for machine translation tasks within restricted domains; they usually offer high speed during the decoding step and they provide competitive results in terms of error rates (Mohri et al., 2002). Moreover, SFSTs have proved to be versatile models, which can be easily integrated with other finite-state models (Pereira and Riley, 1997). The article (Casacuberta and Vidal, 2004) explored an automatic method to learn an SFST from a bilingual set of samples for machine translation purposes, the so-called GIATI (Grammar Inference and Alignments for Transducers Inference). It described how to learn both the structural and the probabilistic components of an SFST making use of underlying alignment models. A multi-target SFST is a generalization of standard SFSTs, in such a way that every input string in the source language results in a tuple of output strings each being associated to a different target language. An extension of GIATI that allowed to infer a multi-target SF"
N09-2055,J85-2002,0,0.647715,"2010:MIPRCV (CSD2007-00018), and by the i3media Cenit project (CDTI 2007-1012). 217 Rule-based machine translation. RBMT was the first approach to machine translation, and thus, a relatively mature area in this field. RBMT systems are basically constituted by two components: the rules, that account for the syntactic knowledge, and the lexicon, which deals with the morphological, syntactic, and semantic information. Both rules and lexicons are grounded on linguistic knowledge and generated by expert linguists. As a result, the build process is expensive and the system is difficult to maintain (Bennett and Slocum, 1985). Furthermore, RBMT systems fail to adapt to new domains. Proceedings of NAACL HLT 2009: Short Papers, pages 217–220, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics Automatic post-editing. An APE system can be viewed as a translation process between the output from a previous MT system, and the target language. In our case, an APE system based on statistical models will be trained to correct the translation errors made by a RBMT system. As a result, both RBMT and SMT technologies will be combined in order to increase the overall translation quality. 3 Experiment"
N09-2055,J93-2003,0,0.00819136,"viewed as a translation process between the output from a previous MT system, and the target language. In our case, an APE system based on statistical models will be trained to correct the translation errors made by a RBMT system. As a result, both RBMT and SMT technologies will be combined in order to increase the overall translation quality. 3 Experiments Training Statistical machine translation. In SMT, translations are generated on the basis of statistical models, which are derived from the analysis of bilingual text corpora. The translation problem can be statistically formulated as in (Brown et al., 1993). In practice, several models are often combined into a log-linear fashion. Each model can represent an important feature for the translation, such as phrase-based, language, or lexical models (Koehn et al., 2003). Table 1: Corpus statistics for Parliament and Protocols. OOV stands for out-of-vocabulary words. Test Although they usually provide a mechanism to create new rules and extend and adapt the lexicon, changes are usually very costly and the results, frequently, do not pay off (Isabelle et al., 2007). Sentences Run. words Vocabulary Perplexity Sentences Run. words OOVs Perplexity Parlia"
N09-2055,W07-0718,0,0.0202812,"in the training set (corpus statistics in Table 1). On the other hand, the Protocols corpus is a collection of medical protocols. This is a more difficult task, as its statistics reflect in Table 1. There are many factors that explain this complexity, such as the different companies involved in training and test sets, out-of-domain test data (see perplexity and Human evaluation. A new human evaluation measure has been proposed to roughly estimate the productivity increase when using each of the systems in a real scenario, grounded on previous works for human evaluation of qualitative factors (Callison-Burch et al., 2007). One of the desired qualities for this measure was that it should pose little effort to the human evaluator. Thus, a binary measure was chosen, the suitability, where the translations are identified as suitable or not suitable. A given translation is considered to be suitable if it can be manually post-edited with effort savings, i.e., the evaluator thinks that a manual post-editing will increase his productivity. On the contrary, if the evaluator prefers to ignore the proposed translation and start it over, the sentence is deemed not suitable. 218 Significance tests. Significance of the resu"
N09-2055,W07-0732,0,0.0397667,"hough less conclusive, are promising as well. Finally, several possible sources of errors have been identified which will help develop future system enhancements. 1 2 Systems description Three different systems are compared in this work, namely the RBMT, SMT, and APE systems. Introduction Current machine translation systems are far from perfect. To achieve high-quality output, the raw translations they generate often need to be corrected, or post-edited by human translators. One way of increasing the productivity of the whole process is the development of automatic post-editing (APE) systems (Dugast et al., 2007; Simard et al., 2007). ∗ Work supported by the EC (FEDER) and the Spanish MEC under grant TIN2006-15694-CO2-01, by the Spanish research programme Consolider Ingenio 2010:MIPRCV (CSD2007-00018), and by the i3media Cenit project (CDTI 2007-1012). 217 Rule-based machine translation. RBMT was the first approach to machine translation, and thus, a relatively mature area in this field. RBMT systems are basically constituted by two components: the rules, that account for the syntactic knowledge, and the lexicon, which deals with the morphological, syntactic, and semantic information. Both rules and"
N09-2055,2007.mtsummit-papers.34,0,0.746555,"Missing"
N09-2055,N03-1017,0,0.00734525,"by a RBMT system. As a result, both RBMT and SMT technologies will be combined in order to increase the overall translation quality. 3 Experiments Training Statistical machine translation. In SMT, translations are generated on the basis of statistical models, which are derived from the analysis of bilingual text corpora. The translation problem can be statistically formulated as in (Brown et al., 1993). In practice, several models are often combined into a log-linear fashion. Each model can represent an important feature for the translation, such as phrase-based, language, or lexical models (Koehn et al., 2003). Table 1: Corpus statistics for Parliament and Protocols. OOV stands for out-of-vocabulary words. Test Although they usually provide a mechanism to create new rules and extend and adapt the lexicon, changes are usually very costly and the results, frequently, do not pay off (Isabelle et al., 2007). Sentences Run. words Vocabulary Perplexity Sentences Run. words OOVs Perplexity Parliament En Sp 90K 90K 2.3M 2.5M 29K 45K 42 37 1K 1K 33K 33K 157 219 44 43 Protocols En Sp 154K 154K 3.2M 3.6M 41K 47K 21 19 3K 3K 54K 71K 2K 1.7K 131 173 out-of-vocabulary words), non-native authors, etc. Evaluation."
N09-2055,P07-2045,0,0.00556799,"trary, if the evaluator prefers to ignore the proposed translation and start it over, the sentence is deemed not suitable. 218 Significance tests. Significance of the results has been assessed by the paired bootstrap resampling method, described in (Koehn, 2004). It estimates how confidently the conclusion that a system outperforms another one can be drawn from a test result. Experimental setup. Rule-based translation was performed by means of a commercial RBMT system. On the other hand, statistical training and translation in both SMT and APE systems were carried out using the Moses toolkit (Koehn et al., 2007). It should be noted that APE system was trained taking the RBMT output as source, instead of the original text. In this way, it is able to post-edit the RBMT translations. Finally, the texts employed for the human evaluation were composed by 350 sentences randomly drawn from each one of the two test corpora described in this paper. Two professional translators carried out the human evaluation. 3.1 Results and discussion Experimentation results in terms of automatic and human evaluation are shown in this section. Automatic evaluation. Table 2 presents Parliament and Protocols corpora translati"
N09-2055,W04-3250,0,0.0212411,"effort to the human evaluator. Thus, a binary measure was chosen, the suitability, where the translations are identified as suitable or not suitable. A given translation is considered to be suitable if it can be manually post-edited with effort savings, i.e., the evaluator thinks that a manual post-editing will increase his productivity. On the contrary, if the evaluator prefers to ignore the proposed translation and start it over, the sentence is deemed not suitable. 218 Significance tests. Significance of the results has been assessed by the paired bootstrap resampling method, described in (Koehn, 2004). It estimates how confidently the conclusion that a system outperforms another one can be drawn from a test result. Experimental setup. Rule-based translation was performed by means of a commercial RBMT system. On the other hand, statistical training and translation in both SMT and APE systems were carried out using the Moses toolkit (Koehn et al., 2007). It should be noted that APE system was trained taking the RBMT output as source, instead of the original text. In this way, it is able to post-edit the RBMT translations. Finally, the texts employed for the human evaluation were composed by"
N09-2055,P02-1040,0,0.102262,"slations. These translations have been also evaluated by professional translators to assess the increase of productivity when using each system. We present some experiments carried out using the introduced APE system, and comparing its performance with that of the RBMT and SMT systems. In the experimentation, two different English-toSpanish corpora have been chosen, Parliament and Protocols, both of them provided by a professional translation agency. Automatic evaluation. The automatic assessment of the translation quality has been carried out using the BiLingual Evaluation Understudy (BLEU) (Papineni et al., 2002), and the Translation Error Rate (TER) (Snover et al., 2006). The latter takes into account the number of edits required to convert the system output into the reference. Hence, this measure roughly estimates the post-edition process. Corpora. The Parliament corpus consists of a series of documents from proceedings of parliamentary sessions, provided by a client of the translation agency involved in this work. Most of the sentences are transcriptions of parliamentary speeches, and thus, with the peculiarities of the oral language. Despite of the multi-topic nature of the speeches, differences i"
N09-2055,N07-1064,0,0.374481,", are promising as well. Finally, several possible sources of errors have been identified which will help develop future system enhancements. 1 2 Systems description Three different systems are compared in this work, namely the RBMT, SMT, and APE systems. Introduction Current machine translation systems are far from perfect. To achieve high-quality output, the raw translations they generate often need to be corrected, or post-edited by human translators. One way of increasing the productivity of the whole process is the development of automatic post-editing (APE) systems (Dugast et al., 2007; Simard et al., 2007). ∗ Work supported by the EC (FEDER) and the Spanish MEC under grant TIN2006-15694-CO2-01, by the Spanish research programme Consolider Ingenio 2010:MIPRCV (CSD2007-00018), and by the i3media Cenit project (CDTI 2007-1012). 217 Rule-based machine translation. RBMT was the first approach to machine translation, and thus, a relatively mature area in this field. RBMT systems are basically constituted by two components: the rules, that account for the syntactic knowledge, and the lexicon, which deals with the morphological, syntactic, and semantic information. Both rules and lexicons are grounded"
N09-2055,2006.amta-papers.25,0,0.0449653,"ssional translators to assess the increase of productivity when using each system. We present some experiments carried out using the introduced APE system, and comparing its performance with that of the RBMT and SMT systems. In the experimentation, two different English-toSpanish corpora have been chosen, Parliament and Protocols, both of them provided by a professional translation agency. Automatic evaluation. The automatic assessment of the translation quality has been carried out using the BiLingual Evaluation Understudy (BLEU) (Papineni et al., 2002), and the Translation Error Rate (TER) (Snover et al., 2006). The latter takes into account the number of edits required to convert the system output into the reference. Hence, this measure roughly estimates the post-edition process. Corpora. The Parliament corpus consists of a series of documents from proceedings of parliamentary sessions, provided by a client of the translation agency involved in this work. Most of the sentences are transcriptions of parliamentary speeches, and thus, with the peculiarities of the oral language. Despite of the multi-topic nature of the speeches, differences in training and test perplexities indicate that the topics in"
N09-2055,O96-2005,0,\N,Missing
N10-1079,2007.mtsummit-papers.3,0,0.0339613,"em involved in the interactive translation process. Then we introduce the required techniques to incrementally update the statistical models used by the system. 4.1 Basic IMT system 3 Related work In this paper we present an application of the online learning paradigm to the IMT framework. In the online learning setting, models are trained sample by sample. Our work is also related to model adaptation, although model adaptation and online learning are not exactly the same thing. The online learning paradigm has been previously applied to train discriminative models in SMT (Liang et al., 2006; Arun and Koehn, 2007; Watanabe et al., 2007; Chiang et al., 2008). These works differ from the one presented here in that we apply online learning techniques to train generative models instead of discriminative models. In (Nepveu et al., 2004), dynamic adaptation of an IMT system via cache-based model extensions to language and translation models is proposed. The work by Nepveu et al. (2004) constitutes a domain adaptation technique and not an online learning technique, since the proposed cache components require pre-existent models estimated in batch mode. In addition to this, their IMT system does not use state"
N10-1079,J09-1002,1,0.824959,"Missing"
N10-1079,J93-2003,0,0.0343512,"obtain the expression: P r(f |e) = X P r(f˜1K , a ˜K ˜K 1 |e 1 ) (4) K,˜ aK 1 Incremental Models Batch Learning Online Learning Figure 2: An Online Interactive SMT system 2 2002), where direct modelling of the posterior probability P r(e |f ) of Equation (1) is used. In this case, the decision rule is given by the expression: ( M ) X ˆ = argmax λm hm (e, f ) (3) e Interactive machine translation e,a IMT can be seen as an evolution of the SMT framework. Given a sentence f from a source language F to be translated into a target sentence e of a target language E, the fundamental equation of SMT (Brown et al., 1993) is the following: ˆ = argmax {P r(e |f )} e (1) e = argmax {P r(f |e) P r(e)} where each a ˜k ∈ {1 . . . K} denotes the index of the target phrase e˜ that is aligned with the k-th source phrase f˜k , assuming a segmentation of length K. According to Equation (4), and following a maximum approximation, the problem stated in Equation (2) can be reframed as:  ˆ ≈ arg max p(e) · p(f , a |e) (5) e (2) e where P r(f |e) is approximated by a translation model that represents the correlation between the source and the target sentence and where P r(e) is approximated by a language model representing"
N10-1079,P96-1041,0,0.0239275,"s respectively), N1+ (ei−1 i−n+1 •) is the number of unique words that follows the history i ei−1 i−n+1 and cX (ei−n+1 ) is the count of the n-gram i ei−n+1 , where cX (·) can represent true counts cT (·) or modified counts cM (·). True counts are used for the higher order n-grams and modified counts for the lower order n-grams. Given a certain n-gram, its modified count consists in the number of different words that precede this ngram in the training corpus. Equation (8) corresponds to the probability given by an n-gram language model with an interpolated version of the Kneser-Ney smoothing (Chen and Goodman, 1996). 1 |e |is the length of e, e0 denotes the begin-of-sentence symbol, e|e|+1 denotes the end-of-sentence symbol, eji ≡ ei ...ej • target sentence-length model (h2 ) h2 (e, f ) = log(p(|f e|)) = log(φ|e |(|f |+0.5)− φ|e |(|f |− 0.5)), where φ|e |(·) denotes the cumulative distribution function (cdf) for the normal distribution (the cdf is used here to integrate the normal density function over an interval of length 1). We use a specific normal distribution with mean µ|e |and standard deviation σ|e |for each possible target sentence length |e|. • inverse and direct phrase-based models (h3 , h4 )"
N10-1079,D08-1024,0,0.0402226,"ocess. Then we introduce the required techniques to incrementally update the statistical models used by the system. 4.1 Basic IMT system 3 Related work In this paper we present an application of the online learning paradigm to the IMT framework. In the online learning setting, models are trained sample by sample. Our work is also related to model adaptation, although model adaptation and online learning are not exactly the same thing. The online learning paradigm has been previously applied to train discriminative models in SMT (Liang et al., 2006; Arun and Koehn, 2007; Watanabe et al., 2007; Chiang et al., 2008). These works differ from the one presented here in that we apply online learning techniques to train generative models instead of discriminative models. In (Nepveu et al., 2004), dynamic adaptation of an IMT system via cache-based model extensions to language and translation models is proposed. The work by Nepveu et al. (2004) constitutes a domain adaptation technique and not an online learning technique, since the proposed cache components require pre-existent models estimated in batch mode. In addition to this, their IMT system does not use state-of-the-art models. To our knowledge, the onl"
N10-1079,1997.mtsummit-papers.1,0,0.747856,"es ep inter.-2 k inter.-3 accept Introduction Information technology advances have led to the need for more efficient translation methods. Current MT systems are not able to produce ready-to-use texts. Indeed, MT systems usually require human post-editing to achieve high-quality translations. One way of taking advantage of MT systems is to combine them with the knowledge of a human translator in the IMT paradigm, which is a special type of the computer-assisted translation paradigm (Isabelle and Church, 1997). An important contribution to IMT technology was pioneered by the TransType project (Foster et al., 1997; Langlais et al., 2002) where data driven MT techniques were adapted for their use in an interactive translation environment. es ep k es ep Para ver la lista de recursos To view a listing of resources To view the resources list To view a list of To view a list list i To view To view a a list i ng listing listing resources resources o o f of resources resources Figure 1: IMT session to translate a Spanish sentence into English. In interaction-0, the system suggests a translation (es ). In interaction-1, the user moves the mouse to accept the first eight characters ”To view ” and presses the a"
N10-1079,N03-1017,0,0.287815,"ut sentence f and its desired transˆ can be used to refine the models used by the lation e system. In general, the model is initially obtained through a classical batch training process from a previously given training sequence of pairs (fi ,ei ) from the task being considered. Now, the models can be extended with the use of valuable user feedback. f e k feedback/interactions ^e Interactive SMT System f f ,e 1 1 f ,e 2 2 ... f e^ e m=1 where each hm (e, f ) is a feature function representing a statistical model and λm its weight. Current MT systems are based on the use of phrase-based models (Koehn et al., 2003) as translation models. The basic idea of Phrase-based Translation (PBT) is to segment the source sentence into phrases, then to translate each source phrase into a target phrase, and finally to reorder the translated target phrases in order to compose the target sentence. If we summarize all the decisions made during the phrase-based translation process by means of the hidden variable a ˜K 1 , we obtain the expression: P r(f |e) = X P r(f˜1K , a ˜K ˜K 1 |e 1 ) (4) K,˜ aK 1 Incremental Models Batch Learning Online Learning Figure 2: An Online Interactive SMT system 2 2002), where direct modell"
N10-1079,P06-1096,0,0.150781,"Missing"
N10-1079,W04-3225,0,0.207589,"n application of the online learning paradigm to the IMT framework. In the online learning setting, models are trained sample by sample. Our work is also related to model adaptation, although model adaptation and online learning are not exactly the same thing. The online learning paradigm has been previously applied to train discriminative models in SMT (Liang et al., 2006; Arun and Koehn, 2007; Watanabe et al., 2007; Chiang et al., 2008). These works differ from the one presented here in that we apply online learning techniques to train generative models instead of discriminative models. In (Nepveu et al., 2004), dynamic adaptation of an IMT system via cache-based model extensions to language and translation models is proposed. The work by Nepveu et al. (2004) constitutes a domain adaptation technique and not an online learning technique, since the proposed cache components require pre-existent models estimated in batch mode. In addition to this, their IMT system does not use state-of-the-art models. To our knowledge, the only previous work on online learning for IMT is (Cesa-Bianchi et al., 2008), where a very constrained version of online learning is presented. This constrained version of online le"
N10-1079,P02-1038,0,0.518282,"Missing"
N10-1079,J03-1002,0,0.00757187,"d h4 . Inverse and direct HMM-based models are used here for two purposes: to smooth the phrase-based models via linear interpolation and to generate word alignment matrices. The weights of the interpolation can be estimated from a development corpus. Equation (10) shows the expression of the probability given by an inverse HMM-based model. The probability includes lexical probabilities p(fj |ei ) and alignment probabilities p(aj |aj−1 , l). Since the alignment in the HMM-based model is determined by a hidden variable, the EM algorithm is required to estimate the parameters of the model (see (Och and Ney, 2003)). However, the standard EM algorithm is not appropriate to incrementally extend our HMM-based models because it is designed to work in batch training scenarios. To solve this problem, we apply the incremental view of the EM algorithm described in (Neal and Hinton, 1998). According to (Och and Ney, 2003), the lexical probability for a 5 pair of words is given by the expression: c(f |e) ′ f ′ c(f |e) p(f |e) = P (14) where c(f |e) is the expected number of times that the word e is aligned to the word f . The alignment probability is defined in a similar way: c(aj |aj−1 , l) p(aj |aj−1 , l) = P"
N10-1079,R09-1060,1,0.894836,"Missing"
N10-1079,2001.mtsummit-papers.68,0,0.0210709,"ort results. IMT experiments were carried out from English to the other three languages. 5.2 Assessment criteria The evaluation of the techniques presented in this paper were carried out using the Key-stroke and mouse-action ratio (KSMR) measure (Barrachina et al., 2009). This is calculated as the number of keystrokes plus the number of mouse movements plus one more count per sentence (aimed at simulating the user action needed to accept the final translation), the sum of which is divided by the total number of reference characters. In addition to this, we also used the well-known BLEU score (Papineni et al., 2001) to measure the translation quality of the first translation hypothesis produced by the IMT system for each source sentence (which is automatically generated without user intervention). 5.3 Online IMT results To test the techniques proposed in this work, we carried out experiments in two different scenarios. In the first one, the first 10 000 sentences extracted from the training corpora were interactively translated by means of an IMT system without any preexistent model stored in memory. Each time a new sentence pair was validated, it was used to incrementally train the system. Figures 3a, 3"
N10-1079,W02-1012,0,0.03357,"s of the direct HMM-based model are estimated analogously to those of the inverse HMM-based model. Once the direct and the inverse HMM-based model parameters have been modified due to the presentation of a new sentence pair to the IMT system, both models are used to obtain word alignments for the new sentence pair. The resulting direct and inverse word alignment matrices are combined by means of the symmetrization alignment operation (Och and Ney, 2003) before extracting the set of consistent phrase pairs. HMM-based alignment models are used here because, according to (Och and Ney, 2003) and (Toutanova et al., 2002), they outperform IBM 1 to IBM 4 alignment models while still allowing the exact calculation of the likelihood for a given sentence pair. The δ parameters of the geometric distributions associated to the feature functions h5 , h6 and h7 are left fixed. Because of this, there are no sufficient statistics to store for these feature functions. Finally, the weights of the log-linear combination are not modified due to the presentation of a new sentence pair to the system. These weights can be adjusted off-line by means of a development corpus and well-known optimization techniques. 551 Experiments"
N10-1079,C96-2141,0,0.216542,"ion with mean µ|e |and standard deviation σ|e |for each possible target sentence length |e|. • inverse and direct phrase-based models (h3 , h4 ) QK ˜ h3 (e, a, f ) = log( k=1 p(fk |˜ ea˜k )), where p(f˜k |˜ ea˜k ) is defined as follows: p(f˜k |˜ ea˜k ) = β · pphr (f˜k |˜ ea˜k ) + ea˜ ) (1 − β).phmm (f˜k |˜ k (9) In Equation (9), pphr (f˜k |˜ ea˜k ) denotes the probability given by a statistical phrase-based dictionary used in regular phrase-based models (see (Koehn et al., 2003) for more details). phmm (f˜k |˜ ea˜k ) is the probability given by an HMM-based (intraphrase) alignment model (see (Vogel et al., 1996)): ˜ phmm (f˜|˜ e) = ǫ |f | XY |f˜| a1 p(f˜j |˜ eaj ) · p(aj |aj−1 , |˜ e|) j=1 (10) The HMM-based alignment model probability is used here for smoothing purposes as described in (Ortiz-Mart´ınez et al., 2009). defined as: Analogously h4 isQ h4 (e, a, f ) = log( K ea˜k |f˜k )) k=1 p(˜ • target phrase-length Q model (h5 ) h5 (e, a, f ) = log( K ek |)), where p(|˜ ek |) = k=1 p(|˜ |˜ e | k δ(1 − δ) . h5 implements a target phrase-length model by means of a geometric distribution with probability of success on each trial δ. The use of a geometric distribution penalizes the length of target phrase"
N10-1079,D07-1080,0,0.038066,"eractive translation process. Then we introduce the required techniques to incrementally update the statistical models used by the system. 4.1 Basic IMT system 3 Related work In this paper we present an application of the online learning paradigm to the IMT framework. In the online learning setting, models are trained sample by sample. Our work is also related to model adaptation, although model adaptation and online learning are not exactly the same thing. The online learning paradigm has been previously applied to train discriminative models in SMT (Liang et al., 2006; Arun and Koehn, 2007; Watanabe et al., 2007; Chiang et al., 2008). These works differ from the one presented here in that we apply online learning techniques to train generative models instead of discriminative models. In (Nepveu et al., 2004), dynamic adaptation of an IMT system via cache-based model extensions to language and translation models is proposed. The work by Nepveu et al. (2004) constitutes a domain adaptation technique and not an online learning technique, since the proposed cache components require pre-existent models estimated in batch mode. In addition to this, their IMT system does not use state-of-the-art models. To"
N10-1079,P02-1040,0,\N,Missing
nevado-etal-2004-translation,J93-2003,0,\N,Missing
nevado-etal-2004-translation,2001.mtsummit-papers.60,0,\N,Missing
nevado-etal-2004-translation,P98-1117,0,\N,Missing
nevado-etal-2004-translation,C98-1113,0,\N,Missing
nevado-etal-2004-translation,P00-1056,0,\N,Missing
nevado-etal-2004-translation,W03-2205,1,\N,Missing
nevado-etal-2004-translation,macklovitch-etal-2000-transsearch,0,\N,Missing
P01-1027,J93-2003,0,\N,Missing
P01-1027,C00-2123,1,\N,Missing
P01-1027,E99-1010,1,\N,Missing
P01-1027,J96-1002,0,\N,Missing
P01-1027,P98-2158,0,\N,Missing
P01-1027,C98-2153,0,\N,Missing
P01-1027,W00-0707,0,\N,Missing
P01-1027,P97-1037,1,\N,Missing
P01-1027,H94-1028,0,\N,Missing
P01-1027,P00-1056,1,\N,Missing
P01-1027,P97-1047,0,\N,Missing
P01-1027,P00-1006,0,\N,Missing
P06-2107,2005.eamt-1.6,0,0.157869,".2 25.6 21.9 the TransType2 project (SchlumbergerSema S.A. et al., 2001). The experimental results have proved that the systems based on such models achieve a good performance, possibly, allowing a saving of human effort with respect to the classical post-editing operation. However, this fact must be checked by actual users. The main critical aspect of the interactive CAT system is the response time. To deal with this issue, other proposals are based on the construction of a word graphs. This method can reduce the generation capability of the fully fledged translation model (Och et al., 2003; Bender et al., 2005). The main contribution of the present proposal is a new decoding algorithm, that combines monotone and non-monotone search. It runs fast enough and the construction of word graph is not necessary. Table 5: Comparison of post-editing effort in MT scenario (WER/CER) and the interactiveediting effort in CAT scenario (WSR/KSR). Nonmonotone search and 1-best hypothesis is used. sonable interaction times. In this approach, the length of the proposed extension is variable in function of the expected benefit of the human translator. In (Och et al., 2003) the Alignment-Templates translation model is u"
P06-2107,J93-2003,0,0.0268123,"her possibility is computer-assisted translation (CAT). In this framework, a human translator interacts with the system in order to obtain high-quality translations. This work follows the approach of interactive CAT initially suggested by (Foster et al., 1996) and developed in the TransType2 project (SchlumbergerSema S.A. et al., 2001; Barrachina et al., 2006). In this framework, the system suggests a possible translation 2 Statistical machine translation The goal of SMT is to translate a given source language sentence sJ1 = s1 ...sJ to a target sentence tI1 = t1 ...tI . The methodology used (Brown et al., 1993) is based on the definition of a function P r(tI1 |sJ1 ) that returns the probability that tI1 is a 835 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 835–841, c Sydney, July 2006. 2006 Association for Computational Linguistics source interaction-0 interaction-1 interaction-2 interaction-3 acceptance Transferir documentos explorados a otro directorio Move documents scanned to other directory Move s canned documents to other directory Move scanned documents to a nother directory Move scanned documents to another f older Move scanned documents to another folder Figure"
P06-2107,J04-2004,1,0.896809,"Missing"
P06-2107,2001.mtsummit-papers.64,1,0.898041,"Missing"
P06-2107,W04-3245,1,0.866645,"Missing"
P06-2107,C96-1067,0,0.0314941,"ave become an important tool to increase the translator’s productivity. In a more extended framework, a machine translation (MT) system can be used to obtain initial versions of the translations. Unfortunately, the state of the art in MT is far from being perfect, and a human translator must edit this output in order to achieve highquality translations. Another possibility is computer-assisted translation (CAT). In this framework, a human translator interacts with the system in order to obtain high-quality translations. This work follows the approach of interactive CAT initially suggested by (Foster et al., 1996) and developed in the TransType2 project (SchlumbergerSema S.A. et al., 2001; Barrachina et al., 2006). In this framework, the system suggests a possible translation 2 Statistical machine translation The goal of SMT is to translate a given source language sentence sJ1 = s1 ...sJ to a target sentence tI1 = t1 ...tI . The methodology used (Brown et al., 1993) is based on the definition of a function P r(tI1 |sJ1 ) that returns the probability that tI1 is a 835 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 835–841, c Sydney, July 2006. 2006 Association for Computationa"
P06-2107,W02-1020,0,0.330522,"Missing"
P06-2107,2002.tmi-tutorials.2,0,0.224551,"citly. A I,tIi+1 template establishes the reordering between two = argmax P r(tI1 )P r(sJ1 |tI1 ) (2) sequences of word classes. However, the lexical I,tIi+1 model continues to be based on word-to-word correspondence. This formulation is very similar to the previous case, but in this one, the search is constrained A simple alternative to these models has been to the set of possible suffixes tIi+1 instead of proposed, the phrase-based (PB) approach (Tom´as the whole target sentences tI1 . Therefore, the and Casacuberta, 2001; Marcu and Wong, 2002; same techniques (translation models, decoder alZens et al., 2002). The principal innovation of the gorithm, etc.) which have been developed for phrase-based alignment model is that it attempts to SMT can be used in CAT. calculate the translation probabilities of word sequences (phrases) rather than of only single words. Note that the statistical models are defined at These methods explicitly learn the probability of a word level. However, the CAT interface described 836 sequence of words in a source sentence (˜ s) being translated as another sequence of words in the target sentence (t˜). To define the PB model, we segment the source sentence sJ1 into K phra"
P06-2107,N03-1017,0,0.0551733,"Missing"
P06-2107,macklovitch-2004-contribution,0,0.0329149,"Missing"
P06-2107,W02-1018,0,0.174712,"argmax P r(tIi+1 |sJ1 , ti1 ) to target language can be learned explicitly. A I,tIi+1 template establishes the reordering between two = argmax P r(tI1 )P r(sJ1 |tI1 ) (2) sequences of word classes. However, the lexical I,tIi+1 model continues to be based on word-to-word correspondence. This formulation is very similar to the previous case, but in this one, the search is constrained A simple alternative to these models has been to the set of possible suffixes tIi+1 instead of proposed, the phrase-based (PB) approach (Tom´as the whole target sentences tI1 . Therefore, the and Casacuberta, 2001; Marcu and Wong, 2002; same techniques (translation models, decoder alZens et al., 2002). The principal innovation of the gorithm, etc.) which have been developed for phrase-based alignment model is that it attempts to SMT can be used in CAT. calculate the translation probabilities of word sequences (phrases) rather than of only single words. Note that the statistical models are defined at These methods explicitly learn the probability of a word level. However, the CAT interface described 836 sequence of words in a source sentence (˜ s) being translated as another sequence of words in the target sentence (t˜). To"
P06-2107,P00-1056,0,0.0609971,"e distortion model p(αk |αk−1 ) (the problength of the source prefix we are translating (i.e. ability of aligning the target segment k with the 0 0 sJ1 ); the sequence of I 0 words, tI1 , is the target source segment αk ) depends only on the previous prefix that has been generated and g is the score of alignment αk−1 (first order model). For the dis0 0 0 the hypothesis (g = Pr(tI1 ) · Pr(tI1 |sJ1 )λ ). tortion model, it is also assumed that an alignment The translation procedure can be described as depends only on the distance of the two phrases follows. The system maintains a large set of hy(Och and Ney, 2000): potheses, each of which has a corresponding trans|γαk −γαk−1 | lation score. This set starts with an initial empty p(αk |αk−1 ) = p0 . (5) hypothesis. Each hypothesis is stored in a different stack, according to the source words that have There are different approaches to the parameter been considered in the hypothesis (J 0 ). The alestimation. The first one corresponds to a digorithm consists of an iterative process. In each rect learning of the parameters of equations 3 or iteration, the system selects the best scored par4 from a sentence-aligned corpus using a maxtial hypothesis to extend"
P06-2107,J03-1002,0,0.00598342,"proach: Non-monotone search is used while the target prefix is generated by the algorithm. Monotone search is used while new words are generated. Note that searching for a prefix that we already know may seem useless. The real utility of this 6 Experimental results 6.1 Evaluation criteria Four different measures have been used in the experiments reported in this paper. These measures are based on the comparison of the system output with a single reference. • Word Error Rate (WER): Edit distance in terms of words between the target sentence provided by the system and the reference translation (Och and Ney, 2003). • Character Error Rate (CER): Edit distance in terms of characters between the target sentence provided by the system and the reference translation (Civera et al., 2004). • Word-Stroke Ratio (WSR): Percentage of words which, in the CAT scenario, must be changed in order to achieve the reference. • Key-Stroke Ratio (KSR): Number of keystrokes that are necessary to achieve the reference translation divided by the number of running characters (Och et al., 2003) 1 . 1 In others works, an extra keystroke is added in the last iteration when the user accepts the sentence. We do not add this extra k"
P06-2107,E03-1032,0,0.578223,"direct the system to the correct translation. The accepted prefix and the new corrected character can be used by the system to propose a new suggestion to complete the prefix. The process is repeated until the user completely accepts the suggestion proposed by the system. Figure 1 shows an example of a possible CAT system interaction. Statistical machine translation (SMT) is an adequate framework for CAT since the MT models used can be learnt automatically from a training bilingual corpus and the search procedures developed for SMT can be adapted efficiently to this new interactive framework (Och et al., 2003). Phrase-based models have proved to be very adequate statistical models for MT (Tom´as et al., 2005). In this work, the use of these models has been extended to interactive CAT. The organization of the paper is as follows. The following section introduces the statistical approach to MT and section 3 introduces the statistical approach to CAT. In section 4, we review the phrase-based translation model. In section 5, we describe the decoding algorithm used in MT, and how it can be adapted to CAT. Finally, we will present some experimental results and conclusions. Obtaining high-quality machine"
P10-2032,J09-1002,1,0.903297,"Missing"
P10-2032,P03-1021,0,0.104804,"Missing"
P10-2032,2005.mtsummit-papers.19,1,0.847332,"Missing"
P10-2032,C04-1046,0,0.143202,"Missing"
P10-2032,J93-2003,0,0.042282,"Missing"
P10-2032,D08-1051,1,0.915309,"Missing"
P10-2032,P04-3001,0,0.292954,"Missing"
P10-2032,1997.mtsummit-papers.1,0,0.2694,"Missing"
P10-2032,2005.eamt-1.35,0,0.482261,"Missing"
P10-2032,J07-1003,0,0.0763409,"Missing"
P10-2032,W02-1021,0,\N,Missing
P10-2032,P02-1040,0,\N,Missing
P10-2032,P07-2045,0,\N,Missing
P10-2032,W03-0413,0,\N,Missing
P11-1127,W10-1703,0,0.06429,"Missing"
P11-1127,P09-1064,0,0.0345399,"lated Work MBR system combination is a multi-system generalization of MBR decoding where the space of hypotheses is not constrained to the space of evidences. We expand the space of hypotheses following some underlying ideas of system combination techniques. 2.1 Minimum Bayes risk In SMT, MBR decoding allows to minimize the loss of the output for a single translation system. MBR is generally implemented by re-ranking an N best list of translations produced by a first pass decoder (Kumar and Byrne, 2004). Different techniques to widen the search space have been described (Tromble et al., 2008; DeNero et al., 2009; Kumar et al., 2009; Li et al., 2009). These works extend the traditional MBR algorithms based on N best lists to work with lattices. The use of MBR to combine the outputs of various MT systems has also been explored previously. Duan et al. (2010) present an MBR decoding that makes use of a mixture of different SMT systems to improve translation accuracy. Our technique differs in that we use a linear combination instead of a mixture, which avoids the problem of component systems not sharing the same search space; perform the decoding in a search space larger than the outputs of the component"
P11-1127,C10-1036,0,0.196449,"chniques. 2.1 Minimum Bayes risk In SMT, MBR decoding allows to minimize the loss of the output for a single translation system. MBR is generally implemented by re-ranking an N best list of translations produced by a first pass decoder (Kumar and Byrne, 2004). Different techniques to widen the search space have been described (Tromble et al., 2008; DeNero et al., 2009; Kumar et al., 2009; Li et al., 2009). These works extend the traditional MBR algorithms based on N best lists to work with lattices. The use of MBR to combine the outputs of various MT systems has also been explored previously. Duan et al. (2010) present an MBR decoding that makes use of a mixture of different SMT systems to improve translation accuracy. Our technique differs in that we use a linear combination instead of a mixture, which avoids the problem of component systems not sharing the same search space; perform the decoding in a search space larger than the outputs of the component models; and optimize an expected BLEU score instead of the linear approximation to it described in (Tromble et al., 2008). DeNero et al. (2010) present model combination, a multi-system lattice MBR decoding on the conjoined evidences spaces of the"
P11-1127,P07-2026,0,0.0377645,"Missing"
P11-1127,A94-1016,0,0.147209,"combination methods. 1 Introduction Once statistical models are trained, a decoding approach determines what translations are finally selected. Two parallel lines of research have shown consistent improvements over the max–derivation decoding objective, which selects the highest probability derivation. Consensus decoding procedures select translations for a single system with a minimum Bayes risk (MBR) (Kumar and Byrne, 2004). System combination procedures, on the other hand, generate translations from the output of multiple component systems by combining the best fragments of these outputs (Frederking and Nirenburg, 1994). In this paper, we present minimum Bayes risk system combination, a technique that unifies these two approaches by learning a consensus translation over multiple underlying component systems. MBR system combination operates directly on the outputs of the component models. We perform an MBR decoding using a linear combination of the component models’ probability distributions. Instead of re-ranking the translations provided by the component systems, we search for the hypothesis with the minimum expected translation error among all the possible finite-length strings in the target language. By u"
P11-1127,D09-1125,0,0.0397296,"es over current approaches to system combination. First, it does not rely on hypothesis alignment between outputs of individual systems. Aligning translation hypotheses can be challenging and has a substantial effect on combination performance (He et al., 2008). Instead of aligning the sentences, we view the sentences as vectors of n-gram counts and compute the expected statistics of the BLEU score to compute the Bayes gain. Second, we do not need to pick a backbone system for combina1275 tion. Choosing a backbone system can also be challenging and also affects system combination performance (He and Toutanova, 2009). MBR system combination sidesteps this issue by working directly on the conjoined evidences space produced by the outputs of the component systems, and allows the consensus model to express system preferences via scaling factors. Despite its simplicity, MBR system combination provides strong performance by leveraging different consensus, decoding and training techniques. It outperforms best MAX or MBR derivation on each of the component systems. In addition, it obtains stateof-the-art performance in a constrained setting better suited for dominant system combination techniques. Acknowledgemen"
P11-1127,D08-1011,0,0.035451,"eusch et al. (2010) generate intermediate translations in several pivot languages, translate them separately into the target language, and generate a consensus translation out of these using a system combination technique. Likewise, these pivot translations could be combined via MBR system combination. MBR system combination has two significant advantages over current approaches to system combination. First, it does not rely on hypothesis alignment between outputs of individual systems. Aligning translation hypotheses can be challenging and has a substantial effect on combination performance (He et al., 2008). Instead of aligning the sentences, we view the sentences as vectors of n-gram counts and compute the expected statistics of the BLEU score to compute the Bayes gain. Second, we do not need to pick a backbone system for combina1275 tion. Choosing a backbone system can also be challenging and also affects system combination performance (He and Toutanova, 2009). MBR system combination sidesteps this issue by working directly on the conjoined evidences space produced by the outputs of the component systems, and allows the consensus model to express system preferences via scaling factors. Despite"
P11-1127,P07-2045,0,0.00861538,"Missing"
P11-1127,N04-1022,0,0.734038,"erogeneous structure. Experiments show that our approach bring significant improvements to single-system-based MBR decoding and achieves comparable results to different state-of-the-art system combination methods. 1 Introduction Once statistical models are trained, a decoding approach determines what translations are finally selected. Two parallel lines of research have shown consistent improvements over the max–derivation decoding objective, which selects the highest probability derivation. Consensus decoding procedures select translations for a single system with a minimum Bayes risk (MBR) (Kumar and Byrne, 2004). System combination procedures, on the other hand, generate translations from the output of multiple component systems by combining the best fragments of these outputs (Frederking and Nirenburg, 1994). In this paper, we present minimum Bayes risk system combination, a technique that unifies these two approaches by learning a consensus translation over multiple underlying component systems. MBR system combination operates directly on the outputs of the component models. We perform an MBR decoding using a linear combination of the component models’ probability distributions. Instead of re-ranki"
P11-1127,P09-1019,0,0.133913,"combination is a multi-system generalization of MBR decoding where the space of hypotheses is not constrained to the space of evidences. We expand the space of hypotheses following some underlying ideas of system combination techniques. 2.1 Minimum Bayes risk In SMT, MBR decoding allows to minimize the loss of the output for a single translation system. MBR is generally implemented by re-ranking an N best list of translations produced by a first pass decoder (Kumar and Byrne, 2004). Different techniques to widen the search space have been described (Tromble et al., 2008; DeNero et al., 2009; Kumar et al., 2009; Li et al., 2009). These works extend the traditional MBR algorithms based on N best lists to work with lattices. The use of MBR to combine the outputs of various MT systems has also been explored previously. Duan et al. (2010) present an MBR decoding that makes use of a mixture of different SMT systems to improve translation accuracy. Our technique differs in that we use a linear combination instead of a mixture, which avoids the problem of component systems not sharing the same search space; perform the decoding in a search space larger than the outputs of the component models; and optimize"
P11-1127,2010.iwslt-papers.12,0,0.045406,"e-length 32 30 28 MBR-SC BBN CMU DCU JHU KOC LIUM RWTH BLEU 26 24 22 20 18 16 cz-en en-cz de-en en-de es-en en-es fr-en en-fr Figure 3: Performance of minimum Bayes risk system combination (MBR-SC) for different language directions in comparison to the rest of system combination techniques presented in the WMT2010 system combination task. strings in the output vocabulary. Component systems can have varied decoding strategies; we only require that each system produce an N -best list (or a lattice) of translations. This flexibility allows the technique to be applied quite broadly. For instance, Leusch et al. (2010) generate intermediate translations in several pivot languages, translate them separately into the target language, and generate a consensus translation out of these using a system combination technique. Likewise, these pivot translations could be combined via MBR system combination. MBR system combination has two significant advantages over current approaches to system combination. First, it does not rely on hypothesis alignment between outputs of individual systems. Aligning translation hypotheses can be challenging and has a substantial effect on combination performance (He et al., 2008). I"
P11-1127,P09-1067,0,0.0166688,"lti-system generalization of MBR decoding where the space of hypotheses is not constrained to the space of evidences. We expand the space of hypotheses following some underlying ideas of system combination techniques. 2.1 Minimum Bayes risk In SMT, MBR decoding allows to minimize the loss of the output for a single translation system. MBR is generally implemented by re-ranking an N best list of translations produced by a first pass decoder (Kumar and Byrne, 2004). Different techniques to widen the search space have been described (Tromble et al., 2008; DeNero et al., 2009; Kumar et al., 2009; Li et al., 2009). These works extend the traditional MBR algorithms based on N best lists to work with lattices. The use of MBR to combine the outputs of various MT systems has also been explored previously. Duan et al. (2010) present an MBR decoding that makes use of a mixture of different SMT systems to improve translation accuracy. Our technique differs in that we use a linear combination instead of a mixture, which avoids the problem of component systems not sharing the same search space; perform the decoding in a search space larger than the outputs of the component models; and optimize an expected BLEU"
P11-1127,2001.mtsummit-papers.46,0,0.0656747,"ince these two systems are identical in their expected BLEU statistics, the improvements in BLEU imply that the extended search space has introduced better hypotheses. The degradation in TER performance can be explained by the use of a BLEU-based gain function in the decoding process. We finally compute the optimum values for the scaling factors of the different system using MERT (MBR-SC-E/C/Ex/MERT). MBR-SCE/C/Ex/MERT slightly improves BLEU score of MBR-SC-E/C/Extended. This implies that the optimal values of the scaling factors do not deviate much from 1.0; a similar result was reported in (Och and Ney, 2001). We hypothesize that this is because the three component systems share the same SMT model, pre-process and decoding. We expect to obtain larger improvements when combining systems implementing different MT paradigms. 33 MAX de→en MAX es→en MAX fr→en MBR-SC Reference BLEU 32.5 32 31.5 MBR-SC MBR-SC C/Extended MBR-SC Conjoin i will return later . i shall come back to that later . i will return to this later . i will return to this point later . i will return to this point later . Figure 2: MBR system combination example. 31 30.5 100 Best MAX 101 102 Number of hypotheses in the N-best lists 103"
P11-1127,P03-1021,0,0.0477939,"ch is performed, Gn (e0 ) is the Bayes gain of hypothesis e0 given by the nth component system and αn is a scaling factor introduced to take into account the differences in quality of the component models. It is worth mentioning that by using a linear combination instead of a mixture model, we avoid the problem of component systems not sharing the same search space (Duan et al., 2010). MBR system combination parameters training and decoding in the extended hypotheses space are described below. 4.1 Model Training We learn the scaling factors in Eq. (8) using minimum error rate training (MERT) (Och, 2003). ˆ on a MERT maximizes the translation quality of e held-out set, according to an evaluation metric that compares to a reference set. We used BLEU, choosing the scaling factors to maximize BLEU score of the set of translations predicted by MBR system combination. We perform the maximization by means of the down-hill simplex algorithm (Nelder and Mead, 1965). 4.2 Model Decoding In most MBR algorithms, the hypotheses space is equal to the evidences space. Following the underlying idea of system combination, we are interested in extend the hypotheses space by including new sentences created usin"
P11-1127,P02-1040,0,0.0948814,"Bayes risk system combination, a technique that unifies these two approaches by learning a consensus translation over multiple underlying component systems. MBR system combination operates directly on the outputs of the component models. We perform an MBR decoding using a linear combination of the component models’ probability distributions. Instead of re-ranking the translations provided by the component systems, we search for the hypothesis with the minimum expected translation error among all the possible finite-length strings in the target language. By using a loss function based on BLEU (Papineni et al., 2002), we avoid the hypothesis alignment problem that is central to standard system combination approaches (Rosti et al., 2007). MBR system combination assumes only that each translation model can produce expectations of n-gram counts; the latent derivation structures of the component systems can differ arbitrary. This flexibility allows us to combine a great variety of SMT systems. The key contributions of this paper are three: the usage of a linear combination of distributions within the MBR decoding, which allows multiple SMT models to be involved in, and makes the computation of n-grams statist"
P11-1127,N07-1029,0,0.457004,"e underlying component systems. MBR system combination operates directly on the outputs of the component models. We perform an MBR decoding using a linear combination of the component models’ probability distributions. Instead of re-ranking the translations provided by the component systems, we search for the hypothesis with the minimum expected translation error among all the possible finite-length strings in the target language. By using a loss function based on BLEU (Papineni et al., 2002), we avoid the hypothesis alignment problem that is central to standard system combination approaches (Rosti et al., 2007). MBR system combination assumes only that each translation model can produce expectations of n-gram counts; the latent derivation structures of the component systems can differ arbitrary. This flexibility allows us to combine a great variety of SMT systems. The key contributions of this paper are three: the usage of a linear combination of distributions within the MBR decoding, which allows multiple SMT models to be involved in, and makes the computation of n-grams statistics to be more accurate; the decoding in an extended search space, which allows to find better hypotheses than the evidenc"
P11-1127,2006.amta-papers.25,0,0.0366402,"eriments We report results on a multi-source translation task. From the Europarl corpus released for the ACL 2006 workshop on MT (WMT2006), we select those sentence pairs from the German–English (de–en), Spanish–English (es–en) and French– English (fr–en) sub-corpora that share the same English translation. We obtain a multi-source corpus with German, Spanish and French as source languages and English as target language. All the experiments were carried out with the lowercased and tokenized version of this corpus. We report results using BLEU (Papineni et al., 2002) and translation edit rate (Snover et al., 2006) (TER). We measure statistical significance using 2 If Dn (f ) is represented by a lattice, the number of n-grams is polynomial in the number of edges in the lattice. 1272 test BLEU TER 25.6∗ 60.3 25.4∗ 60.5 30.4∗ 53.9∗ 30.4∗ 54.0∗ 30.8∗ 53.4∗ 30.9∗ 53.4∗ Table 1: Performance of base systems. ng∈Nk (e0 ) C 0 (ng) = dev BLEU TER 25.3 60.5 25.1 60.7 30.9∗ 53.3∗ 31.0∗ 53.4∗ 30.7∗ 53.9∗ 30.7∗ 53.8∗ dev BLEU TER 30.9∗ 53.3∗ ∗ 31.0 53.4∗ 32.3 52.5 test BLEU TER 30.8∗ 53.4∗ ∗ 30.9 53.4∗ 32.8 52.3 Table 2: Performance from best single system maxderivation decoding (Best MAX), the best single system mi"
P11-1127,D08-1065,0,0.438166,"ional Linguistics 2 Related Work MBR system combination is a multi-system generalization of MBR decoding where the space of hypotheses is not constrained to the space of evidences. We expand the space of hypotheses following some underlying ideas of system combination techniques. 2.1 Minimum Bayes risk In SMT, MBR decoding allows to minimize the loss of the output for a single translation system. MBR is generally implemented by re-ranking an N best list of translations produced by a first pass decoder (Kumar and Byrne, 2004). Different techniques to widen the search space have been described (Tromble et al., 2008; DeNero et al., 2009; Kumar et al., 2009; Li et al., 2009). These works extend the traditional MBR algorithms based on N best lists to work with lattices. The use of MBR to combine the outputs of various MT systems has also been explored previously. Duan et al. (2010) present an MBR decoding that makes use of a mixture of different SMT systems to improve translation accuracy. Our technique differs in that we use a linear combination instead of a mixture, which avoids the problem of component systems not sharing the same search space; perform the decoding in a search space larger than the outp"
P11-1127,2004.tmi-1.9,0,0.314309,"Missing"
P11-1127,W08-0329,0,\N,Missing
P11-1127,N10-1141,0,\N,Missing
P11-2068,J09-1002,1,0.888906,"Missing"
P11-2068,J96-1002,0,0.0975851,"Missing"
P11-2068,2009.mtsummit-papers.8,0,0.0359298,"Missing"
P11-2068,P02-1038,0,0.174179,"Missing"
P11-2068,2005.mtsummit-papers.19,1,0.849025,"Missing"
P11-2068,J93-2003,0,\N,Missing
P11-4012,J09-1002,1,0.42722,"Missing"
P11-4012,1997.mtsummit-papers.1,0,0.634375,"stem require manual post-editing. This serial process prevents the MT system from integrating the knowledge of the human translator. An alternative way to take advantage of the existing MT technologies is to use them in collaboration with human translators within a computer-assisted translation (CAT) or interactive framework (Isabelle and Church, 1997). Interactivity in CAT has been explored for a long time. Systems have been designed to interact with linguists to solve ambiguities or update user dictionaries. An important contribution to CAT technology was pioneered by the TransType project (Foster et al., 1997; Langlais et al., 2002). The idea proposed in that work was to embed data driven MT techniques within the interactive translation environment. Following the TransType ideas, Barrachina et al. (2009) proposed the so-called IMT framework, in which fully-fledged statistical MT (SMT) systems are used to produce full target sentences hypotheses, or portions thereof, which can be accepted or amended by a human translator. Each corrected text segment is then used by the MT system as additional information to achieve improved suggestions. Figure 1 shows an example of a typical IMT session. The vast m"
P11-4012,2005.mtsummit-papers.11,0,0.00439093,"be translated from a list or upload their own documents. 5.4 Demo Description and Usage This demo exploits the WWW to enable the connection of simultaneous accesses across the globe, coordinating client-side scripting with server-side technologies. The interface uses web technologies such as XHTML, JavaScript, and ActionScript; while the IMT engine is written in C++. The prototype is publicly available on the Web (http://cat.iti.upv.es/imt/). To begin with, the UI loads an index of all available translation corpora. Currently, the prototype can be tested with the well-known Europarl corpora (Koehn, 2005). The user chooses a corpus and navigates to the main interface page (Figure 3), where she interactively translates the text segments one by one. User’s feedback is then processed by the IMT server. (a) Source document example, created from EuroParl corpus. (b) Translated example document, preserving original format and highlighting non-translated sentences. Figure 4: Translating documents with the proposed system. All corrections are stored in plain text logs on the server, so the user can retake them in any moment, also allowing collaborative translations between users. On the other hand, th"
P11-4012,P09-4005,0,0.180967,"posed. One previous attempt to implement online learning in IMT is the work by Cesa-Bianchi et al. (2008). In that work, the authors present a very constrained version of online learning, which is not able to extend the translation models due to the high time cost of the learning process. We have adopted the online learning techniques proposed in (Ortiz-Mart´ınez et al., 2010) to implement our IMT system. We are not aware of other IMT tools that include such functionality. For instance, a prototype system for text prediction to help translators is shown in (Foster et al., 2002). Additionally, Koehn (2009) presents the Caitra translation tool. Caitra aids linguists suggesting sentence completions, alternative words or allowing users to post-edit machine translation output. However, neither of these systems are able to take advantage of the user validated translations. 69 3 Interactive Machine Translation IMT can be seen as an evolution of the statistical machine translation (SMT) framework. In SMT, given source string f , we seek for the target string e which maximizes the posterior probability: ˆ = argmax P r(e|f ) e (1) e Within the IMT framework, a state-of-the-art SMT system is employed in"
P11-4012,W04-3225,0,0.261712,"ng and prediction stages are no longer separated. This feature is particularly useful in IMT since it allows to take into account the user feedback. Specifically, our proposed IMT system can be extended with the new training samples that are generated each time the user validates the translation of a given source sentence. The online learning techniques implemented in our IMT system incrementally update the statistical models involved in the translation process. 2 Related work There are some works on IMT in the literature that try to take advantage of user feedback. One example is the work by Nepveu et al. (2004), where dynamic adaptation of an IMT system via cache-based model extensions to language and translation models is proposed. One major drawback of such proposal is its inability to learn new words. 68 Proceedings of the ACL-HLT 2011 System Demonstrations, pages 68–73, c Portland, Oregon, USA, 21 June 2011. 2011 Association for Computational Linguistics source(f ): reference(ˆ e): e interaction-0 p es ep interaction-1 k es ep interaction-2 k es ep interaction-3 k es accept ep Para ver la lista de recursos To view a listing of resources To view the resources list To view a list of resources To v"
P11-4012,P02-1038,0,0.0564561,"hen proposes a new extension, taking the correct prefix ep into account. These steps are repeated until the whole input sentence has been correctly translated. In the resulting decision rule, we maximize over all possible extensions es of ep : ˆs = argmax P r(es |ep , f ) e (2) es It is worth to note that the user interactions are at character level, that is, for each submitted keystroke the system provides a new extension (or suffix) to the current hypothesis. A typical IMT session for a given source sentence is depicted in Figure 1. State-of-the-art SMT systems follow a log-linear approach (Och and Ney, 2002), where the posterior probability P r(e |f ) of Eq. (1) is used. Such loglinear approach can be easily adapted for its use in the IMT framework as follows: ˆs = argmax e es ( M X ) λm hm (ep , es , f ) (3) m=1 where each hm (ep , es , f ) is a feature function representing a statistical model and λm its corresponding weight. Typically, a set of statistical generative models are used as feature functions. Among this feature functions, the most relevant are the language and translation models. The language model is implemented using statistical n-gram language models and the translation model is"
P11-4012,N10-1079,1,0.749117,"Missing"
P19-3012,P17-4012,0,0.0377356,"process consists of delivering machine translations to the user interface and the training process retrains the MT engine with the feedback provided by the user. Both processes are performed through client-server communication. Next, we describe each module in detail. 3.1 Translation Server Machine Translation Engine The core of the MT engine is composed by the models generating translations, which can be retrained when required. Each translation project has its own model, whose architecture is set according to the project’s need. All models are neural-based and are trained using OpenNMT-py (Klein et al., 2017). Each MT model has its own configuration file, which contains personalized translation and OL options, such as tokenization, subword segmentation, learning rate, etc. 1 https://github.com/midobal/ OpenNMT-py/tree/OnlineLearning 2 https://www.sdl.com/ es/software-and-services/ translation-software/sdl-trados-studio/ 3 https://community.sdl.com/ developers-more/developers/ language-developers 71 Figure 2: User Interface from Trados Studio SDL. achieve this, we incorporated the Qualitivity4 plugin for Trados. This plugin generates an XML logging file, which contains all the keystrokes time infor"
P19-3012,W17-3204,0,0.0252757,"ods of time. Machine translation (MT) can help them to achieve this goal: instead of a linguist thinking out or “creating” translations from scratch, “humanizing” automatic translations has become a common process in the industry. This is known as post-editing (PE) and it has been shown to be effective in many cases (Arenas, 2008; Hu and Cadwell, 2016). As MT systems are continuously improving their capabilities (e.g. Hassan et al., 2018; Wu et al., 2016), this workflow has become of major relevance in the translation industry. Nonetheless, MT technology is still far from perfect (Dale, 2016; Koehn and Knowles, 2017), and there is still room for improvement. Inherently to the PE process, new bilingual data is continuously generated (the post-edited samples). This data is typically used for the creation of domain-specific corpora, useful for adapting systems from a broader domain into a specific do2 Adapting a NMT system via online learning We are interested in benefiting from the post-edits generated by the user during the PE process. To that end, we update the system on-the-fly, i.e, as soon as a sentence has been validated by the posteditor. Right after the user confirms a post-edit, 70 Proceedings of t"
P19-3012,W18-2708,0,0.0614576,"tem will consider the previous post-editions. It is assumed that better translations (or translations more suited to the human post-editor preferences) will be produced. The OL paradigm has quickly attracted the attention of researchers and industry. The CasMaCat (Alabau et al., 2013) and MateCat (Federico et al., 2014) projects—where phrase-based statistical MT systems were adapted incrementally from the user post-edits—achieved many advances in this direction. More recently, OL techniques were also applied to neural machine translation (NMT) systems (Peris et al., 2017; Turchi et al., 2017; Kothur et al., 2018; Wuebker et al., 2018; Peris and Casacuberta, 2018). In this paper, we introduce a demo system of our in-house OL framework, in which we integrated our translation servers with the translators user-friendly interface SDL Trados Studio. The rest of this document is structured as follows: Section 2 introduces the online learning paradigm. Next, in Section 3, we describe in detail our in-house architecture in which this paradigm is implemented. Finally, Section 4 summarizes the demo system. We introduce a demonstration of our system, which implements online learning for neural machine translatio"
P19-3012,D18-1104,0,0.0386708,"previous post-editions. It is assumed that better translations (or translations more suited to the human post-editor preferences) will be produced. The OL paradigm has quickly attracted the attention of researchers and industry. The CasMaCat (Alabau et al., 2013) and MateCat (Federico et al., 2014) projects—where phrase-based statistical MT systems were adapted incrementally from the user post-edits—achieved many advances in this direction. More recently, OL techniques were also applied to neural machine translation (NMT) systems (Peris et al., 2017; Turchi et al., 2017; Kothur et al., 2018; Wuebker et al., 2018; Peris and Casacuberta, 2018). In this paper, we introduce a demo system of our in-house OL framework, in which we integrated our translation servers with the translators user-friendly interface SDL Trados Studio. The rest of this document is structured as follows: Section 2 introduces the online learning paradigm. Next, in Section 3, we describe in detail our in-house architecture in which this paradigm is implemented. Finally, Section 4 summarizes the demo system. We introduce a demonstration of our system, which implements online learning for neural machine translation in a production envi"
P19-3012,C14-2028,0,\N,Missing
P19-3012,W19-6737,1,\N,Missing
P19-3012,W16-3420,0,\N,Missing
P19-3014,1997.mtsummit-papers.1,0,0.404241,"al., 2014; Bahdanau et al., 2015), speech recognition and translation (Chan et al., 2016; Niehues et al., 2018), image and video captioning (Xu et al., 2015; Yao et al., 2015), among others. These systems are usually based on the statistical formalization of pattern recognition (e.g. Bishop, 2006). Following this probabilistic framework, the objective is to find most likely output seAs an alternative to the static, decoupled postediting, other strategies have been proposed, aiming to improve the productivity of the correction phase. Among them, the interactive-predictive pattern recognition (Foster et al., 1997) results particularly interesting. Under this framework, the static correction stage shifts to an iterative humancomputer collaboration process. The user interacts with the system by means of a feedback signal f . The system suggests then an ˜ , compatible with the feedalternative hypothesis y back. The inclusion of the feedback into the general pattern recognition rewrites Eq. (1) introduc81 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 81–86 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational"
P19-3014,E17-3017,0,0.0712997,"Missing"
P19-3014,W10-2920,0,0.0113936,"(image captioning) and video-to-text (video captioning). For tackling these tasks, we use a similar model: a neural encoder–decoder, based on recurrent neural networks with attention (Bahdanau et al., 2015; Xu et al., 2015; Yao et al., 2015). Our framework has also support for Transformer-like architectures (Vaswani et al., 2017). The NMT task regards the translation of texts from a medical domain. The system is similar to the one used by Peris and Casacuberta (2019), and was trained on the UFAL corpus (Bojar et al., 2017). The image and video captioning systems were trained on the Flickr8k (Hodosh et al., 2010) and MSVD (Chen and Dolan, 2011) datasets, respectively. The images were encoded using an Inception convolutional neural network (Szegedy et al., 2016) trained on the ILSVRC dataset (Russakovsky et al., 2015). The decoder receives the representation previous to the fully-connected work. In the case of the video captioning system, we applied a 3D convolutional neural network (Tran et al., 2015), for obtaining time-aware features. Finally, as aforementioned in previous sections, the systems can be retrained after the validation of each sample. In our demonstration, the systems We show and analyz"
P19-3014,W16-3420,0,0.0140711,"her alternatives in the aforementioned problems. However and despite these impressive advances, the systems are not perfect, and still make errors (Koehn and Knowles, 2017). In several scenarios, and especially in machine translation, fully-automatic systems are usually used for providing initial predictions to the input objects. These predictions are later revised by a human expert, who corrects the errors made by the system. This is known as post-editing and, in some scenarios, it increases the productivity with respect to performing the task from scratch (Alabau et al., 2016; Arenas, 2008; Hu and Cadwell, 2016). This system is implemented following a client–server architecture. For accessing the system, we developed a website, which communicates with the neural model, hosted in a local server. From this website, the different tasks can be tackled following the interactive-predictive framework. We opensource all the code developed for building this system. The demonstration in hosted in http://casmacat.prhlt.upv.es/ interactive-seq2seq. 1 (1) y Introduction 1.1 Interactive-predictive pattern recognition The sequence to sequence problem involves the transduction of an input sequence x into an outˆ (Gr"
P19-3014,2016.amta-researchers.9,0,0.0200929,"ribe the main architecture, features and usage of our interactivepredictive system. We also describe the frontend of our demonstration website and present an example of interactive session. (2) y compatible with f The most paradigmatic application of the interactive-predictive pattern recognition framework is machine translation. The addition of interactive protocols to foster productivity of translation environments have been studied for long time, for phrase-based models (Alabau et al., 2013, 2016; Barrachina et al., 2009; Federico et al., 2014; Green et al., 2014) and also for NMT systems (Knowles and Koehn, 2016; Peris et al., 2017; Peris and Casacuberta, 2019; Wuebker et al., 2016). The system we are presenting in this work is an extended version of Peris and Casacuberta (2019), who presented a NMT system that accepted a prefix feedback: the user corrected the first wrong character of the sentence. Hence, the system reacted to the feedback by providing an alternative suffix. This protocol can be implemented as a constrained beam search. Moreover, the system can be retrained incrementally, as soon as a corrected sample is validated, following an online learning scenario. We generalize this interactiv"
P19-3014,W17-3204,0,0.0289693,"introduces corrections in the form of characters. The system reacts to each correction, providing alternative hypotheses, compelling with the feedback provided by the user. The final objective is to reduce the human effort required during this correction process. ˆ = arg max p(y |x; Θ) y In the last years, Θ has been frequently implemented as a deep neural network, trained in an end-to-end way. These neural systems have consistently outperformed other alternatives in the aforementioned problems. However and despite these impressive advances, the systems are not perfect, and still make errors (Koehn and Knowles, 2017). In several scenarios, and especially in machine translation, fully-automatic systems are usually used for providing initial predictions to the input objects. These predictions are later revised by a human expert, who corrects the errors made by the system. This is known as post-editing and, in some scenarios, it increases the productivity with respect to performing the task from scratch (Alabau et al., 2016; Arenas, 2008; Hu and Cadwell, 2016). This system is implemented following a client–server architecture. For accessing the system, we developed a website, which communicates with the neur"
P19-3014,D15-1120,0,0.0312574,"he system. 84 As future work, we would like to improve the frontend of our website. Inspecting the attributes of black-box neural models is a relevant research topic, and it is under active development (e.g. Zeiler and Fergus, 2014; Ancona et al., 2017). Visualizing these relevant attributes would help to understand the model predictions and behavior. Moreover, a more sophisticated frontend would allow to implement interesting features, such as mapping the attention weights through the input sequence or the implementation of more complex interaction protocols, such as touch-based interaction (Marie and Max, 2015) or segment-based interaction (Peris et al., 2017). We intend to offer the different functionalities of the toolkit as REST services, for improving the reusability of the code. It is also planned to release the library in a Docker container in order to ease the deployment of future applications. ¨ Marco Ancona, Enea Ceolini, Cengiz Oztireli, and Markus Gross. 2017. Towards better understanding of gradient-based attribution methods for deep neural networks. arXiv:1711.06104. Acknowledgments Ondej Bojar, Barry Haddow, David Mareek , Roman Sudarikov, Aleˇs Tamchyna, and Duan Vari. 2017. Report on"
P19-3014,P16-1007,0,0.013916,"e system. We also describe the frontend of our demonstration website and present an example of interactive session. (2) y compatible with f The most paradigmatic application of the interactive-predictive pattern recognition framework is machine translation. The addition of interactive protocols to foster productivity of translation environments have been studied for long time, for phrase-based models (Alabau et al., 2013, 2016; Barrachina et al., 2009; Federico et al., 2014; Green et al., 2014) and also for NMT systems (Knowles and Koehn, 2016; Peris et al., 2017; Peris and Casacuberta, 2019; Wuebker et al., 2016). The system we are presenting in this work is an extended version of Peris and Casacuberta (2019), who presented a NMT system that accepted a prefix feedback: the user corrected the first wrong character of the sentence. Hence, the system reacted to the feedback by providing an alternative suffix. This protocol can be implemented as a constrained beam search. Moreover, the system can be retrained incrementally, as soon as a corrected sample is validated, following an online learning scenario. We generalize this interactive-predictive NMT system to cope with alternative input modalities, namel"
R09-1060,2005.eamt-1.6,0,0.259633,"Missing"
R09-1060,J93-2003,0,0.0249312,"Missing"
R09-1060,W04-3245,1,0.919012,"Missing"
R09-1060,W02-1020,0,0.22195,"Missing"
R09-1060,W06-1607,0,0.0359072,"Missing"
R09-1060,N03-1017,0,0.0302407,"Missing"
R09-1060,W02-1018,0,0.0562777,"Missing"
R09-1060,P02-1038,0,0.277971,"Missing"
R09-1060,E03-1032,0,0.620646,"Missing"
R09-1060,2008.eamt-1.22,1,0.852298,"Missing"
R09-1060,P06-2107,1,0.807224,"Missing"
R09-1060,2002.tmi-tutorials.2,0,0.0532899,"Missing"
R09-1060,J09-1002,1,\N,Missing
underwood-etal-2014-evaluating,J09-1002,1,\N,Missing
underwood-etal-2014-evaluating,N10-1078,0,\N,Missing
underwood-etal-2014-evaluating,W08-0309,0,\N,Missing
underwood-etal-2014-evaluating,carl-etal-2014-cft13,1,\N,Missing
underwood-etal-2014-evaluating,aziz-etal-2012-pet,0,\N,Missing
underwood-etal-2014-evaluating,2012.eamt-1.31,0,\N,Missing
underwood-etal-2014-evaluating,2012.tc-1.5,0,\N,Missing
W02-0706,W00-0508,0,0.0205933,"ite-state transducer (SFST). Thanks to this integration, the translation process can be efficiently performed by searching for an optimal path of states through the integrated network by using well-known optimization procedures such as (beam-search accelerated) Viterbi search. This “integrated architecture” can be compared with the more conventional “serial architecture”, where the HMMs, along with a suitable source language model, are used as a front-end to recognize a sequence of source-language words which is then processed by the translation model. A related approach has been proposed in (Bangalore and Ricardi, 2000; Bangalore and Ricardi, 2001). In any case, a pure pattern-recognition approach can be followed to build the required systems. Acoustic models can be trained from a sufficiently large source-language speech training set, in the very same way as in speech recognition. On the other hand, using adequate learning algorithms (Casacuberta, 2000; Vilar, 2000), the translation model can also be learned from a sufficiently large training set consisting of source-target parallel text. In this paper, we comment the results obtained using this approach in E U T RANS, a five-year joint effort of four Euro"
W02-0706,N01-1018,0,0.0193559,"Thanks to this integration, the translation process can be efficiently performed by searching for an optimal path of states through the integrated network by using well-known optimization procedures such as (beam-search accelerated) Viterbi search. This “integrated architecture” can be compared with the more conventional “serial architecture”, where the HMMs, along with a suitable source language model, are used as a front-end to recognize a sequence of source-language words which is then processed by the translation model. A related approach has been proposed in (Bangalore and Ricardi, 2000; Bangalore and Ricardi, 2001). In any case, a pure pattern-recognition approach can be followed to build the required systems. Acoustic models can be trained from a sufficiently large source-language speech training set, in the very same way as in speech recognition. On the other hand, using adequate learning algorithms (Casacuberta, 2000; Vilar, 2000), the translation model can also be learned from a sufficiently large training set consisting of source-target parallel text. In this paper, we comment the results obtained using this approach in E U T RANS, a five-year joint effort of four European institutions, partially f"
W03-2205,P00-1056,0,\N,Missing
W03-2205,J93-2003,0,\N,Missing
W03-2205,J90-2002,0,\N,Missing
W03-2804,J90-2002,0,0.203296,"een the previous drawbacks the following metric has been introduced: references, the evaluator will be able to propose new references, if needed. The evaluation process can be carried out very quickly, if one takes as the starting point the result obtained by the WER or the mWER. The idea consists of visualising the incorrect words detected by one of these methods (editing operations). The evaluator just needs to indicate whether each of the marked items is an actual error or whether it can rather be considered as an alternative translation This metric resembles very much the one proposed in (Brown et al, 1990). That work suggested for measuring the translation quality counting the number of times an evaluator would have to press the keyboard keys in order to make the proposed sentence correct. All references WER (aWER): It measures the number of words, which are to be inserted, deleted or replaced in the sentence under evaluation in order to obtain a correct translation. It can also be seen as a particular case of the mWER, but taking for granted that all the possible references are at our disposal. Since it is impossible to have a priori all possible All references Sentence Error Rate (aSER): The"
W03-2804,2001.mtsummit-papers.14,0,0.0351333,"Missing"
W03-2804,niessen-etal-2000-evaluation,0,0.399386,"problem. A brief survey of the current approach to tackle this problem is presented and a new proposal is introduced. This proposal attempts to measure the percentage of words, which should be modified at the output of an automatic translator in order to obtain a correct translation. To show the feasibility of the method we have assessed the most important SpanishCatalan translators in comparing the results obtained by the various methods. 1 Introduction Research in automatic translation lacks an appropriate, consistent and easy to use criterion for evaluating the results (White et al., 1994; Niessen et al., 2000). However, it turns out to be indispensable to have some tool that may allow us to compare two translation systems or to elicit how any variation of our system may affect the quality of the translations. This is important in the field of research as well as when a user has to choose between two or more translators. The evaluation of a translation system shows a number of inherent difficulties. First of all we are dealing with a subjective process, which is even difficult to define. This paper is circumscribed to the project SISHITRA (SIStemas HÍbridos para la TRAducción valenciano-castellano s"
W03-2804,P02-1040,0,0.107017,"which can also be obtained automatically: Multi reference WER (mWER): Identical approach to WER, but it considers several references for each sentence to be translated, i.e., for each sentence the editing distance will be calculated with regard to the various references and the smallest one is chosen (Niessen et al., 2000). It presents the drawback of requiring a great human effort before actually being able to use it. However, the effort is worthwhile, if it can be later used for hundreds of evaluations. BLEU Score: BLEU is an automatic metric designed by IBM, which uses several references (Papineni et al., 2002). The main problem of mWER is that all possible reference translations cannot be introduced. The BLEU score try to solve this problem by combining the available references. In a simplified manner we could say that it measures how many word sequences in the sentence under evaluation match the word sequences of some reference sentence. The BLEU score also includes a penalty for translations whose length differs significantly from that of the reference translation. 2.2 Subjective Evaluation Criteria Other kinds of metrics have been developed, which require human intervention in order to obtain an"
W03-2804,2001.mtsummit-papers.64,1,0.83673,"ample review a free online automatic translator for short texts. Internostrum: an on-line automatic translation program, available at http://www.torsimany.ua.es, designed by the Language and Computational Systems Department of the University of Alicante. It marks the doubtful words or segments as a review helping aid. It uses finite-state technology (Canals et al., 2001). Statistical: An experimental translator developed at the Computer Technology Institute of the Polytechnic University of Valencia. All components have been inferred automatically from training pairs using statistical methods (Tomás & Casacuberta, 2001). It is accessible at http://ttt.gan.upv.es/~jtomas/trad. 4.2 Setting up the evaluation experiment In order to carry out our evaluation, we have translated 120 sentences (2456 words) with the different MT. These sentences have been taken from different media: a newspaper, a technical manual, legal text... The references used by the WER were also taken from the Catalan version of the same documents. In mWER and in BLEU we used three additional references. These new references have been introduced by a human translator modifying the initial reference. Before applying the metrics shown in point 2"
W03-2804,1994.amta-1.25,0,0.0946322,"Missing"
W04-3245,N01-1018,0,0.0207663,"slation systems. Therefore, the human-machine synergy represented by the CAT paradigm seems to be more promising than fully-automatic translation in the near future. The CAT paradigm has two important aspects: the models need to provide adequate completions and they have to do so efficiently to perform under usability constrains. To fulfill these two requirements, Stochastic Finite State Transducers (SFST) have been selected since they have proved in the past to be able to provide adequate translations (Vidal, 1997; Knight and Al-Onaizan, 1998; Amengual et al., 2000; Casacuberta et al., 2001; Bangalore and Ricardi, 2001). In addition, efficient parsing algorithms can be easily adapted in order to provide completions. The rest of the paper is structured as follows. The following section introduces the general setting for machine translation and finite state models. In section 3, the search procedure for an interactive translation is presented. Experimental results are presented in section 4. Finally, some conclusions and future work are explained in section 5. 2 Machine translation with finite-state transducers Given a source sentence , the goal of MT is to find a target sentence t that maximizes:   t argmax"
W04-3245,J93-2003,0,0.0170044,"re labeled by three items: 1. a source symbol (a word from the source language vocabulary); The transformation of a parallel corpus into a corpus of single sentences is performed with the help of statistical alignments: each word is joined with its translation in the output sentence, creating an “extended word”. This joining is done taking care not to invert the order of the output words. The third step is trivial with this arrangement. In our experiments, the alignments are obtained using the GIZA software (Och and Ney, 2000; Al-Onaizan et al., 1999), which implements IBM statistical models (Brown et al., 1993). 2. a target string (a sequence of words from the target language vocabulary) and 3 Interactive search 3. a transition probability. The concept of interactive search is closely related to the CAT paradigm. This paradigm introduces the new factor t into the general machine translation equation (Equation 1). t represents a prefix in the target language obtained as a result of the interaction between the human translator and the machine translation system. They have been successfully applied into many translation tasks (Vidal, 1997; Amengual et al., 2000; Casacuberta et al., 2001). Furthermore"
W04-3245,knight-al-onaizan-1998-translation,0,0.0376173,"lack of translation excellence is a common characteristic in all machine translation systems. Therefore, the human-machine synergy represented by the CAT paradigm seems to be more promising than fully-automatic translation in the near future. The CAT paradigm has two important aspects: the models need to provide adequate completions and they have to do so efficiently to perform under usability constrains. To fulfill these two requirements, Stochastic Finite State Transducers (SFST) have been selected since they have proved in the past to be able to provide adequate translations (Vidal, 1997; Knight and Al-Onaizan, 1998; Amengual et al., 2000; Casacuberta et al., 2001; Bangalore and Ricardi, 2001). In addition, efficient parsing algorithms can be easily adapted in order to provide completions. The rest of the paper is structured as follows. The following section introduces the general setting for machine translation and finite state models. In section 3, the search procedure for an interactive translation is presented. Experimental results are presented in section 4. Finally, some conclusions and future work are explained in section 5. 2 Machine translation with finite-state transducers Given a source senten"
W04-3245,A00-1019,0,0.121909,"Missing"
W04-3245,P00-1056,0,0.0228035,"tochastic Finite-State Transducer (SFST) is a finite-state network whose transitions are labeled by three items: 1. a source symbol (a word from the source language vocabulary); The transformation of a parallel corpus into a corpus of single sentences is performed with the help of statistical alignments: each word is joined with its translation in the output sentence, creating an “extended word”. This joining is done taking care not to invert the order of the output words. The third step is trivial with this arrangement. In our experiments, the alignments are obtained using the GIZA software (Och and Ney, 2000; Al-Onaizan et al., 1999), which implements IBM statistical models (Brown et al., 1993). 2. a target string (a sequence of words from the target language vocabulary) and 3 Interactive search 3. a transition probability. The concept of interactive search is closely related to the CAT paradigm. This paradigm introduces the new factor t into the general machine translation equation (Equation 1). t represents a prefix in the target language obtained as a result of the interaction between the human translator and the machine translation system. They have been successfully applied into many trans"
W04-3245,P02-1040,0,0.0886325,"Missing"
W06-3109,J93-2003,0,0.0064886,"rom the previous equation. For example, in (Zens et al., 2002) the following model is proposed: pθ (f1J |eI1 ) Different translation models (TMs) have been proposed depending on how the relation between the source and the target languages is structured; that is, the way a target sentence is generated from a source sentence. This relation is summarized using the concept of alignment; that is, how the constituents (typically words or group-of-words) of a pair of sentences are aligned to each other. The most widely used single-word-based statistical alignment models (SAMs) have been proposed in (Brown et al., 1993; Ney et al., 2000). On the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (Yamada and Knight, 2001) , alignment templates are used in (Och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (PBT) 65 ˜K aK , e˜K ) P r(˜ aK eK 1 |˜ 1 )P r(f1 |˜ 1 1 = K X Y α(eI1 ) K,˜ aK 1 p(f˜k |˜ ea˜k ) (3) k=1 where a ˜k notes the index of the source phrase e˜ which is aligned with the k-th target phrase f˜k and that all possible segmentations have the sam"
W06-3109,W04-3245,1,0.907975,"Missing"
W06-3109,P01-1030,0,0.0308525,"C2003-08681-C02-02, the Agencia Valenciana de Ciencia y Tecnolog´ıa under contract GRUPOS03/031, the Generalitat Valenciana, and the project HERMES (Vicerrectorado de Investigaci´on - UCLM-05/06) 1 Note that the expression should also be maximized by I; however, for the sake of simplicity we suppose that it is known. (1) The search/decoding problem in SMT consists in solving the maximization problem stated in Eq. (1). In the literature, we can find different techniques to deal with this problem, ranging from heuristic and fast (as greedy decoders) to optimal and very slow decoding algorithms (Germann et al., 2001). Also, under certain circumstances, stack-based decoders can obtain optimal solutions. Many works (Berger et al., 1996; Wang and Waibel, 1998; Germann et al., 2001; Och et al., 2001; Ort´ız et al., 2003) have adopted different types of stack-based algorithms to solve the global search optimization problem for statistical machine translation. All these works follow two main different approaches according to the number of stacks used in the design and implementation of the search algorithm (the stacks are used to store partial hypotheses, sorted according to their partial score/probability, dur"
W06-3109,N03-1017,0,0.0492836,"e pruned. • On the other hand (Berger et al., 1996; Germann et al., 2001) make use of multiple stacks 64 Proceedings of the Workshop on Statistical Machine Translation, pages 64–71, c New York City, June 2006. 2006 Association for Computational Linguistics (one for each set of source covered/translated words in the partial hypothesis) in order to solve the disadvantages of the single-stack approach. By contrast, the problem of finding the best hypothesis to be expanded introduces an exponential term in the computational complexity of the algorithm. in (Marcu and Wong, 2002; Zens et al., 2002; Koehn et al., 2003; Tom´as and Casacuberta, 2003). For the translation model (P r(f1J |eI1 )) in Eq. (1), PBT can be explained from a generative point of view as follows (Zens et al., 2002): In (Ort´ız et al., 2003) the authors present an empirical comparison (about efficiency and translation quality) of the two approaches paying special attention to the advantages and disadvantages of the two approaches. In this paper we present a new formalism consisting of a generalization of the classical stack-based decoding paradigm for SMT. This new formalism defines a new family of stack-based decoders, which also integ"
W06-3109,W02-1018,0,0.0140581,"covered words the higher possibility to be pruned. • On the other hand (Berger et al., 1996; Germann et al., 2001) make use of multiple stacks 64 Proceedings of the Workshop on Statistical Machine Translation, pages 64–71, c New York City, June 2006. 2006 Association for Computational Linguistics (one for each set of source covered/translated words in the partial hypothesis) in order to solve the disadvantages of the single-stack approach. By contrast, the problem of finding the best hypothesis to be expanded introduces an exponential term in the computational complexity of the algorithm. in (Marcu and Wong, 2002; Zens et al., 2002; Koehn et al., 2003; Tom´as and Casacuberta, 2003). For the translation model (P r(f1J |eI1 )) in Eq. (1), PBT can be explained from a generative point of view as follows (Zens et al., 2002): In (Ort´ız et al., 2003) the authors present an empirical comparison (about efficiency and translation quality) of the two approaches paying special attention to the advantages and disadvantages of the two approaches. In this paper we present a new formalism consisting of a generalization of the classical stack-based decoding paradigm for SMT. This new formalism defines a new family of"
W06-3109,W01-1408,0,0.0487396,"M-05/06) 1 Note that the expression should also be maximized by I; however, for the sake of simplicity we suppose that it is known. (1) The search/decoding problem in SMT consists in solving the maximization problem stated in Eq. (1). In the literature, we can find different techniques to deal with this problem, ranging from heuristic and fast (as greedy decoders) to optimal and very slow decoding algorithms (Germann et al., 2001). Also, under certain circumstances, stack-based decoders can obtain optimal solutions. Many works (Berger et al., 1996; Wang and Waibel, 1998; Germann et al., 2001; Och et al., 2001; Ort´ız et al., 2003) have adopted different types of stack-based algorithms to solve the global search optimization problem for statistical machine translation. All these works follow two main different approaches according to the number of stacks used in the design and implementation of the search algorithm (the stacks are used to store partial hypotheses, sorted according to their partial score/probability, during the search process) : • On the one hand, in (Wang and Waibel, 1998; Och et al., 2001) a single stack is used. In that case, in order to make the search feasible, the pruning of t"
W06-3109,2005.mtsummit-papers.19,1,0.669807,",370 – 48.3 Table 2: E U T RANS -I and X EROX corpus statistics 5 Experiments and Results In this section, experimental results are presented for two well-known tasks: the E U T RANS -I (Amengual et al., 1996), a small size and easy translation task, and the X EROX (Cubel et al., 2004), a medium size and difficult translation task. The main statistics of these corpora are shown in Table 2. The translation results were obtained using a non-monotone generalized stack algorithm. For both tasks, the training of the different phrase models was carried out using the publicly available Thot toolkit (Ortiz et al., 2005). Different translation experiments have been carried out, varying the value of G (ranging from 0 to 8) and the maximum number of hypothesis that the algorithm is allow to store for all used stacks (S) (ranging from 28 to 212 ). In these experiments the following statistics are computed: the average score (or logProb) that the phrase-based translation model assigns to each hypothesis, the translation quality (by means of WER and Bleu measures), and the average time (in secs.) per sentence3 . In Figures 4 and 5 two plots are shown: the average time per sentence (left) and the average score (rig"
W06-3109,2001.mtsummit-papers.64,1,0.886716,"Missing"
W06-3109,P01-1067,0,0.0567809,"een the source and the target languages is structured; that is, the way a target sentence is generated from a source sentence. This relation is summarized using the concept of alignment; that is, how the constituents (typically words or group-of-words) of a pair of sentences are aligned to each other. The most widely used single-word-based statistical alignment models (SAMs) have been proposed in (Brown et al., 1993; Ney et al., 2000). On the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (Yamada and Knight, 2001) , alignment templates are used in (Och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (PBT) 65 ˜K aK , e˜K ) P r(˜ aK eK 1 |˜ 1 )P r(f1 |˜ 1 1 = K X Y α(eI1 ) K,˜ aK 1 p(f˜k |˜ ea˜k ) (3) k=1 where a ˜k notes the index of the source phrase e˜ which is aligned with the k-th target phrase f˜k and that all possible segmentations have the same probability. In (Tom´as and Casacuberta, 2001; Zens et al., 2002), it also is assumed that the alignments must be monotonic. This led us to the following equation: pθ (f1J |eI1 ) = α(eI1 ) K X Y K,˜ aK 1"
W06-3109,2002.tmi-tutorials.2,0,0.218058,"er possibility to be pruned. • On the other hand (Berger et al., 1996; Germann et al., 2001) make use of multiple stacks 64 Proceedings of the Workshop on Statistical Machine Translation, pages 64–71, c New York City, June 2006. 2006 Association for Computational Linguistics (one for each set of source covered/translated words in the partial hypothesis) in order to solve the disadvantages of the single-stack approach. By contrast, the problem of finding the best hypothesis to be expanded introduces an exponential term in the computational complexity of the algorithm. in (Marcu and Wong, 2002; Zens et al., 2002; Koehn et al., 2003; Tom´as and Casacuberta, 2003). For the translation model (P r(f1J |eI1 )) in Eq. (1), PBT can be explained from a generative point of view as follows (Zens et al., 2002): In (Ort´ız et al., 2003) the authors present an empirical comparison (about efficiency and translation quality) of the two approaches paying special attention to the advantages and disadvantages of the two approaches. In this paper we present a new formalism consisting of a generalization of the classical stack-based decoding paradigm for SMT. This new formalism defines a new family of stack-based decode"
W06-3109,koen-2004-pharaoh,0,\N,Missing
W07-0708,J93-2003,0,0.00594816,"rget language; Σ denotes the source language vocabulary, and ∆i the i-th target language vocabulary; the algorithm can be outlined as follows: 1. Each multilingual sample is transformed into a single string from an extended vocabulary (Γ ⊆ Σ × ∆∗1 × · · · × ∆∗m ) using a labeling function (Lm ). This transformation searches an adequate monotonic segmentation for each of the m source-target language pairs on the basis of bilingual alignments such as those given by G IZA ++ (Och, 2000). A monotonic segmentation copes with monotonic alignments, that is, j < k ⇒ aj < ak following the notation of (Brown et al., 1993). Each source token, which can be either a word or a phrase (P´erez et al., 2007), is then joined with a target phrase of each language as the corresponding segmentation suggests. Each extended symbol consists of a token from the source language plus zero 3:da 2:jeitsiko 1:minimoa 0:tenperatura 0:temperaturas 1:minimas 2:en 3:descenso 0:temperaturas 1:minimas 2:en 3:descenso 2:falling 1:temperatures 0:low (a) Spanish-Basque (b) Spanish-English Alignment #0 Alignment #0 0 temperaturas |temperatura |NIL 1 maximas |maximoak |high temperatures minimas |minimoak |low temperatures 2 en |NIL |NIL 3 d"
W07-0708,J04-2004,1,0.816824,", q 0 ), which is a transition from the state q to the state q 0 , with the source symbol w and producing the substrings (˜ p1 , . . . , p˜m ); P : R → [0, 1] is the transition probability distribution; 57 F : Q → [0, 1] is the final state probability distribution; The probability distributions satisfy the stochastic constraint: ∀q ∈ Q F (q)+ (1) P P (q, w, p˜1 , . . . , p˜m , q0) =1 w,˜ p1 ,...,˜ pm ,q 0 2.2 Training the multilingual translation model Both topology and parameters of an SFST can be learned fully automatically from bilingual examples making use of underlying alignment models (Casacuberta and Vidal, 2004). Furthermore, a multi-target SFST can be inferred from a multilingual set of samples (Gonz´alez and Casacuberta, 2006). Even though in realistic situations multilingual corpora are too scarce, recent works (Popovi´c et al., 2005) show that bilingual corpora covering the same domain are sufficient to obtain generalized corpora based on which one can subsequently create the required collections of aligned tuples. The inference algorithm, GIAMTI (grammatical inference and alignments for multi-target transducer inference), requires a multilingual corpus, that is, a finite set of multilingual samp"
W07-0708,W05-0831,0,0.012739,"uality between the English and the Basque translations. The underlying reason might be due to the fact that SFST models do not capture properly the rich morphology of the Basque as they have to face long-distance reordering issues. These differences in the performance of the system when translating into English or into Basque have been previously detected in other works (Ortiz et al., 2003). In our case, a manual review of the models and the obtained translations encourage us to make use of reordering models in future work, since they have proved to report good results in a similar framework (Kanthak et al., 2005). 5 Concluding remarks and further work The main contribution of this paper is the proposal of a fully embedded architecture for multiple speech translation. Thus, acoustic models are integrated on the fly into a multi-target translation model. The most significant feature of this approach is its ability to carry out both the recognition and the translation into multiple languages integrated in a unique model. Due to the finite-state nature of this model, the speech translation engine is based on a Viterbilike algorithm. In contrast to the mono-target systems, multitarget SFSTs enable the tran"
W07-0708,knight-al-onaizan-1998-translation,0,0.0627021,"Missing"
W07-0708,2003.mtsummit-papers.40,1,0.821128,"Missing"
W07-0708,W04-0407,0,\N,Missing
W07-0708,W05-0806,0,\N,Missing
W09-1005,J04-2004,1,0.923994,"g from a phrase-based dictionary which is inferred from the parallel corpus. Nevertheless, backoff transitions to lower history levels are taken for smoothing purposes. If the lowest level is reached and no transition has been found for next word sj , then a transition to the &lt;unk&gt; state is fired, thus considering sj as a non-starting word for any bilingual phrase in the model. There is only 1 initial state, which is denoted as &lt;s&gt;, and it is placed at the 1st history level. The inverse labelling function is applied over the automaton transitions as in Figure 4, obtaining a single transducer (Casacuberta and Vidal, 2004). On demande une activité Q Pr = p Q’ Action is required activité / On /ε demande /ε une /ε Action is required Q Q’ Pr = p Pr = 1 Pr = 1 Pr = 1 3 Finite state decoding Figure 4: Phrase-based inverse labelling function Equation 2 expresses the MT problem in terms of a finite state model that is able to compute the exIntermediate states are artificially created since 26 pression Pr(s, t). Given that only the input sentence is known, the model has to be parsed, taking into account all possible t that are compatible with s. The best output hypothesis ˆt would be that one which corresponds to a pat"
W09-1005,2001.mtsummit-papers.68,0,0.0193075,"Missing"
W09-1005,P02-1040,0,\N,Missing
W09-1005,P07-2045,0,\N,Missing
W10-1725,W09-0429,0,0.0136192,"sed the similarity of a given sentence by computing the probability of such sentence with respect to the alignment model of the in-domain corpus, and established the following similarity levels: 5 In translation, as in other linguistics areas, punctuation marks are essential as they help to understand the intention of a message and organise the ideas to avoid ambiguity. They also indicate pauses, hierarchies and emphasis. In our system, punctuation marks have been taken into account during decoding. Traditionally, in SMT punctuation marks are treated as words and this has undesirable effects (Koehn and Haddow, 2009). For example, commas have a high probability of occurrence and many possible translations are generated. Most of them are not consistent across languages. This introduces too much noise to the phrase tables. (Koehn and Haddow, 2009) established a framework to specify reordering constraints with walls and zones, where commas and end of sentence are not mixed with various clauses. Gains between 0.1 and 0.2 of BLEU are reported. Specifying zones and walls with XML tags in input sentences allows us to identify structured fragments that the Moses decoder uses with the following restrictions: • Lev"
W10-1725,P07-2045,0,0.0159995,"Missing"
W10-1725,2005.mtsummit-papers.11,0,0.0190974,"ntal setup For building our SMT systems, the open-source SMT toolkit Moses (Koehn et al., 2007) was used in its standard setup. The decoder includes a loglinear model comprising a phrase-based translation model, a language model, a lexicalised distortion model and word and phrase penalties. The weights of the log-linear interpolation were optimised by means of MERT (Och, 2003). In addition, a 5-gram LM with Kneser-Ney (Kneser and Ney, 1995) smoothing and interpolation was built by means of the SRILM (Stolcke, 2002) toolkit. For building our baseline system, the NewsCommentary and Europarl v5 (Koehn, 2005) data were employed, with maximum sentence length set to 40 in the case of the data used to build the translation models, and without restriction in the case of the LM. Statistics of the bilingual data can be seen in Table 1. In all the experiments reported, MERT was run on the 2008 test set, whereas the test set 2009 was considered as test set as such. In addition, all the experiments described below were performed in lowercase and tokenised conditions. For the final run, the detokenisation and recasing was performed according to the technique described in the Workshop baseline description. 6"
W10-1725,J03-1002,0,0.00593269,"eden, 15-16 July 2010. 2010 Association for Computational Linguistics The out of vocabulary words recovery method is simple: the out of vocabulary words from the test, when taking into account the reduced training set, are obtained and then discarded sentences that contain at least one of them are retrieved. Then, those sentences are added to the reduced training set. Finally, alignments with the resulting training set were computed and the usual training procedure for phrase-based systems was performed. filter for noisy corpora (Khadivi and Ney, 2005). We trained an IBM model 4 using GIZA++ (Och and Ney, 2003) with the in-domain corpus and computed the alignment scores over the United Nations sentences. We assume that the alignment score is a good measure of similarity. An important factor in the alignment score is the length of the sentences, so we clustered the bilingual sentences in groups with the same sum of source and target language sentence sizes. In each of the groups, the higher the alignment score is, the more similar the sentence is to the in-domain corpus sentences. Hence, we computed the average alignment score for each one of the clusters obtained for the corpus considered in-domain"
W10-1725,P03-1021,0,0.00532783,"for thousands/millions. |S |is the number of sentences, |W |the number of running words, and |V | the vocabulary size. Statistics are reported on the tokenised and lowercased corpora. 6 |S| 1822K 108K 6.2M 3.9M Experiments Experimental setup For building our SMT systems, the open-source SMT toolkit Moses (Koehn et al., 2007) was used in its standard setup. The decoder includes a loglinear model comprising a phrase-based translation model, a language model, a lexicalised distortion model and word and phrase penalties. The weights of the log-linear interpolation were optimised by means of MERT (Och, 2003). In addition, a 5-gram LM with Kneser-Ney (Kneser and Ney, 1995) smoothing and interpolation was built by means of the SRILM (Stolcke, 2002) toolkit. For building our baseline system, the NewsCommentary and Europarl v5 (Koehn, 2005) data were employed, with maximum sentence length set to 40 in the case of the data used to build the translation models, and without restriction in the case of the LM. Statistics of the bilingual data can be seen in Table 1. In all the experiments reported, MERT was run on the 2008 test set, whereas the test set 2009 was considered as test set as such. In addition"
W10-1743,P05-3026,0,0.0198953,"on Statistical Machine Translation (WMT 2010). On each translation direction, all the submitted systems were combined into a consensus translation. These consensus translations always improve translation quality of the best individual system. 1 Introduction The UPV-PRHLT approach to MT system combination is based on a refined version of the algorithm described in (Gonz´alez-Rubio and Casacuberta, 2010), with additional information to cope with hypotheses of different quality. In contrast to most of the previous approaches to combine the outputs of multiple MT systems (Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006; Schroeder et al., 2009), which are variations over the ROVER voting scheme (Fiscus, 1997), we consider the problem of computing a consensus translation as the problem of modelling a set of string patterns with an adequate prototype. Under this framework, the translation hypotheses of each of the MT systems are considered as individual patterns in a set of string patterns. The (generalised) median string, which is the optimal prototype of a set of strings (Fu, 1982), is the chosen prototype to model the set of strings. 2 2.1 Median String Given a set E = e1 , . . . , en"
W10-1743,E06-1005,0,0.0231263,"nslation (WMT 2010). On each translation direction, all the submitted systems were combined into a consensus translation. These consensus translations always improve translation quality of the best individual system. 1 Introduction The UPV-PRHLT approach to MT system combination is based on a refined version of the algorithm described in (Gonz´alez-Rubio and Casacuberta, 2010), with additional information to cope with hypotheses of different quality. In contrast to most of the previous approaches to combine the outputs of multiple MT systems (Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006; Schroeder et al., 2009), which are variations over the ROVER voting scheme (Fiscus, 1997), we consider the problem of computing a consensus translation as the problem of modelling a set of string patterns with an adequate prototype. Under this framework, the translation hypotheses of each of the MT systems are considered as individual patterns in a set of string patterns. The (generalised) median string, which is the optimal prototype of a set of strings (Fu, 1982), is the chosen prototype to model the set of strings. 2 2.1 Median String Given a set E = e1 , . . . , en , . . . , eN of transl"
W10-1743,P02-1040,0,0.0964417,"Missing"
W10-1743,E09-1082,0,0.0214719,"n each translation direction, all the submitted systems were combined into a consensus translation. These consensus translations always improve translation quality of the best individual system. 1 Introduction The UPV-PRHLT approach to MT system combination is based on a refined version of the algorithm described in (Gonz´alez-Rubio and Casacuberta, 2010), with additional information to cope with hypotheses of different quality. In contrast to most of the previous approaches to combine the outputs of multiple MT systems (Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006; Schroeder et al., 2009), which are variations over the ROVER voting scheme (Fiscus, 1997), we consider the problem of computing a consensus translation as the problem of modelling a set of string patterns with an adequate prototype. Under this framework, the translation hypotheses of each of the MT systems are considered as individual patterns in a set of string patterns. The (generalised) median string, which is the optimal prototype of a set of strings (Fu, 1982), is the chosen prototype to model the set of strings. 2 2.1 Median String Given a set E = e1 , . . . , en , . . . , eN of translation hypotheses from N M"
W10-1743,2005.eamt-1.20,0,\N,Missing
W11-2116,C10-1036,0,0.0172323,"(e0 ) e (6) e0 ∈Eh ≈ arg max e0 ∈Eh = arg max e0 ∈Eh N X n=1 N X n=1 αn · Gn (e0 ) αn · X (7) Pn (e|f ) · S(e, e0 ) , (8) e∈Dn (f ) where N is the total number of component systems, Eh represents the hypotheses space where the search is performed, Gn (e0 ) is the Bayes gain of hypothesis e0 given by the nth component system and αn is a scaling factor introduced to take into account the differences in quality of the component models. It is worth mentioning that by using a linear combination instead of a mixture model, we avoid the problem of component systems not sharing the same search space (Duan et al., 2010). (9) e∈Dn (f ) ck   r · min e1− c , 1.0 , (10) where r is the length of the evidence, c the length of the hypothesis, mk the number of n-gram matches of size k, and ck the count of n-grams of size k in the hypothesis. The evidences space Dn (f ) may contain a huge number of hypotheses1 which often make impractical to compute Eq. (9) directly. To avoid this problem, Tromble et al. (2008) propose linear BLEU, an approximation to the BLEU score to efficiently perform MBR decoding on the lattices provided by the component systems. However, we want to explore a hypotheses space not restricted to"
W11-2116,W10-1743,1,0.876963,"Missing"
W11-2116,P11-1127,1,0.78013,"nology (PRHLT) group to the system combination task of the sixth workshop on statistical machine translation (WMT 2011). Each submissions is generated by a multi-system minimum Bayes risk (MBR) technique. Our technique uses the MBR decision rule and a linear combination of the component systems’ probability distributions to search for the minimum risk translation among all the sentences in the target language. 1 Minimum Bayes risk Decoding Introduction The UPV-PHRLT approach to machine translation (MT) system combination is based on the minimum Bayes risk system combination (MBRSC) algorithm (Gonzlez-Rubio et al., 2011). A multisystem MBR technique that computes consensus translations over multiple component systems. MBRSC operates directly on the outputs of the component models. We perform an MBR decoding using a linear combination of the component models’ probability distributions. Instead of reranking the translations provided by the component systems, we search for the hypothesis with the minimum expected translation error among all the possible finite-length strings in the target language. By using a loss function based on BLEU (Papineni et al., 2002), we avoid the hypothesis alignment problem that is c"
W11-2116,N04-1022,0,0.0322494,"de Sistemas Inform´aticos y Computaci´on Universitat Polit`ecnica de Val`encia {jegonzalez|fcn}@dsic.upv.es Abstract 2 SMT can be described as a mapping of a word sequence f in a source language to a word sequence e in a target language; this mapping is produced by the MT decoder D(f ). If the reference translation e is known, the decoder performance can be measured by the loss function L(e, D(f )). Given such a loss function L(e, e0 ) between an automatic translation e0 and a reference e, and an underlying probability model P (e|f ), MBR decoding has the following form (Goel and Byrne, 2000; Kumar and Byrne, 2004): This paper presents the submissions of the pattern recognition and human language technology (PRHLT) group to the system combination task of the sixth workshop on statistical machine translation (WMT 2011). Each submissions is generated by a multi-system minimum Bayes risk (MBR) technique. Our technique uses the MBR decision rule and a linear combination of the component systems’ probability distributions to search for the minimum risk translation among all the sentences in the target language. 1 Minimum Bayes risk Decoding Introduction The UPV-PHRLT approach to machine translation (MT) syst"
W11-2116,P09-1019,0,0.0134038,"he size of its state set. the hypothesis and C 0 (ng) is the expected count of ng in the evidences. To compute the n-gram matchings m0k , the count of each n-gram is truncated, if necessary, to not exceed the expected count for that n-gram in the evidences. We have replaced a summation over a possibly exponential number of items (e0 ∈ Dn (f ) in Eq. (9)) with a summation over a polynomial number of ngrams that occur in the evidences2 . Both, the expected length of the evidences r0 and their expected n-gram counts m0k can be pre-computed efficiently from N -best lists and translation lattices (Kumar et al., 2009; DeNero et al., 2010). 3.2 Model Training The scaling factors in Eq. (8) denote the “quality” of each system with respect to the rest of them, i.e. the relative importance of each system in the Bayes gain computation. This scaling factors must be carefully tuned to obtain good translations. We compute the scaling factor of each system as the number of times the hypothesis of the system is the best TER-scoring translation in the tuning corpora. Previous works show that this measure obtains the best translation results among other heuristic measures (Gonz´alez-Rubio et al., 2010) and even as go"
W11-2116,P03-1021,0,0.0186631,"aling factors in Eq. (8) denote the “quality” of each system with respect to the rest of them, i.e. the relative importance of each system in the Bayes gain computation. This scaling factors must be carefully tuned to obtain good translations. We compute the scaling factor of each system as the number of times the hypothesis of the system is the best TER-scoring translation in the tuning corpora. Previous works show that this measure obtains the best translation results among other heuristic measures (Gonz´alez-Rubio et al., 2010) and even as good results as more complex methods such as MERT (Och, 2003). A normalization is performed to transform these counts into the range [0.0, 1.0]. After the normalization, a weight value of 0.0 is assigned to the lowest-scoring system, i.e. the lowestscoring system is discarded and not taken into account in the computation of the Bayes gain. 3.3 Model Decoding In most MBR algorithms, the hypotheses space is equal to the evidences space. However, we are interested in extend the hypotheses space by including new sentences created using fragments of the hypotheses in the evidences spaces of the component models. We perform the search (argmax operation in Eq."
W11-2116,P02-1040,0,0.0891946,"ayes risk system combination (MBRSC) algorithm (Gonzlez-Rubio et al., 2011). A multisystem MBR technique that computes consensus translations over multiple component systems. MBRSC operates directly on the outputs of the component models. We perform an MBR decoding using a linear combination of the component models’ probability distributions. Instead of reranking the translations provided by the component systems, we search for the hypothesis with the minimum expected translation error among all the possible finite-length strings in the target language. By using a loss function based on BLEU (Papineni et al., 2002), we avoid the hypothesis alignment problem that is central to standard system combination approaches (Rosti et al., 2007). MBRSC assumes only that each translation model can produce expectations of n-gram counts; the latent derivation structures of the component systems can differ arbitrary. This flexibility allows us to combine a great variety of MT systems. ˆ = arg min R(e0 ) e e0 ∈E X P (e|f ) · L(e, e0 ) , = arg min e0 ∈E (1) (2) e∈E where R(e0 ) denotes the Bayes risk of candidate translation e0 under loss function L, and E represents the space of translations. If the loss function betwe"
W11-2116,N07-1029,0,0.021372,"sus translations over multiple component systems. MBRSC operates directly on the outputs of the component models. We perform an MBR decoding using a linear combination of the component models’ probability distributions. Instead of reranking the translations provided by the component systems, we search for the hypothesis with the minimum expected translation error among all the possible finite-length strings in the target language. By using a loss function based on BLEU (Papineni et al., 2002), we avoid the hypothesis alignment problem that is central to standard system combination approaches (Rosti et al., 2007). MBRSC assumes only that each translation model can produce expectations of n-gram counts; the latent derivation structures of the component systems can differ arbitrary. This flexibility allows us to combine a great variety of MT systems. ˆ = arg min R(e0 ) e e0 ∈E X P (e|f ) · L(e, e0 ) , = arg min e0 ∈E (1) (2) e∈E where R(e0 ) denotes the Bayes risk of candidate translation e0 under loss function L, and E represents the space of translations. If the loss function between any two hypotheses can be bounded: L(e, e0 ) ≤ Lmax , the MBR decoder can be rewritten in term of a similarity function"
W11-2116,D08-1065,0,0.0154013,"differences in quality of the component models. It is worth mentioning that by using a linear combination instead of a mixture model, we avoid the problem of component systems not sharing the same search space (Duan et al., 2010). (9) e∈Dn (f ) ck   r · min e1− c , 1.0 , (10) where r is the length of the evidence, c the length of the hypothesis, mk the number of n-gram matches of size k, and ck the count of n-grams of size k in the hypothesis. The evidences space Dn (f ) may contain a huge number of hypotheses1 which often make impractical to compute Eq. (9) directly. To avoid this problem, Tromble et al. (2008) propose linear BLEU, an approximation to the BLEU score to efficiently perform MBR decoding on the lattices provided by the component systems. However, we want to explore a hypotheses space not restricted to the evidences provided by the systems. In Eq. (9), we have one hypothesis e0 that is to be compared to a set of evidences e ∈ Dn (f ) which follow a probability distribution Pn (e|f ). Instead of computing the expected BLEU score by calculating the BLEU score with respect to each of the evidences, our approach will be to use the expected n-gram counts and sentence length of the evidences"
W11-2116,N10-1141,0,\N,Missing
W11-4414,J93-2003,0,0.0976892,"target languages. With this basis we present a reformulation of the GIATI methodology to infer stochastic regular bi-languages for machine translation purposes. 1 Introduction The goal of statistical machine translation (SMT) is to search for the sentence ˆt that maximizes the a-posteriori probability P (t|s) of the target sentence t being the translation of a given sentence s from the source language. The translation models in SMT are automatically learned from bilingual samples. In the early nineties machine translation was tackled as a pure probabilistic process by the IBM research group (Brown et al., 1993). Within the SMT framework, stochastic-finite-state transducers (SFSTs) have also been proposed for machine translation purposes (Bangalore and Riccardi, 2002) (Shankar et al., 2005) (Casacuberta and Vidal, 2004) (Casacuberta and Vidal, 2007) (Blackwood et al., 2009). In such a context, SMT can be viewed as the problem of computing the joint probability distribution of some source and target languages. i.e. P (t, s), inferred from a bi-lingual corpus. The 98 Francisco Casacuberta Instituto Tecnol´ogico de Inform´atica Universidad Polit´ecnica de Valencia Valencia, Spain fcn@iti.upv.es joint pr"
W11-4414,J04-2004,1,0.573324,"chine translation (SMT) is to search for the sentence ˆt that maximizes the a-posteriori probability P (t|s) of the target sentence t being the translation of a given sentence s from the source language. The translation models in SMT are automatically learned from bilingual samples. In the early nineties machine translation was tackled as a pure probabilistic process by the IBM research group (Brown et al., 1993). Within the SMT framework, stochastic-finite-state transducers (SFSTs) have also been proposed for machine translation purposes (Bangalore and Riccardi, 2002) (Shankar et al., 2005) (Casacuberta and Vidal, 2004) (Casacuberta and Vidal, 2007) (Blackwood et al., 2009). In such a context, SMT can be viewed as the problem of computing the joint probability distribution of some source and target languages. i.e. P (t, s), inferred from a bi-lingual corpus. The 98 Francisco Casacuberta Instituto Tecnol´ogico de Inform´atica Universidad Polit´ecnica de Valencia Valencia, Spain fcn@iti.upv.es joint probability distributions of pairs of strings may be modeled by a probability distribution on a set of strings based on bi-lingual units as proposed in (Bangalore and Riccardi, 2002) for SFSTs. Alternatively (Casac"
W11-4414,W09-1005,1,0.898737,"Missing"
W11-4414,knight-al-onaizan-1998-translation,0,0.0415578,"sco Casacuberta Instituto Tecnol´ogico de Inform´atica Universidad Polit´ecnica de Valencia Valencia, Spain fcn@iti.upv.es joint probability distributions of pairs of strings may be modeled by a probability distribution on a set of strings based on bi-lingual units as proposed in (Bangalore and Riccardi, 2002) for SFSTs. Alternatively (Casacuberta and Vidal, 2004) (Mari˜no et al., 2006) proposed n-grams models of bi-lingual units. However, only a few techniques to learn finite-state transducers for machine translation purposes can be found (Bangalore and Riccardi, 2002) (Oncina et al., 1993) (Knight and Al-Onaizan, 1998) (Casacuberta and Vidal, 2007). On the other hand, a method of inference of SFST based on the inference of stochastic finite-state automata (Casacuberta and Vidal, 2004) was proposed and then used in machine translation applications (Casacuberta and Vidal, 2007) (P´erez et al., 2008) (Gonz´alez and Casacuberta, 2009). This method was called grammatical inference and alignments for transducer inference (GIATI) and is based on some important properties relating regular translations generated by finite-state-transducers and regular languages over some bi-lingual alphabet (Berstel, 1979). On the o"
W11-4414,J06-4004,0,0.0523339,"Missing"
W11-4414,J03-1002,0,0.00521186,"be defined. This relation was called alignment in (Kornai, 2008) and 103 depends on the the application task. In this context the aim of the alignment is to synchronize sequences of features from two different finite alphabets (Kornai, 1995). Correspondences between source and target strings could be complex, could include longdistance and/or not consecutive associations, etc, such that the choice of a suitable alignment is a difficult problem to be solved. One way to deal with this problem in the machine translation framework is the use of statistical alignments models (Brown et al., 1993) (Och and Ney, 2003). The choice of an adequate alignment/segmentation procedure is also related with the parsing procedure based on the bi-automaton. In the translation procedure, the target sentence ˆt is obtained as the concatenation of target substrings matching a given source sentence that also consists of a sequence of source substrings. A monotonic segmentation guaranties that the procedure to transform pairs of strings in S + into bi-strings in Γ∗ is reversible. Example 5.1. Let Σ = {a, b} and ∆ = {0, 1} be two finite alphabets. Let now S + be a bilingual corpus of translations consisting in pairs of stri"
W12-3111,2007.mtsummit-papers.54,1,0.907507,"of the Universitat Polit`ecnica de Val`encia to the quality estimation task of the seventh workshop on statistical machine translation (WMT12). We focus on two different issues: how to effectively combine subsequence-level features into sentence-level features, and how to select the most adequate subset of features. Results showed that an adequate selection of a subset of highly discriminative features can improve efficiency and performance of the quality estimation system. 1 2 Features and Learning Algorithm 2.1 Introduction Quality estimation (QE) (Ueffing et al., 2003; Blatz et al., 2004; Sanchis et al., 2007; Specia and Farzindar, 2010) is a topic of increasing interest in machine translation (MT). It aims at providing a quality indicator for unseen translations at various granularity levels. Different from MT evaluation, QE do not rely on reference translations and is generally addressed using machine learning techniques to predict quality scores. Our main focus in this article is in the combination of subsequence features into sentence features, and in the selection of a subset of relevant features to improve performance and efficiency. Section 2 describes the features and the learning algorith"
W12-3111,2010.jec-1.5,0,0.191748,"lit`ecnica de Val`encia to the quality estimation task of the seventh workshop on statistical machine translation (WMT12). We focus on two different issues: how to effectively combine subsequence-level features into sentence-level features, and how to select the most adequate subset of features. Results showed that an adequate selection of a subset of highly discriminative features can improve efficiency and performance of the quality estimation system. 1 2 Features and Learning Algorithm 2.1 Introduction Quality estimation (QE) (Ueffing et al., 2003; Blatz et al., 2004; Sanchis et al., 2007; Specia and Farzindar, 2010) is a topic of increasing interest in machine translation (MT). It aims at providing a quality indicator for unseen translations at various granularity levels. Different from MT evaluation, QE do not rely on reference translations and is generally addressed using machine learning techniques to predict quality scores. Our main focus in this article is in the combination of subsequence features into sentence features, and in the selection of a subset of relevant features to improve performance and efficiency. Section 2 describes the features and the learning algorithm used in the experiments. Se"
W12-3111,2003.mtsummit-papers.52,0,0.2075,"nd human language technology group (PRHLT) of the Universitat Polit`ecnica de Val`encia to the quality estimation task of the seventh workshop on statistical machine translation (WMT12). We focus on two different issues: how to effectively combine subsequence-level features into sentence-level features, and how to select the most adequate subset of features. Results showed that an adequate selection of a subset of highly discriminative features can improve efficiency and performance of the quality estimation system. 1 2 Features and Learning Algorithm 2.1 Introduction Quality estimation (QE) (Ueffing et al., 2003; Blatz et al., 2004; Sanchis et al., 2007; Specia and Farzindar, 2010) is a topic of increasing interest in machine translation (MT). It aims at providing a quality indicator for unseen translations at various granularity levels. Different from MT evaluation, QE do not rely on reference translations and is generally addressed using machine learning techniques to predict quality scores. Our main focus in this article is in the combination of subsequence features into sentence features, and in the selection of a subset of relevant features to improve performance and efficiency. Section 2 descri"
W12-3111,C04-1046,1,\N,Missing
W12-6217,J04-2004,1,0.85818,"Missing"
W12-6217,P11-1105,0,0.0428307,"Missing"
W12-6217,J06-4004,0,0.0767439,"Missing"
W12-6217,P02-1040,0,0.0835647,"Missing"
W12-6217,2010.eamt-1.16,1,0.760248,"Missing"
W12-6217,C04-1168,0,0.0386764,"Missing"
W16-3415,J09-1002,1,0.865245,"Missing"
W16-3415,P96-1041,0,0.0250428,"that we want to obtain an empty translation. Word correction: each time the user corrects a word or inserts a new one, we align the new word with its correspondent source words using a hidden markov alignment model (Vogel et al., 1996). All the MT systems used in this work were trained with the standard configuration of Moses, with the weights of the log-linear model being optimized by means of the Minimum Error Rate Training (MERT) procedure (Och, 2003). Lastly, a 5-gram wordbased language model was estimated on the target side of the parallel corpora, using the improved KneserNey smoothing (Chen and Goodman, 1996), by means of the SRILM toolkit (Stolcke, 2002). For the implementation of the classic prefix-based IMT systems, we made the word graph exploration and the best suffix generation for a given prefix following the procedure described by Barrachina et al. (2009): We generated a word graph for each sentence to translate. After that, treating the word graph as a weighted finite-state automaton, we parsed the prefix over it, from the initial state to any other intermediate state, to find the best path that accounts for the prefix. Finally, we obtained the corresponding translation for the best path"
W16-3415,2011.iwslt-evaluation.1,0,0.0323036,"Missing"
W16-3415,D13-1025,1,0.896718,"Missing"
W16-3415,K16-1020,1,0.837364,"Missing"
W16-3415,N12-1036,0,0.0177861,"IMT) field arose as an alternative to classic post-editing systems, aiming to reduce human post-editing effort and increase efficiency. This paradigm strives for combining the knowledge of a human translator and the efficiency of an MT system. Notable contributions to IMT technology were carried out around the TransType (Foster et al., 1997; Langlais and Lapalme, 2002), TransType2 (Barrachina et al., 2009; Casacuberta et al., 2009); and CasMaCat (Mart´ınez-G´omez et al., 2012; Alabau et al., 2013; Gonz´alez-Rubio et al., 2013; Sanchis-Trilles et al., 2014) projects, among others (Koehn, 2009; Huang et al., 2012; Cai et al., 2013; Green et al., 2014; Torregrosa et al., 2014; Azadi and Khadivi, 2015; Marie and Max, 2015). Especially interesting is the so-called prefix-based IMT (Barrachina et al., 2009). In this approach, the user corrected the first wrong word (from left-to-right) of the Interactive-Predictive Translation based on Multiple Word-Segments 283 translation suggested by the system. Then, the system proposed an alternative hypothesis, compatible with the user feedback. A cumbersome phenomenon noticed in this protocol happened when the non-validated part of the sentence contained correct wo"
W16-3415,P09-4005,0,0.105704,"Translation (IMT) field arose as an alternative to classic post-editing systems, aiming to reduce human post-editing effort and increase efficiency. This paradigm strives for combining the knowledge of a human translator and the efficiency of an MT system. Notable contributions to IMT technology were carried out around the TransType (Foster et al., 1997; Langlais and Lapalme, 2002), TransType2 (Barrachina et al., 2009; Casacuberta et al., 2009); and CasMaCat (Mart´ınez-G´omez et al., 2012; Alabau et al., 2013; Gonz´alez-Rubio et al., 2013; Sanchis-Trilles et al., 2014) projects, among others (Koehn, 2009; Huang et al., 2012; Cai et al., 2013; Green et al., 2014; Torregrosa et al., 2014; Azadi and Khadivi, 2015; Marie and Max, 2015). Especially interesting is the so-called prefix-based IMT (Barrachina et al., 2009). In this approach, the user corrected the first wrong word (from left-to-right) of the Interactive-Predictive Translation based on Multiple Word-Segments 283 translation suggested by the system. Then, the system proposed an alternative hypothesis, compatible with the user feedback. A cumbersome phenomenon noticed in this protocol happened when the non-validated part of the sentence"
W16-3415,D15-1120,0,0.295525,"rt and increase efficiency. This paradigm strives for combining the knowledge of a human translator and the efficiency of an MT system. Notable contributions to IMT technology were carried out around the TransType (Foster et al., 1997; Langlais and Lapalme, 2002), TransType2 (Barrachina et al., 2009; Casacuberta et al., 2009); and CasMaCat (Mart´ınez-G´omez et al., 2012; Alabau et al., 2013; Gonz´alez-Rubio et al., 2013; Sanchis-Trilles et al., 2014) projects, among others (Koehn, 2009; Huang et al., 2012; Cai et al., 2013; Green et al., 2014; Torregrosa et al., 2014; Azadi and Khadivi, 2015; Marie and Max, 2015). Especially interesting is the so-called prefix-based IMT (Barrachina et al., 2009). In this approach, the user corrected the first wrong word (from left-to-right) of the Interactive-Predictive Translation based on Multiple Word-Segments 283 translation suggested by the system. Then, the system proposed an alternative hypothesis, compatible with the user feedback. A cumbersome phenomenon noticed in this protocol happened when the non-validated part of the sentence contained correct words. If such words were modified by the system in following predictions, the user had to edit words that were"
W16-3415,P03-1021,0,0.0220698,"e same fashion as with segments, for each word to delete, we align that word with its correspondent source words and generate a new XML tag, indicating that we want to obtain an empty translation. Word correction: each time the user corrects a word or inserts a new one, we align the new word with its correspondent source words using a hidden markov alignment model (Vogel et al., 1996). All the MT systems used in this work were trained with the standard configuration of Moses, with the weights of the log-linear model being optimized by means of the Minimum Error Rate Training (MERT) procedure (Och, 2003). Lastly, a 5-gram wordbased language model was estimated on the target side of the parallel corpora, using the improved KneserNey smoothing (Chen and Goodman, 1996), by means of the SRILM toolkit (Stolcke, 2002). For the implementation of the classic prefix-based IMT systems, we made the word graph exploration and the best suffix generation for a given prefix following the procedure described by Barrachina et al. (2009): We generated a word graph for each sentence to translate. After that, treating the word graph as a weighted finite-state automaton, we parsed the prefix over it, from the ini"
W16-3415,P06-2107,1,0.711673,"Missing"
W16-3415,C96-2141,0,0.175484,"elected by the user, we align the words of that segment with their correspondent source words (phrase alignments), and generate an XML tag to plug in that segment (the desired translation) to those source words. Word deletion: in the same fashion as with segments, for each word to delete, we align that word with its correspondent source words and generate a new XML tag, indicating that we want to obtain an empty translation. Word correction: each time the user corrects a word or inserts a new one, we align the new word with its correspondent source words using a hidden markov alignment model (Vogel et al., 1996). All the MT systems used in this work were trained with the standard configuration of Moses, with the weights of the log-linear model being optimized by means of the Minimum Error Rate Training (MERT) procedure (Och, 2003). Lastly, a 5-gram wordbased language model was estimated on the target side of the parallel corpora, using the improved KneserNey smoothing (Chen and Goodman, 1996), by means of the SRILM toolkit (Stolcke, 2002). For the implementation of the classic prefix-based IMT systems, we made the word graph exploration and the best suffix generation for a given prefix following the"
W16-3415,P07-2045,0,\N,Missing
W17-4714,J09-1002,1,0.0676795,"Missing"
W17-4714,W09-0432,0,0.0175556,"and Manning (2015) tackled the informal speech translation task by starting from a system trained on the WMT data and adapting it to the translation task at hand. In phrase-based statistical machine translation (SMT), synthetic bilingual corpora have been mainly proposed as a mean to exploit the vast amount of monolingual data available. By applying a self-training scheme, the synthetic parallel data can be obtained by automatically translating a source-side monolingual corpus (Ueffing et al., 2007; Wu et al., 2008). Other works used targetside corpora to build the synthetic parallel corpus (Bertoldi and Federico, 2009; Lambert et al., 2011). Inspired by these works in SMT, research referring the inclusion of monolingual data in NMT has a growing interest. Different works have tackled the inclusion of monolingual data, either in source (Zhang and Zong, 2016b) and target language (Gulcehre et al., 2015, 2017). Moreover, Sennrich et al. (2016a) showed that parallel data is not strictly necessary for performing domain adaptation: the usage of synthetic data has positive effects on the NMT system. For obtaining the synthetic data they automatically translated a large monolingual corpus. This syntheticbased appr"
W17-4714,D17-1151,0,0.00475656,"ns obtained by Algorithm 1 for each test set (T ), employed for adapting the NMT system. |S |denotes number of sentences; |W |, number of words; |V |, vocabulary size and |W |, average sentence length. For all results, we computed their confidence intervals (p = 0.05) by means of bootstrap resampling (Koehn, 2004). 5.3 T Machine translation systems We used NMT-Keras (Peris, 2017) for building the NMT system, as described in Section 2. We applied joint byte pair encoding (BPE) (Sennrich et al., 2016b), learning 32, 000 merge operations, on the out-of-domain dataset. Following the findings from Britz et al. (2017), we used LSTM units. Due to practical reasons, we used single-layered LSTMs. The LSTM, word embedding and attention MLP sizes were 512 each. We applied layer normalization (Ba et al., 2016) and Gaussian noise (σ = 0.01) to the weights (Graves, 2011). We clipped the L2 norm of the gradients to 1 (Pascanu et al., 2012). We used Adam (Kingma and Ba, 2014) with a learning rate of 0.0002 (Wu et al., 2016). The size of the beam was set to 6. XRCE – Test EN ES IT – Test E-Com – Test 5.4 |S| |W | |V | |W | 180k 2.2M 1.7M 54k 58k 9.4 12.2 EN ES 150k 2.5M 3.0M 76k 78k 16.7 20.0 EN ES 300k 3.2M 4.1M 100"
W17-4714,P82-1020,0,0.837049,"Missing"
W17-4714,D13-1176,0,0.0238259,"hetic parallel data have been widely used to boost the translation quality of NMT. In this work, we further extend their application by adapting NMT models with synthetic parallel data. In certain language pairs or domains where parallel corpora are scarce or even non-existent, a model adjusted with synthetic data can improve the performance with respect to a more general model. The core idea is that, once a model has been trained on a large, general corpus, we can adapt it to a new domain, by fine-tuning it exclusively using the synthetic data. For doing this, we create an Related work Since Kalchbrenner and Blunsom (2013), Sutskever et al. (2014) and Cho et al. (2014b) proposed the first NMT systems, this has been a boiling research topic. A singular effort has been spent into leverage the advantages that this technology brings in. One of them is the ability of NMT systems to rapidly adapt to a 139 General NMT Pool-Monolingual y1 Best-Monolingual Selecting Synthetic Translating y2 ... y|y| Decoder Adapting Encoder x1 x2 ... x|x| Source-Test True sentence Synthetic sentence Figure 1: The process of building an adequate synthetic parallel corpus for a given test set. (Mikolov et al., 2013a) to generate represent"
W17-4714,P16-1185,0,0.140639,"Missing"
W17-4714,W14-4012,0,0.142352,"Missing"
W17-4714,W04-3250,0,0.154615,"t, with a penalty for sentences that are too short. • TER (Translation Error Rate) (Snover et al., 2006), is an error metric that computes the minimum number of edits (including swaps) required to modify the system hypotheses so that they match the reference. Table 2: Main figures of the selections obtained by Algorithm 1 for each test set (T ), employed for adapting the NMT system. |S |denotes number of sentences; |W |, number of words; |V |, vocabulary size and |W |, average sentence length. For all results, we computed their confidence intervals (p = 0.05) by means of bootstrap resampling (Koehn, 2004). 5.3 T Machine translation systems We used NMT-Keras (Peris, 2017) for building the NMT system, as described in Section 2. We applied joint byte pair encoding (BPE) (Sennrich et al., 2016b), learning 32, 000 merge operations, on the out-of-domain dataset. Following the findings from Britz et al. (2017), we used LSTM units. Due to practical reasons, we used single-layered LSTMs. The LSTM, word embedding and attention MLP sizes were 512 each. We applied layer normalization (Ba et al., 2016) and Gaussian noise (σ = 0.01) to the weights (Graves, 2011). We clipped the L2 norm of the gradients to 1"
W17-4714,P07-2045,0,0.03931,"ion, we also noticed that the application of more sophisticated SGD optimizers (e.g. Adam) is tricky, as they update the model on a more aggressive way. Therefore, if we apply excessively large updates, the knowledge from the general model is somehow lost. We also tested our method with ensembles of NMT systems. Ensembles were made up of 4 models sampled at different points of the training process. Such points were evenly chosen (each 2, 000 updates) around the single model which obtained the highest performance on the development set. Finally, we used Moses toolkit as phrase-based reference (Koehn et al., 2007). We used a 5gram language model with modified Kneser-Ney smoothing (Kneser and Ney, 1995), built with the SRILM toolkit (Stolcke, 2002). The phrase table was generated employing symmetrised word alignments obtained with GIZA++ (Och and Ney, 2003). The log-lineal combination weights were optimized using MERT (Minimum Error Rate Training) (Och, 2003). 26.4 Evaluation Translation quality was assessed according to the following well-known metrics: • BLEU (BiLingual Evaluation Understudy) (Papineni et al., 2002), measures n-gram precision with respect to a reference set, with a penalty for sentenc"
W17-4714,W11-2132,0,0.0431045,"he informal speech translation task by starting from a system trained on the WMT data and adapting it to the translation task at hand. In phrase-based statistical machine translation (SMT), synthetic bilingual corpora have been mainly proposed as a mean to exploit the vast amount of monolingual data available. By applying a self-training scheme, the synthetic parallel data can be obtained by automatically translating a source-side monolingual corpus (Ueffing et al., 2007; Wu et al., 2008). Other works used targetside corpora to build the synthetic parallel corpus (Bertoldi and Federico, 2009; Lambert et al., 2011). Inspired by these works in SMT, research referring the inclusion of monolingual data in NMT has a growing interest. Different works have tackled the inclusion of monolingual data, either in source (Zhang and Zong, 2016b) and target language (Gulcehre et al., 2015, 2017). Moreover, Sennrich et al. (2016a) showed that parallel data is not strictly necessary for performing domain adaptation: the usage of synthetic data has positive effects on the NMT system. For obtaining the synthetic data they automatically translated a large monolingual corpus. This syntheticbased approach obtained better re"
W17-4714,2015.iwslt-evaluation.11,0,0.0329967,"thod and we describe the adaptation pipeline. Section 5 presents the experimental set-up and corpora. Results are analyzed and discussed in Section 6. Finally, conclusions and future work are traced in Section 7. 138 Proceedings of the Conference on Machine Translation (WMT), Volume 1: Research Papers, pages 138–147 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics 2 Neural Machine Translation given domain, when they are already trained on a general domain. This is useful either for creating domain-dependent NMT systems or for low-resource tasks. Thus, Luong and Manning (2015) tackled the informal speech translation task by starting from a system trained on the WMT data and adapting it to the translation task at hand. In phrase-based statistical machine translation (SMT), synthetic bilingual corpora have been mainly proposed as a mean to exploit the vast amount of monolingual data available. By applying a self-training scheme, the synthetic parallel data can be obtained by automatically translating a source-side monolingual corpus (Ueffing et al., 2007; Wu et al., 2008). Other works used targetside corpora to build the synthetic parallel corpus (Bertoldi and Federi"
W17-4714,P03-1021,0,0.0706764,"Missing"
W17-4714,P07-1004,0,0.0225033,"neral domain. This is useful either for creating domain-dependent NMT systems or for low-resource tasks. Thus, Luong and Manning (2015) tackled the informal speech translation task by starting from a system trained on the WMT data and adapting it to the translation task at hand. In phrase-based statistical machine translation (SMT), synthetic bilingual corpora have been mainly proposed as a mean to exploit the vast amount of monolingual data available. By applying a self-training scheme, the synthetic parallel data can be obtained by automatically translating a source-side monolingual corpus (Ueffing et al., 2007; Wu et al., 2008). Other works used targetside corpora to build the synthetic parallel corpus (Bertoldi and Federico, 2009; Lambert et al., 2011). Inspired by these works in SMT, research referring the inclusion of monolingual data in NMT has a growing interest. Different works have tackled the inclusion of monolingual data, either in source (Zhang and Zong, 2016b) and target language (Gulcehre et al., 2015, 2017). Moreover, Sennrich et al. (2016a) showed that parallel data is not strictly necessary for performing domain adaptation: the usage of synthetic data has positive effects on the NMT"
W17-4714,J03-1002,0,0.031516,"ow lost. We also tested our method with ensembles of NMT systems. Ensembles were made up of 4 models sampled at different points of the training process. Such points were evenly chosen (each 2, 000 updates) around the single model which obtained the highest performance on the development set. Finally, we used Moses toolkit as phrase-based reference (Koehn et al., 2007). We used a 5gram language model with modified Kneser-Ney smoothing (Kneser and Ney, 1995), built with the SRILM toolkit (Stolcke, 2002). The phrase table was generated employing symmetrised word alignments obtained with GIZA++ (Och and Ney, 2003). The log-lineal combination weights were optimized using MERT (Minimum Error Rate Training) (Och, 2003). 26.4 Evaluation Translation quality was assessed according to the following well-known metrics: • BLEU (BiLingual Evaluation Understudy) (Papineni et al., 2002), measures n-gram precision with respect to a reference set, with a penalty for sentences that are too short. • TER (Translation Error Rate) (Snover et al., 2006), is an error metric that computes the minimum number of edits (including swaps) required to modify the system hypotheses so that they match the reference. Table 2: Main fi"
W17-4714,C08-1125,0,0.0273962,"Missing"
W17-4714,P02-1040,0,0.110426,"Missing"
W17-4714,D16-1160,0,0.160762,"e been mainly proposed as a mean to exploit the vast amount of monolingual data available. By applying a self-training scheme, the synthetic parallel data can be obtained by automatically translating a source-side monolingual corpus (Ueffing et al., 2007; Wu et al., 2008). Other works used targetside corpora to build the synthetic parallel corpus (Bertoldi and Federico, 2009; Lambert et al., 2011). Inspired by these works in SMT, research referring the inclusion of monolingual data in NMT has a growing interest. Different works have tackled the inclusion of monolingual data, either in source (Zhang and Zong, 2016b) and target language (Gulcehre et al., 2015, 2017). Moreover, Sennrich et al. (2016a) showed that parallel data is not strictly necessary for performing domain adaptation: the usage of synthetic data has positive effects on the NMT system. For obtaining the synthetic data they automatically translated a large monolingual corpus. This syntheticbased approach obtained better results than other methods aimed to exploit monolingual data (e.g. Gulcehre et al. (2015)). Domain adaptation in NMT systems is also integrated in commercial systems, such as SYSTRAN (Crego et al., 2016). Neural machine tr"
W17-4714,P16-1009,0,0.382973,"wellstudied corpora. Then, we evaluated our proposal on a real e-commerce task, yielding consistent improvements in terms of translation quality. 1 • We describe the pipeline of our adaptation process, relating the selection, translation and fine-tuning processes. Introduction • We study our adaptation technique on two classical domains. Additionally, we validate our technique on a real e-commerce translation task. Neural machine translation (NMT) (Sutskever et al., 2014; Cho et al., 2014a; Bahdanau et al., 2015) has obtained state-of-the art performance in several domains and language pairs (Sennrich et al., 2016b; Wu et al., 2016). Given the nature of NMT paradigms, the limitation for obtaining bilingual corpora—or their availability—has been one of the major obstacles faced when building competitive NMT systems. Recently, the idea of using synthetic corpora in NMT has reported promising results with regard to the data scarcity in NMT. Many different works demonstrated that the combination of real parallel corpora with synthetic bilingual corpus enhances the NMT trans• Results show important improvements over a baseline system. This paper is structured as follows. NMT technology is briefly described"
W17-4714,P16-1162,0,0.285395,"wellstudied corpora. Then, we evaluated our proposal on a real e-commerce task, yielding consistent improvements in terms of translation quality. 1 • We describe the pipeline of our adaptation process, relating the selection, translation and fine-tuning processes. Introduction • We study our adaptation technique on two classical domains. Additionally, we validate our technique on a real e-commerce translation task. Neural machine translation (NMT) (Sutskever et al., 2014; Cho et al., 2014a; Bahdanau et al., 2015) has obtained state-of-the art performance in several domains and language pairs (Sennrich et al., 2016b; Wu et al., 2016). Given the nature of NMT paradigms, the limitation for obtaining bilingual corpora—or their availability—has been one of the major obstacles faced when building competitive NMT systems. Recently, the idea of using synthetic corpora in NMT has reported promising results with regard to the data scarcity in NMT. Many different works demonstrated that the combination of real parallel corpora with synthetic bilingual corpus enhances the NMT trans• Results show important improvements over a baseline system. This paper is structured as follows. NMT technology is briefly described"
W17-4714,2006.amta-papers.25,0,0.0713479,"ey smoothing (Kneser and Ney, 1995), built with the SRILM toolkit (Stolcke, 2002). The phrase table was generated employing symmetrised word alignments obtained with GIZA++ (Och and Ney, 2003). The log-lineal combination weights were optimized using MERT (Minimum Error Rate Training) (Och, 2003). 26.4 Evaluation Translation quality was assessed according to the following well-known metrics: • BLEU (BiLingual Evaluation Understudy) (Papineni et al., 2002), measures n-gram precision with respect to a reference set, with a penalty for sentences that are too short. • TER (Translation Error Rate) (Snover et al., 2006), is an error metric that computes the minimum number of edits (including swaps) required to modify the system hypotheses so that they match the reference. Table 2: Main figures of the selections obtained by Algorithm 1 for each test set (T ), employed for adapting the NMT system. |S |denotes number of sentences; |W |, number of words; |V |, vocabulary size and |W |, average sentence length. For all results, we computed their confidence intervals (p = 0.05) by means of bootstrap resampling (Koehn, 2004). 5.3 T Machine translation systems We used NMT-Keras (Peris, 2017) for building the NMT sys"
W19-5439,D19-1632,0,0.0280441,"Missing"
W19-5439,P07-2045,0,0.0113789,"195 196 197 198 199 ACL 2019 Submission ***. Confidential Review Copy. DO NOT DISTRIBUTE. 200 201 202 203 204 205 Table 4: Main figures of the monolingual (mono.) data for Hindi and bilingual data for Hindi–English (hi–en). k denotes thousands of elements and M denotes millions of elements. |S |stands for number of sentences, |W |for number of running words, and |V |for vocabulary size. Figures computed on tokenised and lowercased corpora. 2.3 As specified in the shared task, the evaluation of a selected subset of sentences is done using SMT and NMT. The SMT system is implemented using Moses (Koehn et al., 2007) and the NMT system is built using the FAIRseq (Ott et al., 2019) toolkit. Organisers provided scripts which allow for implementing the same translation system which will be used in the final evaluation. However, we only conducted experiments using NMT. The FAIRseq system tokenises source and target sentences and applies BPE (Sennrich et al., 2016). The tokenisation of Nepali, Sinhala and Hindi sentences is done using the Indic NLP Library3 . The system (Guzm´an et al., 2019) uses a Transformer architecture with 5 encoder and 5 decoder layers, where the number of attention heads, embedding dim"
W19-5439,D11-1033,0,0.0725313,"d on hypothesis and target sentence similarity. This technique consists of building the best possible translation engine for each language pair and generating a translation hypothesis for each sentence of the noisy data. Once the hypotheses are generated, we compute the BLEU (Papineni et al., 2002), smoothed by adding one to both numerator and denominator from (Lin and Och, 2004), between each target and hypothesis. To create a translation engine, which will be used for generating hypothesis for each sentence from noisy corpus, we select sentence pairs using bilingual cross-entropy selection (Axelrod et al., 2011) from all parallel corpora provided (Nepali, Sinhala, Hindi to English) jointly. To apply bilingual cross-entropy, we first train language models using the provided monolingual corpora in Nepali, Sinhala and English. In addition, we use some rules to discard useless sentences by filtering according to sentence length, Nepali and Sinhala characters detection, and BLEU scoring between source and target sentences. The last rule is used to discard highly similar sentence pairs. The paper is structured as follows: Section 2 describes the shared task, the provided data, the subsampling process and t"
W19-5439,N19-4009,0,0.0230734,"py. DO NOT DISTRIBUTE. 200 201 202 203 204 205 Table 4: Main figures of the monolingual (mono.) data for Hindi and bilingual data for Hindi–English (hi–en). k denotes thousands of elements and M denotes millions of elements. |S |stands for number of sentences, |W |for number of running words, and |V |for vocabulary size. Figures computed on tokenised and lowercased corpora. 2.3 As specified in the shared task, the evaluation of a selected subset of sentences is done using SMT and NMT. The SMT system is implemented using Moses (Koehn et al., 2007) and the NMT system is built using the FAIRseq (Ott et al., 2019) toolkit. Organisers provided scripts which allow for implementing the same translation system which will be used in the final evaluation. However, we only conducted experiments using NMT. The FAIRseq system tokenises source and target sentences and applies BPE (Sennrich et al., 2016). The tokenisation of Nepali, Sinhala and Hindi sentences is done using the Indic NLP Library3 . The system (Guzm´an et al., 2019) uses a Transformer architecture with 5 encoder and 5 decoder layers, where the number of attention heads, embedding dimension and inner-layer dimension are 2, 512 and 2048, respectivel"
W19-5439,P02-1040,0,0.105457,"es 004 005 006 007 053 054 055 056 057 008 058 009 059 010 060 011 Abstract 012 the creation of systems for filtering of noisy parallel corpora are needed. In this paper, we introduce a filtering method for noisy parallel corpora based mainly on generating hypotheses for each sentence pair from noisy data and scoring based on hypothesis and target sentence similarity. This technique consists of building the best possible translation engine for each language pair and generating a translation hypothesis for each sentence of the noisy data. Once the hypotheses are generated, we compute the BLEU (Papineni et al., 2002), smoothed by adding one to both numerator and denominator from (Lin and Och, 2004), between each target and hypothesis. To create a translation engine, which will be used for generating hypothesis for each sentence from noisy corpus, we select sentence pairs using bilingual cross-entropy selection (Axelrod et al., 2011) from all parallel corpora provided (Nepali, Sinhala, Hindi to English) jointly. To apply bilingual cross-entropy, we first train language models using the provided monolingual corpora in Nepali, Sinhala and English. In addition, we use some rules to discard useless sentences b"
W19-5439,W18-6319,0,0.0227455,"res will be used to subsample sentence pairs into two different training set sizes: 1 million and 5 million English words. For this task, very noisy corpora of 40.6 million English words in Nepali–English and 59.6 million English words in Sinhala–English are provided. The data were crawled from the web as part of the Paracrawl project2 . The quality of the resulting subsets is determined by the quality of a statistical machine translation (SMT) and neural machine translation (NMT) systems trained on this data. The quality of the machine translation system is measured with the sacreBLEU score (Post, 2018) on a heldout test set of Wikipedia translations for NepaliEnglish (ne–en) and Sinhala-English (si–en). The organisers provide development and test sets for each pair of languages but due to the fact that the task addresses the challenge of data quality and not domain-relatedness of the data for a particular use case, the test sets may be very different from the final official test set in terms of topics. 2.1 150 151 152 153 154 155 156 corpus language ne–en Nepali English si–en Sinhala English |S| |W | |V | 157 52.3M 56.0M 925.3k 782.9k 158 2.2M 3.6M 61.2M 62.6M 822.6k 803.0k 159 160 161 162"
W19-5439,P16-1162,0,0.00876654,"unning words, and |V |for vocabulary size. Figures computed on tokenised and lowercased corpora. 2.3 As specified in the shared task, the evaluation of a selected subset of sentences is done using SMT and NMT. The SMT system is implemented using Moses (Koehn et al., 2007) and the NMT system is built using the FAIRseq (Ott et al., 2019) toolkit. Organisers provided scripts which allow for implementing the same translation system which will be used in the final evaluation. However, we only conducted experiments using NMT. The FAIRseq system tokenises source and target sentences and applies BPE (Sennrich et al., 2016). The tokenisation of Nepali, Sinhala and Hindi sentences is done using the Indic NLP Library3 . The system (Guzm´an et al., 2019) uses a Transformer architecture with 5 encoder and 5 decoder layers, where the number of attention heads, embedding dimension and inner-layer dimension are 2, 512 and 2048, respectively. The model is regularised with dropout, label smoothing and weight decay. The model is optimised with Adam (Kingma and Ba, 2014) using β1 = 0.9, β2 = 0.98, and  = 1e − 8. The learning rate is fixed to lr = 1e3, as described in (Ott et al., 2019). The NMT system from the shared task"
W19-6737,aziz-etal-2012-pet,0,0.0348282,"der laboratory conditions. Next, we conduct the evaluation of the system on a production environment. This experiment involved professional translators, who regularly rely on MT post-editing in their workflow. The results show improvements of adaptive systems in terms of productivity and translation quality. 2 Related work Translation post-editing has been a widely adopted practice in the industry for a long time (e.g., Vasconcellos and Le´on, 1985). As MT technology advanced and improved, the post-editing process gained more relevance and many user studies have demonstrated its capabilities (Aziz et al., 2012; Bentivogli et al., 2016; Castilho et al., 2017; Green et al., 2013a). Adapting an MT system from user post-edits via Dublin, Aug. 19-23, 2019 |p. 219 online learning techniques has also attracted the attention of researchers and industry parallel to the rise of the post-editing protocol. Many advances in this direction were achieved during the CasMaCat (Alabau et al., 2013) and MateCat (Federico et al., 2014) projects, which adapted phrase-based statistical machine translation systems incrementally from user post-edits. Following recent breakthroughs in NMT technology, some works studied the"
W19-6737,J90-2002,0,0.893446,"013b). Regarding the NMT technology, several user studies have been recently conducted, analyzing different MT technologies (Koponen et al., 2019; Jia et al., 2019) or protocols (Daems and Macken, 2019). The closest work to ours was developed by Karimova et al. (2018), who showed savings in human effort, due to the effect of online learning. But in contrast to our work, the individuals used in Karimova et al. (2018) were students, whereas we conducted the study using professional, experienced translators. 3 Online learning from NMT post-edits NMT relies on the statistical formalization of MT (Brown et al., 1990). The goal is to obtain, given a ˆ: source sentence x, its most likely translation y ˆ = arg max Pr(y |x) y y (1) This probability is directly modeled by a neural network with parameters Θ: ˆ = arg max log p(y |x; Θ) y y (2) Proceedings of MT Summit XVII, volume 2 This neural network usually follows an encoder– decoder architecture, featuring recurrent (Bahdanau et al., 2015; Sutskever et al., 2014) or convolutional networks (Gehring et al., 2017) or attention mechanisms (Vaswani et al., 2017). The parameters of the model are typically estimated jointly on large parallel corpora, via stochasti"
W19-6737,W14-3346,0,0.0640727,"ied the FDA data selection technique (Bic¸ici and Yuret, 2015) for selecting related instances from our general corpus and a medical (UFAL, Bojar et al., 2017) and technological2 ones. We selected 8 million additional segments, which were used for fine-tuning the general system. The effects of adaptivity were assessed according to the post-editing time and to two common MT metrics: (h)BLEU (Papineni et al., 2002) and (h)TER (Snover et al., 2006). For ensuring consistent BLEU scores, we used sacreBLEU (Post, 2018). Since we computed per-sentence BLEU scores, we used exponential BLEU smoothing (Chen and Cherry, 2014). In order to determine whether two systems presented statistically significant differences, we applied approximate randomization tests (Riezler and Maxwell, 2005), with 10, 000 repetitions and a p-value of 0.05. 5 Results As introduced in the previous section, we first analyzed the adaptation process in a simulated environment. Next, we studied and discussed the results obtained in the user trials. 5.1 Adaptation with simulated users Table 1 shows the results in terms of translation quality of a static system, compared with an adaptive one, updated using the reference samples. The results obt"
W19-6737,E14-1042,0,0.111546,"MT system with post-edited samples to a new domain via online learning. Other works aimed to refine these adaptation techniques: Wuebker et al. (2018) applied sparse updates; Kothur et al. (2018) introduced a dictionary of translations for dealing with the novel words included in the new domain. However, in all these works, the users were simulated, due to the economical costs of involving humans within experiments. User studies on online adaptation from postedits have been conducted, mainly for phrasebased statistical machine translation systems (Alabau et al., 2016; Bentivogli et al., 2016; Denkowski et al., 2014; Green et al., 2013b). Regarding the NMT technology, several user studies have been recently conducted, analyzing different MT technologies (Koponen et al., 2019; Jia et al., 2019) or protocols (Daems and Macken, 2019). The closest work to ours was developed by Karimova et al. (2018), who showed savings in human effort, due to the effect of online learning. But in contrast to our work, the individuals used in Karimova et al. (2018) were students, whereas we conducted the study using professional, experienced translators. 3 Online learning from NMT post-edits NMT relies on the statistical form"
W19-6737,C14-2028,0,0.212791,"ng time (e.g., Vasconcellos and Le´on, 1985). As MT technology advanced and improved, the post-editing process gained more relevance and many user studies have demonstrated its capabilities (Aziz et al., 2012; Bentivogli et al., 2016; Castilho et al., 2017; Green et al., 2013a). Adapting an MT system from user post-edits via Dublin, Aug. 19-23, 2019 |p. 219 online learning techniques has also attracted the attention of researchers and industry parallel to the rise of the post-editing protocol. Many advances in this direction were achieved during the CasMaCat (Alabau et al., 2013) and MateCat (Federico et al., 2014) projects, which adapted phrase-based statistical machine translation systems incrementally from user post-edits. Following recent breakthroughs in NMT technology, some works studied the construction of adaptive systems via online learning in this postediting scenario. Turchi et al. (2017) and Peris et al. (2017) proposed to adapt an NMT system with post-edited samples to a new domain via online learning. Other works aimed to refine these adaptation techniques: Wuebker et al. (2018) applied sparse updates; Kothur et al. (2018) introduced a dictionary of translations for dealing with the novel"
W19-6737,D18-1397,0,0.0668023,"over, we want to integrate our adaptive systems together with other translation tools, such as translation memories or terminological dictionaries, with the aim of fostering the productivity of the post-editing process. With this feature-rich system, we would like to conduct additional experiments involving more diverse languages and domains, using domain-specialized NMT systems, testing other models (e.g., Transformer, Vaswani et al., 2017) and involving a larger number of professional post-editors. Finally, we also intend to implement the interactive–predictive machine translation protocol (Lam et al., 2018; Peris and Casacuberta, 2019) in our translation environment, and compare it with the regular postediting process. Dublin, Aug. 19-23, 2019 |p. 224 Acknowledgements The research leading to these results has received funding from the Spanish Centre for Technological and Industrial Development (Centro para el Desarrollo Tecnol´ogico Industrial) (CDTI) and the European Union through Programa Operativo de Crecimiento Inteligente (Project IDI-20170964). We gratefully acknowledge the support of NVIDIA Corporation with the donation of a GPU used for part of this research, and the translators and pro"
W19-6737,J16-1004,0,0.23795,"Missing"
W19-6737,W16-3420,0,0.16847,"ed amount of human effort needed when post-editing the outputs of the system, improvements in the translation quality and a positive perception of the adaptive system by the users. 1 Introduction Translation post-editing is a common use case of machine translation (MT) in the industrial environment. Post-editing consists of the supervision by a human agent of outputs generated by an MT system, who corrects the errors made by the MT system. As MT systems are continuously improving their capabilities, translation post-editing has acquired major relevance in the translation market (Arenas, 2008; Hu and Cadwell, 2016). As a byproduct of this process, new data are continuously generated. These data have valuable properties: they are domain-specific training samples, c 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 2 which can be leveraged for adapting the system towards a given domain or post-editor. Moreover, an adaptive system can learn from its mistakes. In other words, it can avoid making the same errors again. A typical way of profiting from these post-edits consists in updating the system"
W19-6737,P02-1040,0,0.110096,"Spanish. Since we lacked an in-domain corpus, we trained a general system with the data from the translation task from WMT’13 (Bojar et al., 2013), consisting in 15 million parallel segments. Next, we applied the FDA data selection technique (Bic¸ici and Yuret, 2015) for selecting related instances from our general corpus and a medical (UFAL, Bojar et al., 2017) and technological2 ones. We selected 8 million additional segments, which were used for fine-tuning the general system. The effects of adaptivity were assessed according to the post-editing time and to two common MT metrics: (h)BLEU (Papineni et al., 2002) and (h)TER (Snover et al., 2006). For ensuring consistent BLEU scores, we used sacreBLEU (Post, 2018). Since we computed per-sentence BLEU scores, we used exponential BLEU smoothing (Chen and Cherry, 2014). In order to determine whether two systems presented statistically significant differences, we applied approximate randomization tests (Riezler and Maxwell, 2005), with 10, 000 repetitions and a p-value of 0.05. 5 Results As introduced in the previous section, we first analyzed the adaptation process in a simulated environment. Next, we studied and discussed the results obtained in the user"
W19-6737,W18-6319,0,0.0157913,"k from WMT’13 (Bojar et al., 2013), consisting in 15 million parallel segments. Next, we applied the FDA data selection technique (Bic¸ici and Yuret, 2015) for selecting related instances from our general corpus and a medical (UFAL, Bojar et al., 2017) and technological2 ones. We selected 8 million additional segments, which were used for fine-tuning the general system. The effects of adaptivity were assessed according to the post-editing time and to two common MT metrics: (h)BLEU (Papineni et al., 2002) and (h)TER (Snover et al., 2006). For ensuring consistent BLEU scores, we used sacreBLEU (Post, 2018). Since we computed per-sentence BLEU scores, we used exponential BLEU smoothing (Chen and Cherry, 2014). In order to determine whether two systems presented statistically significant differences, we applied approximate randomization tests (Riezler and Maxwell, 2005), with 10, 000 repetitions and a p-value of 0.05. 5 Results As introduced in the previous section, we first analyzed the adaptation process in a simulated environment. Next, we studied and discussed the results obtained in the user trials. 5.1 Adaptation with simulated users Table 1 shows the results in terms of translation quality"
W19-6737,W05-0908,0,0.119435,"and technological2 ones. We selected 8 million additional segments, which were used for fine-tuning the general system. The effects of adaptivity were assessed according to the post-editing time and to two common MT metrics: (h)BLEU (Papineni et al., 2002) and (h)TER (Snover et al., 2006). For ensuring consistent BLEU scores, we used sacreBLEU (Post, 2018). Since we computed per-sentence BLEU scores, we used exponential BLEU smoothing (Chen and Cherry, 2014). In order to determine whether two systems presented statistically significant differences, we applied approximate randomization tests (Riezler and Maxwell, 2005), with 10, 000 repetitions and a p-value of 0.05. 5 Results As introduced in the previous section, we first analyzed the adaptation process in a simulated environment. Next, we studied and discussed the results obtained in the user trials. 5.1 Adaptation with simulated users Table 1 shows the results in terms of translation quality of a static system, compared with an adaptive one, updated using the reference samples. The results obtained on this synthetic setup support the usefulness of the adaptation via online learning: in all cases, the adaptive system achieved better TER and BLEU than the"
W19-6737,P13-1031,0,0.501163,"ystem on a production environment. This experiment involved professional translators, who regularly rely on MT post-editing in their workflow. The results show improvements of adaptive systems in terms of productivity and translation quality. 2 Related work Translation post-editing has been a widely adopted practice in the industry for a long time (e.g., Vasconcellos and Le´on, 1985). As MT technology advanced and improved, the post-editing process gained more relevance and many user studies have demonstrated its capabilities (Aziz et al., 2012; Bentivogli et al., 2016; Castilho et al., 2017; Green et al., 2013a). Adapting an MT system from user post-edits via Dublin, Aug. 19-23, 2019 |p. 219 online learning techniques has also attracted the attention of researchers and industry parallel to the rise of the post-editing protocol. Many advances in this direction were achieved during the CasMaCat (Alabau et al., 2013) and MateCat (Federico et al., 2014) projects, which adapted phrase-based statistical machine translation systems incrementally from user post-edits. Following recent breakthroughs in NMT technology, some works studied the construction of adaptive systems via online learning in this posted"
W19-6737,P17-4012,0,0.0592815,"yn ← Post-edit(xn , y Θn+1 ← Update((xn , yn ), Θn ) n←n+1 Algorithm 1: Adaptation via online learning during NMT post-editing. This adaptation of the NMT model can be performed following the same method used in regular training: SGD. 4 Experimental framework We now describe the experimental conditions arranged in our study: the translation systems and environment, the main features of the tasks under study and the evaluation criteria considered. 4.1 NMT systems Our NMT system was a recurrent encoder–decoder with an additive attention mechanism (Bahdanau et al., 2015), built with OpenNMT-py (Klein et al., 2017). We used long short-term memory units Dublin, Aug. 19-23, 2019 |p. 220 (Gers et al., 2000) and we set all model dimensions to 512. The system was trained using Adam (Kingma and Ba, 2014) with a fixed learning rate of 0.0002 (Wu et al., 2016) and a batch size of 60. We applied label smoothing of 0.1 (Szegedy et al., 2015). At the inference time, we used a beam search with a beam size of 6. We applied joint byte pair encoding to all corpora (Sennrich et al., 2016), using 32, 000 merge operations. The adaptive systems were built considering the findings from Peris and Casacuberta (2019), and con"
W19-6737,P16-1162,0,0.158084,"Missing"
W19-6737,W18-2708,0,0.076491,"e achieved during the CasMaCat (Alabau et al., 2013) and MateCat (Federico et al., 2014) projects, which adapted phrase-based statistical machine translation systems incrementally from user post-edits. Following recent breakthroughs in NMT technology, some works studied the construction of adaptive systems via online learning in this postediting scenario. Turchi et al. (2017) and Peris et al. (2017) proposed to adapt an NMT system with post-edited samples to a new domain via online learning. Other works aimed to refine these adaptation techniques: Wuebker et al. (2018) applied sparse updates; Kothur et al. (2018) introduced a dictionary of translations for dealing with the novel words included in the new domain. However, in all these works, the users were simulated, due to the economical costs of involving humans within experiments. User studies on online adaptation from postedits have been conducted, mainly for phrasebased statistical machine translation systems (Alabau et al., 2016; Bentivogli et al., 2016; Denkowski et al., 2014; Green et al., 2013b). Regarding the NMT technology, several user studies have been recently conducted, analyzing different MT technologies (Koponen et al., 2019; Jia et al"
W19-6737,2006.amta-papers.25,0,0.124927,"ain corpus, we trained a general system with the data from the translation task from WMT’13 (Bojar et al., 2013), consisting in 15 million parallel segments. Next, we applied the FDA data selection technique (Bic¸ici and Yuret, 2015) for selecting related instances from our general corpus and a medical (UFAL, Bojar et al., 2017) and technological2 ones. We selected 8 million additional segments, which were used for fine-tuning the general system. The effects of adaptivity were assessed according to the post-editing time and to two common MT metrics: (h)BLEU (Papineni et al., 2002) and (h)TER (Snover et al., 2006). For ensuring consistent BLEU scores, we used sacreBLEU (Post, 2018). Since we computed per-sentence BLEU scores, we used exponential BLEU smoothing (Chen and Cherry, 2014). In order to determine whether two systems presented statistically significant differences, we applied approximate randomization tests (Riezler and Maxwell, 2005), with 10, 000 repetitions and a p-value of 0.05. 5 Results As introduced in the previous section, we first analyzed the adaptation process in a simulated environment. Next, we studied and discussed the results obtained in the user trials. 5.1 Adaptation with simu"
W19-6737,J85-2003,0,0.844192,"Missing"
W19-6737,D18-1104,0,0.12434,"Missing"
W19-6737,2012.eamt-1.31,0,\N,Missing
W19-6737,2012.tc-1.5,0,\N,Missing
