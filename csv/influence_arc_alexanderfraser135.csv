2009.mtsummit-posters.11,J93-2003,0,0.0297587,"tter than symmetrized IBM Model 1 in terms of alignment quality and that it supports trading off precision against recall. 1 Introduction Word alignment, the task of establishing correspondences between words in a bitext (i.e., a sentencealigned parallel corpus), is an important problem with applications in statistical machine translation, the automatic generation of bilingual dictionaries and cross-language information retrieval. According to Och and Ney (2003), there are two general approaches to computing word alignments: statistical and heuristic methods. In statistical alignment methods (Brown et al., 1993), P r (T |S) is written in terms of the conditional probability P r (T, a|S) as: X P r (T |S) = P r (T, a|S) (1) a Here, the alignment a describes a mapping from the positions of the words in the source text S to the positions in the target text T . The heuristic methods are considerably simpler. Generally speaking, they try to align each word according to the associative information of sourcetarget word pairs. This information can be provided using different methods. As our baseline method, we define a simple heuristic model and call it maximum linking. For a given target word tj , maximum li"
2009.mtsummit-posters.11,D07-1006,1,0.87953,"ng and as accurate or more accurate than IBM Model 1, the current method of choice for initializing training of statistical machine translation models. • 2D-Linking can align m-to-n units, unlike the IBM models which can only align 1-to-n units. • 2D-Linking can easily trade off precision vs. recall in word alignment. This is important for many applications of word alignment, in particular for cross-language information retrieval (which in many scenarios requires high precision of word alignments, (Kraaij, 2004)) and machine translation (which usually requires high recall in word alignments, (Fraser and Marcu, 2007b)). This paper is organized as follows. Related work is discussed in Section 2. Section 3 discusses the three association scores we investigate in this paper: the Dice coefficient, expected mutual information and pointwise mutual information. In Section 4, we describe the 2D-Linking algorithm. Sections 5 and 6 present our evaluation results and conclusions. 2 Related Work Statistical alignment models depend on a set of unknown parameters that must be learned from training data. IBM Model 1 is a particularly simple instance of the framework presented in Equation 1. This model assumes a uniform"
2009.mtsummit-posters.11,J07-3002,1,0.908704,"ng and as accurate or more accurate than IBM Model 1, the current method of choice for initializing training of statistical machine translation models. • 2D-Linking can align m-to-n units, unlike the IBM models which can only align 1-to-n units. • 2D-Linking can easily trade off precision vs. recall in word alignment. This is important for many applications of word alignment, in particular for cross-language information retrieval (which in many scenarios requires high precision of word alignments, (Kraaij, 2004)) and machine translation (which usually requires high recall in word alignments, (Fraser and Marcu, 2007b)). This paper is organized as follows. Related work is discussed in Section 2. Section 3 discusses the three association scores we investigate in this paper: the Dice coefficient, expected mutual information and pointwise mutual information. In Section 4, we describe the 2D-Linking algorithm. Sections 5 and 6 present our evaluation results and conclusions. 2 Related Work Statistical alignment models depend on a set of unknown parameters that must be learned from training data. IBM Model 1 is a particularly simple instance of the framework presented in Equation 1. This model assumes a uniform"
2009.mtsummit-posters.11,P04-1064,0,0.018845,"not have m-to-n links. However it is possible to improve the model. Moore (2004) introduced an improvement of IBM Model 1 that tries to control the trade-off between precision and recall by adding additional null words to the source sentence. Like Model 1, Moore’s model requires several passes through the data (whereas 2D-Linking only needs two) and cannot model m-to-n links. There are also some more advanced unsupervised models such as the HMM word alignment model (Vogel et al., 1996), IBM Model 4 (Brown et al., 1993), the Joint (phrase) model (Marcu and Wong, 2002) and Matrix Factorisation (Goutte et al., 2004). But they are much more expensive to calculate. In addition, models like HMM and Model 4 suffer from 1-to-n structure, while the Joint model only allows units consisting of consecutive words. LEAF (Fraser and Marcu, 2007a) directly models m-to-n structure, but is expensive to compute. Alignment by agreement (Liang et al., 2006) is another approach, in which two asymmetric models are trained jointly to maximize a combination of the likelihood of the data. This approach is more expensive than training the two assymetric models independently. It is also biased towards high precision alignment st"
2009.mtsummit-posters.11,N03-1017,0,0.0067491,"ffectively handle indirect associations. But, importantly, it can find m-to-n links. 2D-Linking is most similar to the approach by Tiedemann (2003). He defines the word alignment clue as a score which indicates an association between source-target words by considering various features derived from co-occurrence statistics. But the search algorithm is more similar to competitive linking though it handles 1-to-n and m-to-1 alignments as well. 2D-Linking could be extended to use Tiedemann’s scores in a straightforward manner since it can operate on any association measure. Och and Ney (2003) and Koehn et al. (2003) defined a heuristic procedure that produces an m-ton alignment. Start the procedure by generating the predicted 1-to-n alignment in the direction source to target. In this alignment one source word aligns to zero or more target words. Call the resulting alignment A1. Generate the predicted m-to-1 alignment in the direction target to source. In this alignment one target word aligns to zero or more source words. Call the resulting alignment A2. Combine A1 and A2 into an m-to-n alignment using a symmetrization heuristic. We consider the following three symmetrization heuristics in this paper: (1"
2009.mtsummit-posters.11,N06-1014,0,0.024293,"only needs two) and cannot model m-to-n links. There are also some more advanced unsupervised models such as the HMM word alignment model (Vogel et al., 1996), IBM Model 4 (Brown et al., 1993), the Joint (phrase) model (Marcu and Wong, 2002) and Matrix Factorisation (Goutte et al., 2004). But they are much more expensive to calculate. In addition, models like HMM and Model 4 suffer from 1-to-n structure, while the Joint model only allows units consisting of consecutive words. LEAF (Fraser and Marcu, 2007a) directly models m-to-n structure, but is expensive to compute. Alignment by agreement (Liang et al., 2006) is another approach, in which two asymmetric models are trained jointly to maximize a combination of the likelihood of the data. This approach is more expensive than training the two assymetric models independently. It is also biased towards high precision alignment structure as the posterior of both 1-to-n models must be high for a link to be selected. One of the best known heuristic models is competitive linking (Melamed, 1997). In competitive linking at first the word pair with the highest association score is aligned (this is similar to maximum linking, Eq. 2). Then the corresponding row"
2009.mtsummit-posters.11,W02-1018,0,0.0181157,"on of the other IBM models. Structurally, it cannot have m-to-n links. However it is possible to improve the model. Moore (2004) introduced an improvement of IBM Model 1 that tries to control the trade-off between precision and recall by adding additional null words to the source sentence. Like Model 1, Moore’s model requires several passes through the data (whereas 2D-Linking only needs two) and cannot model m-to-n links. There are also some more advanced unsupervised models such as the HMM word alignment model (Vogel et al., 1996), IBM Model 4 (Brown et al., 1993), the Joint (phrase) model (Marcu and Wong, 2002) and Matrix Factorisation (Goutte et al., 2004). But they are much more expensive to calculate. In addition, models like HMM and Model 4 suffer from 1-to-n structure, while the Joint model only allows units consisting of consecutive words. LEAF (Fraser and Marcu, 2007a) directly models m-to-n structure, but is expensive to compute. Alignment by agreement (Liang et al., 2006) is another approach, in which two asymmetric models are trained jointly to maximize a combination of the likelihood of the data. This approach is more expensive than training the two assymetric models independently. It is"
2009.mtsummit-posters.11,P97-1063,0,0.459608,"ows units consisting of consecutive words. LEAF (Fraser and Marcu, 2007a) directly models m-to-n structure, but is expensive to compute. Alignment by agreement (Liang et al., 2006) is another approach, in which two asymmetric models are trained jointly to maximize a combination of the likelihood of the data. This approach is more expensive than training the two assymetric models independently. It is also biased towards high precision alignment structure as the posterior of both 1-to-n models must be high for a link to be selected. One of the best known heuristic models is competitive linking (Melamed, 1997). In competitive linking at first the word pair with the highest association score is aligned (this is similar to maximum linking, Eq. 2). Then the corresponding row and column are deleted from the alignment matrix. This process is iterated until either all rows have been deleted or all columns have been deleted. The advantage of this method is its ability to filter out most indirect associations – words that have high association scores but are not translations of each other. The main problem with competitive linking is its inability to produce m-to-n links. Like competitive linking, we will"
2009.mtsummit-posters.11,P06-1065,0,0.0379284,"Missing"
2009.mtsummit-posters.11,J03-1002,0,0.0462934,"quires only two passes over the data and less memory than other methods. We show that 2D-Linking is superior to competitive linking and as good as or better than symmetrized IBM Model 1 in terms of alignment quality and that it supports trading off precision against recall. 1 Introduction Word alignment, the task of establishing correspondences between words in a bitext (i.e., a sentencealigned parallel corpus), is an important problem with applications in statistical machine translation, the automatic generation of bilingual dictionaries and cross-language information retrieval. According to Och and Ney (2003), there are two general approaches to computing word alignments: statistical and heuristic methods. In statistical alignment methods (Brown et al., 1993), P r (T |S) is written in terms of the conditional probability P r (T, a|S) as: X P r (T |S) = P r (T, a|S) (1) a Here, the alignment a describes a mapping from the positions of the words in the source text S to the positions in the target text T . The heuristic methods are considerably simpler. Generally speaking, they try to align each word according to the associative information of sourcetarget word pairs. This information can be provided"
2009.mtsummit-posters.11,E03-1026,0,0.268037,"column are deleted from the alignment matrix. This process is iterated until either all rows have been deleted or all columns have been deleted. The advantage of this method is its ability to filter out most indirect associations – words that have high association scores but are not translations of each other. The main problem with competitive linking is its inability to produce m-to-n links. Like competitive linking, we will show that 2D-Linking is also able to effectively handle indirect associations. But, importantly, it can find m-to-n links. 2D-Linking is most similar to the approach by Tiedemann (2003). He defines the word alignment clue as a score which indicates an association between source-target words by considering various features derived from co-occurrence statistics. But the search algorithm is more similar to competitive linking though it handles 1-to-n and m-to-1 alignments as well. 2D-Linking could be extended to use Tiedemann’s scores in a straightforward manner since it can operate on any association measure. Och and Ney (2003) and Koehn et al. (2003) defined a heuristic procedure that produces an m-ton alignment. Start the procedure by generating the predicted 1-to-n alignmen"
2009.mtsummit-posters.11,C96-2141,0,0.189041,"ore details see (Brown et al., 1993). IBM Model 1 is mostly used for initialization of the other IBM models. Structurally, it cannot have m-to-n links. However it is possible to improve the model. Moore (2004) introduced an improvement of IBM Model 1 that tries to control the trade-off between precision and recall by adding additional null words to the source sentence. Like Model 1, Moore’s model requires several passes through the data (whereas 2D-Linking only needs two) and cannot model m-to-n links. There are also some more advanced unsupervised models such as the HMM word alignment model (Vogel et al., 1996), IBM Model 4 (Brown et al., 1993), the Joint (phrase) model (Marcu and Wong, 2002) and Matrix Factorisation (Goutte et al., 2004). But they are much more expensive to calculate. In addition, models like HMM and Model 4 suffer from 1-to-n structure, while the Joint model only allows units consisting of consecutive words. LEAF (Fraser and Marcu, 2007a) directly models m-to-n structure, but is expensive to compute. Alignment by agreement (Liang et al., 2006) is another approach, in which two asymmetric models are trained jointly to maximize a combination of the likelihood of the data. This appro"
2012.eamt-1.42,2009.iwslt-papers.4,0,0.0692607,". Our work is novel in that we look at reordering distances of up to 50 words, and conduct a detailed manual analysis based on a new gold standard. 1 Introduction Word reordering is a well-known issue in SMT. One successful approach has been to use rulebased preprocessing to reorder parse trees. We would like to perform reordering during inference. Phrase-based hierarchical models (Chiang, 2007) have helped, but reordering over long distances is still a difficult open problem. Consider the following German sentence and English output taken from the hierarchical component of the Moses toolkit (Hoang et al., 2009). These sentences illustrate the successful reordering of the participle geeinigt (agreed) from the end of the German clause, to be next to the English auxiliary have. (1) (2) deutschland (germany) , frankreich (france) , israel (israel) und (and) die (the) usa- (us) haben (have) sich (themselves) im (in) mai (may) 2006 darauf (on) geeinigt (agreed) , es (it) zu (to) tun (do). germany , france , israel and the us have agreed in may 2006 , to do it . This reordering involves a word movement over 5 tokens and is therefore not a long-distance reorderc 2012 European Association for Machine Transla"
2012.eamt-1.42,D11-1125,0,0.0315991,"e token labeled by the opening and closing S-Nodes in the parse tree. on all test sets is also provided, but since it can not perform long-distance reorderings we provide no further analysis. The translation model has been trained using 1,502,301 bilingual sentences after length ratio filtering. GIZA++ (Och and Ney, 2003) has been used for generating the word alignments, combined with the grow-diag-final-and heuristic (Koehn et al., 2007). We trained our monolingual 5-gram language model using the English side of the training data. Feature weights are tuned using Pairwise-Ranked optimization (Hopkins and May, 2011) followed by standard MERT line search (for fine tuning of the length penalty). We evaluate two tasks. For the ACL WMT 2009 German-toEnglish shared task, we use news-dev2009a as our dev set, and news-dev2009b as our test set. To reduce the effect of data sparsity for the difficult task of long-distance reordering, we also consider a Europarl translation task, using the same system (with the same training data), but using Europarl test2007 as our dev set, and Europarl dev2006 as our test set. 6 Evaluation We perform a two step evaluation procedure. First the compared systems are evaluated using"
2012.eamt-1.42,P07-2045,0,0.0162566,"by applying a basic POS-based filtering so that long-span rules contain verbs. Finally, we introduce another innovation to Hiero, which is to block our long-span rules from crossing clause boundaries. We release the source code changes to Hierarchical Moses and our annotated test set for further study by other research groups. 2 Previous Work The long-distance reordering issue has been considered in phrase-based SMT as well as in syntaxbased SMT. The basic phrase-based model is able to handle word movement up to six tokens but a decrease of performance is observed at higher distortion limits (Koehn et al., 2007). Many reordering methods use a distortion limit between 6 and 9 words (e.g., (Tillmann and Xia, 2003; Koehn et al., 2007; Galley and Manning, 2008)). Green et al. (2010) implement a future cost function and a distortion model that outperform a standard phrasebased system using a distortion limit of 15. We work with longer distances. Collins et al. (2005) discuss an approach combining rule-based transformations with (phrasebased) SMT. In a preprocessing step, the source language is reordered using parse trees. The restructured output is then provided to a phrasebased MT system. Deterministic p"
2012.eamt-1.42,P08-1114,0,0.0275627,"h use source-side-syntactic parses of the test set sometimes do not use such a restriction because they force a match with a syntactic constituent (in the source language parse). There have been many approaches looking at backing off from hard sourceside constraints on syntactic labels to Hiero-style X rules (e.g., (Venugopal et al., 2007; Hoang and Koehn, 2010; Mylonakis and Sima’an, 2011)). 178 Due to the diversity of possible structures for German clauses and to poor parse accuracy on long sentences we restrict our study to Hiero, with a view towards integrating soft syntactic constraints (Marton and Resnik, 2008; Chiang, 2010) in the future. Hard syntactic constraints would suffer from too many errors (and too much sparsity) to improve performance in our approach. Our study looks at the specific phenomenon of long-distance reordering in a hierarchical-phrase based framework, by modifying Hiero to support span-width specific rules. We consider exactly the reorderings required for the German-to-English clause reordering problem and focus particular attention on ensuring that the correct reorderings can be considered during search. We employ simple lowknowledge techniques to improve the chances that the"
2012.eamt-1.42,P02-1040,0,0.0844797,"ur dev set, and news-dev2009b as our test set. To reduce the effect of data sparsity for the difficult task of long-distance reordering, we also consider a Europarl translation task, using the same system (with the same training data), but using Europarl test2007 as our dev set, and Europarl dev2006 as our test set. 6 Evaluation We perform a two step evaluation procedure. First the compared systems are evaluated using automatic metrics. In a second step we compare the systems using a manually annotated test set. Automatic Evaluation. As a first automatic evaluation metric, we use 4-gram BLEU (Papineni et al., 2002). Because BLEU does not consider the positions of matched n-grams and does not capture the distance of erroneous reorderings, we use LRscore (Birch and Osborne, 2011) as a second metric to evaluate reordering quality. This method compares the alignments between input and reference with the alignments between input and system output (Kendall’s Tau over permutations is used as the distance metric). We provide two measures (i) LRscore as proposed in (Birch and Osborne, 2011) where the interpolation parameter7 α is set to 0.2623 (ii) reordering performance only, i.e., α = 1. Figure 2 shows the res"
2012.eamt-1.42,P11-1103,0,0.0657931,"translation task, using the same system (with the same training data), but using Europarl test2007 as our dev set, and Europarl dev2006 as our test set. 6 Evaluation We perform a two step evaluation procedure. First the compared systems are evaluated using automatic metrics. In a second step we compare the systems using a manually annotated test set. Automatic Evaluation. As a first automatic evaluation metric, we use 4-gram BLEU (Papineni et al., 2002). Because BLEU does not consider the positions of matched n-grams and does not capture the distance of erroneous reorderings, we use LRscore (Birch and Osborne, 2011) as a second metric to evaluate reordering quality. This method compares the alignments between input and reference with the alignments between input and system output (Kendall’s Tau over permutations is used as the distance metric). We provide two measures (i) LRscore as proposed in (Birch and Osborne, 2011) where the interpolation parameter7 α is set to 0.2623 (ii) reordering performance only, i.e., α = 1. Figure 2 shows the results for all systems on the Europarl and ACL WMT 2009 tasks. Our improved hierarchical system is denoted by Improved-50. Hierarchical Moses with span sizes up to 50 t"
2012.eamt-1.42,J07-2003,0,0.66933,"nference, and thus deterministic preprocessing based on reordering parse trees is used. We consider German-to-English translation using Hiero. We show how to effectively model long-distance reorderings during search. Our work is novel in that we look at reordering distances of up to 50 words, and conduct a detailed manual analysis based on a new gold standard. 1 Introduction Word reordering is a well-known issue in SMT. One successful approach has been to use rulebased preprocessing to reorder parse trees. We would like to perform reordering during inference. Phrase-based hierarchical models (Chiang, 2007) have helped, but reordering over long distances is still a difficult open problem. Consider the following German sentence and English output taken from the hierarchical component of the Moses toolkit (Hoang et al., 2009). These sentences illustrate the successful reordering of the participle geeinigt (agreed) from the end of the German clause, to be next to the English auxiliary have. (1) (2) deutschland (germany) , frankreich (france) , israel (israel) und (and) die (the) usa- (us) haben (have) sich (themselves) im (in) mai (may) 2006 darauf (on) geeinigt (agreed) , es (it) zu (to) tun (do)."
2012.eamt-1.42,P11-1065,0,0.0825843,"Missing"
2012.eamt-1.42,C04-1024,0,0.0462137,"50 tokens is intractable in terms of cpu time and disk space. In order to nevertheless work with such a system we adopt the same strategy as described in section 4: we extract rules on spans up to 10 and allow the obtained grammar to apply to spans up to 50 words during decoding. The modified system presented in section 4 will be evaluated against this baseline. Note that choosing a baseline with extended span size allows us to evaluate our approach against a system enabled to perform long-distance reordering. The results obtained by hierarchical Moses with standard settings 6 We use BitPar (Schmid, 2004) to extract clause boundaries. Boundaries correspond to the position of the token labeled by the opening and closing S-Nodes in the parse tree. on all test sets is also provided, but since it can not perform long-distance reorderings we provide no further analysis. The translation model has been trained using 1,502,301 bilingual sentences after length ratio filtering. GIZA++ (Och and Ney, 2003) has been used for generating the word alignments, combined with the grow-diag-final-and heuristic (Koehn et al., 2007). We trained our monolingual 5-gram language model using the English side of the tra"
2012.eamt-1.42,P10-1146,0,0.0282866,"ic parses of the test set sometimes do not use such a restriction because they force a match with a syntactic constituent (in the source language parse). There have been many approaches looking at backing off from hard sourceside constraints on syntactic labels to Hiero-style X rules (e.g., (Venugopal et al., 2007; Hoang and Koehn, 2010; Mylonakis and Sima’an, 2011)). 178 Due to the diversity of possible structures for German clauses and to poor parse accuracy on long sentences we restrict our study to Hiero, with a view towards integrating soft syntactic constraints (Marton and Resnik, 2008; Chiang, 2010) in the future. Hard syntactic constraints would suffer from too many errors (and too much sparsity) to improve performance in our approach. Our study looks at the specific phenomenon of long-distance reordering in a hierarchical-phrase based framework, by modifying Hiero to support span-width specific rules. We consider exactly the reorderings required for the German-to-English clause reordering problem and focus particular attention on ensuring that the correct reorderings can be considered during search. We employ simple lowknowledge techniques to improve the chances that the correct transl"
2012.eamt-1.42,W10-1762,0,0.0427721,"al-phrase based framework, by modifying Hiero to support span-width specific rules. We consider exactly the reorderings required for the German-to-English clause reordering problem and focus particular attention on ensuring that the correct reorderings can be considered during search. We employ simple lowknowledge techniques to improve the chances that the correct translation is not only considered but also chosen, but we expect that implementing soft syntactic constraints will improve this further. The question of handling long-distance movements in hierarchical MT has also been addressed by Sudoh et al. (2010) who present a method that deals with reordering involving connecting together several embedded clauses. Our work differs from (Sudoh et al., 2010) because we handle long-distance reordering inside of a single clause. Moreover, the method by (Sudoh et al., 2010) divides the source language into clauses in a preprocessing step and re-unifies the obtained translations in a post-processing step. In our approach, reordering is performed during inference. 3 Long-Distance Reorderings In this section, we discuss the type of reordering Hiero is not able to handle, given the constraints used by Chiang"
2012.eamt-1.42,P05-1066,0,0.212234,"istance reordering issue has been considered in phrase-based SMT as well as in syntaxbased SMT. The basic phrase-based model is able to handle word movement up to six tokens but a decrease of performance is observed at higher distortion limits (Koehn et al., 2007). Many reordering methods use a distortion limit between 6 and 9 words (e.g., (Tillmann and Xia, 2003; Koehn et al., 2007; Galley and Manning, 2008)). Green et al. (2010) implement a future cost function and a distortion model that outperform a standard phrasebased system using a distortion limit of 15. We work with longer distances. Collins et al. (2005) discuss an approach combining rule-based transformations with (phrasebased) SMT. In a preprocessing step, the source language is reordered using parse trees. The restructured output is then provided to a phrasebased MT system. Deterministic preprocessing has several drawbacks such as high sensitivity to parsing errors or the propagation of wrong phrase correspondences (created by incorrect reordering of the training data) into the learned translation probabilities. Preprocessing also does not allow the interaction of long-distance reordering decisions with nearby translation decisions via the"
2012.eamt-1.42,N03-2036,0,0.0308796,"ce another innovation to Hiero, which is to block our long-span rules from crossing clause boundaries. We release the source code changes to Hierarchical Moses and our annotated test set for further study by other research groups. 2 Previous Work The long-distance reordering issue has been considered in phrase-based SMT as well as in syntaxbased SMT. The basic phrase-based model is able to handle word movement up to six tokens but a decrease of performance is observed at higher distortion limits (Koehn et al., 2007). Many reordering methods use a distortion limit between 6 and 9 words (e.g., (Tillmann and Xia, 2003; Koehn et al., 2007; Galley and Manning, 2008)). Green et al. (2010) implement a future cost function and a distortion model that outperform a standard phrasebased system using a distortion limit of 15. We work with longer distances. Collins et al. (2005) discuss an approach combining rule-based transformations with (phrasebased) SMT. In a preprocessing step, the source language is reordered using parse trees. The restructured output is then provided to a phrasebased MT system. Deterministic preprocessing has several drawbacks such as high sensitivity to parsing errors or the propagation of w"
2012.eamt-1.42,D08-1089,0,0.0694621,"block our long-span rules from crossing clause boundaries. We release the source code changes to Hierarchical Moses and our annotated test set for further study by other research groups. 2 Previous Work The long-distance reordering issue has been considered in phrase-based SMT as well as in syntaxbased SMT. The basic phrase-based model is able to handle word movement up to six tokens but a decrease of performance is observed at higher distortion limits (Koehn et al., 2007). Many reordering methods use a distortion limit between 6 and 9 words (e.g., (Tillmann and Xia, 2003; Koehn et al., 2007; Galley and Manning, 2008)). Green et al. (2010) implement a future cost function and a distortion model that outperform a standard phrasebased system using a distortion limit of 15. We work with longer distances. Collins et al. (2005) discuss an approach combining rule-based transformations with (phrasebased) SMT. In a preprocessing step, the source language is reordered using parse trees. The restructured output is then provided to a phrasebased MT system. Deterministic preprocessing has several drawbacks such as high sensitivity to parsing errors or the propagation of wrong phrase correspondences (created by incorre"
2012.eamt-1.42,N07-1063,0,0.0237546,"within the hierarchical phrase-based MT framework that considers rules allowed to span up to 50 words. Approaches using linguistic syntactic labels (obtained from a source language or target language parser, or both) sometimes also use such span restrictions. However, systems which use source-side-syntactic parses of the test set sometimes do not use such a restriction because they force a match with a syntactic constituent (in the source language parse). There have been many approaches looking at backing off from hard sourceside constraints on syntactic labels to Hiero-style X rules (e.g., (Venugopal et al., 2007; Hoang and Koehn, 2010; Mylonakis and Sima’an, 2011)). 178 Due to the diversity of possible structures for German clauses and to poor parse accuracy on long sentences we restrict our study to Hiero, with a view towards integrating soft syntactic constraints (Marton and Resnik, 2008; Chiang, 2010) in the future. Hard syntactic constraints would suffer from too many errors (and too much sparsity) to improve performance in our approach. Our study looks at the specific phenomenon of long-distance reordering in a hierarchical-phrase based framework, by modifying Hiero to support span-width specifi"
2012.eamt-1.42,N10-1129,0,0.069243,"om crossing clause boundaries. We release the source code changes to Hierarchical Moses and our annotated test set for further study by other research groups. 2 Previous Work The long-distance reordering issue has been considered in phrase-based SMT as well as in syntaxbased SMT. The basic phrase-based model is able to handle word movement up to six tokens but a decrease of performance is observed at higher distortion limits (Koehn et al., 2007). Many reordering methods use a distortion limit between 6 and 9 words (e.g., (Tillmann and Xia, 2003; Koehn et al., 2007; Galley and Manning, 2008)). Green et al. (2010) implement a future cost function and a distortion model that outperform a standard phrasebased system using a distortion limit of 15. We work with longer distances. Collins et al. (2005) discuss an approach combining rule-based transformations with (phrasebased) SMT. In a preprocessing step, the source language is reordered using parse trees. The restructured output is then provided to a phrasebased MT system. Deterministic preprocessing has several drawbacks such as high sensitivity to parsing errors or the propagation of wrong phrase correspondences (created by incorrect reordering of the t"
2012.eamt-1.42,J97-3002,0,0.34322,"utput is then provided to a phrasebased MT system. Deterministic preprocessing has several drawbacks such as high sensitivity to parsing errors or the propagation of wrong phrase correspondences (created by incorrect reordering of the training data) into the learned translation probabilities. Preprocessing also does not allow the interaction of long-distance reordering decisions with nearby translation decisions via the language model. In syntax-based SMT, the size of reordering is given by the span of the grammar rules. In approaches which do not use linguistic syntactic labels (such as ITG (Wu, 1997) or Hiero, where only the start symbol S and the non-terminal X are used), the maximal span size allowed in implementations is often between 10 and 15 tokens, because using wider spans has (in experiments done in the past) resulted in decreased translation quality (e.g., (Chiang, 2007)). Zollmann et al. (2008) expand the span size to 15 only for the translation of short sentences. We present work within the hierarchical phrase-based MT framework that considers rules allowed to span up to 50 words. Approaches using linguistic syntactic labels (obtained from a source language or target language"
2012.eamt-1.42,W10-1761,0,0.045974,"phrase-based MT framework that considers rules allowed to span up to 50 words. Approaches using linguistic syntactic labels (obtained from a source language or target language parser, or both) sometimes also use such span restrictions. However, systems which use source-side-syntactic parses of the test set sometimes do not use such a restriction because they force a match with a syntactic constituent (in the source language parse). There have been many approaches looking at backing off from hard sourceside constraints on syntactic labels to Hiero-style X rules (e.g., (Venugopal et al., 2007; Hoang and Koehn, 2010; Mylonakis and Sima’an, 2011)). 178 Due to the diversity of possible structures for German clauses and to poor parse accuracy on long sentences we restrict our study to Hiero, with a view towards integrating soft syntactic constraints (Marton and Resnik, 2008; Chiang, 2010) in the future. Hard syntactic constraints would suffer from too many errors (and too much sparsity) to improve performance in our approach. Our study looks at the specific phenomenon of long-distance reordering in a hierarchical-phrase based framework, by modifying Hiero to support span-width specific rules. We consider ex"
2012.eamt-1.42,C08-1144,0,0.0353228,"rocessing also does not allow the interaction of long-distance reordering decisions with nearby translation decisions via the language model. In syntax-based SMT, the size of reordering is given by the span of the grammar rules. In approaches which do not use linguistic syntactic labels (such as ITG (Wu, 1997) or Hiero, where only the start symbol S and the non-terminal X are used), the maximal span size allowed in implementations is often between 10 and 15 tokens, because using wider spans has (in experiments done in the past) resulted in decreased translation quality (e.g., (Chiang, 2007)). Zollmann et al. (2008) expand the span size to 15 only for the translation of short sentences. We present work within the hierarchical phrase-based MT framework that considers rules allowed to span up to 50 words. Approaches using linguistic syntactic labels (obtained from a source language or target language parser, or both) sometimes also use such span restrictions. However, systems which use source-side-syntactic parses of the test set sometimes do not use such a restriction because they force a match with a syntactic constituent (in the source language parse). There have been many approaches looking at backing"
2012.eamt-1.42,J03-1002,0,\N,Missing
2014.amta-researchers.21,2009.eamt-1.9,0,0.362469,"the high-quality lexical resource GermaNet. 2 Related Work Translating prepositions is an important problem in machine translation. So far, research has mostly been reported on rule-based systems. Gustavii (2005) uses bilingual features and selectional constraints to correct translations from a rule-based Swedish-English system; she reports a gain in accuracy for prepositions. Naskar and Bandyopadhyay (2006) outline a method to handle prepositions in an English-Bengali MT system: they use WordNet in combination with a bilingual example base for idiomatic PPs, but do not report any evaluation. Agirre et al. (2009) model Basque prepositions and grammatical case using syntactic-semantic features such as subcategorization triples for a rule-based system; they also report a gain in translation accuracy for prepositions. The approach of Shilon et al. (2012) is similar to the work of Agirre et al. (2009); however, Shilon’s system has a statistical component for ranking proposed translations, which leads to an improvement in BLEU for a small test set. Furthermore, Zollmann and Vogel (2011) use cluster information in syntactic SMT, although not specifically for translating prepositions. Huang and Knight (2006)"
2014.amta-researchers.21,E12-1068,1,0.871973,"ymbols and the source-side) remains the same. To keep the amount of generated rules manageable, we used a threshold of f ≥ 5 to select the rules for which to generate new PP rules and only kept generated rules with a translation probability of p ≥ 0.001 (“new rules”). Finally, we added both baseline and new rules (“BL+new”). 5 Experiments and Results We used a morphology-aware English-German translation system that first translates into a lemmatized representation, and then generates inflected forms based on morphological features predicted with a sequence model (e.g. Toutanova et al. (2008), Fraser et al. (2012)). This reduces morphological complexity of nominal phrases, and allows in particular to handle portmanteaus (combination of preposition and article: zur=zu+der: to the) which are split in pre-processing and merged in a post-processing step. Thus, during translation, prepositions occurring as portmanteaus are represented in the same way as non-portmanteau prepositions. Table 4 illustrates the processing steps. The lemmatized representation (first column) contains feature markup on nouns for the features number and gender, which are considered part of the stem. The information about gender is o"
2014.amta-researchers.21,W10-1734,1,0.820456,"ed entity category1 . A second benefit is that only nouns, for which we can expect to have either GermaNet coverage or a sound basis for feature extraction, are considered for clustering; “nonnouns” (such as typos or parse-errors which are often very low-frequency and thus likely to deteriorate clustering performance) are excluded from clustering. The second pre-processing step consists in compound handling: as German noun compounding is very productive and can lead to sparsity and coverage problems, we applied compound splitting to all nouns using a linguistically-informed compound splitter (Fritzinger and Fraser, 2010), which disambiguates competing SMOR analyses relying on corpus statistics. After pre-processing, noun class information is first computed for head nouns. Then, in a second step, compounds are added into classes based on their head noun. While this might introduce noise for a small number of non-compositional compounds, we assume that the gain in generalization is more important. 3.2 GermaNet GermaNet (Hamp and Feldweg, 1997; Kunze, 2000) is a lexical resource for German similar to the English WordNet (Fellbaum, 1998). It is a lexical-semantic taxonomy that groups words of the same concept int"
2014.amta-researchers.21,N04-1035,0,0.0525061,"tags and stems (second column). Based on the predicted morphological features and the lemma, inflected forms can be generated using a morphological resource (third column). Finally, after generating inflected forms, split instances of portmanteau prepositions are merged relying on a simple set of rules4 as illustrated in the example (zu+der → zur) in the third column of table 4. 5.1 Data We used 1.5 M sentences of parallel data (Europarl and news data from the 2009 WMT shared task), with the target-side part as language model data, to train a string-to-tree Moses system with GHKM extraction (Galley et al., 2004; Williams and Koehn, 2012). The tuning/test sets consist of 1025/1026 news sentences (from the 2009 WMT shared task). The German data was parsed with BitPar (Schmid, 2004). For generating inflected forms, we used the morphological tool SMOR (Schmid et al., 2004). For predicting the morphological features number, gender, case and strong/weak inflection, we trained one CRF for each of the four morphological features using the Wapiti toolkit (Lavergne et al., 2010). The tuples for modelling translation probabilities for rule generation and the context vectors for clustering were obtained from a"
2014.amta-researchers.21,2005.eamt-1.16,0,0.583506,"tional preferences as rigid annotation in the parse tree is not optimal, as there is no generally applicable optimal level of semantic information. With regard to resources, we found that cluster analyses based on simple window information are better at capturing selectional preferences, with superior performance to both (a) the clusters relying on syntactic features and (b) the classes induced from the high-quality lexical resource GermaNet. 2 Related Work Translating prepositions is an important problem in machine translation. So far, research has mostly been reported on rule-based systems. Gustavii (2005) uses bilingual features and selectional constraints to correct translations from a rule-based Swedish-English system; she reports a gain in accuracy for prepositions. Naskar and Bandyopadhyay (2006) outline a method to handle prepositions in an English-Bengali MT system: they use WordNet in combination with a bilingual example base for idiomatic PPs, but do not report any evaluation. Agirre et al. (2009) model Basque prepositions and grammatical case using syntactic-semantic features such as subcategorization triples for a rule-based system; they also report a gain in translation accuracy for"
2014.amta-researchers.21,W97-0802,0,0.0844244,"ding is very productive and can lead to sparsity and coverage problems, we applied compound splitting to all nouns using a linguistically-informed compound splitter (Fritzinger and Fraser, 2010), which disambiguates competing SMOR analyses relying on corpus statistics. After pre-processing, noun class information is first computed for head nouns. Then, in a second step, compounds are added into classes based on their head noun. While this might introduce noise for a small number of non-compositional compounds, we assume that the gain in generalization is more important. 3.2 GermaNet GermaNet (Hamp and Feldweg, 1997; Kunze, 2000) is a lexical resource for German similar to the English WordNet (Fellbaum, 1998). It is a lexical-semantic taxonomy that groups words of the same concept into synsets. For each head noun, we looked up the GermaNet class for a given hierarchical level, to determine the degree of generalization: GermaNet is graph-structured, and extracting the nouns at different levels results in more or less fine-grained sets of classes. We used noun classes from the levels 2, 3, 4, 5, counting from the top level2 . 1 Note, however, that our type-based annotation method does not take into account"
2014.amta-researchers.21,N06-1031,0,0.276473,"n. Agirre et al. (2009) model Basque prepositions and grammatical case using syntactic-semantic features such as subcategorization triples for a rule-based system; they also report a gain in translation accuracy for prepositions. The approach of Shilon et al. (2012) is similar to the work of Agirre et al. (2009); however, Shilon’s system has a statistical component for ranking proposed translations, which leads to an improvement in BLEU for a small test set. Furthermore, Zollmann and Vogel (2011) use cluster information in syntactic SMT, although not specifically for translating prepositions. Huang and Knight (2006) propose methods of relabeling syntax trees to improve statistical syntactic translation. Their annotation aims at making the used tag-set (based on the Penn Treebank) less general, assuming that it often fails to capture relevant grammatical distinctions and contexts that are crucial for translation. They distinguish between internal and external annotation. In the case of internal annotation, additional information about the node or its relatives that is otherwise not accessible to the respective node is annotated; this type of annotation consists of lexical and tag information. Their lexica"
2014.amta-researchers.21,kunze-2000-extension,0,0.0693447,"Missing"
2014.amta-researchers.21,P10-1052,0,0.184531,"Missing"
2014.amta-researchers.21,P08-1114,0,0.0219911,"at the same level of granularity. 6.2 Conclusion We started with the hypothesis that noun class information is useful to model selectional preferences in preposition translation rules. However, annotating semantic class information on NP/PP nodes of the parse trees in a string-to-tree system amounts to a hard constraint and our experiments indicate that this form of annotation leads to overly specific rules. We tried to compensate for this by making the non-annotated rules available and by adding new PP rules synthesized from monolingual data. However, previous work, such as e.g. the work of Marton and Resnik (2008), has shown that soft constraints often work better than hard constraints. It might therefore make sense to model selectional preferences through the use of feature functions which reward good choices, rather than markup in the string-to-tree grammar, but this would require extensive changes to the model and decoder. Another problem with our approach is that there is no generally applicable optimal level of selectional preferences. This is in line with semantic research on selectional preferences as verb subcategorization features (Schulte im Walde, 2006; Joanis et al., 2008): across subcatego"
2014.amta-researchers.21,W06-2113,0,0.469097,"that cluster analyses based on simple window information are better at capturing selectional preferences, with superior performance to both (a) the clusters relying on syntactic features and (b) the classes induced from the high-quality lexical resource GermaNet. 2 Related Work Translating prepositions is an important problem in machine translation. So far, research has mostly been reported on rule-based systems. Gustavii (2005) uses bilingual features and selectional constraints to correct translations from a rule-based Swedish-English system; she reports a gain in accuracy for prepositions. Naskar and Bandyopadhyay (2006) outline a method to handle prepositions in an English-Bengali MT system: they use WordNet in combination with a bilingual example base for idiomatic PPs, but do not report any evaluation. Agirre et al. (2009) model Basque prepositions and grammatical case using syntactic-semantic features such as subcategorization triples for a rule-based system; they also report a gain in translation accuracy for prepositions. The approach of Shilon et al. (2012) is similar to the work of Agirre et al. (2009); however, Shilon’s system has a statistical component for ranking proposed translations, which leads"
2014.amta-researchers.21,P06-1014,0,0.0297856,"erally acceptable semantic level of generalization in lexical resources. Because of this, the parse tree annotation is not flexible enough to take into account the varying needs of different contexts, as it always leads to rules of the same degree of specificity, and therefore cannot adapt to the respective contexts. With regard to resources, we found that none of the variants we considered was able to obtain noun class information that is optimal: WordNets in general are known to be very finegrained and contain many ambiguities, making it difficult to derive generally applicable noun groups (Navigli, 2006; Palmer et al., 2007). In contrast, window clusters might not contain the appropriate selectional preference information as they resemble topic clusters rather than a generalization over specific noun types. As opposed to the unstructured information used for the window clustering, the syntactic dependencies constitute the type of information that is needed to determine a valid preposition for a given context, i.e. the governing verb/noun or the noun in the PP. Thus, clusters learned from syntactic features were expected to better capture selectional preferences. However, these clusters faile"
2014.amta-researchers.21,C00-2094,0,0.743559,"s-related cluster contains persons (minister, chancellor) and other terms related to politics. In contrast, the classes assigned by GermNet resemble more a generalization over specific noun types as human beings (minister, chancellor) are grouped together and the remaining terms majority, opposition and dismissal are each in a separate group. Using syntactic features for clustering, in particular prepositions, aims at better capturing selectional preferences, and thus obtaining classes that provide salient information for the task of modeling the choice of prepositions in SMT; cf. for example Prescher et al. (2000), Erk et al. (2010), Joanis et al. (2008), Schulte im Walde (2006) and Schulte im Walde (2010) for more information. A major problem consists in finding a number of clusters that provides both (i) a good representation of the nouns and (ii) the optimal level of abstraction for our SMT-system. In our experiments, we varied the cluster sizes and used sets of 10 – 300 clusters. 4 Using Noun Class Information in SMT This section presents the basic enriched system and its variants extended with non-annotated baseline rules and new PP rules. In all experiments, a preposition is annotated on both its"
2014.amta-researchers.21,C04-1024,0,0.102844,"lly, after generating inflected forms, split instances of portmanteau prepositions are merged relying on a simple set of rules4 as illustrated in the example (zu+der → zur) in the third column of table 4. 5.1 Data We used 1.5 M sentences of parallel data (Europarl and news data from the 2009 WMT shared task), with the target-side part as language model data, to train a string-to-tree Moses system with GHKM extraction (Galley et al., 2004; Williams and Koehn, 2012). The tuning/test sets consist of 1025/1026 news sentences (from the 2009 WMT shared task). The German data was parsed with BitPar (Schmid, 2004). For generating inflected forms, we used the morphological tool SMOR (Schmid et al., 2004). For predicting the morphological features number, gender, case and strong/weak inflection, we trained one CRF for each of the four morphological features using the Wapiti toolkit (Lavergne et al., 2010). The tuples for modelling translation probabilities for rule generation and the context vectors for clustering were obtained from a combination of the web corpus SdeWaC (44M sentences, Faaß and Eckart (2013)) and the German part of the parallel data. 5.2 Results Table 5 presents the results of the syste"
2014.amta-researchers.21,schmid-etal-2004-smor,0,0.190229,"ii) clustering nouns on the basis of syntactic dependency information. Comparing these disjunctive methods should ensure a systematic assessment of integrating selectional preferences. 3.1 Pre-processing In order to obtain a consistent noun class annotation, we applied two pre-processing steps to the target-language data prior to computing noun classes using the three variants. In the first step, we attempt to resolve (possibly) inconsistent parsing decisions for word types tagged both as nouns and named entities. Only words recognized as nouns by the highcoverage morphological analyzer SMOR (Schmid et al., 2004) are considered as common nouns. The remaining instances are considered as named entities; they are classified into organization, location, person and a category for rest (Faruqui and Pad´o, 2010). Performing this preprocessing ensures that nouns are consistently labeled with the same noun class or named entity category1 . A second benefit is that only nouns, for which we can expect to have either GermaNet coverage or a sound basis for feature extraction, are considered for clustering; “nonnouns” (such as typos or parse-errors which are often very low-frequency and thus likely to deteriorate c"
2014.amta-researchers.21,J06-2001,1,0.928046,"Missing"
2014.amta-researchers.21,schulte-im-walde-2010-comparing,1,0.894257,"Missing"
2014.amta-researchers.21,W12-0514,0,0.224268,"lectional constraints to correct translations from a rule-based Swedish-English system; she reports a gain in accuracy for prepositions. Naskar and Bandyopadhyay (2006) outline a method to handle prepositions in an English-Bengali MT system: they use WordNet in combination with a bilingual example base for idiomatic PPs, but do not report any evaluation. Agirre et al. (2009) model Basque prepositions and grammatical case using syntactic-semantic features such as subcategorization triples for a rule-based system; they also report a gain in translation accuracy for prepositions. The approach of Shilon et al. (2012) is similar to the work of Agirre et al. (2009); however, Shilon’s system has a statistical component for ranking proposed translations, which leads to an improvement in BLEU for a small test set. Furthermore, Zollmann and Vogel (2011) use cluster information in syntactic SMT, although not specifically for translating prepositions. Huang and Knight (2006) propose methods of relabeling syntax trees to improve statistical syntactic translation. Their annotation aims at making the used tag-set (based on the Penn Treebank) less general, assuming that it often fails to capture relevant grammatical"
2014.amta-researchers.21,P08-1059,0,0.120768,"(other nodes, terminal symbols and the source-side) remains the same. To keep the amount of generated rules manageable, we used a threshold of f ≥ 5 to select the rules for which to generate new PP rules and only kept generated rules with a translation probability of p ≥ 0.001 (“new rules”). Finally, we added both baseline and new rules (“BL+new”). 5 Experiments and Results We used a morphology-aware English-German translation system that first translates into a lemmatized representation, and then generates inflected forms based on morphological features predicted with a sequence model (e.g. Toutanova et al. (2008), Fraser et al. (2012)). This reduces morphological complexity of nominal phrases, and allows in particular to handle portmanteaus (combination of preposition and article: zur=zu+der: to the) which are split in pre-processing and merged in a post-processing step. Thus, during translation, prepositions occurring as portmanteaus are represented in the same way as non-portmanteau prepositions. Table 4 illustrates the processing steps. The lemmatized representation (first column) contains feature markup on nouns for the features number and gender, which are considered part of the stem. The informa"
2014.amta-researchers.21,W12-3150,0,0.0434317,"nd column). Based on the predicted morphological features and the lemma, inflected forms can be generated using a morphological resource (third column). Finally, after generating inflected forms, split instances of portmanteau prepositions are merged relying on a simple set of rules4 as illustrated in the example (zu+der → zur) in the third column of table 4. 5.1 Data We used 1.5 M sentences of parallel data (Europarl and news data from the 2009 WMT shared task), with the target-side part as language model data, to train a string-to-tree Moses system with GHKM extraction (Galley et al., 2004; Williams and Koehn, 2012). The tuning/test sets consist of 1025/1026 news sentences (from the 2009 WMT shared task). The German data was parsed with BitPar (Schmid, 2004). For generating inflected forms, we used the morphological tool SMOR (Schmid et al., 2004). For predicting the morphological features number, gender, case and strong/weak inflection, we trained one CRF for each of the four morphological features using the Wapiti toolkit (Lavergne et al., 2010). The tuples for modelling translation probabilities for rule generation and the context vectors for clustering were obtained from a combination of the web corp"
2014.amta-researchers.21,P11-1001,0,0.0235711,"MT system: they use WordNet in combination with a bilingual example base for idiomatic PPs, but do not report any evaluation. Agirre et al. (2009) model Basque prepositions and grammatical case using syntactic-semantic features such as subcategorization triples for a rule-based system; they also report a gain in translation accuracy for prepositions. The approach of Shilon et al. (2012) is similar to the work of Agirre et al. (2009); however, Shilon’s system has a statistical component for ranking proposed translations, which leads to an improvement in BLEU for a small test set. Furthermore, Zollmann and Vogel (2011) use cluster information in syntactic SMT, although not specifically for translating prepositions. Huang and Knight (2006) propose methods of relabeling syntax trees to improve statistical syntactic translation. Their annotation aims at making the used tag-set (based on the Penn Treebank) less general, assuming that it often fails to capture relevant grammatical distinctions and contexts that are crucial for translation. They distinguish between internal and external annotation. In the case of internal annotation, additional information about the node or its relatives that is otherwise not acc"
2014.eamt-1.3,I05-1062,0,0.029267,"s to specifically indicate how a term in a given context should be translated. For example, it provides the means to guarantee that a source-language term in plural is translated by the corresponding targetlanguage term in plural, regardless of whether the required inflected form occurs in the training data. Although there are exceptions such as furnitureSG → meublesP L , we believe they play a negligible role when translating under-resourced domains. 2 Related work There has been considerable interest in mining translations directly from comparable corpora. A few representative examples are (Daille and Morin, 2005; Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011; Prochasson and Fung, 2011), all 12 of which mine terms using distributional similarity. These approaches tend to favor recall over precision. In contrast, we use a high-precision method consisting in recognizing term candidates by means of partof-speech patterns with an alignment method relying on dictionary entries (Weller and Heid, 2012). A second strand of relevant work is the integration of terms into SMT decoding. H´alek et al. (2011) integrated named entity translations mined from Wikipedia using the XML mode of Moses, which crea"
2014.eamt-1.3,P11-2071,0,0.0480483,"Missing"
2014.eamt-1.3,2012.amta-monomt.1,0,0.0225543,"ochasson and Fung, 2011), all 12 of which mine terms using distributional similarity. These approaches tend to favor recall over precision. In contrast, we use a high-precision method consisting in recognizing term candidates by means of partof-speech patterns with an alignment method relying on dictionary entries (Weller and Heid, 2012). A second strand of relevant work is the integration of terms into SMT decoding. H´alek et al. (2011) integrated named entity translations mined from Wikipedia using the XML mode of Moses, which creates new phrase table entries dynamically. Pinnis and Skadins (2012) also studied mining named entities, as well as using a high quality terminological database, and added these resources to the parallel training data. We compare these two options (XML vs. added parallel data) and show that adding the terms to the parallel training data leads to better results. To deal with the issue of obtaining the proper inflection of mined terms, we implemented a morphology-aware English to French translation system that separates the translation task into two steps (translation + inflection generation), following Toutanova et al. (2008) and Fraser et al. (2012). Formiga e"
2014.eamt-1.3,E12-1068,1,0.838785,"ally. Pinnis and Skadins (2012) also studied mining named entities, as well as using a high quality terminological database, and added these resources to the parallel training data. We compare these two options (XML vs. added parallel data) and show that adding the terms to the parallel training data leads to better results. To deal with the issue of obtaining the proper inflection of mined terms, we implemented a morphology-aware English to French translation system that separates the translation task into two steps (translation + inflection generation), following Toutanova et al. (2008) and Fraser et al. (2012). Formiga et al. (2012) use a component for targetside morphological generation to translate news and web-log data. In contrast to our work, they do not deal with nominal morphology, but model verb inflection: this is important for web-log data, as second-person verb forms rarely appear in Europarltype training data. Wu et al. (2008) use dictionary entries for adapting a system trained on Europarl to news, but without applying morphological modelling to their EN-FR system. Furthermore, news and also web-log data are considerably more similar to Europarl than technical data. Our main contributi"
2014.eamt-1.3,P08-1088,0,0.0349715,"te how a term in a given context should be translated. For example, it provides the means to guarantee that a source-language term in plural is translated by the corresponding targetlanguage term in plural, regardless of whether the required inflected form occurs in the training data. Although there are exceptions such as furnitureSG → meublesP L , we believe they play a negligible role when translating under-resourced domains. 2 Related work There has been considerable interest in mining translations directly from comparable corpora. A few representative examples are (Daille and Morin, 2005; Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011; Prochasson and Fung, 2011), all 12 of which mine terms using distributional similarity. These approaches tend to favor recall over precision. In contrast, we use a high-precision method consisting in recognizing term candidates by means of partof-speech patterns with an alignment method relying on dictionary entries (Weller and Heid, 2012). A second strand of relevant work is the integration of terms into SMT decoding. H´alek et al. (2011) integrated named entity translations mined from Wikipedia using the XML mode of Moses, which creates new phrase table en"
2014.eamt-1.3,P10-1052,0,0.0644516,"Missing"
2014.eamt-1.3,P11-1133,0,0.0177919,"r example, it provides the means to guarantee that a source-language term in plural is translated by the corresponding targetlanguage term in plural, regardless of whether the required inflected form occurs in the training data. Although there are exceptions such as furnitureSG → meublesP L , we believe they play a negligible role when translating under-resourced domains. 2 Related work There has been considerable interest in mining translations directly from comparable corpora. A few representative examples are (Daille and Morin, 2005; Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011; Prochasson and Fung, 2011), all 12 of which mine terms using distributional similarity. These approaches tend to favor recall over precision. In contrast, we use a high-precision method consisting in recognizing term candidates by means of partof-speech patterns with an alignment method relying on dictionary entries (Weller and Heid, 2012). A second strand of relevant work is the integration of terms into SMT decoding. H´alek et al. (2011) integrated named entity translations mined from Wikipedia using the XML mode of Moses, which creates new phrase table entries dynamically. Pinnis and Skadins (2012) also studied mini"
2014.eamt-1.3,C08-1098,0,0.103118,"F] vendre[VPP] ` a[P] le<+DET>[ART] r´ eseau<M.Sg>[N] pred. feat. M.Sg M.Sg – F.Sg – – M.Sg – M.Sg M.Sg gen. forms le exc`es de e´ nergie peut eˆ tre vendu a` le r´eseau postproc. l’ exc`es d’ e´ nergie peut eˆ tre vendu au r´eseau gloss the excess of energy can be sold to the grid Table 2: Processing steps for the EN input sentence [ ... ] excess energy can be sold back to the grid. 4 Inflection prediction system To build the morphology-aware system, the targetside data (parallel and language model data) is transformed into a stemmed format, based on the annotation of a morphological tagger (Schmid and Laws, 2008). This representation contains translationrelevant feature markup: nouns are marked with gender (considered part of the stem) and number. Assuming that source-side nouns are translated by nouns with the same number value, this feature is indirectly determined by the source-side input. The number markup is thus needed to ensure that the source-side number information is transferred to the target side. For a better generalization, we split portmanteau prepositions into article and preposition (au → a` +le: to+the). For predicting the morphological features of the SMT output (number and gender),"
2014.eamt-1.3,schmid-etal-2004-smor,1,0.646479,"n CRFs on combinations of the wind corpus and the FR part of the parallel data. The CRF has access to the basic features stem and POS tag as well as gender and number within a window of 5 positions to each side of the current word. The morphological analysis of the French training data is obtained using RFTagger, which is designed for annotating fine-grained morphological tags (Schmid and Laws, 2008). For generating inflected forms based on stems and morphological features, we use an extended version of the finitestate morphology FRMOR (Zhou, 2007). FRMOR is a morphology tool similar to SMOR (Schmid et al., 2004), which allows to analyze and generate inflected word forms. The term alignment requires a general language dictionary6 from which we use the 36,963 1-to-1 entries. 8 7 Data and resources Our experiments are carried out on an EN-FR standard phrase-based Moses5 system which is adapted to the domain of wind energy. As a basis for terminology mining, we compiled a target-language corpus for that domain. This included documents obtained by automatic crawling (de Groc, 2011), and manually obtained data from various web-sites. In total, the corpus consists of 161.367 sentences (4.136.751 words). For"
2014.eamt-1.3,I08-2089,0,0.0267387,"features. However, this creates two new problems: first, the representation without number markup loses discriminatory power4 . For example, there is no way to guarantee subject-verb agreement without number information on nouns. The second problem is that parallel domain-specific data is needed to train the models for feature prediction. While we believe that removing number markup in the translation step is a sounder way to deal with targetside morphology in this application, we leave this extension of our model to future work due to the practical problems that arise with this. approach of Schwenk and Koehn (2008). For the feature prediction, we used the Wapiti toolkit (Lavergne et al., 2010) to train CRFs on combinations of the wind corpus and the FR part of the parallel data. The CRF has access to the basic features stem and POS tag as well as gender and number within a window of 5 positions to each side of the current word. The morphological analysis of the French training data is obtained using RFTagger, which is designed for annotating fine-grained morphological tags (Schmid and Laws, 2008). For generating inflected forms based on stems and morphological features, we use an extended version of the"
2014.eamt-1.3,P08-1059,0,0.0801463,"phrase table entries dynamically. Pinnis and Skadins (2012) also studied mining named entities, as well as using a high quality terminological database, and added these resources to the parallel training data. We compare these two options (XML vs. added parallel data) and show that adding the terms to the parallel training data leads to better results. To deal with the issue of obtaining the proper inflection of mined terms, we implemented a morphology-aware English to French translation system that separates the translation task into two steps (translation + inflection generation), following Toutanova et al. (2008) and Fraser et al. (2012). Formiga et al. (2012) use a component for targetside morphological generation to translate news and web-log data. In contrast to our work, they do not deal with nominal morphology, but model verb inflection: this is important for web-log data, as second-person verb forms rarely appear in Europarltype training data. Wu et al. (2008) use dictionary entries for adapting a system trained on Europarl to news, but without applying morphological modelling to their EN-FR system. Furthermore, news and also web-log data are considerably more similar to Europarl than technical"
2014.eamt-1.3,weller-heid-2012-analyzing,1,0.925147,"gligible role when translating under-resourced domains. 2 Related work There has been considerable interest in mining translations directly from comparable corpora. A few representative examples are (Daille and Morin, 2005; Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011; Prochasson and Fung, 2011), all 12 of which mine terms using distributional similarity. These approaches tend to favor recall over precision. In contrast, we use a high-precision method consisting in recognizing term candidates by means of partof-speech patterns with an alignment method relying on dictionary entries (Weller and Heid, 2012). A second strand of relevant work is the integration of terms into SMT decoding. H´alek et al. (2011) integrated named entity translations mined from Wikipedia using the XML mode of Moses, which creates new phrase table entries dynamically. Pinnis and Skadins (2012) also studied mining named entities, as well as using a high quality terminological database, and added these resources to the parallel training data. We compare these two options (XML vs. added parallel data) and show that adding the terms to the parallel training data leads to better results. To deal with the issue of obtaining t"
2014.eamt-1.3,C08-1125,0,0.0283419,"the issue of obtaining the proper inflection of mined terms, we implemented a morphology-aware English to French translation system that separates the translation task into two steps (translation + inflection generation), following Toutanova et al. (2008) and Fraser et al. (2012). Formiga et al. (2012) use a component for targetside morphological generation to translate news and web-log data. In contrast to our work, they do not deal with nominal morphology, but model verb inflection: this is important for web-log data, as second-person verb forms rarely appear in Europarltype training data. Wu et al. (2008) use dictionary entries for adapting a system trained on Europarl to news, but without applying morphological modelling to their EN-FR system. Furthermore, news and also web-log data are considerably more similar to Europarl than technical data. Our main contribution is that we show how to combine three areas of research: bilingual term mining, using terms in SMT, and generation of inflection for SMT. We describe a novel end-to-end morphology-aware solution for using bilingual term mining in SMT decoding. 3 Bilingual terminology mining In contrast to parallel corpora, which are difficult to ob"
2020.acl-main.389,P18-2049,0,0.0139965,"A] Stem with morph. analysis Umwelt&lt;NN&gt;Kriterium f¨ ur die&lt;Def&gt; ermitteln&lt;V&gt;ung&lt;NN&gt;&lt;SUFF&gt; Schutz&lt;NN&gt;bed¨ urftig&lt;Pos&gt; Meer&lt;NN&gt;Region in die&lt;Def&gt; tief&lt;Pos&gt;&lt;ADJ&gt;See inflected form Umweltkriterien f¨ur die Ermittlung schutzbed¨urftiger Meeresregionen in der Tiefsee gloss ecological criteria for the detection in need of protection marine regions in the open (lit: deep) sea Table 1: Representation of the training data for basic inflection prediction. Corresponding English sentence: (the ninth meeting should adopt) ecological criteria to determine marine regions in the open sea that need protection. Ataman and Federico (2018) forego a traditional morphological analysis of the source language, and instead compose word representations from character trigrams. However, these three papers only apply segmentation on the string level and cannot properly handle fusional morphology. Addressing morphology in NMT, Banerjee and Bhattacharyya (2018) combine BPE with a morphological analyzer to “guide” the segmentation of surface forms into substrings. Their approach does not result in morphemes, for example googling → googl|ing, which does not match with google, while in our work we match such morphemes. Tamchyna et al. (2017"
2020.acl-main.389,W18-1207,0,0.144044,"ed of protection marine regions in the open (lit: deep) sea Table 1: Representation of the training data for basic inflection prediction. Corresponding English sentence: (the ninth meeting should adopt) ecological criteria to determine marine regions in the open sea that need protection. Ataman and Federico (2018) forego a traditional morphological analysis of the source language, and instead compose word representations from character trigrams. However, these three papers only apply segmentation on the string level and cannot properly handle fusional morphology. Addressing morphology in NMT, Banerjee and Bhattacharyya (2018) combine BPE with a morphological analyzer to “guide” the segmentation of surface forms into substrings. Their approach does not result in morphemes, for example googling → googl|ing, which does not match with google, while in our work we match such morphemes. Tamchyna et al. (2017) present an NMT system to generate inflected forms on the target side, with a focus on overcoming data-sparsity caused by inflection. Their work contains a simple experiment on compound splitting with promising initial results that encouraged us to systematically explore word formation, including compounding, in NMT"
2020.acl-main.389,C04-1024,0,0.00947925,"t ∼750k sentences of Europarl. We use WMT’15 as dev-set (2169 sentences) and WMT’16 as test-set (2999 sentences). The lemma-tag approach doubles the sentence length by inserting tags. To avoid overly long sentences, the training data was first filtered to sentences of length 50, and after that, sentences more than 60 words long after BPE splitting were removed (e.g., sentences containing mostly foreign language words split nearly at character level). Data pre-processing The baseline was trained on plain surface forms (tokenized and true-cased). For the German lemma-tag system, we used BitPar (Schmid, 2004) to obtain morphological features in the sentence context, and SMOR (Schmid et al., 2004) for morphological analysis. For English, we used TreeTagger (Schmid, 1994). The English morphological analyzer for the small, medium and large2M systems was trained on the large2M data, the analyzer for the large4M system was trained on the full ∼4M lines. All systems (baseline and lemma-tag variants) underwent BPE segmentation (“joint” BPE of source/target side) with 30k merging operations. encoder decoder batch-type batch-size num-layers max-seq-len transformer transformer word 4096 6 max sent len initi"
2020.acl-main.389,D17-1209,0,0.0486254,"Missing"
2020.acl-main.389,schmid-etal-2004-smor,0,0.241829,"Missing"
2020.acl-main.389,E14-1061,1,0.832688,"ween source and target side for structurally different translations. 2 Related work There is a growing interest in the integration of linguistic information in NMT. For example, Eriguchi et al. (2016) and Bastings et al. (2017) demonstrate the positive impact of source-side syntactic information; N˘adejde et al. (2017) report improved translation quality when using syntactic information in form of CCG tags on source and target side. To address data sparsity, compound modeling has already been proved useful for phrase-based MT, e.g., Koehn and Knight (2003) who model source-side compounds, and Cap et al. (2014) who generate compounds on the target side. For NMT, Huck et al. (2017) apply compound and suffix segmentation using a stemmer. Ataman et al. (2017) reduce complex source-side vocabulary by means of an unsupervised morphology learning algorithm. 4227 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4227–4232 c July 5 - 10, 2020. 2020 Association for Computational Linguistics Morphological tag [NN-Neut.Acc.Pl.NA] [APPR-Acc] [ART-Fem.Acc.Sg.St] [NN-Fem.Acc.Sg.NA] [ADJ-NoGend.Gen.Pl.St] [NN-Fem.Gen.Pl.NA] [APPR-Dat] [ART-Fem.Dat.Sg.St] [NN-Fem.Dat.Sg."
2020.acl-main.389,P16-1078,0,0.0265702,"ical processing on the source and target side aims at learning productive word formation processes during translation, such as the English-German translation pair ungovernability↔Unregierbarkeit: un|PREF govern|V able|SUFF-ADJ ity|SUFF-NOUN ↔ un|PREF regieren|V bar|SUFF-ADJ keit|SUFF-NOUN Morphological information should not only handle isomorphic translation equivalents as above, but also help to uncover relations between source and target side for structurally different translations. 2 Related work There is a growing interest in the integration of linguistic information in NMT. For example, Eriguchi et al. (2016) and Bastings et al. (2017) demonstrate the positive impact of source-side syntactic information; N˘adejde et al. (2017) report improved translation quality when using syntactic information in form of CCG tags on source and target side. To address data sparsity, compound modeling has already been proved useful for phrase-based MT, e.g., Koehn and Knight (2003) who model source-side compounds, and Cap et al. (2014) who generate compounds on the target side. For NMT, Huck et al. (2017) apply compound and suffix segmentation using a stemmer. Ataman et al. (2017) reduce complex source-side vocabul"
2020.acl-main.389,P16-1162,0,0.0608268,"rmation. The best system variants employ source-side morphological analysis and model complex target-side words, improving over a standard system. 1 Introduction A major problem in word-level approaches to MT is a lack of morphological generalization. Both inflectional variants of the same lemma and derivations of a shared word stem are treated as unrelated. For morphologically complex languages with a large vocabulary, this is problematic, especially in lowresource or domain-adaption scenarios. A simple and widely used approach to reduce a large vocabulary in NMT is Byte Pair Encoding (BPE) (Sennrich et al., 2016), which iteratively merges the top-frequent bigrams from initially character-level split words until a set vocabulary size is reached. This strategy is effective, but linguistically uninformed and often leads to sub-optimal segmentation. Also, by only segmenting words into substrings, BPE cannot handle non-concatenative operations, for example: • umlautung: BaumSg → B¨aumeP l (tree/trees), • transitional elements that frequently occur in German compounds: Grenz|kontroll|politik → Grenze, Kontrolle (border control policy) • derivation: abundant ↔ abundance In this paper, we apply word segmentat"
2020.acl-main.389,W17-4704,1,0.908181,"Missing"
2020.acl-main.389,W17-1722,1,0.902864,"Missing"
2020.acl-main.389,E17-3017,0,0.0233279,"r for the large4M system was trained on the full ∼4M lines. All systems (baseline and lemma-tag variants) underwent BPE segmentation (“joint” BPE of source/target side) with 30k merging operations. encoder decoder batch-type batch-size num-layers max-seq-len transformer transformer word 4096 6 max sent len initial-learning-rate label-smoothing transf.-dropout-act transf.-dropout-attention transf.-dropout-prepost checkpoint-frequency 0.0002 0.1 0.1 0.1 0.1 3000 Table 6: Sockeye parameters for the Transformer model. Training For the experiments, we used a Transformer NMT model (Sockeye toolkit: Hieber et al. (2017)). Table 6 shows the training parameters. 6.1 System variants Table 5 shows different representation variants on the source and target side, as outlined in section 5. Generally, the lemma-tag systems are better than a standard NMT system; there is not much difference between the old (Tamchyna et al., 2017) and the new version (lines 2 and 3). Source-side lemma-tag pairs improve the small and medium settings when paired with non-split German data; split German data works better for the Large2M system. Both variants perform similarly for the Large4M system (lines 4 and 5). English word-internal"
2020.acl-main.389,W17-4706,1,0.870325,"Related work There is a growing interest in the integration of linguistic information in NMT. For example, Eriguchi et al. (2016) and Bastings et al. (2017) demonstrate the positive impact of source-side syntactic information; N˘adejde et al. (2017) report improved translation quality when using syntactic information in form of CCG tags on source and target side. To address data sparsity, compound modeling has already been proved useful for phrase-based MT, e.g., Koehn and Knight (2003) who model source-side compounds, and Cap et al. (2014) who generate compounds on the target side. For NMT, Huck et al. (2017) apply compound and suffix segmentation using a stemmer. Ataman et al. (2017) reduce complex source-side vocabulary by means of an unsupervised morphology learning algorithm. 4227 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4227–4232 c July 5 - 10, 2020. 2020 Association for Computational Linguistics Morphological tag [NN-Neut.Acc.Pl.NA] [APPR-Acc] [ART-Fem.Acc.Sg.St] [NN-Fem.Acc.Sg.NA] [ADJ-NoGend.Gen.Pl.St] [NN-Fem.Gen.Pl.NA] [APPR-Dat] [ART-Fem.Dat.Sg.St] [NN-Fem.Dat.Sg.NA] Stem with morph. analysis Umwelt&lt;NN&gt;Kriterium f¨ ur die&lt;Def&gt; ermitt"
2020.acl-main.389,E03-1076,0,0.45762,"equivalents as above, but also help to uncover relations between source and target side for structurally different translations. 2 Related work There is a growing interest in the integration of linguistic information in NMT. For example, Eriguchi et al. (2016) and Bastings et al. (2017) demonstrate the positive impact of source-side syntactic information; N˘adejde et al. (2017) report improved translation quality when using syntactic information in form of CCG tags on source and target side. To address data sparsity, compound modeling has already been proved useful for phrase-based MT, e.g., Koehn and Knight (2003) who model source-side compounds, and Cap et al. (2014) who generate compounds on the target side. For NMT, Huck et al. (2017) apply compound and suffix segmentation using a stemmer. Ataman et al. (2017) reduce complex source-side vocabulary by means of an unsupervised morphology learning algorithm. 4227 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4227–4232 c July 5 - 10, 2020. 2020 Association for Computational Linguistics Morphological tag [NN-Neut.Acc.Pl.NA] [APPR-Acc] [ART-Fem.Acc.Sg.St] [NN-Fem.Acc.Sg.NA] [ADJ-NoGend.Gen.Pl.St] [NN-Fem.Ge"
2020.amta-research.8,D18-1214,0,0.0209725,"predicting the top-1 or top-5 most similar words as translations. In order to evaluate our approach intrinsically, we created a test lexicon as is usually done in BLI, but our test lexicon has single words and their bigram translations. Recent work showed that building BWEs is possible without any bilingual signal. Adversarial training was used to rotate the source space to match the target in order to extract an initial seed lexicon which is used to fine-tune the projection (Conneau et al., 2018). Others used word neighborhood information to create the initial mapping (Artetxe et al., 2018a; Alvarez-Melis and Jaakkola, 2018). All these works led to the possibility of building MT systems without parallel data which are based on the word translation capabilities of unsupervised BWEs and back-translation of large monolingual data (Sennrich et al., 2016). Systems based on both neural network approaches (Lample et al., 2018a; Artetxe et al., 2018c; Yang et al., 2018) and phrase-based SMT (Lample et al., 2018b; Artetxe et al., 2018b) were proposed. We evaluate our approach on the downstream task of UMT as well by extending the approach of (Artetxe et al., 2018b), showing translation quality improvements. An important s"
2020.amta-research.8,P18-1073,0,0.0725052,"stream task of unsupervised machine translation and show small but significant BLEU score improvements with our approach. Our approach is an important first step in the direction of handling composition in BWEs, beyond simple memorization of seen bigrams. 1 Introduction Bilingual word embeddings (BWEs) are key components in cross-lingual NLP tasks alleviating data scarcity for many languages. They can be built using source and target language monolingual corpora with either a cheap bilingual signal (Mikolov et al., 2013b; Xing et al., 2015) or no bilingual signal at all (Conneau et al., 2018; Artetxe et al., 2018a). They are applied to many downstream tasks, such as bilingual lexicon induction (BLI) (Vuli´c and Korhonen, 2016) and cross-lingual transfer learning (Schuster et al., 2019). Unsupervised machine translation (UMT) strongly depends on BWEs. Meaningful translations can be generated without any bilingual signal by using BWEs to translate words 1-to-1. However, many words in a given language are the composition of multiple smaller lexical units which are expressed individually in other languages, such as the German compound Waschmaschine → washing machine. Using the idea of atomic embeddings fo"
2020.amta-research.8,D18-1399,0,0.08496,"stream task of unsupervised machine translation and show small but significant BLEU score improvements with our approach. Our approach is an important first step in the direction of handling composition in BWEs, beyond simple memorization of seen bigrams. 1 Introduction Bilingual word embeddings (BWEs) are key components in cross-lingual NLP tasks alleviating data scarcity for many languages. They can be built using source and target language monolingual corpora with either a cheap bilingual signal (Mikolov et al., 2013b; Xing et al., 2015) or no bilingual signal at all (Conneau et al., 2018; Artetxe et al., 2018a). They are applied to many downstream tasks, such as bilingual lexicon induction (BLI) (Vuli´c and Korhonen, 2016) and cross-lingual transfer learning (Schuster et al., 2019). Unsupervised machine translation (UMT) strongly depends on BWEs. Meaningful translations can be generated without any bilingual signal by using BWEs to translate words 1-to-1. However, many words in a given language are the composition of multiple smaller lexical units which are expressed individually in other languages, such as the German compound Waschmaschine → washing machine. Using the idea of atomic embeddings fo"
2020.amta-research.8,D18-1549,0,0.0788703,"stream task of unsupervised machine translation and show small but significant BLEU score improvements with our approach. Our approach is an important first step in the direction of handling composition in BWEs, beyond simple memorization of seen bigrams. 1 Introduction Bilingual word embeddings (BWEs) are key components in cross-lingual NLP tasks alleviating data scarcity for many languages. They can be built using source and target language monolingual corpora with either a cheap bilingual signal (Mikolov et al., 2013b; Xing et al., 2015) or no bilingual signal at all (Conneau et al., 2018; Artetxe et al., 2018a). They are applied to many downstream tasks, such as bilingual lexicon induction (BLI) (Vuli´c and Korhonen, 2016) and cross-lingual transfer learning (Schuster et al., 2019). Unsupervised machine translation (UMT) strongly depends on BWEs. Meaningful translations can be generated without any bilingual signal by using BWEs to translate words 1-to-1. However, many words in a given language are the composition of multiple smaller lexical units which are expressed individually in other languages, such as the German compound Waschmaschine → washing machine. Using the idea of atomic embeddings fo"
2020.amta-research.8,W18-6407,0,0.0406327,"Missing"
2020.amta-research.8,D16-1136,0,0.0213873,"source words. In addition, we show the importance of the system for UMT by including our approach in the pipeline of the UMT system of Artetxe et al. (2018b) and show its positive effects on translation quality. 2 Related Work Bilingual word embeddings became popular resources for many cross-lingual NLP tasks since they allow the transfer of knowledge from a source language to a target language. Various approaches were proposed. Gouws et al. (2015) rely on parallel corpora, while others create artificial cross-lingual corpora using seed lexicons or document alignments (Vuli´c and Moens, 2015; Duong et al., 2016). Following Mikolov et al. (2013b), many authors map monolingual word embeddings (MWEs) into shared bilingual spaces (Faruqui and Dyer, 2014; Xing et al., 2015) because only a weak bilingual signal in the form of a seed lexicon is needed. Bilingual Lexicon Induction (BLI) is often used as the intrinsic evaluation of BWE spaces (Mikolov et al., 2013b; Vuli´c and Korhonen, 2016), where the task is to translate individual source language Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 1: MT Research Track Page 90 words to a"
2020.amta-research.8,W10-1734,1,0.827908,"Missing"
2020.amta-research.8,W11-2123,0,0.00863198,"amine the effects of BWEs on MT, we extend the statistical UMT system of (Artetxe et al., 2018b) which strongly relies on BWEs. By default it is comprised of 5 consecutive steps. In step 1 it builds MWEs containing atomic representations for 1-, 2- and 3-grams and projects them to shared BWE spaces in step 2 with the same method as the basis of our system for the BPLI experiments described above. The Moses statistical MT system is used as the translation system (Koehn et al., 2007) which requires two components in this case: a language model and a phrase-table. The former is built with KenLM (Heafield, 2011) while the latter contains phrase translation pairs and their scores for each source word and the 100 most similar target words which are calculated using cosine similarity in step 3. The weights of the two components are tuned in step 4 on a synthetic parallel corpus generated through back-translation and MERT is applied as the tuning algorithm. Finally, in step 5 the system is iteratively refined (for 3 iterations) using back-translation of monolingual data. We use this off-the-shelf system as one of our baselines which we call atomic since it uses atomic n-gram embeddings. In addition, we r"
2020.amta-research.8,P07-2045,0,0.005404,"on unsupervised MT (Lample et al., 2018b; Artetxe et al., 2018b). We additionally evaluate on WMT 2019 (Barrault et al., 2019). To examine the effects of BWEs on MT, we extend the statistical UMT system of (Artetxe et al., 2018b) which strongly relies on BWEs. By default it is comprised of 5 consecutive steps. In step 1 it builds MWEs containing atomic representations for 1-, 2- and 3-grams and projects them to shared BWE spaces in step 2 with the same method as the basis of our system for the BPLI experiments described above. The Moses statistical MT system is used as the translation system (Koehn et al., 2007) which requires two components in this case: a language model and a phrase-table. The former is built with KenLM (Heafield, 2011) while the latter contains phrase translation pairs and their scores for each source word and the 100 most similar target words which are calculated using cosine similarity in step 3. The weights of the two components are tuned in step 4 on a synthetic parallel corpus generated through back-translation and MERT is applied as the tuning algorithm. Finally, in step 5 the system is iteratively refined (for 3 iterations) using back-translation of monolingual data. We use"
2020.amta-research.8,N19-1162,0,0.0207997,"tion of handling composition in BWEs, beyond simple memorization of seen bigrams. 1 Introduction Bilingual word embeddings (BWEs) are key components in cross-lingual NLP tasks alleviating data scarcity for many languages. They can be built using source and target language monolingual corpora with either a cheap bilingual signal (Mikolov et al., 2013b; Xing et al., 2015) or no bilingual signal at all (Conneau et al., 2018; Artetxe et al., 2018a). They are applied to many downstream tasks, such as bilingual lexicon induction (BLI) (Vuli´c and Korhonen, 2016) and cross-lingual transfer learning (Schuster et al., 2019). Unsupervised machine translation (UMT) strongly depends on BWEs. Meaningful translations can be generated without any bilingual signal by using BWEs to translate words 1-to-1. However, many words in a given language are the composition of multiple smaller lexical units which are expressed individually in other languages, such as the German compound Waschmaschine → washing machine. Using the idea of atomic embeddings for frequent bigrams (Mikolov et al., 2013c) previous work proposed 1-to-2 word translations achieving significant improvements in UMT (Lample et al., 2018b; Artetxe et al., 2018"
2020.amta-research.8,P16-1009,0,0.534781,"order to improve translation of rare words by decomposing source language unigrams to two target words. Given the embedding of a unigram (Cocabauern) we infer two word vectors which we decode to a bigram (coca farmers) by looking for the nearest neighbors of the generated vectors. This way we omit the need for atomic bigram representations on the target side learned in advance and allow the generation of previously unseen bigrams. We employ a multi-layer neural network relying only on unsupervised BWEs and generate cross-lingual training examples using atomic embeddings and back-translation (Sennrich et al., 2016). In addition, we create monolingual examples having a target language bigram as the input and its unigram components as the output, i.e., these examples teach the system to map the atomic embedding of a bigram like “corn farmers” to the two representations of “corn” and “farmers”, which monolingually mimics the cross-lingual translation task. Similarly to auto-encoding based approach, we can generate these monolingual examples easily which are useful for the bilingual task as well since the BWEs on which our system relies represent source and target language words with similar vectors. We tes"
2020.amta-research.8,P16-1024,0,0.0689492,"Missing"
2020.amta-research.8,P15-2118,0,0.0675545,"Missing"
2020.amta-research.8,N15-1104,0,0.188043,"mproves performance. We also show the importance of bigrams for the downstream task of unsupervised machine translation and show small but significant BLEU score improvements with our approach. Our approach is an important first step in the direction of handling composition in BWEs, beyond simple memorization of seen bigrams. 1 Introduction Bilingual word embeddings (BWEs) are key components in cross-lingual NLP tasks alleviating data scarcity for many languages. They can be built using source and target language monolingual corpora with either a cheap bilingual signal (Mikolov et al., 2013b; Xing et al., 2015) or no bilingual signal at all (Conneau et al., 2018; Artetxe et al., 2018a). They are applied to many downstream tasks, such as bilingual lexicon induction (BLI) (Vuli´c and Korhonen, 2016) and cross-lingual transfer learning (Schuster et al., 2019). Unsupervised machine translation (UMT) strongly depends on BWEs. Meaningful translations can be generated without any bilingual signal by using BWEs to translate words 1-to-1. However, many words in a given language are the composition of multiple smaller lexical units which are expressed individually in other languages, such as the German compou"
2020.amta-research.8,D15-1201,0,0.146047,"le learning n-gram embeddings. We give more details about this approach in the following section since we rely on this system in our experiments. On the other hand, the problem of these approaches is that a large amount of monolingual data is required in order to mine frequent bigrams and to learn good quality embeddings for them. Del et al. (2018) alleviated the problem by inferring bigram embeddings by composing the representations of their unigram components. Various composition functions were tested, such as simple addition of vectors or learning a linear projection. Following the work of Yazdani et al. (2015), they use atomic bigram embeddings and the representations of their unigram components as training samples to learn the composition function. However it is not feasible to compose each pair of unigrams in the vocabulary due to their large number, thus the approach considers only those bigram candidates which occur in the input monolingual corpora, typically leading to OOV target bigrams in the case of rare source words. Our approach alleviates these problems by extending previous systems with a decomposition based module for better rare word translation which is able to generate previously un"
2020.bucc-1.8,P19-1309,0,0.0951046,"Missing"
2020.bucc-1.8,P18-1073,0,0.144567,"e monolingual corpora, and training and testing dictionaries for high, middle and low frequency words. In this paper, we present our approach to the shared task and show results on English-German and English-Russian. BWEs are popular for solving BDI by calculating cosine similarity of word pairs and taking the n most similar candidates as translations for a given source word. They were shown to be very effective for the task using a small seed lexicon only (e.g., (Mikolov et al., 2013b)) as opposed to MT based approaches where parallel data is necessary. In addition, Conneau et al. (2018) and Artetxe et al. (2018) were able to learn BWEs without any seed dictionaries using a self-learning method that starts from an initial weak solution and improves the mapping iteratively. Due to this, BDI is one of the building blocks of unsupervised MT and are particularly relevant in low-resource settings (Artetxe et ∗ The authors contributed equally to this manuscript. 49 signal. We test our system on the English-German pairs (En-De, De-En) and English-Russian pairs (En-Ru, Ru-En) provided in the BUCC 2020 Shared Task (Rapp et al., 2020). We participate in both the open and closed tracks of the shared tasks, using"
2020.bucc-1.8,P19-1019,0,0.112307,"Missing"
2020.bucc-1.8,Q17-1010,0,0.532253,"results. 2. and German. On the other hand, for English and Russian the approach is not applicable due to the different character sets of the two languages, thus we employ an unsupervised transliteration model. 3.1. To build BWEs we follow the mapping approach of (Mikolov et al., 2013b), i.e., we build monolingual word embeddings (MWEs) which we then align to a share space using a seed dictionary. We create 4 types of MWE models for each language, since it was shown that combining them is beneficial for BDI (Braune et al., 2018): {word2vec, f asttext} × {cbow, skipgram} (Mikolov et al., 2013a; Bojanowski et al., 2017). We perform the mapping using VecMap (Artetxe et al., 2018) which learns an orthogonal projection of the source MWE to the target space. Although the approach supports unsupervised mapping, we use it in a supervised setup. As the seed lexicon, we use part of the provided high frequency dictionary. Although the dictionary contains multiple translations for some source words, we only use the first translation of each word in order to reduce noise. Finally, we generate a similarity dictionary based on each BWE type containing translation candidates, i.e., the 100 most similar target language wor"
2020.bucc-1.8,N18-2030,1,0.821236,"ource word. We participate in both the open and closed tracks of the shared task and we show improved results of our method compared to simple vector similarity based approaches. Our system was ranked in the top-3 teams and achieved the best results for English-Russian. Keywords: BDI, BWE, Orthography, Transliteration 1. Introduction al., 2019; Lample et al., 2018). Although BWE based methods work well for translating high frequency words, it was shown that they tend to have low performance when translating low-frequency words or named entities due to poor vector representation of such words (Braune et al., 2018; Riley and Gildea, 2018; Czarnowska et al., 2019). By using character n-gram representations and Levenshtein similarity of words, Braune et al. (2018) showed improved results on rare and domain specific words. Similarly, Riley and Gildea (2018) improves the translation of such words by integrating orthographic information into the vector representation of words and in the mapping procedure of BWEs. On the other hand, these techniques are only applicable in the case of language pairs having the same scripts. Recently, Riley and Gildea (2020) proposed an unsupervised system based on expectation"
2020.bucc-1.8,D14-1179,0,0.00580683,"Missing"
2020.bucc-1.8,D19-1090,0,0.158141,"nd closed tracks of the shared task and we show improved results of our method compared to simple vector similarity based approaches. Our system was ranked in the top-3 teams and achieved the best results for English-Russian. Keywords: BDI, BWE, Orthography, Transliteration 1. Introduction al., 2019; Lample et al., 2018). Although BWE based methods work well for translating high frequency words, it was shown that they tend to have low performance when translating low-frequency words or named entities due to poor vector representation of such words (Braune et al., 2018; Riley and Gildea, 2018; Czarnowska et al., 2019). By using character n-gram representations and Levenshtein similarity of words, Braune et al. (2018) showed improved results on rare and domain specific words. Similarly, Riley and Gildea (2018) improves the translation of such words by integrating orthographic information into the vector representation of words and in the mapping procedure of BWEs. On the other hand, these techniques are only applicable in the case of language pairs having the same scripts. Recently, Riley and Gildea (2020) proposed an unsupervised system based on expectation maximization and character-level RNN models to le"
2020.bucc-1.8,P19-1581,1,0.822411,"pervised transliteration model. In contrast to (Riley and Gildea, 2020), we propose a cleaning method for filtering non-transliteration pairs from the used dictionary before training the model to ensure a less noisy training Bilingual Dictionary Induction is the task of inducing word translations from monolingual corpora in different languages. It has been studied extensively as it is one of the main tasks used for evaluating the quality of BWE models (Mikolov et al., 2013b; Vulic and Korhonen, 2016). It is also important for downstream tasks such as translating out-of-vocabulary words in MT (Huck et al., 2019). Although there is a large amount of work for BDI, there is no standard way to measure the performance of the systems, the published results are not comparable and the pros and cons of the various approaches are not clear. The aim of the BUCC 2020 – Bilingual Dictionary Induction from Comparable Corpora – shared task (Rapp et al., 2020) is to solve this problem and compare various systems on a standard test set. It involves multiple language pairs including Chinese, English, French, German, Russian and Spanish and supports comparable monolingual corpora, and training and testing dictionaries"
2020.bucc-1.8,D18-1549,0,0.0299977,"similarity with word surface similarity methods, such as orthography and transliteration information. In addition to the often used top-n translation method, we experiment with a margin based approach aiming for dynamic number of translations for each source word. We participate in both the open and closed tracks of the shared task and we show improved results of our method compared to simple vector similarity based approaches. Our system was ranked in the top-3 teams and achieved the best results for English-Russian. Keywords: BDI, BWE, Orthography, Transliteration 1. Introduction al., 2019; Lample et al., 2018). Although BWE based methods work well for translating high frequency words, it was shown that they tend to have low performance when translating low-frequency words or named entities due to poor vector representation of such words (Braune et al., 2018; Riley and Gildea, 2018; Czarnowska et al., 2019). By using character n-gram representations and Levenshtein similarity of words, Braune et al. (2018) showed improved results on rare and domain specific words. Similarly, Riley and Gildea (2018) improves the translation of such words by integrating orthographic information into the vector represe"
2020.bucc-1.8,D15-1166,0,0.246365,"Missing"
2020.bucc-1.8,P18-2062,0,0.499995,"ipate in both the open and closed tracks of the shared task and we show improved results of our method compared to simple vector similarity based approaches. Our system was ranked in the top-3 teams and achieved the best results for English-Russian. Keywords: BDI, BWE, Orthography, Transliteration 1. Introduction al., 2019; Lample et al., 2018). Although BWE based methods work well for translating high frequency words, it was shown that they tend to have low performance when translating low-frequency words or named entities due to poor vector representation of such words (Braune et al., 2018; Riley and Gildea, 2018; Czarnowska et al., 2019). By using character n-gram representations and Levenshtein similarity of words, Braune et al. (2018) showed improved results on rare and domain specific words. Similarly, Riley and Gildea (2018) improves the translation of such words by integrating orthographic information into the vector representation of words and in the mapping procedure of BWEs. On the other hand, these techniques are only applicable in the case of language pairs having the same scripts. Recently, Riley and Gildea (2020) proposed an unsupervised system based on expectation maximization and charac"
2020.bucc-1.8,P16-1024,0,0.38169,"th different scripts where an orthographic comparison would not be possible and it is obtained from our novel fully unsupervised transliteration model. In contrast to (Riley and Gildea, 2020), we propose a cleaning method for filtering non-transliteration pairs from the used dictionary before training the model to ensure a less noisy training Bilingual Dictionary Induction is the task of inducing word translations from monolingual corpora in different languages. It has been studied extensively as it is one of the main tasks used for evaluating the quality of BWE models (Mikolov et al., 2013b; Vulic and Korhonen, 2016). It is also important for downstream tasks such as translating out-of-vocabulary words in MT (Huck et al., 2019). Although there is a large amount of work for BDI, there is no standard way to measure the performance of the systems, the published results are not comparable and the pros and cons of the various approaches are not clear. The aim of the BUCC 2020 – Bilingual Dictionary Induction from Comparable Corpora – shared task (Rapp et al., 2020) is to solve this problem and compare various systems on a standard test set. It involves multiple language pairs including Chinese, English, French"
2020.coling-main.531,P19-1309,0,0.146474,"NEWS transliteration shared task has been a continuous effort to promote research on this task since 2009 (Li et al., 2009; Chen et al., 2018). A fully unsupervised transliteration model was proposed by Sajjad et al. (2017); it consists of interpolated statistical sub-models for transliteration and non-transliteration detection. In this work we follow a similar idea and propose an unsupervised neural network based system to look for transliteration pairs of source words as possible translation candidates. We also use this system to build BOEs of words. In a parallel sentence mining approach, Artetxe and Schwenk (2019) use a shared encoder and decoder for all languages to build a language agnostic sentence encoder. They use the encoder representations as sentence embeddings to efficiently mine parallel sentences. Similarly, our BOEs are extracted from a single language agnostic encoder, for both English and Russian. In an ablation study, we check the quality of our BOEs on the NEWS 2010 shared task (Kumaran et al., 2010); see below. 3 Approach To tackle the BDI task we exploit BWEs, character-level information (in the form of BOEs) and manually engineered features – such as word frequency and length – and i"
2020.coling-main.531,P17-1042,0,0.0246018,"1 Introduction The task of Bilingual Dictionary Induction is defined as finding target language translations of source language words. It is an important building block in the area of Machine Translation (MT) and it is one of the main tasks for bilingual word embedding evaluation (Mikolov et al., 2013b; Vulic and Korhonen, 2016). Recent work shows that good performance can be achieved relying only on BWEs, which can be built with only a weak bilingual signal, such as a small seed lexicon of a few thousand word pairs (Mikolov et al., 2013b) or common tokens in the source and target languages (Artetxe et al., 2017). In addition, they can even be built without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018), making them the basis of unsupervised MT systems (Lample et al., 2018; Artetxe et al., 2019). Standard BDI learns word representations based on approaches that exploit solely word-level information such as word2vec (Mikolov et al., 2013a) or fasttext (Bojanowski et al., 2017) and then map them to a shared BWE space. Although BWE-based approaches show high BDI performance, they struggle with a subset of hard-to-translate words such as named entities for which orthographic information"
2020.coling-main.531,P18-1073,0,0.338793,"f source language words. It is an important building block in the area of Machine Translation (MT) and it is one of the main tasks for bilingual word embedding evaluation (Mikolov et al., 2013b; Vulic and Korhonen, 2016). Recent work shows that good performance can be achieved relying only on BWEs, which can be built with only a weak bilingual signal, such as a small seed lexicon of a few thousand word pairs (Mikolov et al., 2013b) or common tokens in the source and target languages (Artetxe et al., 2017). In addition, they can even be built without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018), making them the basis of unsupervised MT systems (Lample et al., 2018; Artetxe et al., 2019). Standard BDI learns word representations based on approaches that exploit solely word-level information such as word2vec (Mikolov et al., 2013a) or fasttext (Bojanowski et al., 2017) and then map them to a shared BWE space. Although BWE-based approaches show high BDI performance, they struggle with a subset of hard-to-translate words such as named entities for which orthographic information should be used instead of semantic information. Several approaches have integrated orthographic information in"
2020.coling-main.531,P19-1019,0,0.0860492,"(MT) and it is one of the main tasks for bilingual word embedding evaluation (Mikolov et al., 2013b; Vulic and Korhonen, 2016). Recent work shows that good performance can be achieved relying only on BWEs, which can be built with only a weak bilingual signal, such as a small seed lexicon of a few thousand word pairs (Mikolov et al., 2013b) or common tokens in the source and target languages (Artetxe et al., 2017). In addition, they can even be built without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018), making them the basis of unsupervised MT systems (Lample et al., 2018; Artetxe et al., 2019). Standard BDI learns word representations based on approaches that exploit solely word-level information such as word2vec (Mikolov et al., 2013a) or fasttext (Bojanowski et al., 2017) and then map them to a shared BWE space. Although BWE-based approaches show high BDI performance, they struggle with a subset of hard-to-translate words such as named entities for which orthographic information should be used instead of semantic information. Several approaches have integrated orthographic information into the BDI system. Heyman et al. (2017) relied on character-level information in their classif"
2020.coling-main.531,Q17-1010,0,0.232504,"ed relying only on BWEs, which can be built with only a weak bilingual signal, such as a small seed lexicon of a few thousand word pairs (Mikolov et al., 2013b) or common tokens in the source and target languages (Artetxe et al., 2017). In addition, they can even be built without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018), making them the basis of unsupervised MT systems (Lample et al., 2018; Artetxe et al., 2019). Standard BDI learns word representations based on approaches that exploit solely word-level information such as word2vec (Mikolov et al., 2013a) or fasttext (Bojanowski et al., 2017) and then map them to a shared BWE space. Although BWE-based approaches show high BDI performance, they struggle with a subset of hard-to-translate words such as named entities for which orthographic information should be used instead of semantic information. Several approaches have integrated orthographic information into the BDI system. Heyman et al. (2017) relied on character-level information in their classification based BDI system by using an RNN architecture. Braune et al. (2018) combined orthographic information with BWE-based word similarity information using an ensembling method. Bot"
2020.coling-main.531,N18-2030,1,0.893548,"roaches that exploit solely word-level information such as word2vec (Mikolov et al., 2013a) or fasttext (Bojanowski et al., 2017) and then map them to a shared BWE space. Although BWE-based approaches show high BDI performance, they struggle with a subset of hard-to-translate words such as named entities for which orthographic information should be used instead of semantic information. Several approaches have integrated orthographic information into the BDI system. Heyman et al. (2017) relied on character-level information in their classification based BDI system by using an RNN architecture. Braune et al. (2018) combined orthographic information with BWE-based word similarity information using an ensembling method. Both of these approaches showed improved results, but they relied on Levenshtein distance to get translation candidates for a source word during prediction, which is not applicable for language pairs with different scripts. To bridge the gap between languages with different scripts, a transliteration system was employed by Severini et al. (2020). They followed the approach of Braune et al. (2018) but used the transliteration system instead of Levenshtein distance to get candidates used in"
2020.coling-main.531,W18-2409,0,0.020488,"rvine and Callison-Burch (2017) applied Levenshtein distance to language pairs with different 6045 alphabets by first transliterating from non-Latin to Latin scripts. In contrast, we use a novel transliteration model that encodes the relevant information directly into BOEs without requiring a separate transliteration step. 2.2 Transliteration As motivated above, transliteration mining is an important task that bridges the gap between languages with different scripts. The NEWS transliteration shared task has been a continuous effort to promote research on this task since 2009 (Li et al., 2009; Chen et al., 2018). A fully unsupervised transliteration model was proposed by Sajjad et al. (2017); it consists of interpolated statistical sub-models for transliteration and non-transliteration detection. In this work we follow a similar idea and propose an unsupervised neural network based system to look for transliteration pairs of source words as possible translation candidates. We also use this system to build BOEs of words. In a parallel sentence mining approach, Artetxe and Schwenk (2019) use a shared encoder and decoder for all languages to build a language agnostic sentence encoder. They use the encod"
2020.coling-main.531,D19-1090,0,0.0114955,"ective when only a small seed lexicon is provided (e.g., (Mikolov et al., 2013b)). Conneau et al. (2018) and Artetxe et al. (2018) dispense with seed dictionaries and iteratively improve the mapping from an initial weak solution in a self-learning approach. This setting provides a building block for unsupervised MT and is particularly effective in the low-resource setting where less parallel seed data is available (Artetxe et al., 2019; Lample et al., 2018). BWE-based methods perform worse for low frequency words due to poor vector representations (Braune et al., 2018; Riley and Gildea, 2018; Czarnowska et al., 2019). Koehn and Knight (2002) and Haghighi et al. (2008) show that orthographic features help in the translation process. Languages with a common alphabet (e.g., English/German) often have word pairs with similar orthography (e.g., Concepts/Konzepte, Philosophies/Philosophien), especially in the case of low frequency words. Riley and Gildea (2018) integrate orthographic information into the vector representation of such words and into the mapping procedure of BWEs to improve their quality. Braune et al. (2018) use character n-gram representations and Levenshtein distance to improve BDI while Heyma"
2020.coling-main.531,P08-1088,0,0.0750546,"., (Mikolov et al., 2013b)). Conneau et al. (2018) and Artetxe et al. (2018) dispense with seed dictionaries and iteratively improve the mapping from an initial weak solution in a self-learning approach. This setting provides a building block for unsupervised MT and is particularly effective in the low-resource setting where less parallel seed data is available (Artetxe et al., 2019; Lample et al., 2018). BWE-based methods perform worse for low frequency words due to poor vector representations (Braune et al., 2018; Riley and Gildea, 2018; Czarnowska et al., 2019). Koehn and Knight (2002) and Haghighi et al. (2008) show that orthographic features help in the translation process. Languages with a common alphabet (e.g., English/German) often have word pairs with similar orthography (e.g., Concepts/Konzepte, Philosophies/Philosophien), especially in the case of low frequency words. Riley and Gildea (2018) integrate orthographic information into the vector representation of such words and into the mapping procedure of BWEs to improve their quality. Braune et al. (2018) use character n-gram representations and Levenshtein distance to improve BDI while Heyman et al. (2017) extract this feature automatically f"
2020.coling-main.531,E17-1102,0,0.0376756,"Missing"
2020.coling-main.531,J17-2001,0,0.0196008,"hographic information into the vector representation of such words and into the mapping procedure of BWEs to improve their quality. Braune et al. (2018) use character n-gram representations and Levenshtein distance to improve BDI while Heyman et al. (2017) extract this feature automatically from training data. In languages with different scripts (e.g., English/Russian), the source word is often written with the closest corresponding letters of the target alphabet, i.e., it is transliterated. Richard/Ричард and integrator/интегратор are examples of transliterations between English and Russian. Irvine and Callison-Burch (2017) applied Levenshtein distance to language pairs with different 6045 alphabets by first transliterating from non-Latin to Latin scripts. In contrast, we use a novel transliteration model that encodes the relevant information directly into BOEs without requiring a separate transliteration step. 2.2 Transliteration As motivated above, transliteration mining is an important task that bridges the gap between languages with different scripts. The NEWS transliteration shared task has been a continuous effort to promote research on this task since 2009 (Li et al., 2009; Chen et al., 2018). A fully uns"
2020.coling-main.531,W10-2405,0,0.0951717,"Missing"
2020.coling-main.531,2020.acl-main.618,0,0.0951141,"Missing"
2020.coling-main.531,W02-0902,0,0.282156,"eed lexicon is provided (e.g., (Mikolov et al., 2013b)). Conneau et al. (2018) and Artetxe et al. (2018) dispense with seed dictionaries and iteratively improve the mapping from an initial weak solution in a self-learning approach. This setting provides a building block for unsupervised MT and is particularly effective in the low-resource setting where less parallel seed data is available (Artetxe et al., 2019; Lample et al., 2018). BWE-based methods perform worse for low frequency words due to poor vector representations (Braune et al., 2018; Riley and Gildea, 2018; Czarnowska et al., 2019). Koehn and Knight (2002) and Haghighi et al. (2008) show that orthographic features help in the translation process. Languages with a common alphabet (e.g., English/German) often have word pairs with similar orthography (e.g., Concepts/Konzepte, Philosophies/Philosophien), especially in the case of low frequency words. Riley and Gildea (2018) integrate orthographic information into the vector representation of such words and into the mapping procedure of BWEs to improve their quality. Braune et al. (2018) use character n-gram representations and Levenshtein distance to improve BDI while Heyman et al. (2017) extract t"
2020.coling-main.531,W10-2404,0,0.281312,"0 shared task (Rapp et al., 2020). Test dictionaries were released in three frequency categories: high, middle and low. We evaluate our system on all three sets, both separately and jointly, and show improved performance on all three frequency ranges compared with previous approaches. Furthermore, we show that our classification system is more robust than the ensembling of Severini et al. (2020), which required specialized tuning on each frequency set. Lastly, we conduct a further analysis of the quality of the proposed BOEs by running transliteration mining on the NEWS 2010 shared task data (Kumaran et al., 2010) by using the vector similarity of Bilingual Orthographic Embeddings of words. We show good performance on the task indicating the usefulness of BOEs for other downstream tasks. 2 2.1 Related Work Bilingual Dictionary Induction BWEs are often used for solving BDI tasks by calculating cosine similarity of word pairs and taking the n most similar target candidates as translations for a source word. As opposed to general MT based approaches that rely on parallel sentences, BWEs are also effective when only a small seed lexicon is provided (e.g., (Mikolov et al., 2013b)). Conneau et al. (2018) and"
2020.coling-main.531,D18-1549,0,0.100146,"Machine Translation (MT) and it is one of the main tasks for bilingual word embedding evaluation (Mikolov et al., 2013b; Vulic and Korhonen, 2016). Recent work shows that good performance can be achieved relying only on BWEs, which can be built with only a weak bilingual signal, such as a small seed lexicon of a few thousand word pairs (Mikolov et al., 2013b) or common tokens in the source and target languages (Artetxe et al., 2017). In addition, they can even be built without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018), making them the basis of unsupervised MT systems (Lample et al., 2018; Artetxe et al., 2019). Standard BDI learns word representations based on approaches that exploit solely word-level information such as word2vec (Mikolov et al., 2013a) or fasttext (Bojanowski et al., 2017) and then map them to a shared BWE space. Although BWE-based approaches show high BDI performance, they struggle with a subset of hard-to-translate words such as named entities for which orthographic information should be used instead of semantic information. Several approaches have integrated orthographic information into the BDI system. Heyman et al. (2017) relied on character-level infor"
2020.coling-main.531,W09-3501,0,0.0498586,"sh and Russian. Irvine and Callison-Burch (2017) applied Levenshtein distance to language pairs with different 6045 alphabets by first transliterating from non-Latin to Latin scripts. In contrast, we use a novel transliteration model that encodes the relevant information directly into BOEs without requiring a separate transliteration step. 2.2 Transliteration As motivated above, transliteration mining is an important task that bridges the gap between languages with different scripts. The NEWS transliteration shared task has been a continuous effort to promote research on this task since 2009 (Li et al., 2009; Chen et al., 2018). A fully unsupervised transliteration model was proposed by Sajjad et al. (2017); it consists of interpolated statistical sub-models for transliteration and non-transliteration detection. In this work we follow a similar idea and propose an unsupervised neural network based system to look for transliteration pairs of source words as possible translation candidates. We also use this system to build BOEs of words. In a parallel sentence mining approach, Artetxe and Schwenk (2019) use a shared encoder and decoder for all languages to build a language agnostic sentence encoder"
2020.coling-main.531,D15-1166,0,0.016458,"requent words such as named entities, we propose seq2seqTr, a novel transliteration system. seq2seqTr is trained on a list of word pairs that are translations of one another – both transliterations and non-transliterations. It is unsupervised because we do not rely on labels to distinguish between transliteration and non-transliteration training pairs. seq2seqTr is a character-level sequence-to-sequence model (Sutskever et al., 2014) with a single-layer encoder and a single-layer decoder. The encoder is a bidirectional GRU (Cho et al., 2014) while the decoder is unidirectional with attention (Luong et al., 2015). The input characters are represented as vectors. Figure 1 (bottom) depicts the model. We use this model to calculate the probability of each word in the target language vocabulary with respect to each source test word. The probability corresponds to the average negative log likelihood of the characters in the target word with respect to the source word. We select n target transliteration candidates for each source word. To train seq2seqTr, we start with the same training dictionary as for building BWEs. Since it contains many non-transliteration pairs, we reduce their number with an iterativ"
2020.coling-main.531,2020.bucc-1.2,0,0.0251298,"sliterated (which means we shoud primarily trust the BOEs) and which should be semantically translated (which means we should primarily trust the BWEs), we use a classification approach similar to (Heyman et al., 2017), exploiting our pretrained encoder from seq2seqTr. In contrast to their approach, we use additional features, such as frequency, length, similarity scores, and the ranks assigned by the semantic and character-level submodels, and show that they are necessary to make the right decision. We test our system on the English-Russian (En-Ru) data provided in the BUCC 2020 shared task (Rapp et al., 2020). Test dictionaries were released in three frequency categories: high, middle and low. We evaluate our system on all three sets, both separately and jointly, and show improved performance on all three frequency ranges compared with previous approaches. Furthermore, we show that our classification system is more robust than the ensembling of Severini et al. (2020), which required specialized tuning on each frequency set. Lastly, we conduct a further analysis of the quality of the proposed BOEs by running transliteration mining on the NEWS 2010 shared task data (Kumaran et al., 2010) by using th"
2020.coling-main.531,P18-2062,0,0.0170745,"ences, BWEs are also effective when only a small seed lexicon is provided (e.g., (Mikolov et al., 2013b)). Conneau et al. (2018) and Artetxe et al. (2018) dispense with seed dictionaries and iteratively improve the mapping from an initial weak solution in a self-learning approach. This setting provides a building block for unsupervised MT and is particularly effective in the low-resource setting where less parallel seed data is available (Artetxe et al., 2019; Lample et al., 2018). BWE-based methods perform worse for low frequency words due to poor vector representations (Braune et al., 2018; Riley and Gildea, 2018; Czarnowska et al., 2019). Koehn and Knight (2002) and Haghighi et al. (2008) show that orthographic features help in the translation process. Languages with a common alphabet (e.g., English/German) often have word pairs with similar orthography (e.g., Concepts/Konzepte, Philosophies/Philosophien), especially in the case of low frequency words. Riley and Gildea (2018) integrate orthographic information into the vector representation of such words and into the mapping procedure of BWEs to improve their quality. Braune et al. (2018) use character n-gram representations and Levenshtein distance"
2020.coling-main.531,J17-2003,1,0.900897,"Missing"
2020.coling-main.531,2020.bucc-1.8,1,0.745542,"Missing"
2020.coling-main.531,P16-1024,0,0.0858517,"sed BDI system that uses BWEs, BOEs and a number of other features to make this decision. We test our system on EnglishRussian BDI and show improved performance. In addition, we show the effectiveness of our BOEs by successfully using them for transliteration mining based on cosine similarity. 1 Introduction The task of Bilingual Dictionary Induction is defined as finding target language translations of source language words. It is an important building block in the area of Machine Translation (MT) and it is one of the main tasks for bilingual word embedding evaluation (Mikolov et al., 2013b; Vulic and Korhonen, 2016). Recent work shows that good performance can be achieved relying only on BWEs, which can be built with only a weak bilingual signal, such as a small seed lexicon of a few thousand word pairs (Mikolov et al., 2013b) or common tokens in the source and target languages (Artetxe et al., 2017). In addition, they can even be built without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018), making them the basis of unsupervised MT systems (Lample et al., 2018; Artetxe et al., 2019). Standard BDI learns word representations based on approaches that exploit solely word-level information"
2020.emnlp-main.203,W18-6401,0,0.0195614,"table shows subword-based models trained from random initialization, the right part shows character-level models trained by finetuning. The yellower the background color, the better the value. Small numbers denote the difference from the best model, ∗ is the best model. For finetuning experiments (on the right) we report both difference from the best model and from the parent model. Validation BLEU score are in in the Appendix. tences of the WMT14 data (Bojar et al., 2014). Czech-English is trained on 15.8M sentence pairs of the CzEng 1.7 corpus (Bojar et al., 2016) and tested on WMT18 data (Bojar et al., 2018). Englishto-Turkish translation is trained on 207k sentences of the SETIMES2 corpus (Tiedemann, 2012) and evaluated on the WMT18 test set. We follow the original hyperparameters for the Transformer Base model (Vaswani et al., 2017), including the learning rate schedule. For finetuning, we use Adam (Kingma and Ba, 2015) with a constant learning rate 10−5 . All models are trained using Marian (Junczys-Dowmunt et al., 2018). We also present results for character-level EnglishGerman models having about the same number of parameters as the best-performing subword models. In experiments with BPE Dro"
2020.emnlp-main.203,P18-4020,0,0.0487814,"Missing"
2020.emnlp-main.203,W14-3348,0,0.00966327,"original hyperparameters for the Transformer Base model (Vaswani et al., 2017), including the learning rate schedule. For finetuning, we use Adam (Kingma and Ba, 2015) with a constant learning rate 10−5 . All models are trained using Marian (Junczys-Dowmunt et al., 2018). We also present results for character-level EnglishGerman models having about the same number of parameters as the best-performing subword models. In experiments with BPE Dropout, we set dropout probability p = 0.1. We evaluate the translation quality using BLEU (Papineni et al., 2002), chrF (Popovi´c, 2015), and METEOR 1.5 (Denkowski and Lavie, 2014). Following Gupta et al. (2019), we also conduct a noisesensitivity evaluation to natural noise as introduced by Belinkov and Bisk (2018). With probability p words are replaced with their variants from a misspelling corpus. Following Gupta et al. (2019), we assume the BLEU scores measured with input can be explained by a linear approximation with intercept α and slope β using the noise probability p: BLEU ≈ βp + α. However, unlike them, we report the relative translation quality degradation β/α instead of only β. Parameter β corresponds to absolute BLEU score degradation and is thus higher giv"
2020.emnlp-main.203,2020.acl-main.145,0,0.336439,"Missing"
2020.emnlp-main.203,P02-1040,0,\N,Missing
2020.emnlp-main.203,W15-3049,0,\N,Missing
2020.emnlp-main.203,Q17-1026,0,\N,Missing
2020.emnlp-main.203,W17-4705,0,\N,Missing
2020.emnlp-main.203,D18-1338,0,\N,Missing
2020.emnlp-main.203,P16-1162,0,\N,Missing
2020.emnlp-main.203,D18-1461,0,\N,Missing
2020.emnlp-main.203,tiedemann-2012-parallel,0,\N,Missing
2020.findings-emnlp.150,2020.acl-main.493,0,0.026025,"e neutrality. Zero-shot learning abilities were examined by Pires et al. (2019) on NER and part-of-speech (POS) tagging, showing that the success strongly depends on how typologically similar the languages are. Similarly, Wu and Dredze (2019) trained good multilingual models but struggled to achieve good results in the zero-shot setup for POS tagging, NER, and XLNI. R¨onnqvist et al. (2019) draw similar conclusions for language-generation tasks. Wang et al. (2019) succeeded in zero-shot dependency parsing but required supervised projection trained on word-aligned parallel data. The results of Chi et al. (2020) on dependency parsing suggest that methods like structural probing (Hewitt and Manning, 2019) might be more suitable for zero-shot transfer. Pires et al. (2019) also assessed mBERT on cross-lingual sentence retrieval between three language pairs. They observed that if they subtract the average difference between the embeddings from the target language representation, the retrieval accuracy significantly increases. We systematically study this idea in the later sections. XTREME (Hu et al., 2020) and XGLUE (Liang et al., 2020), two recently introduced benchmarks for multilingual representation"
2020.findings-emnlp.150,2020.acl-main.747,0,0.173152,"Missing"
2020.findings-emnlp.150,D18-1269,0,0.0412762,"ero-shot transfer. Pires et al. (2019) also assessed mBERT on cross-lingual sentence retrieval between three language pairs. They observed that if they subtract the average difference between the embeddings from the target language representation, the retrieval accuracy significantly increases. We systematically study this idea in the later sections. XTREME (Hu et al., 2020) and XGLUE (Liang et al., 2020), two recently introduced benchmarks for multilingual representation evaluation, assess representations on a broader range of zero-shot transfer tasks that include natural language inference (Conneau et al., 2018) and question answering (Artetxe et al., 2019; Lewis et al., 2019). Their results show a clearly superior performance of XLMR compared to mBERT. Many works clearly show that downstream task models can extract relevant features from the multilingual representations (Wu and Dredze, 2019; Kudugunta et al., 2019; Kondratyuk and Straka, 2019a). However, they do not directly show language-neutrality, i.e., to what extent similar phenomena are represented similarly across languages. Thus, it is impossible to say whether the representations are language-agnostic or contain some implicit language ident"
2020.findings-emnlp.150,N19-1423,0,0.0426482,"ddings, which are explicitly trained for language neutrality. Contextual embeddings are still only moderately languageneutral by default, so we propose two simple methods for achieving stronger language neutrality: first, by unsupervised centering of the representation for each language and second, by fitting an explicit projection on small parallel data. Besides, we show how to reach stateof-the-art accuracy on language identification and match the performance of statistical methods for word alignment of parallel sentences without using parallel data. 1 Introduction Multilingual BERT (mBERT; Devlin et al. 2019) gained popularity as a contextual representation for many multilingual tasks, e.g., dependency parsing (Kondratyuk and Straka, 2019a; Wang et al., 2019), cross-lingual natural language inference (XNLI) or named-entity recognition (NER) (Pires et al., 2019; Wu and Dredze, 2019; Kudugunta et al., 2019). Recently, a new pre-trained model, XLM-RoBERTa (XLM-R; Conneau et al. 2019), claimed to outperform mBERT both on XNLI and NER tasks. We also study DistilBERT (Sanh et al., 2019) applied to mBERT, which promises to deliver comparable results to mBERT at a significantly lower computational cost. P"
2020.findings-emnlp.150,N13-1073,0,0.127813,"t the projection by minimizing the element-wise mean squared error between the representation of an English sentence and a linear projection of the representation of its translation. Word Alignment. WA is the task of matching words which are translations of each other in parallel sentences. WA is a key component of statistical machine translation systems (Koehn, 2009). While sentence retrieval could be done with keyword spotting, computing bilingual WA requires resolving detailed correspondence on the word level. Unsupervised statistical methods trained on parallel corpora (Och and Ney, 2003; Dyer et al., 2013) still pose a strong baseline for the task. In a work parallel to ours, Sabet et al. (2020) present a more complex alternative way of leveraging contextual representations for word alignment that outperforms the statistical methods. For a pair of parallel sentences, we find the WA as a minimum weighted edge cover of a bipartite graph. We create an edge for each potential alignment link, weight it by the cosine distance of the token representations, and find the WA as a minimum weighted edge cover of the resulting bipartite graph. Unlike statistical methods, this does not require parallel data"
2020.findings-emnlp.150,D18-1002,0,0.0660149,"Missing"
2020.findings-emnlp.150,W19-6721,0,0.0363306,"Missing"
2020.findings-emnlp.150,L18-1550,0,0.0632994,"Missing"
2020.findings-emnlp.150,N19-1419,0,0.0240241,"and part-of-speech (POS) tagging, showing that the success strongly depends on how typologically similar the languages are. Similarly, Wu and Dredze (2019) trained good multilingual models but struggled to achieve good results in the zero-shot setup for POS tagging, NER, and XLNI. R¨onnqvist et al. (2019) draw similar conclusions for language-generation tasks. Wang et al. (2019) succeeded in zero-shot dependency parsing but required supervised projection trained on word-aligned parallel data. The results of Chi et al. (2020) on dependency parsing suggest that methods like structural probing (Hewitt and Manning, 2019) might be more suitable for zero-shot transfer. Pires et al. (2019) also assessed mBERT on cross-lingual sentence retrieval between three language pairs. They observed that if they subtract the average difference between the embeddings from the target language representation, the retrieval accuracy significantly increases. We systematically study this idea in the later sections. XTREME (Hu et al., 2020) and XGLUE (Liang et al., 2020), two recently introduced benchmarks for multilingual representation evaluation, assess representations on a broader range of zero-shot transfer tasks that include"
2020.findings-emnlp.150,W11-4615,0,0.0209665,"iction. 6 centroids and training the lng-free version of the model. For parallel sentence retrieval, we use a multiparallel corpus of test data from the WMT14 evaluation campaign (Bojar et al., 2014) with 3,000 sentences in Czech, English, French, German, Hindi, and Russian. To compute the linear projection (for the special linear projection experimental condition), we used the WMT14 development data (500– 3000 sentences per language pair). We use manually annotated WA datasets to evaluate word alignment between English on one side and Czech (2.5k sent.; Mareˇcek, 2016)2 , Swedish (192 sent.; Holmqvist and Ahrenberg, 2011)3 , German (508 sent.)4 , French (447 sent.; Och and Ney, 2000)5 and Romanian (248 sent.; Mihalcea and Pedersen, 2003)6 on the other side. We compare the results with FastAlign (Dyer et al., 2013) and ¨ Efmaral (Ostling and Tiedemann, 2016) models, which were provided with 1M additional parallel sentences from ParaCrawl (Espl`a et al., 2019)7 . For MT QE, we use English-German training and test data provided for the WMT19 QE Shared Task (Fonseca et al., 2019, Task 1), consisting of Experimental Setup 2 http://hdl.handle.net/11234/1-1804 http://hdl.handle.net/11372/LRT-1517 4 https://www-i6.inf"
2020.findings-emnlp.150,D18-1330,0,0.0325126,"Missing"
2020.findings-emnlp.150,P09-5002,0,0.00950591,"ons of all sentences on the parallel side of the corpus and select the sentence with the smallest distance. Besides the plain and centered representations, we evaluate explicit projection of the representations into the “English space.” We fit the projection by minimizing the element-wise mean squared error between the representation of an English sentence and a linear projection of the representation of its translation. Word Alignment. WA is the task of matching words which are translations of each other in parallel sentences. WA is a key component of statistical machine translation systems (Koehn, 2009). While sentence retrieval could be done with keyword spotting, computing bilingual WA requires resolving detailed correspondence on the word level. Unsupervised statistical methods trained on parallel corpora (Och and Ney, 2003; Dyer et al., 2013) still pose a strong baseline for the task. In a work parallel to ours, Sabet et al. (2020) present a more complex alternative way of leveraging contextual representations for word alignment that outperforms the statistical methods. For a pair of parallel sentences, we find the WA as a minimum weighted edge cover of a bipartite graph. We create an ed"
2020.findings-emnlp.150,D19-1279,0,0.357373,"l by default, so we propose two simple methods for achieving stronger language neutrality: first, by unsupervised centering of the representation for each language and second, by fitting an explicit projection on small parallel data. Besides, we show how to reach stateof-the-art accuracy on language identification and match the performance of statistical methods for word alignment of parallel sentences without using parallel data. 1 Introduction Multilingual BERT (mBERT; Devlin et al. 2019) gained popularity as a contextual representation for many multilingual tasks, e.g., dependency parsing (Kondratyuk and Straka, 2019a; Wang et al., 2019), cross-lingual natural language inference (XNLI) or named-entity recognition (NER) (Pires et al., 2019; Wu and Dredze, 2019; Kudugunta et al., 2019). Recently, a new pre-trained model, XLM-RoBERTa (XLM-R; Conneau et al. 2019), claimed to outperform mBERT both on XNLI and NER tasks. We also study DistilBERT (Sanh et al., 2019) applied to mBERT, which promises to deliver comparable results to mBERT at a significantly lower computational cost. Pires et al. (2019) present an exploratory paper showing that mBERT can be used cross-lingually for zero-shot transfer in morphologic"
2020.findings-emnlp.150,D18-2012,0,0.0165127,"tropy of its output distribution with respect to the output of the teacher mBERT model while keeping the MLM objective in the multi-task learning setup. As the model is forced to use smaller space to obtain the representation, it might leverage the similarities between languages and reach better language neutrality. XLM-RoBERTa. Conneau et al. (2019) claim that the original mBERT is under-trained and train a similar model on a larger dataset that consists of two terabytes of plain text extracted from CommonCrawl (Wenzek et al., 2019). Unlike mBERT, XLM-R uses a SentencePiece-based vocabulary (Kudo and Richardson, 2018) of 250k tokens. The rest of the architecture remains the same as in the case of mBERT. We train the model using the MLM objective only, without the sentence adjacency prediction. 6 centroids and training the lng-free version of the model. For parallel sentence retrieval, we use a multiparallel corpus of test data from the WMT14 evaluation campaign (Bojar et al., 2014) with 3,000 sentences in Czech, English, French, German, Hindi, and Russian. To compute the linear projection (for the special linear projection experimental condition), we used the WMT14 development data (500– 3000 sentences per"
2020.findings-emnlp.150,D19-1167,0,0.110506,", by fitting an explicit projection on small parallel data. Besides, we show how to reach stateof-the-art accuracy on language identification and match the performance of statistical methods for word alignment of parallel sentences without using parallel data. 1 Introduction Multilingual BERT (mBERT; Devlin et al. 2019) gained popularity as a contextual representation for many multilingual tasks, e.g., dependency parsing (Kondratyuk and Straka, 2019a; Wang et al., 2019), cross-lingual natural language inference (XNLI) or named-entity recognition (NER) (Pires et al., 2019; Wu and Dredze, 2019; Kudugunta et al., 2019). Recently, a new pre-trained model, XLM-RoBERTa (XLM-R; Conneau et al. 2019), claimed to outperform mBERT both on XNLI and NER tasks. We also study DistilBERT (Sanh et al., 2019) applied to mBERT, which promises to deliver comparable results to mBERT at a significantly lower computational cost. Pires et al. (2019) present an exploratory paper showing that mBERT can be used cross-lingually for zero-shot transfer in morphological and syntactic tasks, at least for typologically similar languages. They also study an interesting semantic task, sentence-retrieval, with promising initial results. Th"
2020.findings-emnlp.150,P12-3005,0,0.0977273,"Missing"
2020.findings-emnlp.150,W03-0301,0,0.0287526,"lel corpus of test data from the WMT14 evaluation campaign (Bojar et al., 2014) with 3,000 sentences in Czech, English, French, German, Hindi, and Russian. To compute the linear projection (for the special linear projection experimental condition), we used the WMT14 development data (500– 3000 sentences per language pair). We use manually annotated WA datasets to evaluate word alignment between English on one side and Czech (2.5k sent.; Mareˇcek, 2016)2 , Swedish (192 sent.; Holmqvist and Ahrenberg, 2011)3 , German (508 sent.)4 , French (447 sent.; Och and Ney, 2000)5 and Romanian (248 sent.; Mihalcea and Pedersen, 2003)6 on the other side. We compare the results with FastAlign (Dyer et al., 2013) and ¨ Efmaral (Ostling and Tiedemann, 2016) models, which were provided with 1M additional parallel sentences from ParaCrawl (Espl`a et al., 2019)7 . For MT QE, we use English-German training and test data provided for the WMT19 QE Shared Task (Fonseca et al., 2019, Task 1), consisting of Experimental Setup 2 http://hdl.handle.net/11234/1-1804 http://hdl.handle.net/11372/LRT-1517 4 https://www-i6.informatik.rwth-aachen.de/ goldAlignment 5 http://web.eecs.umich.edu/∼mihalcea/wpt/data/ English-French.test.tar.gz 6 htt"
2020.findings-emnlp.150,P00-1056,0,0.418501,"allel sentence retrieval, we use a multiparallel corpus of test data from the WMT14 evaluation campaign (Bojar et al., 2014) with 3,000 sentences in Czech, English, French, German, Hindi, and Russian. To compute the linear projection (for the special linear projection experimental condition), we used the WMT14 development data (500– 3000 sentences per language pair). We use manually annotated WA datasets to evaluate word alignment between English on one side and Czech (2.5k sent.; Mareˇcek, 2016)2 , Swedish (192 sent.; Holmqvist and Ahrenberg, 2011)3 , German (508 sent.)4 , French (447 sent.; Och and Ney, 2000)5 and Romanian (248 sent.; Mihalcea and Pedersen, 2003)6 on the other side. We compare the results with FastAlign (Dyer et al., 2013) and ¨ Efmaral (Ostling and Tiedemann, 2016) models, which were provided with 1M additional parallel sentences from ParaCrawl (Espl`a et al., 2019)7 . For MT QE, we use English-German training and test data provided for the WMT19 QE Shared Task (Fonseca et al., 2019, Task 1), consisting of Experimental Setup 2 http://hdl.handle.net/11234/1-1804 http://hdl.handle.net/11372/LRT-1517 4 https://www-i6.informatik.rwth-aachen.de/ goldAlignment 5 http://web.eecs.umich.e"
2020.findings-emnlp.150,J03-1002,0,0.0123249,"glish space.” We fit the projection by minimizing the element-wise mean squared error between the representation of an English sentence and a linear projection of the representation of its translation. Word Alignment. WA is the task of matching words which are translations of each other in parallel sentences. WA is a key component of statistical machine translation systems (Koehn, 2009). While sentence retrieval could be done with keyword spotting, computing bilingual WA requires resolving detailed correspondence on the word level. Unsupervised statistical methods trained on parallel corpora (Och and Ney, 2003; Dyer et al., 2013) still pose a strong baseline for the task. In a work parallel to ours, Sabet et al. (2020) present a more complex alternative way of leveraging contextual representations for word alignment that outperforms the statistical methods. For a pair of parallel sentences, we find the WA as a minimum weighted edge cover of a bipartite graph. We create an edge for each potential alignment link, weight it by the cosine distance of the token representations, and find the WA as a minimum weighted edge cover of the resulting bipartite graph. Unlike statistical methods, this does not re"
2020.findings-emnlp.150,P19-1493,0,0.442784,"presentation for each language and second, by fitting an explicit projection on small parallel data. Besides, we show how to reach stateof-the-art accuracy on language identification and match the performance of statistical methods for word alignment of parallel sentences without using parallel data. 1 Introduction Multilingual BERT (mBERT; Devlin et al. 2019) gained popularity as a contextual representation for many multilingual tasks, e.g., dependency parsing (Kondratyuk and Straka, 2019a; Wang et al., 2019), cross-lingual natural language inference (XNLI) or named-entity recognition (NER) (Pires et al., 2019; Wu and Dredze, 2019; Kudugunta et al., 2019). Recently, a new pre-trained model, XLM-RoBERTa (XLM-R; Conneau et al. 2019), claimed to outperform mBERT both on XNLI and NER tasks. We also study DistilBERT (Sanh et al., 2019) applied to mBERT, which promises to deliver comparable results to mBERT at a significantly lower computational cost. Pires et al. (2019) present an exploratory paper showing that mBERT can be used cross-lingually for zero-shot transfer in morphological and syntactic tasks, at least for typologically similar languages. They also study an interesting semantic task, sentence"
2020.findings-emnlp.150,D19-1077,0,0.364128,"h language and second, by fitting an explicit projection on small parallel data. Besides, we show how to reach stateof-the-art accuracy on language identification and match the performance of statistical methods for word alignment of parallel sentences without using parallel data. 1 Introduction Multilingual BERT (mBERT; Devlin et al. 2019) gained popularity as a contextual representation for many multilingual tasks, e.g., dependency parsing (Kondratyuk and Straka, 2019a; Wang et al., 2019), cross-lingual natural language inference (XNLI) or named-entity recognition (NER) (Pires et al., 2019; Wu and Dredze, 2019; Kudugunta et al., 2019). Recently, a new pre-trained model, XLM-RoBERTa (XLM-R; Conneau et al. 2019), claimed to outperform mBERT both on XNLI and NER tasks. We also study DistilBERT (Sanh et al., 2019) applied to mBERT, which promises to deliver comparable results to mBERT at a significantly lower computational cost. Pires et al. (2019) present an exploratory paper showing that mBERT can be used cross-lingually for zero-shot transfer in morphological and syntactic tasks, at least for typologically similar languages. They also study an interesting semantic task, sentence-retrieval, with prom"
2020.findings-emnlp.150,W19-6204,0,0.0884765,"Missing"
2020.findings-emnlp.150,D07-1043,0,0.102303,"es all phenomena in a language-neutral way, it should be difficult to determine what language the sentence is written in. Unlike our other tasks, language ID requires fitting a classifier. We train a linear classifier on top of a sentence representation. Language Similarity. Previous work (Pires et al., 2019; Wang et al., 2019) shows that models can be transferred better between more similar languages, suggesting that similar languages tend to get similar representations. We quantify this observation by V-measure between language families and hierarchical clustering of the language centroids (Rosenberg and Hirschberg, 2007). We cluster the language centroids by their cosine distance using the Nearest Point Algorithm and stop the clustering with a number of clusters equal to the number of language families in the data. Parallel Sentence Retrieval. For each sentence in a multi-parallel corpus, we compute the cosine distance of its representation with representations of all sentences on the parallel side of the corpus and select the sentence with the smallest distance. Besides the plain and centered representations, we evaluate explicit projection of the representations into the “English space.” We fit the projecti"
2020.findings-emnlp.150,2020.findings-emnlp.147,0,0.0264938,"Missing"
2020.findings-emnlp.150,D19-1575,0,0.27855,"o simple methods for achieving stronger language neutrality: first, by unsupervised centering of the representation for each language and second, by fitting an explicit projection on small parallel data. Besides, we show how to reach stateof-the-art accuracy on language identification and match the performance of statistical methods for word alignment of parallel sentences without using parallel data. 1 Introduction Multilingual BERT (mBERT; Devlin et al. 2019) gained popularity as a contextual representation for many multilingual tasks, e.g., dependency parsing (Kondratyuk and Straka, 2019a; Wang et al., 2019), cross-lingual natural language inference (XNLI) or named-entity recognition (NER) (Pires et al., 2019; Wu and Dredze, 2019; Kudugunta et al., 2019). Recently, a new pre-trained model, XLM-RoBERTa (XLM-R; Conneau et al. 2019), claimed to outperform mBERT both on XNLI and NER tasks. We also study DistilBERT (Sanh et al., 2019) applied to mBERT, which promises to deliver comparable results to mBERT at a significantly lower computational cost. Pires et al. (2019) present an exploratory paper showing that mBERT can be used cross-lingually for zero-shot transfer in morphological and syntactic task"
2020.findings-emnlp.150,W14-3302,0,\N,Missing
2020.findings-emnlp.150,W19-5401,0,\N,Missing
2020.lrec-1.313,E17-1088,0,0.216796,"a bilingual signal of 4,955 frequent word pairs, and 2,000 frequent words as test and validation sets. The baseline model failed to deliver promising results, but by applying ensembling techniques combined with orthographic cues, stateof-the-art results were achieved. We extend the experiments of Braune et al. (2018) in mining frequent words for English to German, using their seed lexicon and test set. We set up datasets with different amounts of monolingual corpora, as well as different lexicon size, to determine the amount of data needed to arrive at comparable results. Similar to our work, Adams et al. (2017) investigated word embeddings in low-resource setups. It was shown that the monolingual quality, i.e., the correlation of the cosine similarity of the embeddings with human word similarity judgements, drops drastically when only a few thousand sentences are available. To improve the performance, a large number of sentences from other languages were leveraged. To bridge the gap between the languages, a joint BWE model (Duong et al., 2016) and large bilingual dictionaries were used. They showed significant improvements in monolingual word similarity. However, they do not report results on biling"
2020.lrec-1.313,P19-1019,0,0.0214901,"on only a few major languages, such as English, Spanish, French, German, Chinese and Arabic. Linguistic resources in these languages abound; understandably, statistical and neural machine translation models that have seen impressive results focus on these languages, exploiting massive amounts of parallel corpora. High quality parallel corpora take years to build, backed by millions of dollars per language. To develop systems that can automatically generate translations relying only on monolingual corpora is therefore a huge step in machine translation, particularly for low-resource languages (Artetxe et al., 2019; Conneau and Lample, 2019). Research on low-resource languages, however, poses many challenges. Unlike well-researched languages, they are mainly minority languages that do not have established grammar, dictionaries and orthographic standards. They are usually spoken at home, in small communities or in regions where people primarily learn the language by speaking, leading to lack of written documents, much less machine-readable data. There are usually no active communities of researchers that build linguistic resources. With these challenges, exacerbated by the diminishing number of speakers,"
2020.lrec-1.313,Q17-1010,0,0.0695223,"used a standard phrase-based SMT system trained on WMT 2017 data. 3.4. Training MWEs The monolingual datasets in Section 3.1. are first normalized with Moses tools for tokenizing and lower-casing7 . Punctuation marks are not removed. As there are plenty of digits from the religious texts, i.e., verse numbers, they are deleted along with the noticeable series of empty lines observed in the Hiligaynon texts. These are simply done with Unix commands. After normalization, Skip-gram and CBOW are trained on the monolingual corpora using the toolkits word2vec8 (Mikolov et al., 2013a) and fastText9 (Bojanowski et al., 2017). Training takes longer with fastText as it uses character n-grams to represent word vectors, but the subword information it contains has been shown to better represent morphologically-rich languages like German. Except for setting the dimensions to 50 and 300, and the minimum word count to 3 in order to compensate the small corpus size, all other parameters are set with default values. It is interesting to note that although the small En-Hil dataset has more English word tokens than the En-De dataset has, its number of English word types is lower. This is due to the domains of texts in the da"
2020.lrec-1.313,W16-2301,0,0.0322,"Missing"
2020.lrec-1.313,N18-2030,1,0.133539,"Spanish to English, and English to Czech translations. To test whether the same approach works for unrelated languages, over a billion Vietnamese phrases were trained to mine Vietnamese translations for English words and vice versa, applying previous techniques in vector representations of phrases (Mikolov et al., 2013c). Even with the large corpora, the accuracy is only 10 percent for English to Vietnamese and 24 percent for Vietnamese to English. In this paper, we attempt a word-word translation of English to Hiligaynon using a small available Hiligaynon corpus of a bit over 300,000 tokens. Braune et al. (2018) further explored the feasibility of this approach by evaluating the quality of BWEs to mine rare and domain-specific words, as well as frequent words, in English to German. For frequent words in the general domain, the dataset consisted of monolingual corpora of 4,400,309 English and German sentences from parliament proceedings, news commentaries and web crawls taken from the WMT 2016 shared task (Bojar et al., 2016), a bilingual signal of 4,955 frequent word pairs, and 2,000 frequent words as test and validation sets. The baseline model failed to deliver promising results, but by applying en"
2020.lrec-1.313,Y09-2024,0,0.192847,"es in word order between English and Hiligaynon; unlike the typical subject-verb-object (SVO) order of English, Hiligaynon has a free-word order, i.e., sentences are typically expressed in VSO, and sometimes, in VOS or SOV form, depending on emphasis. For our experiments, we reached out to Macabante et al. (2017) for a copy of the parallel corpus, but were informed that the corpus is no longer available due to technical issues. We make do with the available Hiligaynon monolingual corpus consisting of a bit over 300,000 words in literary and religious texts from the now-defunct Palito website (Dita et al., 2009), datasets of which are still accessible online 1 . To produce a comparable dataset, religious and literary texts in English were also collected. 1,200 most frequent words from the English corpus were then extracted and translated into Hiligaynon by a native speaker: the first 1,000 pairs serve as the training seed lexicon, and the remaining 200 pairs as test set. 1 https://www.dropbox.com/sh/ b1dp56htdm9qux0/AABsNv12EzzdJDpQNop3gb5ea? dl=0 Since results of our experiments show that the small dataset is not sufficient to accurately mine translation pairs, we simulate the low-resource scenario"
2020.lrec-1.313,D16-1136,0,0.0233801,"mounts of monolingual corpora, as well as different lexicon size, to determine the amount of data needed to arrive at comparable results. Similar to our work, Adams et al. (2017) investigated word embeddings in low-resource setups. It was shown that the monolingual quality, i.e., the correlation of the cosine similarity of the embeddings with human word similarity judgements, drops drastically when only a few thousand sentences are available. To improve the performance, a large number of sentences from other languages were leveraged. To bridge the gap between the languages, a joint BWE model (Duong et al., 2016) and large bilingual dictionaries were used. They showed significant improvements in monolingual word similarity. However, they do not report results on bilingual quality, such as BLI, and rely on a large dictionary which is often not available for low-resource languages. In contrast, we focus on evaluating the bilingual quality of the models assuming only a small seed lexicon. 2574 Language English Hiligaynon Language English German En-Hil Words 345,583 319,934 En-De Words 300,120 300,099 Texts books europarl newscomm globalvoices multi un ted talk wiki Total Table 1: Small datasets. The En-H"
2020.lrec-1.313,J17-2001,0,0.0197126,"have been trained separately. Hence, although fastText’s subword information help better represent words with similar substrings, it does not prove effective in the face of very limited data. 4.2. Large Data In order to have a deeper understanding of the required resources for building useful BWEs, we test various setups on En-De. Figure 1 shows the impact of the size of monolingual corpora to BLI performance. Performance having 1.5M words yield 0.2 percent accuracy. Between 12M and 25M, a steep learning curve (8 percent increase) can be observed. This reflects the results of previous works (Irvine and Callison-Burch, 2017; Mikolov et al., 2013b). Accuracy improves as the amount of data increases. We show results derived from word2vec Skip-gram since it consistently outperformed other MWE models across all sizes of monolingual corpora. Detailed comparison with fastText Skip-gram can be seen in Figure 2. 4.2.1. Ensembling + Edit Distance Validating the work of Braune et al. (2018), Figure 2 shows increase in accuracy when the techniques of ensembling and ensembling with edit distance are applied. The poor performance of fastText, probably brought by the noise in the small corpus making character n-grams worse, d"
2020.lrec-1.313,D14-1181,0,0.00335256,"ass results of previous studies. We release the lexicon of 1,200 English-Hiligaynon word pairs we created to encourage further investigation. Keywords: bilingual word embeddings, bilingual lexicon induction, post-hoc mapping, low-resource languages, Hiligaynon 1. Introduction Since the introduction of Skip-gram and Continuous Bagof-Words (Mikolov et al., 2013a) followed by the release of GloVe (Pennington et al., 2014), the use of word embeddings, the continuous vector representations of words, has become the norm for many natural language processing (NLP) tasks. From sentence classification (Kim, 2014), part-of-speech tagging (Abka, 2016), named entity recognition (Melamud et al., 2016), to sentiment analysis (Ruder et al., 2016), it is hard to imagine modern NLP without word embeddings. How this success of monolingual word embeddings (MWEs) can extend to a bilingual setup – to represent meaning and transfer knowledge in bilingual tasks – sparks interests that paved the way for investigating different models of bilingual word embeddings (BWEs). When two MWEs share a single vector space in the form of BWEs, it is likely that, following the concept of MWEs correlating distance with semantic s"
2020.lrec-1.313,P15-1027,0,0.0204203,"– with even better results. With 25 million words of monolingual corpora using only 3,000 seed lexicon, performance of the word2vec Skipgram (29.8 percent) even surpasses results released by previous study (Braune et al., 2018) which trained 100-million-word corpora using 5,000 seed lexicon (27.1 percent). There is still a lot of room for improvement. For instance, the problem of polysemy should be addressed in MWE models so that the two or more polysemous senses of a single word type are not represented using the same vector. Another future work is training BWEs with max margin ranking loss (Lazaridou et al., 2015). As also shown by Braune et al. (2018), this technique generates better results than the post-hoc mapping model applied in our experiments. Additionally, Hiligaynon could also benefit from cross-lingual transfer learning, exploiting high-resource related languages like Cebuano, Filipino or even Spanish. Using a simple, inexpensive model, the experiments and analysis in this paper provide various insights into different factors affecting performance for mining translation pairs – from the size of the monolingual corpora, the frequency and size of the seed lexicon, down to the impact of dimensi"
2020.lrec-1.313,N19-1045,0,0.0273787,"Missing"
2020.lrec-1.313,N16-1118,0,0.0149802,"ligaynon word pairs we created to encourage further investigation. Keywords: bilingual word embeddings, bilingual lexicon induction, post-hoc mapping, low-resource languages, Hiligaynon 1. Introduction Since the introduction of Skip-gram and Continuous Bagof-Words (Mikolov et al., 2013a) followed by the release of GloVe (Pennington et al., 2014), the use of word embeddings, the continuous vector representations of words, has become the norm for many natural language processing (NLP) tasks. From sentence classification (Kim, 2014), part-of-speech tagging (Abka, 2016), named entity recognition (Melamud et al., 2016), to sentiment analysis (Ruder et al., 2016), it is hard to imagine modern NLP without word embeddings. How this success of monolingual word embeddings (MWEs) can extend to a bilingual setup – to represent meaning and transfer knowledge in bilingual tasks – sparks interests that paved the way for investigating different models of bilingual word embeddings (BWEs). When two MWEs share a single vector space in the form of BWEs, it is likely that, following the concept of MWEs correlating distance with semantic similarity, the target language word closest to the source language word is the transla"
2020.lrec-1.313,W18-2204,0,0.0194506,"past left traces in Hiligaynon. Many loan words are adjusted to the orthography and pronunciation of native Hiligaynon sounds. Spanish words like abyerto (abierto), timprano (temprano), gwapo (guapo), munyeka (mu˜neca), merkado (mercado), kambyo (cambio), ubra (obrah), to name a few, find frequent use. Code-switching to English, the country’s another official language, is common, a footprint of America’s post-Spanish occupation. As is mostly the case with Philippine languages, there is only little NLP work on Hiligaynon. Since 2008, only one research paper for statistical machine translation (Oco and Roxas, 2018) has been published. Experiments yielded a BLEU score of 21.74 for Hiligaynon to English, and 24.43 for English to Hiligaynon, using the parallel corpora from the New Testament (Macabante et al., 2017). The lower performance of the Hiligaynon to English translation is attributed by Macabante et al. (2017) to the differences in word order between English and Hiligaynon; unlike the typical subject-verb-object (SVO) order of English, Hiligaynon has a free-word order, i.e., sentences are typically expressed in VSO, and sometimes, in VOS or SOV form, depending on emphasis. For our experiments, we r"
2020.lrec-1.313,D14-1162,0,0.0821541,"Missing"
2020.lrec-1.313,D16-1103,0,0.0116524,"rther investigation. Keywords: bilingual word embeddings, bilingual lexicon induction, post-hoc mapping, low-resource languages, Hiligaynon 1. Introduction Since the introduction of Skip-gram and Continuous Bagof-Words (Mikolov et al., 2013a) followed by the release of GloVe (Pennington et al., 2014), the use of word embeddings, the continuous vector representations of words, has become the norm for many natural language processing (NLP) tasks. From sentence classification (Kim, 2014), part-of-speech tagging (Abka, 2016), named entity recognition (Melamud et al., 2016), to sentiment analysis (Ruder et al., 2016), it is hard to imagine modern NLP without word embeddings. How this success of monolingual word embeddings (MWEs) can extend to a bilingual setup – to represent meaning and transfer knowledge in bilingual tasks – sparks interests that paved the way for investigating different models of bilingual word embeddings (BWEs). When two MWEs share a single vector space in the form of BWEs, it is likely that, following the concept of MWEs correlating distance with semantic similarity, the target language word closest to the source language word is the translation equivalent. To evaluate the quality of"
2020.lrec-1.313,P16-1024,0,0.151659,"Missing"
2020.wmt-1.128,P18-1073,0,0.325239,"eful in the Upper Sorbian→German direction. We explore sampling during backtranslation and curriculum learning to use SMT translations in a more principled way. Finally, we ensemble our bestperforming systems and reach a BLEU score of 32.4 on German→Upper Sorbian and 35.2 on Upper Sorbian→German. 1 Introduction Neural machine translation achieves remarkable results (Bahdanau et al., 2015; Vaswani et al., 2017) when large parallel training corpora are available. However, such corpora are only available for a limited number of languages. UNMT addresses this issue by using monolingual data only (Artetxe et al., 2018c; Lample et al., 2018). The performance of UNMT models is further improved using transfer learning from a pretrained cross-lingual model (Lample and Conneau, 2019; Song et al., 2019). However, pretraining also demands large monolingual corpora for both languages. Without abundant data, UNMT methods are often ineffective (Guzm´an et al., 2019). Therefore, effectively transWe participate in the WMT 2020 unsupervised machine translation shared task. The task includes two directions: German→Upper Sorbian (De→Hsb) and Upper Sorbian→German (Hsb→De). Our systems are constrained, using only the provi"
2020.wmt-1.128,D18-1399,0,0.357372,"eful in the Upper Sorbian→German direction. We explore sampling during backtranslation and curriculum learning to use SMT translations in a more principled way. Finally, we ensemble our bestperforming systems and reach a BLEU score of 32.4 on German→Upper Sorbian and 35.2 on Upper Sorbian→German. 1 Introduction Neural machine translation achieves remarkable results (Bahdanau et al., 2015; Vaswani et al., 2017) when large parallel training corpora are available. However, such corpora are only available for a limited number of languages. UNMT addresses this issue by using monolingual data only (Artetxe et al., 2018c; Lample et al., 2018). The performance of UNMT models is further improved using transfer learning from a pretrained cross-lingual model (Lample and Conneau, 2019; Song et al., 2019). However, pretraining also demands large monolingual corpora for both languages. Without abundant data, UNMT methods are often ineffective (Guzm´an et al., 2019). Therefore, effectively transWe participate in the WMT 2020 unsupervised machine translation shared task. The task includes two directions: German→Upper Sorbian (De→Hsb) and Upper Sorbian→German (Hsb→De). Our systems are constrained, using only the provi"
2020.wmt-1.128,J82-2005,0,0.696537,"Missing"
2020.wmt-1.128,2020.acl-main.421,0,0.0331286,"VHsb vocabularies. We extend the input and output embedding layer to account for the new vocabulary items. The new parameters are then learned during fine-tuning. 2.3 Adapters Besides initializing our UNMT systems with FINE TUNED MASS, we also experiment with pretraining MASS on De and fine-tuning only on Hsb. During fine-tuning, we freeze the encoder and decoder Transformer layers and add adapters (Houlsby et al., 2019) to each of the Transformer layers. Adapters can prevent catastrophic forgetting (Goodfellow et al., 2013) and show promising results in various tasks (Bapna and Firat, 2019; Artetxe et al., 2020). We fine-tune only the output layer, the embeddings and the decoder’s attention to the encoder as well as the lightweight adapter layers. We investigate adapters as fine-tuning in this way is considerably more computationally efficient. We also experimented with freezing the decoder’s attention to the encoder as well as adding an adapter on top of it, but these architecture designs are worse in terms of perplexity during MASS fine-tuning as well as BLEU scores during UNMT. We use the fine-tuned model to initialize an encoder-decoder Transformer, augmented with adapters. The adapter-augmented"
2020.wmt-1.128,D19-1165,0,0.0222418,"he union of the VDe and VHsb vocabularies. We extend the input and output embedding layer to account for the new vocabulary items. The new parameters are then learned during fine-tuning. 2.3 Adapters Besides initializing our UNMT systems with FINE TUNED MASS, we also experiment with pretraining MASS on De and fine-tuning only on Hsb. During fine-tuning, we freeze the encoder and decoder Transformer layers and add adapters (Houlsby et al., 2019) to each of the Transformer layers. Adapters can prevent catastrophic forgetting (Goodfellow et al., 2013) and show promising results in various tasks (Bapna and Firat, 2019; Artetxe et al., 2020). We fine-tune only the output layer, the embeddings and the decoder’s attention to the encoder as well as the lightweight adapter layers. We investigate adapters as fine-tuning in this way is considerably more computationally efficient. We also experimented with freezing the decoder’s attention to the encoder as well as adding an adapter on top of it, but these architecture designs are worse in terms of perplexity during MASS fine-tuning as well as BLEU scores during UNMT. We use the fine-tuned model to initialize an encoder-decoder Transformer, augmented with adapters."
2020.wmt-1.128,2020.emnlp-main.214,1,0.759967,"k Alexandra Chronopoulou, Dario Stojanovski, Viktor Hangya, Alexander Fraser Center for Information and Language Processing, LMU Munich, Germany {achron, stojanovski, hangyav, fraser}@cis.lmu.de Abstract lating between a high-resource and a low-resource language, in terms of monolingual data, which is the target of this year’s unsupervised shared task, is challenging. This paper describes the submission of LMU Munich to the WMT 2020 unsupervised shared task, in two language directions, German↔Upper Sorbian. Our core unsupervised neural machine translation (UNMT) system follows the strategy of Chronopoulou et al. (2020), using a monolingual pretrained language generation model (on German) and finetuning it on both German and Upper Sorbian, before initializing a UNMT model, which is trained with online backtranslation. Pseudoparallel data obtained from an unsupervised statistical machine translation (USMT) system is used to fine-tune the UNMT model. We also apply BPE-Dropout to the low-resource (Upper Sorbian) data to obtain a more robust system. We additionally experiment with residual adapters and find them useful in the Upper Sorbian→German direction. We explore sampling during backtranslation and curricul"
2020.wmt-1.128,N19-1423,0,0.0220642,"et as 7.7M SMT pseudo-parallel. We also backtranslate 10M more De sentences. This dataset is later used to fine-tune one of our systems. We refer to it as 10M Hsb-De SMT pseudo-parallel. 2.2 MASS We initialize our UNMT systems with an encoderdecoder Transformer (Vaswani et al., 2017), which is pretrained using the MASS (Song et al., 2019) objective. The model is pretrained by trying to reconstruct a sentence fragment given the remaining part of the sentence. The encoder takes a randomly masked fragment as input, while the decoder tries to predict the masked fragment. MASS is inspired by BERT (Devlin et al., 2019), but is more suitable for machine translation, as it pretrains the encoder-decoder and the attention mechanism, whereas BERT is an encoder Transformer. In order to pretrain the model, instead of training MASS on both De and Hsb, we initially train it on De. After this, we fine-tune it on both De and Hsb, following RE - LM (Chronopoulou et al., 2020). The intuition behind this is that, if we simultaneously train a cross-lingual model on unbalanced data, where X is much larger than Y , the model starts to overfit the low-resource side Y before being trained on all the high-resource language dat"
2020.wmt-1.128,D18-1045,0,0.0216243,"acktranslation) We initialize our UNMT models with FINE - TUNED MASS . Following Song et al. (2019), we train the systems in an unsupervised manner, using online backtranslation (Sennrich et al., 2016a) of the monolingual Hsb and De data, that were also used for pretraining. As proposed in Song et al. (2019), we do not use denoising auto-encoding (Vincent et al., 2008). We use online backtranslation to generate pseudo bilingual data for training. We refer to the resulting model as UNMT BASELINE. 2.5 Sampling We experiment with sampling instead of greedy decoding during online backtranslation. Edunov et al. (2018) show that sampling is beneficial for backtranslation compared to greedy decoding or beam search for systems trained on larger amounts 1086 of parallel data. Although we do not use any parallel data, we assumed that our initial UNMT baseline is of reasonable quality and that sampling would be beneficial. However, in order to provide a balance, we randomly use either greedy decoding or sampling during training. The frequency with which sampling is used is a hyperparameter which we set to 0.5. Sampling temperature is set to 0.95. 2.6 Curriculum learning Considering the high improvements achieved"
2020.wmt-1.128,D19-1632,0,0.034048,"Missing"
2020.wmt-1.128,kocmi-bojar-2017-curriculum,0,0.0206797,"ta. Although we do not use any parallel data, we assumed that our initial UNMT baseline is of reasonable quality and that sampling would be beneficial. However, in order to provide a balance, we randomly use either greedy decoding or sampling during training. The frequency with which sampling is used is a hyperparameter which we set to 0.5. Sampling temperature is set to 0.95. 2.6 Curriculum learning Considering the high improvements achieved by including SMT backtranslated data, we conduct experiments to determine a more meaningful way to feed the data to the model using curriculum learning (Kocmi and Bojar, 2017; Platanios et al., 2019; Zhang et al., 2019). We learn the curriculum using Bayesian Optimization (BO) for which we use an open source implementation4 . Similar work has been proposed for transfer learning (Ruder and Plank, 2017) and NMT (Wang et al., 2020). As we already have a reasonably trained NMT model, we use it to compute instance-level features for learning the curriculum. Each sentence pair from the SMT backtranslated data is represented with two features: the model scores for this pair in the original (backtranslation → monolingual sentence) and reverse direction (monolingual → back"
2020.wmt-1.128,D18-1549,0,0.0199857,"an→German direction. We explore sampling during backtranslation and curriculum learning to use SMT translations in a more principled way. Finally, we ensemble our bestperforming systems and reach a BLEU score of 32.4 on German→Upper Sorbian and 35.2 on Upper Sorbian→German. 1 Introduction Neural machine translation achieves remarkable results (Bahdanau et al., 2015; Vaswani et al., 2017) when large parallel training corpora are available. However, such corpora are only available for a limited number of languages. UNMT addresses this issue by using monolingual data only (Artetxe et al., 2018c; Lample et al., 2018). The performance of UNMT models is further improved using transfer learning from a pretrained cross-lingual model (Lample and Conneau, 2019; Song et al., 2019). However, pretraining also demands large monolingual corpora for both languages. Without abundant data, UNMT methods are often ineffective (Guzm´an et al., 2019). Therefore, effectively transWe participate in the WMT 2020 unsupervised machine translation shared task. The task includes two directions: German→Upper Sorbian (De→Hsb) and Upper Sorbian→German (Hsb→De). Our systems are constrained, using only the provided Hsb monolingual dat"
2020.wmt-1.128,N19-1119,0,0.0411198,"Missing"
2020.wmt-1.128,W18-6319,0,0.0223994,"Missing"
2020.wmt-1.128,N19-1189,0,0.0193026,"e assumed that our initial UNMT baseline is of reasonable quality and that sampling would be beneficial. However, in order to provide a balance, we randomly use either greedy decoding or sampling during training. The frequency with which sampling is used is a hyperparameter which we set to 0.5. Sampling temperature is set to 0.95. 2.6 Curriculum learning Considering the high improvements achieved by including SMT backtranslated data, we conduct experiments to determine a more meaningful way to feed the data to the model using curriculum learning (Kocmi and Bojar, 2017; Platanios et al., 2019; Zhang et al., 2019). We learn the curriculum using Bayesian Optimization (BO) for which we use an open source implementation4 . Similar work has been proposed for transfer learning (Ruder and Plank, 2017) and NMT (Wang et al., 2020). As we already have a reasonably trained NMT model, we use it to compute instance-level features for learning the curriculum. Each sentence pair from the SMT backtranslated data is represented with two features: the model scores for this pair in the original (backtranslation → monolingual sentence) and reverse direction (monolingual → backtranslation). The weights that determine the"
2020.wmt-1.128,2020.acl-main.170,0,0.0715955,"olingual data and De NewsCrawl monolingual data released for WMT. We pretrain a monolingual encoder-decoder model on a language generation task with the Masked Sequence to Sequence model (MASS) (Song et al., 2019) and fine-tune it on both languages of interest, following Chronopoulou et al. (2020). We then train it on UNMT, using online backtranslation. We use our USMT system to backtranslate monolingual data in both languages. This pseudo-parallel corpus serves to fine-tune our UNMT model. Iterative offline backtranslation is later leveraged, yielding a performance boost. We use BPE-Dropout (Provilkov et al., 2020) as a data augmentation technique, sampling instead of greedy decoding in online backtranslation, and curriculum learning to best include the SMT pseudo-parallel data. We also use residual adapters (Houlsby et al., 2019) to translate to the low-resource language (Hsb). Results Summary. The ensemble of our bestperforming systems yields the best performance in terms of BLEU1 among the participants of the unsupervised machine translation shared task. We release the code and our best models2 in order to facilitate reproduction of our work and experimentation in this field. We note that we have bui"
2020.wmt-1.128,D17-1038,0,0.0263883,"g or sampling during training. The frequency with which sampling is used is a hyperparameter which we set to 0.5. Sampling temperature is set to 0.95. 2.6 Curriculum learning Considering the high improvements achieved by including SMT backtranslated data, we conduct experiments to determine a more meaningful way to feed the data to the model using curriculum learning (Kocmi and Bojar, 2017; Platanios et al., 2019; Zhang et al., 2019). We learn the curriculum using Bayesian Optimization (BO) for which we use an open source implementation4 . Similar work has been proposed for transfer learning (Ruder and Plank, 2017) and NMT (Wang et al., 2020). As we already have a reasonably trained NMT model, we use it to compute instance-level features for learning the curriculum. Each sentence pair from the SMT backtranslated data is represented with two features: the model scores for this pair in the original (backtranslation → monolingual sentence) and reverse direction (monolingual → backtranslation). The weights that determine the importance of these features are learned separately for De→Hsb and Hsb→De, so that we have 4 features in total. BO runs for 30 trials. The feature weights are constrained in the range ["
2020.wmt-1.128,P16-1009,0,0.219369,"rms of perplexity during MASS fine-tuning as well as BLEU scores during UNMT. We use the fine-tuned model to initialize an encoder-decoder Transformer, augmented with adapters. The adapter-augmented model is then trained in an unsupervised way, using online backtranslation. All layers are trainable during unsupervised NMT training. We refer to this model as FINE - TUNED MASS + ADAPTERS . 2.4 Unsupervised NMT (online backtranslation) We initialize our UNMT models with FINE - TUNED MASS . Following Song et al. (2019), we train the systems in an unsupervised manner, using online backtranslation (Sennrich et al., 2016a) of the monolingual Hsb and De data, that were also used for pretraining. As proposed in Song et al. (2019), we do not use denoising auto-encoding (Vincent et al., 2008). We use online backtranslation to generate pseudo bilingual data for training. We refer to the resulting model as UNMT BASELINE. 2.5 Sampling We experiment with sampling instead of greedy decoding during online backtranslation. Edunov et al. (2018) show that sampling is beneficial for backtranslation compared to greedy decoding or beam search for systems trained on larger amounts 1086 of parallel data. Although we do not use"
2020.wmt-1.128,P16-1162,0,0.330446,"rms of perplexity during MASS fine-tuning as well as BLEU scores during UNMT. We use the fine-tuned model to initialize an encoder-decoder Transformer, augmented with adapters. The adapter-augmented model is then trained in an unsupervised way, using online backtranslation. All layers are trainable during unsupervised NMT training. We refer to this model as FINE - TUNED MASS + ADAPTERS . 2.4 Unsupervised NMT (online backtranslation) We initialize our UNMT models with FINE - TUNED MASS . Following Song et al. (2019), we train the systems in an unsupervised manner, using online backtranslation (Sennrich et al., 2016a) of the monolingual Hsb and De data, that were also used for pretraining. As proposed in Song et al. (2019), we do not use denoising auto-encoding (Vincent et al., 2008). We use online backtranslation to generate pseudo bilingual data for training. We refer to the resulting model as UNMT BASELINE. 2.5 Sampling We experiment with sampling instead of greedy decoding during online backtranslation. Edunov et al. (2018) show that sampling is beneficial for backtranslation compared to greedy decoding or beam search for systems trained on larger amounts 1086 of parallel data. Although we do not use"
2020.wmt-1.128,W19-5344,1,0.827236,"the fine-tuned MASS using online backtranslation. We use 4 GPUs to train each one of our UNMT models. We report BLEU using SacreBLEU (Post, 2018)7 on the provided test set. Unsupervised NMT + Pseudo-parallel MT. We train our UNMT systems using a pseudo-parallel supervised translation loss, in addition to the online backtranslation objective. We found out that aug7 BLEU+case.mixed+numrefs.1+smooth.exp+tok.13a+version.1.4.13 1088 menting UNMT systems with pseudo-parallel data obtained by USMT leads to major improvements in translation quality, as previous work has showed (Artetxe et al., 2018b; Stojanovski et al., 2019). 4 Results The results of our systems on the test set provided during development are presented in Table 1. Our USMT model (#1) performs competitively, but is largely outperformed by the UNMT baseline (#2). These results are interesting considering that both systems are trained using small amounts of monolingual Hsb data. We believe that the performance of the UNMT model is largely due to the MASS fine-tuning scheme which allowed us to obtain a strong pretrained model for both languages. We also observe (#3) that mixing greedy decoding and sampling during backtranslation is beneficial compare"
2020.wmt-1.128,2020.acl-main.689,0,0.0247685,"he frequency with which sampling is used is a hyperparameter which we set to 0.5. Sampling temperature is set to 0.95. 2.6 Curriculum learning Considering the high improvements achieved by including SMT backtranslated data, we conduct experiments to determine a more meaningful way to feed the data to the model using curriculum learning (Kocmi and Bojar, 2017; Platanios et al., 2019; Zhang et al., 2019). We learn the curriculum using Bayesian Optimization (BO) for which we use an open source implementation4 . Similar work has been proposed for transfer learning (Ruder and Plank, 2017) and NMT (Wang et al., 2020). As we already have a reasonably trained NMT model, we use it to compute instance-level features for learning the curriculum. Each sentence pair from the SMT backtranslated data is represented with two features: the model scores for this pair in the original (backtranslation → monolingual sentence) and reverse direction (monolingual → backtranslation). The weights that determine the importance of these features are learned separately for De→Hsb and Hsb→De, so that we have 4 features in total. BO runs for 30 trials. The feature weights are constrained in the range [−1, 1]. Each trial runs 5.4K"
2020.wmt-1.131,P18-1073,0,0.310927,"resented in this paper are neural machine translation (NMT) systems based on the Transformer architecture (Vaswani et al., 2017). We experiment with various data preparation and augmentation techniques: back-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited the claims about data needs of supervised NMT and showed that with recent innovations in neural network and careful hyper-parameter tuning, NMT models outperform their phrase-based counterparts with training data as small as 100k tokens (15 times smaller than the data provided for this shared task). Standard techniques for low-resource machine translation include data augmentat"
2020.wmt-1.131,D18-1399,0,0.213784,"resented in this paper are neural machine translation (NMT) systems based on the Transformer architecture (Vaswani et al., 2017). We experiment with various data preparation and augmentation techniques: back-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited the claims about data needs of supervised NMT and showed that with recent innovations in neural network and careful hyper-parameter tuning, NMT models outperform their phrase-based counterparts with training data as small as 100k tokens (15 times smaller than the data provided for this shared task). Standard techniques for low-resource machine translation include data augmentat"
2020.wmt-1.131,W19-5301,0,0.0568547,"Missing"
2020.wmt-1.131,Q17-1010,0,0.0347637,"at we changed compared to the original system and keep the description of the other steps brief. In the first step, we build 300-dimensional monolingual n-gram embeddings for both Czech and SorMonolingual Data In total 696k monolingual Sorbian sentences were provided by the organizers. We noticed that the monolingual Sorbian data contain many OCRrelated errors originating from hyphenation. We thus removed all sentences ending with a hyphen. Additionally, we merged tokens ending with a hyphen with the adjacent one if such merging results 4.1 1105 Unsupervised SMT bian using FastText skip-gram (Bojanowski et al., 2017) on the above mentioned monolingual data. We restrict the vocabulary to the most frequent 200k, 400k, and 400k 1-, 2- and 3-grams, respectively. We map these embeddings to a shared bilingual space using VecMap (Artetxe et al., 2018a). In contrast to the original unsupervised SMT pipeline, which builds bilingual word embeddings (BWEs) without any cross-lingual signal, we use identical words occurring in both languages as the seed lexicon for the mapping. We found that the available small monolingual Sorbian corpus is not adequate to build BWEs in a fully unsupervised way. The corpora are tokeni"
2020.wmt-1.131,W19-5206,0,0.0159603,"ns, we limit the data mixes for training the Big architectures to 180M parallel sentences. One third of the data mix consists of oversampled authentic parallel data. In one set of experiments (Models 3, 4), the rest of the data consists of synthetic data: an equal number of samples of forward- and back-translation (which means that the monolingual Sorbian data is oversampled approximately 80×). In another set of experiments (Model 5), we additionally sample data from the machine-translated Czech-German data set where the Czech part has been automatically translated to Upper Sorbian. Following Caswell et al. (2019), we tag the synthetic data, having a separate tag for each of the synthetic data types. Further, we experiment with finetuning models originally trained for translation between Czech and German. The data for the parent models is prepared using the same protocol as for Model 4. Following Kocmi and Bojar (2018), we train the parent model until convergence and continue training with the German-Sorbian data. Based on preliminary results, we use the data mix for Model 4 for the German-to-Sorbian translation direction and the data mix for Model 5 for translating from Sorbian into German. 1108 Model"
2020.wmt-1.131,P17-2090,0,0.0157647,"howed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited the claims about data needs of supervised NMT and showed that with recent innovations in neural network and careful hyper-parameter tuning, NMT models outperform their phrase-based counterparts with training data as small as 100k tokens (15 times smaller than the data provided for this shared task). Standard techniques for low-resource machine translation include data augmentation with rulebased substitutions (Fadaee et al., 2017), by sam1104 Proceedings of the 5th Conference on Machine Translation (WMT), pages 1104–1111 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics Data # sent. # tok. # tok. # sent. Train de hsb 60k 822k 738k 13.7 12.3 Devel de hsb 2k 28k 25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Prov"
2020.wmt-1.131,L18-1550,0,0.0200445,"as well. 3.3 For transfer learning and the creation of synthetic data, we also used German-Czech parallel data. We downloaded all available parallel datasets from the Opus project (Tiedemann, 2012), which gave us 20.8M parallel sentences, which we further filtered. First, we filtered the parallel sentences by length. We estimated the mean and the standard deviation of the length ratio of German and Czech sentences and kept only those sentence pairs whose length ratio fitted into the interval of two times standard deviation around the mean. Then, we applied a language identifier from FastText (Grave et al., 2018) and only kept sentence pairs identified as GermanCzech. The filtering lefts us with 14.7M parallel sentences. 4 Authentic Parallel Data German-Czech Data Synthetic data from Czech-German The organizers of the shared task provided a parallel corpus of 60k sentences, and validation and development test data of 2k sentences each. The basic statistics about the data are presented in Table 1. Note that the sentences are on average much shorter and therefore also likely to be structurally simpler than in the type of sentences usually used in the WMT test sets. Since Upper Sorbian is related to Czec"
2020.wmt-1.131,W18-2703,0,0.0131086,"ne Translation (WMT), pages 1104–1111 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics Data # sent. # tok. # tok. # sent. Train de hsb 60k 822k 738k 13.7 12.3 Devel de hsb 2k 28k 25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sentences and did 12k token merges. The monolingual Sorbian data were used for traini"
2020.wmt-1.131,P18-4020,0,0.0268715,"Missing"
2020.wmt-1.131,W18-6325,0,0.0731864,"25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sentences and did 12k token merges. The monolingual Sorbian data were used for training the unsupervised Czech-Sorbian translation system (see Section 4.1) and for backtranslation in Sorbian-German systems. Besides, we use 60M German and 60M Czech sentences from the NewsCrawl data provided as mo"
2020.wmt-1.131,P07-2045,0,0.00940763,"ta. We restrict the vocabulary to the most frequent 200k, 400k, and 400k 1-, 2- and 3-grams, respectively. We map these embeddings to a shared bilingual space using VecMap (Artetxe et al., 2018a). In contrast to the original unsupervised SMT pipeline, which builds bilingual word embeddings (BWEs) without any cross-lingual signal, we use identical words occurring in both languages as the seed lexicon for the mapping. We found that the available small monolingual Sorbian corpus is not adequate to build BWEs in a fully unsupervised way. The corpora are tokenized and true-cased using Moses tools (Koehn et al., 2007). We note that because there are no available language rules for Sorbian, we used Czech rules for tokenization, which is reasonable because of the similarity of the two languages. We build phrase tables for both translation directions. For each source n-gram, we take 100 candidates with the closest embeddings based on cosine similarity and additional 100 candidates with the smallest edit distance. We calculate 5 scores for each pair: phrase and lexical translation probabilities and their inverse as in (Artetxe et al., 2018b), and their normalized edit distance. For phrases, the latter is calcu"
2020.wmt-1.131,W17-3204,0,0.0135707,"Western Slavic language related to Czech and Polish, it is possible to take advantage of relatively rich resources collected for these two languages. The German-Sorbian systems presented in this paper are neural machine translation (NMT) systems based on the Transformer architecture (Vaswani et al., 2017). We experiment with various data preparation and augmentation techniques: back-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited the claims about data needs of supervised NMT and showed that with recent innovations in neural network and careful hyper-parameter tuning, NMT models outperform their phrase-based counterparts with trainin"
2020.wmt-1.131,D18-2012,0,0.0163438,"k warm-up steps for the Base architecture and 32k warm-up steps for the Big architecture. The Base architecture is used for the initial systems which generate synthetic data via backwardand forward-translation. We use the Big architecture for the rest of the systems. 5.2 Training Data Preparation An overview of the data generation and system training steps is provided in Figure 1. We use a common BPE-based vocabulary (Sennrich et al., 2016c) for all systems which allows us to better ensemble our systems. Instead of proper tokenization, we use the pre-tokenization heuristic from SentencePiece (Kudo and Richardson, 2018) as implemented in YouTokenToMe.2 The BPE vocabulary consists of 16k merges and was fit using the authentic parallel training data only. 2 https://github.com/VKCOM/YouTokenToMe We apply BPE-dropout (Provilkov et al., 2020) of 0.1 on both the source and the target side of the data. We oversample the monolingual data 1000 times and with different segmentations (Model 2). We hypothesize that in the very low-resource setup, the BPE dropout serves more as a dataaugmentation technique than as regularization. Due to hardware limitations, we limit the data mixes for training the Big architectures to 1"
2020.wmt-1.131,J82-2005,0,0.69835,"Missing"
2020.wmt-1.131,P16-1009,0,0.537623,"rently low-resource problem without any chance that the resources available for Sorbian would ever approach the size of resources for languages spoken by millions of people. On the other hand, being a Western Slavic language related to Czech and Polish, it is possible to take advantage of relatively rich resources collected for these two languages. The German-Sorbian systems presented in this paper are neural machine translation (NMT) systems based on the Transformer architecture (Vaswani et al., 2017). We experiment with various data preparation and augmentation techniques: back-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited th"
2020.wmt-1.131,P16-1162,0,0.738073,"rently low-resource problem without any chance that the resources available for Sorbian would ever approach the size of resources for languages spoken by millions of people. On the other hand, being a Western Slavic language related to Czech and Polish, it is possible to take advantage of relatively rich resources collected for these two languages. The German-Sorbian systems presented in this paper are neural machine translation (NMT) systems based on the Transformer architecture (Vaswani et al., 2017). We experiment with various data preparation and augmentation techniques: back-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited th"
2020.wmt-1.131,P19-1021,0,0.0496486,"ack-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited the claims about data needs of supervised NMT and showed that with recent innovations in neural network and careful hyper-parameter tuning, NMT models outperform their phrase-based counterparts with training data as small as 100k tokens (15 times smaller than the data provided for this shared task). Standard techniques for low-resource machine translation include data augmentation with rulebased substitutions (Fadaee et al., 2017), by sam1104 Proceedings of the 5th Conference on Machine Translation (WMT), pages 1104–1111 c Online, November 19–20, 2020. 2020 Association for Computati"
2020.wmt-1.131,I17-2050,0,0.0153509,"12.3 Devel de hsb 2k 28k 25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sentences and did 12k token merges. The monolingual Sorbian data were used for training the unsupervised Czech-Sorbian translation system (see Section 4.1) and for backtranslation in Sorbian-German systems. Besides, we use 60M German and 60M Czech sentences from the NewsC"
2020.wmt-1.131,tiedemann-2012-parallel,0,0.0222884,"ermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sentences and did 12k token merges. The monolingual Sorbian data were used for training the unsupervised Czech-Sorbian translation system (see Section 4.1) and for backtranslation in Sorbian-German systems. Besides, we use 60M German and 60M Czech sentences from the NewsCrawl data provided as monolingual data for WMT shared tasks (Barrault et al., 2019). The monolingual data were used for generating synthetic training data via back- and forward-translation both for the German-Sorbian and German-Czech systems. In addition, the Czech monoling"
2020.wmt-1.131,P02-1040,0,0.108181,"de→hsb) translations. 5.3 Model Ensembling Following Sennrich et al. (2016a), we also experiment with ensembling several systems and combining systems trained in the left-to-right and right-toleft direction. We trained four models from random initialization and three models by transferring from CzechGerman translation. Note that the transferred models were initialized by the same model and only differed in the order of the training data. Further, we trained two models in the right-toleft direction, starting from random initialization. 6 Results The quantitative results in terms of BLEU score (Papineni et al., 2002) and ChrF (Popovi´c, 2017) score are presented in Table 3. The results were measured using SacreBLEU.3 The Base architecture trained using the parallel data only (Model 1) reaches a surprisingly high BLEU score, which is probably due to the quality of the manually curated training data, domain closeness of the train and test data, and relatively simple sentences both in the train and test sets. The data augmentation using BPE-dropout (Model 2) seems to have a substantial effect on the translation quality, improving the translation by 6–7 BLEU points. This is a much larger effect than Provilkov"
2020.wmt-1.131,W17-4770,0,0.0355876,"Missing"
2020.wmt-1.131,D18-1100,0,0.014892,"s (Fadaee et al., 2017), by sam1104 Proceedings of the 5th Conference on Machine Translation (WMT), pages 1104–1111 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics Data # sent. # tok. # tok. # sent. Train de hsb 60k 822k 738k 13.7 12.3 Devel de hsb 2k 28k 25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sente"
2020.wmt-1.131,2020.acl-main.170,0,0.187155,"017), by sam1104 Proceedings of the 5th Conference on Machine Translation (WMT), pages 1104–1111 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics Data # sent. # tok. # tok. # sent. Train de hsb 60k 822k 738k 13.7 12.3 Devel de hsb 2k 28k 25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sentences and did 12k token me"
2020.wmt-1.131,P12-1049,1,0.779845,"er Sorbian, using transliteration. More precisely, we transliterate Czech words from the German-Czech parallel data which were not seen by the SMT system during training, assuming that the translations of these words are missing in the Sorbian vocabulary on the target side as well. We extracted the training data for the transliteration system using a preliminary transliteration mining model, filtered the data using a preliminary transliteration model, and trained the final transliteration model on the filtered data. Transliteration mining. Our transliteration mining is similar to the model by Sajjad et al. (2012). It consists of a transliteration submodel and a noise submodel. The transliteration submodel is a unigram model over transliteration units (TUs) which jointly generates a source and a target language string. The English-German transliteration pair (Gorbatchev, Gorbatschow) could be generated as the following sequence of TUs: G:G o:o r:r b:b a:a t:t s: c:c h:h e:o v:w. We use only 1-1, 0-1, and 1-0 TUs. The probability p(a) of a sequence of TUs is the product of the unigram probabilities p(ai ): p(a) = p(a1 , ..., an ) = n Y p(ai ) i=1 Probability ptrans (s, t) of a string pair is obtained by"
2020.wmt-1.131,D16-1163,0,0.0240659,"60k 822k 738k 13.7 12.3 Devel de hsb 2k 28k 25k 13.8 12.5 Devel test de hsb 2k 28k 25k 13.9 12.7 German-Czech newstest2019 de cs 2k 49k 43k 24.5 22.0 German-Czech parallel de cs 14.7M 234M 219M 15.9 14.8 Table 1: Statistics on the parallel data compared to German-Czech News Test 2019 and parallel GermanCzech data (see Section 3.3). pling synthetic noise (Wang et al., 2018; Provilkov et al., 2020), or by iterative back-translation (Hoang et al., 2018). Another class of approaches relies on transfer learning from models trained for highresource language pairs of more or less similar languages (Zoph et al., 2016; Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). 3 Data We used several types of data to train our systems. The organizers provided authentic parallel data and Sorbian monolingual data. We also use German and Czech News Crawl data and Czech-German parallel data available in Opus (Tiedemann, 2012). 3.1 in a known Sorbian word. This filtered out 1.6k sentences and did 12k token merges. The monolingual Sorbian data were used for training the unsupervised Czech-Sorbian translation system (see Section 4.1) and for backtranslation in Sorbian-German systems. Besides, we use 60M German and 60M Czech"
2020.wmt-1.131,W16-2323,0,0.295248,"rently low-resource problem without any chance that the resources available for Sorbian would ever approach the size of resources for languages spoken by millions of people. On the other hand, being a Western Slavic language related to Czech and Polish, it is possible to take advantage of relatively rich resources collected for these two languages. The German-Sorbian systems presented in this paper are neural machine translation (NMT) systems based on the Transformer architecture (Vaswani et al., 2017). We experiment with various data preparation and augmentation techniques: back-translation (Sennrich et al., 2016b), finetuning systems trained for translation between Czech 2 Related Work Until recently, phrase-based approaches were believed to be more suitable for low-resource translation. Koehn and Knowles (2017) claimed that a parallel dataset of at least 107 tokens is required for NMT to outperform phrase-based MT. This view was also supported by the results of Artetxe et al. (2018b) and Lample et al. (2018), who showed that phrase-based approaches work well for unsupervised MT, at least in the early stages of the iterative back-translation procedure. Recently, Sennrich and Zhang (2019) revisited th"
2020.wmt-1.80,2020.wmt-1.127,0,0.0907538,"Missing"
2020.wmt-1.80,2020.wmt-1.128,1,0.768444,"Missing"
2020.wmt-1.80,2020.wmt-1.130,0,0.0847551,"Missing"
2020.wmt-1.80,2020.wmt-1.132,0,0.094985,"Missing"
2020.wmt-1.80,2020.wmt-1.133,0,0.0480773,"Missing"
2020.wmt-1.80,2020.wmt-1.22,0,0.246876,"lopment (likewise, the participants were asked to not use it as a parallel training corpus). We would like to thank Jindˇrich Libovick´y for creating the data splits and for work on the training data. The specific data sets are presented in Table 1. The translation output was submitted as real case, detokenized, and in SGML format. We used the Matrix for submission, thanks to Barry Haddow for assistance. The standard script wrap-xml.perl was used to create the sgm files for upload. German and Upper Sorbian Wikipedia, see (Dutta et al., 2020) for more details. The creators of the other system (Li et al., 2020) used parallel data for English to German to initialize an unsupervised system, which is a reasonable scenario to consider. This was highly effective. We suggest that this result be used as an initial benchmark for multilingual transfer-based unsupervised systems. We consider these results to be separate from the simpler unsupervised benchmark that was previously proposed. See the subsequent analysis and discussion for more details. 5.3 Very Low Resource MT A Moses baseline from the Witaj Sprachzentrum using only the data from the shared task web page scored 46.36 for DE-HSB (BLEU-cased, 11b)"
2020.wmt-1.80,2020.wmt-1.131,1,0.520117,"Missing"
2020.wmt-1.80,2020.wmt-1.136,0,0.0526147,"Missing"
2021.acl-short.30,E17-1088,0,0.151659,"enated source and target language corpora exploiting the shared character n-grams in them. Similarly, the shared source and target language subword tokens are used as a cheap cross-lingual signal in Devlin et al. (2019); Conneau and Lample (2019). Furthermore, the advantages of mapping and jointly training the MWEs and BWEs were combined in Wang et al. (2020) for even better BWEs. While these approaches already try to minimize the amount of bilingual signal needed for cross-lingual applications, they still require a larger amount of monolingual data to train semantically rich word embeddings (Adams et al., 2017). This becomes a problem when one of the two languages does not have sufficient monolingual data available (Artetxe et al., 2020). In this case, training a good embedding space can be infeasible which means mapping based approaches are not able to build useful BWEs (Michel et al., 2020). In this paper we introduce a new approach to building BWEs when one of the languages only has limited available monolingual data. Instead of using mapping or joint approaches, this paper takes the middle ground by making use of the MWEs of a resource rich language and training the low resource language embeddi"
2021.acl-short.30,N09-1003,0,0.189842,"Missing"
2021.acl-short.30,D16-1250,0,0.0162304,"esults not only in improved BWEs and bilingual lexicon induction performance, but also in improved target language MWE quality as measured using monolingual word similarity. 1 Introduction Bilingual Word Embeddings are useful for crosslingual tasks such as cross-lingual transfer learning or machine translation. Mapping based BWE approaches rely only on a cheap bilingual signal, in the form of a seed lexicon, and monolingual data to train monolingual word embeddings (MWEs) for each language, which makes them easily applicable in low-resource scenarios (Mikolov et al., 2013b; Xing et al., 2015; Artetxe et al., 2016). It was shown that BWEs can be built using a small seed lexicon (Artetxe et al., 2017) or without any word pairs (Lample et al., 2018a; Artetxe et al., 2018) relying on the assumption of isomorphic MWE spaces. Recent approaches showed that BWEs can be built without the mapping step. Lample et al. (2018b) built FAST T EXT embeddings (Bojanowski et al., 2017) on the concatenated source and target language corpora exploiting the shared character n-grams in them. Similarly, the shared source and target language subword tokens are used as a cheap cross-lingual signal in Devlin et al. (2019); Conne"
2021.acl-short.30,P17-1042,0,0.0686822,"in improved target language MWE quality as measured using monolingual word similarity. 1 Introduction Bilingual Word Embeddings are useful for crosslingual tasks such as cross-lingual transfer learning or machine translation. Mapping based BWE approaches rely only on a cheap bilingual signal, in the form of a seed lexicon, and monolingual data to train monolingual word embeddings (MWEs) for each language, which makes them easily applicable in low-resource scenarios (Mikolov et al., 2013b; Xing et al., 2015; Artetxe et al., 2016). It was shown that BWEs can be built using a small seed lexicon (Artetxe et al., 2017) or without any word pairs (Lample et al., 2018a; Artetxe et al., 2018) relying on the assumption of isomorphic MWE spaces. Recent approaches showed that BWEs can be built without the mapping step. Lample et al. (2018b) built FAST T EXT embeddings (Bojanowski et al., 2017) on the concatenated source and target language corpora exploiting the shared character n-grams in them. Similarly, the shared source and target language subword tokens are used as a cheap cross-lingual signal in Devlin et al. (2019); Conneau and Lample (2019). Furthermore, the advantages of mapping and jointly training the M"
2021.acl-short.30,2020.acl-main.658,0,0.215021,"get language subword tokens are used as a cheap cross-lingual signal in Devlin et al. (2019); Conneau and Lample (2019). Furthermore, the advantages of mapping and jointly training the MWEs and BWEs were combined in Wang et al. (2020) for even better BWEs. While these approaches already try to minimize the amount of bilingual signal needed for cross-lingual applications, they still require a larger amount of monolingual data to train semantically rich word embeddings (Adams et al., 2017). This becomes a problem when one of the two languages does not have sufficient monolingual data available (Artetxe et al., 2020). In this case, training a good embedding space can be infeasible which means mapping based approaches are not able to build useful BWEs (Michel et al., 2020). In this paper we introduce a new approach to building BWEs when one of the languages only has limited available monolingual data. Instead of using mapping or joint approaches, this paper takes the middle ground by making use of the MWEs of a resource rich language and training the low resource language embeddings on top of it. For this, a bilingual seed lexicon is used to initialize the representation of target language words by taking"
2021.acl-short.30,2020.lrec-1.313,1,0.558242,"and jointly training the MWEs and BWEs were combined in Wang et al. (2020) for even better BWEs. While these approaches already try to minimize the amount of bilingual signal needed for cross-lingual applications, they still require a larger amount of monolingual data to train semantically rich word embeddings (Adams et al., 2017). This becomes a problem when one of the two languages does not have sufficient monolingual data available (Artetxe et al., 2020). In this case, training a good embedding space can be infeasible which means mapping based approaches are not able to build useful BWEs (Michel et al., 2020). In this paper we introduce a new approach to building BWEs when one of the languages only has limited available monolingual data. Instead of using mapping or joint approaches, this paper takes the middle ground by making use of the MWEs of a resource rich language and training the low resource language embeddings on top of it. For this, a bilingual seed lexicon is used to initialize the representation of target language words by taking the pre-trained vectors of their source pairs prior to target side training, which acts as an informed starting point to shape the vector space during the pro"
2021.acl-short.30,W19-5301,0,0.0530867,"Missing"
2021.acl-short.30,Q17-1010,0,0.518573,"cheap bilingual signal, in the form of a seed lexicon, and monolingual data to train monolingual word embeddings (MWEs) for each language, which makes them easily applicable in low-resource scenarios (Mikolov et al., 2013b; Xing et al., 2015; Artetxe et al., 2016). It was shown that BWEs can be built using a small seed lexicon (Artetxe et al., 2017) or without any word pairs (Lample et al., 2018a; Artetxe et al., 2018) relying on the assumption of isomorphic MWE spaces. Recent approaches showed that BWEs can be built without the mapping step. Lample et al. (2018b) built FAST T EXT embeddings (Bojanowski et al., 2017) on the concatenated source and target language corpora exploiting the shared character n-grams in them. Similarly, the shared source and target language subword tokens are used as a cheap cross-lingual signal in Devlin et al. (2019); Conneau and Lample (2019). Furthermore, the advantages of mapping and jointly training the MWEs and BWEs were combined in Wang et al. (2020) for even better BWEs. While these approaches already try to minimize the amount of bilingual signal needed for cross-lingual applications, they still require a larger amount of monolingual data to train semantically rich wor"
2021.acl-short.30,N19-1423,0,0.00866048,"2015; Artetxe et al., 2016). It was shown that BWEs can be built using a small seed lexicon (Artetxe et al., 2017) or without any word pairs (Lample et al., 2018a; Artetxe et al., 2018) relying on the assumption of isomorphic MWE spaces. Recent approaches showed that BWEs can be built without the mapping step. Lample et al. (2018b) built FAST T EXT embeddings (Bojanowski et al., 2017) on the concatenated source and target language corpora exploiting the shared character n-grams in them. Similarly, the shared source and target language subword tokens are used as a cheap cross-lingual signal in Devlin et al. (2019); Conneau and Lample (2019). Furthermore, the advantages of mapping and jointly training the MWEs and BWEs were combined in Wang et al. (2020) for even better BWEs. While these approaches already try to minimize the amount of bilingual signal needed for cross-lingual applications, they still require a larger amount of monolingual data to train semantically rich word embeddings (Adams et al., 2017). This becomes a problem when one of the two languages does not have sufficient monolingual data available (Artetxe et al., 2020). In this case, training a good embedding space can be infeasible which"
2021.acl-short.30,I05-1067,0,0.071626,"Missing"
2021.acl-short.30,J82-2005,0,0.668161,"Missing"
2021.acl-short.30,P18-1072,0,0.144673,"Missing"
2021.acl-short.30,N15-1104,0,0.0248071,"that our approach results not only in improved BWEs and bilingual lexicon induction performance, but also in improved target language MWE quality as measured using monolingual word similarity. 1 Introduction Bilingual Word Embeddings are useful for crosslingual tasks such as cross-lingual transfer learning or machine translation. Mapping based BWE approaches rely only on a cheap bilingual signal, in the form of a seed lexicon, and monolingual data to train monolingual word embeddings (MWEs) for each language, which makes them easily applicable in low-resource scenarios (Mikolov et al., 2013b; Xing et al., 2015; Artetxe et al., 2016). It was shown that BWEs can be built using a small seed lexicon (Artetxe et al., 2017) or without any word pairs (Lample et al., 2018a; Artetxe et al., 2018) relying on the assumption of isomorphic MWE spaces. Recent approaches showed that BWEs can be built without the mapping step. Lample et al. (2018b) built FAST T EXT embeddings (Bojanowski et al., 2017) on the concatenated source and target language corpora exploiting the shared character n-grams in them. Similarly, the shared source and target language subword tokens are used as a cheap cross-lingual signal in Devl"
2021.acl-short.30,W06-1104,0,0.0286249,"for English-German. Baselines (MUSE) and proposed methods, reporting acc@5 (acc@1). Model // Corpus Size Baseline Word2Vec (CBOW) Trained and Averaged (CBOW) 1M 0.0 (0.0) 1.6 (0.4) 2M 0.7 (0.0) 4.7 (1.6) 5M 6.0 (1.9) 13.1 (5.6) 10M 18.1 (7.9) 26.3 (13.4) 20M 28.0 (15.1) 35.5 (18.4) 37M 37.0 (20.4) 44.7 (24.2) Table 2: Anchor method vs. baseline (MUSE) at varying data sizes reporting acc@5 (acc@1) for EnglishMacedonian. Algorithm Baseline Michel et al. 50D Baseline Michel et al. 300D Anchor fixed not averaged CBOW 300D Anchor trained not averaged CBOW 300D Acc@5 0.5 0.0 2.6 4.3 2009) and ZG22 (Zesch and Gurevych, 2006), and report the averaged Spearman’s rho correlation between cosine similarity of vector pairs and human annotations. Similar monolingual datasets are not available for Macedonian and Hiligaynon. In Figure 2 the effect of employing the anchor method on monolingual word similarity performance is compared against Word2Vec CBOW trained without anchor initialization. The improvements across different training corpora sizes are in favor of the proposed method, suggesting that it can be employed to improve performance on monolingual tasks. Overall this serves to demonstrate the advantage of the anch"
2021.adaptnlp-1.9,W17-4712,0,0.0141829,"domains can be taken into consideration. Furthermore, this approach assumes that sufficient domain information can be obtained from a single sentence alone. Document-level classifiers (Xu et al., 2007) address this problem, but they are not jointly trained with the MT model. Further work in multi-domain MT is Foster and Kuhn (2007) who propose mixture models to dynamically adapt to the target domain, Foster et al. (2010) who build on this work and include instance weighting, Zeng et al. (2018) where domain-specific and domain-shared annotations from adversarial domain classifiers are used and Britz et al. (2017) where a discriminator is used to backpropagate domain signals. Continued training is an established technique for domain adaptation if access to in-domain resources is possible. The method entails initially training on out-of-domain data, and then continuing training on in-domain data (Luong and Manning, 2015). Chen et al. (2017) and Zhang and Xiong (2018) improve upon this paradigm by integrating a domain classifier or a domain similarity metric into NMT and modifying the training cost based on weights indicating in-domain or out-ofdomain data. Sajjad et al. (2017) and Farajian et al. (2017)"
2021.adaptnlp-1.9,W17-3205,0,0.0175875,"who propose mixture models to dynamically adapt to the target domain, Foster et al. (2010) who build on this work and include instance weighting, Zeng et al. (2018) where domain-specific and domain-shared annotations from adversarial domain classifiers are used and Britz et al. (2017) where a discriminator is used to backpropagate domain signals. Continued training is an established technique for domain adaptation if access to in-domain resources is possible. The method entails initially training on out-of-domain data, and then continuing training on in-domain data (Luong and Manning, 2015). Chen et al. (2017) and Zhang and Xiong (2018) improve upon this paradigm by integrating a domain classifier or a domain similarity metric into NMT and modifying the training cost based on weights indicating in-domain or out-ofdomain data. Sajjad et al. (2017) and Farajian et al. (2017) use continued training in a multi-domain setup and propose various ways of fine-tuning to in-domain data. Standard continued training (Luong and Manning, 2015) leads to catastrophic forgetting, evident by the degrading performance on the out-of-domain dataset. Freitag and Al-Onaizan (2016) address this issue by ensembling the ori"
2021.adaptnlp-1.9,N13-1073,0,0.0298407,"28.7 28.9 22.8 23.4† 35.1 35.7† 33.0 33.4 29.2 29.4 29.8 30.4‡ 29.7 30.1 30.2 30.6† Table 7: Domain adaptation results on PatTR for SentBase and DomEmb(avg). †- p &lt; 0.01, ‡- p &lt; 0.05. domain TED Europarl NewsCommentary OpenSubtitles Rapid Ubuntu PatTR TED Average Joint Translation of Domain-Specific Words We also evaluated the translation of domainspecific words. We extracted the most important words from a domain based on TF-IDF scores and selected the top 100 with the highest scores which have more than 3 characters. Next, we follow Liu et al. (2018) and compute alignments using fastalign (Dyer et al., 2013) based on the training set and force align the test set source sentences to the references and generated translations. We then compute the F1 score of the translation of the domainspecific words. Results are shown in Table 6. We SentBase DomEmb(a) 36.1 36.6‡ ensemble 30.4 30.8† 31.9 32.2‡ 24.6 25.4† 38.8 39.5† 32.7 32.4 16.9 17.0‡ 35.4 35.8‡ 30.1 30.4 28.4 28.8† Table 8: Domain adaptation results on TED for SentBase and DomEmb(avg). †- p &lt; 0.01, ‡- p &lt; 0.05. DomEmb(avg) improved the F1 score across all domains with the largest improvements on OpenSubtitles and TED. Our assumption is that the b"
2021.adaptnlp-1.9,E17-3017,0,0.0782703,"Missing"
2021.adaptnlp-1.9,N19-1191,0,0.0219587,"These domain tags are mapped to corresponding embeddings and are either inserted at the beginning of the sentence or concatenated to the token-level embeddings. The domain embeddings are reserved for specific domains and are fixed for all sentences in a given domain. The number of distinct domain embeddings is limited to the number of known domains. Tars and Fishel (2018) define a similar approach which uses oracle domain tags and Naradowsky et al. (2020) adapt to unseen domains using bandit learning techniques. The method relies on explicit user feedback which is not always easily available. Bapna and Firat (2019) propose a retrieval-based method that, at inference time, adapts to domains not seen during training. However, they assume access to in-domain parallel data at inference time, and they retrieve parallel phrases from this in-domain data. In our 81 Transformer sum average pooling position embeddings token embeddings Document-level context t1 t2 t3 tN Figure 1: Domain embedding Transformer. multi-head attn and hierarchical attention which first computes sentence-level attention scores and subsequently word-level scores. However, for domain adaptation, the full encoder representation is too granu"
2021.adaptnlp-1.9,N10-1000,0,0.0250575,"Missing"
2021.adaptnlp-1.9,D19-6503,0,0.0178905,"zero-resource experiments, we have no access to in-domain parallel data. 3 Context-aware NMT A separate field of inquiry is context-aware NMT which proposes integrating cross-sentence context (Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita et al., 2018; Zhang et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Tu et al., 2018; Maruf and Haffari, 2018; Voita et al., 2019b; Maruf et al., 2019; Yang et al., 2019; Voita et al., 2019a; Tan et al., 2019). These works show that context helps with discourse phenomena such as anaphoric pronouns, deixis and lexical cohesion. Kim et al. (2019) show that using context can improve topicaware lexical choice, but in a single-domain setup. Model The models we propose in this work are extensions of the Transformer (Vaswani et al., 2017). The first approach introduces separate domain embeddings applied to each token-level embedding. The second is conceptually based on previous context-aware models (Voita et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Zhang et al., 2018). Both models are capable of handling documentlevel context. We modify the training data so that all sentences have access to the previous sentences w"
2021.adaptnlp-1.9,D18-1325,0,0.341492,"ptation technique such as using special domain tokens and features (Kobus et al., 2017; Tars and Fishel, 2018). However, it is not always easy to determine the domain of a sentence without larger context. Access to document-level context makes it more probable that domain signals can be observed, i.e., words representative of a domain are more likely to be encountered. We hypothesize that this facilitates better matching of unseen domains to domains seen during training and provide experimental evidence supporting this hypothesis. Recent work has shown that contextual information improves MT (Miculicich et al., 2018; Voita et al., 2019b; Maruf et al., 2019), often by improving anaphoric pronoun translation quality, which can be addressed well with limited context. However, in order to address discourse phenomena such as coherence and cohesion, access to larger context is preferable. Voita et al. (2019b,a) were the first to show large improvements on lexical cohesion in a controlled setting using challenge sets. However, previous work did not make clear whether previous models can help with disambiguation of polysemous words where the sense is domain-dependent. In this work, we study the usefulness of doc"
2021.adaptnlp-1.9,kobus-etal-2017-domain,0,0.184973,"g the original and the fine-tuned model. We show that our model obtains significant improvements compared to a baseline with the ensembling paradigm. In contrast to these previous works, we do not know the domains during training. Our proposed approaches model the domain implicitly by looking at document-level context. Moreover, we evaluate performance on domains not seen during training. Related Work Domain adaptation Several previous works address the problem that standard NMT may fail to adequately model all domains in a multi-domain setup even when all of the domains are known in advance. Kobus et al. (2017) introduce using domain tags for this problem, a similar method to the domain embedding model in our paper. These domain tags are mapped to corresponding embeddings and are either inserted at the beginning of the sentence or concatenated to the token-level embeddings. The domain embeddings are reserved for specific domains and are fixed for all sentences in a given domain. The number of distinct domain embeddings is limited to the number of known domains. Tars and Fishel (2018) define a similar approach which uses oracle domain tags and Naradowsky et al. (2020) adapt to unseen domains using ba"
2021.adaptnlp-1.9,W04-3250,0,0.142336,"://www.cis.uni-muenchen.de/ dario/projects/zero_domain ˜ 83 domain Europarl NewsCommentary OpenSubtitles Rapid Ubuntu TED PatTR train 1.8M 0.3M 2.2M 1.5M 11K 0.2M 1.2M dev 3.2K 1.5K 2.7K 2.5K 1.1K 1.7K 2.0K test 3.0K 1.5K 3.3K 2.5K 0.6K 1.0K 2.2K 5 5.1 Zero-Resource Domain Adaptation In zero-resource domain adaptation experiments, we do not use any data from TED or PatTR, neither as training nor development data. The models are trained on our multi-domain dataset consisting of five domains. The results are shown in Table 2. We compute statistical significance with paired bootstrap resampling (Koehn, 2004). SentBase achieves 16.7 and 32.9 BLEU on PatTR and TED respectively. The domains seen during training are more similar to TED in comparison to PatTR which is the reason for the large BLEU score differences. Our proposed models improve on PatTR by up to 0.4 BLEU and on TED by up to 1.0 BLEU. Improvements vary, but all models increase the BLEU score. The TagBase model does not improve significantly over SentBase. Table 1: Domain datasets sizes in sentences. from lack of document boundaries (M¨uller et al., 2018; Stojanovski and Fraser, 2019b) or random context (Voita et al., 2018). To a large e"
2021.adaptnlp-1.9,D19-1168,0,0.019387,"utputs share (L - 1) encoder encoder t1 t2 t3 t4 tN source c1 c2 c3 c4 c5 c6 cM context Figure 2: Context-aware Transformer with pooling. zero-resource experiments, we have no access to in-domain parallel data. 3 Context-aware NMT A separate field of inquiry is context-aware NMT which proposes integrating cross-sentence context (Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita et al., 2018; Zhang et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Tu et al., 2018; Maruf and Haffari, 2018; Voita et al., 2019b; Maruf et al., 2019; Yang et al., 2019; Voita et al., 2019a; Tan et al., 2019). These works show that context helps with discourse phenomena such as anaphoric pronouns, deixis and lexical cohesion. Kim et al. (2019) show that using context can improve topicaware lexical choice, but in a single-domain setup. Model The models we propose in this work are extensions of the Transformer (Vaswani et al., 2017). The first approach introduces separate domain embeddings applied to each token-level embedding. The second is conceptually based on previous context-aware models (Voita et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Zhang et al., 2018). Both models"
2021.adaptnlp-1.9,D18-1049,0,0.0375628,"Missing"
2021.adaptnlp-1.9,W17-4811,0,0.0801347,"t investigate it from a domain adaptation perspective. To our knowledge, our work is the first at the intersection of domain adaptation and context-aware NMT and shows that document-level context can be used to address zero-resource domains. multi-head attn self attn outputs share (L - 1) encoder encoder t1 t2 t3 t4 tN source c1 c2 c3 c4 c5 c6 cM context Figure 2: Context-aware Transformer with pooling. zero-resource experiments, we have no access to in-domain parallel data. 3 Context-aware NMT A separate field of inquiry is context-aware NMT which proposes integrating cross-sentence context (Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita et al., 2018; Zhang et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Tu et al., 2018; Maruf and Haffari, 2018; Voita et al., 2019b; Maruf et al., 2019; Yang et al., 2019; Voita et al., 2019a; Tan et al., 2019). These works show that context helps with discourse phenomena such as anaphoric pronouns, deixis and lexical cohesion. Kim et al. (2019) show that using context can improve topicaware lexical choice, but in a single-domain setup. Model The models we propose in this work are extensions of the Transformer (Vaswani et al., 2017). The first ap"
2021.adaptnlp-1.9,C18-1269,0,0.0178447,"dels to dynamically adapt to the target domain, Foster et al. (2010) who build on this work and include instance weighting, Zeng et al. (2018) where domain-specific and domain-shared annotations from adversarial domain classifiers are used and Britz et al. (2017) where a discriminator is used to backpropagate domain signals. Continued training is an established technique for domain adaptation if access to in-domain resources is possible. The method entails initially training on out-of-domain data, and then continuing training on in-domain data (Luong and Manning, 2015). Chen et al. (2017) and Zhang and Xiong (2018) improve upon this paradigm by integrating a domain classifier or a domain similarity metric into NMT and modifying the training cost based on weights indicating in-domain or out-ofdomain data. Sajjad et al. (2017) and Farajian et al. (2017) use continued training in a multi-domain setup and propose various ways of fine-tuning to in-domain data. Standard continued training (Luong and Manning, 2015) leads to catastrophic forgetting, evident by the degrading performance on the out-of-domain dataset. Freitag and Al-Onaizan (2016) address this issue by ensembling the original and the fine-tuned mo"
2021.adaptnlp-1.9,D19-1081,0,0.0285276,"Missing"
2021.adaptnlp-1.9,P19-1116,0,0.0382067,"Missing"
2021.adaptnlp-1.9,P18-1117,0,0.217342,"tched to similar domains in the training data. This is to some extent done implicitly by standard NMT. Alternatively, this matching can be facilitated by a 80 Proceedings of the Second Workshop on Domain Adaptation for NLP, pages 80–93 April 20, 2021. ©2021 Association for Computational Linguistics Our first proposed model, which we call the domain embedding model (DomEmb) applies average or max pooling over all context embeddings and adds this representation to each source tokenlevel embedding in the Transformer. The second model is conceptually similar to previous work on context-aware NMT (Voita et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Zhang et al., 2018) and introduces additional multi-head attention components in the encoder and decoder in order to handle the context. However, in order to facilitate larger context sizes, it creates a compressed context representation by applying average or max pooling with a fixed window and stride size. We compare our proposed models against previous context-aware NMT architectures and techniques for handling multi-domain setups, and show they improve upon strong baselines. The proposed models encode context in a coarse-grained way."
2021.adaptnlp-1.9,D19-1164,0,0.0158775,"rce domains. multi-head attn self attn outputs share (L - 1) encoder encoder t1 t2 t3 t4 tN source c1 c2 c3 c4 c5 c6 cM context Figure 2: Context-aware Transformer with pooling. zero-resource experiments, we have no access to in-domain parallel data. 3 Context-aware NMT A separate field of inquiry is context-aware NMT which proposes integrating cross-sentence context (Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita et al., 2018; Zhang et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Tu et al., 2018; Maruf and Haffari, 2018; Voita et al., 2019b; Maruf et al., 2019; Yang et al., 2019; Voita et al., 2019a; Tan et al., 2019). These works show that context helps with discourse phenomena such as anaphoric pronouns, deixis and lexical cohesion. Kim et al. (2019) show that using context can improve topicaware lexical choice, but in a single-domain setup. Model The models we propose in this work are extensions of the Transformer (Vaswani et al., 2017). The first approach introduces separate domain embeddings applied to each token-level embedding. The second is conceptually based on previous context-aware models (Voita et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al."
2021.findings-emnlp.315,P19-1120,0,0.0197317,"ture automatic methods. People need NLP systems that reflect their language and culture, but datasets are lacking: adaptation can help. There has been an explosion of English-language QA datasets, but other languages continue to lag behind. Several approaches try to transfer English’s bounty to other languages (Lewis et al., 2020; Artetxe et al., 2019), but most of the entities asked about in major QA datasets are American (Gor et al., 2021). Adapting entire questions will require not just adapting entities and non-entities in tandem but will also require integration with machine translation (Kim et al., 2019; Hangya and Fraser, 2019). Our automatic methods did not create precise adaptations, but the alternative “incorrect” adaptations may be useful for low-precision tasks, such as generating numerous simple open-ended questions or gauging the popularity of a entity. Given the existence of robust datasets in high resource languages can we adapt, rather than literally translate, them to other cultures and languages? 7 Acknowledgments Peskov was supported by a DAAD Research Fellowship and by the wonderful faculty and students of Ludwig Maximilians Universität München. Fraser is supported by the Euro"
2021.findings-emnlp.315,C08-1114,0,0.0227786,"plausible (Section 5.3). 2 Wer ist Bill Gates? We define cultural adaptation and motivate its application for tasks like creating culturally-centered training data for QA. Vinay and Darbelnet (1995) define adaptation as translation in which the relationship not the literal meaning between the receiver and the content needs to be recreated. You could formulate our task as a tradi3725 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3725–3750 November 7–11, 2021. ©2021 Association for Computational Linguistics tional analogy Drosten::Germany as Fauci::United States (Turney, 2008; Gladkova et al., 2016), but despite this superficial resemblance (explored in Section 4), traditional approaches to analogy ignore the influence of culture and are typically within a language. Hence, analogies are tightly bound with culture; humans struggle with analogies outside their culture (Freedle, 2003). We can use this task to identify named entities (Kasai et al., 2019; Arora et al., 2019; Jain et al., 2019) and for understanding other cultures (Katan and Taibi, 2004). 2.1 . . . and why Bill Gates? This task requires a list of named entities adaptable to other cultures. Our entities"
2021.findings-emnlp.315,P07-2045,0,0.00627561,"sfying as it was Barack Obama who sat across from Merkel for nearly a decade. To capture these more nuanced similarities, we turn to large text corpora in Section 4. 4 An Alternate Embedding Approach While the classic NLP vector example (Mikolov et al., 2013c) isn’t as magical as initially claimed (Rogers et al., 2017), it provides useful intuition. We can use the intuitions of the cliché: −−→ −−→ −−−−→ −−−→ King − Man + Woman = Queen (1) to adapt between languages. This, however, requires relevant embeddings. First, we use the entire Wikipedia in English and German, preprocessed using Moses (Koehn et al., 2007). We follow Mikolov et al. (2013b) and use named entity recognition (Honnibal et al., 2020) to tokenize entities such as Barack_Obama. We use word2vec (Mikolov et al., 2013b), rather than FastText (Bojanowski et al., 2017), as we do not want orthography to influence the similarity of entities. Angela Merkel in English and in German have quite different neighbors, and we intend to keep it that way by preserving the distinction between languages. However, the standard word2vec model assumes a single monolingual embedding space. We use unsupervised Vecmap (Artetxe et al., 2018), a leading tool fo"
2021.findings-emnlp.315,N13-1090,0,0.130532,"ate the similarity of the vectors with Faiss’s L2 distance (Johnson et al., 2021) and for each vector in A find the closest vector in D and vice versa. So who is the American Angela Merkel? One possible answer is Woodrow Wilson, a member of a “political party”, who had a “doctoral advisor” and a “religion”, and ended up with “awards”. This answer may be unsatisfying as it was Barack Obama who sat across from Merkel for nearly a decade. To capture these more nuanced similarities, we turn to large text corpora in Section 4. 4 An Alternate Embedding Approach While the classic NLP vector example (Mikolov et al., 2013c) isn’t as magical as initially claimed (Rogers et al., 2017), it provides useful intuition. We can use the intuitions of the cliché: −−→ −−→ −−−−→ −−−→ King − Man + Woman = Queen (1) to adapt between languages. This, however, requires relevant embeddings. First, we use the entire Wikipedia in English and German, preprocessed using Moses (Koehn et al., 2007). We follow Mikolov et al. (2013b) and use named entity recognition (Honnibal et al., 2020) to tokenize entities such as Barack_Obama. We use word2vec (Mikolov et al., 2013b), rather than FastText (Bojanowski et al., 2017), as we do not wa"
2021.ltedi-1.3,2020.semeval-1.274,0,0.0273794,"e given either of the binary labels. In contrast, the GermEval dataset features a two-tiered annotation schema: each tweet carries a coarsegrained label (‘Offense’ vs ‘Other’) as well as a Kozareva (2006) present a bootstrapping-based approach that annotates new data for named entity recognition to improve the performance in lowresource scenarios. First a set of classifiers are trained, which are then applied to a unlabeled set with majority voting. The extended corpus is used to improve the performance by retraining the models from scratch. Rather than bootstrapping new target language data, Ghadery and Moens (2020) finetune an mBERT model (Devlin et al., 2019) on an 17 Stormfront noHate 9,580 Hate 1,364 EN-OS DE-REL DE-DEV DE-TEST Table 2: Ratio of hate to non-hate labels in the English Stormfront dataset. Train Test Other 3,321 2,330 Abuse 1,022 773 Insult 595 381 Prof. 71 48 noHate 9,580 3,345 642 2,759 Hate 9,548 855 167 773 Table 4: Datasets used for our experiments. the Stormfront dataset with multiple copies of the ‘Hate’ examples, yielding a nearly-balanced distribution that resulted in optimal performance for our models. This oversampled version of the Stormfront dataset will be referred to as E"
2021.ltedi-1.3,W18-5102,0,0.312232,"Missing"
2021.ltedi-1.3,D14-1181,0,0.0178921,"erred to as the Stormfront dataset. Due to the broad nature of its hate speech definition and its decent size (ca. 10,000 examples), it was chosen as the training set for this paper. Table 1 illustrates some ‘Hate’ and ‘noHate’ sen2.2 Low-Resource Approaches SVMs, CNNs and RNNs are the most commonlyused models for hate speech detection and offensive language detection in general (Waseem et al., 2017; Fiˇser et al., 2018; Roberts et al., 2019; Ruppenhofer et al., 2018). Two architectures from the 2018 GermEval task are particularly relevant to this paper. Xi et al. (2018) used a CNN following (Kim, 2014) to address the coarse-grained task. Wiedemann 1 The data samples in this paper are shown for explanatory purposes and do not represent the views of the authors. 2 https://hatespeechdata.com 16 1. 2. 3. 4. 5. Sentence This film tells the story of a poor victimised African boy ( Joseph ) who was allowed into Ireland . Whites in all their glory against impossibly large hordes of non-whites . The video about the “Day of honour”, is really cool . But unfortunately , Maine ’s become the dumping ground for Somalis and other African trash . Most White Western Women have the racial sense of a cabbage"
2021.ltedi-1.3,P07-2045,0,0.00628363,"of resources, making BWEs more interesting in general for low-resource languages. BWEs ensure that source- and target language words are represented in a common vector space, enabling neural models based on BWEs to train on the source language and test on the target language without any intermediate steps. To produce our bilingual English-German embeddings, monolingual embeddings were first trained using FastText SkipGram (Bojanowski et al., 2017) over English and German NewsCrawl corpora (Bojar et al., 2015) which contain text dating from 2007 to 2013 and were preprocessed with Moses tools (Koehn et al., 2007). The resulting embeddings were mapped with MUSE (Conneau et al., 2018). We used the default parameters of the above mentioned tools. Our baseline classifier was a linear SVM over these BWEs. For each training example, we calculated the average of the vector representations of the words in the given text to obtain its global 18 Model SVM CNN1 CNN2 BiLSTM1 BiLSTM2 Accuracy 47.65 59.17 61.04 63.22 72.88 P 22.24 22.15 22.47 21.90 21.71 Hate R 55.76 34.41 31.82 26.52 9.18 F1 31.80 26.95 26.34 23.99 12.91 P 78.54 78.25 78.38 78.12 78.10 noHate R 45.38 66.11 69.23 73.50 90.72 F1 57.52 71.67 73.52 75"
2021.ltedi-1.3,D19-1520,0,0.0270744,"e two approaches. augmented multilingual dataset constructed automatically by translating the English source dataset. Our approach does not require the additional resources of automatic translation, however. We combine the bootstrapping procedure of Kozareva (2006) with the fine-tuning procedure of Mathur et al. (2018), first bootstrapping Germanlanguage data then using it to fine-tune our models. Variations of this bootstrapping procedure have been used for other tasks such as named entity recognition, using active learning instead of only source language trained models to annotate new data (Chaudhary et al., 2019). To our knowledge, we are the first to utilize such a procedure for detecting hate speech. Data scarcity remains a relevant problem for hate speech detection, and recent work still aims to utilize resources from English to improve in languages with less hate speech data. Ranasinghe and Zampieri (2020) train transformer-based architectures on English data and use the learned weights to initialize models which are trained on target language data. Stappen et al. (2020) also utilize transformer architectures, training them on the source language and evaluating on the target language. Alternativel"
2021.ltedi-1.3,E06-3004,0,0.541211,"the racial sense of a cabbage . Label noHate Hate noHate Hate Hate Table 1: Sample ‘Hate’ and ‘noHate’ comments according to de Gibert et al. (12). et al. (2018) used a model combining CNN and BiLSTMs to achieve second-best performance in the coarse-grained task and top performance in the fine-grained task. The classifiers we use are based on these two approaches. augmented multilingual dataset constructed automatically by translating the English source dataset. Our approach does not require the additional resources of automatic translation, however. We combine the bootstrapping procedure of Kozareva (2006) with the fine-tuning procedure of Mathur et al. (2018), first bootstrapping Germanlanguage data then using it to fine-tune our models. Variations of this bootstrapping procedure have been used for other tasks such as named entity recognition, using active learning instead of only source language trained models to annotate new data (Chaudhary et al., 2019). To our knowledge, we are the first to utilize such a procedure for detecting hate speech. Data scarcity remains a relevant problem for hate speech detection, and recent work still aims to utilize resources from English to improve in languag"
2021.ltedi-1.3,2020.alw-1.18,0,0.180559,"ate’. The 168 instances of the ‘Relation’ class were relabeled as ‘Hate’, since these sentences were always hateful when placed in context. After relabeling was completed, we addressed the imbalanced class distributions of the English and German datasets. Examining Table 2, it is clear that the majority of samples in the Stormfront dataset are ‘noHate’. This reflects the real-life observation that hate speech is less common than regular text. But this has been known to pose difficulties for machine learning models, which need plenty of data from both classes in order to be able to generalize (Madukwe et al., 2020; Vidgen and Derczynski, 2020). In our initial experiments, the ‘noHate’ class was so dominant over ‘Hate’ that the models were skewed towards assigning the ‘noHate’ label every time. Previous research suggests that oversampling the underrepresented class yields good model performance (De Smedt and Jaki, 2018). For this reason we oversampled 3.2 Model Architectures All our models described below are based on BWEs. BWEs are one of the most commonlyused tools for conducting cross-lingual transfer, the other being machine translation of source language data. However, ensuring accurate machine tra"
2021.ltedi-1.3,W18-5118,0,0.379222,"noHate Hate Hate Table 1: Sample ‘Hate’ and ‘noHate’ comments according to de Gibert et al. (12). et al. (2018) used a model combining CNN and BiLSTMs to achieve second-best performance in the coarse-grained task and top performance in the fine-grained task. The classifiers we use are based on these two approaches. augmented multilingual dataset constructed automatically by translating the English source dataset. Our approach does not require the additional resources of automatic translation, however. We combine the bootstrapping procedure of Kozareva (2006) with the fine-tuning procedure of Mathur et al. (2018), first bootstrapping Germanlanguage data then using it to fine-tune our models. Variations of this bootstrapping procedure have been used for other tasks such as named entity recognition, using active learning instead of only source language trained models to annotate new data (Chaudhary et al., 2019). To our knowledge, we are the first to utilize such a procedure for detecting hate speech. Data scarcity remains a relevant problem for hate speech detection, and recent work still aims to utilize resources from English to improve in languages with less hate speech data. Ranasinghe and Zampieri"
2021.ltedi-1.3,N19-1423,0,0.0263118,"the GermEval dataset features a two-tiered annotation schema: each tweet carries a coarsegrained label (‘Offense’ vs ‘Other’) as well as a Kozareva (2006) present a bootstrapping-based approach that annotates new data for named entity recognition to improve the performance in lowresource scenarios. First a set of classifiers are trained, which are then applied to a unlabeled set with majority voting. The extended corpus is used to improve the performance by retraining the models from scratch. Rather than bootstrapping new target language data, Ghadery and Moens (2020) finetune an mBERT model (Devlin et al., 2019) on an 17 Stormfront noHate 9,580 Hate 1,364 EN-OS DE-REL DE-DEV DE-TEST Table 2: Ratio of hate to non-hate labels in the English Stormfront dataset. Train Test Other 3,321 2,330 Abuse 1,022 773 Insult 595 381 Prof. 71 48 noHate 9,580 3,345 642 2,759 Hate 9,548 855 167 773 Table 4: Datasets used for our experiments. the Stormfront dataset with multiple copies of the ‘Hate’ examples, yielding a nearly-balanced distribution that resulted in optimal performance for our models. This oversampled version of the Stormfront dataset will be referred to as EN-OS, and is the English dataset used for trai"
2021.ltedi-1.3,2020.emnlp-main.470,0,0.0613401,"Missing"
2021.mrl-1.4,N19-1423,0,0.461308,"Kementchedjhieva et al., 2018; Vuli´c et al., 2019). However, a lack of parallel data impairs the performance of existing strongly supervised models, which is why a lot of recent research focuses on reducing the need for parallel data (Artetxe et al., 2017; Smith et al., 2017; Artetxe et al., 2018; Conneau et al., 2018). Mapping methods are sensitive to the approximate isomorphism of embedding spaces, which is not the case for many languages (Søgaard et al., 2018). The low isomorphism of distant language pairs was tackled by learning CLWEs jointly (Lample et al., 2018; Ormazabal et al., 2019; Devlin et al., 2019). However, they rely on large monolingual corpora which are not available for many languages. Furthermore, the lack of large data leads to low isomorphism as well, since it results in low-quality monolingual embedding spaces (Michel et al., 2020). Hence, mapping methods, which rely on the assumption of approximate isomorphism cannot be fruitfully applied in many cases. However, as there are still only poor CLWEs for many low-resource language pairs (Vuli´c et al., 2019), we argue that in addition to reducing requirements for training data, methods which offer opportunities precisely for low-re"
2021.mrl-1.4,2021.acl-short.30,1,0.77291,"oach (Artetxe et al., 2018) cannot deal properly with multiple distant and low-resource languages. Nevertheless, there are still a lot of languages for which even monolingual data is extremely scarce. For these languages, monolingual embeddings are usually of poor quality (Michel et al., 2020). Consequently, mapping methods are not fruitfully applicable, since they rely on high-quality monolingual embedding spaces. Adams et al. (2017) show that monolingual embedding quality of extremely lowresource languages can be improved if CLWEs for a low- and a high-resource language are trained jointly. Eder et al. (2021) propose a method for better CLWEs by using a small bilingual seed dictionary together with pre-trained monolingual embeddings of the higher-resource language for initialization. On the other hand, these approaches rely only on the source and target languages, while we Leveraging related languages Besides reducing data requirements, it is also helpful to explore information from linguistically related highresource languages in low-resource setups. This idea has, for example, been considered in Machine Translation (MT). Nakov and Ng (2012) propose a statistical MT model which requires only a sm"
2021.mrl-1.4,N18-1032,0,0.0171527,"y related highresource languages in low-resource setups. This idea has, for example, been considered in Machine Translation (MT). Nakov and Ng (2012) propose a statistical MT model which requires only a small parallel corpus of the low-resource source and the high-resource target languages, and additionally a larger parallel corpus of a related high-resource language and the target language. Nguyen and Chiang (2017) introduce a transfer learning model for neural MT (NMT) where embeddings of shared words are kept when transferring the model from the original to a related low-resource language. Gu et al. (2018) train a NMT model where embeddings learned during training are computed from a universal embedding space which embed multiple languages. Thus, high-resource languages can provide support for related low-resource languages. Leveraging information from related highresource languages to build CLWEs for lowresource setups has only been considered in a few works until now. Multiple approaches were proposed to build representations involving more than two languages, but they either rely on pretrained monolingual embeddings (Ammar et al., 2016; Heyman et al., 2019; Chen and Cardie, 2018; Alaux et al"
2021.mrl-1.4,N19-1188,0,0.0505679,"Missing"
2021.mrl-1.4,E17-1088,0,0.0198167,"ays a small amount of parallel data available if monolingual data is abundant (Artetxe et al., 2020). Secondly, Vuli´c et al. (2019) show that even the most robust unsupervised approach (Artetxe et al., 2018) cannot deal properly with multiple distant and low-resource languages. Nevertheless, there are still a lot of languages for which even monolingual data is extremely scarce. For these languages, monolingual embeddings are usually of poor quality (Michel et al., 2020). Consequently, mapping methods are not fruitfully applicable, since they rely on high-quality monolingual embedding spaces. Adams et al. (2017) show that monolingual embedding quality of extremely lowresource languages can be improved if CLWEs for a low- and a high-resource language are trained jointly. Eder et al. (2021) propose a method for better CLWEs by using a small bilingual seed dictionary together with pre-trained monolingual embeddings of the higher-resource language for initialization. On the other hand, these approaches rely only on the source and target languages, while we Leveraging related languages Besides reducing data requirements, it is also helpful to explore information from linguistically related highresource la"
2021.mrl-1.4,D18-1024,0,0.0770494,"al. (2018) train a NMT model where embeddings learned during training are computed from a universal embedding space which embed multiple languages. Thus, high-resource languages can provide support for related low-resource languages. Leveraging information from related highresource languages to build CLWEs for lowresource setups has only been considered in a few works until now. Multiple approaches were proposed to build representations involving more than two languages, but they either rely on pretrained monolingual embeddings (Ammar et al., 2016; Heyman et al., 2019; Chen and Cardie, 2018; Alaux et al., 2018) or large training corpora (Devlin et al., 2019), and are thus not well suited for low-resource setups. Kementchedjhieva et al. (2018) proposed Multi-support Generalized Procrustes Analysis (MGPA) to directly incorporate related languages into CLWEs by learning a threeway alignment among English, a low-resource language, and a supporting language. They improve CLWE quality for multiple low-resource language pairs, including Occitan-English. However, unlike our method, MGPA does not consider the internal structure of the monolingual low-resource language space (since it relies on pre-trained mo"
2021.mrl-1.4,D18-1330,0,0.0131177,"e. jhieva et al., 2018) where pre-trained monolingual embeddings from either French, Spanish or Catalan are incorporated. We use all baseline models with default parameters except the threshold for ranking candidate translation pairs, which we set to 15,000 instead of default 10,000 in all models, since it results in a better alignment. In the first step of our proposed model, we use the joint-align model (Wang et al., 2020) for Occitan and a related language with default parameters. The only exception is that we use supervised MUSE (Conneau et al., 2018) for mapping instead of default RCSLS (Joulin et al., 2018) in order to stay consistent with the second mapping step in our model. We tested using RCSLS in both steps instead, but it did not yield a good mapping for Occitan and English. We use supervised MUSE (Conneau et al., 2018) with the same parameters as in our baseline, both within joint-align training and in the second step of our proposed model. Embeddings In all our experiments, we used the pre-trained English fastText wiki word vectors released by Bojanowski et al. (2017).3 For Occitan, French, Spanish, and Catalan, we train our own monolingual embeddings using the Gensim version ˇ uˇrek and"
2021.mrl-1.4,K18-1021,0,0.325248,"nduction (BLI) (Vuli´c and Korhonen, 2016; Patra et al., 2019), Machine Translation (Lample et al., 2018), and cross-lingual transfer learning (Xiao and Guo, 2014; Schuster et al., 2019). Two main types of approaches to learn CLWEs are mapping methods, where a set of pretrained monolingual embeddings is projected into another monolingual space (Mikolov et al., 2013), and joint methods, where the monolingual and 41 Proceedings of the 1st Workshop on Multilingual Representation Learning, pages 41–50 November 11, 2021. ©2021 Association for Computational Linguistics Occitan, has been proposed by Kementchedjhieva et al. (2018). However, using pre-trained monolingual embedding spaces, they do not take into account that monolingual representations of lowresource languages might be of poor quality, which can impede mapping performance. In this paper, we propose a method where, in contrast to previous work, we consider both addressing the issue of monolingual embedding quality and leveraging information from a supporting language. To this end, we learn multilingual representations for a low-resource source language, a related language, and a target language in two steps: First, we train CLWEs for the low-resource langu"
2021.mrl-1.4,P17-1042,0,0.0211452,"Munich lisa_woller@web.de,{hangyav,fraser}@cis.lmu.de Abstract cross-lingual objectives are optimized jointly (e.g., Klementiev et al., 2012; Lample et al., 2018). Since recent research is more and more interested in dealing with low-resource languages, learning multilingual representations for low-resource languages is important as well (Conneau et al., 2018; Kementchedjhieva et al., 2018; Vuli´c et al., 2019). However, a lack of parallel data impairs the performance of existing strongly supervised models, which is why a lot of recent research focuses on reducing the need for parallel data (Artetxe et al., 2017; Smith et al., 2017; Artetxe et al., 2018; Conneau et al., 2018). Mapping methods are sensitive to the approximate isomorphism of embedding spaces, which is not the case for many languages (Søgaard et al., 2018). The low isomorphism of distant language pairs was tackled by learning CLWEs jointly (Lample et al., 2018; Ormazabal et al., 2019; Devlin et al., 2019). However, they rely on large monolingual corpora which are not available for many languages. Furthermore, the lack of large data leads to low isomorphism as well, since it results in low-quality monolingual embedding spaces (Michel et"
2021.mrl-1.4,C12-1089,0,0.0243763,"Missing"
2021.mrl-1.4,P18-1073,0,0.0887426,"}@cis.lmu.de Abstract cross-lingual objectives are optimized jointly (e.g., Klementiev et al., 2012; Lample et al., 2018). Since recent research is more and more interested in dealing with low-resource languages, learning multilingual representations for low-resource languages is important as well (Conneau et al., 2018; Kementchedjhieva et al., 2018; Vuli´c et al., 2019). However, a lack of parallel data impairs the performance of existing strongly supervised models, which is why a lot of recent research focuses on reducing the need for parallel data (Artetxe et al., 2017; Smith et al., 2017; Artetxe et al., 2018; Conneau et al., 2018). Mapping methods are sensitive to the approximate isomorphism of embedding spaces, which is not the case for many languages (Søgaard et al., 2018). The low isomorphism of distant language pairs was tackled by learning CLWEs jointly (Lample et al., 2018; Ormazabal et al., 2019; Devlin et al., 2019). However, they rely on large monolingual corpora which are not available for many languages. Furthermore, the lack of large data leads to low isomorphism as well, since it results in low-quality monolingual embedding spaces (Michel et al., 2020). Hence, mapping methods, which"
2021.mrl-1.4,D18-1549,0,0.347901,"is important as well (Conneau et al., 2018; Kementchedjhieva et al., 2018; Vuli´c et al., 2019). However, a lack of parallel data impairs the performance of existing strongly supervised models, which is why a lot of recent research focuses on reducing the need for parallel data (Artetxe et al., 2017; Smith et al., 2017; Artetxe et al., 2018; Conneau et al., 2018). Mapping methods are sensitive to the approximate isomorphism of embedding spaces, which is not the case for many languages (Søgaard et al., 2018). The low isomorphism of distant language pairs was tackled by learning CLWEs jointly (Lample et al., 2018; Ormazabal et al., 2019; Devlin et al., 2019). However, they rely on large monolingual corpora which are not available for many languages. Furthermore, the lack of large data leads to low isomorphism as well, since it results in low-quality monolingual embedding spaces (Michel et al., 2020). Hence, mapping methods, which rely on the assumption of approximate isomorphism cannot be fruitfully applied in many cases. However, as there are still only poor CLWEs for many low-resource language pairs (Vuli´c et al., 2019), we argue that in addition to reducing requirements for training data, methods"
2021.mrl-1.4,2020.acl-main.658,0,0.0110511,"both methods. First, CLWEs are trained jointly on a concatenated corpus containing monolingual source and target language data. Oversharing among source and target language vocabularies is then reduced by a vocabulary reallocation step, and finally, source embeddings are mapped to the target embeddings. However, despite the progress of unsupervised CLWE models, multiple surveys argue against focusing on fully unsupervised approaches. Firstly, giving up on every supervision signal is not necessary, since there is always a small amount of parallel data available if monolingual data is abundant (Artetxe et al., 2020). Secondly, Vuli´c et al. (2019) show that even the most robust unsupervised approach (Artetxe et al., 2018) cannot deal properly with multiple distant and low-resource languages. Nevertheless, there are still a lot of languages for which even monolingual data is extremely scarce. For these languages, monolingual embeddings are usually of poor quality (Michel et al., 2020). Consequently, mapping methods are not fruitfully applicable, since they rely on high-quality monolingual embedding spaces. Adams et al. (2017) show that monolingual embedding quality of extremely lowresource languages can b"
2021.mrl-1.4,2020.lrec-1.313,1,0.891599,"al., 2017; Smith et al., 2017; Artetxe et al., 2018; Conneau et al., 2018). Mapping methods are sensitive to the approximate isomorphism of embedding spaces, which is not the case for many languages (Søgaard et al., 2018). The low isomorphism of distant language pairs was tackled by learning CLWEs jointly (Lample et al., 2018; Ormazabal et al., 2019; Devlin et al., 2019). However, they rely on large monolingual corpora which are not available for many languages. Furthermore, the lack of large data leads to low isomorphism as well, since it results in low-quality monolingual embedding spaces (Michel et al., 2020). Hence, mapping methods, which rely on the assumption of approximate isomorphism cannot be fruitfully applied in many cases. However, as there are still only poor CLWEs for many low-resource language pairs (Vuli´c et al., 2019), we argue that in addition to reducing requirements for training data, methods which offer opportunities precisely for low-resource setups, like leveraging data from linguistically related high-resource languages, should be considered as well. While there exist NLP systems that make use of related languages, e.g., in Machine Translation (Nakov and Ng, 2012; Nguyen and"
2021.mrl-1.4,Q17-1010,0,0.668167,"ow-resource setups A lot of research on CLWEs for low-resource languages focuses on reducing the need for cross-lingual data. Zhang et al. (2017) use adversarial training for aligning monolingual vector spaces without any bilingual signal. Conneau et al. (2018) propose an unsupervised mapping method where they combine adversarial training with a Procrustes Analysis refinement step in every iteration. Lample et al. (2018) learn CLWEs jointly for their unsupervised neural machine translation model by concatenating corpora of source and target languages and training fastText skipgram embeddings (Bojanowski et al., 2017) on this corpus. In order to combine the benefits of joint and mapping methods, Wang et al. (2020) propose an approach where they combine both methods. First, CLWEs are trained jointly on a concatenated corpus containing monolingual source and target language data. Oversharing among source and target language vocabularies is then reduced by a vocabulary reallocation step, and finally, source embeddings are mapped to the target embeddings. However, despite the progress of unsupervised CLWE models, multiple surveys argue against focusing on fully unsupervised approaches. Firstly, giving up on ev"
2021.mrl-1.4,I17-2050,0,0.162962,"al., 2020). Hence, mapping methods, which rely on the assumption of approximate isomorphism cannot be fruitfully applied in many cases. However, as there are still only poor CLWEs for many low-resource language pairs (Vuli´c et al., 2019), we argue that in addition to reducing requirements for training data, methods which offer opportunities precisely for low-resource setups, like leveraging data from linguistically related high-resource languages, should be considered as well. While there exist NLP systems that make use of related languages, e.g., in Machine Translation (Nakov and Ng, 2012; Nguyen and Chiang, 2017), only few work focuses on including them directly into CLWEs. An approach considering a related language in order to improve CLWEs for low-resource language pairs, including EnglishCross-lingual word embeddings (CLWEs) have proven indispensable for various natural language processing tasks, e.g., bilingual lexicon induction (BLI). However, the lack of data often impairs the quality of representations. Various approaches requiring only weak crosslingual supervision were proposed, but current methods still fail to learn good CLWEs for languages with only a small monolingual corpus. We therefore"
2021.mrl-1.4,P19-1492,0,0.0172665,"(Conneau et al., 2018; Kementchedjhieva et al., 2018; Vuli´c et al., 2019). However, a lack of parallel data impairs the performance of existing strongly supervised models, which is why a lot of recent research focuses on reducing the need for parallel data (Artetxe et al., 2017; Smith et al., 2017; Artetxe et al., 2018; Conneau et al., 2018). Mapping methods are sensitive to the approximate isomorphism of embedding spaces, which is not the case for many languages (Søgaard et al., 2018). The low isomorphism of distant language pairs was tackled by learning CLWEs jointly (Lample et al., 2018; Ormazabal et al., 2019; Devlin et al., 2019). However, they rely on large monolingual corpora which are not available for many languages. Furthermore, the lack of large data leads to low isomorphism as well, since it results in low-quality monolingual embedding spaces (Michel et al., 2020). Hence, mapping methods, which rely on the assumption of approximate isomorphism cannot be fruitfully applied in many cases. However, as there are still only poor CLWEs for many low-resource language pairs (Vuli´c et al., 2019), we argue that in addition to reducing requirements for training data, methods which offer opportunitie"
2021.mrl-1.4,P19-1018,0,0.0156153,"ce Romance language which is often neglected due to lack of resources. We leverage data from French, Spanish and Catalan for training and evaluate on the Occitan-English BLI task. By incorporating supporting languages our method outperforms previous approaches by a large margin. Furthermore, our analysis shows that the degree of relatedness between an incorporated language and the low-resource language is critically important. 1 Introduction Cross-lingual word embeddings (CLWEs) are important for a wide range of NLP tasks including bilingual lexicon induction (BLI) (Vuli´c and Korhonen, 2016; Patra et al., 2019), Machine Translation (Lample et al., 2018), and cross-lingual transfer learning (Xiao and Guo, 2014; Schuster et al., 2019). Two main types of approaches to learn CLWEs are mapping methods, where a set of pretrained monolingual embeddings is projected into another monolingual space (Mikolov et al., 2013), and joint methods, where the monolingual and 41 Proceedings of the 1st Workshop on Multilingual Representation Learning, pages 41–50 November 11, 2021. ©2021 Association for Computational Linguistics Occitan, has been proposed by Kementchedjhieva et al. (2018). However, using pre-trained mon"
2021.mrl-1.4,N19-1162,0,0.0202397,"for training and evaluate on the Occitan-English BLI task. By incorporating supporting languages our method outperforms previous approaches by a large margin. Furthermore, our analysis shows that the degree of relatedness between an incorporated language and the low-resource language is critically important. 1 Introduction Cross-lingual word embeddings (CLWEs) are important for a wide range of NLP tasks including bilingual lexicon induction (BLI) (Vuli´c and Korhonen, 2016; Patra et al., 2019), Machine Translation (Lample et al., 2018), and cross-lingual transfer learning (Xiao and Guo, 2014; Schuster et al., 2019). Two main types of approaches to learn CLWEs are mapping methods, where a set of pretrained monolingual embeddings is projected into another monolingual space (Mikolov et al., 2013), and joint methods, where the monolingual and 41 Proceedings of the 1st Workshop on Multilingual Representation Learning, pages 41–50 November 11, 2021. ©2021 Association for Computational Linguistics Occitan, has been proposed by Kementchedjhieva et al. (2018). However, using pre-trained monolingual embedding spaces, they do not take into account that monolingual representations of lowresource languages might be"
2021.mrl-1.4,P18-1072,0,0.0264204,"Missing"
2021.mrl-1.4,D19-1449,0,0.0335657,"Missing"
2021.mrl-1.4,P16-1024,0,0.0661944,"Missing"
2021.mrl-1.4,W14-1613,0,0.0213169,"Spanish and Catalan for training and evaluate on the Occitan-English BLI task. By incorporating supporting languages our method outperforms previous approaches by a large margin. Furthermore, our analysis shows that the degree of relatedness between an incorporated language and the low-resource language is critically important. 1 Introduction Cross-lingual word embeddings (CLWEs) are important for a wide range of NLP tasks including bilingual lexicon induction (BLI) (Vuli´c and Korhonen, 2016; Patra et al., 2019), Machine Translation (Lample et al., 2018), and cross-lingual transfer learning (Xiao and Guo, 2014; Schuster et al., 2019). Two main types of approaches to learn CLWEs are mapping methods, where a set of pretrained monolingual embeddings is projected into another monolingual space (Mikolov et al., 2013), and joint methods, where the monolingual and 41 Proceedings of the 1st Workshop on Multilingual Representation Learning, pages 41–50 November 11, 2021. ©2021 Association for Computational Linguistics Occitan, has been proposed by Kementchedjhieva et al. (2018). However, using pre-trained monolingual embedding spaces, they do not take into account that monolingual representations of lowreso"
2021.mrl-1.4,P17-1179,0,0.0278285,"dness of the source, target and the related languages, their BLI performance and the dataset sizes of the individual languages, we found the relatedness of the low-resource and the related language to be most influential. 1 The illustration is available at http://lowlands-l. net/anniversary/images/occitania.jpg. 42 the amount of available written digital resources is low. show the benefits of incorporating further related languages into a multilingual space. CLWEs for low-resource setups A lot of research on CLWEs for low-resource languages focuses on reducing the need for cross-lingual data. Zhang et al. (2017) use adversarial training for aligning monolingual vector spaces without any bilingual signal. Conneau et al. (2018) propose an unsupervised mapping method where they combine adversarial training with a Procrustes Analysis refinement step in every iteration. Lample et al. (2018) learn CLWEs jointly for their unsupervised neural machine translation model by concatenating corpora of source and target languages and training fastText skipgram embeddings (Bojanowski et al., 2017) on this corpus. In order to combine the benefits of joint and mapping methods, Wang et al. (2020) propose an approach wh"
2021.naacl-main.16,2020.emnlp-main.617,0,0.0442538,"Missing"
2021.naacl-main.16,D19-1632,0,0.0926039,"mplicit bilingual signal (Lample et al., 2018a; Artetxe et al., 2018c). Lample and Conneau (2019) suggest to instead pretrain a bilingual language model (XLM) and use it to initialize UNMT, as it can successfully encode higher-level text representations. This approach largely improves translation scores for language pairs with plentiful mono- 2 Proposed Approach lingual data. However, while UNMT is effective Our approach has three distinct steps, which are for high-resource languages, it yields poor results described in the following subsections. when one of the two languages is low-resource (Guzmán et al., 2019). Marchisio et al. (2020) 2.1 VecMap Embeddings show that there is a strong correlation between bilinInitially, we split the monolingual data from both gual lexicon induction (BLI) and final translation languages using BPE tokenization (Sennrich et al., performance when using pretrained cross-lingual 1 embeddings, converted to phrase-tables, as initialhttps://github.com/alexandra-chron/ ization of a UNMT model (Artetxe et al., 2019). lexical_xlm_relm 173 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologie"
2021.naacl-main.16,W15-3049,0,0.0384829,"Missing"
2021.naacl-main.16,W18-6319,0,0.0245581,"Missing"
2021.naacl-main.16,E17-2025,0,0.0658494,"Missing"
2021.naacl-main.16,D19-1071,0,0.017674,"inducted in an unsupervised way by the same monolingual data, or simply with cross-lingual embeddings. Lample et al. (2018c) also use pretrained embeddings, learned on joint monolingual corpora of the two languages of interest, to initialize the embedding layer of the encoder-decoder. Lample and Conneau (2019) remove pretrained embeddings from the UNMT pipeline and align language distributions by simply pretraining a MLM on both languages, in order to learn a cross-lingual mapping. However, it has been shown that this pretraining method provides a weak alignment of the language distributions (Ren et al., 2019). While that work identified as a cause the lack of sharing n-gram level cross-lingual information, we address the lack of cross-lingual information at the lexical level. Moreover, most prior work on UNMT focuses on languages with abundant, high-quality monolingual corpora. In low-resource scenarios though, especially when the languages are not related, pretraining a cross-lingual MLM for unsupervised NMT does not yield good results (Guzmán et al., 2019; Chronopoulou et al., 2020). We propose a method that overcomes this issue by enhancing the MLM with cross-lingual lexical-level representatio"
2021.naacl-main.16,P16-1009,0,0.114803,"he Finally, we transfer the MLM-trained encoder Trans- embedding layer of XLM with unsupervised crossformer to an encoder-decoder translation model. lingual embeddings. Then, we train XLM on the We note that the encoder-decoder attention of the two languages of interest with a masked language Transformer is randomly initialized. We then train modeling objective. Upon convergence, we transthe model for NMT in an unsupervised way, using fer it to the encoder and decoder of an NMT model, denoising auto-encoding (Vincent et al., 2008) and which is trained in an unsupervised way. back-translation (Sennrich et al., 2016a), which is In the case of RE - LM, our method is applied to performed in an online manner. This follows work the MLM fine-tuning step. Instead of randomly iniby Artetxe et al. (2018b); Lample et al. (2018a,c). tializing the new embedding vectors added in this step, we use pretrained unsupervised cross-lingual 3 Experiments embeddings. We obtain them by applying VecMap Datasets. We conduct experiments on English- to fastText pretrained Albanian/Macedonian emMacedonian (En-Mk) and English-Albanian (En- beddings and the English MLM token-level embedSq), as Mk, Sq are low-resource languages, whe"
2021.naacl-main.16,P16-1162,0,0.335903,"he Finally, we transfer the MLM-trained encoder Trans- embedding layer of XLM with unsupervised crossformer to an encoder-decoder translation model. lingual embeddings. Then, we train XLM on the We note that the encoder-decoder attention of the two languages of interest with a masked language Transformer is randomly initialized. We then train modeling objective. Upon convergence, we transthe model for NMT in an unsupervised way, using fer it to the encoder and decoder of an NMT model, denoising auto-encoding (Vincent et al., 2008) and which is trained in an unsupervised way. back-translation (Sennrich et al., 2016a), which is In the case of RE - LM, our method is applied to performed in an online manner. This follows work the MLM fine-tuning step. Instead of randomly iniby Artetxe et al. (2018b); Lample et al. (2018a,c). tializing the new embedding vectors added in this step, we use pretrained unsupervised cross-lingual 3 Experiments embeddings. We obtain them by applying VecMap Datasets. We conduct experiments on English- to fastText pretrained Albanian/Macedonian emMacedonian (En-Mk) and English-Albanian (En- beddings and the English MLM token-level embedSq), as Mk, Sq are low-resource languages, whe"
2021.naacl-main.16,tiedemann-2012-parallel,0,0.0491011,"ross-lingual masked language model. 2016b). We build subword monolingual embeddings with fastText (Bojanowski et al., 2017). Then, we map the monolingual embeddings of the two languages to a shared space, using VecMap (Artetxe et al., 2018a), with identical tokens occurring in both languages serving as the initial seed dictionary, as we do not have any bilingual signal. This is different from the original VecMap approach, which operates at the word level. We use the mapped embeddings of the two languages to initialize the embedding layer of a Transformer-based encoder (Vaswani et al., 2017). (Tiedemann, 2012) as validation/test sets. We also use 68M En sentences from NewsCrawl. For Sq and Mk we use all the CommonCrawl corpora from Ortiz Suárez et al. (2019), which are 4M Sq and 2.4M Mk sentences. Baseline. We use a method that relies on crosslingual language model pretraining, namely XLM (Lample and Conneau, 2019). This approach trains a bilingual MLM separately for En-Mk and En-Sq, which is used to initialize the encoder-decoder of the corresponding NMT system. Each system is then trained in an unsupervised way. Comparison to state-of-the-art. We apply our 2.2 Masked Language Model Training propo"
2021.naacl-main.16,2020.emnlp-main.586,0,0.0583622,"Missing"
C10-2010,P91-1022,0,0.83247,"mon requirement for sentence alignment approaches. However, in order to be applicable to parallel corpora in any language without requiring a separate training set, a method for sentencealignment should also work in an unsupervised fashion and be language pair independent. By “unsupervised”, we denote methods that infer the alignment model directly from the data set to be aligned. Language pair independence refers to approaches that require no specific knowledge about the languages of the parallel texts to align. 2 Related Work Among approaches that are unsupervised and language independent, (Brown et al., 1991) and (Gale and Church, 1993) use sentence-length statistics in order to model the relationship between groups of sentences that are translations of each other. As shown in (Chen, 1993) the accuracy of sentencelength based methods decreases drastically when aligning texts containing small deletions or free translations. In contrast, our approach augments a sentence-length based model with lexical statistics and hence constantly provides high quality alignments. (Moore, 2002) proposes a multi-pass search 81 Coling 2010: Poster Volume, pages 81–89, Beijing, August 2010 procedure where sentence-le"
C10-2010,ceausu-etal-2006-acquis,0,0.0148082,"o-1, and then merges those correspondences into larger alignments. This allows the finding of 1-to-0/0-to-1 alignments as well as high quality 1-to-many/many-to-1 alignments, leading to high accuracy on parallel texts but also on corpora containing large blocs of inserted or deleted text. Furthermore, our approach keeps the computational costs of the alignment procedure low: our aligner is, on average, about 550 times faster than our implementation3 of (Deng et al., 2006). Many other approaches to sentence-alignment are either supervised or language dependent. The approaches by (Chen, 1993), (Ceausu et al., 2006) or (Fattah et al., 2007) need manually aligned pairs of sentences in order to train the used alignment models. The approaches by (Wu, 1994), (Haruno and Yamazaki, 1996), (Ma, 2006) and (Gautam and Sinha, 2007) require an externally supplied bilingual lexicon. Similarly, the approaches by (Simard and Plamondon, 1998) or (Melamed, 2000) are language pair dependent insofar as they are based on cognates. 3 Two-Step Clustering Approach We present here our two-step clustering approach to sentence alignment4 which is the main contribution of this paper. We begin by giving the main ideas of our appro"
C10-2010,J93-1004,0,0.941408,"nce alignment approaches. However, in order to be applicable to parallel corpora in any language without requiring a separate training set, a method for sentencealignment should also work in an unsupervised fashion and be language pair independent. By “unsupervised”, we denote methods that infer the alignment model directly from the data set to be aligned. Language pair independence refers to approaches that require no specific knowledge about the languages of the parallel texts to align. 2 Related Work Among approaches that are unsupervised and language independent, (Brown et al., 1991) and (Gale and Church, 1993) use sentence-length statistics in order to model the relationship between groups of sentences that are translations of each other. As shown in (Chen, 1993) the accuracy of sentencelength based methods decreases drastically when aligning texts containing small deletions or free translations. In contrast, our approach augments a sentence-length based model with lexical statistics and hence constantly provides high quality alignments. (Moore, 2002) proposes a multi-pass search 81 Coling 2010: Poster Volume, pages 81–89, Beijing, August 2010 procedure where sentence-length based statistics are us"
C10-2010,P96-1018,0,0.0764464,"alignments, leading to high accuracy on parallel texts but also on corpora containing large blocs of inserted or deleted text. Furthermore, our approach keeps the computational costs of the alignment procedure low: our aligner is, on average, about 550 times faster than our implementation3 of (Deng et al., 2006). Many other approaches to sentence-alignment are either supervised or language dependent. The approaches by (Chen, 1993), (Ceausu et al., 2006) or (Fattah et al., 2007) need manually aligned pairs of sentences in order to train the used alignment models. The approaches by (Wu, 1994), (Haruno and Yamazaki, 1996), (Ma, 2006) and (Gautam and Sinha, 2007) require an externally supplied bilingual lexicon. Similarly, the approaches by (Simard and Plamondon, 1998) or (Melamed, 2000) are language pair dependent insofar as they are based on cognates. 3 Two-Step Clustering Approach We present here our two-step clustering approach to sentence alignment4 which is the main contribution of this paper. We begin by giving the main ideas of our approach using an introductory example (section 3.1). Then we show to which extent computational costs are reduced in comparison to a standard DP search (section 3.2) before"
C10-2010,W04-3250,0,0.0375857,"Missing"
C10-2010,ma-2006-champollion,0,0.0626307,"ccuracy on parallel texts but also on corpora containing large blocs of inserted or deleted text. Furthermore, our approach keeps the computational costs of the alignment procedure low: our aligner is, on average, about 550 times faster than our implementation3 of (Deng et al., 2006). Many other approaches to sentence-alignment are either supervised or language dependent. The approaches by (Chen, 1993), (Ceausu et al., 2006) or (Fattah et al., 2007) need manually aligned pairs of sentences in order to train the used alignment models. The approaches by (Wu, 1994), (Haruno and Yamazaki, 1996), (Ma, 2006) and (Gautam and Sinha, 2007) require an externally supplied bilingual lexicon. Similarly, the approaches by (Simard and Plamondon, 1998) or (Melamed, 2000) are language pair dependent insofar as they are based on cognates. 3 Two-Step Clustering Approach We present here our two-step clustering approach to sentence alignment4 which is the main contribution of this paper. We begin by giving the main ideas of our approach using an introductory example (section 3.1). Then we show to which extent computational costs are reduced in comparison to a standard DP search (section 3.2) before presenting t"
C10-2010,J00-2004,0,0.0454446,"ts of the alignment procedure low: our aligner is, on average, about 550 times faster than our implementation3 of (Deng et al., 2006). Many other approaches to sentence-alignment are either supervised or language dependent. The approaches by (Chen, 1993), (Ceausu et al., 2006) or (Fattah et al., 2007) need manually aligned pairs of sentences in order to train the used alignment models. The approaches by (Wu, 1994), (Haruno and Yamazaki, 1996), (Ma, 2006) and (Gautam and Sinha, 2007) require an externally supplied bilingual lexicon. Similarly, the approaches by (Simard and Plamondon, 1998) or (Melamed, 2000) are language pair dependent insofar as they are based on cognates. 3 Two-Step Clustering Approach We present here our two-step clustering approach to sentence alignment4 which is the main contribution of this paper. We begin by giving the main ideas of our approach using an introductory example (section 3.1). Then we show to which extent computational costs are reduced in comparison to a standard DP search (section 3.2) before presenting the theoretical background of our approach (section 3.3). We further discuss a novel pruning strategy used within our approach (section 3.4). This pruning te"
C10-2010,moore-2002-fast,0,0.186026,"d Sentence Alignment for Symmetrical and Asymmetrical Parallel Corpora Fabienne Braune Alexander Fraser Institute for Natural Language Processing Universit¨at Stuttgart {braunefe,fraser}@ims.uni-stuttgart.de Abstract We have developed an approach to unsupervised and language-pair independent sentence alignment which allows us to achieve high accuracy in terms of F1 for the alignment of both symmetrical and asymmetrical parallel corpora. Due to the incorporation of a novel two-pass search procedure with pruning, our approach is acceptably fast. Compared with Moore’s bilingual sentence aligner (Moore, 2002), we obtain an average F1 of 98.38 on symmetrical parallel documents, while Moore’s aligner achieves 94.06. On asymmetrical documents, our approach achieves 97.67 F1 while Moore’s aligner obtains 88.70. On average, our sentence aligner is only about 4 times slower than Moore’s aligner. This paper is organized as follows: previous work is described in section 2. In section 3, we present our approach. Finally, in section 4, we conduct an extensive evaluation, including a brief insight into the impact of our aligner on the overall performance of an MT system. We address the problem of unsupervise"
C10-2010,P94-1012,0,0.369567,"y/many-to-1 alignments, leading to high accuracy on parallel texts but also on corpora containing large blocs of inserted or deleted text. Furthermore, our approach keeps the computational costs of the alignment procedure low: our aligner is, on average, about 550 times faster than our implementation3 of (Deng et al., 2006). Many other approaches to sentence-alignment are either supervised or language dependent. The approaches by (Chen, 1993), (Ceausu et al., 2006) or (Fattah et al., 2007) need manually aligned pairs of sentences in order to train the used alignment models. The approaches by (Wu, 1994), (Haruno and Yamazaki, 1996), (Ma, 2006) and (Gautam and Sinha, 2007) require an externally supplied bilingual lexicon. Similarly, the approaches by (Simard and Plamondon, 1998) or (Melamed, 2000) are language pair dependent insofar as they are based on cognates. 3 Two-Step Clustering Approach We present here our two-step clustering approach to sentence alignment4 which is the main contribution of this paper. We begin by giving the main ideas of our approach using an introductory example (section 3.1). Then we show to which extent computational costs are reduced in comparison to a standard DP"
C10-2010,P93-1002,0,\N,Missing
C14-1041,C14-1181,0,0.0290178,"tion over all possible classes when calculating the n-gram probabilities. 422 Figure 1: Operation Sequence Model – Training Sentence with Generation and Test Sentences distributions and better generalizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be interesting. 3 Operation Sequence Model The Operation Seq"
C14-1041,D13-1174,0,0.344604,"o improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate step has been studied by Toutanova et al. (2008), de Gispert and Mariˆno (2008), Fraser et al. (2012), Chahuneau et al. (2013) and others. Koehn and Hoang (2007) proposed to integrate different levels of linguistic information as factors into the phrase-based translation model. Yeniterzi and Oflazer (2010) used source syntactic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them as a part of translation,"
C14-1041,N12-1047,0,0.00920044,"urrani et al., 2014) to transliterate OOV words when translating into Russian. Tuning and Test: The systems were tuned on the dev2010 dataset and evaluated on the test2010-2013 datasets made available for the IWSLT-13 workshop. We performed a secondary set of experiments for German-English pairs using tuning and test sets made available for the WMT-13 workshop. We concatenated the news-test sets 2008 and 2009 to obtain a large dev-set of 4576 sentences. Evaluation was performed on the news-test set 2013 which contains 3000 sentences. Tuning was performed using the k-best batch MIRA algorithm (Cherry and Foster, 2012) with at most 25 iterations. We use BLEU (Papineni et al., 2002) as a metric to evaluate our results. Results I – Using Linguistic Annotation: We trained 5-gram OSM models over different representations and added these to the baseline system. First we evaluated Modeland (Mand ) which uses a MIRA tuned linear combination of different OSM models versus Modelor (Mor ) which computes only one OSM model but allows the generator to switch between different OSM models built on various generalized forms. Table 2 shows results from running experiments on German-English pairs. We found that the simpler"
C14-1041,N13-1003,0,0.251845,"t al., 2010; Wuebker and Ney, 2012). Automatically clustering the training data into word classes in order to obtain smoother 1 We are referring to hard clustering here. Soft clustering is intractable as it requires a marginalization over all possible classes when calculating the n-gram probabilities. 422 Figure 1: Operation Sequence Model – Training Sentence with Generation and Test Sentences distributions and better generalizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due t"
C14-1041,J07-2003,0,0.0625223,"order. Xia and McCord (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflectin"
C14-1041,P05-1066,1,0.078446,"nts the experimental setup and the results. Section 5 concludes the paper. 2 Related Work Previous work on integrating linguistic knowledge into SMT models can be broken into two groups. The first group focuses on using linguistic knowledge to improve reordering between syntactically different languages. A second group focuses on translating into morphologically rich languages. Initial efforts to use linguistic annotation focused on rearranging source sentences to be in the target order. Xia and McCord (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based s"
C14-1041,2007.mtsummit-papers.16,0,0.201558,"Missing"
C14-1041,C10-2023,0,0.179282,"rd (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate s"
C14-1041,P11-1105,1,0.479753,"research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be interesting. 3 Operation Sequence Model The Operation Sequence Model (Durrani et al., 2011) is an instance of the N-gram based SMT framework (Casacuberta and Vidal, 2004; Mari˜no et al., 2006). It represents the translation process through a sequence of operations. An operation can be to simultaneously generate source or target words or to perform reordering. Reordering is carried out through jump and gap operations. The model is different from its ancestors in that it strongly integrates translation and reordering into a single generative story in which translation decisions can influence and get impacted by the reordering decisions and vice versa. Given a bilingual sentence pair &lt;"
C14-1041,N13-1001,1,0.226932,"gically rich or syntactically divergent languages. The former becomes challenging due to lexical sparsity and the latter suffers from sparsity in learning underlying reordering patterns. The last decade of research in Statistical Machine Translation has witnessed many attempts to integrate linguistic analysis into SMT models, to address the challenges of (i) translating into morphologically rich language languages, (ii) modeling syntactic divergence across languages for better generalization in sparse data conditions. The integration of the Operation Sequence Model into phrase-based paradigm (Durrani et al., 2013a; Durrani et al., 2013b) improved the reordering capability and addressed the problem of the phrasal independence assumption in the phrase-based models. The OSM model integrates translation and reordering into a single generative story. By jointly considering translation and reordering context across phrasal boundaries, the OSM model considers much richer conditioning than phrasal translation and lexicalized reordering models. However, due to data sparsity the model often falls back to very small context sizes. We address this problem by learning operation sequences over generalized represent"
C14-1041,P13-2071,1,0.567963,"gically rich or syntactically divergent languages. The former becomes challenging due to lexical sparsity and the latter suffers from sparsity in learning underlying reordering patterns. The last decade of research in Statistical Machine Translation has witnessed many attempts to integrate linguistic analysis into SMT models, to address the challenges of (i) translating into morphologically rich language languages, (ii) modeling syntactic divergence across languages for better generalization in sparse data conditions. The integration of the Operation Sequence Model into phrase-based paradigm (Durrani et al., 2013a; Durrani et al., 2013b) improved the reordering capability and addressed the problem of the phrasal independence assumption in the phrase-based models. The OSM model integrates translation and reordering into a single generative story. By jointly considering translation and reordering context across phrasal boundaries, the OSM model considers much richer conditioning than phrasal translation and lexicalized reordering models. However, due to data sparsity the model often falls back to very small context sizes. We address this problem by learning operation sequences over generalized represent"
C14-1041,E14-4029,1,0.417624,"ack-size of 1000 during tuning and 5000 during test and the no-reordering-over-punctuation heuristic. We used the compact phrase table representation by JunczysDowmunt (2012). For our German-to-English experiments, we used compound splitting (Koehn and Knight, 2003). German-to-English and English-to-German baseline systems also used POS and morphological target sequence models built on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models and as additional factors in phrase translation models (Koehn and Hoang, 2007). We used an unsupervised transliteration model (Durrani et al., 2014) to transliterate OOV words when translating into Russian. Tuning and Test: The systems were tuned on the dev2010 dataset and evaluated on the test2010-2013 datasets made available for the IWSLT-13 workshop. We performed a secondary set of experiments for German-English pairs using tuning and test sets made available for the WMT-13 workshop. We concatenated the news-test sets 2008 and 2009 to obtain a large dev-set of 4576 sentences. Evaluation was performed on the news-test set 2013 which contains 3000 sentences. Tuning was performed using the k-best batch MIRA algorithm (Cherry and Foster, 2"
C14-1041,P08-1115,0,0.0148386,"used source syntactic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them as a part of translation, and which ones are better predicted through generation, also in the English-to-Arabic task. Several researchers attempted to use word lattices to handle generalized representation (Dyer et al., 2008; Hardmeier et al., 2010; Wuebker and Ney, 2012). Automatically clustering the training data into word classes in order to obtain smoother 1 We are referring to hard clustering here. Soft clustering is intractable as it requires a marginalization over all possible classes when calculating the n-gram probabilities. 422 Figure 1: Operation Sequence Model – Training Sentence with Generation and Test Sentences distributions and better generalizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various"
C14-1041,2012.eamt-1.6,0,0.0235645,"Missing"
C14-1041,E12-1068,1,0.40458,"N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate step has been studied by Toutanova et al. (2008), de Gispert and Mariˆno (2008), Fraser et al. (2012), Chahuneau et al. (2013) and others. Koehn and Hoang (2007) proposed to integrate different levels of linguistic information as factors into the phrase-based translation model. Yeniterzi and Oflazer (2010) used source syntactic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them"
C14-1041,P06-1121,0,0.00965802,"on rearranging source sentences to be in the target order. Xia and McCord (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The i"
C14-1041,P14-1066,0,0.0440211,"hnique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be interesting. 3 Operation Sequence Model The Operation Sequence Model (Durrani et al., 2011) is an instance of the N-gram based SMT framework (Casacuberta and Vidal, 2004; Mari˜no et al., 2006). It represents the translation process through a sequence of operations. An operation can be to simultaneo"
C14-1041,P12-1016,0,0.00479192,"group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate step has been studied by Toutanova et al. (2008), de Gispert and Mariˆno (2008), Fraser et al. (2012), Chahuneau et al. (2013) and others. Koehn and Hoang (2007) proposed to integrate different levels of linguistic information as factors into the phrase-based translation model. Yeniterzi and Oflazer (2010) used source syntactic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them as a part of translation, and which ones are better predicted through generation, also in the English-to-Arabic task. Several researchers attempted to use word lattices to handle generalized representation (Dyer et al., 2008; Hardmeier et al., 2010; Wuebker and Ney, 2012). Automatically clustering the training data into word classes in order to obtain"
C14-1041,W10-1710,0,0.04755,"ic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them as a part of translation, and which ones are better predicted through generation, also in the English-to-Arabic task. Several researchers attempted to use word lattices to handle generalized representation (Dyer et al., 2008; Hardmeier et al., 2010; Wuebker and Ney, 2012). Automatically clustering the training data into word classes in order to obtain smoother 1 We are referring to hard clustering here. Soft clustering is intractable as it requires a marginalization over all possible classes when calculating the n-gram probabilities. 422 Figure 1: Operation Sequence Model – Training Sentence with Generation and Test Sentences distributions and better generalizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (201"
C14-1041,2012.iwslt-papers.17,1,0.832647,"et al., 2007), replicating the settings described in (Birch et al., 2013) developed for the 2013 Workshop on Spoken Language Translation. The features included: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (Durrani et al., 2013b) with 4 additional supportive features: 2 gap-based penalties, 1 distance-based feature and 1 deletion penalty, lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the no-reordering-over-punctuation heuristic. We used the compact phrase table representation by JunczysDowmunt (2012). For our German-to-English experiments, we used compound splitting (Koehn and Knight, 2003). German-to-English and English-to-German baseline systems also used POS and morphological target sequence models built on the in-domain subset of the parallel corpus using Kne"
C14-1041,W11-2123,0,0.00711102,"∆+0.54 27.71 ∆+0.44 31.55 ∆+0.09 27.32 ∆+0.05 31.58 ∆+0.12 27.20 ∆-0.07 31.40 ∆-0.06 27.15 ∆-0.12 Table 2: Evaluating Generalized OSM Models for German-English pairs – Bold: Statistically Significant (Koehn, 2004) w.r.t Baseline Baseline System: We trained a Moses system (Koehn et al., 2007), replicating the settings described in (Birch et al., 2013) developed for the 2013 Workshop on Spoken Language Translation. The features included: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (Durrani et al., 2013b) with 4 additional supportive features: 2 gap-based penalties, 1 distance-based feature and 1 deletion penalty, lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the no-reordering-over-punctuation heuristic. We used the compact phrase table representation by Juncz"
C14-1041,E09-1043,1,0.844957,"focuses on using linguistic knowledge to improve reordering between syntactically different languages. A second group focuses on translating into morphologically rich languages. Initial efforts to use linguistic annotation focused on rearranging source sentences to be in the target order. Xia and McCord (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into"
C14-1041,E14-1003,0,0.045332,"n and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be interesting. 3 Operation Sequence Model The Operation Sequence Model (Durrani et al., 2011) is an instance of the N-gram based SMT framework (Casacuberta and Vidal, 2004; Mari˜no et al., 2006). It represents the translation process through a sequence of operations. An operation c"
C14-1041,P07-1019,0,0.0167512,"atures included: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (Durrani et al., 2013b) with 4 additional supportive features: 2 gap-based penalties, 1 distance-based feature and 1 deletion penalty, lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the no-reordering-over-punctuation heuristic. We used the compact phrase table representation by JunczysDowmunt (2012). For our German-to-English experiments, we used compound splitting (Koehn and Knight, 2003). German-to-English and English-to-German baseline systems also used POS and morphological target sequence models built on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models and as additional factors in phrase translation models (Koehn and Hoang, 2007). We used an unsupervised transliterat"
C14-1041,D07-1091,1,0.330247,"can generalize better in sparse data conditions. The model benefits from wider contextual information as we show empirically in our results. We investigate two methods to combine generalized OSM models with the lexically driven OSM model and experimented on German-English translation tasks. Our best system that uses a linear combination of different OSM models gives significant improvements over a competitive baseline system. An improvement of up to +1.35 was observed on the English-to-German and up to +0.63 BLEU points on the German-to-English task over a factored augmented baseline system (Koehn and Hoang, 2007). POS taggers and morphological analyzers, however, are not available for many resource poor languages. In the second half of the paper we investigate whether annotating the data with automatic word This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 421 Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 421–432, Dublin, Ireland, August 23-29 2014. clusters helps improve t"
C14-1041,E03-1076,1,0.545896,"2013b) with 4 additional supportive features: 2 gap-based penalties, 1 distance-based feature and 1 deletion penalty, lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the no-reordering-over-punctuation heuristic. We used the compact phrase table representation by JunczysDowmunt (2012). For our German-to-English experiments, we used compound splitting (Koehn and Knight, 2003). German-to-English and English-to-German baseline systems also used POS and morphological target sequence models built on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models and as additional factors in phrase translation models (Koehn and Hoang, 2007). We used an unsupervised transliteration model (Durrani et al., 2014) to transliterate OOV words when translating into Russian. Tuning and Test: The systems were tuned on the dev2010 dataset and evaluated on the test2010-2013 datasets made available for the IWSLT-13 workshop. We performed a secondary set of exper"
C14-1041,P07-2045,1,0.0212808,"Missing"
C14-1041,W04-3250,1,0.141116,"Missing"
C14-1041,N04-1022,0,0.0715901,"on Spoken Language Translation. The features included: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (Durrani et al., 2013b) with 4 additional supportive features: 2 gap-based penalties, 1 distance-based feature and 1 deletion penalty, lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the no-reordering-over-punctuation heuristic. We used the compact phrase table representation by JunczysDowmunt (2012). For our German-to-English experiments, we used compound splitting (Koehn and Knight, 2003). German-to-English and English-to-German baseline systems also used POS and morphological target sequence models built on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models and as additional factors in phrase translation models (Koehn and Hoang, 2007"
C14-1041,N12-1005,0,0.0378999,"een a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be interesting. 3 Operation Sequence Model The Operation Sequence Model (Durrani et al., 2011) is an instance of the N-gram based SMT framework (Casacuberta and Vidal, 2004; Mari˜no et al., 2006). It represents the translation process through a sequence of operation"
C14-1041,J06-4004,0,0.140693,"Missing"
C14-1041,W11-2124,0,0.0222468,"d to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate step has been studied by To"
C14-1041,J03-1002,0,0.0202923,"421–432, Dublin, Ireland, August 23-29 2014. clusters helps improve the performance. Word clustering is similar to POS-tagging/Morphological annotation except that it also captures interesting syntactic and lexical semantics, for example countries and languages are grouped in separate clusters, animate objects are differentiated from inanimate objects, colors are grouped in a separate cluster etc. Word clusters, however, deterministically map each word type to a unique1 cluster, unlike POS/Morph tagging, and therefore might be less useful for disambiguation. We use the mkcls utility in GIZA (Och and Ney, 2003) to cluster source and target vocabularies into classes and will therefore refer to automatic classes as Och clusters/classes in this paper. We first use Och classes as an additional factor in phrase-based translation model, along with a target LM model over cluster-ids to improve the baseline system. We then additionally use the OSM model over cluster-ids. Our experiments include translation from English to Dutch, French, Italian, Polish, Portuguese, Russian, Spanish, Slovenian and Turkish on IWSLT shared task data. Our results show an average improvement of +0.80, ranging from +0.41 to +2.02"
C14-1041,E99-1010,0,0.442864,"or the Germanto-English pair, giving a statistically significant gain of +0.63 on iwslt10 and +0.35 on wmt13 . Using both the models together did not give any further significant improvements. The results changed by +0.10 and -0.09 on the wmt13 and iwslt10 test-sets respectively. Results-II – Using Och Classes: In our secondary experiments we tested the effect of using Och clusters. The overall goal was to study whether using unsupervised word classes can serve the same purpose as POS tags and to compare the two methods of annotating the data. We obtained Och clusters using the mkcls utility (Och, 1999) in GIZA++ (Och and Ney, 2003). This is generally run during the alignment process where data is divided into 50 classes to estimate IBM Model-4. Chahuneau et al. (2013) found mapping data to 600 Och clusters useful, so we used this as well. We additionally experimented with using 200 and 1000 classes. We integrated Och clusters as additional factors4 when training the phrase-translation models and used a monolingual n-gram model over cluster-ids built on the target-side of the in-domain corpus. Then we added a 5-gram OSM model over cluster-ids. We replace surface forms with their cluster-ids"
C14-1041,P02-1040,0,0.100863,"nto Russian. Tuning and Test: The systems were tuned on the dev2010 dataset and evaluated on the test2010-2013 datasets made available for the IWSLT-13 workshop. We performed a secondary set of experiments for German-English pairs using tuning and test sets made available for the WMT-13 workshop. We concatenated the news-test sets 2008 and 2009 to obtain a large dev-set of 4576 sentences. Evaluation was performed on the news-test set 2013 which contains 3000 sentences. Tuning was performed using the k-best batch MIRA algorithm (Cherry and Foster, 2012) with at most 25 iterations. We use BLEU (Papineni et al., 2002) as a metric to evaluate our results. Results I – Using Linguistic Annotation: We trained 5-gram OSM models over different representations and added these to the baseline system. First we evaluated Modeland (Mand ) which uses a MIRA tuned linear combination of different OSM models versus Modelor (Mor ) which computes only one OSM model but allows the generator to switch between different OSM models built on various generalized forms. Table 2 shows results from running experiments on German-English pairs. We found that the simpler model Modeland outperforms Modelor in all the experiments. Model"
C14-1041,popovic-ney-2006-pos,0,0.201708,"Missing"
C14-1041,C12-2104,0,0.0162602,"lizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be interesting. 3 Operation Sequence Model The Operation Sequence Model (Durrani et al., 2011) is an instance of the N-gram based SMT framework (Casacuberta and Vidal, 2004; Mari˜no et al., 2006). It represents the translation process through a sequ"
C14-1041,P08-1059,0,0.0128728,"1) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate step has been studied by Toutanova et al. (2008), de Gispert and Mariˆno (2008), Fraser et al. (2012), Chahuneau et al. (2013) and others. Koehn and Hoang (2007) proposed to integrate different levels of linguistic information as factors into the phrase-based translation model. Yeniterzi and Oflazer (2010) used source syntactic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find"
C14-1041,W12-3157,0,0.0126006,"nal complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them as a part of translation, and which ones are better predicted through generation, also in the English-to-Arabic task. Several researchers attempted to use word lattices to handle generalized representation (Dyer et al., 2008; Hardmeier et al., 2010; Wuebker and Ney, 2012). Automatically clustering the training data into word classes in order to obtain smoother 1 We are referring to hard clustering here. Soft clustering is intractable as it requires a marginalization over all possible classes when calculating the n-gram probabilities. 422 Figure 1: Operation Sequence Model – Training Sentence with Generation and Test Sentences distributions and better generalizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsi"
C14-1041,D13-1138,0,0.365066,"stering is intractable as it requires a marginalization over all possible classes when calculating the n-gram probabilities. 422 Figure 1: Operation Sequence Model – Training Sentence with Generation and Test Sentences distributions and better generalizations has been a widely known and applied technique in natural language processing. Training based on word classes has been previously explored by various researchers. Cherry (2013) addressed data sparsity in lexicalized reordering models by using sparse features based on word classes. Other parallel attempts on using word-class models include Wuebker et al. (2013), Chahuneau et al. (2013) and Bisazza and Monz (2014). More recent research has started to set apart from the conventional maximum likelihood estimates toward neural network-based models that use continuous space representation (Schwenk, 2012; Le et al., 2012; Hu et al., 2014; Gao et al., 2014). Although these methods have achieved impressive improvements, traditional models continue to dominate the field due to their simplicity and low computational complexity. How much of the improvement will be retained when scaling these models to all available data instead of a limited amount will be inte"
C14-1041,C04-1073,0,0.0421089,"Section 2 gives an account on related work. Section 3 discusses the factor-based OSM model. Section 4 presents the experimental setup and the results. Section 5 concludes the paper. 2 Related Work Previous work on integrating linguistic knowledge into SMT models can be broken into two groups. The first group focuses on using linguistic knowledge to improve reordering between syntactically different languages. A second group focuses on translating into morphologically rich languages. Initial efforts to use linguistic annotation focused on rearranging source sentences to be in the target order. Xia and McCord (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and"
C14-1041,P10-1047,0,0.0375461,"ering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and then inflecting the stems in a separate step has been studied by Toutanova et al. (2008), de Gispert and Mariˆno (2008), Fraser et al. (2012), Chahuneau et al. (2013) and others. Koehn and Hoang (2007) proposed to integrate different levels of linguistic information as factors into the phrase-based translation model. Yeniterzi and Oflazer (2010) used source syntactic structures as additional complex tag factors for English-to-Turkish phrase-based machine translation. Green and DeNero (2012) proposed a target-side, class-based agreement model to handle morpho-syntactic agreement errors when translating from English-to-Arabic. El Kholy and Habash (2012) tested three models to find out which features are best handled by modeling them as a part of translation, and which ones are better predicted through generation, also in the English-to-Arabic task. Several researchers attempted to use word lattices to handle generalized representation"
C14-1041,W06-3119,0,0.0289361,"sentences to be in the target order. Xia and McCord (2004) proposed a method to automatically learn rewrite rules to preorder source sentences. Collins et al. (2005) and Popovi´c and Ney (2006) proposed methods for reordering the source using a small set of handcrafted rules. Crego and Mari˜no (2007) use syntactic trees to derive rewrite rules. Hoang and Koehn (2009) used POS tags to create templates for surface word translation to create longer phrase translation. A whole new paradigm of using syntactic annotation to address long range reorderings has emerged following Galley et al. (2006), Zollmann and Venugopal (2006), Chiang (2007) etc. Crego and Yvon (2010) and Niehues et al. (2011) used a Tuple Sequence Model (TSM) over POS tags in an N-gram-based search to improve mid-range reorderings. Our work is similar to them except that OSM model is substantially different from the TSM model as it integrates both the translation and reordering mechanisms into a combined model. Therefore both translation and reordering decisions can benefit from richer generalized representations. A second group of work addresses the problem of translating into morphologically richer languages. The idea of translating to stems and"
C14-1041,J04-2004,0,\N,Missing
C14-1041,2013.iwslt-evaluation.16,1,\N,Missing
C14-1041,W13-2201,1,\N,Missing
C14-1041,2013.iwslt-evaluation.3,1,\N,Missing
D07-1006,J00-1004,0,0.0127509,"ative model. (Zens et al., 2004) introduced a model featuring a symmetrized lexicon. (Liang et al., 2006) showed how to train two HMM models, a 1-to-N model and a M-to-1 model, to agree in predicting all of the links generated, resulting in a 1-to-1 alignment with occasional rare 1to-N or M-to-1 links. We improve on these works by choosing a new structure for our generative model, the head word link structure, which is both symmetric and a robust structure for modeling of nonconsecutive M-to-N alignments. In designing LEAF, we were also inspired by dependency-based alignment models (Wu, 1997; Alshawi et al., 2000; Yamada and Knight, 2001; Cherry and Lin, 2003; Zhang and Gildea, 2004). In contrast with their approaches, we have a very flat, one-level notion of dependency, which is bilingually motivated and learned automatically from the parallel corpus. This idea of dependency has some similarity with hierarchical SMT models such as (Chiang, 2005). The discriminative component of our work is based on a plethora of recent literature. This literature generally views the discriminative modeling problem as a supervised problem involving the combination of heuristically derived feature functions. These feat"
D07-1006,N06-1013,0,0.0262688,"involving the combination of heuristically derived feature functions. These feature functions generally include the prediction of some type of generative model, such as the HMM model or Model 4. A discriminatively trained 1-to-N model with feature functions specifically designed for Arabic was presented in (Ittycheriah and Roukos, 2005). (Lacoste-Julien et al., 2006) created a discriminative model able to model 1-to-1, 1-to2 and 2-to-1 alignments for which the best results were obtained using features based on symmetric HMMs trained to agree, (Liang et al., 2006), and 58 intersected Model 4. (Ayan and Dorr, 2006) defined a discriminative model which learns how to combine the predictions of several alignment algorithms. The experiments performed included Model 4 and the HMM extensions of (Lopez and Resnik, 2005). (Moore et al., 2006) introduced a discriminative model of 1-to-N and M-to-1 alignments, and similarly to (Lacoste-Julien et al., 2006) the best results were obtained using HMMs trained to agree and intersected Model 4. LEAF is not bound by the structural restrictions present either directly in these models, or in the features derived from the generative models used. We also iterate the generat"
D07-1006,J93-2003,0,0.0754534,"−1 and deterministically set ψi = χi . We can also specialize our generative story to the consecutive word M-to-N alignments used in “phrase-based” models, though in this case the conditioning of the generation decisions would be quite different. This involves adding checks on source and target connection geometry to the generative story which, if violated, would return “failure”; naturally this is at the cost of additional deficiency. 2.2 Unsupervised Parameter Estimation We can perform maximum likelihood estimation of the parameters of this model in a similar fashion 54 to that of Model 4 (Brown et al., 1993), described thoroughly in (Och and Ney, 2003). We use Viterbi training (Brown et al., 1993) but neighborhood estimation (Al-Onaizan et al., 1999; Och and Ney, 2003) or “pegging” (Brown et al., 1993) could also be used. To initialize the parameters of the generative model for the first iteration, we use bootstrapping from a 1-to-N and a M-to-1 alignment. We use the intersection of the 1-to-N and M-to-1 alignments to establish the head word relationship, the 1-to-N alignment to delineate the target word cepts, and the M-to-1 alignment to delineate the source word cepts. In bootstrapping, a probl"
D07-1006,P03-1012,0,0.0160584,"odel featuring a symmetrized lexicon. (Liang et al., 2006) showed how to train two HMM models, a 1-to-N model and a M-to-1 model, to agree in predicting all of the links generated, resulting in a 1-to-1 alignment with occasional rare 1to-N or M-to-1 links. We improve on these works by choosing a new structure for our generative model, the head word link structure, which is both symmetric and a robust structure for modeling of nonconsecutive M-to-N alignments. In designing LEAF, we were also inspired by dependency-based alignment models (Wu, 1997; Alshawi et al., 2000; Yamada and Knight, 2001; Cherry and Lin, 2003; Zhang and Gildea, 2004). In contrast with their approaches, we have a very flat, one-level notion of dependency, which is bilingually motivated and learned automatically from the parallel corpus. This idea of dependency has some similarity with hierarchical SMT models such as (Chiang, 2005). The discriminative component of our work is based on a plethora of recent literature. This literature generally views the discriminative modeling problem as a supervised problem involving the combination of heuristically derived feature functions. These feature functions generally include the prediction"
D07-1006,P05-1033,0,0.0534291,"IZA++ Model 4. We believe that the features in LEAF are too high dimensional to use for the Arabic/English task without the backoffs available in the semi-supervised models. The baseline semi-supervised system (line 3) was run for three iterations and the resulting alignments were combined with the “union” heuristic. We ran the LEAF semi-supervised system for two iterations. The best result is the LEAF semi-supervised system (line 4), with a gain of 5.4 F-Measure over the baseline semi-supervised system. For Arabic/English translation we train a state of the art hierarchical model similar to (Chiang, 2005) using our Viterbi alignments. The translation test data used is described in Table 2. We use two trigram language models, one built using the English portion of the training data and the other built using additional English news data. The test set is from the NIST 2005 translation task. LEAF had the best performance scoring 1.43 BLEU better than the baseline semi-supervised system, which is statistically significant. 57 5 Previous Work The LEAF model is inspired by the literature on generative modeling for statistical word alignment and particularly by Model 4 (Brown et al., 1993). Much of th"
D07-1006,H05-1022,0,0.291779,"5 translation task. LEAF had the best performance scoring 1.43 BLEU better than the baseline semi-supervised system, which is statistically significant. 57 5 Previous Work The LEAF model is inspired by the literature on generative modeling for statistical word alignment and particularly by Model 4 (Brown et al., 1993). Much of the additional work on generative modeling of 1to-N word alignments is based on the HMM model (Vogel et al., 1996). (Toutanova et al., 2002) and (Lopez and Resnik, 2005) presented a variety of refinements of the HMM model particularly effective for low data conditions. (Deng and Byrne, 2005) described work on extending the HMM model using a bigram formulation to generate 1-to-N alignment structure. The common thread connecting these works is their reliance on the 1-to-N approximation, while we have defined a generative model which does not require use of this approximation, at the cost of having to rely on local search. There has also been work on generative models for other alignment structures. (Wang and Waibel, 1998) introduced a generative story based on extension of the generative story of Model 4. The alignment structure modeled was “consecutive M to non-consecutive N”. (Ma"
D07-1006,P06-1097,1,0.924217,"gmax a X λm hm (f, a, e) (7) m We decompose the new generative model presented in Section 2 in both translation directions to provide the initial feature functions for our loglinear model, features 1 to 10 and 16 to 25 in Table 1. We use backoffs for the translation decisions (features 11 and 26 and the HMM translation tables which are features 12 and 27) and the target cept size distributions (features 13, 14, 28 and 29 in Table 1), as well as heuristics which directly control the number of unaligned words we generate (features 15 and 30 in Table 1). We use the semi-supervised EMD algorithm (Fraser and Marcu, 2006b) to train the model. The initial M-step bootstraps parameters as described in Section 2.2 from a M-to-1 and a 1-to-N alignment. We then perform the D-step following (Fraser and 55 A@ @ D B nC nn~n~~ @@ n n @ nn ~ n@n@n ~~~ nnn E A@ @ D B nC nn~n~~ @@ n n @ nn ~ n@n@n ~~~ nnn E Figure 2: Two alignments with the same translational correspondence Marcu, 2006b). Given the feature function parameters estimated in the M-step and the feature function weights λ determined in the D-step, the E-step searches for the Viterbi alignment for the full training corpus. We use 1 − F-Measure as our error crit"
D07-1006,H05-1012,0,0.245971,"arallel corpus. This idea of dependency has some similarity with hierarchical SMT models such as (Chiang, 2005). The discriminative component of our work is based on a plethora of recent literature. This literature generally views the discriminative modeling problem as a supervised problem involving the combination of heuristically derived feature functions. These feature functions generally include the prediction of some type of generative model, such as the HMM model or Model 4. A discriminatively trained 1-to-N model with feature functions specifically designed for Arabic was presented in (Ittycheriah and Roukos, 2005). (Lacoste-Julien et al., 2006) created a discriminative model able to model 1-to-1, 1-to2 and 2-to-1 alignments for which the best results were obtained using features based on symmetric HMMs trained to agree, (Liang et al., 2006), and 58 intersected Model 4. (Ayan and Dorr, 2006) defined a discriminative model which learns how to combine the predictions of several alignment algorithms. The experiments performed included Model 4 and the HMM extensions of (Lopez and Resnik, 2005). (Moore et al., 2006) introduced a discriminative model of 1-to-N and M-to-1 alignments, and similarly to (Lacoste-"
D07-1006,J99-4005,0,0.0357066,"lignment structure where, for instance, a source word generates target words but no link between any of the target words and the source word appears in the intersection, so it is not clear which target word is the target head word. To address this, we consider each of the N generated target words as the target head word in turn and assign this configuration 1/N of the counts. For each iteration of training we search for the Viterbi solution for millions of sentences. Evidence that inference over the space of all possible alignments is intractable has been presented, for a similar problem, in (Knight, 1999). Unlike phrasebased SMT, left-to-right hypothesis extension using a beam decoder is unlikely to be effective because in word alignment reordering is not limited to a small local window and so the necessary beam would be very large. We are not aware of admissible or inadmissible search heuristics which have been shown to be effective when used in conjunction with a search algorithm similar to A* search for a model predicting over a structure like ours. Therefore we use a simple local search algorithm which operates on complete hypotheses. (Brown et al., 1993) defined two local search operation"
D07-1006,N03-1017,1,0.191664,"covered a methodological problem with our baseline systems, which is that two alignments which have the same translational correspondence can have different F-Measures. An example is shown in Figure 2. To overcome this problem we fully interlinked the transitive closure of the undirected bigraph formed by each alignment hypothesized by our baseline alignment systems1 . This operation maps the alignment shown to the left in Figure 2 to the alignment shown to the right. This operation does not change the collection of phrases or rules extracted from a hypothesized alignment, see, for instance, (Koehn et al., 2003). Working with this fully interlinked representation we found that the best settings of α were α = 0.1 for the Arabic/English task and α = 0.4 for the French/English task. 4 Experiments 4.1 Data Sets We perform experiments on two large alignments tasks, for Arabic/English and French/English data sets. Statistics for these sets are shown in Table 2. All of the data used is available from the Linguistic Data Consortium except for the French/English 1 All of the gold standard alignments were fully interlinked as distributed. We did not modify the gold standard alignments. 1 chi(χi |ei ) source wo"
D07-1006,N06-1015,0,0.221337,"endency has some similarity with hierarchical SMT models such as (Chiang, 2005). The discriminative component of our work is based on a plethora of recent literature. This literature generally views the discriminative modeling problem as a supervised problem involving the combination of heuristically derived feature functions. These feature functions generally include the prediction of some type of generative model, such as the HMM model or Model 4. A discriminatively trained 1-to-N model with feature functions specifically designed for Arabic was presented in (Ittycheriah and Roukos, 2005). (Lacoste-Julien et al., 2006) created a discriminative model able to model 1-to-1, 1-to2 and 2-to-1 alignments for which the best results were obtained using features based on symmetric HMMs trained to agree, (Liang et al., 2006), and 58 intersected Model 4. (Ayan and Dorr, 2006) defined a discriminative model which learns how to combine the predictions of several alignment algorithms. The experiments performed included Model 4 and the HMM extensions of (Lopez and Resnik, 2005). (Moore et al., 2006) introduced a discriminative model of 1-to-N and M-to-1 alignments, and similarly to (Lacoste-Julien et al., 2006) the best r"
D07-1006,N06-1014,0,0.37423,"uristic symmetrizaS YSTEM GIZA++ (F RASER AND M ARCU , 2006 B ) LEAF UNSUPERVISED LEAF SEMI - SUPERVISED F RENCH /E NGLISH F-M EASURE (α = 0.4) BLEU 73.5 30.63 74.1 31.40 74.5 76.3 31.86 A RABIC /E NGLISH F- MEASURE (α = 0.1) BLEU 75.8 51.55 79.1 52.89 72.3 84.5 54.34 Table 3: Experimental Results tion of the output of a 1-to-N model and a M-to-1 model resulting in a M-to-N alignment, this was extended in (Koehn et al., 2003). We have used insights from these works to help determine the structure of our generative model. (Zens et al., 2004) introduced a model featuring a symmetrized lexicon. (Liang et al., 2006) showed how to train two HMM models, a 1-to-N model and a M-to-1 model, to agree in predicting all of the links generated, resulting in a 1-to-1 alignment with occasional rare 1to-N or M-to-1 links. We improve on these works by choosing a new structure for our generative model, the head word link structure, which is both symmetric and a robust structure for modeling of nonconsecutive M-to-N alignments. In designing LEAF, we were also inspired by dependency-based alignment models (Wu, 1997; Alshawi et al., 2000; Yamada and Knight, 2001; Cherry and Lin, 2003; Zhang and Gildea, 2004). In contrast"
D07-1006,P05-1057,0,0.0961153,"al., 2006) the best results were obtained using HMMs trained to agree and intersected Model 4. LEAF is not bound by the structural restrictions present either directly in these models, or in the features derived from the generative models used. We also iterate the generative/discriminative process, which allows the discriminative predictions to influence the generative model. Our work is most similar to work using discriminative log-linear models for alignment, which is similar to discriminative log-linear models used for the SMT decoding (translation) problem (Och and Ney, 2002; Och, 2003). (Liu et al., 2005) presented a log-linear model combining IBM Model 3 trained in both directions with heuristic features which resulted in a 1-to-1 alignment. (Fraser and Marcu, 2006b) described symmetrized training of a 1-toN log-linear model and a M-to-1 log-linear model. These models took advantage of features derived from both training directions, similar to the symmetrized lexicons of (Zens et al., 2004), including features derived from the HMM model and Model 4. However, despite the symmetric lexicons, these models were only able to optimize the performance of the 1-to-N model and the M-to-1 model separat"
D07-1006,W05-0812,0,0.110907,"nglish portion of the training data and the other built using additional English news data. The test set is from the NIST 2005 translation task. LEAF had the best performance scoring 1.43 BLEU better than the baseline semi-supervised system, which is statistically significant. 57 5 Previous Work The LEAF model is inspired by the literature on generative modeling for statistical word alignment and particularly by Model 4 (Brown et al., 1993). Much of the additional work on generative modeling of 1to-N word alignments is based on the HMM model (Vogel et al., 1996). (Toutanova et al., 2002) and (Lopez and Resnik, 2005) presented a variety of refinements of the HMM model particularly effective for low data conditions. (Deng and Byrne, 2005) described work on extending the HMM model using a bigram formulation to generate 1-to-N alignment structure. The common thread connecting these works is their reliance on the 1-to-N approximation, while we have defined a generative model which does not require use of this approximation, at the cost of having to rely on local search. There has also been work on generative models for other alignment structures. (Wang and Waibel, 1998) introduced a generative story based on"
D07-1006,W02-1018,1,0.955473,"is terminated when no operation results in an improvement. (Och and Ney, 2003) discussed efficient implementation. In our model, because the alignment structure is richer, we define the following operations: move French non-head word to new head, move English non-head word to new head, swap heads of two French non-head words, swap heads of two English non-head words, swap English head word links of two French head words, link English word to French word making new head words, unlink English and French head words. We use multiple restarts to try to reduce search errors. (Germann et al., 2004; Marcu and Wong, 2002) have some similar operations without the head word distinction. 3 Semi-supervised parameter estimation Equation 6 defines a log-linear model. Each feature function hm has an associated weight λm . Given a vector of these weights λ, the alignment search problem, i.e. the search to return the best alignment a ˆ of the sentences e and f according to the model, is specified by Equation 7. P exp( m λm hm (a, e, f )) P pλ (f, a|e) = P 0 0 a0 ,f 0 exp( m λm hm (a , e, f )) (6) a ˆ = argmax a X λm hm (f, a, e) (7) m We decompose the new generative model presented in Section 2 in both translation dire"
D07-1006,C04-1032,0,0.0448064,"nt structure. The common thread connecting these works is their reliance on the 1-to-N approximation, while we have defined a generative model which does not require use of this approximation, at the cost of having to rely on local search. There has also been work on generative models for other alignment structures. (Wang and Waibel, 1998) introduced a generative story based on extension of the generative story of Model 4. The alignment structure modeled was “consecutive M to non-consecutive N”. (Marcu and Wong, 2002) defined the Joint model, which modeled consecutive word M-to-N alignments. (Matusov et al., 2004) presented a model capable of modeling 1-toN and M-to-1 alignments (but not arbitrary M-toN alignments) which was bootstrapped from Model 4. LEAF directly models non-consecutive M-to-N alignments. One important aspect of LEAF is its symmetry. (Och and Ney, 2003) invented heuristic symmetrizaS YSTEM GIZA++ (F RASER AND M ARCU , 2006 B ) LEAF UNSUPERVISED LEAF SEMI - SUPERVISED F RENCH /E NGLISH F-M EASURE (α = 0.4) BLEU 73.5 30.63 74.1 31.40 74.5 76.3 31.86 A RABIC /E NGLISH F- MEASURE (α = 0.1) BLEU 75.8 51.55 79.1 52.89 72.3 84.5 54.34 Table 3: Experimental Results tion of the output of a 1-t"
D07-1006,P06-1065,0,0.223701,"o-N model with feature functions specifically designed for Arabic was presented in (Ittycheriah and Roukos, 2005). (Lacoste-Julien et al., 2006) created a discriminative model able to model 1-to-1, 1-to2 and 2-to-1 alignments for which the best results were obtained using features based on symmetric HMMs trained to agree, (Liang et al., 2006), and 58 intersected Model 4. (Ayan and Dorr, 2006) defined a discriminative model which learns how to combine the predictions of several alignment algorithms. The experiments performed included Model 4 and the HMM extensions of (Lopez and Resnik, 2005). (Moore et al., 2006) introduced a discriminative model of 1-to-N and M-to-1 alignments, and similarly to (Lacoste-Julien et al., 2006) the best results were obtained using HMMs trained to agree and intersected Model 4. LEAF is not bound by the structural restrictions present either directly in these models, or in the features derived from the generative models used. We also iterate the generative/discriminative process, which allows the discriminative predictions to influence the generative model. Our work is most similar to work using discriminative log-linear models for alignment, which is similar to discrimina"
D07-1006,P02-1038,0,0.0451781,"similarly to (Lacoste-Julien et al., 2006) the best results were obtained using HMMs trained to agree and intersected Model 4. LEAF is not bound by the structural restrictions present either directly in these models, or in the features derived from the generative models used. We also iterate the generative/discriminative process, which allows the discriminative predictions to influence the generative model. Our work is most similar to work using discriminative log-linear models for alignment, which is similar to discriminative log-linear models used for the SMT decoding (translation) problem (Och and Ney, 2002; Och, 2003). (Liu et al., 2005) presented a log-linear model combining IBM Model 3 trained in both directions with heuristic features which resulted in a 1-to-1 alignment. (Fraser and Marcu, 2006b) described symmetrized training of a 1-toN log-linear model and a M-to-1 log-linear model. These models took advantage of features derived from both training directions, similar to the symmetrized lexicons of (Zens et al., 2004), including features derived from the HMM model and Model 4. However, despite the symmetric lexicons, these models were only able to optimize the performance of the 1-to-N mo"
D07-1006,J03-1002,0,0.41614,"tion l Y p(f, a|e) =[ g(χi |ei )] i=1 l Y [ i=1 l Y [ δ(χi , −1)w−1 (µi − i|classe (ei ))] δ(χi , 1)t1 (τi1 |ei )] i=1 l Y [ δ(χi , 1)s(ψi |ei , γi )] let f be the string f πik = τik i=1 We note that the steps which return “failure” are required because the model is deficient. Deficiency means that a portion of the probability mass in the model is allocated towards generative stories which would result in infeasible alignment structures. Our model has deficiency in the non-spurious target word placement, just as Model 4 does. It has additional deficiency in the source word linking decisions. (Och and Ney, 2003) presented results suggesting that the additional parameters required to ensure that a model is not deficient result in inferior performance, but we plan to study whether this is the case for our generative model in future work. Given e, f and a candidate alignment a, which represents both the links between source and target head-words and the head-word connections of the non-head words, we would like to calculate p(f, a|e). The formula for this is: 53 [s0 (ψ0 | l X ψi )] i=1 [ ψ0 Y t0 (τ0k )] k=1 ψi l Y Y t&gt;1 (τik |ei , classh (τi1 ))] [ i=1 k=2 ψi l Y Y [ Dik (πik )] i=1 k=1 where: δ(i, i0 )"
D07-1006,J04-4002,0,0.109529,"est symmetrization heuristic for this system was “union”, which is most likely due to our use of fully linked alignments which was discussed at the end of Section 3. We observe that LEAF unsupervised (line 3) is competitive with GIZA++ (line 1), and is in fact competitive with the baseline semi-supervised result (line 2). We ran the LEAF semi-supervised system for two iterations (line 4). The best result is the LEAF semi-supervised system, with a gain of 1.8 F-Measure over the LEAF unsupervised system. For French/English translation we use a state of the art phrase-based MT system similar to (Och and Ney, 2004; Koehn et al., 2003). The translation test data is described in Table 2. We use two trigram language models, one built using the English portion of the training data and the other built using additional English news data. The BLEU scores reported in this work are calculated using lowercased and tokenized data. For semi-supervised LEAF the gain of 0.46 BLEU over the semi-supervised baseline is not statistically significant (a gain of 0.78 BLEU would be required), but LEAF semi-supervised compared with GIZA++ is significant, with a gain of 1.23 BLEU. We note that this shows a large gain in tran"
D07-1006,P03-1021,0,0.0606469,"te-Julien et al., 2006) the best results were obtained using HMMs trained to agree and intersected Model 4. LEAF is not bound by the structural restrictions present either directly in these models, or in the features derived from the generative models used. We also iterate the generative/discriminative process, which allows the discriminative predictions to influence the generative model. Our work is most similar to work using discriminative log-linear models for alignment, which is similar to discriminative log-linear models used for the SMT decoding (translation) problem (Och and Ney, 2002; Och, 2003). (Liu et al., 2005) presented a log-linear model combining IBM Model 3 trained in both directions with heuristic features which resulted in a 1-to-1 alignment. (Fraser and Marcu, 2006b) described symmetrized training of a 1-toN log-linear model and a M-to-1 log-linear model. These models took advantage of features derived from both training directions, similar to the symmetrized lexicons of (Zens et al., 2004), including features derived from the HMM model and Model 4. However, despite the symmetric lexicons, these models were only able to optimize the performance of the 1-to-N model and the"
D07-1006,W02-1012,0,0.0197476,"Missing"
D07-1006,C96-2141,0,0.986805,"eft-most target non-head word d&gt;2 (4j|classf (fj )) movement for subsequent target non-head words t(fj |ei ) translation without dependency on word-type t(fj |ei ) translation table from final HMM iteration s(ψi |γi ) target cept size without dependency on source head word e s(ψi |ei ) target cept size without dependency on γi target spurious word penalty (same features, other direction) Table 1: Feature functions gold standard alignments which are available from the authors. 4.2 Experiments To build all alignment systems, we start with 5 iterations of Model 1 followed by 4 iterations of HMM (Vogel et al., 1996), as implemented in GIZA++ (Och and Ney, 2003). For all non-LEAF systems, we take the best performing of the “union”, “refined” and “intersection” symmetrization heuristics (Och and Ney, 2003) to combine the 1-to-N and M-to-1 directions resulting in a M-to-N alignment. Because these systems do not output fully linked alignments, we fully link the resulting alignments as described at the end of Section 3. The reader should recall that this does not change the set of rules or phrases that can be extracted using the alignment. We perform one main comparison, which is of semi-supervised systems, w"
D07-1006,P98-2221,0,0.138288,", 1996). (Toutanova et al., 2002) and (Lopez and Resnik, 2005) presented a variety of refinements of the HMM model particularly effective for low data conditions. (Deng and Byrne, 2005) described work on extending the HMM model using a bigram formulation to generate 1-to-N alignment structure. The common thread connecting these works is their reliance on the 1-to-N approximation, while we have defined a generative model which does not require use of this approximation, at the cost of having to rely on local search. There has also been work on generative models for other alignment structures. (Wang and Waibel, 1998) introduced a generative story based on extension of the generative story of Model 4. The alignment structure modeled was “consecutive M to non-consecutive N”. (Marcu and Wong, 2002) defined the Joint model, which modeled consecutive word M-to-N alignments. (Matusov et al., 2004) presented a model capable of modeling 1-toN and M-to-1 alignments (but not arbitrary M-toN alignments) which was bootstrapped from Model 4. LEAF directly models non-consecutive M-to-N alignments. One important aspect of LEAF is its symmetry. (Och and Ney, 2003) invented heuristic symmetrizaS YSTEM GIZA++ (F RASER AND"
D07-1006,J97-3002,0,0.399103,"our generative model. (Zens et al., 2004) introduced a model featuring a symmetrized lexicon. (Liang et al., 2006) showed how to train two HMM models, a 1-to-N model and a M-to-1 model, to agree in predicting all of the links generated, resulting in a 1-to-1 alignment with occasional rare 1to-N or M-to-1 links. We improve on these works by choosing a new structure for our generative model, the head word link structure, which is both symmetric and a robust structure for modeling of nonconsecutive M-to-N alignments. In designing LEAF, we were also inspired by dependency-based alignment models (Wu, 1997; Alshawi et al., 2000; Yamada and Knight, 2001; Cherry and Lin, 2003; Zhang and Gildea, 2004). In contrast with their approaches, we have a very flat, one-level notion of dependency, which is bilingually motivated and learned automatically from the parallel corpus. This idea of dependency has some similarity with hierarchical SMT models such as (Chiang, 2005). The discriminative component of our work is based on a plethora of recent literature. This literature generally views the discriminative modeling problem as a supervised problem involving the combination of heuristically derived feature"
D07-1006,P01-1067,0,0.0485432,"al., 2004) introduced a model featuring a symmetrized lexicon. (Liang et al., 2006) showed how to train two HMM models, a 1-to-N model and a M-to-1 model, to agree in predicting all of the links generated, resulting in a 1-to-1 alignment with occasional rare 1to-N or M-to-1 links. We improve on these works by choosing a new structure for our generative model, the head word link structure, which is both symmetric and a robust structure for modeling of nonconsecutive M-to-N alignments. In designing LEAF, we were also inspired by dependency-based alignment models (Wu, 1997; Alshawi et al., 2000; Yamada and Knight, 2001; Cherry and Lin, 2003; Zhang and Gildea, 2004). In contrast with their approaches, we have a very flat, one-level notion of dependency, which is bilingually motivated and learned automatically from the parallel corpus. This idea of dependency has some similarity with hierarchical SMT models such as (Chiang, 2005). The discriminative component of our work is based on a plethora of recent literature. This literature generally views the discriminative modeling problem as a supervised problem involving the combination of heuristically derived feature functions. These feature functions generally i"
D07-1006,C04-1006,0,0.152164,"mportant aspect of LEAF is its symmetry. (Och and Ney, 2003) invented heuristic symmetrizaS YSTEM GIZA++ (F RASER AND M ARCU , 2006 B ) LEAF UNSUPERVISED LEAF SEMI - SUPERVISED F RENCH /E NGLISH F-M EASURE (α = 0.4) BLEU 73.5 30.63 74.1 31.40 74.5 76.3 31.86 A RABIC /E NGLISH F- MEASURE (α = 0.1) BLEU 75.8 51.55 79.1 52.89 72.3 84.5 54.34 Table 3: Experimental Results tion of the output of a 1-to-N model and a M-to-1 model resulting in a M-to-N alignment, this was extended in (Koehn et al., 2003). We have used insights from these works to help determine the structure of our generative model. (Zens et al., 2004) introduced a model featuring a symmetrized lexicon. (Liang et al., 2006) showed how to train two HMM models, a 1-to-N model and a M-to-1 model, to agree in predicting all of the links generated, resulting in a 1-to-1 alignment with occasional rare 1to-N or M-to-1 links. We improve on these works by choosing a new structure for our generative model, the head word link structure, which is both symmetric and a robust structure for modeling of nonconsecutive M-to-N alignments. In designing LEAF, we were also inspired by dependency-based alignment models (Wu, 1997; Alshawi et al., 2000; Yamada and"
D07-1006,C04-1060,0,0.0184119,"trized lexicon. (Liang et al., 2006) showed how to train two HMM models, a 1-to-N model and a M-to-1 model, to agree in predicting all of the links generated, resulting in a 1-to-1 alignment with occasional rare 1to-N or M-to-1 links. We improve on these works by choosing a new structure for our generative model, the head word link structure, which is both symmetric and a robust structure for modeling of nonconsecutive M-to-N alignments. In designing LEAF, we were also inspired by dependency-based alignment models (Wu, 1997; Alshawi et al., 2000; Yamada and Knight, 2001; Cherry and Lin, 2003; Zhang and Gildea, 2004). In contrast with their approaches, we have a very flat, one-level notion of dependency, which is bilingually motivated and learned automatically from the parallel corpus. This idea of dependency has some similarity with hierarchical SMT models such as (Chiang, 2005). The discriminative component of our work is based on a plethora of recent literature. This literature generally views the discriminative modeling problem as a supervised problem involving the combination of heuristically derived feature functions. These feature functions generally include the prediction of some type of generativ"
D07-1006,J07-3002,1,\N,Missing
D07-1006,C98-2216,0,\N,Missing
D07-1006,P01-1030,1,\N,Missing
D15-1129,2009.iwslt-papers.4,0,0.475384,"Section 2 that string-to-tree rule selection is different from the hierarchical case addressed by previous work and define our rule selection model. In Section 3 we present the training procedure before providing a proof-of-concept evaluation in Section 4. 2 2.1 Rule selection for string-to-tree SMT String-to-tree machine translation We present string-to-tree machine translation as implemented in Moses (which is the framework that we use). String-to-tree rules have the form X/A → hα, γ, ∼i. On the source language side, 1 We use the string-to-tree component of Moses (Williams and Koehn, 2012; Hoang et al., 2009) in which we integrate the high-speed classifier Vowpal Wabbit http://hunch. net/˜vw/. 1095 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1095–1101, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computational Linguistics. Ces cellules pr´esentent plusieurs caract´eristiques sp´ecifiques F (Diverses)X1 caract´eristiques (importantes)X2 n’ont pas e´ t´e prises en compte. (Various)X1 characteristics (important)X2 were not considered. several specific characteristics These cells present JJ DT NNS VBP NP JJ NNS NP 2.2 VP S Ces robots"
D15-1129,D10-1063,0,0.0140753,"ng to training data by employing early stopping once classifier accuracy decreases on a heldout dataset.6 4 Experiments 4.1 Experimental Setup Our baseline system is a syntax-based system with linguistic annotation on the target language side (string-to-tree). We use the version implemented in the Moses open source toolkit (Hoang et al., 2009; Williams and Koehn, 2012) with standard parameters. Rule extraction is performed as in (Galley et al., 2004) with rule composition (Galley et al., 2006; DeNeefe et al., 2007). Non-lexical unary rules are removed (Chung et al., 2011) and scope-3 pruning (Hopkins and Langmead, 2010) is performed. Rule scoring is done using relative frequencies normalized over the source rhs and aligned non-terminals in the target rhs. The contrastive system is the same string-to-tree system but augmented with our rule selection model as a feature of the log-linear model. 4 Which is based on (Galley et al., 2004; Galley et al., 2006; DeNeefe et al., 2007). 5 Specifically, the label dependent version of Cost Sensitive One Against All which uses classification. 6 We use the development set which is also used for MIRA tuning. 1097 System Baseline Contrastive science 34.06 34.36 medical 49.87"
D15-1129,D13-1053,0,0.0189745,"erformance on several language pairs (Bojar et al., 2014). At the same time, soft syntactic features significantly improve the translation quality of hierarchical systems (Hiero) as shown in (Marton et al., 2012; Chiang, 2010; Liu et al., 2011; Cui et al., 2010). Improving the performance of stringto-tree systems through the integration of soft syntactic constraints on the source language side is therefore an interesting task. So far, all approaches on this topic include soft syntactic constraints into the rules of string-to-tree (Zhang et al., 2011; Huck et al., 2014) or stringto-dependency (Huang et al., 2013) systems and define heuristics to determine to what extent these constituents match the syntactic structure of the source sentence. We propose a novel way to integrate soft syntactic constraints into a string-totree system. We define a discriminative rule selection model for string-to-tree machine translation. We consider rule selection as a multi-class classification problem where the task is to select the correct target side of a rule given its source side as well as contextual information about the source sentence and the considered rule. So far, such models have been applied to systems wit"
D15-1129,2006.amta-papers.8,0,0.0419335,"orrect target side of a translation rule among rules with the same source side. We define a discriminative rule selection model for systems that have syntactic annotation on the target language side (stringto-tree). This is a new and clean way to integrate soft source syntactic constraints into string-to-tree systems as features of the rule selection model. We release our implementation as part of Moses. 1 Introduction Syntax-based machine translation is well known for its ability to handle non-local reordering. Syntax-based models either use linguistic annotation on the source language side (Huang, 2006; Liu et al., 2006), target language side (Galley et al., 2004; Galley et al., 2006) or are syntactic in a structural sense only (Chiang, 2005). Recent shared tasks have shown that systems integrating information on the target language side, also called string-to-tree systems, achieve the best performance on several language pairs (Bojar et al., 2014). At the same time, soft syntactic features significantly improve the translation quality of hierarchical systems (Hiero) as shown in (Marton et al., 2012; Chiang, 2010; Liu et al., 2011; Cui et al., 2010). Improving the performance of stringto-tr"
D15-1129,P13-1141,0,0.0142358,"tree system evaluation results. We evaluate the baseline and our global model on three domains: (1) news, (2) medical, and (3) science. The training data for news is taken from Europarl-v4. Development and test sets are from the news translation task of WMT 2009 (Callison-Burch et al., 2009). For medical we use the biomedical data from EMEA (Tiedemann, 2009). Since this is a parallel corpus only, we first removed duplicate sentences and then constructed development and test sets by randomly selecting sentence pairs. As training data for science we use the scientific abstracts data provided by Carpuat et al. (2013). Table 1 gives an overview of the corpora sizes. Berkeley parser (Petrov et al., 2006) is used to parse the English side of each parallel corpus (for string-to-tree rule extraction) as well as for parsing the French source side (for feature extraction). We trained a 5-gram language model on the English side of each training corpus using the SRI Language Modeling Toolkit (Stolcke, 2002). We train the model in the standard way and generate word alignments using GIZA++. After training, we reduced the number of translation rules by only keeping the 30-best rules with the same source side accordin"
D15-1129,W14-4018,0,0.0599425,"string-to-tree systems, achieve the best performance on several language pairs (Bojar et al., 2014). At the same time, soft syntactic features significantly improve the translation quality of hierarchical systems (Hiero) as shown in (Marton et al., 2012; Chiang, 2010; Liu et al., 2011; Cui et al., 2010). Improving the performance of stringto-tree systems through the integration of soft syntactic constraints on the source language side is therefore an interesting task. So far, all approaches on this topic include soft syntactic constraints into the rules of string-to-tree (Zhang et al., 2011; Huck et al., 2014) or stringto-dependency (Huang et al., 2013) systems and define heuristics to determine to what extent these constituents match the syntactic structure of the source sentence. We propose a novel way to integrate soft syntactic constraints into a string-totree system. We define a discriminative rule selection model for string-to-tree machine translation. We consider rule selection as a multi-class classification problem where the task is to select the correct target side of a rule given its source side as well as contextual information about the source sentence and the considered rule. So far,"
D15-1129,W04-3250,0,0.121965,"l in the standard way and generate word alignments using GIZA++. After training, we reduced the number of translation rules by only keeping the 30-best rules with the same source side according to the direct rule translation rule probability. Our rule selection model was trained with VW. All systems were tuned using batch MIRA (Cherry and Foster, 2012). We measured the overall translation quality with 4-gram BLEU (Papineni et al., 2002), which was computed on tokenized and lowercased data for all systems. Statistical significance is computed with the pairwise bootstrap resampling technique of Koehn (2004). 4.2 Results Table 2 displays the BLEU scores for our experiments. On science and news, small improvements are achieved while for medical a small decrease is observed. None of these differences is statistically significant. An analysis of the system outputs for each domain showed that the small improvements are due to the fact that in string-to-tree systems there is not enough ambiguity between competing rules during decoding. To support this conjecture, we first analyzed rule diversity by looking at the negative samples collected during training example acquisition. In a second step, we comp"
D15-1129,N12-1047,0,0.0540739,"corpus (for string-to-tree rule extraction) as well as for parsing the French source side (for feature extraction). We trained a 5-gram language model on the English side of each training corpus using the SRI Language Modeling Toolkit (Stolcke, 2002). We train the model in the standard way and generate word alignments using GIZA++. After training, we reduced the number of translation rules by only keeping the 30-best rules with the same source side according to the direct rule translation rule probability. Our rule selection model was trained with VW. All systems were tuned using batch MIRA (Cherry and Foster, 2012). We measured the overall translation quality with 4-gram BLEU (Papineni et al., 2002), which was computed on tokenized and lowercased data for all systems. Statistical significance is computed with the pairwise bootstrap resampling technique of Koehn (2004). 4.2 Results Table 2 displays the BLEU scores for our experiments. On science and news, small improvements are achieved while for medical a small decrease is observed. None of these differences is statistically significant. An analysis of the system outputs for each domain showed that the small improvements are due to the fact that in stri"
D15-1129,P10-1146,0,0.0163573,"ntax-based models either use linguistic annotation on the source language side (Huang, 2006; Liu et al., 2006), target language side (Galley et al., 2004; Galley et al., 2006) or are syntactic in a structural sense only (Chiang, 2005). Recent shared tasks have shown that systems integrating information on the target language side, also called string-to-tree systems, achieve the best performance on several language pairs (Bojar et al., 2014). At the same time, soft syntactic features significantly improve the translation quality of hierarchical systems (Hiero) as shown in (Marton et al., 2012; Chiang, 2010; Liu et al., 2011; Cui et al., 2010). Improving the performance of stringto-tree systems through the integration of soft syntactic constraints on the source language side is therefore an interesting task. So far, all approaches on this topic include soft syntactic constraints into the rules of string-to-tree (Zhang et al., 2011; Huck et al., 2014) or stringto-dependency (Huang et al., 2013) systems and define heuristics to determine to what extent these constituents match the syntactic structure of the source sentence. We propose a novel way to integrate soft syntactic constraints into a stri"
D15-1129,P11-2072,0,0.0134356,"f Vowpal Wabbit (VW).5 We avoid overfitting to training data by employing early stopping once classifier accuracy decreases on a heldout dataset.6 4 Experiments 4.1 Experimental Setup Our baseline system is a syntax-based system with linguistic annotation on the target language side (string-to-tree). We use the version implemented in the Moses open source toolkit (Hoang et al., 2009; Williams and Koehn, 2012) with standard parameters. Rule extraction is performed as in (Galley et al., 2004) with rule composition (Galley et al., 2006; DeNeefe et al., 2007). Non-lexical unary rules are removed (Chung et al., 2011) and scope-3 pruning (Hopkins and Langmead, 2010) is performed. Rule scoring is done using relative frequencies normalized over the source rhs and aligned non-terminals in the target rhs. The contrastive system is the same string-to-tree system but augmented with our rule selection model as a feature of the log-linear model. 4 Which is based on (Galley et al., 2004; Galley et al., 2006; DeNeefe et al., 2007). 5 Specifically, the label dependent version of Cost Sensitive One Against All which uses classification. 6 We use the development set which is also used for MIRA tuning. 1097 System Basel"
D15-1129,P06-1077,0,0.0494218,"side of a translation rule among rules with the same source side. We define a discriminative rule selection model for systems that have syntactic annotation on the target language side (stringto-tree). This is a new and clean way to integrate soft source syntactic constraints into string-to-tree systems as features of the rule selection model. We release our implementation as part of Moses. 1 Introduction Syntax-based machine translation is well known for its ability to handle non-local reordering. Syntax-based models either use linguistic annotation on the source language side (Huang, 2006; Liu et al., 2006), target language side (Galley et al., 2004; Galley et al., 2006) or are syntactic in a structural sense only (Chiang, 2005). Recent shared tasks have shown that systems integrating information on the target language side, also called string-to-tree systems, achieve the best performance on several language pairs (Bojar et al., 2014). At the same time, soft syntactic features significantly improve the translation quality of hierarchical systems (Hiero) as shown in (Marton et al., 2012; Chiang, 2010; Liu et al., 2011; Cui et al., 2010). Improving the performance of stringto-tree systems through"
D15-1129,D08-1010,0,0.0193018,"constraints into a string-totree system. We define a discriminative rule selection model for string-to-tree machine translation. We consider rule selection as a multi-class classification problem where the task is to select the correct target side of a rule given its source side as well as contextual information about the source sentence and the considered rule. So far, such models have been applied to systems without syntactic annotation on the target language side. He et al. (2008), He et al. (2010) and Cui et al. (2010) apply such rule selection models to hierarchical machine translation, Liu et al. (2008) to tree-to-string systems and Zhai et al. (2013) to systems based on predicate argument structures. When target side syntactic annotations are taken into account, the task of rule selection has to be reformulated (see Section 2) while the same type of model can be used in approaches without target annotations. This work is the first attempt to define a rule selection model for a string-to-tree system. We make our implementation publicly available as part of Moses.1 We show in Section 2 that string-to-tree rule selection is different from the hierarchical case addressed by previous work and de"
D15-1129,2011.mtsummit-papers.28,0,0.034716,"els either use linguistic annotation on the source language side (Huang, 2006; Liu et al., 2006), target language side (Galley et al., 2004; Galley et al., 2006) or are syntactic in a structural sense only (Chiang, 2005). Recent shared tasks have shown that systems integrating information on the target language side, also called string-to-tree systems, achieve the best performance on several language pairs (Bojar et al., 2014). At the same time, soft syntactic features significantly improve the translation quality of hierarchical systems (Hiero) as shown in (Marton et al., 2012; Chiang, 2010; Liu et al., 2011; Cui et al., 2010). Improving the performance of stringto-tree systems through the integration of soft syntactic constraints on the source language side is therefore an interesting task. So far, all approaches on this topic include soft syntactic constraints into the rules of string-to-tree (Zhang et al., 2011; Huck et al., 2014) or stringto-dependency (Huang et al., 2013) systems and define heuristics to determine to what extent these constituents match the syntactic structure of the source sentence. We propose a novel way to integrate soft syntactic constraints into a string-totree system."
D15-1129,P10-2002,0,0.23718,"guistic annotation on the source language side (Huang, 2006; Liu et al., 2006), target language side (Galley et al., 2004; Galley et al., 2006) or are syntactic in a structural sense only (Chiang, 2005). Recent shared tasks have shown that systems integrating information on the target language side, also called string-to-tree systems, achieve the best performance on several language pairs (Bojar et al., 2014). At the same time, soft syntactic features significantly improve the translation quality of hierarchical systems (Hiero) as shown in (Marton et al., 2012; Chiang, 2010; Liu et al., 2011; Cui et al., 2010). Improving the performance of stringto-tree systems through the integration of soft syntactic constraints on the source language side is therefore an interesting task. So far, all approaches on this topic include soft syntactic constraints into the rules of string-to-tree (Zhang et al., 2011; Huck et al., 2014) or stringto-dependency (Huang et al., 2013) systems and define heuristics to determine to what extent these constituents match the syntactic structure of the source sentence. We propose a novel way to integrate soft syntactic constraints into a string-totree system. We define a discrim"
D15-1129,D07-1079,0,0.0161739,"itive one-against-all-reduction (Beygelzimer et al., 2005) of Vowpal Wabbit (VW).5 We avoid overfitting to training data by employing early stopping once classifier accuracy decreases on a heldout dataset.6 4 Experiments 4.1 Experimental Setup Our baseline system is a syntax-based system with linguistic annotation on the target language side (string-to-tree). We use the version implemented in the Moses open source toolkit (Hoang et al., 2009; Williams and Koehn, 2012) with standard parameters. Rule extraction is performed as in (Galley et al., 2004) with rule composition (Galley et al., 2006; DeNeefe et al., 2007). Non-lexical unary rules are removed (Chung et al., 2011) and scope-3 pruning (Hopkins and Langmead, 2010) is performed. Rule scoring is done using relative frequencies normalized over the source rhs and aligned non-terminals in the target rhs. The contrastive system is the same string-to-tree system but augmented with our rule selection model as a feature of the log-linear model. 4 Which is based on (Galley et al., 2004; Galley et al., 2006; DeNeefe et al., 2007). 5 Specifically, the label dependent version of Cost Sensitive One Against All which uses classification. 6 We use the development"
D15-1129,P02-1040,0,0.0958523,"de (for feature extraction). We trained a 5-gram language model on the English side of each training corpus using the SRI Language Modeling Toolkit (Stolcke, 2002). We train the model in the standard way and generate word alignments using GIZA++. After training, we reduced the number of translation rules by only keeping the 30-best rules with the same source side according to the direct rule translation rule probability. Our rule selection model was trained with VW. All systems were tuned using batch MIRA (Cherry and Foster, 2012). We measured the overall translation quality with 4-gram BLEU (Papineni et al., 2002), which was computed on tokenized and lowercased data for all systems. Statistical significance is computed with the pairwise bootstrap resampling technique of Koehn (2004). 4.2 Results Table 2 displays the BLEU scores for our experiments. On science and news, small improvements are achieved while for medical a small decrease is observed. None of these differences is statistically significant. An analysis of the system outputs for each domain showed that the small improvements are due to the fact that in string-to-tree systems there is not enough ambiguity between competing rules during decodi"
D15-1129,N04-1035,0,0.335276,"ith the same source side. We define a discriminative rule selection model for systems that have syntactic annotation on the target language side (stringto-tree). This is a new and clean way to integrate soft source syntactic constraints into string-to-tree systems as features of the rule selection model. We release our implementation as part of Moses. 1 Introduction Syntax-based machine translation is well known for its ability to handle non-local reordering. Syntax-based models either use linguistic annotation on the source language side (Huang, 2006; Liu et al., 2006), target language side (Galley et al., 2004; Galley et al., 2006) or are syntactic in a structural sense only (Chiang, 2005). Recent shared tasks have shown that systems integrating information on the target language side, also called string-to-tree systems, achieve the best performance on several language pairs (Bojar et al., 2014). At the same time, soft syntactic features significantly improve the translation quality of hierarchical systems (Hiero) as shown in (Marton et al., 2012; Chiang, 2010; Liu et al., 2011; Cui et al., 2010). Improving the performance of stringto-tree systems through the integration of soft syntactic constrain"
D15-1129,P06-1055,0,0.150246,"omains: (1) news, (2) medical, and (3) science. The training data for news is taken from Europarl-v4. Development and test sets are from the news translation task of WMT 2009 (Callison-Burch et al., 2009). For medical we use the biomedical data from EMEA (Tiedemann, 2009). Since this is a parallel corpus only, we first removed duplicate sentences and then constructed development and test sets by randomly selecting sentence pairs. As training data for science we use the scientific abstracts data provided by Carpuat et al. (2013). Table 1 gives an overview of the corpora sizes. Berkeley parser (Petrov et al., 2006) is used to parse the English side of each parallel corpus (for string-to-tree rule extraction) as well as for parsing the French source side (for feature extraction). We trained a 5-gram language model on the English side of each training corpus using the SRI Language Modeling Toolkit (Stolcke, 2002). We train the model in the standard way and generate word alignments using GIZA++. After training, we reduced the number of translation rules by only keeping the 30-best rules with the same source side according to the direct rule translation rule probability. Our rule selection model was trained"
D15-1129,P06-1121,0,0.364243,"ide. We define a discriminative rule selection model for systems that have syntactic annotation on the target language side (stringto-tree). This is a new and clean way to integrate soft source syntactic constraints into string-to-tree systems as features of the rule selection model. We release our implementation as part of Moses. 1 Introduction Syntax-based machine translation is well known for its ability to handle non-local reordering. Syntax-based models either use linguistic annotation on the source language side (Huang, 2006; Liu et al., 2006), target language side (Galley et al., 2004; Galley et al., 2006) or are syntactic in a structural sense only (Chiang, 2005). Recent shared tasks have shown that systems integrating information on the target language side, also called string-to-tree systems, achieve the best performance on several language pairs (Bojar et al., 2014). At the same time, soft syntactic features significantly improve the translation quality of hierarchical systems (Hiero) as shown in (Marton et al., 2012; Chiang, 2010; Liu et al., 2011; Cui et al., 2010). Improving the performance of stringto-tree systems through the integration of soft syntactic constraints on the source langu"
D15-1129,C08-1041,0,0.0208798,"ent these constituents match the syntactic structure of the source sentence. We propose a novel way to integrate soft syntactic constraints into a string-totree system. We define a discriminative rule selection model for string-to-tree machine translation. We consider rule selection as a multi-class classification problem where the task is to select the correct target side of a rule given its source side as well as contextual information about the source sentence and the considered rule. So far, such models have been applied to systems without syntactic annotation on the target language side. He et al. (2008), He et al. (2010) and Cui et al. (2010) apply such rule selection models to hierarchical machine translation, Liu et al. (2008) to tree-to-string systems and Zhai et al. (2013) to systems based on predicate argument structures. When target side syntactic annotations are taken into account, the task of rule selection has to be reformulated (see Section 2) while the same type of model can be used in approaches without target annotations. This work is the first attempt to define a rule selection model for a string-to-tree system. We make our implementation publicly available as part of Moses.1 W"
D15-1129,D10-1054,0,0.0191569,"ents match the syntactic structure of the source sentence. We propose a novel way to integrate soft syntactic constraints into a string-totree system. We define a discriminative rule selection model for string-to-tree machine translation. We consider rule selection as a multi-class classification problem where the task is to select the correct target side of a rule given its source side as well as contextual information about the source sentence and the considered rule. So far, such models have been applied to systems without syntactic annotation on the target language side. He et al. (2008), He et al. (2010) and Cui et al. (2010) apply such rule selection models to hierarchical machine translation, Liu et al. (2008) to tree-to-string systems and Zhai et al. (2013) to systems based on predicate argument structures. When target side syntactic annotations are taken into account, the task of rule selection has to be reformulated (see Section 2) while the same type of model can be used in approaches without target annotations. This work is the first attempt to define a rule selection model for a string-to-tree system. We make our implementation publicly available as part of Moses.1 We show in Section"
D15-1129,W12-3150,0,0.106353,"part of Moses.1 We show in Section 2 that string-to-tree rule selection is different from the hierarchical case addressed by previous work and define our rule selection model. In Section 3 we present the training procedure before providing a proof-of-concept evaluation in Section 4. 2 2.1 Rule selection for string-to-tree SMT String-to-tree machine translation We present string-to-tree machine translation as implemented in Moses (which is the framework that we use). String-to-tree rules have the form X/A → hα, γ, ∼i. On the source language side, 1 We use the string-to-tree component of Moses (Williams and Koehn, 2012; Hoang et al., 2009) in which we integrate the high-speed classifier Vowpal Wabbit http://hunch. net/˜vw/. 1095 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1095–1101, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computational Linguistics. Ces cellules pr´esentent plusieurs caract´eristiques sp´ecifiques F (Diverses)X1 caract´eristiques (importantes)X2 n’ont pas e´ t´e prises en compte. (Various)X1 characteristics (important)X2 were not considered. several specific characteristics These cells present JJ DT NNS VBP NP JJ NNS NP"
D15-1129,P13-1111,0,0.0120621,"ine a discriminative rule selection model for string-to-tree machine translation. We consider rule selection as a multi-class classification problem where the task is to select the correct target side of a rule given its source side as well as contextual information about the source sentence and the considered rule. So far, such models have been applied to systems without syntactic annotation on the target language side. He et al. (2008), He et al. (2010) and Cui et al. (2010) apply such rule selection models to hierarchical machine translation, Liu et al. (2008) to tree-to-string systems and Zhai et al. (2013) to systems based on predicate argument structures. When target side syntactic annotations are taken into account, the task of rule selection has to be reformulated (see Section 2) while the same type of model can be used in approaches without target annotations. This work is the first attempt to define a rule selection model for a string-to-tree system. We make our implementation publicly available as part of Moses.1 We show in Section 2 that string-to-tree rule selection is different from the hierarchical case addressed by previous work and define our rule selection model. In Section 3 we pr"
D15-1129,D11-1019,0,0.0176334,"ge side, also called string-to-tree systems, achieve the best performance on several language pairs (Bojar et al., 2014). At the same time, soft syntactic features significantly improve the translation quality of hierarchical systems (Hiero) as shown in (Marton et al., 2012; Chiang, 2010; Liu et al., 2011; Cui et al., 2010). Improving the performance of stringto-tree systems through the integration of soft syntactic constraints on the source language side is therefore an interesting task. So far, all approaches on this topic include soft syntactic constraints into the rules of string-to-tree (Zhang et al., 2011; Huck et al., 2014) or stringto-dependency (Huang et al., 2013) systems and define heuristics to determine to what extent these constituents match the syntactic structure of the source sentence. We propose a novel way to integrate soft syntactic constraints into a string-totree system. We define a discriminative rule selection model for string-to-tree machine translation. We consider rule selection as a multi-class classification problem where the task is to select the correct target side of a rule given its source side as well as contextual information about the source sentence and the consi"
D15-1129,W09-0401,0,\N,Missing
D15-1129,J07-2003,0,\N,Missing
D15-1272,C10-3009,0,0.0148955,"Missing"
D15-1272,P14-5010,0,0.00199005,"Missing"
D15-1272,chrupala-etal-2008-learning,0,0.0925021,"Missing"
D15-1272,J93-2004,0,0.0488165,"G models not using morphology (+dict) (×) or both (+ ×) are marked. More baseline numbers in the appendix (Table A2). including OOVs, and only requires the same training corpus as a generic tagger (containing tags and lemmata), a resource that is available for many languages. 5 Experiments Datasets. We present experiments on the joint task of lemmatization and tagging in six diverse languages: English, German, Czech, Hungarian, Latin and Spanish. We use the same data sets as in M¨uller and Sch¨utze (2015), but do not use the out-of-domain test sets. The English data is from the Penn Treebank (Marcus et al., 1993), Latin from PROIEL (Haug and Jøhndal, 2008), German and Hungarian from SPMRL 2013 (Seddah et al., 2013), and Spanish and Czech from CoNLL 2009 (Hajiˇc et al., 2009). For German, Hungarian, Spanish and Czech we use the splits from the shared tasks; for English the split from SANCL (Petrov and McDonald, 2012); and for Latin a 8/1/1 split into train/dev/test. For all languages we limit our training data to the first 100,000 tokens. Dataset statistics can be found in Table A4 of the appendix. The lemma of Spanish se is set to be consistent. Baselines. We compare our model to three baselines. (i)"
D15-1272,N15-1055,1,0.894932,"Missing"
D15-1272,W02-1001,0,0.0542005,"g/gnu/aspell/dict Example: for the Spanish noun medidas “measures” with attributes N OUN, C OMMON, P LURAL and F EMININE, we conjoin each feature above with N OUN, N OUN +C OMMON, N OUN +P LURAL and N OUN +F EMININE. 4 candidates by extracting edit operation sequences between lemmata and surface forms (Chrupała, 2006), and then trains two maximum entropy Markov models (Ratnaparkhi, 1996) for morphological tagging and lemmatization, which are queried using a beam search decoder. In our experiments we use the latest version5 of M ORFETTE. This version is based on structured perceptron learning (Collins, 2002) and edit trees (Chrupała, 2008). Models similar to M ORFETTE include those of Bj¨orkelund et al. (2010) and Gesmundo and Samardzic (2012) and have also been used for generation (Duˇsek and Jurˇc´ıcˇ ek, 2013). Wicentowski (2002) similarly treats lemmatization as classification over a deterministically chosen candidate set, but uses distributional information extracted from large corpora as a key source of information. Toutanova and Cherry (2009)’s joint morphological analyzer predicts the set of possible lemmata and coarse-grained POS for a word type. This is different from our problem of lem"
D15-1272,D13-1032,1,0.912146,"Missing"
D15-1272,P14-2102,1,0.754648,"Missing"
D15-1272,D08-1113,0,0.0505869,"Missing"
D15-1272,P13-3023,0,0.0421399,"Missing"
D15-1272,E12-1068,1,0.283993,"isambiguate the lemma of a form, which explains why many NLP systems (Manning et al., 2014; Padr´o and Stanilovsky, 2012) apply a pipeline approach of tagging followed by lemmatization. Conversely, knowing the lemma of a form is often beneficial for tagging, for instance in the presence of syncretism; e.g., since German plural noun phrases do not mark gender, it is important to know the lemma (singular form) to correctly tag gender on the noun. Introduction Lemmatization is important for many NLP tasks, including parsing (Bj¨orkelund et al., 2010; Seddah et al., 2010) and machine translation (Fraser et al., 2012). Lemmata are required whenever we want to map words to lexical resources and establish the relation between inflected forms, particularly critical for morphologically rich languages to address the sparsity of unlemmatized forms. This strongly motivates work on language-independent tokenbased lemmatization, but until now there has been little work (Chrupała et al., 2008). Many regular transformations can be described by simple replacement rules, but lemmatization of unknown words requires more than this. For instance the Spanish paradigms for verbs ending in ir and er share the same 3rd person"
D15-1272,P12-2072,0,0.0321468,"e conjoin each feature above with N OUN, N OUN +C OMMON, N OUN +P LURAL and N OUN +F EMININE. 4 candidates by extracting edit operation sequences between lemmata and surface forms (Chrupała, 2006), and then trains two maximum entropy Markov models (Ratnaparkhi, 1996) for morphological tagging and lemmatization, which are queried using a beam search decoder. In our experiments we use the latest version5 of M ORFETTE. This version is based on structured perceptron learning (Collins, 2002) and edit trees (Chrupała, 2008). Models similar to M ORFETTE include those of Bj¨orkelund et al. (2010) and Gesmundo and Samardzic (2012) and have also been used for generation (Duˇsek and Jurˇc´ıcˇ ek, 2013). Wicentowski (2002) similarly treats lemmatization as classification over a deterministically chosen candidate set, but uses distributional information extracted from large corpora as a key source of information. Toutanova and Cherry (2009)’s joint morphological analyzer predicts the set of possible lemmata and coarse-grained POS for a word type. This is different from our problem of lemmatization and fine-grained morphological tagging of tokens in context. Despite the superficial similarity of the two problems, direct com"
D15-1272,padro-stanilovsky-2012-freeling,0,0.0187324,"Missing"
D15-1272,W96-0213,0,0.203493,"e results of the joint model by initializing it with the parameters of a pretrained tagging model. 4 Related Work In functionality, our system resembles M ORFETTE (Chrupała et al., 2008), which generates lemma 3 ftp://ftp.gnu.org/gnu/aspell/dict Example: for the Spanish noun medidas “measures” with attributes N OUN, C OMMON, P LURAL and F EMININE, we conjoin each feature above with N OUN, N OUN +C OMMON, N OUN +P LURAL and N OUN +F EMININE. 4 candidates by extracting edit operation sequences between lemmata and surface forms (Chrupała, 2006), and then trains two maximum entropy Markov models (Ratnaparkhi, 1996) for morphological tagging and lemmatization, which are queried using a beam search decoder. In our experiments we use the latest version5 of M ORFETTE. This version is based on structured perceptron learning (Collins, 2002) and edit trees (Chrupała, 2008). Models similar to M ORFETTE include those of Bj¨orkelund et al. (2010) and Gesmundo and Samardzic (2012) and have also been used for generation (Duˇsek and Jurˇc´ıcˇ ek, 2013). Wicentowski (2002) similarly treats lemmatization as classification over a deterministically chosen candidate set, but uses distributional information extracted from"
D15-1272,W10-1410,0,0.0704151,"Missing"
D15-1272,P08-1103,0,0.0390074,"int morphological analyzer predicts the set of possible lemmata and coarse-grained POS for a word type. This is different from our problem of lemmatization and fine-grained morphological tagging of tokens in context. Despite the superficial similarity of the two problems, direct comparison is not possible. TC’s model is best thought of as inducing a tagging dictionary for OOV types, mapping them to a set of tag and lemma pairs, whereas L EM MING is a token-level, context-based morphological tagger. We do, however, use TC’s model of lemmatization, a string-to-string transduction model based on Jiampojamarn et al. (2008) (JCK), as a standalone baseline. Our tagging-in-context model is faced with higher complexity of learning and inference since it addresses a more difficult task; thus, while we could in principle use JCK as a replacement for our candidate selection, the edit tree approach – which has high coverage at a low average number of lemma candidates (cf. Section 5) – allows us to train and apply L EMMING efficiently. Smith et al. (2005) proposed a log-linear model for the context-based disambiguation of a morphological dictionary. This has the effect of joint tagging, morphological segmentation and le"
D15-1272,H05-1060,0,0.0361191,"L EM MING is a token-level, context-based morphological tagger. We do, however, use TC’s model of lemmatization, a string-to-string transduction model based on Jiampojamarn et al. (2008) (JCK), as a standalone baseline. Our tagging-in-context model is faced with higher complexity of learning and inference since it addresses a more difficult task; thus, while we could in principle use JCK as a replacement for our candidate selection, the edit tree approach – which has high coverage at a low average number of lemma candidates (cf. Section 5) – allows us to train and apply L EMMING efficiently. Smith et al. (2005) proposed a log-linear model for the context-based disambiguation of a morphological dictionary. This has the effect of joint tagging, morphological segmentation and lemmatization, but, critically, is limited to the entries in the morphological dictionary (without which the approach cannot be used), causing problems of recall. In contrast, L EMMING can analyze any word, 5 https://github.com/ gchrupala/morfette/commit/ ca886556916b6cc1e808db4d32daf720664d17d6 2270 cs 5 6 7 JCK L EMMING -P 4 9 10 11 12 13 L EMMING -J 8 tag+lemma +mrph +dict 3 lemma +dict 2 M AR M OT tag lemma tag+lemma lemma tag"
D15-1272,P09-1055,0,0.102223,"e been used in different previous models. All features are extracted given a form-lemma pair hw, li created with an edit tree e. We use the following three edit tree features of Chrupała (2008). (i) The edit tree e. (ii) The pair he, wi. This feature is crucial for the model to memorize irregular forms, e.g., the lemma of was is be. (iii) For each form affix (of maximum length 10): its conjunction with e. These features are useful in learning orthographic and phonological regularities, e.g., the lemma of signalling is signal, not signall. We define the following alignment features. Similar to Toutanova and Cherry (2009) (TC), we define an alignment between w and l. Our alignments can be read from an edit tree by aligning the characters in LCS nodes character by character and characters in substitution nodes block-wise. Thus the alignment of umgeschaut - umschauen is: u-u, m-m, ge-, s-s, c-c, h-h, a-a, u-u, t-en. Each alignment pair constitutes a feature in our model. These features allow the model to learn that the substitution t/en is likely in German. We also concatenate each alignment pair with its form and lemma character context (of up to length 6) to learn, e.g., that ge is often deleted after um. We"
D15-1272,P09-1054,0,0.0122241,"apitalization, digits, hyphens) and the immediate lexical context. We combine lemmatization and higher-order CRF components in a treestructured CRF. Given a sequence of forms w with lemmata l and morphological+POS tags m, we define a globally normalized model: Q T p(l, m |w) ∝ i hwi (li ) exp(f (li , wi , mi ) θ +g(mi , mi−1 , mi−2 , w, i)T λ), where f and g are the features associated with lemma and tag cliques respectively and θ and λ are weight vectors. The graphical model is shown in Figure 2. We perform inference with belief propagation (Pearl, 1988) and estimate the parameters with SGD (Tsuruoka et al., 2009). We greatly improved the results of the joint model by initializing it with the parameters of a pretrained tagging model. 4 Related Work In functionality, our system resembles M ORFETTE (Chrupała et al., 2008), which generates lemma 3 ftp://ftp.gnu.org/gnu/aspell/dict Example: for the Spanish noun medidas “measures” with attributes N OUN, C OMMON, P LURAL and F EMININE, we conjoin each feature above with N OUN, N OUN +C OMMON, N OUN +P LURAL and N OUN +F EMININE. 4 candidates by extracting edit operation sequences between lemmata and surface forms (Chrupała, 2006), and then trains two maximum"
D15-1272,C00-2137,0,0.0183128,"xperiments showed that correct morphological attributes would substantially improve lemmatization as they help in cases of ambiguity. As an example, number helps to lemmatize the singular German noun Raps “canola”, which looks like the plural of Rap “rap”. Numbers can be found in Table A3 of the appendix. This motivates the necessity of joint tagging and lemmatization. For the final experiments, we run pipeline models on tags predicted by M AR M OT (M¨uller et al., 2013) and compare them to L EMMING -J, the 7 8 Unknown word accuracies in the appendix (Table A1). We use the randomization test (Yeh, 2000) and p = .05. joint model described in Section 3. All L EMMING versions use exactly the same features. Table 2 shows that L EMMING -J outperforms L EMMING P in three measures (see bold tag, lemma & joint (tag+lemma) accuracies) except for English, where we observe a tie in lemma accuracy and a small drop in tag and tag+lemma accuracy. Coupling morphological attributes and lemmatization (lines 8–10 vs 11–13) improves tag+lemma prediction for five languages. Improvements in lemma accuracy of the joint over the best pipeline systems range from .1 (Spanish), over >.3 (German, Hungarian) to ≥.96 (C"
E09-1033,J07-4002,1,0.885864,"Missing"
E09-1033,J93-2003,0,0.0126508,"Missing"
E09-1033,D08-1092,0,0.0565955,"al and Chatterjee (2006). Our work differs from theirs in that we are performing a parse reranking task in English using knowledge gained from German parses, and parsing accuracy is generally thought to be worse in German than in English. Hopkins and Kuhn (2006) conducted research with goals similar to ours. They showed how to build a powerful generative model which flexibly incorporates features from parallel text in four languages, but were not able to show an improvement in parsing performance. After the submission of our paper for review, two papers outlining relevant work were published. Burkett and Klein (2008) describe a system for simultaneously improving Chinese and English parses of a Chinese/English bitext. This work is complementary to ours. The system is trained using gold standard trees in both Chinese and English, in contrast with our system which only has access to gold standard trees in English. Their system uses a tree alignment which varies within training, but this does not appear to make a large difference in performance. They use coarsely defined features which are language independent. We use several features similar to their two best performing sets of features, but in contrast wit"
E09-1033,P05-1022,0,0.107013,"e translated from English to German by a graduate student and an additional 3218 sen287 1 2 3 System Baseline Contrastive (5 trials/fold) Contrastive (greedy selection) Train 87.89 88.70 +base +base 0.82 Test 87.89 88.45 0.56 greedy feature selection helps with this (see also section 7). 88.82 0.93 88.55 0.66 6 Previous Work As we mentioned in section 2, work on parse reranking is relevant, but a vital difference is that we use features based only on syntactic projection of the two languages in a bitext. For an overview of different types of features that have been used in parse reranking see Charniak and Johnson (2005). Like Collins (2000) we use cross-validation to train our model, but we have access to much less data (3718 sentences total, which is less than 1/10 of the data Collins used). We use rich feature functions which were designed by hand to specifically address problems in English parses which can be disambiguated using the German translation. Syntactic projection has been used to bootstrap treebanks in resource poor languages. Some examples of projection of syntactic parses from English to a resource poor language for which no parser is available are the works of Yarowsky and Ngai (2001), Hwa et"
E09-1033,W98-1115,0,0.0270442,"glish sentences (and an additional 1000 reserved sentences) when we trained BitPar on the Penn treebank. Parses. We use the BitPar parser (Schmid, 2004) which is based on a bit-vector implementation (cf. (Graham et al., 1980)) of the Cocke-Younger-Kasami algorithm (Kasami, 1965; Younger, 1967). It computes a compact parse forest for all possible analyses. As all possible analyses are computed, any number of best parses can be extracted. In contrast, other treebank parsers use sophisticated search strategies to find the most probable analysis without examining the set of all possible analyses (Charniak et al., 1998; Klein and Manning, 2003). BitPar is particularly useful for N-best parsing as the N-best parses can be computed efficiently. For the 3718 sentences in the translated set, we created 100-best English parses and 1-best German parses. The German parser was trained on the TIGER treebank. For the Europarl corpus, we created 1-best parses for both languages. Word Alignment. We use a word alignment of the translated sentences from the Penn treebank, as well as a word alignment of the Europarl corpus. We align these two data sets together with data from the JRC Acquis (Steinberger et al., 2006) to t"
E09-1033,W06-1608,0,0.056453,"n style is different, e.g., NP structure in German is flatter. Introduction Parallel text or bitext is an important knowledge source for solving many problems such as machine translation, cross-language information retrieval, and the projection of linguistic resources from one language to another. In this paper, we show that bitext-based features are effective in addressing another NLP problem, increasing the accuracy of statistical parsing. We pursue this approach for a number of reasons. First, one limiting factor for syntactic approaches to statistical machine translation is parse quality (Quirk and Corston-Oliver, 2006). Improved parses of bitext should result in improved machine translation. Second, as more and more texts are available in several languages, it will be increasingly the case that a text to be parsed is itself part of a bitext. Third, we hope that the improved parses of bitext will serve as higher quality training data for improving monolingual parsing using a process similar to self-training (McClosky et al., 2006). It is well known that different languages encode different types of grammatical information (agreement, case, tense etc.) and that what can be left unspecified in one language mus"
E09-1033,2008.amta-srw.2,0,0.716401,"nguages. Word Alignment. We use a word alignment of the translated sentences from the Penn treebank, as well as a word alignment of the Europarl corpus. We align these two data sets together with data from the JRC Acquis (Steinberger et al., 2006) to try to obtain better quality alignments (it is well known that alignment quality improves as the amount of data increases (Fraser and Marcu, 2007)). We aligned approximately 3.08 million sentence pairs. We tried to obtain better alignment quality as alignment quality is a problem in many cases where syntactic projection would otherwise work well (Fossum and Knight, 2008). Data and Experiments We used the subset of the Wall Street Journal investigated in (Atterer and Schu¨ tze, 2007) for our experiments, which consists of all sentences that have at least one prepositional phrase attachment ambiguity. This difficult subset of sentences seems particularly interesting when investigating the potential of information in bitext for improving parsing performance. The first 500 sentences of this set were translated from English to German by a graduate student and an additional 3218 sen287 1 2 3 System Baseline Contrastive (5 trials/fold) Contrastive (greedy selection)"
E09-1033,J07-3002,1,0.821458,"tly. For the 3718 sentences in the translated set, we created 100-best English parses and 1-best German parses. The German parser was trained on the TIGER treebank. For the Europarl corpus, we created 1-best parses for both languages. Word Alignment. We use a word alignment of the translated sentences from the Penn treebank, as well as a word alignment of the Europarl corpus. We align these two data sets together with data from the JRC Acquis (Steinberger et al., 2006) to try to obtain better quality alignments (it is well known that alignment quality improves as the amount of data increases (Fraser and Marcu, 2007)). We aligned approximately 3.08 million sentence pairs. We tried to obtain better alignment quality as alignment quality is a problem in many cases where syntactic projection would otherwise work well (Fossum and Knight, 2008). Data and Experiments We used the subset of the Wall Street Journal investigated in (Atterer and Schu¨ tze, 2007) for our experiments, which consists of all sentences that have at least one prepositional phrase attachment ambiguity. This difficult subset of sentences seems particularly interesting when investigating the potential of information in bitext for improving p"
E09-1033,P02-1035,0,0.028046,"hown in figures 1 and 2, respectively, and that the semantically more plausible second parse in figure 2 is correct. How can we determine that the second parse should be favored? Since we are parsing bitext, we can observe the German translation which is “Er sah ein Baby und eine Frau, die graue Haare hatte” (glossed: “he saw a baby and a woman, who gray hair had”). The singular verb in the subordinate clause (“hatte”: “had”) indicates that the subordinate S must be attached low to “woman” (“Frau”) as shown in figure 3. We follow Collins’ (2000) approach to discriminative reranking (see also (Riezler et al., 2002)). Given a new sentence to parse, we first select the best N parse trees according to a generative model. Then we use new features to learn discriminatively how to rerank the parses in this N-best list. We use features derived using projections of the 1-best German parse onto the hypothesized English parse under consideration. In more detail, we take the 100 best English parses from the BitPar parser (Schmid, 2004) and rerank them. We have a good chance of finding the optimal parse among the 100-best1 . An automatically generated word alignment determines translational correspondence between G"
E09-1033,C04-1024,0,0.533724,"d”) indicates that the subordinate S must be attached low to “woman” (“Frau”) as shown in figure 3. We follow Collins’ (2000) approach to discriminative reranking (see also (Riezler et al., 2002)). Given a new sentence to parse, we first select the best N parse trees according to a generative model. Then we use new features to learn discriminatively how to rerank the parses in this N-best list. We use features derived using projections of the 1-best German parse onto the hypothesized English parse under consideration. In more detail, we take the 100 best English parses from the BitPar parser (Schmid, 2004) and rerank them. We have a good chance of finding the optimal parse among the 100-best1 . An automatically generated word alignment determines translational correspondence between German and English. We use features which measure syntactic di3 Model We use a log-linear model to choose the best English parse. The feature functions are functions on the hypothesized English parse e, the German parse g, and the word alignment a, and they assign a score (varying between 0 and infinity) that measures syntactic divergence. The alignment of a sentence pair is a function that, for each English word, r"
E09-1033,P06-2039,0,0.0167168,"2000) we use cross-validation to train our model, but we have access to much less data (3718 sentences total, which is less than 1/10 of the data Collins used). We use rich feature functions which were designed by hand to specifically address problems in English parses which can be disambiguated using the German translation. Syntactic projection has been used to bootstrap treebanks in resource poor languages. Some examples of projection of syntactic parses from English to a resource poor language for which no parser is available are the works of Yarowsky and Ngai (2001), Hwa et al. (2005) and Goyal and Chatterjee (2006). Our work differs from theirs in that we are performing a parse reranking task in English using knowledge gained from German parses, and parsing accuracy is generally thought to be worse in German than in English. Hopkins and Kuhn (2006) conducted research with goals similar to ours. They showed how to build a powerful generative model which flexibly incorporates features from parallel text in four languages, but were not able to show an improvement in parsing performance. After the submission of our paper for review, two papers outlining relevant work were published. Burkett and Klein (2008)"
E09-1033,steinberger-etal-2006-jrc,0,0.0309533,"nalyses (Charniak et al., 1998; Klein and Manning, 2003). BitPar is particularly useful for N-best parsing as the N-best parses can be computed efficiently. For the 3718 sentences in the translated set, we created 100-best English parses and 1-best German parses. The German parser was trained on the TIGER treebank. For the Europarl corpus, we created 1-best parses for both languages. Word Alignment. We use a word alignment of the translated sentences from the Penn treebank, as well as a word alignment of the Europarl corpus. We align these two data sets together with data from the JRC Acquis (Steinberger et al., 2006) to try to obtain better quality alignments (it is well known that alignment quality improves as the amount of data increases (Fraser and Marcu, 2007)). We aligned approximately 3.08 million sentence pairs. We tried to obtain better alignment quality as alignment quality is a problem in many cases where syntactic projection would otherwise work well (Fossum and Knight, 2008). Data and Experiments We used the subset of the Wall Street Journal investigated in (Atterer and Schu¨ tze, 2007) for our experiments, which consists of all sentences that have at least one prepositional phrase attachment"
E09-1033,N01-1026,0,0.0753461,"see Charniak and Johnson (2005). Like Collins (2000) we use cross-validation to train our model, but we have access to much less data (3718 sentences total, which is less than 1/10 of the data Collins used). We use rich feature functions which were designed by hand to specifically address problems in English parses which can be disambiguated using the German translation. Syntactic projection has been used to bootstrap treebanks in resource poor languages. Some examples of projection of syntactic parses from English to a resource poor language for which no parser is available are the works of Yarowsky and Ngai (2001), Hwa et al. (2005) and Goyal and Chatterjee (2006). Our work differs from theirs in that we are performing a parse reranking task in English using knowledge gained from German parses, and parsing accuracy is generally thought to be worse in German than in English. Hopkins and Kuhn (2006) conducted research with goals similar to ours. They showed how to build a powerful generative model which flexibly incorporates features from parallel text in four languages, but were not able to show an improvement in parsing performance. After the submission of our paper for review, two papers outlining rel"
E09-1033,W06-2002,0,0.0277199,"problems in English parses which can be disambiguated using the German translation. Syntactic projection has been used to bootstrap treebanks in resource poor languages. Some examples of projection of syntactic parses from English to a resource poor language for which no parser is available are the works of Yarowsky and Ngai (2001), Hwa et al. (2005) and Goyal and Chatterjee (2006). Our work differs from theirs in that we are performing a parse reranking task in English using knowledge gained from German parses, and parsing accuracy is generally thought to be worse in German than in English. Hopkins and Kuhn (2006) conducted research with goals similar to ours. They showed how to build a powerful generative model which flexibly incorporates features from parallel text in four languages, but were not able to show an improvement in parsing performance. After the submission of our paper for review, two papers outlining relevant work were published. Burkett and Klein (2008) describe a system for simultaneously improving Chinese and English parses of a Chinese/English bitext. This work is complementary to ours. The system is trained using gold standard trees in both Chinese and English, in contrast with our"
E09-1033,N03-1016,0,0.0113093,"additional 1000 reserved sentences) when we trained BitPar on the Penn treebank. Parses. We use the BitPar parser (Schmid, 2004) which is based on a bit-vector implementation (cf. (Graham et al., 1980)) of the Cocke-Younger-Kasami algorithm (Kasami, 1965; Younger, 1967). It computes a compact parse forest for all possible analyses. As all possible analyses are computed, any number of best parses can be extracted. In contrast, other treebank parsers use sophisticated search strategies to find the most probable analysis without examining the set of all possible analyses (Charniak et al., 1998; Klein and Manning, 2003). BitPar is particularly useful for N-best parsing as the N-best parses can be computed efficiently. For the 3718 sentences in the translated set, we created 100-best English parses and 1-best German parses. The German parser was trained on the TIGER treebank. For the Europarl corpus, we created 1-best parses for both languages. Word Alignment. We use a word alignment of the translated sentences from the Penn treebank, as well as a word alignment of the Europarl corpus. We align these two data sets together with data from the JRC Acquis (Steinberger et al., 2006) to try to obtain better qualit"
E09-1033,N03-1017,0,0.00391606,"erforming sets of features, but in contrast with their work, we also define features which are specifically aimed at English disambiguation problems that we have observed can be resolved Table 1: Average F1 of 7-way cross-validation To generate the alignments, we used Model 4 (Brown et al., 1993), as implemented in GIZA++ (Och and Ney, 2003). As is standard practice, we trained Model 4 with English as the source language, and then trained Model 4 with German as the source language, resulting in two Viterbi alignments. These were combined using the Grow Diag Final And symmetrization heuristic (Koehn et al., 2003). Experiments. We perform 7-way crossvalidation on 3718 sentences. In each fold of the cross-validation, the training set is 3186 sentences, while the test set is 532 sentences. Our results are shown in table 1. In row 1, we take the hypothesis ranked best by BitPar. In row 2, we train using the algorithm outlined in section 4. To cancel out any effect caused by a particularly effective or ineffective starting λ value, we perform 5 trials each time. Columns 3 and 5 report the improvement over the baseline on train and test respectively. We reach an improvement of 0.56 over the baseline using t"
E09-1033,2005.mtsummit-papers.11,0,0.0213247,"ure value is calculated in eq. 10. where constituents starting with “DT NN”, e.g., (NP (DT NN NN NN)), are incorrectly split into two NPs, e.g., (NP (DT NN)) and (NP (NN NN)). This feature fires in this case, and projects the (NP (DT NN)) into German. If the German projection is a surprisingly large number of words (as should be the case if the German also consists of a determiner followed by several nouns) then the penalty paid by this feature is large. This feature is important as (NP (DT NN)) is a very common construction. q(i, j) = p(tag(up(i))|tag(j), tag(up(j))) l X i=1 We use Europarl (Koehn, 2005), from which we extract a parallel corpus of approximately 1.22 million sentence pairs, to estimate the probabilistic feature functions described in this section. For the PDepth feature, we estimate English parse depth probability conditioned on German parse depth from Europarl by calculating a simple probability distribution over the 1-best parse pairs for each parallel sentence. A very deep German parse is unlikely to correspond to a flat English parse and we can penalize such a parse using PDepth. The index i refers to a sentence pair in Europarl, as does j. Let li and mi be the depths of t"
E09-1033,J93-2004,0,0.0335382,"Missing"
E09-1033,N06-1020,0,0.053054,"tistical parsing. We pursue this approach for a number of reasons. First, one limiting factor for syntactic approaches to statistical machine translation is parse quality (Quirk and Corston-Oliver, 2006). Improved parses of bitext should result in improved machine translation. Second, as more and more texts are available in several languages, it will be increasingly the case that a text to be parsed is itself part of a bitext. Third, we hope that the improved parses of bitext will serve as higher quality training data for improving monolingual parsing using a process similar to self-training (McClosky et al., 2006). It is well known that different languages encode different types of grammatical information (agreement, case, tense etc.) and that what can be left unspecified in one language must be made explicit We conduct our research in the framework of N-best parse reranking, but apply it to bitext and add only features based on syntactic projection from German to English. We test the idea that, generally, English parses with more isomorphism with respect to the projected German parse are better. The system takes as input (i) English sentences with a list of automatically generated syntactic parses, (i"
E09-1033,J03-1002,0,0.00441457,"ndard trees in English. Their system uses a tree alignment which varies within training, but this does not appear to make a large difference in performance. They use coarsely defined features which are language independent. We use several features similar to their two best performing sets of features, but in contrast with their work, we also define features which are specifically aimed at English disambiguation problems that we have observed can be resolved Table 1: Average F1 of 7-way cross-validation To generate the alignments, we used Model 4 (Brown et al., 1993), as implemented in GIZA++ (Och and Ney, 2003). As is standard practice, we trained Model 4 with English as the source language, and then trained Model 4 with German as the source language, resulting in two Viterbi alignments. These were combined using the Grow Diag Final And symmetrization heuristic (Koehn et al., 2003). Experiments. We perform 7-way crossvalidation on 3718 sentences. In each fold of the cross-validation, the training set is 3186 sentences, while the test set is 532 sentences. Our results are shown in table 1. In row 1, we take the hypothesis ranked best by BitPar. In row 2, we train using the algorithm outlined in secti"
E09-1033,P03-1021,0,0.00834679,"to the DTNN feature function but trying to counteract a bias towards (NP (NP) (PP)) units (v) A feature function which penalizes aligning clausal units to non-clausal units (vi) The BitPar rank 4 Training Log-linear models are often trained using the Maximum Entropy criterion, but we train our model directly to maximize F1 . We score F1 by comparing hypothesized parses for the discriminative training set with the gold standard. To try to find the optimal λ vector, we perform direct accuracy maximization, meaning that we search for the λ vector which directly optimizes F1 on the training set. Och (2003) has described an efficient exact onedimensional accuracy maximization technique for a similar search problem in machine translation. The technique involves calculating an explicit representation of the piecewise constant function gm (x) which evaluates the accuracy of the hypotheses which would be picked by eq. 2 from a set of hypotheses if we hold all weights constant, except for the weight λm , which is set to x. This is calculated in one pass over the data. The algorithm for training is initialized with a choice for λ and is described in figure 4. The function F1 (λ) returns F1 of the pars"
E12-1068,P08-1087,0,0.108597,"which is a useful approach for dealing with issues of word-formation. However, this does not deal directly with linguistic features marked by inflection. In German these linguistic features are marked very irregularly and there is widespread syncretism, making it difficult to split off morphemes specifying these features. So it is questionable as to whether morpheme segmentation techniques are sufficient to solve the inflectional problem we are addressing. Much previous work looks at the impact of using source side information (i.e., feature functions on the aligned English), such as those of Avramidis and Koehn (2008), Yeniterzi and Oflazer (2010) and others. Toutanova et. al.’s work showed that it is most important to model target side coherence and our stem markup also allows us to access source side information. Using additional source side information beyond the markup did not produce a gain in performance. For compound splitting, we follow Fritzinger and Fraser (2010), using linguistic knowledge encoded in a rule-based morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies. Other approaches use less deep linguistic resources (e.g., POS-tags Sty"
E12-1068,P08-2039,0,0.0493127,"problematic as this requires the use of morphologically-aware syntactic parsers to annotate the training data with such features, and additionally depends on the coverage of morphological analysis and generation. Despite this, our research clearly shows that the feature-based approach is superior for English-to-German SMT. This is a striking result considering state-of-theart performance of German parsing is poor compared with the best performance on English parsing. As parsing performance improves, the performance of linguistic-feature-based approaches will increase. Virpioja et al. (2007), Badr et al. (2008), Luong et al. (2010), Clifton and Sarkar (2011), and others are primarily concerned with using morpheme segmentation in SMT, which is a useful approach for dealing with issues of word-formation. However, this does not deal directly with linguistic features marked by inflection. In German these linguistic features are marked very irregularly and there is widespread syncretism, making it difficult to split off morphemes specifying these features. So it is questionable as to whether morpheme segmentation techniques are sufficient to solve the inflectional problem we are addressing. Much previous"
E12-1068,W10-1705,0,0.154895,"cessing and resynthesize in postprocessing” approach to these phenomena, combined with inflection prediction that is similar to that of Toutanova et. al. The only work that we are aware of which deals with both issues is the work of de Gispert and Mari˜no (2008), which deals with verbal morphology and attached pronouns. There has been other work on solving inflection. Koehn and Hoang (2007) introduced factored SMT. We use more complex context features. Fraser (2009) tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms. Bojar and Kos (2010) improved on this by marking prepositions with the case they mark (one of the most important markups in our system). Both efforts were ineffective on large data sets. Williams and Koehn (2011) used unification in an SMT system to model some of the 671 agreement phenomena that we model. Our CRF framework allows us to use more complex context features. We have directly addressed the question as to whether inflection should be predicted using surface forms as the target of the prediction, or whether linguistic features should be predicted, along with the use of a subsequent generation step. The d"
E12-1068,P11-1004,0,0.0914439,"morphologically-aware syntactic parsers to annotate the training data with such features, and additionally depends on the coverage of morphological analysis and generation. Despite this, our research clearly shows that the feature-based approach is superior for English-to-German SMT. This is a striking result considering state-of-theart performance of German parsing is poor compared with the best performance on English parsing. As parsing performance improves, the performance of linguistic-feature-based approaches will increase. Virpioja et al. (2007), Badr et al. (2008), Luong et al. (2010), Clifton and Sarkar (2011), and others are primarily concerned with using morpheme segmentation in SMT, which is a useful approach for dealing with issues of word-formation. However, this does not deal directly with linguistic features marked by inflection. In German these linguistic features are marked very irregularly and there is widespread syncretism, making it difficult to split off morphemes specifying these features. So it is questionable as to whether morpheme segmentation techniques are sufficient to solve the inflectional problem we are addressing. Much previous work looks at the impact of using source side i"
E12-1068,W09-0420,1,0.874006,"zation. We view this issue as a different sort of problem entirely, one of word-formation (rather than inflection). We apply a “split in preprocessing and resynthesize in postprocessing” approach to these phenomena, combined with inflection prediction that is similar to that of Toutanova et. al. The only work that we are aware of which deals with both issues is the work of de Gispert and Mari˜no (2008), which deals with verbal morphology and attached pronouns. There has been other work on solving inflection. Koehn and Hoang (2007) introduced factored SMT. We use more complex context features. Fraser (2009) tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms. Bojar and Kos (2010) improved on this by marking prepositions with the case they mark (one of the most important markups in our system). Both efforts were ineffective on large data sets. Williams and Koehn (2011) used unification in an SMT system to model some of the 671 agreement phenomena that we model. Our CRF framework allows us to use more complex context features. We have directly addressed the question as to whether inflection should be predicted using surfac"
E12-1068,W10-1734,1,0.864458,"productive in German and lead to data sparsity. We split the German compounds in the training data, so that our stem translation system can now work with the individual words in the compounds. After we have translated to a split/stemmed representation, we determine whether to merge words together to form a compound. Then we merge them to create stems in the same representation as before and we perform inflection and portmanteau merging exactly as previously discussed. 8.1 Details of Splitting Process We prepare the training data by splitting compounds in two steps, following the technique of Fritzinger and Fraser (2010). First, possible split points are extracted using SMOR, and second, the best split points are selected using the geometric mean of word part frequencies. compound Inflationsrate auszubrechen word parts Inflation Rate aus zu brechen gloss inflation rate out to break (to break out) Training data is then stemmed as described in Section 2.3. The formerly modifying words of the compound (in our example the words to the left of the rightmost word) do not have a stem markup assigned, except for two cases: i) they are nouns themselves or ii) they are particles separated from a verb. In these cases, f"
E12-1068,D07-1091,0,0.685969,"this moves some of the difficulty in predicting case from the inflection prediction step to the stem translation step. Since the choice of case in a PP is often determined by the PP’s meaning (and there are often different meanings possible given different case choices), it seems reasonable to make this decision during stem translation. Verbs are represented using their inflected surface form. Having access to inflected verb forms has a positive influence on case prediction in the second 2 We use an additional target factor to obtain the coarse POS for each stem, applying a 7-gram POS model. Koehn and Hoang (2007) showed that the use of a POS factor only results in negligible BLEU improvements, but we need access to the POS in our inflection prediction models. 665 input decoder output inflected in<APPR&gt;<Dat&gt; in in die<+ART&gt;<Def&gt; dem contrast Gegensatz<+NN&gt;<Masc&gt;<Sg&gt; Gegensatz to zu<APPR&gt;<Dat&gt; zu the die<+ART&gt;<Def&gt; der animated lebhaft<+ADJ&gt;<Pos&gt; lebhaften debate Debatte<+NN&gt;<Fem&gt;<Sg&gt; Debatte merged im Gegensatz zur lebhaften Debatte Table 1: Re-merging of prepositions and articles after inflection to form portmanteaus, in dem means in the. step through subject-verb agreement. Articles are reduced to th"
E12-1068,E03-1076,0,0.321449,"va et. al.’s work showed that it is most important to model target side coherence and our stem markup also allows us to access source side information. Using additional source side information beyond the markup did not produce a gain in performance. For compound splitting, we follow Fritzinger and Fraser (2010), using linguistic knowledge encoded in a rule-based morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies. Other approaches use less deep linguistic resources (e.g., POS-tags Stymne (2008)) or are (almost) knowledge-free (e.g., Koehn and Knight (2003)). Compound merging is less well studied. Popovic et al. (2006) used a simple, list-based merging approach, merging all consecutive words included in a merging list. This approach resulted in too many compounds. We follow Stymne and Cancedda (2011), for compound merging. We trained a CRF using (nearly all) of the features they used and found their approach to be effective (when combined with inflection and portmanteau merging) on one of our two test sets. 10 Conclusion We have shown that both the prediction of surface forms and the prediction of linguistic features are of interest for improvin"
E12-1068,P10-1052,0,0.234392,"Missing"
E12-1068,D10-1015,0,0.0193011,"requires the use of morphologically-aware syntactic parsers to annotate the training data with such features, and additionally depends on the coverage of morphological analysis and generation. Despite this, our research clearly shows that the feature-based approach is superior for English-to-German SMT. This is a striking result considering state-of-theart performance of German parsing is poor compared with the best performance on English parsing. As parsing performance improves, the performance of linguistic-feature-based approaches will increase. Virpioja et al. (2007), Badr et al. (2008), Luong et al. (2010), Clifton and Sarkar (2011), and others are primarily concerned with using morpheme segmentation in SMT, which is a useful approach for dealing with issues of word-formation. However, this does not deal directly with linguistic features marked by inflection. In German these linguistic features are marked very irregularly and there is widespread syncretism, making it difficult to split off morphemes specifying these features. So it is questionable as to whether morpheme segmentation techniques are sufficient to solve the inflectional problem we are addressing. Much previous work looks at the im"
E12-1068,schmid-etal-2004-smor,0,0.877102,"n, including the inflection-dependent phenomenon of portmanteaus. Later, after performing an extensive analysis of this system, we will extend it 664 Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 664–674, c Avignon, France, April 23 - 27 2012. 2012 Association for Computational Linguistics to model compounds, a highly productive phenomenon in German (see Section 8). The key linguistic knowledge sources that we use are morphological analysis and generation of German based on SMOR, a morphological analyzer/generator of German (Schmid et al., 2004) and the BitPar parser, which is a state-of-the-art parser of German (Schmid, 2004). 2.1 Issues of inflection prediction In order to ensure coherent German NPs, we model linguistic features of each word in an NP. We model case, gender, and number agreement and whether or not the word is in the scope of a determiner (such as a definite article), which we label in-weak-context (this linguistic feature is necessary to determine the type of inflection of adjectives and other words: strong, weak, mixed). This is a diverse group of features. The number of a German noun can often be determined given"
E12-1068,C04-1024,0,0.286356,"an extensive analysis of this system, we will extend it 664 Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 664–674, c Avignon, France, April 23 - 27 2012. 2012 Association for Computational Linguistics to model compounds, a highly productive phenomenon in German (see Section 8). The key linguistic knowledge sources that we use are morphological analysis and generation of German based on SMOR, a morphological analyzer/generator of German (Schmid et al., 2004) and the BitPar parser, which is a state-of-the-art parser of German (Schmid, 2004). 2.1 Issues of inflection prediction In order to ensure coherent German NPs, we model linguistic features of each word in an NP. We model case, gender, and number agreement and whether or not the word is in the scope of a determiner (such as a definite article), which we label in-weak-context (this linguistic feature is necessary to determine the type of inflection of adjectives and other words: strong, weak, mixed). This is a diverse group of features. The number of a German noun can often be determined given only the English source word. The gender of a German noun is innate and often diffi"
E12-1068,W11-2129,0,0.446157,"3. The formerly modifying words of the compound (in our example the words to the left of the rightmost word) do not have a stem markup assigned, except for two cases: i) they are nouns themselves or ii) they are particles separated from a verb. In these cases, former modifiers are represented identically to their individual occurring counterparts, which helps generalization. 8.2 Model for Compound Merging After translation, compound parts have to be resynthesized into compounds before inflection. Two decisions have to be taken: i) where to 670 merge and ii) how to merge. Following the work of Stymne and Cancedda (2011), we implement a linear-chain CRF merging system using the following features: stemmed (separated) surface form, part-of-speech14 and frequencies from the training corpus for bigrams/merging of word and word+1, word as true prefix, word+1 as true suffix, plus frequency comparisons of these. The CRF is trained on the split monolingual data. It only proposes merging decisions, merging itself uses a list extracted from the monolingual data (Popovic et al., 2006). 8.3 Experiments We evaluated the end-to-end inflection system with the addition of compounds.15 As in the inflection experiments descri"
E12-1068,P08-1059,0,0.455719,"M) and has a different input representation based on the previously described markup. The input consists of a sequence of coarse POS tags, and for those stems that are marked up with the relevant feature, this feature value. Finally, we combine the predicted features together to produce the same final output as the single joint sequence model, and then generate each surface form using SMOR. 5. Using four CRFs (one for each linguistic feature). The sequence models already presented are limited to the n-gram feature space, and those that predict linguistic features are not strongly lexicalized. Toutanova et al. (2008) uses an MEMM which allows the integration of a wide variety of feature functions. We also wanted to experiment with additional feature functions, and so we train 4 separate linear chain CRF6 models on our data (one for each linguistic feature we want to predict). We chose CRFs over MEMMs to avoid the label bias problem (Lafferty et al., 2001). The CRF feature functions, for each German word wi , are in Table 3. The common feature functions are used in all models, while each of the 4 separate models (one for each linguistic feature) includes the context of only that linguistic feature. We use"
E12-1068,2007.mtsummit-papers.65,0,0.019067,"Missing"
E12-1068,W11-2126,0,0.152964,"f which deals with both issues is the work of de Gispert and Mari˜no (2008), which deals with verbal morphology and attached pronouns. There has been other work on solving inflection. Koehn and Hoang (2007) introduced factored SMT. We use more complex context features. Fraser (2009) tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms. Bojar and Kos (2010) improved on this by marking prepositions with the case they mark (one of the most important markups in our system). Both efforts were ineffective on large data sets. Williams and Koehn (2011) used unification in an SMT system to model some of the 671 agreement phenomena that we model. Our CRF framework allows us to use more complex context features. We have directly addressed the question as to whether inflection should be predicted using surface forms as the target of the prediction, or whether linguistic features should be predicted, along with the use of a subsequent generation step. The direct prediction of surface forms is limited to those forms observed in the training data, which is a significant limitation. However, it is reasonable to expect that the use of features (and"
E12-1068,P10-1047,0,0.0195547,"or dealing with issues of word-formation. However, this does not deal directly with linguistic features marked by inflection. In German these linguistic features are marked very irregularly and there is widespread syncretism, making it difficult to split off morphemes specifying these features. So it is questionable as to whether morpheme segmentation techniques are sufficient to solve the inflectional problem we are addressing. Much previous work looks at the impact of using source side information (i.e., feature functions on the aligned English), such as those of Avramidis and Koehn (2008), Yeniterzi and Oflazer (2010) and others. Toutanova et. al.’s work showed that it is most important to model target side coherence and our stem markup also allows us to access source side information. Using additional source side information beyond the markup did not produce a gain in performance. For compound splitting, we follow Fritzinger and Fraser (2010), using linguistic knowledge encoded in a rule-based morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies. Other approaches use less deep linguistic resources (e.g., POS-tags Stymne (2008)) or are (almost) kn"
E12-1074,P05-1022,0,0.164074,". The processing steps are shown in figure 1. For the development of the reordering rules, we used a small sample of the training data. In particular, by observing the English parse trees extracted randomly from the training data, we developed a set of rules which transform the original trees in such a way that the English verbs are moved to the positions which correspond to the placement of verbs in German. 4.1 Labeling clauses with their type As shown in section 3.1, the verb positions in German depend on the clause type. Since we use English parse trees produced by the generative parser of Charniak and Johnson (2005) which do not have any function labels, we implemented a simple rule-based clause type labeling script which 728 S−EXTR ADVP , reordering RB , Yesterday NP VP1 PRP VBD I . NP read . NP S−SUB DT NN a book WHNP S which NP VP PRP VBD S−EXTR ADVP , RB Yesterday , bought JJ I VBD NP VP1 read PRP I NP NN . last NP NP week . S−SUB DT NN a book WHNP S which NP VP PRP read out and translate NP I JJ last VBD NN bought week Figure 1: Processing steps: Clause type labeling annotates the given original tree with clause type labels (in figure, S-EXTR and S-SUB). Subsequently, the reordering is performed (cf"
E12-1074,P05-1066,0,0.626584,"Missing"
E12-1074,P08-1115,0,0.0166195,"rent positions. Therefore, we need to identify exactly which parts of a verbal complex must be moved and their possible positions in a German sentence. Reordering rules can also be extracted automatically. For example, Niehues and Kolss (2009) automatically extracted discontiguous reordering rules (allowing gaps between POS tags which can include an arbitrary number of words) from a word-aligned parallel corpus with POS tagged source side. Since many different rules can be applied on a given sentence, a number of reordered sentence alternatives are created which are encoded as a word lattice (Dyer et al., 2008). They dealt with the translation directions German-toEnglish and English-to-German, but translation improvement was obtained only for the Germanto-English direction. This may be due to missing information about clause boundaries since English verbs often have to be moved to the clause end. Our reordering has access to this kind of knowledge since we are working with a full syntactic parser of English. Genzel (2010) proposed a languageindependent method for learning reordering rules where the rules are extracted from parsed source language sentences. For each node, all possible reorderings (pe"
E12-1074,C10-1043,0,0.586669,"rectly left near their position in English, creating problems of fluency. Verbs are also often omitted since the distortion model cannot move verbs to positions which are licensed by the German language model, making the translations difficult to understand. A common approach for handling the longrange reordering problem within PSMT is performing syntax-based or part-of-speech-based (POS-based) reordering of the input as a preprocessing step before translation (e.g., Collins et al. (2005), Gupta et al. (2007), Habash (2007), Xu et al. (2009), Niehues and Kolss (2009), KatzBrown et al. (2011), Genzel (2010)). We reorder English to improve the translation to German. The verb reordering process is implemented using deterministic reordering rules on English parse trees. The sequence of reorderings is derived from the clause type and the composition of a given verbal complex (a (possibly discontiguous) sequence of verbal elements in a single clause). Only one rule can be applied in a given context and for each word to be reordered, there is a unique reordered position. We train a standard PSMT system on the reordered English training and tuning data and use it to translate the reordered English test"
E12-1074,2007.mtsummit-papers.28,0,0.13323,"s English and German. When translating from English to German, verbs in the German output are often incorrectly left near their position in English, creating problems of fluency. Verbs are also often omitted since the distortion model cannot move verbs to positions which are licensed by the German language model, making the translations difficult to understand. A common approach for handling the longrange reordering problem within PSMT is performing syntax-based or part-of-speech-based (POS-based) reordering of the input as a preprocessing step before translation (e.g., Collins et al. (2005), Gupta et al. (2007), Habash (2007), Xu et al. (2009), Niehues and Kolss (2009), KatzBrown et al. (2011), Genzel (2010)). We reorder English to improve the translation to German. The verb reordering process is implemented using deterministic reordering rules on English parse trees. The sequence of reorderings is derived from the clause type and the composition of a given verbal complex (a (possibly discontiguous) sequence of verbal elements in a single clause). Only one rule can be applied in a given context and for each word to be reordered, there is a unique reordered position. We train a standard PSMT system o"
E12-1074,2007.mtsummit-papers.29,0,0.0787998,"When translating from English to German, verbs in the German output are often incorrectly left near their position in English, creating problems of fluency. Verbs are also often omitted since the distortion model cannot move verbs to positions which are licensed by the German language model, making the translations difficult to understand. A common approach for handling the longrange reordering problem within PSMT is performing syntax-based or part-of-speech-based (POS-based) reordering of the input as a preprocessing step before translation (e.g., Collins et al. (2005), Gupta et al. (2007), Habash (2007), Xu et al. (2009), Niehues and Kolss (2009), KatzBrown et al. (2011), Genzel (2010)). We reorder English to improve the translation to German. The verb reordering process is implemented using deterministic reordering rules on English parse trees. The sequence of reorderings is derived from the clause type and the composition of a given verbal complex (a (possibly discontiguous) sequence of verbal elements in a single clause). Only one rule can be applied in a given context and for each word to be reordered, there is a unique reordered position. We train a standard PSMT system on the reordered"
E12-1074,D11-1017,0,0.209794,"Missing"
E12-1074,P07-2045,0,0.015547,"clause they will have in the German translation. This is a difficult problem, as German verbal elements can appear in different positions within a clause (in contrast with English verbal elements, whose positions do not vary as much). We obtain a significant improvement in translation performance. 1 Introduction Phrase-based SMT (PSMT) systems translate word sequences (phrases) from a source language into a target language, performing reordering of target phrases in order to generate a fluent target language output. The reordering models, such as, for example, the models implemented in Moses (Koehn et al., 2007), are often limited to a certain reordering range since reordering beyond this distance cannot be performed accurately. This results in problems of fluency for language pairs with large differences in constituent order, such as English and German. When translating from English to German, verbs in the German output are often incorrectly left near their position in English, creating problems of fluency. Verbs are also often omitted since the distortion model cannot move verbs to positions which are licensed by the German language model, making the translations difficult to understand. A common a"
E12-1074,W04-3250,0,0.068289,"Missing"
E12-1074,W09-0435,0,0.336075,"German, verbs in the German output are often incorrectly left near their position in English, creating problems of fluency. Verbs are also often omitted since the distortion model cannot move verbs to positions which are licensed by the German language model, making the translations difficult to understand. A common approach for handling the longrange reordering problem within PSMT is performing syntax-based or part-of-speech-based (POS-based) reordering of the input as a preprocessing step before translation (e.g., Collins et al. (2005), Gupta et al. (2007), Habash (2007), Xu et al. (2009), Niehues and Kolss (2009), KatzBrown et al. (2011), Genzel (2010)). We reorder English to improve the translation to German. The verb reordering process is implemented using deterministic reordering rules on English parse trees. The sequence of reorderings is derived from the clause type and the composition of a given verbal complex (a (possibly discontiguous) sequence of verbal elements in a single clause). Only one rule can be applied in a given context and for each word to be reordered, there is a unique reordered position. We train a standard PSMT system on the reordered English training and tuning data and use it"
E12-1074,P02-1040,0,0.0830366,"Missing"
E12-1074,N09-1028,0,0.0468147,"ng from English to German, verbs in the German output are often incorrectly left near their position in English, creating problems of fluency. Verbs are also often omitted since the distortion model cannot move verbs to positions which are licensed by the German language model, making the translations difficult to understand. A common approach for handling the longrange reordering problem within PSMT is performing syntax-based or part-of-speech-based (POS-based) reordering of the input as a preprocessing step before translation (e.g., Collins et al. (2005), Gupta et al. (2007), Habash (2007), Xu et al. (2009), Niehues and Kolss (2009), KatzBrown et al. (2011), Genzel (2010)). We reorder English to improve the translation to German. The verb reordering process is implemented using deterministic reordering rules on English parse trees. The sequence of reorderings is derived from the clause type and the composition of a given verbal complex (a (possibly discontiguous) sequence of verbal elements in a single clause). Only one rule can be applied in a given context and for each word to be reordered, there is a unique reordered position. We train a standard PSMT system on the reordered English training"
E14-1061,N12-1047,0,0.0368869,"Models were trained with the default settings of the Moses SMT toolkit, v1.0 (Koehn et al., 2007) using the data from the EACL 2009 workshop on statistical machine translation. All compound processing systems are trained and tuned identically, except using different C RF models for compound prediction. All training data was split and reduced to the underspecified representation described in Section 4. We used KenLM (Heafield, 2011) with SRILM (Stolcke, 2002) to train a 5-gram language model based on all available target language training data. For tuning, we used batch-mira with ‘safe-hope’ (Cherry and Foster, 2012) and ran it separately for every experiment. We integrated the 9 We used pair-wise bootstrap resampling with sample size 1000 and p-value 0.05, from: http://www.ark.cs.cmu.edu/MT 584 lexically matches the reference correct translation wrong translation group ID 1a: perfect match 1b: inflection wrong 2a: merging wrong 2b: no merging 3a: compound 3b: no compound 4a: compound 4b: no compound example reference english Inflationsrate Inflationsrate inflation rate Rohstoffpreisen Rohstoffpreise raw material prices Anwaltsbewegung Anw¨altebewegung lawyers movement Polizei Chef Polizeichef police chie"
E14-1061,schmid-etal-2004-smor,0,0.288925,"e all of the morphological information stripped from the underspecified representation. Note that erroneous over-splitting might make the correct merging of compounds difficult3 (or even impossible), due to the number of correct decisions required. For example, it requires only 1 correct prediction to recombine “Niederschlag|Menge” into “Niederschlagsmenge” (“amount of precipitation”) but 3 for the wrong split into “nie|der|Schlag|Menge” (“never|the|hit|amount”). We use the compound splitter of Fritzinger and Fraser (2010), who have shown that using a rule-based morphological analyser (S MOR, Schmid et al. (2004)) drastically reduced the number of erroneous splits when compared to the frequency-based approach of Koehn and Knight (2003). However, we adapted it to work on tokens: some words can, depending on their context, either be interpreted as named entities or common nouns, e.g., “Dinkelacker” (a German beer brand or “spelt|field”).4 We parsed the training data and use the parser’s decisions to identify proper names, see “Baumeister” in Figure 2. After splitting, we use S MOR to reduce words to lemmas, keeping morphological features like gender or number, and stripping features like case, as ¨ illu"
E14-1061,E12-1068,1,0.889999,"rred in the parallel training data. As parallel training data is limited, it is desirable to extract as much information from it as possible. We present an approach for compound processing in SMT, translating from English to German, that splits compounds prior to training (in order to access the individual words which together form the compound) and recombines them after translation. While compound splitting is a well-studied task, compound merging has not received as much attention in the past. We start from Stymne and Cancedda (2011), who used sequence models to predict compound merging and Fraser et al. (2012) who, in addition, generalise over German inflection. Our new contributions are: (i) We project 2 Dealing with Compounds in SMT In German, two (or more) single words (usually nouns or adjectives) are combined to form a compound which is considered a semantic unit. The rightmost part is referred to as the head while all other parts are called modifiers. E XAMPLE (1) lists different ways of joining simple words into compounds: mostly, no modification is required (A) or a filler letter is introduced (B). More rarely, a letter is deleted (C), or transformed (D). 579 Proceedings of the 14th Confere"
E14-1061,W10-1734,1,0.959617,"(D) Kriterium+Liste = Kriterienliste (“criteria list”) In the past, there have been numerous attempts to split compounds, all improving translation quality when translating from a compounding to a noncompounding language. Several compound splitting approaches make use of substring corpus frequencies in order to find the optimal split points of a compound (e.g. Koehn and Knight (2003), who allowed only “(e)s” as filler letters). Stymne et al. (2008) use Koehn and Knight’s technique, include a larger list of possible modifier transformations and apply P OS restrictions on the substrings, while Fritzinger and Fraser (2010) use a morphological analyser to find only linguistically motivated substrings. In contrast, Dyer (2010) presents a latticebased approach to encode different segmentations of words (instead of finding the one-best split). More recently, Macherey et al. (2011) presented a language-independent unsupervised approach in which filler letters and a list of words not to be split (e.g., named entities) are learned using phrase tables and Levenshtein distance. German compounds are highly productive,1 and traditional SMT approaches often fail in the face of such productivity. Therefore, special processi"
E14-1061,W11-2129,0,0.322661,"translation (SMT) approaches, because words can only be translated as they have occurred in the parallel training data. As parallel training data is limited, it is desirable to extract as much information from it as possible. We present an approach for compound processing in SMT, translating from English to German, that splits compounds prior to training (in order to access the individual words which together form the compound) and recombines them after translation. While compound splitting is a well-studied task, compound merging has not received as much attention in the past. We start from Stymne and Cancedda (2011), who used sequence models to predict compound merging and Fraser et al. (2012) who, in addition, generalise over German inflection. Our new contributions are: (i) We project 2 Dealing with Compounds in SMT In German, two (or more) single words (usually nouns or adjectives) are combined to form a compound which is considered a semantic unit. The rightmost part is referred to as the head while all other parts are called modifiers. E XAMPLE (1) lists different ways of joining simple words into compounds: mostly, no modification is required (A) or a filler letter is introduced (B). More rarely, a"
E14-1061,W11-2123,0,0.0223943,"R (14.61) and the U NSPLIT baseline (14.74) is not statistically significant. Translation Performance We integrated our compound processing pipeline into an end-to-end SMT system. Models were trained with the default settings of the Moses SMT toolkit, v1.0 (Koehn et al., 2007) using the data from the EACL 2009 workshop on statistical machine translation. All compound processing systems are trained and tuned identically, except using different C RF models for compound prediction. All training data was split and reduced to the underspecified representation described in Section 4. We used KenLM (Heafield, 2011) with SRILM (Stolcke, 2002) to train a 5-gram language model based on all available target language training data. For tuning, we used batch-mira with ‘safe-hope’ (Cherry and Foster, 2012) and ran it separately for every experiment. We integrated the 9 We used pair-wise bootstrap resampling with sample size 1000 and p-value 0.05, from: http://www.ark.cs.cmu.edu/MT 584 lexically matches the reference correct translation wrong translation group ID 1a: perfect match 1b: inflection wrong 2a: merging wrong 2b: no merging 3a: compound 3b: no compound 4a: compound 4b: no compound example reference en"
E14-1061,E03-1076,0,0.675514,"training data. ting and merging, we thus report on previous approaches for both of these tasks. E XAMPLE (1) (A) Haus+Boot = Hausboot (“house boat”) (B) Ort+s+Zeit = Ortszeit (“local time”) (C) Kirche-e+Turm = Kirchturm (“church tower”) (D) Kriterium+Liste = Kriterienliste (“criteria list”) In the past, there have been numerous attempts to split compounds, all improving translation quality when translating from a compounding to a noncompounding language. Several compound splitting approaches make use of substring corpus frequencies in order to find the optimal split points of a compound (e.g. Koehn and Knight (2003), who allowed only “(e)s” as filler letters). Stymne et al. (2008) use Koehn and Knight’s technique, include a larger list of possible modifier transformations and apply P OS restrictions on the substrings, while Fritzinger and Fraser (2010) use a morphological analyser to find only linguistically motivated substrings. In contrast, Dyer (2010) presents a latticebased approach to encode different segmentations of words (instead of finding the one-best split). More recently, Macherey et al. (2011) presented a language-independent unsupervised approach in which filler letters and a list of words"
E14-1061,W08-0317,0,0.513437,"s for both of these tasks. E XAMPLE (1) (A) Haus+Boot = Hausboot (“house boat”) (B) Ort+s+Zeit = Ortszeit (“local time”) (C) Kirche-e+Turm = Kirchturm (“church tower”) (D) Kriterium+Liste = Kriterienliste (“criteria list”) In the past, there have been numerous attempts to split compounds, all improving translation quality when translating from a compounding to a noncompounding language. Several compound splitting approaches make use of substring corpus frequencies in order to find the optimal split points of a compound (e.g. Koehn and Knight (2003), who allowed only “(e)s” as filler letters). Stymne et al. (2008) use Koehn and Knight’s technique, include a larger list of possible modifier transformations and apply P OS restrictions on the substrings, while Fritzinger and Fraser (2010) use a morphological analyser to find only linguistically motivated substrings. In contrast, Dyer (2010) presents a latticebased approach to encode different segmentations of words (instead of finding the one-best split). More recently, Macherey et al. (2011) presented a language-independent unsupervised approach in which filler letters and a list of words not to be split (e.g., named entities) are learned using phrase ta"
E14-1061,P07-2045,0,0.00594032,"but without compound processing (U NSPLIT). Table 4 shows that only U NSPLIT and S TR (source language and a reduced set of target language features) are significantly9 improving over the R AW baseline. They also significantly outperform all other systems, except S T (full source and target language feature set). The difference between S TR (14.61) and the U NSPLIT baseline (14.74) is not statistically significant. Translation Performance We integrated our compound processing pipeline into an end-to-end SMT system. Models were trained with the default settings of the Moses SMT toolkit, v1.0 (Koehn et al., 2007) using the data from the EACL 2009 workshop on statistical machine translation. All compound processing systems are trained and tuned identically, except using different C RF models for compound prediction. All training data was split and reduced to the underspecified representation described in Section 4. We used KenLM (Heafield, 2011) with SRILM (Stolcke, 2002) to train a 5-gram language model based on all available target language training data. For tuning, we used batch-mira with ‘safe-hope’ (Cherry and Foster, 2012) and ran it separately for every experiment. We integrated the 9 We used p"
E14-1061,E09-3008,0,0.0820407,"Missing"
E14-1061,P08-1059,0,0.139495,"d representation we are using allows for maximal generalisation over word parts independent of their position of occurrence or inflectional realisations. Moreover, their experiments were limited to predicting compounds on held-out data; no results were reported for using their approach in translation. In Fraser et al. (2012) we re-implemented the approach of Stymne and Cancedda (2011), combined it with inflection prediction and applied it to a translation task. However, compound merging was restricted to a list of compounds and parts. Our present work facilitates more independent combination. Toutanova et al. (2008) and Weller et al. (2013) used source language features for target language inflection, but to our knowledge, none of these works applied source language features for compound merging. 4 Step 1: Underspecified Representation 3 In contrast, they may not hurt translation quality in the other direction, where phrase-based SMT is likely to learn the split words as a phrase and thus recover from that error. 4 Note that Macherey et al. (2011) blocked splitting of words which can be used as named entities, independent of context, which is less general than our solution. In order to enhance translatio"
E14-1061,P13-1058,1,0.831988,"g allows for maximal generalisation over word parts independent of their position of occurrence or inflectional realisations. Moreover, their experiments were limited to predicting compounds on held-out data; no results were reported for using their approach in translation. In Fraser et al. (2012) we re-implemented the approach of Stymne and Cancedda (2011), combined it with inflection prediction and applied it to a translation task. However, compound merging was restricted to a list of compounds and parts. Our present work facilitates more independent combination. Toutanova et al. (2008) and Weller et al. (2013) used source language features for target language inflection, but to our knowledge, none of these works applied source language features for compound merging. 4 Step 1: Underspecified Representation 3 In contrast, they may not hurt translation quality in the other direction, where phrase-based SMT is likely to learn the split words as a phrase and thus recover from that error. 4 Note that Macherey et al. (2011) blocked splitting of words which can be used as named entities, independent of context, which is less general than our solution. In order to enhance translation model accuracy, it is r"
E14-1061,P11-1140,0,0.229461,"use of substring corpus frequencies in order to find the optimal split points of a compound (e.g. Koehn and Knight (2003), who allowed only “(e)s” as filler letters). Stymne et al. (2008) use Koehn and Knight’s technique, include a larger list of possible modifier transformations and apply P OS restrictions on the substrings, while Fritzinger and Fraser (2010) use a morphological analyser to find only linguistically motivated substrings. In contrast, Dyer (2010) presents a latticebased approach to encode different segmentations of words (instead of finding the one-best split). More recently, Macherey et al. (2011) presented a language-independent unsupervised approach in which filler letters and a list of words not to be split (e.g., named entities) are learned using phrase tables and Levenshtein distance. German compounds are highly productive,1 and traditional SMT approaches often fail in the face of such productivity. Therefore, special processing of compounds is required for translation into German, as many compounds will not (e.g. Hausboot, “house boat”) or only rarely have been seen in the training data.2 In contrast, most compounds consist of two (or more) simple words that occur more frequently"
E14-1061,P02-1040,0,\N,Missing
E17-2059,N12-1047,0,0.0199491,"ne. We choose English→Czech as a task that is representative for machine translation from a morphologically underspecified language into a morphologically rich language. 5.1 11.8 12.7 50K pre-pruned by applying a minimum score threshold of 0.0001 on the source-to-target phrase translation probability, and the decoder loads a maximum of 100 best translation options per distinct source side. We use cube pruning in decoding. Pop limit and stack limit for cube pruning are set to 1000 for tuning and to 5000 for testing. The distortion limit is 6. Weights are tuned on newstest2013 with k-best MIRA (Cherry and Foster, 2012) over 200-best lists for 25 iterations. Translation quality is measured in B LEU (Papineni et al., 2002) on three different test sets, newstest2014, newstest2015, and newstest2016.3 Our training data amounts to around 50 million bilingual sentences overall, but we conduct sets of experiments with systems trained using different fractions of this data (50K, 500K, 5M, 50M). Whereas English→Czech has good coverage in terms of training corpora, we simulate lowand medium-resource conditions for the purpose of drawing more general conclusions. Irrespective of this, we utilize the same large LMs in a"
E17-2059,N13-1001,1,0.853824,"s using 5M training sentence pairs. Table 6: English→Czech experimental results using 50M training sentence pairs. In our baseline systems, we already draw on lemmas and morphosyntactic tags as factors on the target side, in addition to word surface forms.1 The additional target-side factors allow us to integrate features that independently model word sense (in terms of the lemma) and morphological attributes (in terms of the morphosyntactic tag). All our translation engines (cf. Section 5) incorporate ngram LMs over lemmas and over morphosyntactic tags, and an operation sequence model (OSM) (Durrani et al., 2013) with lemmas on the target side. These models counteract sparsity, and where models over surface forms fail for unseen variants, they still assign scores which are based on reliable probability estimates. When enhancing a system with synthesized phrase table entries, we add further features. Since the usual phrase translation and lexical translation log-probabilities over surface forms cannot be estimated for unseen morphological variants, but all new variants are generated from existing lemmas, we utilize the corresponding log-probabilities over target lemmas. Those can be extracted from the"
E17-2059,W10-1705,1,0.905261,"low-resource conditions, but the problem persists even with larger amounts of parallel training data. When translating into the morphologically rich language, the system fails at producing the unseen morphological variants, leading to major translation errors. Consider the Czech example in Table 1. A small parallel corpus of 50K English-Czech sentences contains only a single variant of the morphological 2 Related Work Translation into morphologically rich languages is often tackled through “two-step”, i.e., separate modules for morphological prediction and generation (Toutanova et al., 2008; Bojar and Kos, 2010; 369 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 369–375, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics Fraser et al., 2012; Burlot et al., 2016). An important problem is that lexical choice (of the lemma) is carried out in a separate step from morphological prediction. Factored machine translation with separate translation and generation models represents a different approach, operating with a singlestep search. However, too many options in decoding cause a blow"
E17-2059,N13-1073,0,0.0371886,"t no separate generation model). The target factors are the word surface form, lemma, and a morphosyntactic tag. We use the Czech positional tagset (Hajiˇc and Hladká, 1998) which fully describes the word’s morphological attributes. On the source side we use only surface forms, except for the discriminative classifier, which includes the features as shown in Table 2. We employ corpora that have been provided for the English→Czech News translation shared task at WMT16 (Bojar et al., 2016b), including the CzEng parallel corpus (Bojar et al., 2016a). Word alignments are created using fast_align (Dyer et al., 2013) and symmetrized. We extract phrases up to a maximum length of 7. The phrase table is 3 We evaluate case-sensitive with mteval-v13a.pl -c, comparing post-processed hypotheses against the raw reference. 372 input: now , six in 10 Republicans have a favorable view of Donald Trump . baseline: ted’ , šest v 10 republikáni mají pˇríznivý výhled Donald Trump . now, six inlocation 10 Republicansnom have a_favorable outlook Donaldnom Trumpnom . + synthetic (mtu) + morph-vw: ted’ , šest do deseti republikán˚u má pˇríznivý názor na Donalda Trumpa . now, six into tengen Republicansgen have a_favorable op"
E17-2059,W11-2138,1,0.887605,"et al., 2012; Burlot et al., 2016). An important problem is that lexical choice (of the lemma) is carried out in a separate step from morphological prediction. Factored machine translation with separate translation and generation models represents a different approach, operating with a singlestep search. However, too many options in decoding cause a blow-up of the search space; and useful information is dropped when modeling source_word→target_lemma and target_lemma→target_word separately. Word forms not seen in parallel data are sometimes still available in monolingual data. Backtranslation (Bojar and Tamchyna, 2011) takes advantage of this. The monolingual target language data is lemmatized, automatically translated to the source language, and the translations are aligned with the original, inflected target corpus to produce supplementary training data. Disadvantages are both the computational expense and that the back-translated text may contain errors. Previous work on synthetic phrases by Chahuneau et al. (2013) is most similar to our work. They commit to generation of a single candidate inflection of a lemma prior to decoding, chosen only based on a hierarchical rule and source-side information, a si"
E17-2059,E12-1068,1,0.915146,"rors. Consider the Czech example in Table 1. A small parallel corpus of 50K English-Czech sentences contains only a single variant of the morphological 2 Related Work Translation into morphologically rich languages is often tackled through “two-step”, i.e., separate modules for morphological prediction and generation (Toutanova et al., 2008; Bojar and Kos, 2010; 369 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 369–375, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics Fraser et al., 2012; Burlot et al., 2016). An important problem is that lexical choice (of the lemma) is carried out in a separate step from morphological prediction. Factored machine translation with separate translation and generation models represents a different approach, operating with a singlestep search. However, too many options in decoding cause a blow-up of the search space; and useful information is dropped when modeling source_word→target_lemma and target_lemma→target_word separately. Word forms not seen in parallel data are sometimes still available in monolingual data. Backtranslation (Bojar and Ta"
E17-2059,P98-1080,0,0.622887,"Missing"
E17-2059,D07-1091,0,0.389039,"morphological forms that are not known as translations of the source side of the phrase, we add these morphological variants as new translation options. We consider two settings: Scoring Unseen Morphological Variants Assigning dependable model scores to synthesized morphological forms is a primary challenge. During decoding, the artificially added phrase table entries compete with baseline phrases that had been directly extracted from the parallel training data. The correct choice has to be determined in search based on model scores. A phrase-based model with linguistically motivated factors (Koehn and Hoang, 2007) enables us to achieve better generalization capabilities when translating into a morphologically rich language. 370 newstest 2014 B LEU 2015 B LEU 2016 B LEU 12.4 12.2 10.8 10.6 11.8 11.8 + synthetic (word) + morph-vw-50K 13.4 13.4 11.3 11.4 12.5 12.7 + synthetic (word?) + morph-vw-50K 13.3 13.3 11.3 11.3 + synthetic (mtu) + morph-vw-50K 13.5 13.4 + synthetic (mtu?) + morph-vw-50K 13.4 13.5 system baseline 50K + morph-vw-50K 2015 B LEU 2016 B LEU 17.7 17.6 14.4 14.4 16.1 16.5 + synthetic (word) + morph-vw-500K 18.1 18.4 14.7 15.2 16.4 17.3 12.5 12.7 + synthetic (word?) + morph-vw-500K 18.0 18"
E17-2059,N03-1017,0,0.0265226,"emmas. We design techniques for generating and scoring unseen morphological variants fully integrated into phrase-based search, with the decoder being able to choose freely amongst all possible morphological variants. Empirically, we observe considerable gains in translation quality especially under medium- to low-resource conditions. Introduction Morphologically rich languages exhibit a large amount of inflected word surface forms for most lemmas, which poses difficulties to current statistical machine translation (SMT) technology. SMT systems, such as phrase-based translation (PBT) engines (Koehn et al., 2003), are trained on parallel corpora and can learn the vocabulary that is observed in the data. After training, the decoder can output words which have been seen on the target side of the corpus, but no unseen words. Sparsity of morphological variants leads to many linguistically valid morphological word forms remaining unseen in practical scenarios. This is a substantial issue under low-resource conditions, but the problem persists even with larger amounts of parallel training data. When translating into the morphologically rich language, the system fails at producing the unseen morphological va"
E17-2059,P07-2045,1,0.0312554,"f a known word, these two independent components should still be able to assign meaningful scores to the translation. Note that the features require lemmatization and tagging on both sides and a dependency parse of the source side. 5 16.1 17.3 500K 18.9 19.0 5M 20.5 20.8 50M 0 5 10 15 20 B LEU Figure 1: Visualization of the English→Czech translation quality on newstest2016, showing the benefit of our approach under different training resource conditions (50K/500K/5M/50M). Empirical Evaluation For an empirical evaluation of our technique, we build baseline phrase-based SMT engines using Moses (Koehn et al., 2007). We then enrich these baselines with linguistically motivated morphological variants that are unseen in the parallel training data, and we augment the model with the discriminative classifier to guide morphological selection during decoding. Different flavors of synthetic morphological variants are compared, each either combined with the discriminative classifier or standalone. We choose English→Czech as a task that is representative for machine translation from a morphologically underspecified language into a morphologically rich language. 5.1 11.8 12.7 50K pre-pruned by applying a minimum s"
E17-2059,P02-1040,0,0.101706,"y underspecified language into a morphologically rich language. 5.1 11.8 12.7 50K pre-pruned by applying a minimum score threshold of 0.0001 on the source-to-target phrase translation probability, and the decoder loads a maximum of 100 best translation options per distinct source side. We use cube pruning in decoding. Pop limit and stack limit for cube pruning are set to 1000 for tuning and to 5000 for testing. The distortion limit is 6. Weights are tuned on newstest2013 with k-best MIRA (Cherry and Foster, 2012) over 200-best lists for 25 iterations. Translation quality is measured in B LEU (Papineni et al., 2002) on three different test sets, newstest2014, newstest2015, and newstest2016.3 Our training data amounts to around 50 million bilingual sentences overall, but we conduct sets of experiments with systems trained using different fractions of this data (50K, 500K, 5M, 50M). Whereas English→Czech has good coverage in terms of training corpora, we simulate lowand medium-resource conditions for the purpose of drawing more general conclusions. Irrespective of this, we utilize the same large LMs in all setups, assuming that proper amounts of target language monolingual data can often be gathered, even"
E17-2059,P14-5003,0,0.110248,"Missing"
E17-2059,P16-1161,1,0.749918,"entries. For baseline phrase table entries, we retain their four baseline phrase translation and lexical translation features, meaning that features over target lemmas score synthesized entries and features over surface forms score baseline entries. The features have separate weights in the model combination. Furthermore, a binary indicator distinguishes baseline phrases from synthesized phrases. The final key to our approach is using a discriminative classifier (morph-vw, Vowpal Wabbit2 for Morphology) which can take context from both the source side and the target side into account, as in (Tamchyna et al., 2016). We design feature templates for the classifier that generalize to unseen morphological variants, as listed in Table 2. “Indicator” features are concatenations of words inside 1 But note that our factored systems operate without a division into separate translation and generation models. 2 371 https://hunch.net/~vw/ baseline + synthetic (mtu) + morph-vw the phrase, “internal” features represent each word in the phrase separately. Context features on the source side capture a fixed-sized window around the phrase. Target-side context is only to the left of the current phrase. The feature set is"
E17-2059,P08-1059,0,0.170483,"substantial issue under low-resource conditions, but the problem persists even with larger amounts of parallel training data. When translating into the morphologically rich language, the system fails at producing the unseen morphological variants, leading to major translation errors. Consider the Czech example in Table 1. A small parallel corpus of 50K English-Czech sentences contains only a single variant of the morphological 2 Related Work Translation into morphologically rich languages is often tackled through “two-step”, i.e., separate modules for morphological prediction and generation (Toutanova et al., 2008; Bojar and Kos, 2010; 369 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 369–375, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics Fraser et al., 2012; Burlot et al., 2016). An important problem is that lexical choice (of the lemma) is carried out in a separate step from morphological prediction. Factored machine translation with separate translation and generation models represents a different approach, operating with a singlestep search. However, too many options in"
E17-2099,2012.eamt-1.42,1,0.863105,"on enriched with features relevant for support verb constructions and verbal inflection. We show that the components targeting the different linguistic levels are complementary, but also that applying only verbal pre-ordering can introduce problems on the morpho-lexical level; our Syntax Different syntactic structures in source and target language are problematic as they are hard to capture by word alignment, and long-distance reorderings are typically also disfavoured in phrasebased SMT. Hierarchical systems can bridge gaps up to a certain length, possibly enhanced by explicit modeling, e.g. Braune et al. (2012). An alternative method, especially for phrasebased systems, is source-side reordering: in a preprocessing step, the source-side data is arranged such that it corresponds to the target-side structure. This improves the alignment and does not require long-distance reordering during decoding, see e.g. Collins et al. (2005) and Gojun and Fraser (2012). Lexicon Problems on the lexical level are diverse and include word sense disambiguation, selectional preferences and the translation of multi-word structures. Many approaches rely on rich source-side features to provide more context for decoding, e"
E17-2099,W15-0903,1,0.843872,"es for source context: Standard Features on the source-side comprise part-of-speech tags and lemmas within the phrase and a context window (5 for tags, 3 for word/lemma). Information across larger gaps is captured by dependency relations such as verbobject pairs or verb-subject pairs, cf. columns 4 and 5 in table 1. On the target-side, lemmas and part-of-speech tags for the current phrase are given. Support Verb Constructions are formed by a verb and a predicative noun, e.g. make a contribution. Typically, the verb does not contribute its full meaning, and thus cannot be translated literally. Cap et al. (2015) improved German-English phrasebased SMT by annotating support verb status on source-side verbs, which essentially divides verbs into two groups: “non-literal use” in a support verb construction, and “literal use” otherwise. The set of support verb constructions consists of highly associated noun+verb tuples. Cap et al. (2015) opted for a hard annotation by adding markup. Instead, we add a classifier feature and compare two variants: (i) setting the feature to a binary support verb status (yes/no) for a fixed set of tuples (using a log-likelihood threshold of 1000, as in Cap et al. (2015)). Th"
E17-2099,loaiciga-etal-2014-english,0,0.0605651,"Missing"
E17-2099,W16-2203,1,0.84877,"ime) and target-side generation of nominal inflection (post-processing). For (ii), we focus on source-side reordering and investigate whether introducing German clause ordering in the English data entails new problems: while in “regular” English verbs and their arguments are close to each other, they can be separated by large distances in the German-structured English. Reordering improves translation quality, but separating the verb from its arguments has also negative consequences. First, the agreement in number between verbs and subjects is impaired because subjects and verbs are separated (Ramm and Fraser, 2016). Second, there can be a negative effect on the lexical level, for example when translating multiword expressions. Consider the phrase to cut interest rates: if the parts occur close to each other, there is enough context to translate cut into senken (‘to decrease’). However, with too large a gap between cut and interest rates, it becomes difficult to disambiguate cut, leading to the wrong translation schneiden (’to cut with a knife’). 2 Morpho-Syntactic Modeling This section outlines the pre- and post-processing steps for morpho-syntactic modeling. during translation. To re-inflect the stemme"
E17-2099,schmid-etal-2004-smor,0,0.0241496,"Missing"
E17-2099,D07-1007,0,0.0606299,"alternative method, especially for phrasebased systems, is source-side reordering: in a preprocessing step, the source-side data is arranged such that it corresponds to the target-side structure. This improves the alignment and does not require long-distance reordering during decoding, see e.g. Collins et al. (2005) and Gojun and Fraser (2012). Lexicon Problems on the lexical level are diverse and include word sense disambiguation, selectional preferences and the translation of multi-word structures. Many approaches rely on rich source-side features to provide more context for decoding, e.g. Carpuat and Wu (2007), Jeong et al. (2010), Tamchyna et al. (2014), Tamchyna et al. (2016). 625 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 625–630, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics that the ground was permanently frozen in the current crisis , the us federal reserve and the european central bank cut interest rates dass der boden ständig gefroren war in der aktuellen krise senken die us-notenbank und die europäische zentralbank die zinssätze that the ground permanently fr"
E17-2099,D13-1174,0,0.0186888,"l features with features geared towards verbal inflection. 1 Morphology Inflection is one of the main problems when translating into a morphologically rich language. It is subject to local restrictions such as agreement in nominal phrases, but also depends on sentence-level interactions, such as verb-subject agreement, or the realization of grammatical case. Target-side morphology can be modeled through computation of inflectional features and generation of inflected forms (Toutanova et al., 2008; Fraser et al., 2012), by means of synthetic phrases to provide the full set of word inflections (Chahuneau et al., 2013), or by introducing agreement restrictions for consistent inflection (Williams and Koehn, 2011). Introduction and Motivation Many of the errors occurring in SMT can be attributed to problems on three linguistic levels: morphological richness, structural differences between source and target language, and lexical choice. Often, these categories are intertwined: for example, the syntactic function of an argument can be expressed on the morphological level by grammatical case (e.g. in German), or on the syntactic level through word ordering (such as SVO in English). This paper addresses problems"
E17-2099,P05-1022,0,0.0418345,"del is based on 4.592.139 parallel sentences; and 45M sentences (News14+parallel data) are used to train a 5-gram language model. We use NewsTest’13 (3000 sentences) and News Test’14 (3003 sentences) for tuning and testing. The linguistic processing for inflection prediction includes parsing (Schmid, 2004) and morphological analysis/generation (Schmid et al., 2004). To predict the features for nominal inflection, CRF sequence models (Lavergne et al., 2010) are trained on the target-side of the parallel data. The reordering rules from Gojun and Fraser (2012) are applied to parsed English data (Charniak and Johnson, 2005). We use a version of Moses with the integrated discriminative classifier VowpalWabbit (Tamchyna et al., 2014)2 . Training examples are extracted from the parallel data based on phrase-table entries. In order to keep the amount of training examples manageable, the phrase-table is reduced with sigtestfiltering with the setting -l a+e -n 30.3 We run 50 training iterations and apply early-stopping on the development set to identify the optimal model. 627 2 3 github.com/moses-smt/mosesdecoder/tree/master/vw All experiments use sigtest-filtered phrase-tables. 19.45 VW-1 pos/lem 19.81* VW-2 pos/lem/"
E17-2099,P05-1066,0,0.0738678,"n source and target language are problematic as they are hard to capture by word alignment, and long-distance reorderings are typically also disfavoured in phrasebased SMT. Hierarchical systems can bridge gaps up to a certain length, possibly enhanced by explicit modeling, e.g. Braune et al. (2012). An alternative method, especially for phrasebased systems, is source-side reordering: in a preprocessing step, the source-side data is arranged such that it corresponds to the target-side structure. This improves the alignment and does not require long-distance reordering during decoding, see e.g. Collins et al. (2005) and Gojun and Fraser (2012). Lexicon Problems on the lexical level are diverse and include word sense disambiguation, selectional preferences and the translation of multi-word structures. Many approaches rely on rich source-side features to provide more context for decoding, e.g. Carpuat and Wu (2007), Jeong et al. (2010), Tamchyna et al. (2014), Tamchyna et al. (2016). 625 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 625–630, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Lin"
E17-2099,E12-1068,1,0.91806,"scriminative classifier can overcome these problems, in particular when enriching standard lexical features with features geared towards verbal inflection. 1 Morphology Inflection is one of the main problems when translating into a morphologically rich language. It is subject to local restrictions such as agreement in nominal phrases, but also depends on sentence-level interactions, such as verb-subject agreement, or the realization of grammatical case. Target-side morphology can be modeled through computation of inflectional features and generation of inflected forms (Toutanova et al., 2008; Fraser et al., 2012), by means of synthetic phrases to provide the full set of word inflections (Chahuneau et al., 2013), or by introducing agreement restrictions for consistent inflection (Williams and Koehn, 2011). Introduction and Motivation Many of the errors occurring in SMT can be attributed to problems on three linguistic levels: morphological richness, structural differences between source and target language, and lexical choice. Often, these categories are intertwined: for example, the syntactic function of an argument can be expressed on the morphological level by grammatical case (e.g. in German), or o"
E17-2099,E12-1074,1,0.934706,"ge are problematic as they are hard to capture by word alignment, and long-distance reorderings are typically also disfavoured in phrasebased SMT. Hierarchical systems can bridge gaps up to a certain length, possibly enhanced by explicit modeling, e.g. Braune et al. (2012). An alternative method, especially for phrasebased systems, is source-side reordering: in a preprocessing step, the source-side data is arranged such that it corresponds to the target-side structure. This improves the alignment and does not require long-distance reordering during decoding, see e.g. Collins et al. (2005) and Gojun and Fraser (2012). Lexicon Problems on the lexical level are diverse and include word sense disambiguation, selectional preferences and the translation of multi-word structures. Many approaches rely on rich source-side features to provide more context for decoding, e.g. Carpuat and Wu (2007), Jeong et al. (2010), Tamchyna et al. (2014), Tamchyna et al. (2016). 625 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 625–630, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics that the ground was"
E17-2099,2010.amta-papers.33,0,0.026038,"pecially for phrasebased systems, is source-side reordering: in a preprocessing step, the source-side data is arranged such that it corresponds to the target-side structure. This improves the alignment and does not require long-distance reordering during decoding, see e.g. Collins et al. (2005) and Gojun and Fraser (2012). Lexicon Problems on the lexical level are diverse and include word sense disambiguation, selectional preferences and the translation of multi-word structures. Many approaches rely on rich source-side features to provide more context for decoding, e.g. Carpuat and Wu (2007), Jeong et al. (2010), Tamchyna et al. (2014), Tamchyna et al. (2016). 625 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 625–630, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics that the ground was permanently frozen in the current crisis , the us federal reserve and the european central bank cut interest rates dass der boden ständig gefroren war in der aktuellen krise senken die us-notenbank und die europäische zentralbank die zinssätze that the ground permanently frozen was in the curre"
E17-2099,P10-1052,0,0.10306,"Missing"
E17-2099,C04-1024,0,0.0114703,"rrect auxiliary (sein: ’to be’ vs. haben: ’to have’) for German present/past perfect. 4 Experiments and Results This section presents the results of combining the strategies for the three linguistic levels. Data and Resources All systems are built using the Moses phrase-based framework. The translation model is based on 4.592.139 parallel sentences; and 45M sentences (News14+parallel data) are used to train a 5-gram language model. We use NewsTest’13 (3000 sentences) and News Test’14 (3003 sentences) for tuning and testing. The linguistic processing for inflection prediction includes parsing (Schmid, 2004) and morphological analysis/generation (Schmid et al., 2004). To predict the features for nominal inflection, CRF sequence models (Lavergne et al., 2010) are trained on the target-side of the parallel data. The reordering rules from Gojun and Fraser (2012) are applied to parsed English data (Charniak and Johnson, 2005). We use a version of Moses with the integrated discriminative classifier VowpalWabbit (Tamchyna et al., 2014)2 . Training examples are extracted from the parallel data based on phrase-table entries. In order to keep the amount of training examples manageable, the phrase-table is"
E17-2099,P16-1161,1,0.854072,"ide reordering: in a preprocessing step, the source-side data is arranged such that it corresponds to the target-side structure. This improves the alignment and does not require long-distance reordering during decoding, see e.g. Collins et al. (2005) and Gojun and Fraser (2012). Lexicon Problems on the lexical level are diverse and include word sense disambiguation, selectional preferences and the translation of multi-word structures. Many approaches rely on rich source-side features to provide more context for decoding, e.g. Carpuat and Wu (2007), Jeong et al. (2010), Tamchyna et al. (2014), Tamchyna et al. (2016). 625 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 625–630, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics that the ground was permanently frozen in the current crisis , the us federal reserve and the european central bank cut interest rates dass der boden ständig gefroren war in der aktuellen krise senken die us-notenbank und die europäische zentralbank die zinssätze that the ground permanently frozen was in the current crisis , cut the us federal reserve and the e"
E17-2099,P08-1059,0,0.0267052,"and lexical level. A discriminative classifier can overcome these problems, in particular when enriching standard lexical features with features geared towards verbal inflection. 1 Morphology Inflection is one of the main problems when translating into a morphologically rich language. It is subject to local restrictions such as agreement in nominal phrases, but also depends on sentence-level interactions, such as verb-subject agreement, or the realization of grammatical case. Target-side morphology can be modeled through computation of inflectional features and generation of inflected forms (Toutanova et al., 2008; Fraser et al., 2012), by means of synthetic phrases to provide the full set of word inflections (Chahuneau et al., 2013), or by introducing agreement restrictions for consistent inflection (Williams and Koehn, 2011). Introduction and Motivation Many of the errors occurring in SMT can be attributed to problems on three linguistic levels: morphological richness, structural differences between source and target language, and lexical choice. Often, these categories are intertwined: for example, the syntactic function of an argument can be expressed on the morphological level by grammatical case"
E17-2099,W11-2126,0,0.0180105,"the main problems when translating into a morphologically rich language. It is subject to local restrictions such as agreement in nominal phrases, but also depends on sentence-level interactions, such as verb-subject agreement, or the realization of grammatical case. Target-side morphology can be modeled through computation of inflectional features and generation of inflected forms (Toutanova et al., 2008; Fraser et al., 2012), by means of synthetic phrases to provide the full set of word inflections (Chahuneau et al., 2013), or by introducing agreement restrictions for consistent inflection (Williams and Koehn, 2011). Introduction and Motivation Many of the errors occurring in SMT can be attributed to problems on three linguistic levels: morphological richness, structural differences between source and target language, and lexical choice. Often, these categories are intertwined: for example, the syntactic function of an argument can be expressed on the morphological level by grammatical case (e.g. in German), or on the syntactic level through word ordering (such as SVO in English). This paper addresses problems across the three linguistic levels by combining established approaches which were previously st"
I11-1015,C08-1068,0,0.517934,"ration. They build a conditional probability model. The graphemebased model performs better than the phonemebased model and the hybrid model. This motivates our use of grapheme-based models. In this paper, we use a grapheme-based approach for transliteration from Hindi to Urdu. The phoneme-based approach would involve the conversion of Hindi and Urdu text into a phonemic representation which is not a trivial task as the short vowel ‘a’ is not written in Hindi text and no short vowels are written in Urdu text. The difficulty of this additional step would be likely to lead to additional errors. Malik et al. (2008) and Malik et al. (2009) work on transliteration from Hindi to Urdu and Urdu to Hindi respectively. They use the rules of SAMPA (Speech Assessment Methods Pho3 Extraction of Transliteration Pairs We automatically word-align the parallel corpus and extract a word list, later referred to as “list of word pairs“ (see Section 5, for details on training data). We use two methods to extract transliteration pairs from the list of word pairs. In the first 1 SAMPA and XSAMPA are used to represent the IPA symbols using 7-bit printable ASCII characters. 130 iteration which best predicts the held-out data"
I11-1015,W09-3536,0,0.117608,"ditional probability model. The graphemebased model performs better than the phonemebased model and the hybrid model. This motivates our use of grapheme-based models. In this paper, we use a grapheme-based approach for transliteration from Hindi to Urdu. The phoneme-based approach would involve the conversion of Hindi and Urdu text into a phonemic representation which is not a trivial task as the short vowel ‘a’ is not written in Hindi text and no short vowels are written in Urdu text. The difficulty of this additional step would be likely to lead to additional errors. Malik et al. (2008) and Malik et al. (2009) work on transliteration from Hindi to Urdu and Urdu to Hindi respectively. They use the rules of SAMPA (Speech Assessment Methods Pho3 Extraction of Transliteration Pairs We automatically word-align the parallel corpus and extract a word list, later referred to as “list of word pairs“ (see Section 5, for details on training data). We use two methods to extract transliteration pairs from the list of word pairs. In the first 1 SAMPA and XSAMPA are used to represent the IPA symbols using 7-bit printable ASCII characters. 130 iteration which best predicts the held-out data is selected as the stop"
I11-1015,P10-1048,1,0.879527,"Missing"
I11-1015,J03-1002,0,0.0156683,"Missing"
I11-1015,P09-1016,0,0.0358459,"Missing"
I11-1015,P06-2025,0,0.254507,"Missing"
I11-1015,P11-1044,1,0.904408,"In this paper, the term transliteration pair refers to a word pair where the words are transliterations of each other and the term transliteration unit refers to a character pair where the characters are transliterations of each other. We are interested in building joint source channel models for transliteration. Because we do not have a list of transliteration pairs to use as training data in building such a transliteration model, we use two methods to extract the list of transliteration pairs from a parallel corpus of Hindi/Urdu. The first method uses the transliteration mining algorithm of Sajjad et al. (2011) to automatically extract transliteration pairs. This approach does not use any language specific knowledge. The second method uses handcrafted transliteration rules specific to the mapping between Hindi and Urdu to extract transliteration pairs. We automatically align the two lists of extracted transliteration pairs at the character level and learn two transliteration models. We compare the results with three other transliteration systems. Both of our transliteration systems perform better than the other systems. The 1-best output of the transliteration system built on the list extracted usin"
I11-1015,P08-1045,0,0.30392,"Missing"
I11-1015,W98-1005,0,0.0866721,"n pairs. This method does not use any language dependent information. In the second approach, we use a rule-based method to extract transliteration pairs. Both processes are imperfect, meaning that there is noise in the extracted list of transliteration pairs. We build a joint source channel model as described by Li et al. (2004) and Ekbal et al. (2006) on the extracted list of transliteration pairs. The following sections describe the two mining approaches and the model in detail. Previous Work Transliteration can be done with phoneme-based or grapheme-based models. Knight and Graehl (1998), Stalls and Knight (1998), Al-Onaizan and Knight (2002) and Pervouchine et al. (2009) use the phoneme-based approach for transliteration. Kashani et al. (2007) and Al-Onaizan and Knight (2002) use a grapheme-based model to transliterate from Arabic into English. Al-Onaizan and Knight (2002) compare a grapheme-based approach, a phoneme-based approach and a linear combination of both for transliteration. They build a conditional probability model. The graphemebased model performs better than the phonemebased model and the hybrid model. This motivates our use of grapheme-based models. In this paper, we use a grapheme-bas"
I11-1015,N03-1017,0,0.0309845,"Missing"
I11-1015,P04-1021,0,0.16253,"Missing"
I11-1015,N10-1077,1,\N,Missing
I11-1015,W02-0505,0,\N,Missing
I11-1015,J98-4003,0,\N,Missing
J07-3002,H05-1009,0,0.123424,"Missing"
J07-3002,J93-2003,0,0.0861831,"requently been decoupled from the translation task and assumptions have been made about measuring alignment quality for machine translation which, it turns out, are not justified. In particular, none of the tens of papers published over the last five years has shown that significant decreases in alignment error rate (AER) result in significant increases in translation performance. This paper explains this state of affairs and presents steps towards measuring alignment quality in a way which is predictive of statistical machine translation performance. 1. Introduction Automatic word alignment (Brown et al. 1993) is a vital component of all statistical machine translation (SMT) approaches. There were a number of research papers presented from 2000 to 2005 at ACL, NAACL, HLT, COLING, WPT03, WPT05, and so forth, outlining techniques for attempting to increase word alignment quality. Despite this high level of interest, none of these techniques has been shown to result in a large gain in translation performance as measured by BLEU (Papineni et al. 2001) or any other metric. We find this lack of correlation between previous word alignment quality metrics and BLEU counterintuitive, because we and other res"
J07-3002,P03-1012,0,0.0574918,"Missing"
J07-3002,W05-0814,1,0.75988,"ific task, such as improving phrasal SMT, and calculate an appropriate α to be used. Individual researchers working on the same phrasal SMT tasks as those reported here (or on very similar tasks) could use the values of α we calculated. Our work invalidates some of the conclusions of recent alignment work which presented only evaluations based on metrics like AER or balanced F-Measure, and explains the lack of correlation in the few works which presented both such a metric 301 Computational Linguistics Volume 33, Number 3 and final MT results. A good example of the former are our own results (Fraser and Marcu 2005). The work presented there had the highest balanced F-Measure scores for the Romanian/English WPT05 shared task, but based on the findings here it is possible that a different algorithm tuned for the correct criterion would have had better MT performance. Other work includes many papers working on alignment models where words are allowed to participate in a maximum of one link. These models generally have higher precision and lower recall than IBM Model 4 symmetrized using the “Refined” or “Union” heuristics. Recall that in Section 3.1 we showed that AER is broken in a way that favors precisio"
J07-3002,P06-1097,1,0.766274,"Missing"
J07-3002,P04-1064,0,0.259175,"Missing"
J07-3002,H05-1012,0,0.380852,"Missing"
J07-3002,N03-1017,1,0.0224132,"Missing"
J07-3002,N06-1015,0,0.392134,"Missing"
J07-3002,P05-1057,0,0.334734,"Missing"
J07-3002,W05-0809,0,0.018286,"Missing"
J07-3002,W03-0301,0,0.0191539,"aluation.3 The English side of the bitext is 99.3 million words. The translation development set is the “NIST 2002 Dry Run,” and the test set is the “NIST 2003 evaluation set.” We have annotated gold standard alignments for 100 parallel sentences using Sure links, following the Blinker guidelines (Melamed 1998), which call for Sure links only (there were 2,154 Sure links). Here we also examine a medium task using 1/8 of the data (12.4 million English words) and a large task using all of the data. The Romanian/English training data was used for the tasks on Romanian/English alignment at WPT03 (Mihalcea and Pederson 2003) and WPT05 (Martin, Mihalcea, and Pedersen 2005). We carefully removed two sections of news bitext to use as the translation development and test sets. The English side of the training corpus is 964,000 words. The alignment set is the first 148 annotated sentences used for the 2003 task (there were 3,181 Sure links). 2 Sure links are by definition also Possible. 3 http://www.nist.gov/speech/tests/summaries/2004/mt04.htm. 294 Fraser and Marcu Measuring Word Alignment Quality for Statistical Machine Translation 2.2 Measuring Translation Performance Changes Caused By Alignment In phrased-based SM"
J07-3002,P03-1021,0,0.0758597,"d alignment are called Sure links. Some of the alignment sets also have links which are not Sure links but are Possible links (Och and Ney 2003). Possible links which are not Sure2 may be present but need not be present. We evaluate the translation performance of SMT systems by translating a heldout translation test set and measuring the BLEU score of our hypothesized translations against one or more reference translations. We also have an additional held-out translation set, the development set, which is employed by the MT system to train the weights of its log-linear model to maximize BLEU (Och 2003). We work with data sets for three different language pairs, examining French to English, Arabic to English, and Romanian to English translation tasks. The training data for the French/English data set is taken from the LDC Canadian Hansard data set, from which the word aligned data (presented in Och and Ney 2003) was also taken. The English side of the bitext is 67.4 million words. We used a separate Canadian Hansard data set (released by ISI) as the source of the translation test set and development set. We evaluate two different tasks using this data, a medium task where 1/8 of the data (8."
J07-3002,J03-1002,0,0.35012,"2.1 Data To build an SMT system we require a bitext and a word alignment of that bitext, as well as language models built from target language data. In all of our experiments, we will hold the bitext and target language resources constant, and only vary how we construct the word alignment. The gold standard word alignment sets we use have been manually annotated using links between words showing translational correspondence. Links which must be present in a hypothesized alignment are called Sure links. Some of the alignment sets also have links which are not Sure links but are Possible links (Och and Ney 2003). Possible links which are not Sure2 may be present but need not be present. We evaluate the translation performance of SMT systems by translating a heldout translation test set and measuring the BLEU score of our hypothesized translations against one or more reference translations. We also have an additional held-out translation set, the development set, which is employed by the MT system to train the weights of its log-linear model to maximize BLEU (Och 2003). We work with data sets for three different language pairs, examining French to English, Arabic to English, and Romanian to English tr"
J07-3002,2001.mtsummit-papers.68,0,0.0149733,"s towards measuring alignment quality in a way which is predictive of statistical machine translation performance. 1. Introduction Automatic word alignment (Brown et al. 1993) is a vital component of all statistical machine translation (SMT) approaches. There were a number of research papers presented from 2000 to 2005 at ACL, NAACL, HLT, COLING, WPT03, WPT05, and so forth, outlining techniques for attempting to increase word alignment quality. Despite this high level of interest, none of these techniques has been shown to result in a large gain in translation performance as measured by BLEU (Papineni et al. 2001) or any other metric. We find this lack of correlation between previous word alignment quality metrics and BLEU counterintuitive, because we and other researchers have measured this correlation in the context of building SMT systems that have benefited from using the BLEU metric in improving performance in open evaluations such as the NIST evaluations.1 We confirm experimentally that previous metrics do not predict BLEU well and develop a methodology for measuring alignment quality that is predictive of BLEU. We ∗ USC/ISI - Natural Language Group, 4676 Admiralty Way, Suite 1001, Marina del Rey"
J07-3002,C96-2141,0,0.961969,"Missing"
J07-3002,P02-1040,0,\N,Missing
J07-3002,P06-1065,0,\N,Missing
J07-3002,H05-1011,0,\N,Missing
J07-3002,J00-2004,0,\N,Missing
J07-3002,J08-4005,0,\N,Missing
J07-3002,H05-1010,0,\N,Missing
J13-1005,E06-2001,0,0.074573,"e derivational rule applied at the node in question. The last and biggest group of the pattern features is formed by the bilexical dependencies. They are based on the head word of the constituent node in question and its daughters. Versley and Rehbein (2009) have also introduced features that exploit statistical information gathered from an external data set and aim to resolve PP attachment ambiguity. Mutual information values were gathered on the association between nouns and immediately following prepositions, as well as between prepositions and closely following verbs on the DE-WaC corpus (Baroni and Kilgarriff 2006). These feature values were then used at NP→PP and VP→PP daughter attachments. A total of 2.7 million features ﬁred in the Tiger train. We ignored features ﬁring in less than ﬁve sentences for computational efﬁciency, resulting in 117,000 extremely sparse features. 7.3 Monolingual Reranking Experiments We rerank 100-best lists from BitPar (Schmid 2004), which uses the grammar extraction procedure and lexical resources introduced in Section 3. In each of the experiments we extracted the grammar from the Tiger train and used it to obtain the 100-best parses for the sentences of the evaluation co"
J13-1005,H91-1060,0,0.502125,"l reranking, which will be discussed later. 70 Fraser et al. Knowledge Sources for Parsing German to the same format as the gold standard trees by undoing Steps 2, 3, and 4 of Section 3.1. This conversion involves four steps: 1. Demarkovization removes all the auxiliary nodes introduced by markovization and raises their children to the next non-auxiliary node. 2. The added unary-branching nodes are eliminated. 3. The original grammatical function labels NK inside of NPs and PPs, and CJ inside of coordinated phrases, are restored. 4. All feature annotations are deleted. We use PARSEVAL scores (Black et al. 1991) and the standard evaluation tool evalb16 to compare the converted parse trees with the gold standard parse trees using labeled F-score. We report accuracies for all test sentences and not just sentences of length up to 40. We do not evaluate parsers with gold standard POS tags, but instead automatically infer them. These considerations make our evaluation setting as close to the real-world setting as possible. We report results for evaluations with and without grammatical functions. We report PARSEVAL scores with grammatical functions inside parentheses after the results using only basic cons"
J13-1005,A00-1031,0,0.0930958,"ecause some of the rules which are not markovized are also covered by markovization rules. 3.7 Dealing with Unknown Words and Unseen POS Tags BitPar includes a sophisticated POS guesser that uses several strategies to deal with unknown words and unseen POS tags of known words. Unknown words are divided into eight classes11 based on regular expressions that are manually deﬁned. These classes distinguish between lower-case words, capitalized words, all upper-case words, hyphenated words, numbers, and so forth. For each word class, BitPar builds a sufﬁx tree (Weischedel et al. 1993; Schmid 1995; Brants 2000) from the sufﬁxes of all words in the lexicon up to a length of 7. At each node of the sufﬁx tree, it sums up the conditional POS probabilities (given the word) over all known words with that sufﬁx. By summing POS probabilities rather than frequencies, all words have the same weight, which is appropriate here because we need to model the POS probabilities of infrequent words. BitPar computes POS probability estimates for each node using the sum of probabilities as a pseudo-frequency for each tag. The estimates are recursively smoothed with the Witten-Bell method using the smoothed POS probabil"
J13-1005,N10-1015,0,0.0304786,"Missing"
J13-1005,D08-1092,0,0.164596,"(+1.06) +0.78 (+1.00) +0.09 (+0.01) +0.78 (+0.70) The parse tree in Figure 6 demonstrates the value of bilingual features. It was produced by the monolingual reranker and it incorrectly combines the two adverbs aber and ebenso into an adverbial phrase and places this under the VP. The bilingual reranker instead attaches the two adverbs separately at the S level. The attachment to the S node indicates that the two adverbs modify the modal verb kann and not the full verb sagen. This is triggered by the feature POSPar2Prj. 8.3 Previous Work on Bitext Parsing Bitext parsing was also addressed by Burkett and Klein (2008). In that work, they use feature functions deﬁned on triples of (English parse tree, Chinese parse tree, alignment) which are combined in a log-linear model, much as we do. In later work (Burkett, Blitzer, and Klein 2010), they developed a uniﬁed joint model for solving the same problem using a weakly synchronized grammar. To train these models they use a small parallel Treebank that contains gold standard trees for parallel sentences in Chinese and English, whereas we only require gold standard trees for the language we are reranking. Another important difference is that Burkett and Klein (20"
J13-1005,P11-2037,0,0.0377588,"Missing"
J13-1005,P04-1082,0,0.0497864,"Missing"
J13-1005,P05-1022,0,0.827942,"at the gain of the two sets of reranking features (monolingual and bilingual) is additive, suggesting that they capture different types of information. The resulting parser is currently the best constituent parser for German (with or without bilingual features). In particular, we show that the baseline parser without reranking is competitive with the previous state of the art (the Berkeley parser) and that the re-ranking can add an important gain. 2. Previous Work Constituent parsing for English is well studied. The best generative constituent parsers are currently the Brown reranking parser (Charniak and Johnson 2005), the extension of this parser with self training by McClosky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCF"
J13-1005,P97-1003,0,0.510396,"es without a subject. We also mark conjunct clauses with the feature nosubj if they are neither headed by an imperative nor contain a child node with the grammatical function SB (subject) or EP (expletive). This is useful in order to correctly parse coordinations where the subject is dropped in the second conjunct. 3.6 Markovization The Tiger Treebank uses rather ﬂat structures where nodes have up to 25 child nodes. This causes sparse data problems because only some of the possible rules of that length actually appear in the training corpus. The sparse data problem is solved by markovization (Collins 1997; Klein and Manning 2003), which splits long rules into a set of shorter rules. The shorter rules generate the child nodes of the original rule one by one. First, the left siblings of the head child of the rule are generated from left to right, then the right siblings are generated from right to left. Finally, the head is generated. Figure 4 shows the markovization of the rule NP → NM NN PP PP. The auxiliary symbols that are used here encode information about the parent category, the head child, and previously generated children. Because all auxiliary symbols encode the head category, the head"
J13-1005,A92-1018,0,0.0352465,"Missing"
J13-1005,W06-2929,0,0.0602476,"Missing"
J13-1005,P03-1013,0,0.0390987,"generative constituent parsers are currently the Brown reranking parser (Charniak and Johnson 2005), the extension of this parser with self training by McClosky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previ"
J13-1005,P01-1024,0,0.0588643,"ment by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performance, but add more information"
J13-1005,P08-1109,0,0.0939797,"Missing"
J13-1005,W07-1203,0,0.0147603,"d parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performance, but add more information and achieve a larger improvement. We use the monolingual feature set of Versley and Rehbein in our reranker, but add further monolingual features as well as bilingu"
J13-1005,2008.amta-srw.2,0,0.0296618,"-HD VP-OC Man kann AVP-MO one can ADV-MO ADV-HD aber ebenso but just-as-well VVINF-HD , sagen say S-OC , KOUS-CP PPER-SB ADJD-PD VAFIN-HD dass sie anspruchsvoll sind that they demanding are Figure 6 Erroneous parse produced by the reranker using only monolingual features, which is corrected by bilingual features. The sentence means One can, however, just as well say that they are demanding. 81 Computational Linguistics Volume 39, Number 1 improve ranking of German BitPar parses in the held-out test sets, which is a form of self-training. Two other interesting studies in this area are those of Fossum and Knight (2008) and of Huang, Jiang, and Liu (2009). They improve English prepositional phrase attachment using features from a Chinese sentence. Unlike our approach, however, they do not require a Chinese syntactic parse as the word order in Chinese is sufﬁcient to unambiguously determine the correct attachment point of the prepositional phrase in the English sentence without using a Chinese syntactic parse. We know of no other work that has investigated to what extent monolingual and bilingual features in parse reranking are complementary. In particular, the work on bitext parsing by Burkett and Klein (200"
J13-1005,E09-1033,1,0.938949,"nominal head. The extraction of verbal heads is somewhat more complicated. In order to obtain the correct verbal head of a clause irrespective of the verb position (verb-ﬁrst, verbsecond, verb-ﬁnal), we extract all verbs that are dominated by the clause and a possibly empty sequence of VP-OC or VP-PD (statal passive) nodes and an optional VZ-HD node. Then we take the ﬁrst non-ﬁnite verb, or alternatively the ﬁrst ﬁnite verb if all verbs were ﬁnite. In order to avoid sparse data problems caused by the many different inﬂections of German verbs, we lemmatize the verbs. ¨ 21 In Fraser, Wang, and Schutze (2009) we used Minimum Error Rate Training. Once we made this change to maximum entropy the results on small feature sets became similar (details omitted). 22 An exception to this is that if a PP argument dominates a node of category PROAV-PH, it is considered a PROAV-PH argument. An example is the sentence Er [he] wartet [waits] (PP-OP (PROAV-PH darauf [for this]), (S-RE dass [that] sie [she] kommt [comes])). 74 Fraser et al. Knowledge Sources for Parsing German Table 2 Arguments used in extracted subcategorization frames. NP-SB, PN-SB, CNP-SB, S-SB, VP-SB NP-OA, PN-OA, CNP-OA NP-DA, PN-DA, CNP-DA"
J13-1005,N06-1024,0,0.0274491,"Missing"
J13-1005,W08-1007,0,0.160992,"sing is which type of parsing formalism to adopt, constituency or dependency. It is a widely held belief that dependency structures are better suited to represent syntactic analyses for morphologically rich languages because they allow non-projective structures (the equivalent of discontinuous constituents in constituency parsing). As Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. In fact, most state-of-the-art dependency parsers (McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al. 2010a) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step. Comparable post-processing techniques have been used in English constituency parsing (Gabbard, Marcus, and Kulick 2006; Schmid 2006; Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents and might work for other languages, as well. ¨ The overview paper of the Parsing German Shared Task (Kubler 2008) reports higher accuracies for detecting grammatical functions with dependency parsers than with constituent parsers, but"
J13-1005,W08-2122,0,0.027458,". The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performance, but add more information and achieve a larger improvement. We use the mon"
J13-1005,P08-1067,0,0.0386001,"ious state of the art (the Berkeley parser) and that the re-ranking can add an important gain. 2. Previous Work Constituent parsing for English is well studied. The best generative constituent parsers are currently the Brown reranking parser (Charniak and Johnson 2005), the extension of this parser with self training by McClosky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been deve"
J13-1005,D09-1127,0,0.0481369,"Missing"
J13-1005,J98-4004,0,0.233603,"s the chart as a large bit vector. This representation is memory efﬁcient and allows full parsing (without search space pruning) with large treebank grammars. BitPar is also quite fast because the basic parsing operations are parallelized by means of (single-instruction) and-operations on bitvectors. BitPar can either be used to compute the most likely parse (Viterbi parse), or the full set of parses in the form of a parse forest, or the n-best parse trees. 3.1 Grammar The grammar and lexicon used by our generative parser are extracted from the Tiger2 Treebank (Brants et al. 2002). Similar to Johnson (1998) and Klein and Manning (2003) we improve the accuracy of the unlexicalized parser by reﬁning the non-terminal symbols of the grammar to encode relevant contextual information. This reﬁnement weakens the strong independence assumptions of PCFGs and improves parsing accuracy. The extraction of the grammar and lexicon involves the following steps: 1. Discontinuous constituents are eliminated (Section 3.2). 2. Treebank annotations are transformed (Section 3.4) and augmented (Section 3.5). 3. Grammar rules, lexical rules, and their frequencies are extracted from the annotated parse trees. 4. The gr"
J13-1005,P03-1054,0,0.408779,"rge bit vector. This representation is memory efﬁcient and allows full parsing (without search space pruning) with large treebank grammars. BitPar is also quite fast because the basic parsing operations are parallelized by means of (single-instruction) and-operations on bitvectors. BitPar can either be used to compute the most likely parse (Viterbi parse), or the full set of parses in the form of a parse forest, or the n-best parse trees. 3.1 Grammar The grammar and lexicon used by our generative parser are extracted from the Tiger2 Treebank (Brants et al. 2002). Similar to Johnson (1998) and Klein and Manning (2003) we improve the accuracy of the unlexicalized parser by reﬁning the non-terminal symbols of the grammar to encode relevant contextual information. This reﬁnement weakens the strong independence assumptions of PCFGs and improves parsing accuracy. The extraction of the grammar and lexicon involves the following steps: 1. Discontinuous constituents are eliminated (Section 3.2). 2. Treebank annotations are transformed (Section 3.4) and augmented (Section 3.5). 3. Grammar rules, lexical rules, and their frequencies are extracted from the annotated parse trees. 4. The grammar is markovized (Section"
J13-1005,2005.mtsummit-papers.11,0,0.0116501,"to German, and sums all the span differences. It is measured in words. In addition to PPParentPrjWord we implement two bonus features, NonPPWord and NonPPPer. The former simply calculates the number of words that 79 Computational Linguistics Volume 39, Number 1 do not belong to PP phrases in the sentence, and the latter computes the non-PP proportion in a character-based fashion. These can be thought of as tunable parameters which adjust PPParentPrjWord to not disfavor large PPs. The other selected projection features are described in Table 4. Probabilistic Feature Functions. We use Europarl (Koehn 2005), from which we extract a parallel corpus of approximately 1.22 million sentence pairs, to estimate the probabilistic feature functions described in this section. We describe the feature PTag, despite the fact that it was not selected by the feature analysis, because several variations (described next) were selected. PTag measures tagging inconsistency based on estimating the probability for each English word that it has a particular POS tag, given the aligned German word’s POS tag. To avoid noisy feature values due to outliers and parse errors, we bound the value of PTag at 5.26 We use relati"
J13-1005,W06-1614,0,0.0820292,"Missing"
J13-1005,P04-1042,0,0.0790196,"Missing"
J13-1005,N06-1020,0,0.165602,"Missing"
J13-1005,P06-1043,0,0.0877529,"Missing"
J13-1005,E06-1011,0,0.0241518,"key question for MR&LC parsing is which type of parsing formalism to adopt, constituency or dependency. It is a widely held belief that dependency structures are better suited to represent syntactic analyses for morphologically rich languages because they allow non-projective structures (the equivalent of discontinuous constituents in constituency parsing). As Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. In fact, most state-of-the-art dependency parsers (McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al. 2010a) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step. Comparable post-processing techniques have been used in English constituency parsing (Gabbard, Marcus, and Kulick 2006; Schmid 2006; Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents and might work for other languages, as well. ¨ The overview paper of the Parsing German Shared Task (Kubler 2008) reports higher accuracies for detecting grammatical functions with dependency parsers than with con"
J13-1005,W98-0509,0,0.0308318,"roduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performa"
J13-1005,N07-1051,0,0.0190713,"information. The resulting parser is currently the best constituent parser for German (with or without bilingual features). In particular, we show that the baseline parser without reranking is competitive with the previous state of the art (the Berkeley parser) and that the re-ranking can add an important gain. 2. Previous Work Constituent parsing for English is well studied. The best generative constituent parsers are currently the Brown reranking parser (Charniak and Johnson 2005), the extension of this parser with self training by McClosky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Wo"
J13-1005,W08-1005,0,0.136381,"ge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein a"
J13-1005,W06-1608,0,0.0290991,"for German previously by Versley and Rehbein (2009). We show that the richer subcategorization-based framework for monolingual reranking is effective; it has comparable performance to the sparse feature set—moreover, they complement each other. For bilingual reranking, we present our approach to bitext parsing, where a German parse is found that minimizes syntactic divergence with an automatically generated parse of its English translation. We pursue this approach for a number of reasons. First, one limiting factor for syntactic approaches to statistical machine translation is parse quality (Quirk and Corston-Oliver 2006). Improved parses of bitext should result in improved machine translation. Second, as more and more texts are available in several languages, it will be increasingly the case that a text to be parsed is itself part of a bitext. Third, we hope that the improved parses of bitext can serve as higher quality training data for improving monolingual parsing using a process similar to self-training (McClosky, Charniak, and Johnson 2006a). We show that the three different knowledge sources we use in this paper (lexical knowledge, monolingual features, and bilingual features) are valuable separately. W"
J13-1005,P05-1034,0,0.0754638,"Missing"
J13-1005,W08-1006,0,0.02696,"tent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexica"
J13-1005,N10-1049,0,0.0149329,"search question.3 Constituent parses often provide more information than dependency parses. An example is the coordination ambiguity in old men and women versus old men and children. The correct constituent parse for the ﬁrst expression contains a coordination at the noun level whereas the parse for the second expression coordinates at the level of NPs. The dependency structures of both expressions, on the other hand, are usually identical and thus unable to reﬂect the fact that old modiﬁes women but not children. It is possible, in principle, to encode the difference in dependency trees (cf. Rambow 2010), 2 This is due to how the evalb tool used to calculate PARSEVAL works. If a constituent is not perfectly matched, the grammatical function is considered to be wrong, even if there was a partial match (at the token level). This is not a problem with dependency-based evaluation. For further discussion of the PARSEVAL metric and dependency-based evaluation see, for example, Rehbein and van Genabith (2007) and Tsarfaty, Nivre, and Andersson (2012). 3 Two possible solutions are to use TedEval (Tsarfaty, Nivre, and Andersson 2012), or to conduct an analysis of grammatical functions at the token lev"
J13-1005,W07-2460,0,0.0876378,"Missing"
J13-1005,C04-1056,0,0.0313236,"ky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to"
J13-1005,C04-1024,1,0.911442,"y and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performance, but add more information and achieve a larger improvement. We use the monolingual feature set of Versley and Rehbein in our reranker, but add further monolingual features as well as bilingual features. 3. Generative Parsing Framework Our generative parser is an unlexicalized PCFG parser which is based on the BitPar parser (Schmid 2004). BitPar uses a fast bitvector-based implementation of the wellknown Cocke-Younger-Kasami algorithm and stores the chart as a large bit vector. This representation is memory efﬁcient and allows full parsing (without search space pruning) with large treebank grammars. BitPar is also quite fast because the basic parsing operations are parallelized by means of (single-instruction) and-operations on bitvectors. BitPar can either be used to compute the most likely parse (Viterbi parse), or the full set of parses in the form of a parse forest, or the n-best parse trees. 3.1 Grammar The grammar and l"
J13-1005,P06-1023,1,0.822361,"tuents in constituency parsing). As Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. In fact, most state-of-the-art dependency parsers (McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al. 2010a) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step. Comparable post-processing techniques have been used in English constituency parsing (Gabbard, Marcus, and Kulick 2006; Schmid 2006; Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents and might work for other languages, as well. ¨ The overview paper of the Parsing German Shared Task (Kubler 2008) reports higher accuracies for detecting grammatical functions with dependency parsers than with constituent parsers, but the direct comparison is not fair as it required phrase boundaries to be correct on the constituent side while the tokens were the unit of evaluation on the dependency side.2 How to carry out an absolutely fair comparison of the two representations is still an open research question.3 Consti"
J13-1005,schmid-etal-2004-smor,1,0.827637,"Missing"
J13-1005,C10-2129,0,0.260946,"parsing formalism to adopt, constituency or dependency. It is a widely held belief that dependency structures are better suited to represent syntactic analyses for morphologically rich languages because they allow non-projective structures (the equivalent of discontinuous constituents in constituency parsing). As Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. In fact, most state-of-the-art dependency parsers (McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al. 2010a) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step. Comparable post-processing techniques have been used in English constituency parsing (Gabbard, Marcus, and Kulick 2006; Schmid 2006; Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents and might work for other languages, as well. ¨ The overview paper of the Parsing German Shared Task (Kubler 2008) reports higher accuracies for detecting grammatical functions with dependency parsers than with constituent parsers, but the direct comparis"
J13-1005,P10-1111,0,0.0405122,"Missing"
J13-1005,P08-1066,0,0.0270618,"Missing"
J13-1005,E12-1006,0,0.13257,"Missing"
J13-1005,W10-1401,0,0.107052,"Missing"
J13-1005,C10-1123,0,0.0139946,"ion, acting together. The most natural way of doing this in a language like German is to perform this integration of the two knowledge sources directly as part of parsing. We do this by annotating constituent labels with grammatical function where appropriate. In contrast with syntactic parses of strongly conﬁgurational languages like English, syntactic parses of German are not useful for most tasks without having 4 We do note, however, that there are a few translation systems which use a dependency representation directly (e.g., Quirk, Menezes, and Cherry 2005; Shen, Xu, and Weischedel 2008; Tu et al. 2010). 61 Computational Linguistics Volume 39, Number 1 grammatical functions indicated. It is not even possible to access the basic subcategorization of the verb (such as determining the subject) without grammatical functions. We argue that MR&LC languages like German should always be evaluated on labelscum-grammatical-function. Our last main contribution in this paper concerns the fact that we believe that MR&LC languages give rise to more ambiguity than languages that are predominantly conﬁgurational or morphological. As an example consider the German sentence “Die [the] Katze [cat] jagt [hunts]"
J13-1005,W09-3820,0,0.334604,"disambiguation. We believe that this distinguishing characteristic of MR&LC languages makes it necessary to tap additional knowledge sources. In this paper, we look at two such knowledge sources: monolingual reranking (which captures global properties of well-formed parses for additional disambiguation) and bilingual reranking (which exploits parallel text in a different language for disambiguation). For monolingual reranking, we deﬁne a novel set of rich features based on subcategorization frames. We compare our compact feature set with a sparse feature set designed for German previously by Versley and Rehbein (2009). We show that the richer subcategorization-based framework for monolingual reranking is effective; it has comparable performance to the sparse feature set—moreover, they complement each other. For bilingual reranking, we present our approach to bitext parsing, where a German parse is found that minimizes syntactic divergence with an automatically generated parse of its English translation. We pursue this approach for a number of reasons. First, one limiting factor for syntactic approaches to statistical machine translation is parse quality (Quirk and Corston-Oliver 2006). Improved parses of b"
J13-1005,J93-2006,0,0.218488,"re spurious ambiguities. They arise because some of the rules which are not markovized are also covered by markovization rules. 3.7 Dealing with Unknown Words and Unseen POS Tags BitPar includes a sophisticated POS guesser that uses several strategies to deal with unknown words and unseen POS tags of known words. Unknown words are divided into eight classes11 based on regular expressions that are manually deﬁned. These classes distinguish between lower-case words, capitalized words, all upper-case words, hyphenated words, numbers, and so forth. For each word class, BitPar builds a sufﬁx tree (Weischedel et al. 1993; Schmid 1995; Brants 2000) from the sufﬁxes of all words in the lexicon up to a length of 7. At each node of the sufﬁx tree, it sums up the conditional POS probabilities (given the word) over all known words with that sufﬁx. By summing POS probabilities rather than frequencies, all words have the same weight, which is appropriate here because we need to model the POS probabilities of infrequent words. BitPar computes POS probability estimates for each node using the sum of probabilities as a pseudo-frequency for each tag. The estimates are recursively smoothed with the Witten-Bell method usin"
J13-1005,W08-1008,0,\N,Missing
J13-1005,P02-1018,0,\N,Missing
J13-1005,J05-1003,0,\N,Missing
J15-2001,W13-2257,0,0.0166003,"ight words lets the translation accuracy drop because of search errors (Koehn et al. 2005). The use of a hard limit is undesirable for German–English and similar language pairs with significantly different syntactic structures. Several researchers have tried to address this problem. Moore and Quirk (2007) proposed improved future cost estimation to enable higher distortion limits in phrasal MT. Green, Galley, and Manning (2010) additionally proposed discriminative distortion models to achieve better translation accuracy than the baseline phrase-based system for a distortion limit of 15 words. Bisazza and Federico (2013) recently proposed a novel method to dynamically select which longrange reorderings to consider during the hypothesis extension process in a phrasebased decoder and showed an improvement in a German–English task by increasing the distortion limit to 18. Spurious Phrasal Segmentation. A problem with the phrase-based model is that there is no unique correct phrasal segmentation of a sentence. Therefore, all possible ways of segmenting a bilingual sentence consistent with the word alignment are learned and used. This leads to two problems: (i) phrase frequencies are obtained by counting all possi"
J15-2001,J93-2003,0,0.090203,"tics Volume 41, Number 2 better than state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems (Ncode) on standard translation tasks. We compare the reordering component of the OSM to the Moses lexical reordering model by integrating it into Moses. Our results show that OSM outperforms lexicalized reordering on all translation tasks. The translation quality is shown to be improved further by learning generalized representations with a POS-based OSM. 1. Introduction Statistical Machine Translation (SMT) advanced near the beginning of the century from word-based models (Brown et al. 1993) towards more advanced models that take contextual information into account. Phrase-based (Koehn, Och, and Marcu 2003; Och and Ney 2004) and N-gram-based (Casacuberta and Vidal 2004; Marino ˜ et al. 2006) models are two instances of such frameworks. Although the two models have some common properties, they are substantially different. The present work is a step towards combining the benefits and remedying the flaws of these two frameworks. Phrase-based systems have a simple but effective mechanism that learns larger chunks of translation called bilingual phrases.1 Memorizing larger units enabl"
J15-2001,N10-2003,0,0.0347044,"Missing"
J15-2001,N13-1003,0,0.0149619,"ccount how previous words were translated and reordered. Although such an independence assumption is useful to reduce sparsity, it is overly generalizing and does not help to disambiguate good reorderings from the bad ones. Moreover, a vast majority of extracted phrases are singletons and the corresponding probability of orientation given phrase-pair estimates are based on a single observation. Due to sparsity, the model falls back to use one-word phrases instead, the orientation of which is ambiguous and can only be judged based on context that is ignored. This drawback has been addressed by Cherry (2013) by using sparse features for reordering models. Hard Distortion Limit. The lexicalized reordering model fails to filter out bad largescale reorderings effectively (Koehn 2010). A hard distortion limit is therefore required during decoding in order to produce good translations. A distortion limit beyond eight words lets the translation accuracy drop because of search errors (Koehn et al. 2005). The use of a hard limit is undesirable for German–English and similar language pairs with significantly different syntactic structures. Several researchers have tried to address this problem. Moore and"
J15-2001,J07-2003,0,0.0395574,"mework. We also use four supportive features: the Gap, Open Gap, Gap-distance, and Deletion counts, as described earlier (see Section 3.6.1). 6.1 Baseline Our Moses (Koehn et al. 2007) baseline systems are based on the setup described in Durrani et al. (2013b). We trained our systems with the following settings: maximum sentence length 80, grow-diag-final and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield 2011) used at runtime, distortion limit of 6, minimum Bayes-risk decoding (Kumar and Byrne 2004), cube pruning (Huang and Chiang 2007), and the no-reordering-over-punctuation heuristic. We used factored models (Koehn and Hoang 2007), for German–English and English–German. We trained the lexicalized reordering model (Koehn et al. 2005) with msd-bidirectional-fe settings. 6.2 Results Table 5 shows that the OSM results in higher gains than the lexicalized reordering model on top of a plain phrase-based baseline (Pb). The average improvement obtained using the lexicalized reordering model (Pblex ) over the baseline (Pb) is 0.50. In comparison, the average improvement obtained by using the OSM (Pbosm ) over the baseline (Pb) is 0"
J15-2001,N07-2035,0,0.0710623,"Missing"
J15-2001,2005.iwslt-1.25,0,0.0712731,"taining content words (which are less frequent than functional words). For example, the alignment link hinunterschuttete ¨ – ‘down’ is deleted and only the link hinunterschuttete ¨ – ‘poured’ is retained because ‘down’ occurs more frequently than ‘poured’. Crego and Yvon (2009) used split tokens to deal with this phenomenon. For MTU-based decoding we also need to deal with unaligned target words. For each unaligned target word, we determine the (left or right) neighbor that it appears more frequently with and align it with the same source word as this neighbor. Crego, de Gispert, and Marino ˜ (2005) and Marino ˜ et al. (2006) instead used lexical probabilities p( f |e) obtained from IBM Model 1 (Brown et al. 1993) to decide whether to attach left or right. A more sophisticated strategy based on part-of-speech entropy was proposed by Gispert and Marino ˜ (2006). 4.2 Initial Evaluation We evaluated our systems on German-to-English, French-to-English, and Spanish-toEnglish news translation for the purpose of development and evaluation. We used data from the eighth version of the Europarl Corpus and the News Commentary made available for the translation task of the Eighth Workshop on Statist"
J15-2001,2007.mtsummit-papers.16,0,0.0557062,"ce 164 Durrani et al. Operation Sequence Model versa. Notice how the reordering decision is triggered by the translation decision in the example. The probability of a gap insertion operation after the generation of the auxiliaries wurden ¨ – ‘would’ will be high because reordering is necessary in order to move the second part of the German verb complex (stimmen) to its correct position at the end of the clause. Complex reorderings can be achieved by inserting multiple gaps and/or recursively inserting a gap within a gap. Consider the generation of the example in Figure 3 (borrowed from Chiang [2007]). The generation of this bilingual sentence pair proceeds as follows: Generate(Aozhou, Australia) Generate(shi, is) Insert Gap Generate(zhiyi, one of ) At this point, the (partial) Chinese and English sentences look like this: Aozhou shi zhiyi ↓ Australia is one of The translator now jumps back and recursively inserts a gap inside of the gap before continuing translation: Jump Back (1) Insert Gap Generate(shaoshu, the few) Generate(guojia, countries) Aozhou shi shaoshu guojia ↓ zhiyi Australia is one of the few countries The rest of the sentence pair is generated as follows: Jump Back (1) Ins"
J15-2001,2009.eamt-1.10,0,0.0196584,"aligned and discontinuous targets. If a source word is aligned with multiple target words that are not consecutive, first the link to the least frequent target word is identified, and the group (consecutive adjacent words) of links containing this word is retained while the others are deleted. The intuition here is to keep the alignments containing content words (which are less frequent than functional words). For example, the alignment link hinunterschuttete ¨ – ‘down’ is deleted and only the link hinunterschuttete ¨ – ‘poured’ is retained because ‘down’ occurs more frequently than ‘poured’. Crego and Yvon (2009) used split tokens to deal with this phenomenon. For MTU-based decoding we also need to deal with unaligned target words. For each unaligned target word, we determine the (left or right) neighbor that it appears more frequently with and align it with the same source word as this neighbor. Crego, de Gispert, and Marino ˜ (2005) and Marino ˜ et al. (2006) instead used lexical probabilities p( f |e) obtained from IBM Model 1 (Brown et al. 1993) to decide whether to attach left or right. A more sophisticated strategy based on part-of-speech entropy was proposed by Gispert and Marino ˜ (2006). 4.2"
J15-2001,C10-2023,0,0.0480813,"Missing"
J15-2001,N13-1001,1,0.781265,"the subsequent parts of discontinuous target cepts to appear after the first word of the cept. During decoding we use phrase-internal alignments to hypothesize such a linearization. This is done only for the estimation of the OSM, and the target for all other purposes is generated in its original order. This heuristic allows us to deal with target discontinuities without extending the operation sequence model in complicated ways. It results in better BLEU accuracy in comparison with the post-editing of the alignments method described in Section 4.1. For details and empirical results refer to Durrani et al. (2013a) (see Table 2 therein, compare Rows 4 and 5). Note that the OSM, like the discontinuous phrase-based model (Galley and Manning 2010), allows all possible geometries as shown in Figure 7. However, because our decoder only uses continuous phrases, we cannot hypothesize (ii) and (iii) unless they appear inside of a phrase. But our model could be integrated into a discontinuous phrase-based system to overcome this limitation. 6. Further Comparative Experiments Our model, like the reordering models (Tillmann and Zhang 2005; Galley and Manning 2008) used in phrase-based decoders, is lexicalized. H"
J15-2001,P13-2071,1,0.853331,"the subsequent parts of discontinuous target cepts to appear after the first word of the cept. During decoding we use phrase-internal alignments to hypothesize such a linearization. This is done only for the estimation of the OSM, and the target for all other purposes is generated in its original order. This heuristic allows us to deal with target discontinuities without extending the operation sequence model in complicated ways. It results in better BLEU accuracy in comparison with the post-editing of the alignments method described in Section 4.1. For details and empirical results refer to Durrani et al. (2013a) (see Table 2 therein, compare Rows 4 and 5). Note that the OSM, like the discontinuous phrase-based model (Galley and Manning 2010), allows all possible geometries as shown in Figure 7. However, because our decoder only uses continuous phrases, we cannot hypothesize (ii) and (iii) unless they appear inside of a phrase. But our model could be integrated into a discontinuous phrase-based system to overcome this limitation. 6. Further Comparative Experiments Our model, like the reordering models (Tillmann and Zhang 2005; Galley and Manning 2008) used in phrase-based decoders, is lexicalized. H"
J15-2001,W13-2212,1,0.943997,"the subsequent parts of discontinuous target cepts to appear after the first word of the cept. During decoding we use phrase-internal alignments to hypothesize such a linearization. This is done only for the estimation of the OSM, and the target for all other purposes is generated in its original order. This heuristic allows us to deal with target discontinuities without extending the operation sequence model in complicated ways. It results in better BLEU accuracy in comparison with the post-editing of the alignments method described in Section 4.1. For details and empirical results refer to Durrani et al. (2013a) (see Table 2 therein, compare Rows 4 and 5). Note that the OSM, like the discontinuous phrase-based model (Galley and Manning 2010), allows all possible geometries as shown in Figure 7. However, because our decoder only uses continuous phrases, we cannot hypothesize (ii) and (iii) unless they appear inside of a phrase. But our model could be integrated into a discontinuous phrase-based system to overcome this limitation. 6. Further Comparative Experiments Our model, like the reordering models (Tillmann and Zhang 2005; Galley and Manning 2008) used in phrase-based decoders, is lexicalized. H"
J15-2001,C14-1041,1,0.834353,". It also shows the model sizes when filtered on news-test2013. A similar amount of reduction could be achieved by applying filtering to the OSMs following the language model filtering described by Heafield and Lavie (2010). 15 We also tried to amalgamate lexically driven OSM and generalized OSMs into a single model rather than using these as separate features. However, this attempt was unsuccessful (See Durrani et al. [2014] for details). 16 We also found using morphological tags and automatic word clusters to be useful in our recent IWSLT evaluation campaign (Birch, Durrani, and Koehn 2013; Durrani et al. 2014). 17 The code for the OSM in Moses can be greatly optimized but requires major modifications to source and target phrase classes in Moses. 182 Durrani et al. Operation Sequence Model Table 8 Wall-clock decoding times (in minutes) on WMT-13. Into English From English Pblex Pblex+osm Pblex Pblex+osm DE FR ES 61 108 111 88 Δ 27 163 Δ 55 142 Δ 31 143 113 74 158 Δ 15 154 Δ 41 109 Δ 35 Avg 93 131 Δ 38 110 140 Δ 30 Table 9 Data sizes (in number of sentences) and memory usage (in giga-bytes). Columns: Phrase translation and lexicalized reordering tables give overall model sizes/sizes when filtered on"
J15-2001,P11-1105,1,0.82518,"Missing"
J15-2001,D08-1089,0,0.42418,"d tasks of translating German–English, French–English, and Spanish–English pairs. Our integration gives statistically significant improvements over submission quality baseline systems. Section 7 concludes. 2. Previous Work 2.1 Phrase-Based SMT The phrase-based model (Koehn et al. 2003; Och and Ney 2004) segments a bilingual sentence pair into phrases that are continuous sequences of words. These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang 2005) or block of phrases (Galley and Manning 2008). Phrase-based models memorize local dependencies such as short reorderings, translations of idioms, and the insertion and deletion of words sensitive to local context. Phrase-based systems, however, have the following drawbacks. Handling of Non-local Dependencies. Phrase-based SMT models dependencies between words and their translations inside of a phrase well. However, dependencies across phrase boundaries are ignored because of the strong phrasal independence assumption. Consider the bilingual sentence pair shown in Figure 1(a). Reordering of the German word stimmen is internal to the phras"
J15-2001,N10-1129,0,0.038666,"Missing"
J15-2001,W11-2123,0,0.0840724,"extracting the MTUs within the phrase pair and using phrase internal alignments. The OSM is used as a feature in the log-linear framework. We also use four supportive features: the Gap, Open Gap, Gap-distance, and Deletion counts, as described earlier (see Section 3.6.1). 6.1 Baseline Our Moses (Koehn et al. 2007) baseline systems are based on the setup described in Durrani et al. (2013b). We trained our systems with the following settings: maximum sentence length 80, grow-diag-final and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield 2011) used at runtime, distortion limit of 6, minimum Bayes-risk decoding (Kumar and Byrne 2004), cube pruning (Huang and Chiang 2007), and the no-reordering-over-punctuation heuristic. We used factored models (Koehn and Hoang 2007), for German–English and English–German. We trained the lexicalized reordering model (Koehn et al. 2005) with msd-bidirectional-fe settings. 6.2 Results Table 5 shows that the OSM results in higher gains than the lexicalized reordering model on top of a plain phrase-based baseline (Pb). The average improvement obtained using the lexicalized reordering model (Pblex ) over"
J15-2001,P07-1019,0,0.00922897,"linear framework. We also use four supportive features: the Gap, Open Gap, Gap-distance, and Deletion counts, as described earlier (see Section 3.6.1). 6.1 Baseline Our Moses (Koehn et al. 2007) baseline systems are based on the setup described in Durrani et al. (2013b). We trained our systems with the following settings: maximum sentence length 80, grow-diag-final and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield 2011) used at runtime, distortion limit of 6, minimum Bayes-risk decoding (Kumar and Byrne 2004), cube pruning (Huang and Chiang 2007), and the no-reordering-over-punctuation heuristic. We used factored models (Koehn and Hoang 2007), for German–English and English–German. We trained the lexicalized reordering model (Koehn et al. 2005) with msd-bidirectional-fe settings. 6.2 Results Table 5 shows that the OSM results in higher gains than the lexicalized reordering model on top of a plain phrase-based baseline (Pb). The average improvement obtained using the lexicalized reordering model (Pblex ) over the baseline (Pb) is 0.50. In comparison, the average improvement obtained by using the OSM (Pbosm ) over the baseline (Pb) is 0"
J15-2001,koen-2004-pharaoh,0,0.186183,"used in our model is the Source Gap Width. This feature only applies in the case of a discontinuous translation unit and computes the distance between the words of a gappy cept. Let f = f1 . . . , fi , . . . , fn be a gappy source cept where xi is the index of the ith source word in the cept f . The value of the gap-width penalty is calculated as: wj = n  xi − xi−1 − 1 i=2 4. MTU-Based Search We explored two decoding strategies in this work. Our first decoder complements the model and only uses minimal translation units in left-to-right stack-based decoding, similar to that used in Pharaoh (Koehn 2004a). The overall process can be roughly divided into the following steps: (i) extraction of translation units, (ii) future cost estimation, (iii) hypothesis extension, and (iv) recombination and pruning. The last two steps are repeated iteratively until all the words in the source sentence have been translated. Our hypotheses maintain the index of the last source word covered (j), the position of the right-most source word covered so far (Z), the number of open gaps, the number of gaps so far inserted, the previously generated operations, the generated target string, and the accumulated values"
J15-2001,W04-3250,1,0.372367,"Missing"
J15-2001,J10-4005,0,0.083559,"ambiguate good reorderings from the bad ones. Moreover, a vast majority of extracted phrases are singletons and the corresponding probability of orientation given phrase-pair estimates are based on a single observation. Due to sparsity, the model falls back to use one-word phrases instead, the orientation of which is ambiguous and can only be judged based on context that is ignored. This drawback has been addressed by Cherry (2013) by using sparse features for reordering models. Hard Distortion Limit. The lexicalized reordering model fails to filter out bad largescale reorderings effectively (Koehn 2010). A hard distortion limit is therefore required during decoding in order to produce good translations. A distortion limit beyond eight words lets the translation accuracy drop because of search errors (Koehn et al. 2005). The use of a hard limit is undesirable for German–English and similar language pairs with significantly different syntactic structures. Several researchers have tried to address this problem. Moore and Quirk (2007) proposed improved future cost estimation to enable higher distortion limits in phrasal MT. Green, Galley, and Manning (2010) additionally proposed discriminative d"
J15-2001,2005.iwslt-1.8,1,0.753813,"Missing"
J15-2001,D07-1091,1,0.765644,"Missing"
J15-2001,N03-1017,1,0.0601065,"information available in phrases can be used to improve the search performance and translation quality. Finally, we probe whether integrating our model into the phrase-based SMT framework addresses the mentioned drawbacks and improves translation quality. Section 6 provides an empirical evaluation of our integration on six standard tasks of translating German–English, French–English, and Spanish–English pairs. Our integration gives statistically significant improvements over submission quality baseline systems. Section 7 concludes. 2. Previous Work 2.1 Phrase-Based SMT The phrase-based model (Koehn et al. 2003; Och and Ney 2004) segments a bilingual sentence pair into phrases that are continuous sequences of words. These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang 2005) or block of phrases (Galley and Manning 2008). Phrase-based models memorize local dependencies such as short reorderings, translations of idioms, and the insertion and deletion of words sensitive to local context. Phrase-based systems, however, have the following drawbacks. Handling of Non-local Dependenc"
J15-2001,N04-1022,0,0.17139,"Missing"
J15-2001,J06-4004,0,0.0271931,"Missing"
J15-2001,2007.mtsummit-papers.43,0,0.0235298,"rry (2013) by using sparse features for reordering models. Hard Distortion Limit. The lexicalized reordering model fails to filter out bad largescale reorderings effectively (Koehn 2010). A hard distortion limit is therefore required during decoding in order to produce good translations. A distortion limit beyond eight words lets the translation accuracy drop because of search errors (Koehn et al. 2005). The use of a hard limit is undesirable for German–English and similar language pairs with significantly different syntactic structures. Several researchers have tried to address this problem. Moore and Quirk (2007) proposed improved future cost estimation to enable higher distortion limits in phrasal MT. Green, Galley, and Manning (2010) additionally proposed discriminative distortion models to achieve better translation accuracy than the baseline phrase-based system for a distortion limit of 15 words. Bisazza and Federico (2013) recently proposed a novel method to dynamically select which longrange reorderings to consider during the hypothesis extension process in a phrasebased decoder and showed an improvement in a German–English task by increasing the distortion limit to 18. Spurious Phrasal Segmenta"
J15-2001,W11-2124,0,0.297085,"odel to the OSM and to see whether we can improve the performance further by using both models together. Our integration of the OSM into Moses gave a statistically significant improvement over a competitive baseline system in most cases. In order to assess the contribution of improved reordering versus the contribution of better modeling with MTUs in the OSM-augmented Moses system, we removed the reordering operations from the stream of operations. This is equivalent to integrating the conventional N-gram tuple sequence model (Marino ˜ et al. 2006) into a phrasebased decoder, as also tried by Niehues et al. (2011). Small gains were observed in most cases, showing that much of the improvement obtained by the OSM is due to better reordering. Generalized Operation Sequence Model. The primary strength of the OSM over the lexicalized reordering model is its ability to take advantage of the wider contextual information. In an error analysis we found that the lexically driven OSM often falls back to very small context sizes because of data sparsity. We show that this problem can be addressed by learning operation sequences over generalized representations such as POS tags. The article is organized into seven"
J15-2001,P03-1021,0,0.10251,"nments. The corpus conversion algorithm (Algorithm 1) maps each bilingual sentence pair given its alignment into a unique sequence of operations deterministically, thus maintaining a 1-to-1 correspondence. This property of the model is useful because it addresses the spurious phrasal segmentation problem in phrase-based models. A phrase-based model assigns different scores to a derivation based on which phrasal segmentation is chosen. Unlike this, the OSM assigns only one score because the model does not suffer from spurious ambiguity. 3.6.1 Discriminative Model. We use a log-linear approach (Och 2003) to make use of standard features along with several novel features that we introduce to improve endto-end accuracy. We search for a target string E that maximizes a linear combination of feature functions: Eˆ = arg max E ⎧ J ⎨ ⎩ j=1 λj hj (F, E) ⎫ ⎬ ⎭ where λj is the weight associated with the feature hj (F, E). Apart from the OSM and standard features such as target-side language model, length bonus, distortion limit, and IBM lexical features (Koehn, Och, and Marcu 2003), we used the following new features: Deletion Penalty. Deleting a source word (Generate Source Only (X)) is a common oper"
J15-2001,J03-1002,0,0.0268454,"4.2 Initial Evaluation We evaluated our systems on German-to-English, French-to-English, and Spanish-toEnglish news translation for the purpose of development and evaluation. We used data from the eighth version of the Europarl Corpus and the News Commentary made available for the translation task of the Eighth Workshop on Statistical Machine Translation.7 The bilingual corpora contained roughly 2M bilingual sentence pairs, which we obtained by concatenating news commentary (≈ 184K sentences) and Europarl for the estimation of the translation model. Word alignments were generated with GIZA++ (Och and Ney 2003), using the grow-diag-final-and heuristic8 (Koehn et al. 2005). All data are lowercased, and we use the Moses tokenizer. We took news-test-2008 as the dev set for optimization and news-test 2009-2012 for testing. The feature weights are tuned with Z-MERT (Zaidan 2009). 4.2.1 Baseline Systems. We compared our system with (i) Moses9 (Koehn et al. 2007), (ii) Phrasal10 (Cer et al. 2010), and (iii) Ncode11 (Crego, Yvon, and Marino ˜ 2011). We used 7 http://www.statmt.org/wmt13/translation-task.html 8 We also tested other symmetrization heuristics such as “Union” and “Intersection” but found the GD"
J15-2001,J04-4002,0,0.218255,"rd translation tasks. We compare the reordering component of the OSM to the Moses lexical reordering model by integrating it into Moses. Our results show that OSM outperforms lexicalized reordering on all translation tasks. The translation quality is shown to be improved further by learning generalized representations with a POS-based OSM. 1. Introduction Statistical Machine Translation (SMT) advanced near the beginning of the century from word-based models (Brown et al. 1993) towards more advanced models that take contextual information into account. Phrase-based (Koehn, Och, and Marcu 2003; Och and Ney 2004) and N-gram-based (Casacuberta and Vidal 2004; Marino ˜ et al. 2006) models are two instances of such frameworks. Although the two models have some common properties, they are substantially different. The present work is a step towards combining the benefits and remedying the flaws of these two frameworks. Phrase-based systems have a simple but effective mechanism that learns larger chunks of translation called bilingual phrases.1 Memorizing larger units enables the phrase-based model to learn local dependencies such as short-distance reorderings, idiomatic collocations, and insertions and del"
J15-2001,P05-1069,0,0.175007,"l evaluation of our integration on six standard tasks of translating German–English, French–English, and Spanish–English pairs. Our integration gives statistically significant improvements over submission quality baseline systems. Section 7 concludes. 2. Previous Work 2.1 Phrase-Based SMT The phrase-based model (Koehn et al. 2003; Och and Ney 2004) segments a bilingual sentence pair into phrases that are continuous sequences of words. These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang 2005) or block of phrases (Galley and Manning 2008). Phrase-based models memorize local dependencies such as short reorderings, translations of idioms, and the insertion and deletion of words sensitive to local context. Phrase-based systems, however, have the following drawbacks. Handling of Non-local Dependencies. Phrase-based SMT models dependencies between words and their translations inside of a phrase well. However, dependencies across phrase boundaries are ignored because of the strong phrasal independence assumption. Consider the bilingual sentence pair shown in Figure 1(a). Reordering of th"
J15-2001,P11-1086,0,0.0241791,"ns over a very competitive Moses baseline system. We showed that considering both translation and reordering context is important and ignoring reordering context results in a significant reduction in the performance. We also showed that an OSM based on surface forms suffers from data sparsity and that an OSM based on a generalized representation with part-of-speech tags improves the translation quality by considering a larger context. In the future we would like to study whether the insight of using minimal units for modeling and search based on composed rules would hold for hierarchical SMT. Vaswani et al. (2011) recently showed that a Markov model over the derivation history of minimal rules can obtain the same translation quality as using grammars formed with composed rules, which we believe is quite promising. Acknowledgments We would like to thank the anonymous reviewers and Andreas Maletti and Franc¸ois Yvon for their helpful feedback and suggestions. The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007-2013) under grant agreements 287658 (EU-Bridge) and 287688 (MateCat). Alexander Fraser was funded by Deutsche Forschungsgemeinsc"
J15-2001,N13-1002,0,0.0122981,"(TSM) of Marino ˜ et al. (2006), except that we use phrase-internal reordering rather than POS-based rewrite rules to do the source linearization. Table 6 shows an average improvement of just 0.13 on top of the baseline phrase-based system with lexicalized reordering, which is much lower than the 0.46 points obtained with the full operation sequence model. Bilingual translation models (without reordering) have been integrated into phrase-based systems before, either inside the decoder (Niehues et al. 2011) or to rerank the N-best candidate translations in the output of a phrase-based system (Zhang et al. 2013). Both groups reported improvements of similar magnitude when using a targetorder left-to-right TSM model for German–English and French–English translation with shared task data, but higher gains on other data sets and language pairs. Zhang et al. (2013) showed further gains by combining models with target and source left-to-right and right-to-left orders. The assumption of generating the target in monotonic order is a weakness of our work that can be addressed following Zhang et al. (2013). By generating MTUs in source order and allowing gaps and jumps on the target side, the model will be ab"
J15-2001,N10-1140,0,\N,Missing
J15-2001,2006.iwslt-evaluation.17,0,\N,Missing
J15-2001,P07-2045,1,\N,Missing
J15-2001,J04-2004,0,\N,Missing
J15-2001,2014.iwslt-evaluation.6,1,\N,Missing
J15-2001,2013.iwslt-evaluation.3,1,\N,Missing
J17-2003,J84-3009,0,0.122732,"Missing"
J17-2003,2012.iwslt-papers.6,0,0.0419685,"Missing"
J17-2003,W10-2407,0,0.0148307,"threshold are extracted (Jiampojamarn et al. 2010; Noeman and Madkour 2010; Sajjad et al. 2011). Supervised transliteration mining systems (Nabende 2010; Noeman and Madkour 2010; El-Kahki et al. 2011) make use of an initial list of transliteration pairs that is automatically aligned at the character level. The systems are trained on the aligned data and applied to an unlabeled list of candidate word pairs. Word pairs with a probability greater than a certain threshold are classified as transliteration pairs. Similarly to supervised approaches, semi-supervised systems (Sherif and Kondrak 2007; Darwish 2010) also use a list of transliteration pairs for training. However, here the list is generally small. The systems thus do not solely rely on it to mine transliteration pairs. They use both the list of transliteration pairs and unlabeled data for training. We are only aware of two unsupervised systems (requiring no labeled data). One of them was proposed by Fei Huang (2005). He extracts named entity pairs from a bilingual corpus, converts all words into Latin script by romanization, and classifies them into transliterations and non-transliterations based on the edit distance. This system still req"
J17-2003,2014.eamt-1.17,0,0.0188764,"ations. Sajjad et al. (2013b) generated improved word alignment of the parallel training data by incorporating the transliteration mining module into GIZA++. Sajjad et al. (2013a), and Durrani et al. (2014) used transliteration mining to transliterate out-of-vocabulary words in a statistical machine translation system. They extracted transliteration pairs from the parallel corpus in an unsupervised fashion and trained a transliteration system on them. Kunchukuttan and Bhattacharyya (2015) showed the usefulness of unsupervised transliteration mining for the transliteration of Indian languages. Durrani and Koehn (2014) exploited the closeness between Urdu and Hindi using transliteration mining. They created synthetic Hindi-English parallel data by transliterating Urdu to Hindi. When they used the data for machine translation, it substantially improved translation quality. 10. Conclusions We presented a statistical model for mining transliteration pairs from a list of candidate pairs in a fully unsupervised fashion. Our model consists of sub-models for transliterations and non-transliterations that are interpolated. The transliteration sub-model is an n-gram model over 1–1, 0–1, and 1–0 character pairs and t"
J17-2003,P10-1048,1,0.805721,"language; (3) punctuation errors: one word has an additional punctuation symbol that makes the word pair a non-transliteration; (4) gold standard error: errors in the gold standard; (5) worst errors: word pairs that are far from being considered as transliteration pairs. Table 13 shows the number of errors of each type. The affix-based and pronunciation errors are the top errors made by the system. Both of them plus punctuation errors come under the broad definition of close transliterations. These word pairs are helpful because they provide useful character-level transliteration information. Durrani et al. (2010) incorporated our unsupervised transliteration mining system into machine translation. They showed that for language pairs with fewer transliterations, the close transliterations help to build a stronger transliteration system. Table 13 Types of errors made by the unsupervised transliteration mining system on the English/Arabic language pair. The numbers are based on randomly selected 100 word pairs that were wrongly classified by the mining system. Error Type Affix-based Error Gold Standard Error 372 Count Error Type Count Error Type Count 38 9 Pronunciation Error Worst Error 22 21 Punctuatio"
J17-2003,E14-4029,1,0.848098,"ost of the target language words in the cross-product list. The unsupervised system starts learning wrong transliterations because of their high frequency. Durrani et al. (2010) preprocess the candidate list before mining the transliteration pairs and remove words pairs with the most common source and target words. 9. Applications Our unsupervised transliteration mining system has been used in several NLP applications. Sajjad et al. (2013b) generated improved word alignment of the parallel training data by incorporating the transliteration mining module into GIZA++. Sajjad et al. (2013a), and Durrani et al. (2014) used transliteration mining to transliterate out-of-vocabulary words in a statistical machine translation system. They extracted transliteration pairs from the parallel corpus in an unsupervised fashion and trained a transliteration system on them. Kunchukuttan and Bhattacharyya (2015) showed the usefulness of unsupervised transliteration mining for the transliteration of Indian languages. Durrani and Koehn (2014) exploited the closeness between Urdu and Hindi using transliteration mining. They created synthetic Hindi-English parallel data by transliterating Urdu to Hindi. When they used the"
J17-2003,eisele-chen-2010-multiun,0,0.0445614,"Missing"
J17-2003,D11-1128,0,0.0606321,"Missing"
J17-2003,J93-1004,0,0.666995,"multigram sequences: p1 (e, f) = X p1 (a) (1) a∈Align(e,f ) where Align(e, f) returns all possible multigram sequences for the transliteration pair (e, f). In a unigram model, the probability of a multigram sequence a is the product of the probabilities of the multigrams it contains: p1 (a) = p1 (a1 a2 ...a|a |) = |a| Y p1 (aj ) (2) j=1 where |a |is the length of the sequence a. The non-transliteration sub-model generates source and target words that are unrelated. We model such pairs with two separate character unigram models (a source and a target model) whose probabilities are multiplied (Gale and Church 1993). Their parameters are learned from monolingual corpora and not updated during EM training. The non-transliteration sub-model is defined as follows: p2 (e, f) = pE (e)pF (f) (3) Q|e| Q|f| pE (e) = i=1 pE (ei ) and pF (f) = i=1 pF ( fi ) The transliteration mining model is obtained by interpolating the transliteration model p1 (e, f) and the non-transliteration model p2 (e, f): p(e, f) = (1 − λ )p1 (e, f) + λp2 (e, f) (4) where λ is the prior probability of non-transliteration. Interpolation with the non-transliteration model allows the transliteration model to concentrate on modeling translite"
J17-2003,W10-2405,0,0.150552,"it is attractive to extract transliteration pairs automatically from a noisy list of transliteration candidates, which can be obtained from aligned bilingual corpora, for instance. This extraction process is called transliteration mining. There are rule-based, supervised, semi-supervised, and unsupervised ways to mine transliteration pairs. Rule-based methods apply weighted handwritten rules that map characters between two languages, and compute a weighted edit distance metric that assigns a score to every candidate word pair. Pairs with an edit distance below a given threshold are extracted (Jiampojamarn et al. 2010; Noeman and Madkour 2010; Sajjad et al. 2011). Supervised transliteration mining systems (Nabende 2010; Noeman and Madkour 2010; El-Kahki et al. 2011) make use of an initial list of transliteration pairs that is automatically aligned at the character level. The systems are trained on the aligned data and applied to an unlabeled list of candidate word pairs. Word pairs with a probability greater than a certain threshold are classified as transliteration pairs. Similarly to supervised approaches, semi-supervised systems (Sherif and Kondrak 2007; Darwish 2010) also use a list of transliteration"
J17-2003,N03-1017,0,0.0598518,"Missing"
J17-2003,W15-3912,0,0.014598,"with the most common source and target words. 9. Applications Our unsupervised transliteration mining system has been used in several NLP applications. Sajjad et al. (2013b) generated improved word alignment of the parallel training data by incorporating the transliteration mining module into GIZA++. Sajjad et al. (2013a), and Durrani et al. (2014) used transliteration mining to transliterate out-of-vocabulary words in a statistical machine translation system. They extracted transliteration pairs from the parallel corpus in an unsupervised fashion and trained a transliteration system on them. Kunchukuttan and Bhattacharyya (2015) showed the usefulness of unsupervised transliteration mining for the transliteration of Indian languages. Durrani and Koehn (2014) exploited the closeness between Urdu and Hindi using transliteration mining. They created synthetic Hindi-English parallel data by transliterating Urdu to Hindi. When they used the data for machine translation, it substantially improved translation quality. 10. Conclusions We presented a statistical model for mining transliteration pairs from a list of candidate pairs in a fully unsupervised fashion. Our model consists of sub-models for transliterations and non-tr"
J17-2003,P04-1021,0,0.327325,"Missing"
J17-2003,W05-0809,0,0.0518742,"Missing"
J17-2003,W10-2412,0,0.014251,"ich can be obtained from aligned bilingual corpora, for instance. This extraction process is called transliteration mining. There are rule-based, supervised, semi-supervised, and unsupervised ways to mine transliteration pairs. Rule-based methods apply weighted handwritten rules that map characters between two languages, and compute a weighted edit distance metric that assigns a score to every candidate word pair. Pairs with an edit distance below a given threshold are extracted (Jiampojamarn et al. 2010; Noeman and Madkour 2010; Sajjad et al. 2011). Supervised transliteration mining systems (Nabende 2010; Noeman and Madkour 2010; El-Kahki et al. 2011) make use of an initial list of transliteration pairs that is automatically aligned at the character level. The systems are trained on the aligned data and applied to an unlabeled list of candidate word pairs. Word pairs with a probability greater than a certain threshold are classified as transliteration pairs. Similarly to supervised approaches, semi-supervised systems (Sherif and Kondrak 2007; Darwish 2010) also use a list of transliteration pairs for training. However, here the list is generally small. The systems thus do not solely rely on i"
J17-2003,W10-2408,0,0.0497492,"Missing"
J17-2003,J03-1002,0,0.0745413,"Missing"
J17-2003,I11-1015,1,0.907278,"utomatically from a noisy list of transliteration candidates, which can be obtained from aligned bilingual corpora, for instance. This extraction process is called transliteration mining. There are rule-based, supervised, semi-supervised, and unsupervised ways to mine transliteration pairs. Rule-based methods apply weighted handwritten rules that map characters between two languages, and compute a weighted edit distance metric that assigns a score to every candidate word pair. Pairs with an edit distance below a given threshold are extracted (Jiampojamarn et al. 2010; Noeman and Madkour 2010; Sajjad et al. 2011). Supervised transliteration mining systems (Nabende 2010; Noeman and Madkour 2010; El-Kahki et al. 2011) make use of an initial list of transliteration pairs that is automatically aligned at the character level. The systems are trained on the aligned data and applied to an unlabeled list of candidate word pairs. Word pairs with a probability greater than a certain threshold are classified as transliteration pairs. Similarly to supervised approaches, semi-supervised systems (Sherif and Kondrak 2007; Darwish 2010) also use a list of transliteration pairs for training. However, here the list is"
J17-2003,P11-1044,1,0.884668,"utomatically from a noisy list of transliteration candidates, which can be obtained from aligned bilingual corpora, for instance. This extraction process is called transliteration mining. There are rule-based, supervised, semi-supervised, and unsupervised ways to mine transliteration pairs. Rule-based methods apply weighted handwritten rules that map characters between two languages, and compute a weighted edit distance metric that assigns a score to every candidate word pair. Pairs with an edit distance below a given threshold are extracted (Jiampojamarn et al. 2010; Noeman and Madkour 2010; Sajjad et al. 2011). Supervised transliteration mining systems (Nabende 2010; Noeman and Madkour 2010; El-Kahki et al. 2011) make use of an initial list of transliteration pairs that is automatically aligned at the character level. The systems are trained on the aligned data and applied to an unlabeled list of candidate word pairs. Word pairs with a probability greater than a certain threshold are classified as transliteration pairs. Similarly to supervised approaches, semi-supervised systems (Sherif and Kondrak 2007; Darwish 2010) also use a list of transliteration pairs for training. However, here the list is"
J17-2003,P12-1049,1,0.795048,"Missing"
J17-2003,2013.iwslt-evaluation.8,1,0.860414,"ration Mining We observed that most of the word pairs in class 5 (worst errors) contain stop words. Because stop words are the most frequent words in a corpus, they occur with most of the target language words in the cross-product list. The unsupervised system starts learning wrong transliterations because of their high frequency. Durrani et al. (2010) preprocess the candidate list before mining the transliteration pairs and remove words pairs with the most common source and target words. 9. Applications Our unsupervised transliteration mining system has been used in several NLP applications. Sajjad et al. (2013b) generated improved word alignment of the parallel training data by incorporating the transliteration mining module into GIZA++. Sajjad et al. (2013a), and Durrani et al. (2014) used transliteration mining to transliterate out-of-vocabulary words in a statistical machine translation system. They extracted transliteration pairs from the parallel corpus in an unsupervised fashion and trained a transliteration system on them. Kunchukuttan and Bhattacharyya (2015) showed the usefulness of unsupervised transliteration mining for the transliteration of Indian languages. Durrani and Koehn (2014) ex"
J17-2003,W13-2228,1,0.851534,"ration Mining We observed that most of the word pairs in class 5 (worst errors) contain stop words. Because stop words are the most frequent words in a corpus, they occur with most of the target language words in the cross-product list. The unsupervised system starts learning wrong transliterations because of their high frequency. Durrani et al. (2010) preprocess the candidate list before mining the transliteration pairs and remove words pairs with the most common source and target words. 9. Applications Our unsupervised transliteration mining system has been used in several NLP applications. Sajjad et al. (2013b) generated improved word alignment of the parallel training data by incorporating the transliteration mining module into GIZA++. Sajjad et al. (2013a), and Durrani et al. (2014) used transliteration mining to transliterate out-of-vocabulary words in a statistical machine translation system. They extracted transliteration pairs from the parallel corpus in an unsupervised fashion and trained a transliteration system on them. Kunchukuttan and Bhattacharyya (2015) showed the usefulness of unsupervised transliteration mining for the transliteration of Indian languages. Durrani and Koehn (2014) ex"
J17-2003,P07-1109,0,0.0293419,"t distance below a given threshold are extracted (Jiampojamarn et al. 2010; Noeman and Madkour 2010; Sajjad et al. 2011). Supervised transliteration mining systems (Nabende 2010; Noeman and Madkour 2010; El-Kahki et al. 2011) make use of an initial list of transliteration pairs that is automatically aligned at the character level. The systems are trained on the aligned data and applied to an unlabeled list of candidate word pairs. Word pairs with a probability greater than a certain threshold are classified as transliteration pairs. Similarly to supervised approaches, semi-supervised systems (Sherif and Kondrak 2007; Darwish 2010) also use a list of transliteration pairs for training. However, here the list is generally small. The systems thus do not solely rely on it to mine transliteration pairs. They use both the list of transliteration pairs and unlabeled data for training. We are only aware of two unsupervised systems (requiring no labeled data). One of them was proposed by Fei Huang (2005). He extracts named entity pairs from a bilingual corpus, converts all words into Latin script by romanization, and classifies them into transliterations and non-transliterations based on the edit distance. This s"
J17-2003,W06-1630,0,0.0426347,"ent and accurate and can be used in three different training settings—unsupervised, semi-supervised, and supervised learning. Our method directly learns character correspondences between two scripts from a noisy unlabeled list of word pairs which contains both transliterations and non-transliterations. When such a list is extracted from an aligned bilingual corpus, for instance, it contains, 1 There are other approaches to transliteration mining that exploit phonetic similarity between languages (Aransa, Schwenk, and Barrault 2012) and make use of temporal information available with the data (Tao et al. 2006). We do not discuss them here because they are out of the scope of this work. 350 Sajjad et al. Statistical Models for Transliteration Mining apart from transliterations, also both translations and misalignments, which we will call non-transliterations. Our statistical model interpolates a transliteration sub-model and a nontransliteration sub-model. The intuition behind using two sub-models is that the transliteration pairs and non-transliteration pairs, which make up the unlabeled training data, have rather different characteristics and need to be modeled separately. Transliteration word pai"
J17-2003,W12-4410,0,\N,Missing
J17-2003,J93-2003,0,\N,Missing
J17-2003,C96-2141,0,\N,Missing
J17-2003,W98-1005,0,\N,Missing
J17-2003,W07-0703,0,\N,Missing
J17-2003,J07-3002,1,\N,Missing
J17-2003,W02-0505,0,\N,Missing
J17-2003,C08-1068,0,\N,Missing
J17-2003,N07-1046,0,\N,Missing
J17-2003,W09-3528,0,\N,Missing
J17-2003,N07-1047,0,\N,Missing
J17-2003,P06-1103,0,\N,Missing
J17-2003,P07-1119,0,\N,Missing
J17-2003,P06-1010,0,\N,Missing
J17-2003,P08-1045,0,\N,Missing
J17-2003,P06-2025,0,\N,Missing
J17-2003,W09-3525,0,\N,Missing
J17-2003,W09-3522,0,\N,Missing
J17-2003,W07-0711,0,\N,Missing
J17-2003,W04-3250,0,\N,Missing
J17-2003,2010.iwslt-papers.7,0,\N,Missing
J17-2003,I08-8003,0,\N,Missing
J17-2003,J98-4003,0,\N,Missing
J17-2003,W10-2404,0,\N,Missing
J17-2003,P00-1056,0,\N,Missing
J17-2003,W05-0606,0,\N,Missing
J17-2003,W09-3507,0,\N,Missing
J17-2003,W09-3504,0,\N,Missing
J17-2003,P03-1021,0,\N,Missing
K15-1017,W06-1655,0,0.0677899,"as well as the semi-supervised model of Kohonen et al. (2010a) on English, Finnish and Turkish. Finally, Ruokolainen et al. (2014) get further consistent improvements by using features extracted from large corpora, based on the letter successor variety (LSV) model (Harris, 1995) and on unsupervised segmentation models such as Morfessor CatMAP (Creutz et al., 2007a). The idea behind LSV is that for example talking should be split into talk and ing, because talk can also be followed by different letters then i such as e (talked) and s (talks). Chinese word segmentation (CWS) is related to UMS. Andrew (2006) successfully apply semiCRFs to CWS. The problem of joint CWS and POS tagging (Ng and Low, 2004; Zhang and Clark, 2008) is related to LMS. To our knowledge, joint CWS and POS tagging has not been addressed by a simple single semi-CRF, possibly because POS tagsets typically used in Chinese treebanks are much bigger than our morphotactic tagsets and the morphological poverty of Chinese makes higher-order models necessary and the direct application of semi-CRFs infeasible. 6 English Finnish German Indonesian Turkish Zulu 878k 2,928k 2,338k 88k 617k 123k Train+Tune+Dev Train Tune Dev 800 100 100 8"
K15-1017,W06-2920,0,0.0387228,"e labels are needed for many tasks, for instance in sentiment analysis detecting morphologically encoded negation, as in Turkish, is crucial. In other words, for many applications UMS is insufficient. (ii) The LMS framework allows us to learn a probabilistic model of morphotactics. Working with LMS results in higher UMS accuracy. So even in applications that only need segments and no labels, LMS is beneficial. Note that the concatenation of labels across segments yields a bundle of morphological attributes similar to those found in the CoNLL datasets often used to train morphological taggers (Buchholz and Marsi, 2006)— thus LMS helps to unify UMS and morphological tagging. We believe that LMS is a needed extension of current work in morphological segmentation. Our framework concisely allows the model to capture interdependencies among various morphemes and model relations between entire mor2 Like en in English open, en in German Offen is part of the root. 165 5 4 3 2 1 0 German English P REFIX :D ERIV:V ERB P REFIX :D ERIV:V ERB P REFIX :D ERIV:V ERB P REFIX :D ERIV P REFIX S EGMENT Ent de ROOT:N OUN ROOT:N OUN ROOT:N OUN ROOT ROOT S EGMENT eis frost S UFFIX :D ERIV:N OUN S UFFIX :D ERIV:N OUN S UFFIX :D E"
K15-1017,chrupala-etal-2008-learning,0,0.145492,"Missing"
K15-1017,W02-1001,0,0.168778,"7 Un. Data al. (2009) introduces a Bayesian state-space model with corpus-wide priors. The model resembles a semi-CRF, but dynamic programming is no longer possible due to the priors. They employ the threestate tagset of Creutz and Lagus (2004) (row 1 in Figure 2) for Arabic and Hebrew UMS. Their gradient and objective computation is based on an enumeration of a heuristically chosen subset of the exponentially many segmentations. This limits its applicability to language with complex concatenative morphology, e.g., Turkish and Finnish. Ruokolainen et al. (2013) present an averaged perceptron (Collins, 2002), a discriminative structured prediction method, for UMS. The model outperforms the semi-supervised model of Poon et al. (2009) on Arabic and Hebrew morpheme segmentation as well as the semi-supervised model of Kohonen et al. (2010a) on English, Finnish and Turkish. Finally, Ruokolainen et al. (2014) get further consistent improvements by using features extracted from large corpora, based on the letter successor variety (LSV) model (Harris, 1995) and on unsupervised segmentation models such as Morfessor CatMAP (Creutz et al., 2007a). The idea behind LSV is that for example talking should be sp"
K15-1017,W02-0603,0,0.824231,"present memory-based approaches to discriminative learning of morphological segmentation. This is the previous work most similar to our work. They address the problem of LMS. We distinguish our work from theirs in that we define a cross-lingual schema for defining a hierarchical tagset for LMS. Morever, we tackle the problem with a feature-rich log-linear model, allowing us to easily incorporate disparate sources of knowledge into a single framework, as we show in our extensive evaluation. UMS has been mainly addressed by unsupervised algorithms. L INGUISTICA (Goldsmith, 2001) and M ORFESSOR (Creutz and Lagus, 2002) are built around an idea of optimally encoding the data, in the sense of minimal description length (MDL). M ORFESSOR C AT-MAP (Creutz et al., 2007a) formulates the model as sequence prediction based on HMMs over a morph dictionary and MAP estimation. The model also attempts to induce basic morphotactic categories (P REFIX, ROOT, S UFFIX). Kohonen et al. (2010a,b) and Grönroos et al. (2014) present variations of M OR FESSOR for semi-supervised learning. Poon et 4 A good example of such a resource is en.wiktionary.org/wiki/Category:Turkish_suffixes. 167 Un. Data al. (2009) introduces a Bayesia"
K15-1017,W04-0106,0,0.110462,"ence prediction based on HMMs over a morph dictionary and MAP estimation. The model also attempts to induce basic morphotactic categories (P REFIX, ROOT, S UFFIX). Kohonen et al. (2010a,b) and Grönroos et al. (2014) present variations of M OR FESSOR for semi-supervised learning. Poon et 4 A good example of such a resource is en.wiktionary.org/wiki/Category:Turkish_suffixes. 167 Un. Data al. (2009) introduces a Bayesian state-space model with corpus-wide priors. The model resembles a semi-CRF, but dynamic programming is no longer possible due to the priors. They employ the threestate tagset of Creutz and Lagus (2004) (row 1 in Figure 2) for Arabic and Hebrew UMS. Their gradient and objective computation is based on an enumeration of a heuristically chosen subset of the exponentially many segmentations. This limits its applicability to language with complex concatenative morphology, e.g., Turkish and Finnish. Ruokolainen et al. (2013) present an averaged perceptron (Collins, 2002), a discriminative structured prediction method, for UMS. The model outperforms the semi-supervised model of Poon et al. (2009) on Arabic and Hebrew morpheme segmentation as well as the semi-supervised model of Kohonen et al. (201"
K15-1017,W05-0701,0,0.101986,"Missing"
K15-1017,P08-1115,0,0.064437,"s: (i) morphological segmentation, (ii) stemming and (iii) morphological tag classification. For morphological segmentation our method shows absolute improvements of 2-6 points F1 over a strong baseline. 1 Introduction Morphological processing is often an overlooked problem since many well-studied languages (e.g., Chinese and English) are morphologically impoverished. But for languages with complex morphology (e.g., Finnish and Turkish) morphological processing is essential. A specific form of morphological processing, morphological segmentation, has shown its utility for machine translation (Dyer et al., 2008), sentiment analysis (AbdulMageed et al., 2014), bilingual word alignment (Eyigöz et al., 2013), speech processing (Creutz et al., 2007b) and keyword spotting (Narasimhan et al., 2014), inter alia. We advance the state-of-theart in supervised morphological segmentation by describing a high-performance, data-driven tool for handling complex morphology, even in lowresource settings. In this work, we make the distinction between unlabeled morphological segmentation (UMS ) (often just called “morphological segmentation”) and labeled morphological segmentation (LMS). The labels in our supervised di"
K15-1017,D13-1032,1,0.778252,"y predicting LMS and then discarding the labels. Our primary baseline is the state-of-the-art supervised system CRF-M ORPH of Ruokolainen et al. (2013). We ran the version of the system that the authors published on their website.8 We optimized the model’s two hyperparameters on Tune: the number of epochs and the maximal length of ngram character features. The system also supports Harris’s letter successor variety (LSV) features (Section 5), extracted from large unannotated corpora, our second baseline. For completeness, we also compare C HIPMUNK with a first-order CRF and a higher-order CRF (Müller et al., 2013), both used the same n-gram features as CRF-M ORPH, but without the LSV features.9 We evaluate all models using the traditional macro F1 of the segmentation boundaries. Discussion. The UMS results on held-out data are displayed in Table 5. Our most complex model beats the best baseline by between 1 (German) and 3 (Finnish) points F1 on all six languages. We additionally provide extensive ablation studies to highlight the contribution of our novel features. We find that the properties of each specific language highly influences which features are most effective. For the agglutinative languages,"
K15-1017,N13-1004,0,0.0261228,"For morphological segmentation our method shows absolute improvements of 2-6 points F1 over a strong baseline. 1 Introduction Morphological processing is often an overlooked problem since many well-studied languages (e.g., Chinese and English) are morphologically impoverished. But for languages with complex morphology (e.g., Finnish and Turkish) morphological processing is essential. A specific form of morphological processing, morphological segmentation, has shown its utility for machine translation (Dyer et al., 2008), sentiment analysis (AbdulMageed et al., 2014), bilingual word alignment (Eyigöz et al., 2013), speech processing (Creutz et al., 2007b) and keyword spotting (Narasimhan et al., 2014), inter alia. We advance the state-of-theart in supervised morphological segmentation by describing a high-performance, data-driven tool for handling complex morphology, even in lowresource settings. In this work, we make the distinction between unlabeled morphological segmentation (UMS ) (often just called “morphological segmentation”) and labeled morphological segmentation (LMS). The labels in our supervised discriminative model 1 Terminological notes: We use root to refer to a morpheme with concrete mea"
K15-1017,D14-1095,0,0.0748928,"1 over a strong baseline. 1 Introduction Morphological processing is often an overlooked problem since many well-studied languages (e.g., Chinese and English) are morphologically impoverished. But for languages with complex morphology (e.g., Finnish and Turkish) morphological processing is essential. A specific form of morphological processing, morphological segmentation, has shown its utility for machine translation (Dyer et al., 2008), sentiment analysis (AbdulMageed et al., 2014), bilingual word alignment (Eyigöz et al., 2013), speech processing (Creutz et al., 2007b) and keyword spotting (Narasimhan et al., 2014), inter alia. We advance the state-of-theart in supervised morphological segmentation by describing a high-performance, data-driven tool for handling complex morphology, even in lowresource settings. In this work, we make the distinction between unlabeled morphological segmentation (UMS ) (often just called “morphological segmentation”) and labeled morphological segmentation (LMS). The labels in our supervised discriminative model 1 Terminological notes: We use root to refer to a morpheme with concrete meaning, stem to refer to the concatenation of all roots and derivational affixes, root dete"
K15-1017,J01-2001,0,0.672752,"s (1999) and Marsi et al. (2005) present memory-based approaches to discriminative learning of morphological segmentation. This is the previous work most similar to our work. They address the problem of LMS. We distinguish our work from theirs in that we define a cross-lingual schema for defining a hierarchical tagset for LMS. Morever, we tackle the problem with a feature-rich log-linear model, allowing us to easily incorporate disparate sources of knowledge into a single framework, as we show in our extensive evaluation. UMS has been mainly addressed by unsupervised algorithms. L INGUISTICA (Goldsmith, 2001) and M ORFESSOR (Creutz and Lagus, 2002) are built around an idea of optimally encoding the data, in the sense of minimal description length (MDL). M ORFESSOR C AT-MAP (Creutz et al., 2007a) formulates the model as sequence prediction based on HMMs over a morph dictionary and MAP estimation. The model also attempts to induce basic morphotactic categories (P REFIX, ROOT, S UFFIX). Kohonen et al. (2010a,b) and Grönroos et al. (2014) present variations of M OR FESSOR for semi-supervised learning. Poon et 4 A good example of such a resource is en.wiktionary.org/wiki/Category:Turkish_suffixes. 167"
K15-1017,W04-3236,0,0.00874839,"ish. Finally, Ruokolainen et al. (2014) get further consistent improvements by using features extracted from large corpora, based on the letter successor variety (LSV) model (Harris, 1995) and on unsupervised segmentation models such as Morfessor CatMAP (Creutz et al., 2007a). The idea behind LSV is that for example talking should be split into talk and ing, because talk can also be followed by different letters then i such as e (talked) and s (talks). Chinese word segmentation (CWS) is related to UMS. Andrew (2006) successfully apply semiCRFs to CWS. The problem of joint CWS and POS tagging (Ng and Low, 2004; Zhang and Clark, 2008) is related to LMS. To our knowledge, joint CWS and POS tagging has not been addressed by a simple single semi-CRF, possibly because POS tagsets typically used in Chinese treebanks are much bigger than our morphotactic tagsets and the morphological poverty of Chinese makes higher-order models necessary and the direct application of semi-CRFs infeasible. 6 English Finnish German Indonesian Turkish Zulu 878k 2,928k 2,338k 88k 617k 123k Train+Tune+Dev Train Tune Dev 800 100 100 800 100 100 800 100 100 800 100 100 800 100 100 800 100 100 Test 694 835 751 2500 763 9040 Table"
K15-1017,C14-1111,0,0.0697741,"ate disparate sources of knowledge into a single framework, as we show in our extensive evaluation. UMS has been mainly addressed by unsupervised algorithms. L INGUISTICA (Goldsmith, 2001) and M ORFESSOR (Creutz and Lagus, 2002) are built around an idea of optimally encoding the data, in the sense of minimal description length (MDL). M ORFESSOR C AT-MAP (Creutz et al., 2007a) formulates the model as sequence prediction based on HMMs over a morph dictionary and MAP estimation. The model also attempts to induce basic morphotactic categories (P REFIX, ROOT, S UFFIX). Kohonen et al. (2010a,b) and Grönroos et al. (2014) present variations of M OR FESSOR for semi-supervised learning. Poon et 4 A good example of such a resource is en.wiktionary.org/wiki/Category:Turkish_suffixes. 167 Un. Data al. (2009) introduces a Bayesian state-space model with corpus-wide priors. The model resembles a semi-CRF, but dynamic programming is no longer possible due to the priors. They employ the threestate tagset of Creutz and Lagus (2004) (row 1 in Figure 2) for Arabic and Hebrew UMS. Their gradient and objective computation is based on an enumeration of a heuristically chosen subset of the exponentially many segmentations. Th"
K15-1017,N09-1024,0,0.0623345,"dynamic programming is no longer possible due to the priors. They employ the threestate tagset of Creutz and Lagus (2004) (row 1 in Figure 2) for Arabic and Hebrew UMS. Their gradient and objective computation is based on an enumeration of a heuristically chosen subset of the exponentially many segmentations. This limits its applicability to language with complex concatenative morphology, e.g., Turkish and Finnish. Ruokolainen et al. (2013) present an averaged perceptron (Collins, 2002), a discriminative structured prediction method, for UMS. The model outperforms the semi-supervised model of Poon et al. (2009) on Arabic and Hebrew morpheme segmentation as well as the semi-supervised model of Kohonen et al. (2010a) on English, Finnish and Turkish. Finally, Ruokolainen et al. (2014) get further consistent improvements by using features extracted from large corpora, based on the letter successor variety (LSV) model (Harris, 1995) and on unsupervised segmentation models such as Morfessor CatMAP (Creutz et al., 2007a). The idea behind LSV is that for example talking should be split into talk and ing, because talk can also be followed by different letters then i such as e (talked) and s (talks). Chinese"
K15-1017,W13-3504,0,0.276986,"h Zulu Table 2: Sizes of the various affix gazetteers. 4 119,839 6,690,417 364,564 35,269 80,261 73,525 Table 3: Number of words covered by the respective ASPELL dictionary Features features that fire if a segment is valid for a given spell checker. Spell-check features function effectively as a proxy for a “root detector”. We use the open-source ASPELL dictionaries as they are freely available in 91 languages. Table 3 shows the coverage of these dictionaries. Integrating the Features. Our model uses the features discussed in this section and additionally the simple n-gram context features of Ruokolainen et al. (2013). The n-gram features look at variable length substrings of the word on both the right and left side of each potential boundary. We create conjunctive features from the cross-product between the morphotactic tagset (Section 2) and the features. We introduce several novel features for LMS. We exploit existing resources, e.g., spell checkers and Wiktionary, to create straightforward and effective features and we incorporate ideas from related areas: named-entity recognition (NER) and morphological tagging. Affix Features and Gazetteers. In contrast to syntax and semantics, the morphology of a la"
K15-1017,W10-2210,0,0.124893,"llowing us to easily incorporate disparate sources of knowledge into a single framework, as we show in our extensive evaluation. UMS has been mainly addressed by unsupervised algorithms. L INGUISTICA (Goldsmith, 2001) and M ORFESSOR (Creutz and Lagus, 2002) are built around an idea of optimally encoding the data, in the sense of minimal description length (MDL). M ORFESSOR C AT-MAP (Creutz et al., 2007a) formulates the model as sequence prediction based on HMMs over a morph dictionary and MAP estimation. The model also attempts to induce basic morphotactic categories (P REFIX, ROOT, S UFFIX). Kohonen et al. (2010a,b) and Grönroos et al. (2014) present variations of M OR FESSOR for semi-supervised learning. Poon et 4 A good example of such a resource is en.wiktionary.org/wiki/Category:Turkish_suffixes. 167 Un. Data al. (2009) introduces a Bayesian state-space model with corpus-wide priors. The model resembles a semi-CRF, but dynamic programming is no longer possible due to the priors. They employ the threestate tagset of Creutz and Lagus (2004) (row 1 in Figure 2) for Arabic and Hebrew UMS. Their gradient and objective computation is based on an enumeration of a heuristically chosen subset of the expon"
K15-1017,E14-4017,0,0.108741,". Their gradient and objective computation is based on an enumeration of a heuristically chosen subset of the exponentially many segmentations. This limits its applicability to language with complex concatenative morphology, e.g., Turkish and Finnish. Ruokolainen et al. (2013) present an averaged perceptron (Collins, 2002), a discriminative structured prediction method, for UMS. The model outperforms the semi-supervised model of Poon et al. (2009) on Arabic and Hebrew morpheme segmentation as well as the semi-supervised model of Kohonen et al. (2010a) on English, Finnish and Turkish. Finally, Ruokolainen et al. (2014) get further consistent improvements by using features extracted from large corpora, based on the letter successor variety (LSV) model (Harris, 1995) and on unsupervised segmentation models such as Morfessor CatMAP (Creutz et al., 2007a). The idea behind LSV is that for example talking should be split into talk and ing, because talk can also be followed by different letters then i such as e (talked) and s (talks). Chinese word segmentation (CWS) is related to UMS. Andrew (2006) successfully apply semiCRFs to CWS. The problem of joint CWS and POS tagging (Ng and Low, 2004; Zhang and Clark, 2008"
K15-1017,W10-2211,0,0.0842879,"from Wikipedia and the corpus of Krisnawati and Schulz (2013). Table 4 shows the important statistics of our datasets. In all evaluations, we use variants of the standard MorphoChallenge evaluation approach. Importantly, for word types with multiple correct segmentations, this involves finding the maximum score by comparing our hypothesized segmentation with each correct segmentation, as is standardly done in MorphoChallenge. Experiments We experimented on six languages from diverse language families. The segmentation data for English, Finnish and Turkish was taken from MorphoChallenge 2010 (Kurimo et al., 2010).5 Despite typically being used for UMS tasks, the MorphoChallenge datasets do contain morpheme level 6 https://github.com/desmond86/ Indonesian-English-Bilingual-Corpus 7 We used both Tune and Dev in order to both optimize hyperparameters on held-out data (Tune) and perform qualitative error analysis on separate held-out data (Dev). 5 http://research.ics.aalto.fi/events/ morphochallenge2010/ 168 CRF-M ORPH CRF-M ORPH +LSV First-order CRF Higher-order CRF C HIPMUNK C HIPMUNK +Morph C HIPMUNK +Affix C HIPMUNK +Dict C HIPMUNK +Dict,+Affix,+Morph English 83.23 84.45 84.66 84.66 84.40 83.27 83.81"
K15-1017,W06-2918,0,0.0380945,"resources, e.g., spell checkers and Wiktionary, to create straightforward and effective features and we incorporate ideas from related areas: named-entity recognition (NER) and morphological tagging. Affix Features and Gazetteers. In contrast to syntax and semantics, the morphology of a language is often simple to document and a list of the most common morphs can be found in any good grammar book. Wiktionary, for example, contains affix lists for all the six languages used in our experiments.4 Providing a supervised learner with such a list is a great boon, just as gazetteer features aid NER (Smith and Osborne, 2006)— perhaps even more so since suffixes and prefixes are generally closed-class; hence these lists are likely to be comprehensive. These features are binary and fire if a given substring occurs in the gazetteer list. In this paper, we simply use suffix lists from English Wiktionary, except for Zulu, for which we use a prefix list, see Table 2. We also include a feature that fires on the conjunction of tags and substrings observed in the training data. In the level 5 tagset this allows us to link all allomorphs of a given morpheme. In the lower level tagsets, this links related morphemes. Virpioj"
K15-1017,C10-1115,0,0.0740834,"Missing"
K15-1017,P99-1037,0,0.623548,"Missing"
K15-1017,P08-1101,0,0.0645359,"olainen et al. (2014) get further consistent improvements by using features extracted from large corpora, based on the letter successor variety (LSV) model (Harris, 1995) and on unsupervised segmentation models such as Morfessor CatMAP (Creutz et al., 2007a). The idea behind LSV is that for example talking should be split into talk and ing, because talk can also be followed by different letters then i such as e (talked) and s (talks). Chinese word segmentation (CWS) is related to UMS. Andrew (2006) successfully apply semiCRFs to CWS. The problem of joint CWS and POS tagging (Ng and Low, 2004; Zhang and Clark, 2008) is related to LMS. To our knowledge, joint CWS and POS tagging has not been addressed by a simple single semi-CRF, possibly because POS tagsets typically used in Chinese treebanks are much bigger than our morphotactic tagsets and the morphological poverty of Chinese makes higher-order models necessary and the direct application of semi-CRFs infeasible. 6 English Finnish German Indonesian Turkish Zulu 878k 2,928k 2,338k 88k 617k 123k Train+Tune+Dev Train Tune Dev 800 100 100 800 100 100 800 100 100 800 100 100 800 100 100 800 100 100 Test 694 835 751 2500 763 9040 Table 4: Dataset sizes (numbe"
N10-1113,D08-1092,0,0.0835525,"e necessary to resolve this ambiguity. Work on projecting semantic roles (Pad´o and Lapata, 2009; Fung et al., 2007) requires both syntactic parsing and semantic role labeling and is concerned with filling in the complete information in a semantic frame. Our approach is simpler and concerned only with syntactic disambiguation, not semantic projection. We focus only on difficult cases of subject-object ambiguity and although we do not always make a prediction, we obtain levels of precision that projection approaches making no use of knowledge of German syntax cannot achieve. In bitext parsing, Burkett and Klein (2008) and Fraser et al. (2009) used feature functions defined on triples of (parse tree in language 1, parse tree in language 2, word alignment), combined in a log-linear model trained to maximize parse accuracy, requiring translated treebanks. We focus only on subjectobject disambiguation in German, and annotated a new gold standard. We work on sentences that a partial parser has determined to be ambiguous. Fossum and Knight (2008) and Huang et al. (2009) improve English prepositional phrase attachment using features from an unparsed Chinese sentence. The latter work integrated the PP-attachment c"
N10-1113,J96-2004,0,0.0529047,"ng a graphical user interface (GUI). The GUI showed the ambiguous words in context and gave the annotator four different subject-object labels to choose from for each ambiguous word: subject, object, expletive es and none. Because the syntactic expletive “es” (English gloss: ‘it’) is frequent in German, as in “es scheint zu regnen” ‘it appears to be raining,’ we created a separate label for expletive “es”, which is not treated as a subject.2 The statistics are shown in table 1. 1000 sentences were annotated by all four annotators. Inter-annotator agreement was sufficient (κ = 0.77 on average (Carletta, 1996)). Evaluation Measures. The output of our algorithm labels each word that FSPar classified as ambiguous with one of the three possible labels subject, 1 Figure 2: Disambiguation Algorithm We used standard heuristics for improving word alignment (Och and Ney, 2003; Koehn et al., 2003), but there were many misalignments of ambiguous 738 FSPar has a very high precision in detecting subject-object ambiguities, as can be seen in Table 1 (approximately 0.955, the sum of two left columns divided by sum of all cells). We tried to get an idea of recall using the smaller gold standard. We made conservat"
N10-1113,2008.amta-srw.2,0,0.480568,"do not always make a prediction, we obtain levels of precision that projection approaches making no use of knowledge of German syntax cannot achieve. In bitext parsing, Burkett and Klein (2008) and Fraser et al. (2009) used feature functions defined on triples of (parse tree in language 1, parse tree in language 2, word alignment), combined in a log-linear model trained to maximize parse accuracy, requiring translated treebanks. We focus only on subjectobject disambiguation in German, and annotated a new gold standard. We work on sentences that a partial parser has determined to be ambiguous. Fossum and Knight (2008) and Huang et al. (2009) improve English prepositional phrase attachment using features from an unparsed Chinese sentence. The latter work integrated the PP-attachment constraint (detected from the Chinese translation) directly into an English shift-reduce parser. As we have shown in the labeling experiment, integrating our subjectobject disambiguation into BitPar could result in further increases beyond 100-best reranking. 6 Conclusion We demonstrated the utility of bitext-based disambiguation of grammatical roles. We automatically created a large corpus of 164,874 disambiguated subject-objec"
N10-1113,E09-1033,1,0.840854,"Missing"
N10-1113,2007.tmi-papers.10,0,0.0718207,"Missing"
N10-1113,D09-1127,0,0.0380513,"on, we obtain levels of precision that projection approaches making no use of knowledge of German syntax cannot achieve. In bitext parsing, Burkett and Klein (2008) and Fraser et al. (2009) used feature functions defined on triples of (parse tree in language 1, parse tree in language 2, word alignment), combined in a log-linear model trained to maximize parse accuracy, requiring translated treebanks. We focus only on subjectobject disambiguation in German, and annotated a new gold standard. We work on sentences that a partial parser has determined to be ambiguous. Fossum and Knight (2008) and Huang et al. (2009) improve English prepositional phrase attachment using features from an unparsed Chinese sentence. The latter work integrated the PP-attachment constraint (detected from the Chinese translation) directly into an English shift-reduce parser. As we have shown in the labeling experiment, integrating our subjectobject disambiguation into BitPar could result in further increases beyond 100-best reranking. 6 Conclusion We demonstrated the utility of bitext-based disambiguation of grammatical roles. We automatically created a large corpus of 164,874 disambiguated subject-object decisions with a preci"
N10-1113,N03-1017,0,0.00268218,") is frequent in German, as in “es scheint zu regnen” ‘it appears to be raining,’ we created a separate label for expletive “es”, which is not treated as a subject.2 The statistics are shown in table 1. 1000 sentences were annotated by all four annotators. Inter-annotator agreement was sufficient (κ = 0.77 on average (Carletta, 1996)). Evaluation Measures. The output of our algorithm labels each word that FSPar classified as ambiguous with one of the three possible labels subject, 1 Figure 2: Disambiguation Algorithm We used standard heuristics for improving word alignment (Och and Ney, 2003; Koehn et al., 2003), but there were many misalignments of ambiguous 738 FSPar has a very high precision in detecting subject-object ambiguities, as can be seen in Table 1 (approximately 0.955, the sum of two left columns divided by sum of all cells). We tried to get an idea of recall using the smaller gold standard. We made conservative assumptions about recall errors which we manually checked on a small sample, details are omitted. Using these assumptions led to an estimate for recall of 0.733, but true recall is likely higher. 2 German “es” is also frequently used as a non-expletive, where it can take a syntac"
N10-1113,2005.mtsummit-papers.11,0,0.0173974,"ambiguities are much less frequent in languages that possess a less flexible syntax than German. In English, the translation of the sentence “Die Maus jagt die Katze” is not ambiguous. If we have access to this translation, we can use this information to disambiguate the German sentence. The English translation is viewed as a surrogate for both contextual knowledge from the text and for world knowledge. We present a method for disambiguating the subject and object roles in German sentences. We use Algorithm Data and Word Alignment. We use the aligned English and German sentences in Europarl (Koehn, 2005) for our experiments. The corpus contains long and complex sentences. To establish translational correspondence between parallel sentences we use GIZA++ (Och and Ney, 2003). Its input is a tokenized parallel corpus. We lemmatized the text prior to aligning it. Procedure. Figure 1 shows the architecture of our system. The boxes signify data sets, while the lines are processes applied to the data sets. The paper presents two applications. The first is the creation of a set of disambiguated German sentences (which involves word alignments in the upper right corner, and the use of parsers in the m"
N10-1113,J03-1002,0,0.00939333,"” is not ambiguous. If we have access to this translation, we can use this information to disambiguate the German sentence. The English translation is viewed as a surrogate for both contextual knowledge from the text and for world knowledge. We present a method for disambiguating the subject and object roles in German sentences. We use Algorithm Data and Word Alignment. We use the aligned English and German sentences in Europarl (Koehn, 2005) for our experiments. The corpus contains long and complex sentences. To establish translational correspondence between parallel sentences we use GIZA++ (Och and Ney, 2003). Its input is a tokenized parallel corpus. We lemmatized the text prior to aligning it. Procedure. Figure 1 shows the architecture of our system. The boxes signify data sets, while the lines are processes applied to the data sets. The paper presents two applications. The first is the creation of a set of disambiguated German sentences (which involves word alignments in the upper right corner, and the use of parsers in the middle of the graphic). We also present a reranking of the N -best parses produced by BitPar (Schmid, 2004), a state of the art statistical parser (bottom of the graphic). F"
N10-1113,E03-1087,0,0.0266438,"hat the German word to be disambiguated be aligned to the English subject or object. For this reason, we implemented second guessing based on a dictionary that lists for every German word the 10 most frequently aligned English words (found using the word alignment of all of Europarl). If an ambiguous German word was either unaligned or not aligned to the English subject or object, it was checked whether a dictionary translation was part of the parallel sentence and marked as subject or object by MINIPAR. If so, this dictionary word was used for disambiguation. 3 Figure 1: System Architecture (Schiehlen, 2003), a fast shallow dependency parser. FSPar has extensive lexical knowledge which helps it to find subject-object ambiguities with high accuracy, but it does not try to resolve such ambiguities. The key to our approach is to project syntactic roles from English text. For English parsing we used MINIPAR (Lin, 1998). Based on FSPar’s analysis, all German sentences with a subject-object ambiguity (about a third) were selected from EuroParl. The parallel English sentences were parsed with MINIPAR. Words marked as ambiguous by FSPar were then processed using our algorithm. If an ambiguous German word"
N10-1113,C04-1024,0,0.0121683,"nal correspondence between parallel sentences we use GIZA++ (Och and Ney, 2003). Its input is a tokenized parallel corpus. We lemmatized the text prior to aligning it. Procedure. Figure 1 shows the architecture of our system. The boxes signify data sets, while the lines are processes applied to the data sets. The paper presents two applications. The first is the creation of a set of disambiguated German sentences (which involves word alignments in the upper right corner, and the use of parsers in the middle of the graphic). We also present a reranking of the N -best parses produced by BitPar (Schmid, 2004), a state of the art statistical parser (bottom of the graphic). For processing of German we chose FSPar 737 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 737–740, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics German words. In order for the procedure to work, we require that the German word to be disambiguated be aligned to the English subject or object. For this reason, we implemented second guessing based on a dictionary that lists for every German word the 10 most frequently aligned English word"
N10-1113,N01-1026,0,0.359374,"Missing"
N13-1001,J93-2003,0,0.0650306,"arch performance and superior selection of translation units. In this paper we combine N-grambased modeling with phrase-based decoding, and obtain the benefits of both approaches. Our experiments show that using this combination not only improves the search accuracy of the N-gram model but that it also improves the BLEU scores. Our system outperforms state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems by a significant margin on German, French and Spanish to English translation tasks. 1 Introduction Statistical Machine Translation advanced from word-based models (Brown et al., 1993) towards more sophisticated models that take contextual information into account. Phrase-based (Och and Ney, 2004; Koehn et al., 2003) and N-gram-based (Mari˜no et al., 2006) models are two instances of such frameworks. While the two models have some common properties, they are substantially different. ∗ Much of the work presented here was carried out while the first author was at the University of Stuttgart. Phrase-based systems employ a simple and effective machinery by learning larger chunks of translation called phrases1 . Memorizing larger units enables the phrase-based model to learn loc"
N13-1001,N10-2003,0,0.0274872,"and N-gram-based systems on German-to-English, French-to-English, and Spanish-to-English tasks13 . We used the official evaluation data (news-test sets) from the Statistical Machine Translation Workshops 2009-2011 for all three language pairs (German, Spanish and French). The feature weights for all the systems are tuned using the dev set news-dev2009a. We separately tune the baseline system (cept.500) and the phrase-based system (phrase.200) and do not hold the lambda vector constant like before. Baseline Systems: We also compared our system with i) Moses (Koehn et al., 2007), ii) Phrasal14 (Cer et al., 2010), and iii) Ncode (Crego et al., 2011). We used the default stack sizes of 100 for Moses15 , 200 for Phrasal, 25 for Ncode (with 2m stacks). A 5-gram English language model is used. Both phrase-based systems use 20-best phrases for translation, Ncode uses 25-best tuple translations. The training and test data for Ncode was tagged using TreeTagger (Schmid, 1994). All the baseline systems used lexicalized reordering model. A hard reordering limit16 of 6 words is used as a default in 13 We did not include the results of Spanish in the previous section due to space limitations but these are similar"
N13-1001,N07-2035,0,0.427586,"Missing"
N13-1001,2005.mtsummit-papers.37,0,0.122551,"Missing"
N13-1001,P11-1105,1,0.0967324,"ormation outside of phrases ii) it has issues handling long-distance reordering iii) it has the spurious phrasal segmentation problem which allows multiple derivations of a bilingual sentence pair having different model scores for each segmentation. Modeling with minimal translation units helps address some of these issues. The N-gram-based SMT framework is based on tuples. Tuples are minimal translation units composed of source and target cepts2 . N-gram-based models are Markov models over sequences of tuples (Mari˜no et al., 2006; Crego and Mari˜no, 2006) or operations encapsulating tuples (Durrani et al., 2011). This mechanism has several useful properties. Firstly, no phrasal independence assumption is made. The model has access to both source and target context outside of phrases. Secondly the model learns a unique derivation of a bilingual sentence given its alignment, thus avoiding the spurious segmentation problem. Using minimal translation units, however, results in a higher number of search errors because of i) 1 A phrase-pair in PBSMT is a sequence of source and target words that is translation of each other, and is not necessarily a linguistic constituent. Phrases are built by combining min"
N13-1001,2010.amta-papers.22,0,0.219773,"Missing"
N13-1001,D08-1089,0,0.282782,"-art N-gram-based systems (Ncode and OSM) on standard translation tasks. 2 Previous Work Phrase-based and N-gram-based SMT are alternative frameworks for string-to-string translation. Phrase-based SMT segments a bilingual sentence pair into phrases that are continuous sequences of words (Och and Ney, 2004; Koehn et al., 2003) or discontinuous sequences of words (Galley and Manning, 2010). These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang, 2005) or block of phrases (Galley and Manning, 2008). There are several drawbacks of the phrase-based model. Firstly it makes an independence assumption over phrases, according to which phrases are translated independently of each other, thus ignoring the contextual information outside of the phrasal boundary. This problem is corrected by the monolingual language model that takes context into account. But often the language model cannot compensate for the dispreference of the translation model for nonlocal dependencies. The second problem is that the model is unaware of the actual phrasal segmentation of a sentence during training. It therefore"
N13-1001,N03-1017,0,0.395697,", and obtain the benefits of both approaches. Our experiments show that using this combination not only improves the search accuracy of the N-gram model but that it also improves the BLEU scores. Our system outperforms state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems by a significant margin on German, French and Spanish to English translation tasks. 1 Introduction Statistical Machine Translation advanced from word-based models (Brown et al., 1993) towards more sophisticated models that take contextual information into account. Phrase-based (Och and Ney, 2004; Koehn et al., 2003) and N-gram-based (Mari˜no et al., 2006) models are two instances of such frameworks. While the two models have some common properties, they are substantially different. ∗ Much of the work presented here was carried out while the first author was at the University of Stuttgart. Phrase-based systems employ a simple and effective machinery by learning larger chunks of translation called phrases1 . Memorizing larger units enables the phrase-based model to learn local dependencies such as short reorderings, idioms, insertions and deletions, etc. The model however, has the following drawbacks: i) i"
N13-1001,P07-2045,0,0.0197622,"other state-of-the-art phrase-based and N-gram-based systems on German-to-English, French-to-English, and Spanish-to-English tasks13 . We used the official evaluation data (news-test sets) from the Statistical Machine Translation Workshops 2009-2011 for all three language pairs (German, Spanish and French). The feature weights for all the systems are tuned using the dev set news-dev2009a. We separately tune the baseline system (cept.500) and the phrase-based system (phrase.200) and do not hold the lambda vector constant like before. Baseline Systems: We also compared our system with i) Moses (Koehn et al., 2007), ii) Phrasal14 (Cer et al., 2010), and iii) Ncode (Crego et al., 2011). We used the default stack sizes of 100 for Moses15 , 200 for Phrasal, 25 for Ncode (with 2m stacks). A 5-gram English language model is used. Both phrase-based systems use 20-best phrases for translation, Ncode uses 25-best tuple translations. The training and test data for Ncode was tagged using TreeTagger (Schmid, 1994). All the baseline systems used lexicalized reordering model. A hard reordering limit16 of 6 words is used as a default in 13 We did not include the results of Spanish in the previous section due to space"
N13-1001,koen-2004-pharaoh,0,0.151724,"ted as an N-gram model of operations using SRILM-Toolkit (Stolcke, 2002) with Kneser-Ney smoothing. A 9-gram model is used. Several count-based features such as gap and open gap penalties and distance-based features such as gap-width and reordering distance are added to the model, along with the lexical weighting and length penalty features in a standard log-linear framework (Durrani et al., 2011). 4 The generation is carried out in the order of the target language E. 4 4 4.1 Search Overview of Decoding Framework The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004a). The decoder uses beam search to build up the translation from left to right. The hypotheses are arranged in m stacks such that stack i maintains hypotheses that have already translated i many foreign words. The ultimate goal is to find the best scoring hypothesis, that has translated all the words in the foreign sentence. The overall process can be roughly divided into the following steps: i) extraction of translation units ii) future-cost estimation, iii) hypothesis extension iv) recombination and pruning. During the hypothesis extension each extracted phrase is translated into a sequence"
N13-1001,W04-3250,0,0.0729896,"ted as an N-gram model of operations using SRILM-Toolkit (Stolcke, 2002) with Kneser-Ney smoothing. A 9-gram model is used. Several count-based features such as gap and open gap penalties and distance-based features such as gap-width and reordering distance are added to the model, along with the lexical weighting and length penalty features in a standard log-linear framework (Durrani et al., 2011). 4 The generation is carried out in the order of the target language E. 4 4 4.1 Search Overview of Decoding Framework The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004a). The decoder uses beam search to build up the translation from left to right. The hypotheses are arranged in m stacks such that stack i maintains hypotheses that have already translated i many foreign words. The ultimate goal is to find the best scoring hypothesis, that has translated all the words in the foreign sentence. The overall process can be roughly divided into the following steps: i) extraction of translation units ii) future-cost estimation, iii) hypothesis extension iv) recombination and pruning. During the hypothesis extension each extracted phrase is translated into a sequence"
N13-1001,J06-4004,0,0.524902,"Missing"
N13-1001,J03-1002,0,0.0227905,"quality is measured through BLEU (Papineni et al., 2002). 6 Experimental Setup We initially experimented with two language pairs: German-to-English (G-E) and French-to-English (FE). We trained our system and the baseline systems on most of the data6 made available for the translation task of the Fourth Workshop on Statistical Machine Translation.7 We used 1M bilingual sentences, for the estimation of the translation model and 2M sentences from the monolingual corpus (news commentary) which also contains the English part of the bilingual corpus. Word alignments are obtained by running GIZA++ (Och and Ney, 2003) with the grow-diag-final-and (Koehn et al., 2005) symmetrization heuristic. We follow the training steps described in Durrani et al. (2011), consisting of i) post-processing the alignments to remove discontinuous and unaligned target cepts, ii) conversion of bilingual alignments into operation sequences, iii) estimation of the n-gram language models. 6 We did not use all the available data due to scalability issues. The scores reported are therefore well below those obtained by the systems submitted to the WMT evaluation series. 7 http://www.statmt.org/wmt09/translation-task.html 7 6.1 Search"
N13-1001,J04-4002,0,0.734935,"rase-based decoding, and obtain the benefits of both approaches. Our experiments show that using this combination not only improves the search accuracy of the N-gram model but that it also improves the BLEU scores. Our system outperforms state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems by a significant margin on German, French and Spanish to English translation tasks. 1 Introduction Statistical Machine Translation advanced from word-based models (Brown et al., 1993) towards more sophisticated models that take contextual information into account. Phrase-based (Och and Ney, 2004; Koehn et al., 2003) and N-gram-based (Mari˜no et al., 2006) models are two instances of such frameworks. While the two models have some common properties, they are substantially different. ∗ Much of the work presented here was carried out while the first author was at the University of Stuttgart. Phrase-based systems employ a simple and effective machinery by learning larger chunks of translation called phrases1 . Memorizing larger units enables the phrase-based model to learn local dependencies such as short reorderings, idioms, insertions and deletions, etc. The model however, has the foll"
N13-1001,W99-0604,0,0.0862666,"st sentences. Firstly, we used future-cost ing can help improve search accuracy and translation estimates from the extracted phrases (see system quality. cept.500.fc in Table1). This however, leads to inconsistency in the cases where the future cost is es5.1 Training We extended the training steps in Durrani et al. timated from some phrasal unit that cannot be gen(2011) to extract a phrase lexicon from the paral- erated through the available cept translations. For lel data. We extract all phrase pairs of length 6 and example, say the best cost to cover the sequence below, that are consistent (Och et al., 1999) with “Wie heißen Sie” is given by the phrase “What is the word alignments. Only continuous phrases as your name”. The 20-best translation options in ceptused in a traditional phrase-based system are ex- based system, however, do not have tuples “Wie – tracted thus allowing only inside-out (Wu, 1997) What” and “heißen – name”. To remove this distype of alignments. The future cost of each fea- crepancy, we add all such tuples that are used in ture component used in the log-linear model is cal- the extracted phrases, to the list of extracted cepts culated. The operation sequence required to hypo"
N13-1001,P02-1040,0,0.107226,"Missing"
N13-1001,P05-1069,0,0.0446686,"systems (Moses and Phrasal) and two stateof-the-art N-gram-based systems (Ncode and OSM) on standard translation tasks. 2 Previous Work Phrase-based and N-gram-based SMT are alternative frameworks for string-to-string translation. Phrase-based SMT segments a bilingual sentence pair into phrases that are continuous sequences of words (Och and Ney, 2004; Koehn et al., 2003) or discontinuous sequences of words (Galley and Manning, 2010). These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang, 2005) or block of phrases (Galley and Manning, 2008). There are several drawbacks of the phrase-based model. Firstly it makes an independence assumption over phrases, according to which phrases are translated independently of each other, thus ignoring the contextual information outside of the phrasal boundary. This problem is corrected by the monolingual language model that takes context into account. But often the language model cannot compensate for the dispreference of the translation model for nonlocal dependencies. The second problem is that the model is unaware of the actual phrasal segmentat"
N13-1001,P11-1086,0,0.0996612,"tatistically significant improvements over all the baseline systems in most of the cases. We have shown the benefits of using phrase-based search with a model based on minimal units. In future work, we would like to study whether a phrase-based system like Moses or Phrasal can profit from an OSM-style or N-gramstyle feature. Feng et al. (2010) previously showed that adding a linearized source-side language model in a phrase-based system helped. It would also be interesting to study whether the insight of using minimal units for modeling and phrase-based search would hold for hierarchical SMT. Vaswani et al. (2011) recently showed that a Markov model over the derivation history of minimal rules can obtain the same translation quality as using grammars formed with composed rules. Acknowledgments Conclusion and Future Work We proposed a combination of using a model based on minimal units and decoding with phrases. Modeling with minimal units enables us to learn local and non-local dependencies in a unified manner and avoid spurious segmentation ambiguities. However, using minimal units also in the search presents a significant challenge because of the poor translation coverage, inaccurate future-cost esti"
N13-1001,J97-3002,0,0.189575,"et al. timated from some phrasal unit that cannot be gen(2011) to extract a phrase lexicon from the paral- erated through the available cept translations. For lel data. We extract all phrase pairs of length 6 and example, say the best cost to cover the sequence below, that are consistent (Och et al., 1999) with “Wie heißen Sie” is given by the phrase “What is the word alignments. Only continuous phrases as your name”. The 20-best translation options in ceptused in a traditional phrase-based system are ex- based system, however, do not have tuples “Wie – tracted thus allowing only inside-out (Wu, 1997) What” and “heißen – name”. To remove this distype of alignments. The future cost of each fea- crepancy, we add all such tuples that are used in ture component used in the log-linear model is cal- the extracted phrases, to the list of extracted cepts culated. The operation sequence required to hypoth- (system cept.500.fc.t). We also studied how much esize each phrase is generated and its future cost is gain we obtain by only adding tuples from phrases calculated. The future costs of other features such and using cept-based future-cost estimates (system as language models, lexicalized probabili"
N13-1001,N10-1140,0,\N,Missing
N13-1001,2005.iwslt-1.8,0,\N,Missing
N18-2030,Q17-1010,0,0.152374,"lexicon induction using MWEs trained with FASTTEXT (FTT). in very few contexts only. Through post-hoc mapping, these (poor) embeddings get projected randomly into the bilingual space which results in very poor performance on BLI especially for the medical domain. 4.1 Using Subword Models A first way to create BWEs that are better adapted to rare words is to generate MWEs that provide better vector representations for the words. One simple idea is to try to add subword information. We show empirically this helps BLI of rare words, which has not been shown before, to our knowledge. FAST T EXT (Bojanowski et al., 2017) extends W 2 V by adding subword information s(w, c) to the context-based objective as follows: X s(w, c) = zg> vc (3) Applying BWEs for Mining Rare Word-Pairs g∈Gw where Gw ⊂ {1, ..., G} is a set of character ngram indices corresponding to the n-grams that appear in the word w, zg is the vector representation of the n-gram and vc is the vector of the context words. Subword information helps for rare words (by using n-gram information shared between words) and generates more accurate MWEs especially for morphologically rich languages like German. We create 300 dimensional MWEs using FASTTEXT s"
N18-2030,D16-1136,0,0.0635171,"|W ||(1) W∈Rd1 ×d2 where X and Y are stacked vectors of x~i and y~i respectively. Lazaridou et al. (2015) use a maxmargin ranking loss (MAX - MARG) to estimate W. For each (x~i , y~i ) ∈ L, a candidate y~i∗ = W · x~i is computed. The ranking loss is: k X j6=i max{0, γ + sim(y~i∗ , y~i ) − sim(y~i∗ , y~j )} (2) where y~j is a randomly selected negative example, i.e., it is not a translation of x~i , k is the number of negative examples and sim(~x, ~y ) computes cosine similarity between ~x and ~y . Hyperparameters γ and k are tuned on held-out validation data.6 2 5 Gouws and Søgaard (2015) and Duong et al. (2016) also leverage seed lexicons. However, in order to generate high quality BWEs, these approaches leverage much larger bilingual dictionaries. 6 Ideally, the sum in Equation 2 should be computed over the complete target vocabulary (i.e., k = |Vt |). Since this is not feasible in practice, Lazaridou et al. (2015) treat k as another hyperparameter tuned together with γ. This is taken from the in-domain part of: https:// ufal.mff.cuni.cz/ufal_medical_corpus. 3 This word-level dictionary is taken from a standard phrase-based SMT system trained on WMT 2017 data. 4 Words with frequencies 1 and 2 are v"
N18-2030,E14-1049,0,0.0545883,"2016). • MEDICAL: 3,108,183 English and German sentences from titles of medical Wikipedia articles, medical term-pairs, patents, documents from the European Medicines Agency.2 • GEN F REQ: 2000 frequent words from GEN ERAL (1000 validation, 1000 test) • MED F REQ: 2000 frequent words from MED ICAL (1000 validation, 1000 test) 3 Bilingual Word Embedding Creation To create bilingual word embeddings, we use post-hoc mapping (PHM), a method that projects monolingual words embeddings (MWEs) into a shared space using a linear transformation trained with a small seed lexicon (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xing et al., 2015; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016). Among methods to generate BWEs, PHM uses a very cheap bilingual signal.5 Given MWEs in two languages Vs and Vt , the goal of post-hoc mapping is to find a matrix W ∈ Rd1 ×d2 that maps each representation x~s ∈ Rd1 of a source word s ∈ Vs to the representation y~t ∈ Rd2 of its translation t ∈ Vt . Typically, W is learned using a seed lexicon L = {(x~1 , y~1 ), . . . , (x~n , y~n )}, where each pair (x~i , y~i ) ∈ Vs × Vt are mutual translations. A common objective for cross-lingual mapping is ridge regression (Mikolov et a"
N18-2030,N15-1157,0,0.0196492,"W∗ = arg min ||XW − Y ||+λ ||W ||(1) W∈Rd1 ×d2 where X and Y are stacked vectors of x~i and y~i respectively. Lazaridou et al. (2015) use a maxmargin ranking loss (MAX - MARG) to estimate W. For each (x~i , y~i ) ∈ L, a candidate y~i∗ = W · x~i is computed. The ranking loss is: k X j6=i max{0, γ + sim(y~i∗ , y~i ) − sim(y~i∗ , y~j )} (2) where y~j is a randomly selected negative example, i.e., it is not a translation of x~i , k is the number of negative examples and sim(~x, ~y ) computes cosine similarity between ~x and ~y . Hyperparameters γ and k are tuned on held-out validation data.6 2 5 Gouws and Søgaard (2015) and Duong et al. (2016) also leverage seed lexicons. However, in order to generate high quality BWEs, these approaches leverage much larger bilingual dictionaries. 6 Ideally, the sum in Equation 2 should be computed over the complete target vocabulary (i.e., k = |Vt |). Since this is not feasible in practice, Lazaridou et al. (2015) treat k as another hyperparameter tuned together with γ. This is taken from the in-domain part of: https:// ufal.mff.cuni.cz/ufal_medical_corpus. 3 This word-level dictionary is taken from a standard phrase-based SMT system trained on WMT 2017 data. 4 Words with f"
N18-2030,E17-1102,0,0.0960242,"Missing"
N18-2030,P15-1027,0,0.521881,"rman sentences from titles of medical Wikipedia articles, medical term-pairs, patents, documents from the European Medicines Agency.2 • GEN F REQ: 2000 frequent words from GEN ERAL (1000 validation, 1000 test) • MED F REQ: 2000 frequent words from MED ICAL (1000 validation, 1000 test) 3 Bilingual Word Embedding Creation To create bilingual word embeddings, we use post-hoc mapping (PHM), a method that projects monolingual words embeddings (MWEs) into a shared space using a linear transformation trained with a small seed lexicon (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xing et al., 2015; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016). Among methods to generate BWEs, PHM uses a very cheap bilingual signal.5 Given MWEs in two languages Vs and Vt , the goal of post-hoc mapping is to find a matrix W ∈ Rd1 ×d2 that maps each representation x~s ∈ Rd1 of a source word s ∈ Vs to the representation y~t ∈ Rd2 of its translation t ∈ Vt . Typically, W is learned using a seed lexicon L = {(x~1 , y~1 ), . . . , (x~n , y~n )}, where each pair (x~i , y~i ) ∈ Vs × Vt are mutual translations. A common objective for cross-lingual mapping is ridge regression (Mikolov et al., 2013b) (RIDGE), where W is estimated by"
N18-2030,P16-1024,0,0.0934446,"Missing"
N18-2030,N15-1104,0,0.10379,",183 English and German sentences from titles of medical Wikipedia articles, medical term-pairs, patents, documents from the European Medicines Agency.2 • GEN F REQ: 2000 frequent words from GEN ERAL (1000 validation, 1000 test) • MED F REQ: 2000 frequent words from MED ICAL (1000 validation, 1000 test) 3 Bilingual Word Embedding Creation To create bilingual word embeddings, we use post-hoc mapping (PHM), a method that projects monolingual words embeddings (MWEs) into a shared space using a linear transformation trained with a small seed lexicon (Mikolov et al., 2013b; Faruqui and Dyer, 2014; Xing et al., 2015; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016). Among methods to generate BWEs, PHM uses a very cheap bilingual signal.5 Given MWEs in two languages Vs and Vt , the goal of post-hoc mapping is to find a matrix W ∈ Rd1 ×d2 that maps each representation x~s ∈ Rd1 of a source word s ∈ Vs to the representation y~t ∈ Rd2 of its translation t ∈ Vt . Typically, W is learned using a seed lexicon L = {(x~1 , y~1 ), . . . , (x~n , y~n )}, where each pair (x~i , y~i ) ∈ Vs × Vt are mutual translations. A common objective for cross-lingual mapping is ridge regression (Mikolov et al., 2013b) (RIDGE),"
P06-1097,P05-1057,0,0.214078,"other built using additional English news data. We run Maximum BLEU (Och, 2003) for 25 iterations individually for each system. Table 8 shows our results. We report BLEU (Papineni et al., 2001) multiplied by 100. We also show the F-measure after heuristic symmetrization of the alignment test sets. The table shows that F (A, S, α) = 1 α Precision(A,S) (1−α) + Recall (A,S) (3) 6 Previous Research Previous work on discriminative training for wordalignment differed most strongly from our approach in that it generally views word-alignment as a supervised task. Examples of this perspective include (Liu et al., 2005; Ittycheriah and Roukos, 2005; Moore, 2005; Taskar et al., 2005). All of these also used knowledge from one of the IBM Models in order to obtain competitive results 4 We would like to thank an anonymous reviewer for suggesting that this experiment would be useful even when using a small discriminative training corpus. 774 S YSTEM A/E U NSUP. M ODEL 4 UNION A/E EMD 3 UNION F/E U NSUP. M ODEL 4 REFINED F/E EMD 2 REFINED BLEU 49.16 50.84 30.63 31.56 F- MEASURE 64.6 69.4 76.4 81.2 Table 8: Evaluation of Translation Quality tions with a relatively small number of parameters. An initial model is es"
P06-1097,H05-1011,0,0.612532,"We run Maximum BLEU (Och, 2003) for 25 iterations individually for each system. Table 8 shows our results. We report BLEU (Papineni et al., 2001) multiplied by 100. We also show the F-measure after heuristic symmetrization of the alignment test sets. The table shows that F (A, S, α) = 1 α Precision(A,S) (1−α) + Recall (A,S) (3) 6 Previous Research Previous work on discriminative training for wordalignment differed most strongly from our approach in that it generally views word-alignment as a supervised task. Examples of this perspective include (Liu et al., 2005; Ittycheriah and Roukos, 2005; Moore, 2005; Taskar et al., 2005). All of these also used knowledge from one of the IBM Models in order to obtain competitive results 4 We would like to thank an anonymous reviewer for suggesting that this experiment would be useful even when using a small discriminative training corpus. 774 S YSTEM A/E U NSUP. M ODEL 4 UNION A/E EMD 3 UNION F/E U NSUP. M ODEL 4 REFINED F/E EMD 2 REFINED BLEU 49.16 50.84 30.63 31.56 F- MEASURE 64.6 69.4 76.4 81.2 Table 8: Evaluation of Translation Quality tions with a relatively small number of parameters. An initial model is estimated in a supervised fashion using the l"
P06-1097,J03-1002,0,0.113385,"4 F- MEASURE F TO E 65.6 / 60.5 73.8 / 75.1 F- MEASURE E TO F 53.6 / 50.2 74.2 / 73.5 F- MEASURE B EST S YMM . 69.1 / 64.6 ( UNION ) 76.5 / 76.4 ( REFINED ) Table 2: Baseline Results. F-measures are presented on both the alignment discriminative training set and the alignment test set sub-corpora, separated by /. consisting of links from one English word to zero or more Foreign words. It is standard practice to improve the final alignments by combining the “F to E” and “E to F” directions using symmetrization heuristics. We use the “union”, “refined” and “intersection” heuristics defined in (Och and Ney, 2003) which are used in conjunction with IBM Model 4 as the baseline in virtually all recent work on word alignment. In Table 2, we report the best symmetrized results. The low F-measure scores of the baselines motivate our work. discriminative training set and alignment test set. Translation quality is evaluated by translating a held-out translation test set. An additional translation set called the Maximum BLEU set is employed by the SMT system to train the weights associated with the components of its log-linear model (Och, 2003). The training corpora are publicly available: both the Arabic/Engl"
P06-1097,J93-2003,0,0.0595758,"Missing"
P06-1097,P03-1021,0,0.726197,"nion”, “refined” and “intersection” heuristics defined in (Och and Ney, 2003) which are used in conjunction with IBM Model 4 as the baseline in virtually all recent work on word alignment. In Table 2, we report the best symmetrized results. The low F-measure scores of the baselines motivate our work. discriminative training set and alignment test set. Translation quality is evaluated by translating a held-out translation test set. An additional translation set called the Maximum BLEU set is employed by the SMT system to train the weights associated with the components of its log-linear model (Och, 2003). The training corpora are publicly available: both the Arabic/English data and the French/English Hansards were released by LDC. We created the manual word alignments ourselves, following the Blinker guidelines (Melamed, 1998). To train our baseline systems we follow a standard procedure. The models were trained two times, first using French or Arabic as the source language and then using English as the source language. For each training direction, we run GIZA++ (Och and Ney, 2003), specifying 5 iterations of Model 1, 4 iterations of the HMM model (Vogel et al., 1996), and 4 iterations of Mod"
P06-1097,P04-1023,0,0.624189,"57.0 ( UNION ) 72.0 / 66.4 ( UNION ) 74.1 / 68.1 ( UNION ) 74.7 / 69.4 ( UNION ) 76.4 / 77.3 ( REFINED ) 79.6 / 80.4 ( REFINED ) 79.9 / 81.2 ( REFINED ) Table 7: Semi-Supervised Training Task F-measure the new algorithm4 . Like Ittycheriah and Roukos (2005), we converted the alignment discriminative training corpus links into a special corpus consisting of parallel sentences where each sentence consists only of a single word involved in the link. We found that the information in the links was “washed out” by the rest of the data and resulted in no change in the alignment test set’s F-Measure. Callison-Burch et al. (2004) showed in their work on combining alignments of lower and higher quality that the alignments of higher quality should be given a much higher weight than the lower quality alignments. Using this insight, we found that adding 10,000 copies of the special corpus to our training data resulted in the highest alignment test set gain, which was a small gain of 0.6 F-Measure. This result suggests that while the link information is useful for improving FMeasure, our improved methods for training are producing much larger improvements. 5 our algorithm produces heuristically symmetrized final alignments"
P06-1097,2001.mtsummit-papers.68,0,0.0129094,"tion of EMD were used to build phrasal SMT systems, as were the symmetrized Model 4 alignments (the baseline). Aside from the final alignment, all other resources were held constant between the baseline and contrastive SMT systems, including those based on lower level alignments models such as IBM Model 1. For all of our experiments, we use two language models, one built using the English portion of the training data and the other built using additional English news data. We run Maximum BLEU (Och, 2003) for 25 iterations individually for each system. Table 8 shows our results. We report BLEU (Papineni et al., 2001) multiplied by 100. We also show the F-measure after heuristic symmetrization of the alignment test sets. The table shows that F (A, S, α) = 1 α Precision(A,S) (1−α) + Recall (A,S) (3) 6 Previous Research Previous work on discriminative training for wordalignment differed most strongly from our approach in that it generally views word-alignment as a supervised task. Examples of this perspective include (Liu et al., 2005; Ittycheriah and Roukos, 2005; Moore, 2005; Taskar et al., 2005). All of these also used knowledge from one of the IBM Models in order to obtain competitive results 4 We would"
P06-1097,P03-1012,0,0.0569136,"ng constraints on clusters. For instance, in (Basu et al., 2004), the clustering system was supplied with pairs of instances labeled as belonging to the same or different clusters. with the baseline (with the exception of (Moore, 2005)). We interleave discriminative training with EM and are therefore performing semi-supervised training. We show that semi-supervised training leads to better word alignments than running unsupervised training followed by discriminative training. Another important difference with previous work is that we are concerned with generating many-to-many word alignments. Cherry and Lin (2003) and Taskar et al. (2005) compared their results with Model 4 using “intersection” by looking at AER (with the “Sure” versus “Possible” link distinction), and restricted themselves to considering 1-to-1 alignments. However, “union” and “refined” alignments, which are many-to-many, are what are used to build competitive phrasal SMT systems, because “intersection” performs poorly, despite having been shown to have the best AER scores for the French/English corpus we are using (Och and Ney, 2003). (Fraser and Marcu, 2006) recently found serious problems with AER both empirically and analytically,"
P06-1097,H05-1010,0,0.502317,"m BLEU (Och, 2003) for 25 iterations individually for each system. Table 8 shows our results. We report BLEU (Papineni et al., 2001) multiplied by 100. We also show the F-measure after heuristic symmetrization of the alignment test sets. The table shows that F (A, S, α) = 1 α Precision(A,S) (1−α) + Recall (A,S) (3) 6 Previous Research Previous work on discriminative training for wordalignment differed most strongly from our approach in that it generally views word-alignment as a supervised task. Examples of this perspective include (Liu et al., 2005; Ittycheriah and Roukos, 2005; Moore, 2005; Taskar et al., 2005). All of these also used knowledge from one of the IBM Models in order to obtain competitive results 4 We would like to thank an anonymous reviewer for suggesting that this experiment would be useful even when using a small discriminative training corpus. 774 S YSTEM A/E U NSUP. M ODEL 4 UNION A/E EMD 3 UNION F/E U NSUP. M ODEL 4 REFINED F/E EMD 2 REFINED BLEU 49.16 50.84 30.63 31.56 F- MEASURE 64.6 69.4 76.4 81.2 Table 8: Evaluation of Translation Quality tions with a relatively small number of parameters. An initial model is estimated in a supervised fashion using the labeled data, and this"
P06-1097,C96-2141,0,0.855901,"mponents of its log-linear model (Och, 2003). The training corpora are publicly available: both the Arabic/English data and the French/English Hansards were released by LDC. We created the manual word alignments ourselves, following the Blinker guidelines (Melamed, 1998). To train our baseline systems we follow a standard procedure. The models were trained two times, first using French or Arabic as the source language and then using English as the source language. For each training direction, we run GIZA++ (Och and Ney, 2003), specifying 5 iterations of Model 1, 4 iterations of the HMM model (Vogel et al., 1996), and 4 iterations of Model 4. We quantify the quality of the resulting hypothesized alignments with F-measure using the manually aligned sets. We present the results for three different conditions in Table 2. For the “F to E” direction the models assign non-zero probability to alignments consisting of links from one Foreign word to zero or more English words, while for “E to F” the models assign non-zero probability to alignments 3 Improving Word Alignments 3.1 Discriminative Reranking of the IBM Models We reinterpret the five groups of parameters of Model 4 listed in the first five lines of"
P06-1097,H05-1012,0,0.639419,"TARTING P OINT A/E EMD: I TERATION 1 A/E EMD: I TERATION 2 A/E EMD: I TERATION 3 F/E S TARTING P OINT F/E EMD: I TERATION 1 F/E EMD: I TERATION 2 F- MEASURE F TO E 58.6 / 54.4 68.4 / 62.2 69.8 / 63.1 70.6 / 65.4 72.4 / 73.9 78.7 / 80.2 79.4 / 80.5 F- MEASURE E TO F 47.7 / 39.9 61.6 / 57.7 64.1 / 59.5 64.3 / 59.2 71.5 / 71.8 79.3 / 79.6 79.8 / 80.5 B EST S YMM . 62.1 / 57.0 ( UNION ) 72.0 / 66.4 ( UNION ) 74.1 / 68.1 ( UNION ) 74.7 / 69.4 ( UNION ) 76.4 / 77.3 ( REFINED ) 79.6 / 80.4 ( REFINED ) 79.9 / 81.2 ( REFINED ) Table 7: Semi-Supervised Training Task F-measure the new algorithm4 . Like Ittycheriah and Roukos (2005), we converted the alignment discriminative training corpus links into a special corpus consisting of parallel sentences where each sentence consists only of a single word involved in the link. We found that the information in the links was “washed out” by the rest of the data and resulted in no change in the alignment test set’s F-Measure. Callison-Burch et al. (2004) showed in their work on combining alignments of lower and higher quality that the alignments of higher quality should be given a much higher weight than the lower quality alignments. Using this insight, we found that adding 10,0"
P06-1097,W98-1426,0,\N,Missing
P06-1097,2003.mtsummit-papers.53,0,\N,Missing
P06-1097,W04-3208,0,\N,Missing
P06-1097,soricut-etal-2002-using,1,\N,Missing
P06-1097,N04-1014,0,\N,Missing
P06-1097,J93-1004,0,\N,Missing
P06-1097,W02-2103,0,\N,Missing
P06-1097,J91-1004,0,\N,Missing
P06-1097,W95-0115,0,\N,Missing
P06-1097,W99-0604,0,\N,Missing
P06-1097,W99-0906,0,\N,Missing
P06-1097,J97-2001,0,\N,Missing
P06-1097,N04-1035,1,\N,Missing
P06-1097,J99-4005,0,\N,Missing
P06-1097,1994.amta-1.18,0,\N,Missing
P06-1097,1999.tc-1.8,0,\N,Missing
P06-1097,W99-0626,0,\N,Missing
P06-1097,W96-0501,0,\N,Missing
P06-1097,W95-0114,0,\N,Missing
P06-1097,A00-2023,0,\N,Missing
P06-1097,J98-1001,0,\N,Missing
P06-1097,J97-4005,0,\N,Missing
P06-1097,W96-0208,0,\N,Missing
P06-1097,C00-2172,0,\N,Missing
P06-1097,C00-2135,0,\N,Missing
P06-1097,C00-2105,0,\N,Missing
P06-1097,C94-1007,0,\N,Missing
P06-1097,W00-0801,0,\N,Missing
P06-1097,W06-1626,0,\N,Missing
P06-1097,C94-2183,0,\N,Missing
P06-1097,C00-2089,0,\N,Missing
P06-1097,W98-1230,0,\N,Missing
P06-1097,2002.tmi-papers.20,0,\N,Missing
P06-1097,W02-1021,0,\N,Missing
P06-1097,N03-2036,0,\N,Missing
P06-1097,W01-1407,0,\N,Missing
P06-1097,P98-1069,0,\N,Missing
P06-1097,C98-1066,0,\N,Missing
P06-1097,J03-3002,0,\N,Missing
P06-1097,P00-1059,0,\N,Missing
P06-1097,W98-1005,0,\N,Missing
P06-1097,C00-1007,0,\N,Missing
P06-1097,C02-1012,0,\N,Missing
P06-1097,C96-2098,0,\N,Missing
P06-1097,J07-3002,1,\N,Missing
P06-1097,W01-1412,0,\N,Missing
P06-1097,N01-1020,0,\N,Missing
P06-1097,J90-2002,0,\N,Missing
P06-1097,P03-1054,0,\N,Missing
P06-1097,P02-1040,0,\N,Missing
P06-1097,P95-1026,0,\N,Missing
P06-1097,P95-1034,0,\N,Missing
P06-1097,W01-1409,0,\N,Missing
P06-1097,P99-1067,0,\N,Missing
P06-1097,J94-4003,0,\N,Missing
P06-1097,N06-1031,0,\N,Missing
P06-1097,P98-1116,0,\N,Missing
P06-1097,C98-1112,0,\N,Missing
P06-1097,P02-1039,0,\N,Missing
P06-1097,1995.tmi-1.21,0,\N,Missing
P06-1097,P01-1067,0,\N,Missing
P06-1097,J95-4004,0,\N,Missing
P06-1097,P03-1011,0,\N,Missing
P06-1097,P01-1050,1,\N,Missing
P06-1097,P93-1003,0,\N,Missing
P06-1097,P91-1034,0,\N,Missing
P06-1097,J98-1004,0,\N,Missing
P06-1097,knight-al-onaizan-1998-translation,0,\N,Missing
P06-1097,N06-1001,1,\N,Missing
P06-1097,J96-4002,0,\N,Missing
P06-1097,J04-2003,0,\N,Missing
P06-1097,P04-1067,0,\N,Missing
P06-1097,P03-1057,0,\N,Missing
P06-1097,A00-1031,0,\N,Missing
P06-1097,N04-1022,0,\N,Missing
P06-1097,P06-1055,0,\N,Missing
P06-1097,W03-0430,0,\N,Missing
P06-1097,P03-2041,0,\N,Missing
P06-1097,P05-1074,0,\N,Missing
P06-1097,P99-1068,0,\N,Missing
P06-1097,P96-1021,0,\N,Missing
P06-1097,P02-1051,0,\N,Missing
P06-1097,N03-1017,1,\N,Missing
P06-1097,P02-1038,0,\N,Missing
P06-1097,P97-1037,0,\N,Missing
P06-1097,J97-3002,0,\N,Missing
P06-1097,W02-1039,0,\N,Missing
P06-1097,P04-1068,0,\N,Missing
P06-1097,J03-1005,0,\N,Missing
P06-1097,P06-1121,1,\N,Missing
P06-1097,J08-3004,0,\N,Missing
P06-1097,N04-1021,0,\N,Missing
P06-1097,P97-1017,0,\N,Missing
P06-1097,2006.iwslt-evaluation.12,0,\N,Missing
P06-1097,P03-1020,0,\N,Missing
P06-1097,W01-0504,0,\N,Missing
P06-1097,W00-2004,0,\N,Missing
P06-1097,fleming-cohen-2000-mixed,0,\N,Missing
P06-1097,N06-1033,0,\N,Missing
P06-1097,P00-1056,0,\N,Missing
P06-1097,P97-1047,0,\N,Missing
P06-1097,W00-1401,0,\N,Missing
P06-1097,P96-1029,0,\N,Missing
P06-1097,P01-1030,1,\N,Missing
P10-1048,P04-1021,0,0.0650915,"model decides whether Differently in Different Contexts to translate or transliterate and how it is able to choose among different valid transliterations given Hindi Urdu SAMPA Gloss the context. Section 8 concludes the paper. / simA Border/Seema / / 2 Previous Work There has been a significant amount of work on transliteration. We can break down previous work into three groups. The first group is generic transliteration work, which is evaluated outside of the context of translation. This work uses either grapheme or phoneme based models to transliterate words lists (Knight and Graehl, 1998; Li et al., 2004; Ekbal et al., 2006; Malik et al., 2008). The work by Malik et al. addresses Hindi to Urdu transliteration using hand-crafted rules and a phonemic representation; it ignores translation context. A second group deals with out-of-vocabulary words for SMT systems built on large parallel corpora, and therefore focuses on name transliteration, which is largely independent of context. AlOnaizan and Knight (2002) transliterate Arabic NEs into English and score them against their respective translations using a modified IBM Model 1. The options are further re-ranked based on different measures such a"
P10-1048,P02-1051,0,0.0189206,"Missing"
P10-1048,C08-1068,0,0.105223,"Different Contexts to translate or transliterate and how it is able to choose among different valid transliterations given Hindi Urdu SAMPA Gloss the context. Section 8 concludes the paper. / simA Border/Seema / / 2 Previous Work There has been a significant amount of work on transliteration. We can break down previous work into three groups. The first group is generic transliteration work, which is evaluated outside of the context of translation. This work uses either grapheme or phoneme based models to transliterate words lists (Knight and Graehl, 1998; Li et al., 2004; Ekbal et al., 2006; Malik et al., 2008). The work by Malik et al. addresses Hindi to Urdu transliteration using hand-crafted rules and a phonemic representation; it ignores translation context. A second group deals with out-of-vocabulary words for SMT systems built on large parallel corpora, and therefore focuses on name transliteration, which is largely independent of context. AlOnaizan and Knight (2002) transliterate Arabic NEs into English and score them against their respective translations using a modified IBM Model 1. The options are further re-ranked based on different measures such as web counts and using coreference to res"
P10-1048,P06-2025,0,0.116436,"ether Differently in Different Contexts to translate or transliterate and how it is able to choose among different valid transliterations given Hindi Urdu SAMPA Gloss the context. Section 8 concludes the paper. / simA Border/Seema / / 2 Previous Work There has been a significant amount of work on transliteration. We can break down previous work into three groups. The first group is generic transliteration work, which is evaluated outside of the context of translation. This work uses either grapheme or phoneme based models to transliterate words lists (Knight and Graehl, 1998; Li et al., 2004; Ekbal et al., 2006; Malik et al., 2008). The work by Malik et al. addresses Hindi to Urdu transliteration using hand-crafted rules and a phonemic representation; it ignores translation context. A second group deals with out-of-vocabulary words for SMT systems built on large parallel corpora, and therefore focuses on name transliteration, which is largely independent of context. AlOnaizan and Knight (2002) transliterate Arabic NEs into English and score them against their respective translations using a modified IBM Model 1. The options are further re-ranked based on different measures such as web counts and usi"
P10-1048,moore-2002-fast,0,0.0206337,"Missing"
P10-1048,J03-1002,0,0.0455825,"Missing"
P10-1048,2001.mtsummit-papers.68,0,0.0625189,"Missing"
P10-1048,P08-1045,0,0.0400247,"Missing"
P10-1048,W07-0703,0,0.192128,"es such as web counts and using coreference to resolve ambiguity. These re-ranking methodologies can not be performed in SMT at the decoding time. An efficient way to compute and re-rank the transliterations of NEs and integrate them on the fly might be possible. However, this is not practical in our case as our model considers transliterations of all input words and not just NEs. A log-linear block transliteration model is applied to OOV NEs in Arabic to English SMT by Zhao et al. (2007). This work is also transliterating only NEs and not doing any disambiguation. The best method proposed by Kashani et al. (2007) integrates translations provided by external sources such as transliteration or rule-base translation of numbers and dates, for an arbitrary number of entries within the input text. Our work is different from Kashani et al. (2007) in that our model compares transliterations with translations Table 2: Hindi Words That Can Be Translated or Transliterated in Different Contexts which focus primarily on name transliteration, because we need different transliterations in different contexts; in their case context is irrelevant. For example: consider the problem of transliterating the English word “r"
P10-1048,2009.mtsummit-caasl.12,0,0.0167695,"table dynamically such that they can directly compete with translations during decoding. This is closer to our approach except that we use transliteration as an alternative to translation for all Hindi words. Our focus is disambiguation of Hindi homonyms whereas they are concentrating only on transliterating NE’s. Moreover, they are working with a large bitext so they can rely on their translation model and only need to transliterate NEs and OOVs. Our translation model is based on data which is both sparse and noisy. Therefore we pit transliterations against translations for every input word. Sinha (2009) presents a rule-based MT system that uses Hindi as a pivot to translate from English to Urdu. This work also uses transliteration only for the translation of unknown words. Their work can not be used for direct translation from Hindi to Urdu (independently of English) “due to various ambiguous mappings that have to be resolved”. The third group uses transliteration models inside of a cross-lingual IR system (AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003; Pirkola et al., 2003). Picking a single best transliteration or translation in context is not important in an IR system. Instead,"
P10-1048,W03-1508,0,0.0274178,"translation model is based on data which is both sparse and noisy. Therefore we pit transliterations against translations for every input word. Sinha (2009) presents a rule-based MT system that uses Hindi as a pivot to translate from English to Urdu. This work also uses transliteration only for the translation of unknown words. Their work can not be used for direct translation from Hindi to Urdu (independently of English) “due to various ambiguous mappings that have to be resolved”. The third group uses transliteration models inside of a cross-lingual IR system (AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003; Pirkola et al., 2003). Picking a single best transliteration or translation in context is not important in an IR system. Instead, all the options are used by giving them weights and context is typically not taken into account. 3 ematical formulation of our two models, Model-1 and Model-2. 3.1 Model-1 : Conditional Probability Model Applying a noisy channel model to compute the most probable translation u ˆn1 , we get: p(un1 )p(hn1 |un1 ) p(un1 |hn1 ) = arg max arg max n n u1 u1 (1) 3.1.1 Language Model The language model (LM) p(un1 ) is implemented as an n-gram model using the SRILM-Toolkit"
P10-1048,N07-1046,0,0.178172,"ainst their respective translations using a modified IBM Model 1. The options are further re-ranked based on different measures such as web counts and using coreference to resolve ambiguity. These re-ranking methodologies can not be performed in SMT at the decoding time. An efficient way to compute and re-rank the transliterations of NEs and integrate them on the fly might be possible. However, this is not practical in our case as our model considers transliterations of all input words and not just NEs. A log-linear block transliteration model is applied to OOV NEs in Arabic to English SMT by Zhao et al. (2007). This work is also transliterating only NEs and not doing any disambiguation. The best method proposed by Kashani et al. (2007) integrates translations provided by external sources such as transliteration or rule-base translation of numbers and dates, for an arbitrary number of entries within the input text. Our work is different from Kashani et al. (2007) in that our model compares transliterations with translations Table 2: Hindi Words That Can Be Translated or Transliterated in Different Contexts which focus primarily on name transliteration, because we need different transliterations in d"
P10-1048,koen-2004-pharaoh,0,0.0404474,"ng convention in Urdu. For example (can go ; d ZA s@kt de) is alternathe previous section. Putting (11) and (12) in (10) we get p(hn1 |un1 ) = n Y λpw (hi , ui ) + (1 − λ)pc (hi , ui ) λpw (ui ) + (1 − λ)pc (ui ) (13) The idea is to interpolate joint probabilities and divide them by the interpolated marginals. The final equation for Model-2 is given as: i=1 u ˆn1 = arg max n u1 n Y pLM (ui |ui−1 i−k )× i=1 λpw (hi , ui ) + (1 − λ)pc (hi , ui ) λpw (ui ) + (1 − λ)pc (ui ) 3.3 (14) Search The decoder performs a stack-based search using a beam-search algorithm similar to the one used in Pharoah (Koehn, 2004a). It searches for an Urdu string that maximizes the product of translation probability and the language model probability (equation 1) by translating one Hindi word at a time. It is implemented as a two-level process. At the lower level, it computes n-best transliterations for each Hindi word hi according to pc (h, u). The joint probabilities given by pc (h, u) are marginalized for each Urdu transliteration to give pc (h|u). At the higher level, transliteration probabilities are interpolated with pw (h|u) and then multiplied with language model probabilities to give the probability of a hypo"
P10-1048,W04-3250,0,0.0158741,"ng convention in Urdu. For example (can go ; d ZA s@kt de) is alternathe previous section. Putting (11) and (12) in (10) we get p(hn1 |un1 ) = n Y λpw (hi , ui ) + (1 − λ)pc (hi , ui ) λpw (ui ) + (1 − λ)pc (ui ) (13) The idea is to interpolate joint probabilities and divide them by the interpolated marginals. The final equation for Model-2 is given as: i=1 u ˆn1 = arg max n u1 n Y pLM (ui |ui−1 i−k )× i=1 λpw (hi , ui ) + (1 − λ)pc (hi , ui ) λpw (ui ) + (1 − λ)pc (ui ) 3.3 (14) Search The decoder performs a stack-based search using a beam-search algorithm similar to the one used in Pharoah (Koehn, 2004a). It searches for an Urdu string that maximizes the product of translation probability and the language model probability (equation 1) by translating one Hindi word at a time. It is implemented as a two-level process. At the lower level, it computes n-best transliterations for each Hindi word hi according to pc (h, u). The joint probabilities given by pc (h, u) are marginalized for each Urdu transliteration to give pc (h|u). At the higher level, transliteration probabilities are interpolated with pw (h|u) and then multiplied with language model probabilities to give the probability of a hypo"
P10-1048,N10-1077,1,\N,Missing
P10-1048,P02-1040,0,\N,Missing
P10-1048,P07-2045,0,\N,Missing
P10-1048,J98-4003,0,\N,Missing
P11-1044,W10-2407,0,0.0865748,"Missing"
P11-1044,eisele-chen-2010-multiun,0,0.0441317,"corpora, we apply it to parallel corpora of English/Hindi and English/Arabic, and compare the transliteration mining results with a gold standard. 434 Table 2: Cognates from English/Russian corpus extracted by our system as transliteration pairs. None of them are correct transliteration pairs according to the gold standard. We use the English/Hindi corpus from the shared task on word alignment, organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts (WA05) (Martin et al., 2005). For English/Arabic, we use a freely available parallel corpus from the United Nations (UN) (Eisele and Chen, 2010). We randomly take 200,000 parallel sentences from the UN corpus of the year 2000. We create gold standards for both language pairs by randomly selecting a few thousand word pairs from the lists of word pairs extracted from the two corpora. We manually tag them as either transliterations or non-transliterations. The English/Hindi gold standard contains 180 transliteration pairs and 2084 non-transliteration pairs and the English/Arabic gold standard contains 288 transliteration pairs and 6639 non-transliteration pairs. We have submitted these gold standards with the paper. They are available to"
P11-1044,W08-0509,0,0.0150714,"ation pairs as transliterations (see table 3, last column). Most of these word pairs are close transliterations and differ by only one or two characters from perfect transliteration pairs. The close transliteration pairs provide many valid multigrams which may be helpful for the mining system. 4.3 Integration into Word Alignment Model In the previous section, we presented a method for the extraction of transliteration pairs from a parallel corpus. In this section, we will explain how to build a transliteration module on the extracted transliteration pairs and how to integrate it into MGIZA++ (Gao and Vogel, 2008) by interpolating it with the ttable probabilities of the IBM models and the HMM model. MGIZA++ is an extension of GIZA++. It has the ability to resume training from any model rather than starting with Model1. 4.3.1 Modified EM Training of the Word Alignment Models GIZA++ applies the IBM models (Brown et al., 1993) and the HMM model (Vogel et al., 1996) in both directions, i.e., source to target and target to source. The alignments are refined using the grow-diag-final-and heuristic (Koehn et al., 2003). GIZA++ generates a list of translation pairs with alignment probabilities, which is called"
P11-1044,D09-1024,0,0.039788,"-supervised systems on three language pairs. We are only aware of one previous work which uses transliteration information for word alignment. 6 They use the seed data as positive examples. In order to obtain also negative examples, they generate all possible word pairs from the source and target words in the seed data and extract the ones which are not transliterations but have a common substring of some minimal length. 7 They use the phrase table of Moses to build a mapping table between source and target characters. The mapping table is then used to construct a finite state transducer. 438 Hermjakob (2009) proposed a linguistically focused word alignment system which uses many features including hand-crafted transliteration rules for Arabic/English alignment. His evaluation did not explicitly examine the effect of transliteration (alone) on word alignment. We show that the integration of a transliteration system based on unsupervised transliteration mining increases the word alignment quality for the two language pairs we tested. 6 Conclusion We proposed a method to automatically extract transliteration pairs from parallel corpora without supervision or linguistic knowledge. We evaluated it aga"
P11-1044,W10-2405,0,0.0779976,"the test data and add them to the training data. Our method is different from the method of Sherif and Kondrak (2007) as our method is fully unsupervised, and because in each iteration, they add the most probable transliteration pairs to the training data, while we filter out the least probable transliteration pairs from the training data. The transliteration mining systems of the four NEWS10 participants are either based on discriminative or on generative methods. All systems use manually labelled (seed) data for the initial training. The system based on the edit distance method submitted by Jiampojamarn et al. (2010) performs best for the English/Russian task. Jiampojamarn et al. (2010) submitted another system based on a standard n-gram kernel which ranked first for the English/Hindi and English/Tamil tasks.6 For the English/Arabic task, the transliteration mining system of Noeman and Madkour (2010) was best. They normalize the English and Arabic characters in the training data which increases the recall.7 Our transliteration extraction method differs in that we extract transliteration pairs from a parallel corpus without supervision. The results of the NEWS10 experiments (Kumaran et al., 2010) show that"
P11-1044,P06-1103,0,0.112777,"WA05. Three systems, one limited and two un-limited, participated in the English/Hindi task. We outperform the limited system and one un-limited system. 5 Previous Research Previous work on transliteration mining uses a manually labelled set of training data to extract transliteration pairs from a parallel corpus or comparable corpora. The training data may contain a few hundred randomly selected transliteration pairs from a transliteration dictionary (Yoon et al., 2007; Sproat et al., 2006; Lee and Chang, 2003) or just a few carefully selected transliteration pairs (Sherif and Kondrak, 2007; Klementiev and Roth, 2006). Our work is more challenging as we extract transliteration pairs without using transliteration dictionaries or gold standard transliteration pairs. Klementiev and Roth (2006) initialize their transliteration model with a list of 20 transliteration tion; so we did not interpolate in just those iterations of training where we were transitioning from one model to the next. pairs. Their model makes use of temporal scoring to rank the candidate transliterations. A lot of work has been done on discovering and learning transliterations from comparable corpora by using temporal and phonetic informat"
P11-1044,N03-1017,0,0.329806,"am models of order > 1 did not work well because these models tended to learn noise (information from non-transliteration pairs) in the training data. For our experiments, we only trained g2p with the unigram model. In test mode, we look for the best sequence of multigrams given a fixed source and target string and return the probability of this sequence. For the mining process, we trained g2p on lists containing both transliteration pairs and nontransliteration pairs. 2.2 Statistical Machine Transliteration System We build a phrase-based MT system for transliteration using the Moses toolkit (Koehn et al., 2003). We also tried using g2p for implementing the transliteration decoder but found Moses to perform better. Moses has the advantage of using Minimum Error Rate Training (MERT) which optimizes transliteration accuracy rather than the likelihood of the training data as g2p does. The training data contains more non-transliteration pairs than transliteration pairs. We don’t want to maximize the likelihood of the non-transliteration pairs. Instead we want to optimize the transliteration performance for test data. Secondly, it is easy to use a large language model (LM) with Moses. We build the LM on t"
P11-1044,W10-2404,0,0.0889357,"Missing"
P11-1044,W03-0317,0,0.0228532,"sion of our word alignment system We compared our word alignment results with the systems presented at WA05. Three systems, one limited and two un-limited, participated in the English/Hindi task. We outperform the limited system and one un-limited system. 5 Previous Research Previous work on transliteration mining uses a manually labelled set of training data to extract transliteration pairs from a parallel corpus or comparable corpora. The training data may contain a few hundred randomly selected transliteration pairs from a transliteration dictionary (Yoon et al., 2007; Sproat et al., 2006; Lee and Chang, 2003) or just a few carefully selected transliteration pairs (Sherif and Kondrak, 2007; Klementiev and Roth, 2006). Our work is more challenging as we extract transliteration pairs without using transliteration dictionaries or gold standard transliteration pairs. Klementiev and Roth (2006) initialize their transliteration model with a list of 20 transliteration tion; so we did not interpolate in just those iterations of training where we were transitioning from one model to the next. pairs. Their model makes use of temporal scoring to rank the candidate transliterations. A lot of work has been done"
P11-1044,W05-0809,0,0.0389042,"oportion of transliterations than a parallel corpus. In order to examine how well our method performs on parallel corpora, we apply it to parallel corpora of English/Hindi and English/Arabic, and compare the transliteration mining results with a gold standard. 434 Table 2: Cognates from English/Russian corpus extracted by our system as transliteration pairs. None of them are correct transliteration pairs according to the gold standard. We use the English/Hindi corpus from the shared task on word alignment, organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts (WA05) (Martin et al., 2005). For English/Arabic, we use a freely available parallel corpus from the United Nations (UN) (Eisele and Chen, 2010). We randomly take 200,000 parallel sentences from the UN corpus of the year 2000. We create gold standards for both language pairs by randomly selecting a few thousand word pairs from the lists of word pairs extracted from the two corpora. We manually tag them as either transliterations or non-transliterations. The English/Hindi gold standard contains 180 transliteration pairs and 2084 non-transliteration pairs and the English/Arabic gold standard contains 288 transliteration pa"
P11-1044,W10-2408,0,0.0371531,"bable transliteration pairs from the training data. The transliteration mining systems of the four NEWS10 participants are either based on discriminative or on generative methods. All systems use manually labelled (seed) data for the initial training. The system based on the edit distance method submitted by Jiampojamarn et al. (2010) performs best for the English/Russian task. Jiampojamarn et al. (2010) submitted another system based on a standard n-gram kernel which ranked first for the English/Hindi and English/Tamil tasks.6 For the English/Arabic task, the transliteration mining system of Noeman and Madkour (2010) was best. They normalize the English and Arabic characters in the training data which increases the recall.7 Our transliteration extraction method differs in that we extract transliteration pairs from a parallel corpus without supervision. The results of the NEWS10 experiments (Kumaran et al., 2010) show that no single system performs well on all language pairs. Our unsupervised method seems robust as its performance is similar to or better than many of the semi-supervised systems on three language pairs. We are only aware of one previous work which uses transliteration information for word a"
P11-1044,J03-1002,0,0.0209882,"g criterion and return the filtered data set from this iteration. The stopping criterion uses unlabelled held-out data to predict the optimal stopping point. The following sections describe the transliteration mining method in detail. 3.1 Methodology We will first describe the iterative filtering algorithm (Algorithm 1) and then the algorithm for the stopping criterion (Algorithm 2). In practice, we first run Algorithm 2 for 100 iterations to determine the best number of iterations. Then, we run Algorithm 1 for that many iterations. Initially, the parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003), and the alignments are refined using the grow-diag-final-and heuristic (Koehn et al., 2003). We extract all word pairs which occur as 1-to-1 alignments in the word-aligned corpus. We ignore non-1-to-1 alignments because they are less likely to be transliterations for most language pairs. The extracted set of word pairs will be called “list of word pairs” later on. We use the list of word pairs as the training data for Algorithm 1. Algorithm 1 builds a joint sequence model using g2p on the training data and computes the joint probability of all word pairs according to g2p. We normalize the pr"
P11-1044,P07-1109,0,0.223769,"the systems presented at WA05. Three systems, one limited and two un-limited, participated in the English/Hindi task. We outperform the limited system and one un-limited system. 5 Previous Research Previous work on transliteration mining uses a manually labelled set of training data to extract transliteration pairs from a parallel corpus or comparable corpora. The training data may contain a few hundred randomly selected transliteration pairs from a transliteration dictionary (Yoon et al., 2007; Sproat et al., 2006; Lee and Chang, 2003) or just a few carefully selected transliteration pairs (Sherif and Kondrak, 2007; Klementiev and Roth, 2006). Our work is more challenging as we extract transliteration pairs without using transliteration dictionaries or gold standard transliteration pairs. Klementiev and Roth (2006) initialize their transliteration model with a list of 20 transliteration tion; so we did not interpolate in just those iterations of training where we were transitioning from one model to the next. pairs. Their model makes use of temporal scoring to rank the candidate transliterations. A lot of work has been done on discovering and learning transliterations from comparable corpora by using te"
P11-1044,P06-1010,0,0.0192233,"and Pti is the precision of our word alignment system We compared our word alignment results with the systems presented at WA05. Three systems, one limited and two un-limited, participated in the English/Hindi task. We outperform the limited system and one un-limited system. 5 Previous Research Previous work on transliteration mining uses a manually labelled set of training data to extract transliteration pairs from a parallel corpus or comparable corpora. The training data may contain a few hundred randomly selected transliteration pairs from a transliteration dictionary (Yoon et al., 2007; Sproat et al., 2006; Lee and Chang, 2003) or just a few carefully selected transliteration pairs (Sherif and Kondrak, 2007; Klementiev and Roth, 2006). Our work is more challenging as we extract transliteration pairs without using transliteration dictionaries or gold standard transliteration pairs. Klementiev and Roth (2006) initialize their transliteration model with a list of 20 transliteration tion; so we did not interpolate in just those iterations of training where we were transitioning from one model to the next. pairs. Their model makes use of temporal scoring to rank the candidate transliterations. A lot"
P11-1044,W06-1630,0,0.179402,"work is more challenging as we extract transliteration pairs without using transliteration dictionaries or gold standard transliteration pairs. Klementiev and Roth (2006) initialize their transliteration model with a list of 20 transliteration tion; so we did not interpolate in just those iterations of training where we were transitioning from one model to the next. pairs. Their model makes use of temporal scoring to rank the candidate transliterations. A lot of work has been done on discovering and learning transliterations from comparable corpora by using temporal and phonetic information (Tao et al., 2006; Klementiev and Roth, 2006; Sproat et al., 2006). We do not have access to this information. Sherif and Kondrak (2007) train a probabilistic transducer on 14 manually constructed transliteration pairs of English/Arabic. They iteratively extract transliteration pairs from the test data and add them to the training data. Our method is different from the method of Sherif and Kondrak (2007) as our method is fully unsupervised, and because in each iteration, they add the most probable transliteration pairs to the training data, while we filter out the least probable transliteration pairs from the"
P11-1044,C96-2141,0,0.420695,"tion, we presented a method for the extraction of transliteration pairs from a parallel corpus. In this section, we will explain how to build a transliteration module on the extracted transliteration pairs and how to integrate it into MGIZA++ (Gao and Vogel, 2008) by interpolating it with the ttable probabilities of the IBM models and the HMM model. MGIZA++ is an extension of GIZA++. It has the ability to resume training from any model rather than starting with Model1. 4.3.1 Modified EM Training of the Word Alignment Models GIZA++ applies the IBM models (Brown et al., 1993) and the HMM model (Vogel et al., 1996) in both directions, i.e., source to target and target to source. The alignments are refined using the grow-diag-final-and heuristic (Koehn et al., 2003). GIZA++ generates a list of translation pairs with alignment probabilities, which is called the t-table. In this section, we propose a method to modify the translation probabilities of the t-table by interpolating the translation counts with transliteration counts. The interpolation is done in both directions. In the following, we will only consider the e-to-f direction. The transliteration module which is used to calculate the conditional tr"
P11-1044,P07-1015,0,0.0435323,"of baseline GIZA++ and Pti is the precision of our word alignment system We compared our word alignment results with the systems presented at WA05. Three systems, one limited and two un-limited, participated in the English/Hindi task. We outperform the limited system and one un-limited system. 5 Previous Research Previous work on transliteration mining uses a manually labelled set of training data to extract transliteration pairs from a parallel corpus or comparable corpora. The training data may contain a few hundred randomly selected transliteration pairs from a transliteration dictionary (Yoon et al., 2007; Sproat et al., 2006; Lee and Chang, 2003) or just a few carefully selected transliteration pairs (Sherif and Kondrak, 2007; Klementiev and Roth, 2006). Our work is more challenging as we extract transliteration pairs without using transliteration dictionaries or gold standard transliteration pairs. Klementiev and Roth (2006) initialize their transliteration model with a list of 20 transliteration tion; so we did not interpolate in just those iterations of training where we were transitioning from one model to the next. pairs. Their model makes use of temporal scoring to rank the candidate tr"
P11-1044,J93-2003,0,\N,Missing
P11-1105,J93-2003,0,0.0466104,"near order. The generation of the second (and subsequent) German word in a multi-word cept can be delayed by gaps, jumps and the Generate Source Only operation defined below. Continue Source Cept: The German words added 2 However, Crego and Yvon (2009), in their N-gram system, use split rules to handle target-side gaps and show a slight improvement on a Chinese-English translation task. 3 Generating the English words in order is also what the decoder does when translating from German to English. 4 A cept is a group of words in one language translated as a minimal unit in one specific context (Brown et al., 1993). to the queue by the Generate (X,Y) operation are generated by the Continue Source Cept operation. Each Continue Source Cept operation removes one German word from the queue and copies it to the German string. If X contains more than one German word, say n many, then it requires n translation operations, an initial Generate (X1 ...Xn , Y ) operation and n − 1 Continue Source Cept operations. For example “hat...gelesen – read” is generated by the operation Generate (hat gelesen, read), which adds “hat” and “read” to the German and English strings and “gelesen” to a queue. A Continue Source Cep"
P11-1105,J07-2003,0,0.0818341,"n continuous phrases. Given the phrase inventory in Table 1, phrasal MT is able to generate example in Figure 1(a). The information “hat...gelesen – read” is internal to the phrase pair “hat er ein buch gelesen – he read a book”, and is therefore handled conveniently. On the other hand, the phrase table does not have the entry “hat er eine zeitung gelesen – he read a newspaper” (Figure 1(b)). Hence, there is no option but to translate “hat...gelesen” separately, translating “hat” to “has” which is a common translation for “hat” but wrong in the given context. Context-free hierarchical models (Chiang, 2007; Melamed, 2004) have rules like “hat er X gelesen – he read X” to handle such cases. Galley and Manning (2010) recently solved this problem for phrasal MT by extracting phrase pairs with source and target-side gaps. Our model can also use tuples with source-side discontinuities. The above sentence would be generated by the following sequence of operations: (i) generate “dann – then” (ii) insert a gap (iii) generate “er – he” (iv) backward jump to the gap (v) generate “hat...[gelesen] – read” (only “hat” and “read” are added to the sentences yet) (vi) jump forward to the right-most source word"
P11-1105,2009.eamt-1.10,0,0.0357915,"r discontinuous, but the words in Y (English) must be consecutive. This operation causes the words in Y and the first word in X to be added to the English and German strings respectively, that were generated so far. Subsequent words in X are added to a queue to be generated later. All the English words in Y are generated immediately because English is generated in linear order. The generation of the second (and subsequent) German word in a multi-word cept can be delayed by gaps, jumps and the Generate Source Only operation defined below. Continue Source Cept: The German words added 2 However, Crego and Yvon (2009), in their N-gram system, use split rules to handle target-side gaps and show a slight improvement on a Chinese-English translation task. 3 Generating the English words in order is also what the decoder does when translating from German to English. 4 A cept is a group of words in one language translated as a minimal unit in one specific context (Brown et al., 1993). to the queue by the Generate (X,Y) operation are generated by the Continue Source Cept operation. Each Continue Source Cept operation removes one German word from the queue and copies it to the German string. If X contains more tha"
P11-1105,C10-2023,0,0.0911957,"ing of translation context (Crego et al., 2005a). The tuples used in N-gram systems are much smaller translation units than phrases and are extracted in such a way that a unique segmentation of each bilingual sentence pair is produced. This helps N-gram systems to avoid the spurious phrasal segmentation problem. Reordering works by linearization of the source side and tuple unfolding (Crego et al., 2005b). The decoder uses word lattices which are built with linguistically motivated re-write rules. This mechanism is further enhanced with an N-gram model of bilingual units built using POS tags (Crego and Yvon, 2010). A drawback of their reordering approach is that search is only performed on a small number of reorderings that are pre-calculated on the source side independently of the target side. Often, the evidence for the correct ordering is provided by the target-side language model (LM). In the N-gram approach, the LM only plays a role in selecting between the precalculated orderings. Our model is based on the N-gram SMT model, but differs from previous N-gram systems in some important aspects. It uses operation n-grams rather than tuple n-grams. The reordering approach is entirely different and cons"
P11-1105,2005.iwslt-1.23,0,0.0188713,"hrasal MT is spurious phrasal segmentation. Given a sentence pair and a corresponding word alignment, phrasal MT can learn an arbitrary number of source segmentations. This is problematic during decoding because different compositions of the same minimal phrasal units are allowed to compete with each other. 2.2 Relation of our work to N-gram SMT N-gram based SMT is an alternative to hierarchical and non-hierarchical phrase-based systems. The main difference between phrase-based and N-gram SMT is the extraction procedure of translation units and the statistical modeling of translation context (Crego et al., 2005a). The tuples used in N-gram systems are much smaller translation units than phrases and are extracted in such a way that a unique segmentation of each bilingual sentence pair is produced. This helps N-gram systems to avoid the spurious phrasal segmentation problem. Reordering works by linearization of the source side and tuple unfolding (Crego et al., 2005b). The decoder uses word lattices which are built with linguistically motivated re-write rules. This mechanism is further enhanced with an N-gram model of bilingual units built using POS tags (Crego and Yvon, 2010). A drawback of their reo"
P11-1105,2005.mtsummit-papers.37,0,0.178798,"Missing"
P11-1105,N10-1140,0,0.215417,"e in Figure 1(a). The information “hat...gelesen – read” is internal to the phrase pair “hat er ein buch gelesen – he read a book”, and is therefore handled conveniently. On the other hand, the phrase table does not have the entry “hat er eine zeitung gelesen – he read a newspaper” (Figure 1(b)). Hence, there is no option but to translate “hat...gelesen” separately, translating “hat” to “has” which is a common translation for “hat” but wrong in the given context. Context-free hierarchical models (Chiang, 2007; Melamed, 2004) have rules like “hat er X gelesen – he read X” to handle such cases. Galley and Manning (2010) recently solved this problem for phrasal MT by extracting phrase pairs with source and target-side gaps. Our model can also use tuples with source-side discontinuities. The above sentence would be generated by the following sequence of operations: (i) generate “dann – then” (ii) insert a gap (iii) generate “er – he” (iv) backward jump to the gap (v) generate “hat...[gelesen] – read” (only “hat” and “read” are added to the sentences yet) (vi) jump forward to the right-most source word so far generated (vii) insert a gap (viii) continue the source cept (“gelesen” is inserted now) (ix) backward"
P11-1105,N03-1017,0,0.0592803,"and Generate Source Only. For a source cept coverd by indexes X1 , . . . , Xn , we get the feature value gj = X1 − S, where S is the index of the left-most source word where a gap starts. 8 Let X1 , . . . , Xn and Y1 , . . . , Ym represent indexes of the source words covered by the tuples tj and tj−1 respectively. The distance between tj and tj−1 is given as dj = min(|Xk − Yl |− 1) ∀ Xk ∈ {X1 , . . . , Xn } and ∀ Yl ∈ {Y1 , . . . , Ym } 1050 Lexical Features We also use source-to-target p(e|f ) and target-to-source p(f |e) lexical translation probabilities. Our lexical features are standard (Koehn et al., 2003). The estimation is motivated by IBM Model-1. Given a tuple ti with source words f = f1 , f2 , . . . , fn , target words e = e1 , e2 , . . . , em and an alignment a between the source word positions x = 1, . . . , n and the target word positions y = 1, . . . , m, the lexical feature pw (f |e) is computed as follows: n Y X 1 pw (f |e, a) = w(fx |ey ) |{y : (x, y) ∈ a}| x=1 ∀(x,y)∈a pw (e|f, a) is computed in the same way. 5 Decoding Our decoder for the new model performs a stackbased search with a beam-search algorithm similar to that used in Pharoah (Koehn, 2004a). Given an input sentence F ,"
P11-1105,2005.iwslt-1.8,0,0.0973201,"system on three data sets with German-to-English, Spanish-to-English and Frenchto-English news translations, respectively. We used data from the 4th version of the Europarl Corpus and the News Commentary which was made available for the translation task of the Fourth Workshop on Statistical Machine Translation.11 We use 200K bilingual sentences, composed by concatenating the entire news commentary (≈ 74K sentences) and Europarl (≈ 126K sentence), for the estimation of the translation model. Word alignments were generated with GIZA++ (Och and Ney, 2003), using the growdiag-final-and heuristic (Koehn et al., 2005). In order to obtain the best alignment quality, the alignment task is performed on the entire parallel data and not just on the training data we use. All data is lowercased, and we use the Moses tokenizer and recapitalizer. Our monolingual language model is trained on 500K sentences. These comprise 300K sentences from the monolingual corpus (news commentary) and 200K sentences from the target-side part of the bilingual corpus. The latter part is also used to train the prior probability model. The dev and test sets are news-dev2009a and news-dev2009b which contain 1025 and 1026 parallel senten"
P11-1105,koen-2004-pharaoh,0,0.0331812,"features are standard (Koehn et al., 2003). The estimation is motivated by IBM Model-1. Given a tuple ti with source words f = f1 , f2 , . . . , fn , target words e = e1 , e2 , . . . , em and an alignment a between the source word positions x = 1, . . . , n and the target word positions y = 1, . . . , m, the lexical feature pw (f |e) is computed as follows: n Y X 1 pw (f |e, a) = w(fx |ey ) |{y : (x, y) ∈ a}| x=1 ∀(x,y)∈a pw (e|f, a) is computed in the same way. 5 Decoding Our decoder for the new model performs a stackbased search with a beam-search algorithm similar to that used in Pharoah (Koehn, 2004a). Given an input sentence F , it first extracts a set of matching source-side cepts along with their n-best translations to form a tuple inventory. During hypothesis expansion, the decoder picks a tuple from the inventory and generates the sequence of operations required for the translation with this tuple in light of the previous hypothesis.9 The sequence of operations may include translation (generate, continue source cept etc.) and reordering (gap insertions, jumps) operations. The decoder also calculates the overall cost of the new hypothesis. Recombination is performed on hypotheses hav"
P11-1105,W04-3250,0,0.24088,"features are standard (Koehn et al., 2003). The estimation is motivated by IBM Model-1. Given a tuple ti with source words f = f1 , f2 , . . . , fn , target words e = e1 , e2 , . . . , em and an alignment a between the source word positions x = 1, . . . , n and the target word positions y = 1, . . . , m, the lexical feature pw (f |e) is computed as follows: n Y X 1 pw (f |e, a) = w(fx |ey ) |{y : (x, y) ∈ a}| x=1 ∀(x,y)∈a pw (e|f, a) is computed in the same way. 5 Decoding Our decoder for the new model performs a stackbased search with a beam-search algorithm similar to that used in Pharoah (Koehn, 2004a). Given an input sentence F , it first extracts a set of matching source-side cepts along with their n-best translations to form a tuple inventory. During hypothesis expansion, the decoder picks a tuple from the inventory and generates the sequence of operations required for the translation with this tuple in light of the previous hypothesis.9 The sequence of operations may include translation (generate, continue source cept etc.) and reordering (gap insertions, jumps) operations. The decoder also calculates the overall cost of the new hypothesis. Recombination is performed on hypotheses hav"
P11-1105,W09-0424,0,0.0505208,"enon more directly by means of tuples with source-side discon1047 tinuities. The most notable feature of our work is that it has a complete generative story of translation which combines translation and reordering operations into a single operation sequence model. Like the N-gram model2 , our model cannot deal with target-side discontinuities. These are eliminated from the training data by a post-editing process on the alignments (see Section 6). Galley and Manning (2010) found that target-side gaps were not useful in their system and not useful in the hierarchical phrase-based system Joshua (Li et al., 2009). 3 Generative Story Our generative story is motivated by the complex reorderings in the German-to-English translation task. The German and English sentences are jointly generated through a sequence of operations. The English words are generated in linear order3 while the German words are generated in parallel with their English translations. Occasionally the translator jumps back on the German side to insert some material at an earlier position. After this is done, it jumps forward again and continues the translation. The backward jumps always end at designated landing sites (gaps) which were"
P11-1105,J06-4004,0,0.19283,"Missing"
P11-1105,P04-1083,0,0.0444978,"hrases. Given the phrase inventory in Table 1, phrasal MT is able to generate example in Figure 1(a). The information “hat...gelesen – read” is internal to the phrase pair “hat er ein buch gelesen – he read a book”, and is therefore handled conveniently. On the other hand, the phrase table does not have the entry “hat er eine zeitung gelesen – he read a newspaper” (Figure 1(b)). Hence, there is no option but to translate “hat...gelesen” separately, translating “hat” to “has” which is a common translation for “hat” but wrong in the given context. Context-free hierarchical models (Chiang, 2007; Melamed, 2004) have rules like “hat er X gelesen – he read X” to handle such cases. Galley and Manning (2010) recently solved this problem for phrasal MT by extracting phrase pairs with source and target-side gaps. Our model can also use tuples with source-side discontinuities. The above sentence would be generated by the following sequence of operations: (i) generate “dann – then” (ii) insert a gap (iii) generate “er – he” (iv) backward jump to the gap (v) generate “hat...[gelesen] – read” (only “hat” and “read” are added to the sentences yet) (vi) jump forward to the right-most source word so far generate"
P11-1105,J03-1002,0,0.0254667,"k papers. 1051 Experimental Setup 7.1 Data We evaluated the system on three data sets with German-to-English, Spanish-to-English and Frenchto-English news translations, respectively. We used data from the 4th version of the Europarl Corpus and the News Commentary which was made available for the translation task of the Fourth Workshop on Statistical Machine Translation.11 We use 200K bilingual sentences, composed by concatenating the entire news commentary (≈ 74K sentences) and Europarl (≈ 126K sentence), for the estimation of the translation model. Word alignments were generated with GIZA++ (Och and Ney, 2003), using the growdiag-final-and heuristic (Koehn et al., 2005). In order to obtain the best alignment quality, the alignment task is performed on the entire parallel data and not just on the training data we use. All data is lowercased, and we use the Moses tokenizer and recapitalizer. Our monolingual language model is trained on 500K sentences. These comprise 300K sentences from the monolingual corpus (news commentary) and 200K sentences from the target-side part of the bilingual corpus. The latter part is also used to train the prior probability model. The dev and test sets are news-dev2009a"
P11-1105,J04-4002,0,0.0487591,"to marginalize the joint-probability model p(F, E). The search is then redefined as: ˆ = arg max pLM (E) p(F, E) E E ppr (E) Both, the monolingual language and the prior probability model are implemented as standard word-based n-gram models: J Y px (E) ≈ p(wj |wj−m+1 , . . . , wj−1 ) j=1 where m = 4 (5-gram model) for the standard monolingual model (x = LM ) and m = 8 (same as the operation model5 ) for the prior probability model (x = pr). In order to improve end-to-end accuracy, we introduce new features for our model and shift from the generative6 model to the standard log-linear approach (Och and Ney, 2004) to tune7 them. We search for a target string E which maximizes a linear combination of feature functions: 5 In decoding, the amount of context used for the prior probability is synchronized with the position of back-off in the operation model. 6 Our generative model is about 3 BLEU points worse than the best discriminative results. 7 We tune the operation, monolingual and prior probability models as separate features. We expect the prior probability model to get a negative weight but we do not force MERT to assign a negative weight to this feature. ˆ = arg max E E  J X  j=1   λj hj (F, E"
P11-1105,P02-1040,0,0.100978,"ecapitalizer. Our monolingual language model is trained on 500K sentences. These comprise 300K sentences from the monolingual corpus (news commentary) and 200K sentences from the target-side part of the bilingual corpus. The latter part is also used to train the prior probability model. The dev and test sets are news-dev2009a and news-dev2009b which contain 1025 and 1026 parallel sentences. The feature weights are tuned with Z-MERT (Zaidan, 2009). 7.2 Results Baseline: We compare our model to a recent version of Moses (Koehn et al., 2007) using Koehn’s training scripts and evaluate with BLEU (Papineni et al., 2002). We provide Moses with the same initial alignments as we are using to train our system.12 We use the default parameters for Moses, and a 5gram English language model (the same as in our system). We compare two variants of our system. The first system (T wno−rl ) applies no hard reordering limit and uses the distortion and gap distance penalty features as soft constraints, allowing all possible reorderings. The second system (T wrl−6 ) uses no distortion and gap distance features, but applies a hard constraint which limits reordering to no more than 6 11 http://www.statmt.org/wmt09/translation"
P11-1105,W09-0429,0,\N,Missing
P11-1105,P07-2045,0,\N,Missing
P12-1049,eisele-chen-2010-multiun,0,0.0346249,"Missing"
P12-1049,W10-2405,0,0.0874072,"led the “seed data”) for initial training. All systems which participated in the NEWS10 shared task are either supervised or semi-supervised. They are described in (Kumaran et al., 2010a). Our transliteration mining model can mine transliterations without using any labelled data. However, if there is some labelled data available, our system is able to use it effectively. The transliteration mining systems evaluated on the NEWS10 dataset generally used heuristic methods, discriminative models or generative models for transliteration mining (Kumaran et al., 2010a). The heuristic-based system of Jiampojamarn et al. (2010) is based on the edit distance method which scores the similarity between source and target words. They presented two discriminative methods – an SVM-based classifier and alignment-based string similarity for transliteration mining. These methods model the conditional probability distribution and require supervised/semi-supervised information for learning. We propose a flexible generative model for transliteration mining usable for both unsupervised and semi-supervised learning. Previous work on generative approaches uses Hidden Markov Models (Nabende, 2010; Darwish, 2010; Jiampojamarn et al.,"
P12-1049,N03-1017,0,0.0184368,"ikipedia pages written in different languages, which may be transliterations or translations. The seed data is a list of 1000 transliteration pairs provided to semi-supervised systems for initial training. We use the seed data only in our semi-supervised system, and not in the unsupervised system. The reference data is a small subset of the training data which is manually annotated with positive and negative examples. 5.1.1 Training We word-aligned the parallel phrases of the training data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using the grow-diagfinal-and heuristic (Koehn et al., 2003). We extract all word pairs which occur as 1-to-1 alignments (like Sajjad et al. (2011)) and later refer to them as the word-aligned list. We compared the word-aligned list with the NEWS10 reference data and found that the word-aligned list is missing some transliteration pairs because of word-alignment errors. We built another list by adding a word pair for every source word that cooccurs with a target word in a parallel phrase/sentence and call it the cross-product list later on. The cross-product list is noisier but contains almost all transliteration pairs in the corpus. 473 EA EH ET ER 27"
P12-1049,P04-1021,0,0.212852,"Missing"
P12-1049,W05-0809,0,0.0377036,"Missing"
P12-1049,W10-2412,0,0.0242759,"uristic-based system of Jiampojamarn et al. (2010) is based on the edit distance method which scores the similarity between source and target words. They presented two discriminative methods – an SVM-based classifier and alignment-based string similarity for transliteration mining. These methods model the conditional probability distribution and require supervised/semi-supervised information for learning. We propose a flexible generative model for transliteration mining usable for both unsupervised and semi-supervised learning. Previous work on generative approaches uses Hidden Markov Models (Nabende, 2010; Darwish, 2010; Jiampojamarn et al., 2010), Finite State Automata (Noeman and Madkour, 2010) and Bayesian learning (Kahki et al., 2011) to learn transliteration pairs from labelled data. Our method is different from theirs as our generative story explains the unlabelled data using a combination of a transliteration and a non-transliteration sub-model. The transliteration model jointly generates source and target 470 strings, whereas the non-transliteration system generates them independently of each other. Sajjad et al. (2011) proposed a heuristic-based unsupervised transliteration mining sys"
P12-1049,R11-1053,0,0.0189504,"ases. This assumption is not followed for certain phrases like ”New York” and ”New Mexico”. EA EH ET ER Unsupervised SJD OU Semi-supervised/Supervised OS SBest GR DBN 87.4 92.2 90.1 76.0 92.7 96.3 94.6 83.1 92.4 95.7 93.2 79.4 91.5 94.4 91.4 87.5 94.1 93.2 95.5 92.3 95.5 93.9 82.5 Table 2: F-measure results on NEWS10 datasets where SJD is the unsupervised system of Sajjad11, OU is our unsupervised system built on the cross-product list, OS is our semi-supervised system, SBest is the best NEWS10 system, GR is the supervised system of Kahki et al. (2011) and DBN is the semi-supervised system of Nabende (2011) Our unsupervised mining system built on the cross-product list consistently outperforms the one built on the word-aligned list. Later, we consider only the system built on the cross-product list. Table 2 shows the results of our unsupervised system OU in comparison with the unsupervised system of Sajjad11 (SJD), the best semi-supervised systems presented at NEWS10 (SBEST ) and the best semi-supervised results reported on the NEWS10 dataset (GR, DBN ). On three language pairs, our unsupervised system performs better than all semisupervised systems which participated in NEWS10. It has competiti"
P12-1049,W10-2408,0,0.0248795,"method which scores the similarity between source and target words. They presented two discriminative methods – an SVM-based classifier and alignment-based string similarity for transliteration mining. These methods model the conditional probability distribution and require supervised/semi-supervised information for learning. We propose a flexible generative model for transliteration mining usable for both unsupervised and semi-supervised learning. Previous work on generative approaches uses Hidden Markov Models (Nabende, 2010; Darwish, 2010; Jiampojamarn et al., 2010), Finite State Automata (Noeman and Madkour, 2010) and Bayesian learning (Kahki et al., 2011) to learn transliteration pairs from labelled data. Our method is different from theirs as our generative story explains the unlabelled data using a combination of a transliteration and a non-transliteration sub-model. The transliteration model jointly generates source and target 470 strings, whereas the non-transliteration system generates them independently of each other. Sajjad et al. (2011) proposed a heuristic-based unsupervised transliteration mining system. We later call it Sajjad11. It is the only unsupervised mining system that was evaluated"
P12-1049,J03-1002,0,0.0287122,"ta, seed data and reference data. The NEWS10 data consists of pairs of titles of the same Wikipedia pages written in different languages, which may be transliterations or translations. The seed data is a list of 1000 transliteration pairs provided to semi-supervised systems for initial training. We use the seed data only in our semi-supervised system, and not in the unsupervised system. The reference data is a small subset of the training data which is manually annotated with positive and negative examples. 5.1.1 Training We word-aligned the parallel phrases of the training data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using the grow-diagfinal-and heuristic (Koehn et al., 2003). We extract all word pairs which occur as 1-to-1 alignments (like Sajjad et al. (2011)) and later refer to them as the word-aligned list. We compared the word-aligned list with the NEWS10 reference data and found that the word-aligned list is missing some transliteration pairs because of word-alignment errors. We built another list by adding a word pair for every source word that cooccurs with a target word in a parallel phrase/sentence and call it the cross-product list later on. The cross-product lis"
P12-1049,P11-1044,1,0.89978,"arning. Previous work on generative approaches uses Hidden Markov Models (Nabende, 2010; Darwish, 2010; Jiampojamarn et al., 2010), Finite State Automata (Noeman and Madkour, 2010) and Bayesian learning (Kahki et al., 2011) to learn transliteration pairs from labelled data. Our method is different from theirs as our generative story explains the unlabelled data using a combination of a transliteration and a non-transliteration sub-model. The transliteration model jointly generates source and target 470 strings, whereas the non-transliteration system generates them independently of each other. Sajjad et al. (2011) proposed a heuristic-based unsupervised transliteration mining system. We later call it Sajjad11. It is the only unsupervised mining system that was evaluated on the NEWS10 dataset up until now, as far as we know. That system is computationally expensive. We show in Section 5 that its runtime is much higher than that of our system. In this paper, we propose a novel model-based approach to transliteration mining. Our approach is language pair independent – at least for alphabetic languages – and efficient. Unlike the previous unsupervised system, and unlike the supervised and semi-supervised s"
P12-1049,W10-2407,0,\N,Missing
P12-1049,D11-1128,0,\N,Missing
P12-1049,W10-2403,0,\N,Missing
P12-1049,W10-2404,0,\N,Missing
P13-1058,2012.eamt-1.6,0,0.155104,"Missing"
P13-1058,C10-1011,0,0.0114686,"is identified, and via the alignment, the equivalent German verb is obtained. Similarly, candidates for noun-nounGen structures are identified by extracting and aligning English noun-of-noun phrases. 5 We train four CRFs on data prepared as shown in section 3. The corpora used for the extraction of subcategorization tuples were Europarl and German newspaper data (200 million words). We choose this particular data combination in order to provide data that matches the training data, as well as to add new data of the test set’s domain (news). The German part of Europarl was dependencyparsed with Bohnet (2010), and subcategorization information was extracted as described in Scheible et al. (2013); the newspaper data (HGC - Huge German Corpus) was parsed with Schmid (2000), and subcategorization information was extracted as described in Schulte im Walde (2002b). 5.2 We report results of two types of systems (table 5): first, a regular translation system built on surface forms (i.e., normal text) and second, four inflection prediction systems. The first inflection prediction system (1) uses a simple case prediction model, whereas the remaining systems are enriched with (2) subcategorization informati"
P13-1058,A97-1052,0,0.219587,"t gloss influence the political stability Table 2: Overview of the inflection process: the stem markup is highlighted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 EP HGC Both V-SUBJ 454,350 712,717 1,089,492 V-OBJAcc 332,847 329,830 607,541 V-OBJDat 53,711 160,377 206,764 Table 3: Number of verb-noun types extracted from Europarl (EP) and newspaper d"
P13-1058,2012.eamt-1.35,0,0.0170999,"l. (2012) has access to lexical information, it is limited to a certain window size and has no direct information about the relation of verb–noun pairs occurring in the sentence. Using a window of a limited size is particularly problematic for German, as there can be large gaps between the verb and its subcategorized nouns; introducing information about the relation of verbs and nouns helps to bridge such gaps. Furthermore, that model was not able to make effective use of source-side features. One of the objectives of using an inflection prediction model is morphologically well-formed output. Kirchhoff et al. (2012) evaluated user reactions to different error types in machine translation and came to the result that morphological 3.1 Translation pipeline Stemmed representation/feature markup We first parse the German side of the parallel training data with BitPar (Schmid, 2004). This maps each surface form appearing in normal text to a stem and morphological features (case, gender, number). We use this representation to create the stemmed representation for training the translation model. With the exception of stem-markup (discussed below), all morphological features are removed from the stemmed represent"
P13-1058,P05-1005,0,0.0268511,"3), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 EP HGC Both V-SUBJ 454,350 712,717 1,089,492 V-OBJAcc 332,847 329,830 607,541 V-OBJDat 53,711 160,377 206,764 Table 3: Number of verb-noun types extracted from Europarl (EP) and newspaper data (HGC). that modify nouns (noun–noun modification case prediction). Typically, these NP modifiers are genitive NPs. To this end, we integrate nounnounGen tuples with their respective frequencies. These preferences for a certain function (i.e. subject, object or modifier) are passed on to the system at the level of nouns and integrated into the CRF through the derived probabil"
P13-1058,W98-1114,0,0.089596,"Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 EP HGC Both V-SUBJ 454,350 712,717 1,089,492 V-OBJAcc 332,847 329,830 607,541 V-OBJDat 53,711 160,377 206,764 Table 3: Number of verb-noun types extracted from Europarl (EP) and newspaper data (HGC). that modify nouns (noun–noun modification case prediction). Typically, these NP modifiers are genitive NPs. To this end, we integrate nounnounGen tuples with their respective frequencies. These preferences for a certain function (i.e. subject, object or modifier) are passed on to the system"
P13-1058,P10-1052,0,0.0584832,"Missing"
P13-1058,C10-1081,0,0.048035,"Missing"
P13-1058,E12-1068,1,0.642165,"3 Previous work Previous work has already introduced the idea of generating inflected forms as a post-processing step for a translation system that has been stripped of (most) target-language-specific features. Toutanova et al. (2008) and Jeong et al. (2010) built translation systems that predict inflected word forms based on a large array of morphological and syntactic features, obtained from both source and target side. Kholy and Habash (2012) and Green and DeNero (2012) work on English to Arabic translation and model gender, number and definiteness, focusing primarily on improving fluency. Fraser et al. (2012) used a phrase-based system to transfer stems and generated inflected forms based on the stems and their morphological features. For case prediction, they trained a CRF with access to lemmas and POS-tags within a given window. We re-implemented the system by Fraser et al. as a hierarchical machine translation system using a string-to-tree setup. In contrast to the flat phrase-based setting of Fraser et al. (2012), syntactic trees on the SMT output allow us to work with verb–noun structures, which are relevant for case prediction. While the CRF used for case prediction in Fraser et al. (2012) h"
P13-1058,J07-4005,0,0.0160654,"et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 EP HGC Both V-SUBJ 454,350 712,717 1,089,492 V-OBJAcc 332,847 329,830 607,541 V-OBJDat 53,711 160,377 206,764 Table 3: Number of verb-noun types extracted from Europarl (EP) and newspaper data (HGC). that modify nouns (noun–noun modification case prediction). Typically, these NP modifiers are genitive NPs. To this end, we integrate nounnounGen tuples with their respective frequencies. These preferences for a certain function (i.e. subject, object or modifier) are passed on to the system at the level of nouns and integrated into the CRF through the derived probabilities. The tuples and tr"
P13-1058,P08-3010,0,0.0138294,"ghted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 EP HGC Both V-SUBJ 454,350 712,717 1,089,492 V-OBJAcc 332,847 329,830 607,541 V-OBJDat 53,711 160,377 206,764 Table 3: Number of verb-noun types extracted from Europarl (EP) and newspaper data (HGC). that modify nouns (noun–noun modification case prediction). Typically, these NP modifiers"
P13-1058,N04-1035,0,0.0744853,"data and annotating it with the respective features, and then adding this new data set to the original training data. As this method comes with its own problems, such as transferring the morphological annotation to not necessarily isomorphically translated text, we do not use translated data as part of the training data. Instead, we limit the power of the CRF model through experimenting with the removal of features, until we had a system that was robust to this problem. We use a hierarchical translation system. Instead of translating phrases, a hierarchical system extracts translation rules (Galley et al., 2004) which allow the decoder to provide a tree spanning over the translated sentence. In order to avoid sparsity during rule extraction, we use a string-to-tree setup, where only the target-side part of the data is parsed. Translation rules are of the following form: [X]1 allows [X]2 [X]1 allows [X]2 → [NP]1 [NP]2 erlaubt → [NP]1 erlaubt [NP]2 This example illustrates how rules can cover the different word ordering possibilities in German. PP nodes are annotated with their respective case, as well as with the lemma of the preposition they contain. In our experiments, this enriched annotation has s"
P13-1058,P12-1016,0,0.0289141,"ubsections 3.1 to 3.4, we present the simple version of the inflection prediction system; our new features are described in sections 4.2 and 4.3. 3 Previous work Previous work has already introduced the idea of generating inflected forms as a post-processing step for a translation system that has been stripped of (most) target-language-specific features. Toutanova et al. (2008) and Jeong et al. (2010) built translation systems that predict inflected word forms based on a large array of morphological and syntactic features, obtained from both source and target side. Kholy and Habash (2012) and Green and DeNero (2012) work on English to Arabic translation and model gender, number and definiteness, focusing primarily on improving fluency. Fraser et al. (2012) used a phrase-based system to transfer stems and generated inflected forms based on the stems and their morphological features. For case prediction, they trained a CRF with access to lemmas and POS-tags within a given window. We re-implemented the system by Fraser et al. as a hierarchical machine translation system using a string-to-tree setup. In contrast to the flat phrase-based setting of Fraser et al. (2012), syntactic trees on the SMT output allow"
P13-1058,J05-1004,0,0.0242722,"SMT output beeinflussen<VVFIN> d<ART> politisch<ADJ> Stabilit¨ at<NN><Fem><Sg> predicted features – Fem.Acc.Sg.St Fem.Acc.Sg.Wk Fem.Acc.Sg.Wk inflected forms beeinflussen die politische Stabilit¨at gloss influence the political stability Table 2: Overview of the inflection process: the stem markup is highlighted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al"
P13-1058,N06-1031,0,0.0140266,"ows [X]2 → [NP]1 [NP]2 erlaubt → [NP]1 erlaubt [NP]2 This example illustrates how rules can cover the different word ordering possibilities in German. PP nodes are annotated with their respective case, as well as with the lemma of the preposition they contain. In our experiments, this enriched annotation has small improvements over the simpler setting with only head categories (details omitted). This outcome, in particular that adding the lemma of the preposition to the PP node helps to improve translation quality, has been observed before in tree restructuring work for improving translation (Huang and Knight, 2006). 3.3 Feature prediction and generation of inflected forms In this section we discuss our focus, which is prediction of case, but also the prediction of number, gender and strong/weak adjectival inflection. The latter feature is German-specific; its values2 (strong/weak) depend on the combination of the other features, as well as on the type of determiner (e.g. definite/indefinite/none). Morphological features are predicted on four separate CRF models, one for each feature. The models for case, number and gender are independent of another, whereas the model for adjectival inflection requires i"
P13-1058,2001.mtsummit-papers.68,0,0.0404221,"tion (cf. section 4.2), (3) source-side features (cf. section 4.3), and (4) both source-side features and subcategorization information. In (2) and (4), the subcategorization information was included using tuples obtained from source-side dependencies11 . The simple prediction system corresponds to that presented in section 3; for all inflection prediction systems, the same SMT output and models for number, gender and strong/weak inflection were used; thus the only difference with the simple prediction system is the model for case prediction. We present three types of evaluation: BLEU scores (Papineni et al., 2001), prediction accuracy on clean data and a manual evaluation of the best system in section 5.3. Table 5 gives results in case-insensitive BLEU. While the inflection prediction systems (1-4) are significantly12 better than the surface-form system (0), the different versions of the inflection systems are not distinguishable in terms of BLEU; however, our manual evaluation shows that the new features have a positive impact on translation quality. Experiments and evaluation In this section, we present experiments using different feature combinations. We also present a manual evaluation of our best"
P13-1058,2010.amta-papers.33,0,0.0775772,"In the first step, English input is translated to German stems. In the second step, morphological features are predicted and inflected forms are generated based on the word stems and the morphological features. In subsections 3.1 to 3.4, we present the simple version of the inflection prediction system; our new features are described in sections 4.2 and 4.3. 3 Previous work Previous work has already introduced the idea of generating inflected forms as a post-processing step for a translation system that has been stripped of (most) target-language-specific features. Toutanova et al. (2008) and Jeong et al. (2010) built translation systems that predict inflected word forms based on a large array of morphological and syntactic features, obtained from both source and target side. Kholy and Habash (2012) and Green and DeNero (2012) work on English to Arabic translation and model gender, number and definiteness, focusing primarily on improving fluency. Fraser et al. (2012) used a phrase-based system to transfer stems and generated inflected forms based on the stems and their morphological features. For case prediction, they trained a CRF with access to lemmas and POS-tags within a given window. We re-imple"
P13-1058,C00-2100,0,0.0661059,"y Table 2: Overview of the inflection process: the stem markup is highlighted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 EP HGC Both V-SUBJ 454,350 712,717 1,089,492 V-OBJAcc 332,847 329,830 607,541 V-OBJDat 53,711 160,377 206,764 Table 3: Number of verb-noun types extracted from Europarl (EP) and newspaper data (HGC). that modify nouns (noun–no"
P13-1058,2009.eamt-1.30,0,0.049735,"Missing"
P13-1058,schmid-etal-2004-smor,0,0.0401568,"the markup (number and gender on nouns) in the stemmed output of the SMT system is part of the input to the respective feature prediction. For gender and number, the values given on the stems of the nouns are then propagated over the phrase. While the case of prepositional phrases is determined by the case annotation on prepositions, the case of nominal phrases is computed only based on the respective contexts. After predicting all morphological features, the information required to generate inflected forms is complete: based on the stems and the features, we use the morphological tool SMOR (Schmid et al., 2004) for the generation of inflected forms. One general problem with feature-prediction is that the ill-formed SMT output is not well represented by the training data which consists of wellformed sentences. This problem was also mentioned by Stymne and Cancedda (2011) and Kholy and Habash (2012). They deal with this problem by translating the training data and annotating it with the respective features, and then adding this new data set to the original training data. As this method comes with its own problems, such as transferring the morphological annotation to not necessarily isomorphically tran"
P13-1058,N09-2004,0,0.100737,"Missing"
P13-1058,C04-1024,0,0.0332844,"ps between the verb and its subcategorized nouns; introducing information about the relation of verbs and nouns helps to bridge such gaps. Furthermore, that model was not able to make effective use of source-side features. One of the objectives of using an inflection prediction model is morphologically well-formed output. Kirchhoff et al. (2012) evaluated user reactions to different error types in machine translation and came to the result that morphological 3.1 Translation pipeline Stemmed representation/feature markup We first parse the German side of the parallel training data with BitPar (Schmid, 2004). This maps each surface form appearing in normal text to a stem and morphological features (case, gender, number). We use this representation to create the stemmed representation for training the translation model. With the exception of stem-markup (discussed below), all morphological features are removed from the stemmed representation. The stem markup is used as part of the input to the feature prediction; the basic idea is that the given feature values are picked up by the prediction model and then propagated over the phrase. Nouns, as the head of NPs and PPs, are annotated with gender and"
P13-1058,schulte-im-walde-2002-subcategorisation,1,0.776383,"the stem markup is highlighted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 EP HGC Both V-SUBJ 454,350 712,717 1,089,492 V-OBJAcc 332,847 329,830 607,541 V-OBJDat 53,711 160,377 206,764 Table 3: Number of verb-noun types extracted from Europarl (EP) and newspaper data (HGC). that modify nouns (noun–noun modification case prediction)."
P13-1058,W11-2129,0,0.153639,"of prepositional phrases is determined by the case annotation on prepositions, the case of nominal phrases is computed only based on the respective contexts. After predicting all morphological features, the information required to generate inflected forms is complete: based on the stems and the features, we use the morphological tool SMOR (Schmid et al., 2004) for the generation of inflected forms. One general problem with feature-prediction is that the ill-formed SMT output is not well represented by the training data which consists of wellformed sentences. This problem was also mentioned by Stymne and Cancedda (2011) and Kholy and Habash (2012). They deal with this problem by translating the training data and annotating it with the respective features, and then adding this new data set to the original training data. As this method comes with its own problems, such as transferring the morphological annotation to not necessarily isomorphically translated text, we do not use translated data as part of the training data. Instead, we limit the power of the CRF model through experimenting with the removal of features, until we had a system that was robust to this problem. We use a hierarchical translation syste"
P13-1058,P03-1002,0,0.0301945,"ocusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 EP HGC Both V-SUBJ 454,350 712,717 1,089,492 V-OBJAcc 332,847 329,830 607,541 V-OBJDat 53,711 160,377 206,764 Table 3: Number of verb-noun types extracted from Europarl (EP) and newspaper data (HGC). that modify nouns (noun–noun modification case prediction). Typically, these NP modifiers are genitive NPs. To this end, we integrate nounnounGen tuples with their respective frequencies. These preferences for a certain function (i.e. s"
P13-1058,P08-1059,0,0.367113,"o-step translation process. In the first step, English input is translated to German stems. In the second step, morphological features are predicted and inflected forms are generated based on the word stems and the morphological features. In subsections 3.1 to 3.4, we present the simple version of the inflection prediction system; our new features are described in sections 4.2 and 4.3. 3 Previous work Previous work has already introduced the idea of generating inflected forms as a post-processing step for a translation system that has been stripped of (most) target-language-specific features. Toutanova et al. (2008) and Jeong et al. (2010) built translation systems that predict inflected word forms based on a large array of morphological and syntactic features, obtained from both source and target side. Kholy and Habash (2012) and Green and DeNero (2012) work on English to Arabic translation and model gender, number and definiteness, focusing primarily on improving fluency. Fraser et al. (2012) used a phrase-based system to transfer stems and generated inflected forms based on the stems and their morphological features. For case prediction, they trained a CRF with access to lemmas and POS-tags within a g"
P13-1058,P02-1040,0,\N,Missing
P13-1058,P11-2121,0,\N,Missing
P13-1058,W12-3150,0,\N,Missing
P13-1058,W08-0308,0,\N,Missing
P13-2071,N12-1047,0,0.023851,"sed 402 No. 1. 2. 3. 4. 5. System Baseline 1+pp 1+pp+tsm 1+pp+osm 1+osm* fr-en 31.89 31.87 31.94 32.17 32.13 es-en 35.07 35.09 35.25 35.50 35.65 cs-en 23.88 23.64 23.85 24.14 24.23 ru-en 33.45 33.04 32.97 33.21 33.91 en-fr 29.89 29.70 29.98 30.35 30.54 en-es 35.03 35.00 35.06 35.34 35.49 en-cs 16.22 16.17 16.30 16.49 16.62 en-ru 23.88 24.05 23.96 24.22 24.25 Table 2: Translating into and from English. Bold: Statistically Significant (Koehn, 2004) w.r.t Baseline 5 the first half for tuning and second for test. We test our systems on news-test 2012. We tune with the k-best batch MIRA algorithm (Cherry and Foster, 2012). Conclusion and Future Work We have addressed the problem of the independence assumption in PBSMT by integrating Ngram-based models inside a phrase-based system using a log-linear framework. We try to replicate the effect of rewrite and split rules as used in the TSM model through phrasal alignments. We presented a novel extension of the OSM model to handle unaligned and discontinuous target MTUs in the OSM model. Phrase-based search helps us to address these problems that are non-trivial to handle in the decoding frameworks of the N-grambased models. We tested our extentions and modification"
P13-2071,2012.iwslt-papers.17,1,0.551072,"continous phrases. The discontinuous MTUs that span beyond a phrasal length of 6 words are therefore never hypothesized. We would like to explore this further by extending the search to use discontinuous phrases (Galley and Manning, 2010). Moses Baseline: We trained a Moses system (Koehn et al., 2007) with the following settings: maximum sentence length 80, grow-diag-finaland symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) and the no-reordering-overpunctuation heuristic. Results: Table 2 shows uncased BLEU scores (Papineni et al., 2002) on the test set. Row 2 (+pp) shows that the post-editing of alignments to remove unaligned and discontinuous target MTUs decreases the performance in the case of ru-en, csen and en-fr. Row 3 (+pp+tsm) shows that our integration of the TSM model slightly improves the BLEU scores for en-fr, and es-en. Results drop in ru-en and en-ru. Row"
P13-2071,N07-2035,0,0.16661,"Missing"
P13-2071,W11-2123,0,0.0901439,"s to the OSM model enables discontinuous MTUs, we did not fully utilize these during decoding, as Moses only uses continous phrases. The discontinuous MTUs that span beyond a phrasal length of 6 words are therefore never hypothesized. We would like to explore this further by extending the search to use discontinuous phrases (Galley and Manning, 2010). Moses Baseline: We trained a Moses system (Koehn et al., 2007) with the following settings: maximum sentence length 80, grow-diag-finaland symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) and the no-reordering-overpunctuation heuristic. Results: Table 2 shows uncased BLEU scores (Papineni et al., 2002) on the test set. Row 2 (+pp) shows that the post-editing of alignments to remove unaligned and discontinuous target MTUs decreases the performance in the case of ru-en, csen and en-fr. Row 3 (+pp+tsm) shows that our int"
P13-2071,P07-1019,0,0.372958,"ore this further by extending the search to use discontinuous phrases (Galley and Manning, 2010). Moses Baseline: We trained a Moses system (Koehn et al., 2007) with the following settings: maximum sentence length 80, grow-diag-finaland symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) and the no-reordering-overpunctuation heuristic. Results: Table 2 shows uncased BLEU scores (Papineni et al., 2002) on the test set. Row 2 (+pp) shows that the post-editing of alignments to remove unaligned and discontinuous target MTUs decreases the performance in the case of ru-en, csen and en-fr. Row 3 (+pp+tsm) shows that our integration of the TSM model slightly improves the BLEU scores for en-fr, and es-en. Results drop in ru-en and en-ru. Row 4 (+pp+osm) shows that the OSM model consistently improves the BLEU scores over the Baseline systems (Row 1) giving significant improvements in h"
P13-2071,2009.eamt-1.10,0,0.0260482,"ave ignored so far are the handling of MTUs which have discontinuous targets, and the handling of unaligned target words. Both TSM and OSM N-gram models generate MTUs linearly in left-to-right order. This assumption becomes problematic in the cases of MTUs that have target-side discontinuities (See Figure 2(a)). The MTU A → g . . . a can not be generated because of the intervening MTUs B → b, C . . . H → c and D → d. In the original TSM model, such cases are dealt with by merging all the intervening MTUs to form a bigger unit t01 in Figure 2(c). A solution that uses split-rules is proposed by Crego and Yvon (2009) but has not been adopted in Ncode (Crego et al., 2011), the state-of-the-art TSM Ngram system. Durrani et al. (2011) dealt with this problem by applying a post-processing (PP) heuristic that modifies the alignments to remove such cases. When a source word is aligned to a discontinuous target-cept, first the link to the least frequent target word is identified, and the group of links containing this word is retained while the others are deleted. The alignment in Figure 2(a), for example, is transformed to that in Figure 2(b). This allows OSM to extract the intervening MTUs t2 . . . t5 (Figure"
P13-2071,E09-1049,0,0.0142488,"-gram-based system. However, they do not use phrase-based models in their work, relying only on the OSM model. This paper combines insights from these recent pieces of work and show that phrase-based search combined with N-gram-based and phrase-based models in decoding is the overall best way to go. We integrate the two N-grambased models, TSM and OSM, into phrase-based Moses and show that the translation quality is improved by taking both translation and reordering context into account. Other approaches that explored such models in syntax-based systems used MTUs for sentence level reranking (Khalilov and Fonollosa, 2009), in dependency translation models (Quirk and Menezes, 2006) and in target language syntax systems (Vaswani et al., 2011). 3 Figure 1: Example (a) Word Alignments (b) Unfolded MTU Sequence (c) Operation Sequence (d) Step-wise Generation tem. Given a bilingual sentence pair (F, E) and its alignment (A), we first identify minimal translation units (MTUs) from it. An MTU is defined as a translation rule that cannot be broken down any further. The MTUs extracted from Figure 1(a) are A → a, B → b, C . . . H → c1 and D → d. These units are then generated left-to-right in two different ways, as we wi"
P13-2071,C10-2023,0,0.141203,"se399 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 399–405, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics baseline system, and shows statistically significant improvements in seven out of eight cases. 2 Previous Work Several researchers have tried to combine the ideas of phrase-based and N-gram-based SMT. Costajuss`a et al. (2007) proposed a method for combining the two approaches by applying sentence level reranking. Feng et al. (2010) added a linearized source-side language model in a phrase-based system. Crego and Yvon (2010) modified the phrasebased lexical reordering model of Tillman (2004) for an N-gram-based system. Niehues et al. (2011) integrated a bilingual language model based on surface word forms and POS tags into a phrasebased system. Zhang et al. (2013) explored multiple decomposition structures for generating MTUs in the task of lexical selection, and to rerank the N-best candidate translations in the output of a phrase-based. A drawback of the TSM model is the assumption that source and target information is generated monotonically. The process of reordering is disconnected from lexical generation wh"
P13-2071,W12-3139,1,0.843905,"y the decoder to arbitrarily generate unaligned MTUs but hypothesize these only when they appear within Parallel ≈39 M ≈15.6 M ≈15.2 M ≈2 M Monolingual ≈91 M ≈43.4 M ≈65.7 M ≈21.7 M ≈287.3 M Lang fr cs es ru en Table 1: Number of Sentences (in Millions) used for Training We follow the approach of Schwenk and Koehn (2008) and trained domain-specific language models separately and then linearly interpolated them using SRILM with weights optimized on the heldout dev-set. We concatenated the news-test sets from four years (2008-2011) to obtain a large devsetin order to obtain more stable weights (Koehn and Haddow, 2012). For Russian-English and English-Russian language pairs, we divided the tuning-set news-test 2012 into two halves and used 402 No. 1. 2. 3. 4. 5. System Baseline 1+pp 1+pp+tsm 1+pp+osm 1+osm* fr-en 31.89 31.87 31.94 32.17 32.13 es-en 35.07 35.09 35.25 35.50 35.65 cs-en 23.88 23.64 23.85 24.14 24.23 ru-en 33.45 33.04 32.97 33.21 33.91 en-fr 29.89 29.70 29.98 30.35 30.54 en-es 35.03 35.00 35.06 35.34 35.49 en-cs 16.22 16.17 16.30 16.49 16.62 en-ru 23.88 24.05 23.96 24.22 24.25 Table 2: Translating into and from English. Bold: Statistically Significant (Koehn, 2004) w.r.t Baseline 5 the first ha"
P13-2071,P11-1105,1,0.732808,"for an N-gram-based system. Niehues et al. (2011) integrated a bilingual language model based on surface word forms and POS tags into a phrasebased system. Zhang et al. (2013) explored multiple decomposition structures for generating MTUs in the task of lexical selection, and to rerank the N-best candidate translations in the output of a phrase-based. A drawback of the TSM model is the assumption that source and target information is generated monotonically. The process of reordering is disconnected from lexical generation which restricts the search to a small set of precomputed reorderings. Durrani et al. (2011) addressed this problem by coupling lexical generation and reordering information into a single generative process and enriching the N-gram models to learn lexical reordering triggers. Durrani et al. (2013) showed that using larger phrasal units during decoding is superior to MTU-based decoding in an N-gram-based system. However, they do not use phrase-based models in their work, relying only on the OSM model. This paper combines insights from these recent pieces of work and show that phrase-based search combined with N-gram-based and phrase-based models in decoding is the overall best way to"
P13-2071,N03-1017,1,0.0357267,"model that captures dependencies across phrasal boundaries. Some work has been done to combine insights from these two frameworks. A recent successful attempt showed the advantage of using phrasebased search on top of an N-gram-based model. We probe this question in the reverse direction by investigating whether integrating N-gram-based translation and reordering models into a phrase-based decoder helps overcome the problematic phrasal independence assumption. A large scale evaluation over 8 language pairs shows that performance does significantly improve. 1 Introduction Phrase-based models (Koehn et al., 2003; Och and Ney, 2004) learn local dependencies such as reorderings, idiomatic collocations, deletions and insertions by memorization. A fundamental drawback is that phrases are translated and reordered independently of each other and contextual information outside of phrasal boundaries is ignored. The monolingual language model somewhat reduces this problem. However i) often the language model cannot overcome the dispreference of the translation model for nonlocal dependencies, ii) source-side contextual dependencies are still ignored and iii) generation of lexical translations and reordering i"
P13-2071,N13-1001,1,0.531868,"on structures for generating MTUs in the task of lexical selection, and to rerank the N-best candidate translations in the output of a phrase-based. A drawback of the TSM model is the assumption that source and target information is generated monotonically. The process of reordering is disconnected from lexical generation which restricts the search to a small set of precomputed reorderings. Durrani et al. (2011) addressed this problem by coupling lexical generation and reordering information into a single generative process and enriching the N-gram models to learn lexical reordering triggers. Durrani et al. (2013) showed that using larger phrasal units during decoding is superior to MTU-based decoding in an N-gram-based system. However, they do not use phrase-based models in their work, relying only on the OSM model. This paper combines insights from these recent pieces of work and show that phrase-based search combined with N-gram-based and phrase-based models in decoding is the overall best way to go. We integrate the two N-grambased models, TSM and OSM, into phrase-based Moses and show that the translation quality is improved by taking both translation and reordering context into account. Other appr"
P13-2071,P07-2045,1,0.0139628,"deration consistently improves the performance of the baseline system. Our modification to the OSM model produces the best results giving significant improvements in most cases. Although our modifications to the OSM model enables discontinuous MTUs, we did not fully utilize these during decoding, as Moses only uses continous phrases. The discontinuous MTUs that span beyond a phrasal length of 6 words are therefore never hypothesized. We would like to explore this further by extending the search to use discontinuous phrases (Galley and Manning, 2010). Moses Baseline: We trained a Moses system (Koehn et al., 2007) with the following settings: maximum sentence length 80, grow-diag-finaland symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) and the no-reordering-overpunctuation heuristic. Results: Table 2 shows uncased BLEU scores (Papineni et al., 2002) on the test set. Row"
P13-2071,2010.amta-papers.22,0,0.288871,"Missing"
P13-2071,W04-3250,1,0.53813,"Missing"
P13-2071,N04-1022,0,0.483452,"er hypothesized. We would like to explore this further by extending the search to use discontinuous phrases (Galley and Manning, 2010). Moses Baseline: We trained a Moses system (Koehn et al., 2007) with the following settings: maximum sentence length 80, grow-diag-finaland symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) and the no-reordering-overpunctuation heuristic. Results: Table 2 shows uncased BLEU scores (Papineni et al., 2002) on the test set. Row 2 (+pp) shows that the post-editing of alignments to remove unaligned and discontinuous target MTUs decreases the performance in the case of ru-en, csen and en-fr. Row 3 (+pp+tsm) shows that our integration of the TSM model slightly improves the BLEU scores for en-fr, and es-en. Results drop in ru-en and en-ru. Row 4 (+pp+osm) shows that the OSM model consistently improves the BLEU scores over the Baseline systems (Row"
P13-2071,W11-2124,0,0.0307268,"Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics baseline system, and shows statistically significant improvements in seven out of eight cases. 2 Previous Work Several researchers have tried to combine the ideas of phrase-based and N-gram-based SMT. Costajuss`a et al. (2007) proposed a method for combining the two approaches by applying sentence level reranking. Feng et al. (2010) added a linearized source-side language model in a phrase-based system. Crego and Yvon (2010) modified the phrasebased lexical reordering model of Tillman (2004) for an N-gram-based system. Niehues et al. (2011) integrated a bilingual language model based on surface word forms and POS tags into a phrasebased system. Zhang et al. (2013) explored multiple decomposition structures for generating MTUs in the task of lexical selection, and to rerank the N-best candidate translations in the output of a phrase-based. A drawback of the TSM model is the assumption that source and target information is generated monotonically. The process of reordering is disconnected from lexical generation which restricts the search to a small set of precomputed reorderings. Durrani et al. (2011) addressed this problem by co"
P13-2071,J04-4002,0,0.11205,"dependencies across phrasal boundaries. Some work has been done to combine insights from these two frameworks. A recent successful attempt showed the advantage of using phrasebased search on top of an N-gram-based model. We probe this question in the reverse direction by investigating whether integrating N-gram-based translation and reordering models into a phrase-based decoder helps overcome the problematic phrasal independence assumption. A large scale evaluation over 8 language pairs shows that performance does significantly improve. 1 Introduction Phrase-based models (Koehn et al., 2003; Och and Ney, 2004) learn local dependencies such as reorderings, idiomatic collocations, deletions and insertions by memorization. A fundamental drawback is that phrases are translated and reordered independently of each other and contextual information outside of phrasal boundaries is ignored. The monolingual language model somewhat reduces this problem. However i) often the language model cannot overcome the dispreference of the translation model for nonlocal dependencies, ii) source-side contextual dependencies are still ignored and iii) generation of lexical translations and reordering is separated. The N-g"
P13-2071,P02-1040,0,0.106262,"trained a Moses system (Koehn et al., 2007) with the following settings: maximum sentence length 80, grow-diag-finaland symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) and the no-reordering-overpunctuation heuristic. Results: Table 2 shows uncased BLEU scores (Papineni et al., 2002) on the test set. Row 2 (+pp) shows that the post-editing of alignments to remove unaligned and discontinuous target MTUs decreases the performance in the case of ru-en, csen and en-fr. Row 3 (+pp+tsm) shows that our integration of the TSM model slightly improves the BLEU scores for en-fr, and es-en. Results drop in ru-en and en-ru. Row 4 (+pp+osm) shows that the OSM model consistently improves the BLEU scores over the Baseline systems (Row 1) giving significant improvements in half the cases. The only result that is lower than the baseline system is that of the ru-en experiment, because OSM i"
P13-2071,N06-1002,0,0.0506902,"in their work, relying only on the OSM model. This paper combines insights from these recent pieces of work and show that phrase-based search combined with N-gram-based and phrase-based models in decoding is the overall best way to go. We integrate the two N-grambased models, TSM and OSM, into phrase-based Moses and show that the translation quality is improved by taking both translation and reordering context into account. Other approaches that explored such models in syntax-based systems used MTUs for sentence level reranking (Khalilov and Fonollosa, 2009), in dependency translation models (Quirk and Menezes, 2006) and in target language syntax systems (Vaswani et al., 2011). 3 Figure 1: Example (a) Word Alignments (b) Unfolded MTU Sequence (c) Operation Sequence (d) Step-wise Generation tem. Given a bilingual sentence pair (F, E) and its alignment (A), we first identify minimal translation units (MTUs) from it. An MTU is defined as a translation rule that cannot be broken down any further. The MTUs extracted from Figure 1(a) are A → a, B → b, C . . . H → c1 and D → d. These units are then generated left-to-right in two different ways, as we will describe next. 3.1 Tuple Sequence Model (TSM) The TSM tra"
P13-2071,I08-2089,1,0.813358,"ration is generated as soon as the MTU containing its previous target word is generated. In Figure 2(a), ε − f is generated immediately after MTU E − e is generated. In a sequence of unaligned source and target MTUs, unaligned source MTUs are generated before the unaligned target MTUs. We do not modify the decoder to arbitrarily generate unaligned MTUs but hypothesize these only when they appear within Parallel ≈39 M ≈15.6 M ≈15.2 M ≈2 M Monolingual ≈91 M ≈43.4 M ≈65.7 M ≈21.7 M ≈287.3 M Lang fr cs es ru en Table 1: Number of Sentences (in Millions) used for Training We follow the approach of Schwenk and Koehn (2008) and trained domain-specific language models separately and then linearly interpolated them using SRILM with weights optimized on the heldout dev-set. We concatenated the news-test sets from four years (2008-2011) to obtain a large devsetin order to obtain more stable weights (Koehn and Haddow, 2012). For Russian-English and English-Russian language pairs, we divided the tuning-set news-test 2012 into two halves and used 402 No. 1. 2. 3. 4. 5. System Baseline 1+pp 1+pp+tsm 1+pp+osm 1+osm* fr-en 31.89 31.87 31.94 32.17 32.13 es-en 35.07 35.09 35.25 35.50 35.65 cs-en 23.88 23.64 23.85 24.14 24.2"
P13-2071,N04-4026,0,0.0506055,"tional Linguistics, pages 399–405, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics baseline system, and shows statistically significant improvements in seven out of eight cases. 2 Previous Work Several researchers have tried to combine the ideas of phrase-based and N-gram-based SMT. Costajuss`a et al. (2007) proposed a method for combining the two approaches by applying sentence level reranking. Feng et al. (2010) added a linearized source-side language model in a phrase-based system. Crego and Yvon (2010) modified the phrasebased lexical reordering model of Tillman (2004) for an N-gram-based system. Niehues et al. (2011) integrated a bilingual language model based on surface word forms and POS tags into a phrasebased system. Zhang et al. (2013) explored multiple decomposition structures for generating MTUs in the task of lexical selection, and to rerank the N-best candidate translations in the output of a phrase-based. A drawback of the TSM model is the assumption that source and target information is generated monotonically. The process of reordering is disconnected from lexical generation which restricts the search to a small set of precomputed reorderings."
P13-2071,P11-1086,0,0.0372821,"s insights from these recent pieces of work and show that phrase-based search combined with N-gram-based and phrase-based models in decoding is the overall best way to go. We integrate the two N-grambased models, TSM and OSM, into phrase-based Moses and show that the translation quality is improved by taking both translation and reordering context into account. Other approaches that explored such models in syntax-based systems used MTUs for sentence level reranking (Khalilov and Fonollosa, 2009), in dependency translation models (Quirk and Menezes, 2006) and in target language syntax systems (Vaswani et al., 2011). 3 Figure 1: Example (a) Word Alignments (b) Unfolded MTU Sequence (c) Operation Sequence (d) Step-wise Generation tem. Given a bilingual sentence pair (F, E) and its alignment (A), we first identify minimal translation units (MTUs) from it. An MTU is defined as a translation rule that cannot be broken down any further. The MTUs extracted from Figure 1(a) are A → a, B → b, C . . . H → c1 and D → d. These units are then generated left-to-right in two different ways, as we will describe next. 3.1 Tuple Sequence Model (TSM) The TSM translation model assumes that MTUs are generated monotonically."
P13-2071,N13-1002,0,0.215931,"improvements in seven out of eight cases. 2 Previous Work Several researchers have tried to combine the ideas of phrase-based and N-gram-based SMT. Costajuss`a et al. (2007) proposed a method for combining the two approaches by applying sentence level reranking. Feng et al. (2010) added a linearized source-side language model in a phrase-based system. Crego and Yvon (2010) modified the phrasebased lexical reordering model of Tillman (2004) for an N-gram-based system. Niehues et al. (2011) integrated a bilingual language model based on surface word forms and POS tags into a phrasebased system. Zhang et al. (2013) explored multiple decomposition structures for generating MTUs in the task of lexical selection, and to rerank the N-best candidate translations in the output of a phrase-based. A drawback of the TSM model is the assumption that source and target information is generated monotonically. The process of reordering is disconnected from lexical generation which restricts the search to a small set of precomputed reorderings. Durrani et al. (2011) addressed this problem by coupling lexical generation and reordering information into a single generative process and enriching the N-gram models to learn"
P13-2071,N10-1140,0,\N,Missing
P13-2071,J06-4004,0,\N,Missing
P16-1161,D07-1007,0,0.312333,"econd issue has to do with morphology (and syntax): given that we selected the correct meaning, which of its inflected surface forms is appropriate? In this work, we integrate such a model directly into the SMT decoder. This enables our classifier to extract features not only from the full source sentence but also from a limited targetside context. This allows the model to not only help with semantics but also to improve morphological and syntactic coherence. For sense disambiguation, source context is the main source of information, as has been shown in previous work (Vickrey et al., 2005), (Carpuat and Wu, 2007), (Gimpel and Smith, 2008) inter alia. Consider the first set of examples in Figure 1, produced by a strong baseline PBMT system. The English word “shooting” has multiple senses when translated into Czech: it may either be the act of firing a weapon or making a film. When the cue word “film” is close, the phrase-based model is able to use it in one phrase with the ambiguous “shooting”, disambiguating correctly the translation. When we add a single word in between, the model fails to capture the relationship and the most frequent sense is selected instead. Wider source context information is re"
P16-1161,2012.eamt-1.60,0,0.0164676,"test set and we test on the WMT14 set. We use TreeTagger (Schmid, 1994) to lemmatize and tag the German data. English-Polish has not been included in WMT shared tasks so far, but was present as a language pair for several IWSLT editions which concentrate on TED talk translation. Full test sets are only available for 2010, 2011, and 2012. The references for 2013 and 2014 were not made public. We use the development set and test set from 2010 as development data for parameter tuning. The remaining two test sets (2011, 2012) are our test data. We train on the concatenation of Europarl and WIT3 (Cettolo et al., 2012), ca. 750 thousand sentence pairs. The Polish half has been tagged using WCRFT (Radziszewski, 2013) which produces full morphological tags compatible with the NKJP tagset (Przepi´orkowski, 2009). English-Romanian was added in WMT16. We train our system using the available parallel data – Europarl and SETIMES2 (Tiedemann, 2009), roughly 600 thousand sentence pairs. We tune the English-Romanian system on the official development set and we test on the WMT16 test set. We use the online tagger by Tufis et al. (2008) to preprocess the data. Table 3 shows the obtained results. Similarly to English-C"
P16-1161,P11-2031,0,0.0533509,"– our classifier with source-context features only, • +target – our classifier with both sourcecontext and target-context features. For each of these settings, we vary the size of the training data for our classifier, the phrase table and the LM. We experiment with three different sizes: small (200 thousand sentence pairs), medium (5 million sentence pairs), and full (the whole CzEng corpus, over 14.8 million sentence pairs). For each setting, we run system weight optimization (tuning) using minimum error rate training (Och, 2003) five times and report the average BLEU score. We use MultEval (Clark et al., 2011) to compare the systems and to determine whether the differences in results are statistically significant. We always compare the baseline with +source and +source with +target. Table 2 shows the obtained results. Statistically significant differences (α=0.01) are marked in bold. The source-context model does not help in the small data setting but brings a substantial improvement of 0.7-0.8 BLEU points for the medium and full data settings, which is an encouraging result. Target-side context information allows our model to push the translation quality further: even for the small data setting, i"
P16-1161,P14-1129,0,0.036134,"We look at phrase counts and cooccurrence counts in the training data, we subtract one from the number of occurrences for the current source phrase, target phrase and the phrase pair. If the count goes to zero, we skip the training example. Without this technique, the classifier might learn to simply trust very long phrase pairs which were extracted from the same training sentence. For target-side context features, we simply use the true (gold) target context. This leads to training which is similar to language model estimation; this model is somewhat similar to the neural joint model for MT (Devlin et al., 2014), but in our case implemented using a linear (maximumentropy-like) model. 2.4 Training We use Vowpal Wabbit in the --csoaa ldf mc setting which reduces our multi-class problem to one-against-all binary classification. We use the logistic loss as our objective. We experimented with various settings of L2 regularization but were not able to get an improvement over not using regularization at all. We train each model with 10 iterations over the data. We evaluate all of our models on a held-out set. We use the same dataset as for MT system tuning because it closely matches the domain of our test s"
P16-1161,W08-0302,0,0.0657345,"th morphology (and syntax): given that we selected the correct meaning, which of its inflected surface forms is appropriate? In this work, we integrate such a model directly into the SMT decoder. This enables our classifier to extract features not only from the full source sentence but also from a limited targetside context. This allows the model to not only help with semantics but also to improve morphological and syntactic coherence. For sense disambiguation, source context is the main source of information, as has been shown in previous work (Vickrey et al., 2005), (Carpuat and Wu, 2007), (Gimpel and Smith, 2008) inter alia. Consider the first set of examples in Figure 1, produced by a strong baseline PBMT system. The English word “shooting” has multiple senses when translated into Czech: it may either be the act of firing a weapon or making a film. When the cue word “film” is close, the phrase-based model is able to use it in one phrase with the ambiguous “shooting”, disambiguating correctly the translation. When we add a single word in between, the model fails to capture the relationship and the most frequent sense is selected instead. Wider source context information is required for correct disambi"
P16-1161,2010.amta-papers.33,0,0.107227,"nt phrases. They used a strong feature set originally developed for word sense disambiguation. Gimpel and Smith (2008) also used wider source-context information but did not train a classifier; instead, the features were included directly in the log-linear model of the decoder. Mauser et al. (2009) introduced the “discriminative word lexicon” and trained a binary classifier for each target word, using as features only the bag of words (from the whole source sentence). Training sentences where the target word occurred were used as positive examples, other sentences served as negative examples. Jeong et al. (2010) proposed a discriminative lexicon with a rich feature set tailored to translation into morphologically rich languages; unlike our work, their model only used source-context features. Subotin (2011) included target-side context information in a maximum-entropy model for the prediction of morphology. The work was done within the paradigm of hierarchical PBMT and assumes that cube pruning is used in decoding. Their algorithm was tailored to the specific problem of passing non-local information about morphological agreement required by individual rules (such as explicit rules enforcing subject-ve"
P16-1161,D07-1091,0,0.151245,"perimented with various settings of L2 regularization but were not able to get an improvement over not using regularization at all. We train each model with 10 iterations over the data. We evaluate all of our models on a held-out set. We use the same dataset as for MT system tuning because it closely matches the domain of our test set. We evaluate model accuracy after each pass over the training data to detect over-fitting and we select the model with the highest held-out accuracy. 2.5 Feature Set Our feature set requires some linguistic processing of the data. We use the factored MT setting (Koehn and Hoang, 2007) and we represent each type of information as an individual factor. On the source side, we use the word surface form, its lemma, morphological tag, analytical function (such as Subj for subjects) and the lemma of the parent node in the dependency parse tree. On the target side, we only use word lemmas and morphological tags. Table 1 lists our feature sets for each language pair. We implemented indicator features for both the source and target side; these are simply concatenations of the words in the current phrase into a single feature. Internal features describe words within the current phras"
P16-1161,2005.mtsummit-papers.11,0,0.0967476,"ur model. A baseline which always chooses the most frequent phrasal translation obtains accuracy of 51.5. For the sourcecontext model, the held-out accuracy was 66.3, while the target context model achieved accuracy of 74.8. Note that this high difference is somewhat misleading because in this setting, the targetcontext model has access to the true target context (i.e., it is cheating). 4.2 Additional Language Pairs We experiment with translation from English into German, Polish, and Romanian. Our English-German system is trained on the data available for the WMT14 translation task: Europarl (Koehn, 2005) and the Common Crawl corpus,3 roughly 4.3 million sentence pairs altogether. We tune the system on the WMT13 test set and we test on the WMT14 set. We use TreeTagger (Schmid, 1994) to lemmatize and tag the German data. English-Polish has not been included in WMT shared tasks so far, but was present as a language pair for several IWSLT editions which concentrate on TED talk translation. Full test sets are only available for 2010, 2011, and 2012. The references for 2013 and 2014 were not made public. We use the development set and test set from 2010 as development data for parameter tuning. The"
P16-1161,D09-1022,0,0.0271419,"have been proposed before. Carpuat and Wu (2007) trained a maximum entropy classifier for each source phrase type which used source context information to disambiguate its translations. The models did not capture target-side information and they were independent; no parameters were shared between classifiers for different phrases. They used a strong feature set originally developed for word sense disambiguation. Gimpel and Smith (2008) also used wider source-context information but did not train a classifier; instead, the features were included directly in the log-linear model of the decoder. Mauser et al. (2009) introduced the “discriminative word lexicon” and trained a binary classifier for each target word, using as features only the bag of words (from the whole source sentence). Training sentences where the target word occurred were used as positive examples, other sentences served as negative examples. Jeong et al. (2010) proposed a discriminative lexicon with a rich feature set tailored to translation into morphologically rich languages; unlike our work, their model only used source-context features. Subotin (2011) included target-side context information in a maximum-entropy model for the predi"
P16-1161,W11-2124,0,0.0242953,"mplemented indicator features for both the source and target side; these are simply concatenations of the words in the current phrase into a single feature. Internal features describe words within the current phrase. Context features are extracted either from a window of a fixed size around the current phrase (on the source side) or from a limited left-hand side context (on the target side). Bilingual context features are concatenations of target-side context words and their sourceside counterparts (according to word alignment); these features are similar to bilingual tokens in bilingual LMs (Niehues et al., 2011). Each of our feature types can be configured to look at any individual factors or their combinations. The features in Table 1 are divided into three sets. The first set contains label-independent (=shared) features which only depend on the source sentence. The second set contains shared features which depend on target-side context; these can only be used when VW is applied during decoding. We use target context size two in all our experiments.2 Finally, the third set contains label-dependent features which describe the currently predicted phrasal translation. 2 In preliminary experiments we f"
P16-1161,P03-1021,0,0.038966,"English to Czech translation. To verify that our method is 1709 • +source – our classifier with source-context features only, • +target – our classifier with both sourcecontext and target-context features. For each of these settings, we vary the size of the training data for our classifier, the phrase table and the LM. We experiment with three different sizes: small (200 thousand sentence pairs), medium (5 million sentence pairs), and full (the whole CzEng corpus, over 14.8 million sentence pairs). For each setting, we run system weight optimization (tuning) using minimum error rate training (Och, 2003) five times and report the average BLEU score. We use MultEval (Clark et al., 2011) to compare the systems and to determine whether the differences in results are statistically significant. We always compare the baseline with +source and +source with +target. Table 2 shows the obtained results. Statistically significant differences (α=0.01) are marked in bold. The source-context model does not help in the small data setting but brings a substantial improvement of 0.7-0.8 BLEU points for the medium and full data settings, which is an encouraging result. Target-side context information allows ou"
P16-1161,P14-5003,0,0.0928089,"Missing"
P16-1161,P11-1024,0,0.0179208,"the features were included directly in the log-linear model of the decoder. Mauser et al. (2009) introduced the “discriminative word lexicon” and trained a binary classifier for each target word, using as features only the bag of words (from the whole source sentence). Training sentences where the target word occurred were used as positive examples, other sentences served as negative examples. Jeong et al. (2010) proposed a discriminative lexicon with a rich feature set tailored to translation into morphologically rich languages; unlike our work, their model only used source-context features. Subotin (2011) included target-side context information in a maximum-entropy model for the prediction of morphology. The work was done within the paradigm of hierarchical PBMT and assumes that cube pruning is used in decoding. Their algorithm was tailored to the specific problem of passing non-local information about morphological agreement required by individual rules (such as explicit rules enforcing subject-verb agreement). Our algorithm only assumes that hypotheses are constructed left to right and provides a general way for including target context information in the classifier, regardless of the type"
P16-1161,tufis-etal-2008-racais,0,0.132569,"11, 2012) are our test data. We train on the concatenation of Europarl and WIT3 (Cettolo et al., 2012), ca. 750 thousand sentence pairs. The Polish half has been tagged using WCRFT (Radziszewski, 2013) which produces full morphological tags compatible with the NKJP tagset (Przepi´orkowski, 2009). English-Romanian was added in WMT16. We train our system using the available parallel data – Europarl and SETIMES2 (Tiedemann, 2009), roughly 600 thousand sentence pairs. We tune the English-Romanian system on the official development set and we test on the WMT16 test set. We use the online tagger by Tufis et al. (2008) to preprocess the data. Table 3 shows the obtained results. Similarly to English-Czech experiments, BLEU scores are av1710 3 http://commoncrawl.org/ input: baseline: +source: +target: the most intensive mining took place there from 1953 to 1962 . nejv´ıce intenzivn´ı tˇezˇ ba doˇslo tam z roku 1953 , aby 1962 . the most intensive miningnom there occurred there from 1953 , in order to 1962 . nejv´ıce intenzivn´ı tˇezˇ by m´ısto tam z roku 1953 do roku 1962 . the most intensive mininggen place there from year 1953 until year 1962 . nejv´ıce intenzivn´ı tˇezˇ ba prob´ıhala od roku 1953 do roku 1"
P16-1161,H05-1097,0,0.0554915,"iminative lexicon. The second issue has to do with morphology (and syntax): given that we selected the correct meaning, which of its inflected surface forms is appropriate? In this work, we integrate such a model directly into the SMT decoder. This enables our classifier to extract features not only from the full source sentence but also from a limited targetside context. This allows the model to not only help with semantics but also to improve morphological and syntactic coherence. For sense disambiguation, source context is the main source of information, as has been shown in previous work (Vickrey et al., 2005), (Carpuat and Wu, 2007), (Gimpel and Smith, 2008) inter alia. Consider the first set of examples in Figure 1, produced by a strong baseline PBMT system. The English word “shooting” has multiple senses when translated into Czech: it may either be the act of firing a weapon or making a film. When the cue word “film” is close, the phrase-based model is able to use it in one phrase with the ambiguous “shooting”, disambiguating correctly the translation. When we add a single word in between, the model fails to capture the relationship and the most frequent sense is selected instead. Wider source c"
P16-1161,W14-3302,1,\N,Missing
P17-4001,D15-1294,1,0.860611,"ndicative indicative indicative passive active active passive passive active Figure 1: Example for TMV extraction. formation about the VCs into a TSV file which can easily be used for further processing. rules for annotating tense, mood and voice for English, French and German. Furthermore, the online demo3 version of the tool allows for fast text processing without installing the tool. Related work. Lo´aiciga et al. (2014) use rules to automatically annotate tense and voice information in English and French parallel texts. Ramm and Fraser (2016) use similar tense annotation rules for German. Friedrich and Pinkal (2015) provide a tool which, among other syntacticsemantic features, derives the tense of English verbal complexes. This tense annotation is based on the set of rules used by Lo´aiciga et al. (2014) For English, PropBank (Palmer et al., 2005) contains annotations for tense, aspect and voice, but there are no annotations for subjunctive constructions including modals. The German T¨uBaD/Z corpus only contains morphological features.1 2 Properties of the verbal complexes In this section, we describe the morphosyntactic features that we extract for verbal complexes. 2.1 Finite and non-finite VCs We defi"
P17-4001,2005.mtsummit-papers.11,0,0.112051,"Missing"
P17-4001,loaiciga-etal-2014-english,1,0.891583,"Missing"
P17-4001,J05-1004,0,0.201333,"ice for English, French and German. Furthermore, the online demo3 version of the tool allows for fast text processing without installing the tool. Related work. Lo´aiciga et al. (2014) use rules to automatically annotate tense and voice information in English and French parallel texts. Ramm and Fraser (2016) use similar tense annotation rules for German. Friedrich and Pinkal (2015) provide a tool which, among other syntacticsemantic features, derives the tense of English verbal complexes. This tense annotation is based on the set of rules used by Lo´aiciga et al. (2014) For English, PropBank (Palmer et al., 2005) contains annotations for tense, aspect and voice, but there are no annotations for subjunctive constructions including modals. The German T¨uBaD/Z corpus only contains morphological features.1 2 Properties of the verbal complexes In this section, we describe the morphosyntactic features that we extract for verbal complexes. 2.1 Finite and non-finite VCs We define a verbal complex (VC) as a sequence of verbs within a verbal phrase, i.e. a sentence may include more than one VC. In addition to the verbs, a VC can also contain verbal particles and negation words but not arguments. We distinguish"
P17-4001,W16-2203,1,0.815444,"esent → present → futureI → present indicative indicative indicative indicative indicative indicative passive active active passive passive active Figure 1: Example for TMV extraction. formation about the VCs into a TSV file which can easily be used for further processing. rules for annotating tense, mood and voice for English, French and German. Furthermore, the online demo3 version of the tool allows for fast text processing without installing the tool. Related work. Lo´aiciga et al. (2014) use rules to automatically annotate tense and voice information in English and French parallel texts. Ramm and Fraser (2016) use similar tense annotation rules for German. Friedrich and Pinkal (2015) provide a tool which, among other syntacticsemantic features, derives the tense of English verbal complexes. This tense annotation is based on the set of rules used by Lo´aiciga et al. (2014) For English, PropBank (Palmer et al., 2005) contains annotations for tense, aspect and voice, but there are no annotations for subjunctive constructions including modals. The German T¨uBaD/Z corpus only contains morphological features.1 2 Properties of the verbal complexes In this section, we describe the morphosyntactic features"
P17-4001,D10-1032,0,0.417965,"Missing"
P17-4001,D12-1133,0,0.156417,"Missing"
P17-4001,E12-1027,0,0.0743976,"Missing"
P18-1075,2005.mtsummit-papers.11,0,0.0291577,"gative examples are randomly generated for each positive one in the training lexicon. We used default parameters as reported by Heyman et al. (2017) except for the t classification thresholds (used at prediction time). We finetuned these on dev. We note that the system works with pre-trained MWEs as well (and report these as official baseline results) but it requires BWEs for candidate generation at prediction time, thus we use BWEs for the system’s input for all experiments. In preliminary work, we had found that MWE and BWE results are similar. the English and Dutch data from Europarl (v7) (Koehn, 2005), a corpus of 2 million sentence pairs. Although Europarl is a parallel corpus, we use it in a monolingual way and shuffle each side of the corpus before training. By using massive cheap data we create high-quality MWEs in each language which are still domain-specific (due to inclusion of medical data). To obtain an out-ofdomain seed lexicon, we translated the English words in BNC to Dutch using Google Translate (just as we did before for the Twitter CLSC task). We then use the out-of-domain BNC and the indomain medical seed lexicons in separate experiments to create BWEs with post-hoc mapping"
P18-1075,C12-2008,0,0.0275641,"dependent (in that it only requires unlabeled in-domain text), which is an important strength. 2.2 Cross-Lingual Sentiment Analysis Sentiment analysis is widely applied, and thus ideally we would have access to high quality supervised models in all human languages. Unfortunately, good quality labeled datasets are missing for many languages. Training models on resource rich languages and applying them to resource poor languages is therefore highly desirable. Crosslingual sentiment classification (CLSC) tackles this problem (Mihalcea et al., 2007; Banea et al., 2010; Wan, 2009; Lu et al., 2011; Balamurali and Joshi, 2012; Gui et al., 2013). Recent CLSC approaches use BWEs as features of deep learning architectures which allows us to use a model for target-language sentiment classification, even when the model was trained only using sourcelanguage supervised training data. Following this approach we perform CLSC on Spanish tweets using English training data. Even though Spanish is not resource-poor we simulate this by using only English annotated data. 2.3 Bilingual Lexicon Induction (BLI) BLI is an important task that has been addressed by a large amount of previous work. The goal of BLI is to automatically e"
P18-1075,C10-1004,0,0.0183517,"le approach is, in contrast, effectively task independent (in that it only requires unlabeled in-domain text), which is an important strength. 2.2 Cross-Lingual Sentiment Analysis Sentiment analysis is widely applied, and thus ideally we would have access to high quality supervised models in all human languages. Unfortunately, good quality labeled datasets are missing for many languages. Training models on resource rich languages and applying them to resource poor languages is therefore highly desirable. Crosslingual sentiment classification (CLSC) tackles this problem (Mihalcea et al., 2007; Banea et al., 2010; Wan, 2009; Lu et al., 2011; Balamurali and Joshi, 2012; Gui et al., 2013). Recent CLSC approaches use BWEs as features of deep learning architectures which allows us to use a model for target-language sentiment classification, even when the model was trained only using sourcelanguage supervised training data. Following this approach we perform CLSC on Spanish tweets using English training data. Even though Spanish is not resource-poor we simulate this by using only English annotated data. 2.3 Bilingual Lexicon Induction (BLI) BLI is an important task that has been addressed by a large amount"
P18-1075,P15-1027,0,0.435942,"l target-language in-domain unlabeled text. Both of the approaches we study in this work fit this criterion, the delightfully simple method for adapting BWEs can improve the performance of any off-the-shelf classifier that is based on BWEs, while the broadly applicable semi-supervised approach of H¨ausser et al. (2017) can improve the performance of any off-the-shelf classifier. Bilingual Word Embeddings Many approaches have been proposed for creating high quality BWEs using different bilingual signals. Following Mikolov et al. (2013b), many authors (Faruqui and Dyer, 2014; Xing et al., 2015; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016) map monolingual word embeddings (MWEs) into the same bilingual space. Others leverage parallel texts (Hermann and Blunsom, 2014; Gouws et al., 2015) or create artificial cross-lingual corpora using seed lexicons or document alignments (Vuli´c and Moens, 2015; Duong et al., 2016) to train BWEs. In contrast, our aim is not to improve the intrinsic quality of BWEs, but to adapt BWEs to specific domains to enhance their performance on bilingual tasks in these domains. Faruqui et al. (2015), Gouws and Søgaard (2015), Rothe et al. (2016) have previously studied domain ad"
P18-1075,L16-1147,0,0.0226462,"guages and then map those into the same space using post-hoc mapping (Mikolov et al., 2013b). We train MWEs for both languages by concatenating monolingual out-of-domain and in-domain data. The out-of-domain data allows us to create accurate distributed representations of common vocabulary while the in-domain data embeds domain specific words. We then map the two MWEs using a small seed lexicon to create the adapted BWEs. Because post-hoc mapping only requires a seed lexicon as bilingual signal it can Training Data for Twitter Specific BWEs As comparable non-twitter data we use OpenSubtitles (Lison and Tiedemann, 2016) which contains 49.2M English and Spanish subtitle sentences respectively (Subtitle). The reason behind choosing Subtitles is that although it is out-of-domain it contains slang words similar to tweets thus serving as a strong baseline in our setup. We experiment with two monolingual twitter data sets: (i) 22M tweets: Downloaded2 English (17.2M) and Spanish (4.8M) tweets using the public 1 2 812 https://github.com/dav/word2vec We downloaded for a month starting on 2016-10-15. Twitter Streaming API 3 with language filters en and es BWEs and feeds them to a bi-directional gated neural network. P"
P18-1075,P11-1033,0,0.0232914,"fectively task independent (in that it only requires unlabeled in-domain text), which is an important strength. 2.2 Cross-Lingual Sentiment Analysis Sentiment analysis is widely applied, and thus ideally we would have access to high quality supervised models in all human languages. Unfortunately, good quality labeled datasets are missing for many languages. Training models on resource rich languages and applying them to resource poor languages is therefore highly desirable. Crosslingual sentiment classification (CLSC) tackles this problem (Mihalcea et al., 2007; Banea et al., 2010; Wan, 2009; Lu et al., 2011; Balamurali and Joshi, 2012; Gui et al., 2013). Recent CLSC approaches use BWEs as features of deep learning architectures which allows us to use a model for target-language sentiment classification, even when the model was trained only using sourcelanguage supervised training data. Following this approach we perform CLSC on Spanish tweets using English training data. Even though Spanish is not resource-poor we simulate this by using only English annotated data. 2.3 Bilingual Lexicon Induction (BLI) BLI is an important task that has been addressed by a large amount of previous work. The goal"
P18-1075,D16-1136,0,0.0187249,"l. (2017) can improve the performance of any off-the-shelf classifier. Bilingual Word Embeddings Many approaches have been proposed for creating high quality BWEs using different bilingual signals. Following Mikolov et al. (2013b), many authors (Faruqui and Dyer, 2014; Xing et al., 2015; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016) map monolingual word embeddings (MWEs) into the same bilingual space. Others leverage parallel texts (Hermann and Blunsom, 2014; Gouws et al., 2015) or create artificial cross-lingual corpora using seed lexicons or document alignments (Vuli´c and Moens, 2015; Duong et al., 2016) to train BWEs. In contrast, our aim is not to improve the intrinsic quality of BWEs, but to adapt BWEs to specific domains to enhance their performance on bilingual tasks in these domains. Faruqui et al. (2015), Gouws and Søgaard (2015), Rothe et al. (2016) have previously studied domain adaptation of bilingual word embeddings, showing it to be highly effective for improving downstream tasks. However, importantly, their proposed methods are based on specialized domain lexicons (such as, e.g., sentiment lexicons) which contain task specific word relations. Our delightfully simple approach is,"
P18-1075,W17-2617,0,0.0412645,"Missing"
P18-1075,N15-1184,0,0.034825,"ikolov et al. (2013b), many authors (Faruqui and Dyer, 2014; Xing et al., 2015; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016) map monolingual word embeddings (MWEs) into the same bilingual space. Others leverage parallel texts (Hermann and Blunsom, 2014; Gouws et al., 2015) or create artificial cross-lingual corpora using seed lexicons or document alignments (Vuli´c and Moens, 2015; Duong et al., 2016) to train BWEs. In contrast, our aim is not to improve the intrinsic quality of BWEs, but to adapt BWEs to specific domains to enhance their performance on bilingual tasks in these domains. Faruqui et al. (2015), Gouws and Søgaard (2015), Rothe et al. (2016) have previously studied domain adaptation of bilingual word embeddings, showing it to be highly effective for improving downstream tasks. However, importantly, their proposed methods are based on specialized domain lexicons (such as, e.g., sentiment lexicons) which contain task specific word relations. Our delightfully simple approach is, in contrast, effectively task independent (in that it only requires unlabeled in-domain text), which is an important strength. 2.2 Cross-Lingual Sentiment Analysis Sentiment analysis is widely applied, and thus"
P18-1075,P07-1123,0,0.0650837,". Our delightfully simple approach is, in contrast, effectively task independent (in that it only requires unlabeled in-domain text), which is an important strength. 2.2 Cross-Lingual Sentiment Analysis Sentiment analysis is widely applied, and thus ideally we would have access to high quality supervised models in all human languages. Unfortunately, good quality labeled datasets are missing for many languages. Training models on resource rich languages and applying them to resource poor languages is therefore highly desirable. Crosslingual sentiment classification (CLSC) tackles this problem (Mihalcea et al., 2007; Banea et al., 2010; Wan, 2009; Lu et al., 2011; Balamurali and Joshi, 2012; Gui et al., 2013). Recent CLSC approaches use BWEs as features of deep learning architectures which allows us to use a model for target-language sentiment classification, even when the model was trained only using sourcelanguage supervised training data. Following this approach we perform CLSC on Spanish tweets using English training data. Even though Spanish is not resource-poor we simulate this by using only English annotated data. 2.3 Bilingual Lexicon Induction (BLI) BLI is an important task that has been address"
P18-1075,E14-1049,0,0.030169,"ge sources beyond having access to plentiful target-language in-domain unlabeled text. Both of the approaches we study in this work fit this criterion, the delightfully simple method for adapting BWEs can improve the performance of any off-the-shelf classifier that is based on BWEs, while the broadly applicable semi-supervised approach of H¨ausser et al. (2017) can improve the performance of any off-the-shelf classifier. Bilingual Word Embeddings Many approaches have been proposed for creating high quality BWEs using different bilingual signals. Following Mikolov et al. (2013b), many authors (Faruqui and Dyer, 2014; Xing et al., 2015; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016) map monolingual word embeddings (MWEs) into the same bilingual space. Others leverage parallel texts (Hermann and Blunsom, 2014; Gouws et al., 2015) or create artificial cross-lingual corpora using seed lexicons or document alignments (Vuli´c and Moens, 2015; Duong et al., 2016) to train BWEs. In contrast, our aim is not to improve the intrinsic quality of BWEs, but to adapt BWEs to specific domains to enhance their performance on bilingual tasks in these domains. Faruqui et al. (2015), Gouws and Søgaard (2015), Rothe et a"
P18-1075,N15-1157,0,0.0227138,"many authors (Faruqui and Dyer, 2014; Xing et al., 2015; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016) map monolingual word embeddings (MWEs) into the same bilingual space. Others leverage parallel texts (Hermann and Blunsom, 2014; Gouws et al., 2015) or create artificial cross-lingual corpora using seed lexicons or document alignments (Vuli´c and Moens, 2015; Duong et al., 2016) to train BWEs. In contrast, our aim is not to improve the intrinsic quality of BWEs, but to adapt BWEs to specific domains to enhance their performance on bilingual tasks in these domains. Faruqui et al. (2015), Gouws and Søgaard (2015), Rothe et al. (2016) have previously studied domain adaptation of bilingual word embeddings, showing it to be highly effective for improving downstream tasks. However, importantly, their proposed methods are based on specialized domain lexicons (such as, e.g., sentiment lexicons) which contain task specific word relations. Our delightfully simple approach is, in contrast, effectively task independent (in that it only requires unlabeled in-domain text), which is an important strength. 2.2 Cross-Lingual Sentiment Analysis Sentiment analysis is widely applied, and thus ideally we would have acce"
P18-1075,N16-1091,1,0.92208,"Missing"
P18-1075,P14-1006,0,0.0266157,"BWEs can improve the performance of any off-the-shelf classifier that is based on BWEs, while the broadly applicable semi-supervised approach of H¨ausser et al. (2017) can improve the performance of any off-the-shelf classifier. Bilingual Word Embeddings Many approaches have been proposed for creating high quality BWEs using different bilingual signals. Following Mikolov et al. (2013b), many authors (Faruqui and Dyer, 2014; Xing et al., 2015; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016) map monolingual word embeddings (MWEs) into the same bilingual space. Others leverage parallel texts (Hermann and Blunsom, 2014; Gouws et al., 2015) or create artificial cross-lingual corpora using seed lexicons or document alignments (Vuli´c and Moens, 2015; Duong et al., 2016) to train BWEs. In contrast, our aim is not to improve the intrinsic quality of BWEs, but to adapt BWEs to specific domains to enhance their performance on bilingual tasks in these domains. Faruqui et al. (2015), Gouws and Søgaard (2015), Rothe et al. (2016) have previously studied domain adaptation of bilingual word embeddings, showing it to be highly effective for improving downstream tasks. However, importantly, their proposed methods are ba"
P18-1075,E17-1102,0,0.0391898,"Missing"
P18-1075,P16-1024,0,0.053412,"Missing"
P18-1075,P15-2118,0,0.0630264,"Missing"
P18-1075,D14-1181,0,0.0116884,"Missing"
P18-1075,P09-1027,0,0.0514212,"ontrast, effectively task independent (in that it only requires unlabeled in-domain text), which is an important strength. 2.2 Cross-Lingual Sentiment Analysis Sentiment analysis is widely applied, and thus ideally we would have access to high quality supervised models in all human languages. Unfortunately, good quality labeled datasets are missing for many languages. Training models on resource rich languages and applying them to resource poor languages is therefore highly desirable. Crosslingual sentiment classification (CLSC) tackles this problem (Mihalcea et al., 2007; Banea et al., 2010; Wan, 2009; Lu et al., 2011; Balamurali and Joshi, 2012; Gui et al., 2013). Recent CLSC approaches use BWEs as features of deep learning architectures which allows us to use a model for target-language sentiment classification, even when the model was trained only using sourcelanguage supervised training data. Following this approach we perform CLSC on Spanish tweets using English training data. Even though Spanish is not resource-poor we simulate this by using only English annotated data. 2.3 Bilingual Lexicon Induction (BLI) BLI is an important task that has been addressed by a large amount of previou"
P18-1075,D13-1153,0,0.0180411,"t language, an impressive result considering that we require no target-language annotated data. The method also yields impressive improvements for bilingual lexicon induction compared with baselines trained on in-domain data. We show that this system requires the high-quality domain-adapted bilingual word embeddings we previously created to use unlabeled data well. 810 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 810–820 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics 2 2.1 Previous Work Xiao and Guo (2013) proposed a cross-lingual log-bilinear document model to learn distributed representations of words, which can capture both the semantic similarities of words across languages and the predictive information with respect to the classification task. Similarly, Tang and Wan (2014) jointly embedded texts in different languages into a joint semantic space representing sentiment. Zhou et al. (2014) employed aligned sentences in the BWE learning process, but in the sentiment classification process only representations in the source language are used for training, and representations in the target lan"
P18-1075,N15-1104,0,0.0432713,"access to plentiful target-language in-domain unlabeled text. Both of the approaches we study in this work fit this criterion, the delightfully simple method for adapting BWEs can improve the performance of any off-the-shelf classifier that is based on BWEs, while the broadly applicable semi-supervised approach of H¨ausser et al. (2017) can improve the performance of any off-the-shelf classifier. Bilingual Word Embeddings Many approaches have been proposed for creating high quality BWEs using different bilingual signals. Following Mikolov et al. (2013b), many authors (Faruqui and Dyer, 2014; Xing et al., 2015; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016) map monolingual word embeddings (MWEs) into the same bilingual space. Others leverage parallel texts (Hermann and Blunsom, 2014; Gouws et al., 2015) or create artificial cross-lingual corpora using seed lexicons or document alignments (Vuli´c and Moens, 2015; Duong et al., 2016) to train BWEs. In contrast, our aim is not to improve the intrinsic quality of BWEs, but to adapt BWEs to specific domains to enhance their performance on bilingual tasks in these domains. Faruqui et al. (2015), Gouws and Søgaard (2015), Rothe et al. (2016) have prev"
P18-1075,P15-1042,0,0.0252714,"classification task. Similarly, Tang and Wan (2014) jointly embedded texts in different languages into a joint semantic space representing sentiment. Zhou et al. (2014) employed aligned sentences in the BWE learning process, but in the sentiment classification process only representations in the source language are used for training, and representations in the target language are used for predicting labels. An important weakness of these three works was that aligned sentences were required. Some work has trained sentiment-specific BWEs using annotated sentiment information in both languages (Zhou et al., 2015, 2016), which is desirable, but this is not applicable to our scenario. Our goal is to adapt BWEs to a specific domain without requiring additional task-specific engineering or knowledge sources beyond having access to plentiful target-language in-domain unlabeled text. Both of the approaches we study in this work fit this criterion, the delightfully simple method for adapting BWEs can improve the performance of any off-the-shelf classifier that is based on BWEs, while the broadly applicable semi-supervised approach of H¨ausser et al. (2017) can improve the performance of any off-the-shelf cl"
P18-1075,P16-1133,0,0.0177361,"nt training data instead of English. BWEs trained on Subtitle using posthoc mapping. The difference between the two is that the embeddings of (ii) are enriched with English words which can be beneficial for the classification of Spanish tweets because they often contain a few English words. We do not compare with word embedding adaptation methods relying on specialized resources. The point of our work is to study task-independent methods and to the best of our knowledge ours is the first such attempt. Similarly, we do not compare against machine translation based sentiment classifiers (e.g., (Zhou et al., 2016)) because for their adaptation in-domain parallel data would be needed. Table 1 gives results for both classifiers. It shows that the adaptation of Subtitle based BWEs with data from Twitter (22M tweets and BACKGROUND) clearly outperforms the Baseline in all cases. The target-aware system performed poorly with the baseline BWEs and could benefit significantly from the adaptation approach. The target-ignorant performed better with the baseline BWEs but could also benefit from the adaptation. Comparing results with the Twitter-dataset-only based BWEs, the 22M tweets performed better even though"
P18-1141,Q16-1022,0,0.0496476,"Missing"
P18-1141,P14-1006,0,0.122748,"ual embeddings, shared representation of words across languages (Klementiev et al., 2012). Such embeddings can be beneficial in machine translation in sparse data settings because multilingual embeddings provide meaning representations of source and target in the same space. Similarly, in transfer learning, models trained in one language on multilingual embeddings can be deployed in other languages (Zeman and Resnik, 2008; McDonald et al., 2011; Tsvetkov et al., 2014). Automatically learned embeddings have the added advantage of requiring fewer resources for training (Klementiev et al., 2012; Hermann and Blunsom, 2014b; Guo et al., 2016). Thus, massively multilingual word embeddings (i.e., covering 100s or 1000s of languages) are likely to be important in NLP. The basic information many embedding learners use is word-context information; e.g., the embedding of a word is optimized to predict a representation of its context. We instead learn embeddings from word-concept information. As a first approximation, a concept is a set of semantically similar words. Figure 1 shows an example concept and also indicates one way we learn concepts: we interpret cliques in the dictionary graph as concepts. The nodes of th"
P18-1141,E17-1102,0,0.0392696,"Missing"
P18-1141,D17-1011,1,0.856467,"Missing"
P18-1141,C12-1089,0,0.143169,"highly parallel corpus and learn semantic representations of words in 1259 different languages in a single common space. An extensive experimental evaluation on crosslingual word similarity and sentiment analysis indicates that concept-based multilingual embedding learning performs better than previous approaches. 1 Figure 1: Example of a CLIQUE concept: “water” Introduction Vector space representations of words are widely used because they improve performance on monolingual tasks. This success has generated interest in multilingual embeddings, shared representation of words across languages (Klementiev et al., 2012). Such embeddings can be beneficial in machine translation in sparse data settings because multilingual embeddings provide meaning representations of source and target in the same space. Similarly, in transfer learning, models trained in one language on multilingual embeddings can be deployed in other languages (Zeman and Resnik, 2008; McDonald et al., 2011; Tsvetkov et al., 2014). Automatically learned embeddings have the added advantage of requiring fewer resources for training (Klementiev et al., 2012; Hermann and Blunsom, 2014b; Guo et al., 2016). Thus, massively multilingual word embeddin"
P18-1141,E17-1084,0,0.0466535,"Missing"
P18-1141,N13-1073,0,0.327681,"ngo Creole; Central Africa 1895 Algorithm 1 χ2 -based dictionary induction 268 315 242 191 177 208 231 226 194 192 Table 2: Our ten pivot languages, the languages in PBC with the lowest number of types. Tokens in 1000s. Tok Pisin and Bislama are English-based and Sango is a Ngbandi-based creole. PNG = Papua New Guinea UTF-8 has properties different from Chinese UTF8. Thus, universal language processing is easier to design on the byte level. We refer to this ngram representation as CHAR and to standard tokenization as WORD. 2.3 Dictionary induction Alignment-based dictionary. We use fastalign (Dyer et al., 2013) to compute word alignments and use GDFA for symmetrization. All alignment edges that occurred at least twice are added to the dictionary graph. Initial experiments indicated that alignment-based dictionaries have poor quality for CHAR, probably due to the fact that overlapping ngram representations of sentences have properties quite different from the tokenized sentences that aligners are optimized for. Thus we use this dictionary induction method only for WORD and developed the following alternative for CHAR. Correlation-based dictionary (χ2 ). χ2 is a greedy algorithm, shown in Figure 2, th"
P18-1141,E14-1049,0,0.0743377,"Missing"
P18-1141,N16-1155,0,0.0416912,"pes based on this selection because most editions do not contain a few of the selected 6458 verses. 2.2 Character-level modeling (CHAR) We will see that tokenization-based models have poor performance on a subset of the 1259 languages. To overcome tokenization problems, we represent a verse of length m bytes, as a sequence of m − (n − 1) + 2 overlapping byte n-grams. In this paper, “n-gram” always refers to “byte ngram”. We pad the verse with initial and final space, resulting in two additional n-grams (hence “+2”). This representation is in the spirit of earlier byte-level processing, e.g., (Gillick et al., 2016). There are several motivations for this. (i) We can take advantage of byte-level generalizations. (ii) This is robust if there is noise in the byte encoding. (iii) Characters have different properties in different languages and encodings, e.g., English 1521 tokens types iso name family; (example) region lhu Lahu Sino-Tibetan; Thailand 1452 ahk Akha Sino-Tibetan; China 1550 hak Hakka Chinese Chinese; China 1596 ium Iu Mien Hmong-Mien; Laos 1779 tpi Tok Pisin Creole; PNG 1815 mio Pinotepa Mixtec Oto-Manguean; Oaxaca 1828 cya Highland Chatino Oto-Manguean; Oaxaca 1868 bis Bislama Creole; Vanuatu"
P18-1141,2009.mtsummit-posters.11,1,0.830059,"Missing"
P18-1141,R09-1040,0,0.13124,"vot languages and one target language as a bag of words (BOW) and consider this bag as a context.3 Levy et al. (2017) show that sentence ID features (interpretable as an abstract representation of the word’s context) are effective. We use a corpus with lines consisting of pairs of an identifier of a 2 We use code.google.com/archive/p/word2vec The actual implementation slightly differs to avoid very long lines. It does only consider two pivot languages at a time, but writes each verse multiple times. 3 verse and a unit extracted from that verse as input to word2vec and call this baseline S-ID. Lardilleux and Lepage (2009) propose a simple and efficient baseline: sample-based concept induction. Words that strictly occur in the same verses are assigned to the same concept. To increase coverage, they propose to sample many different subcorpora.4 We induce concepts using this method and project them analogous to CLIQUE. We call this baseline SAMPLE. One novel contribution of this paper is roundtrip evaluation of embeddings. We learn embeddings based on a dictionary. The question arises: are the embeddings simply reproducing the information already in the dictionary or are they improving the performance of roundtri"
P18-1141,E17-1072,0,0.33965,"dding learning algorithms that define contexts and then sample pairs of an input word (more generally, an input unit) and a context word (more generally, a context unit) from each context. The only difference is that our contexts are concepts. For simplicity, we use word2vec (Mikolov et al., 2013a) as the implementation of this model.2 2.6 Baselines Baselines for multilingual embedding learning. One baseline is inspired by (Vuli´c and Moens, 2015). We consider words of one aligned verse in the pivot languages and one target language as a bag of words (BOW) and consider this bag as a context.3 Levy et al. (2017) show that sentence ID features (interpretable as an abstract representation of the word’s context) are effective. We use a corpus with lines consisting of pairs of an identifier of a 2 We use code.google.com/archive/p/word2vec The actual implementation slightly differs to avoid very long lines. It does only consider two pivot languages at a time, but writes each verse multiple times. 3 verse and a unit extracted from that verse as input to word2vec and call this baseline S-ID. Lardilleux and Lepage (2009) propose a simple and efficient baseline: sample-based concept induction. Words that stri"
P18-1141,W15-1521,0,0.0268834,"network approaches include (Hermann and Blunsom, 2014a) (BiCVM) and (Sarath Chandar et al., 2014) (autoencoders). Again, we have not enough data for training neural networks of this size. Søgaard et al. (2015) learn an interlingual space by using Wikipedia articles as concepts and applying inverted indexing. Levy et al. (2017) show that what we call S-ID is a strongly performing embedding learning method. We use S-ID as a baseline. Group C combines mono- and multilingual information in the embedding learning objective. Klementiev et al. (2012) add a word-alignment based term in the objective. Luong et al. (2015) extend Mikolov et al. (2013a)’s skipgram model to a bilingual model. Gouws et al. (2015) introduce a crosslingual term in the objective, which does not rely on any word-pair or alignment information. For n editions, including O(n2 ) bilingual terms in the objective function does not scale. Group D creates pseudocorpora by merging data from multiple languages into a single corpus. One such method, due to Vuli´c and Moens (2015), is our baseline BOW. ¨ Ostling (2014) generates multilingual concepts using a Chinese Restaurant process, a computationally expensive method. Wang et al. (2016) base t"
P18-1141,D17-1268,0,0.0243288,"ates pseudocorpora by merging data from multiple languages into a single corpus. One such method, due to Vuli´c and Moens (2015), is our baseline BOW. ¨ Ostling (2014) generates multilingual concepts using a Chinese Restaurant process, a computationally expensive method. Wang et al. (2016) base their concepts on cliques. We extend their notion of clique from the bilingual to the multilingual case. Ammar et al. (2016) use connected components. Our baseline SAMPLE, based on (Lardilleux and Lepage, 2007, 2009), samples aligned sentences from a multilingual corpus and extracts perfect alignments. Malaviya et al. (2017), Asgari and Sch¨utze ¨ (2017), Ostling and Tiedemann (2017) and Tiedemann (2018) perform evaluation on the language level (e.g., typology prediction) for 1000+ languages or perform experiments on 1000+ languages without evaluating each language. We present the first work that evaluates on 1000+ languages on the sentence level on a difficult task. Somers (2005) criticizes RT evaluation on the sentence level; but see Aiken and Park (2010). We demonstrated that when used on the word/unit level, it distinguishes weak from strong embeddings and correlates well with an independent sentiment evaluat"
P18-1141,mayer-cysouw-2014-creating,0,0.20655,"query q ∈ Lq . Retrieve the target unit t ∈ Lt that is closest to p. Retrieve the pivot word p0 ∈ Lp that is closest to t. Retrieve the unit q 0 ∈ Lq that is closest to p0 . If q = q 0 , this is an exact hit. We run this experiment for all pivot and target languages. Note that roundtrip evaluation tests the capability of a system to go from any language to any other language. In an embedding space, this requires two hops. In a highly multilingual dataset of n languages in which not all O(n2 ) bilingual dictionaries exist, this requires four hops. 3 Experiments and results 3.1 Data We use PBC (Mayer and Cysouw, 2014). The version we pulled on 2017-12-11 contains 1664 Bible editions in 1259 languages (based on ISO 639-3 codes) after we discarded editions that have low coverage of the New Testament. We use 7958 verses that have good coverage in these 1664 editions. The data is verse aligned; a verse of the New Testament can consist of multiple sentences. We randomly split verses 6458/1500 into train/test. 3.2 Evaluation For sentiment analysis, we represent a verse as the IDF-weighted sum of its embeddings. Sentiment classifiers (linear SVMs) are trained on the training set of the World English Bible edition"
P18-1141,D11-1006,0,0.0371145,"r” Introduction Vector space representations of words are widely used because they improve performance on monolingual tasks. This success has generated interest in multilingual embeddings, shared representation of words across languages (Klementiev et al., 2012). Such embeddings can be beneficial in machine translation in sparse data settings because multilingual embeddings provide meaning representations of source and target in the same space. Similarly, in transfer learning, models trained in one language on multilingual embeddings can be deployed in other languages (Zeman and Resnik, 2008; McDonald et al., 2011; Tsvetkov et al., 2014). Automatically learned embeddings have the added advantage of requiring fewer resources for training (Klementiev et al., 2012; Hermann and Blunsom, 2014b; Guo et al., 2016). Thus, massively multilingual word embeddings (i.e., covering 100s or 1000s of languages) are likely to be important in NLP. The basic information many embedding learners use is word-context information; e.g., the embedding of a word is optimized to predict a representation of its context. We instead learn embeddings from word-concept information. As a first approximation, a concept is a set of sema"
P18-1141,P97-1063,0,0.402767,"anguages on the sentence level on a difficult task. Somers (2005) criticizes RT evaluation on the sentence level; but see Aiken and Park (2010). We demonstrated that when used on the word/unit level, it distinguishes weak from strong embeddings and correlates well with an independent sentiment evaluation. Any alignment algorithm can be used for dictionary induction. We only used a member of the IBM class of models (Dyer et al., 2013), but presumably we could improve results by using either higher performing albeit slower aligners or non-IBM aligners (e.g., (Och and Ney, 2003; Tiedemann, 2003; Melamed, 1997)). Other alignment algorithms include 2D linking (Kobdani et al., 2009), sampling based methods (e.g., Vulic ¨ and Moens (2012)) and EFMARAL (Ostling and Tiedemann, 2016). EFMARAL is especially intriguing as it is based on IBM1 and Agi´c et al. (2016) find IBM2-based models to favor closely related languages more than models based on IBM1. However, the challenge is that we need to compute tens of thousands of alignments, so speed is of the essence. We ran character-based and word-based induction separately; combining them is promising future research; cf. (Heyman et al., 2017). There is much w"
P18-1141,J03-1002,0,0.0101017,"first work that evaluates on 1000+ languages on the sentence level on a difficult task. Somers (2005) criticizes RT evaluation on the sentence level; but see Aiken and Park (2010). We demonstrated that when used on the word/unit level, it distinguishes weak from strong embeddings and correlates well with an independent sentiment evaluation. Any alignment algorithm can be used for dictionary induction. We only used a member of the IBM class of models (Dyer et al., 2013), but presumably we could improve results by using either higher performing albeit slower aligners or non-IBM aligners (e.g., (Och and Ney, 2003; Tiedemann, 2003; Melamed, 1997)). Other alignment algorithms include 2D linking (Kobdani et al., 2009), sampling based methods (e.g., Vulic ¨ and Moens (2012)) and EFMARAL (Ostling and Tiedemann, 2016). EFMARAL is especially intriguing as it is based on IBM1 and Agi´c et al. (2016) find IBM2-based models to favor closely related languages more than models based on IBM1. However, the challenge is that we need to compute tens of thousands of alignments, so speed is of the essence. We ran character-based and word-based induction separately; combining them is promising future research; cf. (Heym"
P18-1141,E14-4024,0,0.242936,"information in the embedding learning objective. Klementiev et al. (2012) add a word-alignment based term in the objective. Luong et al. (2015) extend Mikolov et al. (2013a)’s skipgram model to a bilingual model. Gouws et al. (2015) introduce a crosslingual term in the objective, which does not rely on any word-pair or alignment information. For n editions, including O(n2 ) bilingual terms in the objective function does not scale. Group D creates pseudocorpora by merging data from multiple languages into a single corpus. One such method, due to Vuli´c and Moens (2015), is our baseline BOW. ¨ Ostling (2014) generates multilingual concepts using a Chinese Restaurant process, a computationally expensive method. Wang et al. (2016) base their concepts on cliques. We extend their notion of clique from the bilingual to the multilingual case. Ammar et al. (2016) use connected components. Our baseline SAMPLE, based on (Lardilleux and Lepage, 2007, 2009), samples aligned sentences from a multilingual corpus and extracts perfect alignments. Malaviya et al. (2017), Asgari and Sch¨utze ¨ (2017), Ostling and Tiedemann (2017) and Tiedemann (2018) perform evaluation on the language level (e.g., typology predic"
P18-1141,E17-2102,0,0.0220708,"ages into a single corpus. One such method, due to Vuli´c and Moens (2015), is our baseline BOW. ¨ Ostling (2014) generates multilingual concepts using a Chinese Restaurant process, a computationally expensive method. Wang et al. (2016) base their concepts on cliques. We extend their notion of clique from the bilingual to the multilingual case. Ammar et al. (2016) use connected components. Our baseline SAMPLE, based on (Lardilleux and Lepage, 2007, 2009), samples aligned sentences from a multilingual corpus and extracts perfect alignments. Malaviya et al. (2017), Asgari and Sch¨utze ¨ (2017), Ostling and Tiedemann (2017) and Tiedemann (2018) perform evaluation on the language level (e.g., typology prediction) for 1000+ languages or perform experiments on 1000+ languages without evaluating each language. We present the first work that evaluates on 1000+ languages on the sentence level on a difficult task. Somers (2005) criticizes RT evaluation on the sentence level; but see Aiken and Park (2010). We demonstrated that when used on the word/unit level, it distinguishes weak from strong embeddings and correlates well with an independent sentiment evaluation. Any alignment algorithm can be used for dictionary indu"
P18-1141,W99-0602,0,0.113614,"pts that cover around 8k of the total vocabulary of 24k English words (WORD). As an alternative to cliques, Ammar et al. (2016) use connected components (CCs). The reachability relation (induced by CC) is the transitive closure of the edge relation. This results in semantically unrelated words being in the same concept for very low levels of noise. In contrast, cliques are more “strict”: only node subsets are considered whose corresponding edge relation is already transitive (or almost so for ν = 0.6). Transitivity across languages often does not hold in alignments or dictionaries; see, e.g., Simard (1999). This is why we only consider cliques (which reflect already existent transitivity) rather than CCs, which impose transitivity where it does not hold naturally. 2.4.2 N (t) (target neighborhood) concept induction Let N (t) be the neighborhood of target node t in the multipartite dictionary graph, i.e., the set of pivot words that are linked to t. We refer to N (t) as target neighborhood. Figure 4 shows an example of such a target neighborhood, the set N (t) consisting of four words.1 A target neighborhood concept consists of a set T of pivot words and all target words t for which T = N (t) ho"
P18-1141,P15-1165,0,0.0424929,"Missing"
P18-1141,U05-1019,0,0.0189545,"al to the multilingual case. Ammar et al. (2016) use connected components. Our baseline SAMPLE, based on (Lardilleux and Lepage, 2007, 2009), samples aligned sentences from a multilingual corpus and extracts perfect alignments. Malaviya et al. (2017), Asgari and Sch¨utze ¨ (2017), Ostling and Tiedemann (2017) and Tiedemann (2018) perform evaluation on the language level (e.g., typology prediction) for 1000+ languages or perform experiments on 1000+ languages without evaluating each language. We present the first work that evaluates on 1000+ languages on the sentence level on a difficult task. Somers (2005) criticizes RT evaluation on the sentence level; but see Aiken and Park (2010). We demonstrated that when used on the word/unit level, it distinguishes weak from strong embeddings and correlates well with an independent sentiment evaluation. Any alignment algorithm can be used for dictionary induction. We only used a member of the IBM class of models (Dyer et al., 2013), but presumably we could improve results by using either higher performing albeit slower aligners or non-IBM aligners (e.g., (Och and Ney, 2003; Tiedemann, 2003; Melamed, 1997)). Other alignment algorithms include 2D linking (K"
P18-1141,E03-1026,0,0.0958877,"luates on 1000+ languages on the sentence level on a difficult task. Somers (2005) criticizes RT evaluation on the sentence level; but see Aiken and Park (2010). We demonstrated that when used on the word/unit level, it distinguishes weak from strong embeddings and correlates well with an independent sentiment evaluation. Any alignment algorithm can be used for dictionary induction. We only used a member of the IBM class of models (Dyer et al., 2013), but presumably we could improve results by using either higher performing albeit slower aligners or non-IBM aligners (e.g., (Och and Ney, 2003; Tiedemann, 2003; Melamed, 1997)). Other alignment algorithms include 2D linking (Kobdani et al., 2009), sampling based methods (e.g., Vulic ¨ and Moens (2012)) and EFMARAL (Ostling and Tiedemann, 2016). EFMARAL is especially intriguing as it is based on IBM1 and Agi´c et al. (2016) find IBM2-based models to favor closely related languages more than models based on IBM1. However, the challenge is that we need to compute tens of thousands of alignments, so speed is of the essence. We ran character-based and word-based induction separately; combining them is promising future research; cf. (Heyman et al., 2017)."
P18-1141,P14-1024,0,0.0230133,"space representations of words are widely used because they improve performance on monolingual tasks. This success has generated interest in multilingual embeddings, shared representation of words across languages (Klementiev et al., 2012). Such embeddings can be beneficial in machine translation in sparse data settings because multilingual embeddings provide meaning representations of source and target in the same space. Similarly, in transfer learning, models trained in one language on multilingual embeddings can be deployed in other languages (Zeman and Resnik, 2008; McDonald et al., 2011; Tsvetkov et al., 2014). Automatically learned embeddings have the added advantage of requiring fewer resources for training (Klementiev et al., 2012; Hermann and Blunsom, 2014b; Guo et al., 2016). Thus, massively multilingual word embeddings (i.e., covering 100s or 1000s of languages) are likely to be important in NLP. The basic information many embedding learners use is word-context information; e.g., the embedding of a word is optimized to predict a representation of its context. We instead learn embeddings from word-concept information. As a first approximation, a concept is a set of semantically similar words."
P18-1141,P16-1157,0,0.0339305,"Missing"
P18-1141,E12-1046,0,0.0583073,"Missing"
P18-1141,C12-1166,0,0.0573241,"Missing"
P18-1141,P15-2118,0,0.0468425,"Missing"
P18-1141,W14-1613,0,0.0551922,"Missing"
P18-1141,I08-3008,0,0.032048,"a CLIQUE concept: “water” Introduction Vector space representations of words are widely used because they improve performance on monolingual tasks. This success has generated interest in multilingual embeddings, shared representation of words across languages (Klementiev et al., 2012). Such embeddings can be beneficial in machine translation in sparse data settings because multilingual embeddings provide meaning representations of source and target in the same space. Similarly, in transfer learning, models trained in one language on multilingual embeddings can be deployed in other languages (Zeman and Resnik, 2008; McDonald et al., 2011; Tsvetkov et al., 2014). Automatically learned embeddings have the added advantage of requiring fewer resources for training (Klementiev et al., 2012; Hermann and Blunsom, 2014b; Guo et al., 2016). Thus, massively multilingual word embeddings (i.e., covering 100s or 1000s of languages) are likely to be important in NLP. The basic information many embedding learners use is word-context information; e.g., the embedding of a word is optimized to predict a representation of its context. We instead learn embeddings from word-concept information. As a first approximation, a c"
P18-1141,D13-1141,0,0.0380356,"Missing"
P19-1118,D18-1214,0,0.013397,", 2014; Xing et al., 2015), others leverage parallel texts (Gouws et al., 2015) or create artificial cross-lingual corpora using seed lexicons or document alignments (Vuli´c and Moens, 2015; Duong et al., 2016) to train BWEs. Several authors have shown that good quality BWEs can be trained by mapping monolingual spaces without any bilingual signal. Conneau et al. (2018) used adversarial training to rotate the source space to match the target and extracted an initial lexicon to fine tune the mapping. Others used word neighborhood information to create an initial mapping (Artetxe et al., 2018a; Alvarez-Melis and Jaakkola, 2018). We use the work of Conneau et al. (2018) to build BWEs for parallel sentence extraction. The development of unsupervised BWEs opened the door to creating machine translation systems without any parallel data. Unsupervised BWEs are used to make initial word-by-word translating systems which are then improved by iterative back-translation (Sennrich et al., 2016) using neural systems (Lample et al., 2018a; Artetxe et al., 2018c; Yang et al., 2018). It is also possible to initialize phrase tables for statistical MT systems and increase their performance with the 1225 same back-translation techni"
P19-1118,P18-1073,0,0.0782291,"Missing"
P19-1118,D18-1399,0,0.0966195,"Missing"
P19-1118,Q17-1010,0,0.00736714,"words, such as named entities and rare words, can be improved using orthographic information (Braune et al., 2018; Riley and Gildea, 2018). We follow the approach of Braune et al. (2018) and create a dictionary similar to the dictionary in the previous paragraph but using orthographic similarity of words, i.e., one minus normalized Levenshtein distance, instead of CSLS. We then merge the two dictionaries to get the final set of similar word pairs by taking all target words from both dictionaries for each source language word2 . To build monolingual embeddings we use fastText’s skipgram model (Bojanowski et al., 2017) with dimension size 300 and keeping all other parameters default3 . We use MUSE as the implementation of (Conneau et al., 2018) with default parameters4 for building unsupervised BWEs. 3.2 Word Similarity The first step of our method is to define the similarity of words. For this we use BWEs, where source and target language words are embedded in the same vector space. First, we build monolingual word embeddings and map the source words into the target space. Initially, a seed lexicon of source and target language words was needed to learn a mapping between the two spaces (Mikolov et al., 201"
P19-1118,N18-2030,1,0.842852,"aseline results. 3 Approach Our approach for mining parallel sentences is based on calculating the similarity of sentence pair candidates. To avoid mining pairs having similar words but different meaning we look for continuous parallel segments in the candidates based on word alignments. We use the length of the segments to either filter the candidate out or to weight the averaged similarity scores of words to get the final score of a given candidate. 3.1 built based on BWEs, the translations of some words, such as named entities and rare words, can be improved using orthographic information (Braune et al., 2018; Riley and Gildea, 2018). We follow the approach of Braune et al. (2018) and create a dictionary similar to the dictionary in the previous paragraph but using orthographic similarity of words, i.e., one minus normalized Levenshtein distance, instead of CSLS. We then merge the two dictionaries to get the final set of similar word pairs by taking all target words from both dictionaries for each source language word2 . To build monolingual embeddings we use fastText’s skipgram model (Bojanowski et al., 2017) with dimension size 300 and keeping all other parameters default3 . We use MUSE as the i"
P19-1118,D16-1136,0,0.018314,"ing. Also, the usefulness of the system in downstream tasks was not tested. Our approach is based on BWEs where representations of source and target language words are in the same bilingual space. Previous approaches building BWEs were using bilingual signals of various granularity. Following Mikolov et al. (2013), many authors map monolingual word embeddings into the same bilingual space (Faruqui and Dyer, 2014; Xing et al., 2015), others leverage parallel texts (Gouws et al., 2015) or create artificial cross-lingual corpora using seed lexicons or document alignments (Vuli´c and Moens, 2015; Duong et al., 2016) to train BWEs. Several authors have shown that good quality BWEs can be trained by mapping monolingual spaces without any bilingual signal. Conneau et al. (2018) used adversarial training to rotate the source space to match the target and extracted an initial lexicon to fine tune the mapping. Others used word neighborhood information to create an initial mapping (Artetxe et al., 2018a; Alvarez-Melis and Jaakkola, 2018). We use the work of Conneau et al. (2018) to build BWEs for parallel sentence extraction. The development of unsupervised BWEs opened the door to creating machine translation s"
P19-1118,E14-1049,0,0.0577486,"ach which only uses monolingual data. A fully unsupervised system was proposed in (Hangya et al., 2018) but the system introduced too much noise by mining sentence pairs with similar words but different meaning. Also, the usefulness of the system in downstream tasks was not tested. Our approach is based on BWEs where representations of source and target language words are in the same bilingual space. Previous approaches building BWEs were using bilingual signals of various granularity. Following Mikolov et al. (2013), many authors map monolingual word embeddings into the same bilingual space (Faruqui and Dyer, 2014; Xing et al., 2015), others leverage parallel texts (Gouws et al., 2015) or create artificial cross-lingual corpora using seed lexicons or document alignments (Vuli´c and Moens, 2015; Duong et al., 2016) to train BWEs. Several authors have shown that good quality BWEs can be trained by mapping monolingual spaces without any bilingual signal. Conneau et al. (2018) used adversarial training to rotate the source space to match the target and extracted an initial lexicon to fine tune the mapping. Others used word neighborhood information to create an initial mapping (Artetxe et al., 2018a; Alvare"
P19-1118,W17-2509,0,0.0663276,"Missing"
P19-1118,P17-3003,0,0.127413,"Center for Information and Language Processing LMU Munich, Germany {hangyav, fraser}@cis.lmu.de Abstract ters. For many interesting low resource language pairs, we do not have enough parallel data, but we do have access to sources of comparable monolingual text. In this paper we propose a strong unsupervised system for parallel sentence mining and show that the mined data improves the performance of unsupervised MT systems. Previously many approaches tackled the problem of parallel sentence extraction but they were relying on different levels of bilingual signals either to build dictionaries (Grover and Mitra, 2017), parallel sentence classifiers (Bouamor and Sajjad, 2018) or bilingual sentence representations (Schwenk, 2018). An unsupervised system was also proposed which only relied on unsupervised BWEs, thus no additional resources are needed (Hangya et al., 2018). We use this approach as our baseline and show that relying only on word similarity information leads to false positive sentence pairs, such as in this example: Mining parallel sentences from comparable corpora is important. Most previous work relies on supervised systems, which are trained on parallel data, thus their applicability is probl"
P19-1118,N04-1034,1,0.594961,"crawl data to mine parallel sentences, and use them to improve an unsupervised neural MT system by using the extracted data as silverstandard parallel training data. We show for the first time that exploiting comparable monolingual text sources with an unsupervised parallel sentence mining system helps unsupervised MT. Furthermore, we achieve increased performance compared with the previous unsupervised mining system. 2 Related Work Most previous systems addressing parallel sentence extraction depend on bilingual resources which makes their applicability problematic in low-resource scenarios. Munteanu et al. (2004) used a bilingual dictionary and a small number of parallel sentences to train a maximum entropy classifier for mining Arabic and English parallel sentences. Similarly, parallel data was used to train IBM Model 1 and a maximum entropy classifier (Smith et al., 2010). Munteanu and Marcu (2006) extracted parallel sub-sentential segments from partly parallel sentences and used them to improve a statistical MT system. We follow this idea in our work and detect continuous parallel segments in order to weight the similarity values of candidate sentence pairs. To further promote the task, the BUCC 20"
P19-1118,P06-1011,0,0.155034,"system helps unsupervised MT. Furthermore, we achieve increased performance compared with the previous unsupervised mining system. 2 Related Work Most previous systems addressing parallel sentence extraction depend on bilingual resources which makes their applicability problematic in low-resource scenarios. Munteanu et al. (2004) used a bilingual dictionary and a small number of parallel sentences to train a maximum entropy classifier for mining Arabic and English parallel sentences. Similarly, parallel data was used to train IBM Model 1 and a maximum entropy classifier (Smith et al., 2010). Munteanu and Marcu (2006) extracted parallel sub-sentential segments from partly parallel sentences and used them to improve a statistical MT system. We follow this idea in our work and detect continuous parallel segments in order to weight the similarity values of candidate sentence pairs. To further promote the task, the BUCC 2017 shared task – Identifying parallel sentences in comparable corpora 1 Chinese-English is left for future work, as a study of unsupervised Chinese word segmentation approaches is needed. – was organized, where parallel sentences were automatically inserted into two monolingual corpora to pro"
P19-1118,P18-2062,0,0.0224102,"proach Our approach for mining parallel sentences is based on calculating the similarity of sentence pair candidates. To avoid mining pairs having similar words but different meaning we look for continuous parallel segments in the candidates based on word alignments. We use the length of the segments to either filter the candidate out or to weight the averaged similarity scores of words to get the final score of a given candidate. 3.1 built based on BWEs, the translations of some words, such as named entities and rare words, can be improved using orthographic information (Braune et al., 2018; Riley and Gildea, 2018). We follow the approach of Braune et al. (2018) and create a dictionary similar to the dictionary in the previous paragraph but using orthographic similarity of words, i.e., one minus normalized Levenshtein distance, instead of CSLS. We then merge the two dictionaries to get the final set of similar word pairs by taking all target words from both dictionaries for each source language word2 . To build monolingual embeddings we use fastText’s skipgram model (Bojanowski et al., 2017) with dimension size 300 and keeping all other parameters default3 . We use MUSE as the implementation of (Conneau"
P19-1118,P18-2037,0,0.148416,"nteresting low resource language pairs, we do not have enough parallel data, but we do have access to sources of comparable monolingual text. In this paper we propose a strong unsupervised system for parallel sentence mining and show that the mined data improves the performance of unsupervised MT systems. Previously many approaches tackled the problem of parallel sentence extraction but they were relying on different levels of bilingual signals either to build dictionaries (Grover and Mitra, 2017), parallel sentence classifiers (Bouamor and Sajjad, 2018) or bilingual sentence representations (Schwenk, 2018). An unsupervised system was also proposed which only relied on unsupervised BWEs, thus no additional resources are needed (Hangya et al., 2018). We use this approach as our baseline and show that relying only on word similarity information leads to false positive sentence pairs, such as in this example: Mining parallel sentences from comparable corpora is important. Most previous work relies on supervised systems, which are trained on parallel data, thus their applicability is problematic in low-resource scenarios. Recent developments in building unsupervised bilingual word embeddings made it"
P19-1118,P16-1009,0,0.334622,"ed adversarial training to rotate the source space to match the target and extracted an initial lexicon to fine tune the mapping. Others used word neighborhood information to create an initial mapping (Artetxe et al., 2018a; Alvarez-Melis and Jaakkola, 2018). We use the work of Conneau et al. (2018) to build BWEs for parallel sentence extraction. The development of unsupervised BWEs opened the door to creating machine translation systems without any parallel data. Unsupervised BWEs are used to make initial word-by-word translating systems which are then improved by iterative back-translation (Sennrich et al., 2016) using neural systems (Lample et al., 2018a; Artetxe et al., 2018c; Yang et al., 2018). It is also possible to initialize phrase tables for statistical MT systems and increase their performance with the 1225 same back-translation techniques (Lample et al., 2018b; Artetxe et al., 2018b). Although the initial results are promising, there are many issues still to be solved. In our experiments we use the NMT system of (Artetxe et al., 2018c). We show that the addition of our mined parallel data improves performance over baseline results. 3 Approach Our approach for mining parallel sentences is bas"
P19-1118,N10-1063,0,0.0362227,"allel sentence mining system helps unsupervised MT. Furthermore, we achieve increased performance compared with the previous unsupervised mining system. 2 Related Work Most previous systems addressing parallel sentence extraction depend on bilingual resources which makes their applicability problematic in low-resource scenarios. Munteanu et al. (2004) used a bilingual dictionary and a small number of parallel sentences to train a maximum entropy classifier for mining Arabic and English parallel sentences. Similarly, parallel data was used to train IBM Model 1 and a maximum entropy classifier (Smith et al., 2010). Munteanu and Marcu (2006) extracted parallel sub-sentential segments from partly parallel sentences and used them to improve a statistical MT system. We follow this idea in our work and detect continuous parallel segments in order to weight the similarity values of candidate sentence pairs. To further promote the task, the BUCC 2017 shared task – Identifying parallel sentences in comparable corpora 1 Chinese-English is left for future work, as a study of unsupervised Chinese word segmentation approaches is needed. – was organized, where parallel sentences were automatically inserted into two"
P19-1118,P15-2118,0,0.0765051,"Missing"
P19-1118,N15-1104,0,0.226765,"lingual data. A fully unsupervised system was proposed in (Hangya et al., 2018) but the system introduced too much noise by mining sentence pairs with similar words but different meaning. Also, the usefulness of the system in downstream tasks was not tested. Our approach is based on BWEs where representations of source and target language words are in the same bilingual space. Previous approaches building BWEs were using bilingual signals of various granularity. Following Mikolov et al. (2013), many authors map monolingual word embeddings into the same bilingual space (Faruqui and Dyer, 2014; Xing et al., 2015), others leverage parallel texts (Gouws et al., 2015) or create artificial cross-lingual corpora using seed lexicons or document alignments (Vuli´c and Moens, 2015; Duong et al., 2016) to train BWEs. Several authors have shown that good quality BWEs can be trained by mapping monolingual spaces without any bilingual signal. Conneau et al. (2018) used adversarial training to rotate the source space to match the target and extracted an initial lexicon to fine tune the mapping. Others used word neighborhood information to create an initial mapping (Artetxe et al., 2018a; Alvarez-Melis and Jaakkola"
P19-1118,D17-1319,0,0.0229535,"rt non-parallel segment divides a longer parallel segment which could be solved by either using larger window size for the average filter or by merging segments if they are a few tokens away from each other. On the other hand, this could also introduce false positives. In general, we can conclude that we improved F1 score significantly, except for French-English where the baseline performed only a couple of percentage points better. Furthermore, our method achieved the highest precision, out-performing the baseline in all three language pairs, which is more important when mining from the web (Xu and Koehn, 2017). 5 Improving Unsupervised MT Since, parallel sentence mining is mostly important for downstream tasks such as low resource machine translation, we now show that mined sentences improve MT performance, which was not 1229 shown before. In this section we mine parallel data from real life data sources and use the extracted sentences to improve the performance of unsupervised MT. For this we simulate a lowresource setup for the German-English language pair similarly to previous work on unsupervised MT (Artetxe et al., 2018c; Lample et al., 2018b). 5.1 Evaluation Setup To mine parallel sentence pa"
P19-1118,P18-1005,0,0.0330962,"itial lexicon to fine tune the mapping. Others used word neighborhood information to create an initial mapping (Artetxe et al., 2018a; Alvarez-Melis and Jaakkola, 2018). We use the work of Conneau et al. (2018) to build BWEs for parallel sentence extraction. The development of unsupervised BWEs opened the door to creating machine translation systems without any parallel data. Unsupervised BWEs are used to make initial word-by-word translating systems which are then improved by iterative back-translation (Sennrich et al., 2016) using neural systems (Lample et al., 2018a; Artetxe et al., 2018c; Yang et al., 2018). It is also possible to initialize phrase tables for statistical MT systems and increase their performance with the 1225 same back-translation techniques (Lample et al., 2018b; Artetxe et al., 2018b). Although the initial results are promising, there are many issues still to be solved. In our experiments we use the NMT system of (Artetxe et al., 2018c). We show that the addition of our mined parallel data improves performance over baseline results. 3 Approach Our approach for mining parallel sentences is based on calculating the similarity of sentence pair candidates. To avoid mining pairs ha"
P19-1118,W17-2512,0,0.107771,"aly, July 28 - August 2, 2019. 2019 Association for Computational Linguistics sides that are aligned with each other. In order to increase the precision of our system we only mine similar sentence pairs where the detected parallel segments form a large part of the full sentence pairs thus overcoming the problem of only nearly parallel sentence pairs mentioned above. We conduct two sets of experiments to show that our system mines more useful parallel sentences and that they are beneficial for MT systems. First, we evaluate the accuracy of the mining approach on the BUCC 2017 shared task data (Zweigenbaum et al., 2017). We show that by looking for continuous parallel segments we can increase the performance significantly compared to (Hangya et al., 2018), especially the precision of the system, on German-, French- and RussianEnglish language pairs.1 Second, since the data used in previous work was artificially assembled, we use real life German and English monolingual news crawl data to mine parallel sentences, and use them to improve an unsupervised neural MT system by using the extracted data as silverstandard parallel training data. We show for the first time that exploiting comparable monolingual text s"
P19-1581,P18-1073,0,0.0253661,"xt. 2.1 Word Translation To translate source language words we use a combination of BWE based cosine and orthographic similarity. BWEs represent source and target language words in a joint space and can be built by training monolingual spaces and projecting them to the common space. Initially, a small seed lexicon was used as the bilingual signal to learn a linear mapping (Mikolov et al., 2013) which was further improved by applying orthogonal transformations only (Xing et al., 2015). Recently, various techniques were developed to build BWEs without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018). In the work of Conneau et al. (2018) adversarial training is employed to generate an initial seed lexicon of frequent words which is then used for orthogonal mapping. Even though BWEs in general are of good quality the translation of various words types, such as named entities and rare words, could be further improved by using orthographic similarity (Braune et al., 2018; Riley and Gildea, 2018; Artetxe et al., 2019). Similarly to (Braune et al., 2018), we combine the BWE based cosine and orthographic similarity of word pairs to get the translations of source words. We generate a dictionary"
P19-1581,P19-1019,0,0.0605015,"Missing"
P19-1581,Q17-1010,0,0.0446987,"), we combine the BWE based cosine and orthographic similarity of word pairs to get the translations of source words. We generate a dictionary of source-target word pairs by taking the top n most similar target words for each source using both similarity measures. We define orthographic similarity as one minus normalized Levenshtein distance. Since orthographic similarity of close words are higher than their cosine, we weight the former with 0.2 (we found this value to work well on a different task and did not tune it further). To build monolingual embeddings we use fastText’s skipgram model (Bojanowski et al., 2017) with dimension size 300 and minimum word frequency 3. For building unsupervised BWEs we use MUSE as the implementation of (Conneau et al., 2018). Note that we use unsupervised BWEs due to their good performance on the En-De language pair (see (Conneau et al., 2018)). But acquiring a small lexicon including frequent words is cheap for language pairs where unsupervised mapping has a lower performance than supervised mapping, and could be considered in future work. 2.2 NMT Fine-Tuning We mine target language sentences from a monolingual corpus which contains the translations of source OOVs. Sinc"
P19-1581,N18-2030,1,0.940825,"ikolov et al., 2013) which was further improved by applying orthogonal transformations only (Xing et al., 2015). Recently, various techniques were developed to build BWEs without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018). In the work of Conneau et al. (2018) adversarial training is employed to generate an initial seed lexicon of frequent words which is then used for orthogonal mapping. Even though BWEs in general are of good quality the translation of various words types, such as named entities and rare words, could be further improved by using orthographic similarity (Braune et al., 2018; Riley and Gildea, 2018; Artetxe et al., 2019). Similarly to (Braune et al., 2018), we combine the BWE based cosine and orthographic similarity of word pairs to get the translations of source words. We generate a dictionary of source-target word pairs by taking the top n most similar target words for each source using both similarity measures. We define orthographic similarity as one minus normalized Levenshtein distance. Since orthographic similarity of close words are higher than their cosine, we weight the former with 0.2 (we found this value to work well on a different task and did not tu"
P19-1581,W17-4713,0,0.0691799,"vocabulary. Given the sentences to translate we look for source language words not included in the parallel training set of our MT system (OOVs). We translate OOVs using BWE based dictionaries taking nbest candidates as opposed to previous work (e.g., (Luong et al., 2015)) where only the best translation is used during post-processing. In our experiments we take the 5−best predictions of our BWEs, and retrieve sentences containing these target-language predictions from a monolingual corpus. As was shown before, NMT systems can be quickly and effectively fine-tuned using just a few sentences (Farajian et al., 2017, 2018; Wuebker et al., 2018). Based on the 5−best translations of OOVs we mine sentences from target language monolingual data and generate a synthetic parallel corpus using back-translation (Sennrich et al., 2016a). We force the source-language translation of each OOV-translation-candidate to be the original OOV. We show that by using this synthetic data to fine-tune our system the translation of unseen words can be dramatically improved, despite the presence of wrong translations of each OOV in the synthetic data. We test our system on the translation of English medical terms to German and"
P19-1581,P16-1014,0,0.0157605,"se by definition source-side OOVs were not seen in the training parallel data together with their translations. In this work, we evaluate a simple approach for improving the translation of OOVs using bilingual word embeddings (BWEs), which we hope will trigger more research on this interesting problem. In previous approaches, to include words in the target sentence for which the translation is unknown the token unk is often used which can be handled by later steps. In many cases, such as named entities, it is possible to just copy the source token to the target side instead of translating it. Gulcehre et al. (2016) proposed a pointer network based (Vinyals et al., 2015) system which can learn when to translate and when to copy. On the other hand, it is not possible to always copy when the translation is unknown. If the alignment of the unk tokens to the source are known it is possible to translate source words using a large dictionary as a post-processing step. Although NMT systems do not rely on word alignments explicitly, it is possible to learn and output word alignments (Luong et al., 2015). It is also possible to use lexically-constrained decoders (Post and Vilar, 2018; Hasler et al., 2018) in orde"
P19-1581,P18-1075,1,0.911766,"e UFAL Medical Corpus (UFAL). Since the corpus is parallel, we split it and used even sentences for English and odd ones for German. We built BWEs not only on the monolingual medical data but on 5811 rare freq (Braune et al., 2018) EU+UFAL+orth (Braune et al., 2018) EU+UFAL+orth Acc1 38.6 25.9 26.3 17.5 Acc5 47.4 40.6 28.2 28.8 baseline copy fine-tuned Table 2: Medical bilingual lexicon induction results showing the quality of the BWE based dictionaries using 1-best and 5-best translations. the concatenation of all Europarl data and the monolingual medical data to improve the quality of BWEs (Hangya et al., 2018). We only mined sentences from the monolingual medical German corpus. The testing of our approach was done on the medical Health In My Language (HimL) corpora (Haddow et al., 2017) containing 1.9K sentence pairs in both development and test sets. All corpora were tokenized and truecased using Moses scripts (Koehn et al., 2007). We ran two sets of experiments. First we show the translation quality of our dictionaries by looking at the OOVs and their translations using HimL development data. Then we show translation quality improvements on the HimL test data. 3.1 OOV Translation The quality of o"
P19-1581,N18-2081,0,0.0756065,"Missing"
P19-1581,W17-4730,1,0.871614,"s of medical terms, and back-translate the rest to generate synthetic parallel data. We force the back-translation of each of the proposed target-language OOVtranslation-candidates to be the original sourcelanguage OOV. In our experiments we use an encoder-decoder NMT system (Sennrich et al., 2017) with attention, 500 dimensional embedding layer, 1024 dimensional GRU layer and we use Adam with a learning rate of 0.0001 to train the network. We apply word segmentation with BPE using 50K merge operations to the English text, and a linguistically informed pipeline to the target-side German text (Huck et al., 2017b). It is important to understand that OOVs for us are words, and we handle both the dictionary based OOV translation and sentence mining on the word level. BPEs are only used when using NMT to translate. We train two systems, one each for the forward and backward directions. We describe the used data in Section 3. During back-translation we force the OOV-translation-candidates to be back-translated to the original source-language OOV by changing the OOV-translation-candidate to a special token on the target side before translation and then substituting the special token in the source-language"
P19-1581,W17-4706,1,0.899393,"s of medical terms, and back-translate the rest to generate synthetic parallel data. We force the back-translation of each of the proposed target-language OOVtranslation-candidates to be the original sourcelanguage OOV. In our experiments we use an encoder-decoder NMT system (Sennrich et al., 2017) with attention, 500 dimensional embedding layer, 1024 dimensional GRU layer and we use Adam with a learning rate of 0.0001 to train the network. We apply word segmentation with BPE using 50K merge operations to the English text, and a linguistically informed pipeline to the target-side German text (Huck et al., 2017b). It is important to understand that OOVs for us are words, and we handle both the dictionary based OOV translation and sentence mining on the word level. BPEs are only used when using NMT to translate. We train two systems, one each for the forward and backward directions. We describe the used data in Section 3. During back-translation we force the OOV-translation-candidates to be back-translated to the original source-language OOV by changing the OOV-translation-candidate to a special token on the target side before translation and then substituting the special token in the source-language"
P19-1581,2005.mtsummit-papers.11,0,0.0159432,"polysemous words, because the input context (which often disambiguates a polysemous word) will usually be most similar to the target-language context of the correct OOV-translation-candidate. Furthermore, this also makes our approach robust against incorrect OOV-translation-candidates in the used dictionary, since they are often used in very different contexts compared to the context of the source OOV we are translating. 3 Experiments We translate medical English sentences to German. To train the baseline NMT system we used the Europarl v7 (EU) parallel dataset containing 1.9M sentence pairs (Koehn, 2005). As medical data, we took 3.1M sentences from titles of medical Wikipedia articles, medical termpairs, patents and documents from the European Medicines Agency which are part of the UFAL Medical Corpus (UFAL). Since the corpus is parallel, we split it and used even sentences for English and odd ones for German. We built BWEs not only on the monolingual medical data but on 5811 rare freq (Braune et al., 2018) EU+UFAL+orth (Braune et al., 2018) EU+UFAL+orth Acc1 38.6 25.9 26.3 17.5 Acc5 47.4 40.6 28.2 28.8 baseline copy fine-tuned Table 2: Medical bilingual lexicon induction results showing the"
P19-1581,P07-2045,0,0.00445595,"baseline copy fine-tuned Table 2: Medical bilingual lexicon induction results showing the quality of the BWE based dictionaries using 1-best and 5-best translations. the concatenation of all Europarl data and the monolingual medical data to improve the quality of BWEs (Hangya et al., 2018). We only mined sentences from the monolingual medical German corpus. The testing of our approach was done on the medical Health In My Language (HimL) corpora (Haddow et al., 2017) containing 1.9K sentence pairs in both development and test sets. All corpora were tokenized and truecased using Moses scripts (Koehn et al., 2007). We ran two sets of experiments. First we show the translation quality of our dictionaries by looking at the OOVs and their translations using HimL development data. Then we show translation quality improvements on the HimL test data. 3.1 OOV Translation The quality of our proposed method is highly dependent on that of the used dictionaries, since in order to mine useful sentences OOVs first needed to be translated correctly. Since we lack the gold translations of the OOVs, we measure the quality of the mined target language sentences using parallel data by following the approach presented fo"
P19-1581,N18-1119,0,0.0208947,"instead of translating it. Gulcehre et al. (2016) proposed a pointer network based (Vinyals et al., 2015) system which can learn when to translate and when to copy. On the other hand, it is not possible to always copy when the translation is unknown. If the alignment of the unk tokens to the source are known it is possible to translate source words using a large dictionary as a post-processing step. Although NMT systems do not rely on word alignments explicitly, it is possible to learn and output word alignments (Luong et al., 2015). It is also possible to use lexically-constrained decoders (Post and Vilar, 2018; Hasler et al., 2018) in order to force the network to output certain words or sequences. This way alignments are not needed and the system can decide the position of the constraints in the output. The disadvantage of the above methods is that the translation of words needed to be decided either as a pre- or post-processing step without the context which makes the translation of some words, such as polysemous words, difficult. In addition, lexically-constrained decoders require the target words to be observed in context at training time, or they will usually not be placed properly. In contras"
P19-1581,P18-2062,0,0.0552118,"which was further improved by applying orthogonal transformations only (Xing et al., 2015). Recently, various techniques were developed to build BWEs without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018). In the work of Conneau et al. (2018) adversarial training is employed to generate an initial seed lexicon of frequent words which is then used for orthogonal mapping. Even though BWEs in general are of good quality the translation of various words types, such as named entities and rare words, could be further improved by using orthographic similarity (Braune et al., 2018; Riley and Gildea, 2018; Artetxe et al., 2019). Similarly to (Braune et al., 2018), we combine the BWE based cosine and orthographic similarity of word pairs to get the translations of source words. We generate a dictionary of source-target word pairs by taking the top n most similar target words for each source using both similarity measures. We define orthographic similarity as one minus normalized Levenshtein distance. Since orthographic similarity of close words are higher than their cosine, we weight the former with 0.2 (we found this value to work well on a different task and did not tune it further). To build"
P19-1581,E17-3017,0,0.0195946,"-letter characters as more than one third of their characters. In addition, we also filter out translations that are stopwords. We then use the set of target language words to mine all sentences that contain any of them from the monolingual data. We filter out sentences longer than 50 tokens, since they tend to be listings of medical terms, and back-translate the rest to generate synthetic parallel data. We force the back-translation of each of the proposed target-language OOVtranslation-candidates to be the original sourcelanguage OOV. In our experiments we use an encoder-decoder NMT system (Sennrich et al., 2017) with attention, 500 dimensional embedding layer, 1024 dimensional GRU layer and we use Adam with a learning rate of 0.0001 to train the network. We apply word segmentation with BPE using 50K merge operations to the English text, and a linguistically informed pipeline to the target-side German text (Huck et al., 2017b). It is important to understand that OOVs for us are words, and we handle both the dictionary based OOV translation and sentence mining on the word level. BPEs are only used when using NMT to translate. We train two systems, one each for the forward and backward directions. We de"
P19-1581,P16-1009,0,0.271199,"ramatically improved. In our experiments we use a system trained on Europarl and mine sentences containing medical terms from monolingual data. 1 Introduction Neural machine translation (NMT) systems achieved a breakthrough in translation quality recently, by learning an end-to-end system (Sutskever et al., 2014; Bahdanau et al., 2015). However, NMT systems have low quality when translating out-of-vocabulary words (OOVs), especially because they have a fixed modest sized vocabulary due to memory limitations. By splitting words into subword units the problem of representing OOVs can be solved (Sennrich et al., 2016b) but their translation is still problematic because by definition source-side OOVs were not seen in the training parallel data together with their translations. In this work, we evaluate a simple approach for improving the translation of OOVs using bilingual word embeddings (BWEs), which we hope will trigger more research on this interesting problem. In previous approaches, to include words in the target sentence for which the translation is unknown the token unk is often used which can be handled by later steps. In many cases, such as named entities, it is possible to just copy the source t"
P19-1581,P16-1162,0,0.599446,"ramatically improved. In our experiments we use a system trained on Europarl and mine sentences containing medical terms from monolingual data. 1 Introduction Neural machine translation (NMT) systems achieved a breakthrough in translation quality recently, by learning an end-to-end system (Sutskever et al., 2014; Bahdanau et al., 2015). However, NMT systems have low quality when translating out-of-vocabulary words (OOVs), especially because they have a fixed modest sized vocabulary due to memory limitations. By splitting words into subword units the problem of representing OOVs can be solved (Sennrich et al., 2016b) but their translation is still problematic because by definition source-side OOVs were not seen in the training parallel data together with their translations. In this work, we evaluate a simple approach for improving the translation of OOVs using bilingual word embeddings (BWEs), which we hope will trigger more research on this interesting problem. In previous approaches, to include words in the target sentence for which the translation is unknown the token unk is often used which can be handled by later steps. In many cases, such as named entities, it is possible to just copy the source t"
P19-1581,P18-1072,0,0.0322542,"Missing"
P19-1581,D18-1104,0,0.150908,"ces to translate we look for source language words not included in the parallel training set of our MT system (OOVs). We translate OOVs using BWE based dictionaries taking nbest candidates as opposed to previous work (e.g., (Luong et al., 2015)) where only the best translation is used during post-processing. In our experiments we take the 5−best predictions of our BWEs, and retrieve sentences containing these target-language predictions from a monolingual corpus. As was shown before, NMT systems can be quickly and effectively fine-tuned using just a few sentences (Farajian et al., 2017, 2018; Wuebker et al., 2018). Based on the 5−best translations of OOVs we mine sentences from target language monolingual data and generate a synthetic parallel corpus using back-translation (Sennrich et al., 2016a). We force the source-language translation of each OOV-translation-candidate to be the original OOV. We show that by using this synthetic data to fine-tune our system the translation of unseen words can be dramatically improved, despite the presence of wrong translations of each OOV in the synthetic data. We test our system on the translation of English medical terms to German and show significant improvements"
P19-1581,N15-1104,0,0.0309723,"rrect, we show in our experiments that the NMT system can effectively filter out the noise in the synthetic corpus using the context. 2.1 Word Translation To translate source language words we use a combination of BWE based cosine and orthographic similarity. BWEs represent source and target language words in a joint space and can be built by training monolingual spaces and projecting them to the common space. Initially, a small seed lexicon was used as the bilingual signal to learn a linear mapping (Mikolov et al., 2013) which was further improved by applying orthogonal transformations only (Xing et al., 2015). Recently, various techniques were developed to build BWEs without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018). In the work of Conneau et al. (2018) adversarial training is employed to generate an initial seed lexicon of frequent words which is then used for orthogonal mapping. Even though BWEs in general are of good quality the translation of various words types, such as named entities and rare words, could be further improved by using orthographic similarity (Braune et al., 2018; Riley and Gildea, 2018; Artetxe et al., 2019). Similarly to (Braune et al., 2018), we comb"
W05-0814,J93-2003,0,0.0703643,"292-6601 marcu@isi.edu Abstract We discuss results on the shared task of Romanian-English word alignment. The baseline technique is that of symmetrizing two word alignments automatically generated using IBM Model 4. A simple vocabulary reduction technique results in an improvement in performance. We also report on a new alignment model and a new training algorithm based on alternating maximization of likelihood with minimization of error rate. 1 Introduction ISI participated in the WPT05 Romanian-English word alignment task. The system used for baseline experiments is two runs of IBM Model 4 (Brown et al., 1993) in the GIZA++ (Och and Ney, 2003) implementation, which includes smoothing extensions to Model 4. For symmetrization, we found that Och and Ney’s “refined” technique described in (Och and Ney, 2003) produced the best AER for this data set under all experimental conditions. We experimented with a statistical model for inducing a stemmer cross-lingually, but found that the best performance was obtained by simply lowercasing both the English and Romanian text and removing all but the first four characters of each word. We also tried a new model and a new training criterion based on alternating t"
W05-0814,2004.iwslt-papers.2,0,0.0116132,"FROM E NGLISH WORD TTABLE ESTIMATED FROM INTERSECTION OF TWO STARTING ALIGNMENTS FOR THIS ITERATION TRANSLATION TABLE FROM E NGLISH TO ROMANIAN M ODEL 1 I TERATION 5 TRANSLATION TABLE FROM ROMANIAN TO E NGLISH M ODEL 1 I TERATION 5 BACKOFF FERTILITY ( FERTILITY ESTIMATED OVER ALL E NGLISH WORDS ) ZERO FERTILITY E NGLISH WORD PENALTY NON - ZERO FERTILITY E NGLISH WORD PENALTY consider English to be the source language and Romanian the target language. The log-linear alignment model is specified by equation 3. The model assigns non-zero probabilities only to 1-to-many alignments, like Model 4. (Cettolo and Federico, 2004) used a log-linear model trained using error minimization for the translation task, 3 of the submodels were taken from Model 4 in a similar way to our first 5 submodels. P exp( m λm hm (f, a, e)) P pλ (a, f |e) = P (3) f,e,a exp( m λm hm (f, a, e)) Given λ, the alignment search problem is to find the alignment a of highest probability according to equation 3. We solve this using the local search defined in (Brown et al., 1993). We set λ as follows. Given a sequence A of alignments we can calculate an error function, E(A). For these experiments average sentence AER was used. We wish to minimize"
W05-0814,W03-0305,0,0.037944,"ind a setting for λ that reduces AER on discriminative training set (new D-step) We use the first 148 sentences of the 2003 test set for the discriminative training set. 10 settings for λ are found, the hypothesis list is augmented using the results of 10 searches using these settings, and then another 10 settings for λ are found. We then select the best λ. The discriminative training regimen is otherwise similar to (Och, 2003). 5 Experiments Table 2 provides a comparison of our baseline systems using the “refined” symmetrization metric with the best limited resources track system from WPT03 (Dejean et al., 2003) on the 2003 test set. The best results are obtained by stemming both English and Romanian words to the first four letters, as described in section 2. Table 3 provides details on our shared task submission. RUN1 is the word-based baseline system. RUN2 is the stem-based baseline system. RUN4 uses only the first 6 submodels, while RUN5 uses all 11 submodels. RUN3 had errors in processing, so we omit it. Results: • Our new 1-to-many alignment model and training method are successful, producing decreases of 0.03 AER when the source is Romanian, and 0.01 AER when the source is English. Table 2: Sum"
W05-0814,J03-1002,0,0.0414906,"discuss results on the shared task of Romanian-English word alignment. The baseline technique is that of symmetrizing two word alignments automatically generated using IBM Model 4. A simple vocabulary reduction technique results in an improvement in performance. We also report on a new alignment model and a new training algorithm based on alternating maximization of likelihood with minimization of error rate. 1 Introduction ISI participated in the WPT05 Romanian-English word alignment task. The system used for baseline experiments is two runs of IBM Model 4 (Brown et al., 1993) in the GIZA++ (Och and Ney, 2003) implementation, which includes smoothing extensions to Model 4. For symmetrization, we found that Och and Ney’s “refined” technique described in (Och and Ney, 2003) produced the best AER for this data set under all experimental conditions. We experimented with a statistical model for inducing a stemmer cross-lingually, but found that the best performance was obtained by simply lowercasing both the English and Romanian text and removing all but the first four characters of each word. We also tried a new model and a new training criterion based on alternating the maximization of likelihood and"
W05-0814,P03-1021,0,0.00824257,"(a, f |e) = P (3) f,e,a exp( m λm hm (f, a, e)) Given λ, the alignment search problem is to find the alignment a of highest probability according to equation 3. We solve this using the local search defined in (Brown et al., 1993). We set λ as follows. Given a sequence A of alignments we can calculate an error function, E(A). For these experiments average sentence AER was used. We wish to minimize this error function, so we select λ accordingly: argmin λ X a ˜ E(˜ a)δ(˜ a, (argmax pλ (a, f |e))) (4) a Maximizing performance for all of the weights at once is not computationally tractable, but (Och, 2003) has described an efficient one-dimensional search for a similar problem. We search over each λm (holding the others constant) using this technique to find the best λm to update and the best value to update it to. We repeat the process until no further gain can be found. Our new training method is: REPEAT • Start with submodels and lambda from previous iteration 93 • Find Viterbi alignments on entire training corpus using new model (similar to E-step of Model 4 training) • Reestimate submodel parameters from Viterbi alignments (similar to M-step of Model 4 Viterbi training) • Find a setting fo"
W05-0814,P03-1050,0,0.0143884,"r than using likelihood training. Turning off the extensions to GIZA++ and training p0 as in (Brown et al., 1993) produces a substantial increase in AER. 3 Vocabulary Size Reduction Romanian is a Romance language which has a system of suffixes for inflection which is richer than English. Given the small amount of training data, we decided that vocabulary size reduction was desirable. As a baseline for vocabulary reduction, we tried reducing words to prefixes of varying sizes for both English and Romanian after lowercasing the corpora. We also tried Porter stemming (Porter, 1997) for English. (Rogati et al., 2003) extended Model 1 with an additional hidden variable to represent the split points in Arabic between the prefix, the stem and the suffix to generate a stemming for use in Cross-Lingual Information Retrieval. As in (Rogati et al., 2003), we can find the most probable stemming given the model, apply this stemming, and retrain our word alignment system. However, we can also use the modified model directly to find the best word alignment without converting the text to its stemmed form. We introduce a variable rj for the Romanian stem and a variable sj for the Romanian suffix (which when concatenat"
W05-0814,C96-2141,0,0.157821,"y simply lowercasing both the English and Romanian text and removing all but the first four characters of each word. We also tried a new model and a new training criterion based on alternating the maximization of likelihood and minimization of the alignment error rate. For these experiments, we have implemented an alignment package for IBM Model 4 using a hillclimbing search and Viterbi training as described in (Brown et al., 1993), and extended this to use new submodels. The starting point is the final alignment generated using GIZA++’s implementation of IBM Model 1 and the Aachen HMM model (Vogel et al., 1996). Paper organization: Section 2 is on the baseline, Section 3 discusses vocabulary reduction, Section 4 introduces our new model and training method, Section 5 describes experiments, Section 6 concludes. We use the following notation: e refers to an English sentence composed of English words labeled ei . f refers to a Romanian sentence composed of Romanian words labeled fj . a is an alignment of e to f . We use the term “Viterbi alignment” to denote the most probable alignment we can find, rather than the true Viterbi alignment. 2 Baseline To train our systems, Model 4 was trained two times, f"
W09-0420,schmid-etal-2004-smor,0,0.0797319,"of the target language have been studied by Niessen and Ney (2004), Xia and McCord (2004), Dr´abek and Yarowsky (2004), Collins et al. (2005), Popovi´c and Ney (2006), Wang et al. (2007) and many others. To obtain a parse of each German sentence in the training, dev and test corpora, we employed the IfNLP BitPar probabilistic parser (Schmid, 2004), using models learned from the Tiger Treebank for German. Dealing with morphological productivity is important in the syntactic parsing of German. BitPar has been designed with this in mind. IfNLP’s SMOR analyzer is used for morphological analysis (Schmid et al., 2004). SMOR is run over a list of types in each German sentence, and outputs a list of analyses for each type, each of which corresponds to a POS tag. BitPar is limited to choosing one of these POS tags for this type. Words which SMOR fails to analyze are allowed to occur with any POS tag. We reimplemented the syntactic preprocessing approach of Collins et al. (2005), with modifications. Reordering rules are applied to a German parse tree (generated by BitPar), and focus on reordering the words in the German clause structure to more closely resemble English clause structure. The rules are applied t"
W09-0420,W08-0309,0,0.0207953,"e, and we hoped we were performing similar morphological generalization. We expect to be able to improve this system through error analysis. In an initial inspection we found case mismatching problems between step one and step two. guage model trained using SRILM to the binary format using IRSTLM. Experiments are presented in table 1, using BLEU (Papineni et al., 2001) and METEOR5 (Banerjee and Lavie, 2005), and we also show the length ratio (ratio of hypothesized tokens to reference tokens). For translation into English METEOR had superior correlation with human rankings to BLEU at WMT 2008 (Callison-Burch et al., 2008). Our submitted system had a bug where the environment variable LC ALL was set to en US when creating the binarized filtered lexicalized reordering table for the test set (and for the blindtest set, but not for the dev set used for MERT). This caused minor degradation, see the system marked (*) for the system with the bug corrected. Each system increases in both BLEU and METEOR as improvements are added. An exception is that splitting/stemming decreases BLEU somewhat. However, we trust the METEOR results more due to their better correlation with human judgements. We also compared using a diffe"
W09-0420,C04-1024,0,0.105161,"quantized as * RANDLM as * RANDLM 21.2 2.3 Reordering German German word order differs from English substantially. Preprocessing approaches involving the use of a syntactic parse of the source sentence to change the word order to more closely match the word order of the target language have been studied by Niessen and Ney (2004), Xia and McCord (2004), Dr´abek and Yarowsky (2004), Collins et al. (2005), Popovi´c and Ney (2006), Wang et al. (2007) and many others. To obtain a parse of each German sentence in the training, dev and test corpora, we employed the IfNLP BitPar probabilistic parser (Schmid, 2004), using models learned from the Tiger Treebank for German. Dealing with morphological productivity is important in the syntactic parsing of German. BitPar has been designed with this in mind. IfNLP’s SMOR analyzer is used for morphological analysis (Schmid et al., 2004). SMOR is run over a list of types in each German sentence, and outputs a list of analyses for each type, each of which corresponds to a POS tag. BitPar is limited to choosing one of these POS tags for this type. Words which SMOR fails to analyze are allowed to occur with any POS tag. We reimplemented the syntactic preprocessing"
W09-0420,P05-1066,0,0.24615,"Missing"
W09-0420,P04-3014,0,0.0499114,"Missing"
W09-0420,W08-0317,0,0.298486,"ed was that S-RC constituents which do not have a complementizer are reordered incorrectly. We modified the original verb 2nd rule, so that if there is no complementizer in a S-RC constituent, then the head is moved to the second position, see the second part of table 3 for an example. Using the original rules, the verb 2nd rule fails to fire, incorrectly leaving haben (gloss: have) at the end of the clause. 2.4 Morphological Decomposition We implemented the frequency-based word splitting approach of Koehn and Knight (2003), and made modifications, including some similar to those described by Stymne et al. (2008). This well-known technique splits compound words. In addition, we performed simple suffix elimination, aimed at removing inflection marking features such as gender and case that are not necessary for translation to English. We took the stem combination with the highest geometric mean of the frequencies of the stems, but following Stymne et al. (2008), we restricted stems to minimum length 4, and we allowed an extended list of infixes: s, n, en, nen, es, er and ien. For suffixes, we allowed: e, en, n, es, s, em and er, which is more aggressive 2 Note that there is an unrelated reordering error"
W09-0420,P07-1065,0,0.0126959,"the dev set used for MERT). This caused minor degradation, see the system marked (*) for the system with the bug corrected. Each system increases in both BLEU and METEOR as improvements are added. An exception is that splitting/stemming decreases BLEU somewhat. However, we trust the METEOR results more due to their better correlation with human judgements. We also compared using a different language model instead of the SRILM model (the bottom half of table 1). These used either the reduced English language modeling data or the full data (21.2 M segments, marked 21.2 in the results). RANDLM (Talbot and Osborne, 2007) performs well and scaled to the full data with improvement (resulting in our best overall system). IRSTLM (Federico and Cettolo, 2007) also performs well, but the quantized model on the 21.2 data did not improve over the smaller quantized model 6 . IRSTLM uses an approximation of Witten-Bell smoothing, our results support that this is competitive. 4 Conclusion We presented our German to English system which employed character normalization, compensated for problems caused by the German writing reform, used modified syntactic reordering rules (in combination with morphologically aware parsing)"
W09-0420,W07-0712,0,0.0282714,"tem increases in both BLEU and METEOR as improvements are added. An exception is that splitting/stemming decreases BLEU somewhat. However, we trust the METEOR results more due to their better correlation with human judgements. We also compared using a different language model instead of the SRILM model (the bottom half of table 1). These used either the reduced English language modeling data or the full data (21.2 M segments, marked 21.2 in the results). RANDLM (Talbot and Osborne, 2007) performs well and scaled to the full data with improvement (resulting in our best overall system). IRSTLM (Federico and Cettolo, 2007) also performs well, but the quantized model on the 21.2 data did not improve over the smaller quantized model 6 . IRSTLM uses an approximation of Witten-Bell smoothing, our results support that this is competitive. 4 Conclusion We presented our German to English system which employed character normalization, compensated for problems caused by the German writing reform, used modified syntactic reordering rules (in combination with morphologically aware parsing), and employed substring-based morphological analysis. Our best system improves by 2.46 METEOR and 1.12 BLEU over a standard Moses syst"
W09-0420,C96-2141,0,0.0230936,"the procedure to Kirchturm results in Kirche Turm (gloss: church tower)). We store an alignment from the original German to the simplified German which we will use in the next section. 2.5 Morphological Generation For translation from English to German, we first translated from English to the simplified German presented in the previous section, and then performed an independent translation step from simplified German to fully inflected German. Two processes are handled by this step. First, series of stems corresponding to compound words 3 We used 5 iterations of Model 1, 4 iterations of HMM (Vogel et al., 1996) and 4 iterations of Model 4. 4 SRILM failed when trained on the full data, even when a machine with 32 GB RAM and 48 GB swap was used. 117 model on simplified German. The second SMT system translates mixed case simplified German to mixed case unsimplified German. The translation model is built only on the simplified German from the parallel text, and the language model is trained on all German data. We present the results in table 2. METEOR7 did not correlate as well as BLEU for translation out of English in WMT 2008. The BLEU score of our final system is worse than the baseline. We had chose"
W09-0420,W08-0509,0,0.0173787,"ard Moses settings. 3 Experiments 3.1 German to English We trained our German to English system on the constrained parallel data. The English data was processed using character normalization. The German data was first processed using character and word (writing reform) normalization. We then parsed the German data using BitPar and applied the modified reordering rules. After this the splitting and stemming process was applied. Finally, we lowercased the data. Word alignments were generated using Model 4 (Brown et al., 1993) using the multi-threaded implementation of GIZA++ (Och and Ney, 2003; Gao and Vogel, 2008). We first trained Model 4 with English as the source language, and then with German as the source language, resulting in two Viterbi alignments3 . The resulting Viterbi alignments were combined using the Grow Diag Final And symmetrization heuristic (Koehn et al., 2003). We estimated a standard Moses system using default settings. MERT was run until convergence using dev-2009a (separately for each experiment). One limitation of our German to English system is that we were unable to scale to the full language modeling data using SRILM (Stolcke, 2002), 5grams and modified Kneser-Ney with no sing"
W09-0420,E03-1076,0,0.175581,"itive), c+w = char+word normalization, s/s = splitting/stemming The second error that we handled was that S-RC constituents which do not have a complementizer are reordered incorrectly. We modified the original verb 2nd rule, so that if there is no complementizer in a S-RC constituent, then the head is moved to the second position, see the second part of table 3 for an example. Using the original rules, the verb 2nd rule fails to fire, incorrectly leaving haben (gloss: have) at the end of the clause. 2.4 Morphological Decomposition We implemented the frequency-based word splitting approach of Koehn and Knight (2003), and made modifications, including some similar to those described by Stymne et al. (2008). This well-known technique splits compound words. In addition, we performed simple suffix elimination, aimed at removing inflection marking features such as gender and case that are not necessary for translation to English. We took the stem combination with the highest geometric mean of the frequencies of the stems, but following Stymne et al. (2008), we restricted stems to minimum length 4, and we allowed an extended list of infixes: s, n, en, nen, es, er and ien. For suffixes, we allowed: e, en, n, es"
W09-0420,D07-1077,0,0.0167317,"+w, s/s c+w, old reordering c+w, new reordering c+w, new reordering, s/s (submitted, bug) * c+w, new reordering, s/s as * IRSTLM quantized as * IRSTLM as * IRSTLM 21.2 quantized as * RANDLM as * RANDLM 21.2 2.3 Reordering German German word order differs from English substantially. Preprocessing approaches involving the use of a syntactic parse of the source sentence to change the word order to more closely match the word order of the target language have been studied by Niessen and Ney (2004), Xia and McCord (2004), Dr´abek and Yarowsky (2004), Collins et al. (2005), Popovi´c and Ney (2006), Wang et al. (2007) and many others. To obtain a parse of each German sentence in the training, dev and test corpora, we employed the IfNLP BitPar probabilistic parser (Schmid, 2004), using models learned from the Tiger Treebank for German. Dealing with morphological productivity is important in the syntactic parsing of German. BitPar has been designed with this in mind. IfNLP’s SMOR analyzer is used for morphological analysis (Schmid et al., 2004). SMOR is run over a list of types in each German sentence, and outputs a list of analyses for each type, each of which corresponds to a POS tag. BitPar is limited to"
W09-0420,C04-1073,0,0.0288721,"March – 31 March 2009. 2009 Association for Computational Linguistics 115 System no processing c+w c+w, s/s c+w, old reordering c+w, new reordering c+w, new reordering, s/s (submitted, bug) * c+w, new reordering, s/s as * IRSTLM quantized as * IRSTLM as * IRSTLM 21.2 quantized as * RANDLM as * RANDLM 21.2 2.3 Reordering German German word order differs from English substantially. Preprocessing approaches involving the use of a syntactic parse of the source sentence to change the word order to more closely match the word order of the target language have been studied by Niessen and Ney (2004), Xia and McCord (2004), Dr´abek and Yarowsky (2004), Collins et al. (2005), Popovi´c and Ney (2006), Wang et al. (2007) and many others. To obtain a parse of each German sentence in the training, dev and test corpora, we employed the IfNLP BitPar probabilistic parser (Schmid, 2004), using models learned from the Tiger Treebank for German. Dealing with morphological productivity is important in the syntactic parsing of German. BitPar has been designed with this in mind. IfNLP’s SMOR analyzer is used for morphological analysis (Schmid et al., 2004). SMOR is run over a list of types in each German sentence, and output"
W09-0420,N03-1017,0,0.0148918,"ormalization. We then parsed the German data using BitPar and applied the modified reordering rules. After this the splitting and stemming process was applied. Finally, we lowercased the data. Word alignments were generated using Model 4 (Brown et al., 1993) using the multi-threaded implementation of GIZA++ (Och and Ney, 2003; Gao and Vogel, 2008). We first trained Model 4 with English as the source language, and then with German as the source language, resulting in two Viterbi alignments3 . The resulting Viterbi alignments were combined using the Grow Diag Final And symmetrization heuristic (Koehn et al., 2003). We estimated a standard Moses system using default settings. MERT was run until convergence using dev-2009a (separately for each experiment). One limitation of our German to English system is that we were unable to scale to the full language modeling data using SRILM (Stolcke, 2002), 5grams and modified Kneser-Ney with no singleton deletion4 . The language model in our submitted system is based on all of the available English data, but news-train08 is truncated to the first 10193376 lines, meaning that we did not train on the remaining 11038787 lines, so we used a little less than half of th"
W09-0420,P07-2045,0,0.00819143,", respectively, in each chunk. We added the news corpora to the new portion. For each variant we counted the number of times it occurred in the new data and subtracted the number of times it occurred in the old data; the variant with the highest adjusted count was selected. Introduction The Institute for Natural Language Processing (IfNLP), Stuttgart, participated in the WMT-2009 shared tasks for German to English and English to German translation with constrained systems which employed morphological and syntactic processing techniques. The systems were based on the open source Moses docoder (Koehn et al., 2007). We combined IfNLP tools for syntactic and morphological analysis (which are publicly available and widely used) with preprocessing techniques that were successfully used by other groups in WMT-2008, and extended these. For English to German translation, we additionally performed a step which recreated compound words and generated morphological inflection. 1.1 Baseline The baseline is the standard system supplied for the shared task. We used the default parameters of the Moses toolkit, except for a small difference in the generation of the word alignments, see section 3. 2 Improvements 2.1 Ch"
W09-0420,J04-2003,0,0.071311,"9, c Athens, Greece, 30 March – 31 March 2009. 2009 Association for Computational Linguistics 115 System no processing c+w c+w, s/s c+w, old reordering c+w, new reordering c+w, new reordering, s/s (submitted, bug) * c+w, new reordering, s/s as * IRSTLM quantized as * IRSTLM as * IRSTLM 21.2 quantized as * RANDLM as * RANDLM 21.2 2.3 Reordering German German word order differs from English substantially. Preprocessing approaches involving the use of a syntactic parse of the source sentence to change the word order to more closely match the word order of the target language have been studied by Niessen and Ney (2004), Xia and McCord (2004), Dr´abek and Yarowsky (2004), Collins et al. (2005), Popovi´c and Ney (2006), Wang et al. (2007) and many others. To obtain a parse of each German sentence in the training, dev and test corpora, we employed the IfNLP BitPar probabilistic parser (Schmid, 2004), using models learned from the Tiger Treebank for German. Dealing with morphological productivity is important in the syntactic parsing of German. BitPar has been designed with this in mind. IfNLP’s SMOR analyzer is used for morphological analysis (Schmid et al., 2004). SMOR is run over a list of types in each Germ"
W09-0420,J03-1002,0,0.0102552,"otherwise use standard Moses settings. 3 Experiments 3.1 German to English We trained our German to English system on the constrained parallel data. The English data was processed using character normalization. The German data was first processed using character and word (writing reform) normalization. We then parsed the German data using BitPar and applied the modified reordering rules. After this the splitting and stemming process was applied. Finally, we lowercased the data. Word alignments were generated using Model 4 (Brown et al., 1993) using the multi-threaded implementation of GIZA++ (Och and Ney, 2003; Gao and Vogel, 2008). We first trained Model 4 with English as the source language, and then with German as the source language, resulting in two Viterbi alignments3 . The resulting Viterbi alignments were combined using the Grow Diag Final And symmetrization heuristic (Koehn et al., 2003). We estimated a standard Moses system using default settings. MERT was run until convergence using dev-2009a (separately for each experiment). One limitation of our German to English system is that we were unable to scale to the full language modeling data using SRILM (Stolcke, 2002), 5grams and modified K"
W09-0420,2001.mtsummit-papers.68,0,0.0280403,"s worse than the baseline. We had chosen to submit this system as we found it more interesting than submitting a vanilla system. In addition, the system of Stymne et al. (2008) received a good human evaluation despite having a relatively low BLEU score, and we hoped we were performing similar morphological generalization. We expect to be able to improve this system through error analysis. In an initial inspection we found case mismatching problems between step one and step two. guage model trained using SRILM to the binary format using IRSTLM. Experiments are presented in table 1, using BLEU (Papineni et al., 2001) and METEOR5 (Banerjee and Lavie, 2005), and we also show the length ratio (ratio of hypothesized tokens to reference tokens). For translation into English METEOR had superior correlation with human rankings to BLEU at WMT 2008 (Callison-Burch et al., 2008). Our submitted system had a bug where the environment variable LC ALL was set to en US when creating the binarized filtered lexicalized reordering table for the test set (and for the blindtest set, but not for the dev set used for MERT). This caused minor degradation, see the system marked (*) for the system with the bug corrected. Each sys"
W09-0420,popovic-ney-2006-pos,0,0.0454188,"Missing"
W09-0420,J93-2003,0,\N,Missing
W09-0420,P02-1040,0,\N,Missing
W09-0420,W05-0909,0,\N,Missing
W10-1734,N09-1046,0,0.0675605,"ord length, scoring method, filler letters. Popovi´c et al. (2006), compared the approach of Nießen and Ney (2000) with the corpus-driven splitting of Koehn and Knight (2003) in terms of performance on an S MT task. Both systems yield similar results for a large training corpus, while the linguistic-based approach is slightly superior when the amount of training data is drastically reduced. There has recently been a large amount of interest in the use of input lattices in S MT. One use of lattices is to defer disambiguation of word-level phenomena such as inflection and compounds to decoding. Dyer (2009) applied this to German using a lattice encoding different segmentations of German words. The work is evaluated by using the 1-best output of a weak segmenter2 on the training data and then using a lattice of the N-best output of the same segmenter on the test set to decode, which was 0.6 B LEU better than the unsegmented baseline. It would be of interest to test whether deferral of disambiguation to decoding still produces an improvement when used in combination with a high-performance segmenter such as the one we present, an issue we leave for future work. unsplit compound Inflationsraten En"
W10-1734,E03-1076,0,0.221343,"work best for phrase-based statistical machine translation from German to English, a worrisome contradiction. We address this situation by combining linguistic analysis with corpus-driven statistics and obtaining better results in terms of both producing splittings according to a gold standard and statistical machine translation performance. 1 Introduction Compounds are highly productive in German and cause problems of data sparsity in data-driven systems. Compound splitting is an important component of German to English statistical machine translation systems. The central result of work by (Koehn and Knight, 2003) is that corpus-driven approaches to compound splitting perform better than approaches based on linguistic analysis, and this result has since been confirmed by other researchers (Popovi´c et al., 2006; Stymne, 2008). This is despite the fact that linguistic analysis performs better in terms of matching a gold standard splitting. Our work shows that integrating these two approaches, by employing high-recall linguistic analysis disambiguated using corpus statistics, effectively combines the benefits of both approaches. This is important due to the wide usage of the Koehn and Knight approach in"
W10-1734,P07-2045,0,0.00683085,"encoded as one lexeme), while the corpus-driven approach correctly splits it. 5 system raw cd sm sm@nn smc smc@nn test B LEU 15.72 16.17 16.59 16.76 16.63 16.40 test M ETEOR 47.65 49.29 49.98 49.77 50.13 49.64 Table 6: Effects of compound splitting: raw = without preprocessing, cd = corpus-driven, sm = hybrid approach using all S MOR analyses, smc = hybrid approach with minimal S MOR splits *@nn = split only nouns. bold-face = significant wrt. raw underlined = significant wrt. cd Translation Performance 5.1 tuning B LEU 18.10 18.52 19.47 19.42 19.53 19.61 System Description The Moses toolkit (Koehn et al., 2007) was used to construct a baseline P B S MT system (with default parameters), following the instructions of the shared task9 . The baseline system is Moses built exactly as described for the shared task baseline. Contrastive systems are also built identically, except for the use of preprocessing on the German training, tuning and testing data; this ensures that all measured effects on translation quality are attributable to the preprocessing. We used data from the EACL 2009 workshop on statistical machine translation10 . The data include ∼1.2 million parallel sentences for training (E UROPARL a"
W10-1734,C00-2162,0,0.326203,"t that linguistic analysis performs better in terms of matching a gold standard splitting. Our work shows that integrating these two approaches, by employing high-recall linguistic analysis disambiguated using corpus statistics, effectively combines the benefits of both approaches. This is important due to the wide usage of the Koehn and Knight approach in statistical machine translation systems. The splittings we produce are best in terms of both end-to-end machine translation performance 2 Related Work on German Compound Splitting Rule-based compound splitting for S MT has been addressed by Nießen and Ney (2000), where G ERTWOL was used for morphological analysis and the G ERCG parser for lexical analysis and disambiguation. Their results showed that morphosyntactic analysis could reduce the subjective sentence error rate. The empirical approach of Koehn and Knight (2003) splits German compounds into words found in a training corpus. A minimal amount of linguistic knowledge is included in that the filler letters “s” and “es” are allowed to be introduced between any two words while “n” might be 1 See Table 6 in section 5 for details. 224 Proceedings of the Joint 5th Workshop on Statistical Machine Tra"
W10-1734,P03-1021,0,0.0306281,"(E UROPARL and news), 1,025 sentences for tuning and 1,026 sentences for testing. All data was lowercased and tokenized, using the shared task tokenizer. We used the English side of the parallel data for the language model. As specified in the instructions, sentences longer than 40 words were removed from the bilingual training corpus, but not from the language model corpus. The monolingual language model training data (containing roughly 227 million words11 ) was used to derive corpus frequencies for the splitting approaches. For tuning of feature weights we ran Minimum Error Rate Training (Och, 2003) until convergence, individually for each system (optimizing B LEU). The experiments were evaluated using B LEU (Papineni et al., 2002) and M ETEOR (Lavie and Agarwal, 2007)12 . Tuning scores are calculated on lowercased, tokenized text; all test scores are case sensitive and performed on automatically recapitalized, detokenized text. 5.2 Translation Results The B LEU and M ETEOR scores of our experiments are summarized in Table 6. Results that are significantly better than the baseline are boldfaced13 . Underlining indicates that a result is significantly better than corpus-driven. Compared t"
W10-1734,P02-1040,0,0.0957062,"sing the shared task tokenizer. We used the English side of the parallel data for the language model. As specified in the instructions, sentences longer than 40 words were removed from the bilingual training corpus, but not from the language model corpus. The monolingual language model training data (containing roughly 227 million words11 ) was used to derive corpus frequencies for the splitting approaches. For tuning of feature weights we ran Minimum Error Rate Training (Och, 2003) until convergence, individually for each system (optimizing B LEU). The experiments were evaluated using B LEU (Papineni et al., 2002) and M ETEOR (Lavie and Agarwal, 2007)12 . Tuning scores are calculated on lowercased, tokenized text; all test scores are case sensitive and performed on automatically recapitalized, detokenized text. 5.2 Translation Results The B LEU and M ETEOR scores of our experiments are summarized in Table 6. Results that are significantly better than the baseline are boldfaced13 . Underlining indicates that a result is significantly better than corpus-driven. Compared to not-splitting (raw), the corpusdriven approach (cd) gains 0.45 B LEU points and +1.64 in M ETEOR for testing. All variants of the hyb"
W10-1734,schmid-etal-2004-smor,0,0.58599,"ranslation inflation rates split compound Inflation Raten 1−to−n alignment 1−to−1 alignment Figure 1: Compound splitting enhances the number of 1-to-1 word alignments. amounts of data and scoring metrics. We briefly introduce the computational morphology S MOR (section 3.1) and the corpusdriven approach of Koehn and Knight (2003) (section 3.2), before we present our hybrid approach that combines the benefits of both in section 3.3. 3.1 S MOR is a finite-state based morphological analyzer covering the productive word formation processes of German, namely inflection, derivation and compounding (Schmid et al., 2004). Word formation is implemented as a concatenation of morphemes filtered according to selectional restrictions. These restrictions are based on feature decorations of stems and affixes encoded in the lexicon. Inflection is realized using inflection classes. An abbreviated3 S MOR analysis of the word Durchschnittsauto (“standard car”)4 is given in Figure 2 (a). The hierarchical structure of the word formation process is given in Figure 2 (b). Implemented with finite-state technology, S MOR is not able to produce this hierarchy: in our example it outputs two (correct) analyses of different depth"
W10-1734,2007.mtsummit-papers.65,0,0.0243793,"Missing"
W10-1734,W07-0734,0,\N,Missing
W13-2213,D11-1033,0,0.0919379,"Missing"
W13-2213,P05-1066,0,0.0443099,"a are also automatically tagged and phrases with words and POS tags on both sides are extracted. The POSbased OSM model is only used in the German-toEnglish and English-to-German experiments.4 So far, we only used coarse POS tags without gender and case information. 4 Constituent Parse Reordering Our German-to-English system used constituent parses for pre-ordering of the input. We parsed all of the parallel German to English data available, and the tuning, test and blind-test sets. We then applied reordering rules to these parses. We used the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data (training, tuning and test data). To produce the parses, we started with the generative BitPar parser trained on the Tiger treebank with optimizations of the grammar, as described by (Fraser et al., 2013). We then performed self-training using the high quality Europarl corpus - we parsed it, and then retrained the parser on the output. Decoder The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004). The decoder uses beam search to build up t"
W13-2213,P11-1105,1,0.934423,"rd Farkas4 1 2 University of Edinburgh – dnadir@inf.ed.ac.uk Ludwig Maximilian University Munich – schmid,fraser@cis.uni-muenchen.de 3 Qatar Computing Research Institute – hsajjad@qf.org.qa 4 University of Szeged – rfarkas@inf.u-szeged.hu Abstract reordering operations and learns a Markov model over a sequence of operations. Our decoder uses the beam search algorithm in a stack-based decoder like most sequence-based SMT frameworks. Although the model is based on minimal translation units, we use phrases during search because they improve the search accuracy of our system. The earlier decoder (Durrani et al., 2011) was based on minimal units. But we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors (Durrani et al., 2013a) than MTU-based decoding. We have therefore shifted to phrase-based search on top of the OSM model. This paper is organized as follows. Section 2 gives a short description of the model and search as used in the OSM decoder. In Section 3 we give a description of the POS-based operation sequence model that we test for our German-English and English-German experiments. Section 4 describes our proces"
W13-2213,N13-1001,1,0.917412,"ty of Szeged – rfarkas@inf.u-szeged.hu Abstract reordering operations and learns a Markov model over a sequence of operations. Our decoder uses the beam search algorithm in a stack-based decoder like most sequence-based SMT frameworks. Although the model is based on minimal translation units, we use phrases during search because they improve the search accuracy of our system. The earlier decoder (Durrani et al., 2011) was based on minimal units. But we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors (Durrani et al., 2013a) than MTU-based decoding. We have therefore shifted to phrase-based search on top of the OSM model. This paper is organized as follows. Section 2 gives a short description of the model and search as used in the OSM decoder. In Section 3 we give a description of the POS-based operation sequence model that we test for our German-English and English-German experiments. Section 4 describes our processing of the German and English data for German-English and English-German experiments. In Section 5 we describe the unsupervised transliteration mining that has been done for the Russian-English and"
W13-2213,P13-2071,1,0.919884,"ty of Szeged – rfarkas@inf.u-szeged.hu Abstract reordering operations and learns a Markov model over a sequence of operations. Our decoder uses the beam search algorithm in a stack-based decoder like most sequence-based SMT frameworks. Although the model is based on minimal translation units, we use phrases during search because they improve the search accuracy of our system. The earlier decoder (Durrani et al., 2011) was based on minimal units. But we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors (Durrani et al., 2013a) than MTU-based decoding. We have therefore shifted to phrase-based search on top of the OSM model. This paper is organized as follows. Section 2 gives a short description of the model and search as used in the OSM decoder. In Section 3 we give a description of the POS-based operation sequence model that we test for our German-English and English-German experiments. Section 4 describes our processing of the German and English data for German-English and English-German experiments. In Section 5 we describe the unsupervised transliteration mining that has been done for the Russian-English and"
W13-2213,W13-2212,1,0.928384,"ty of Szeged – rfarkas@inf.u-szeged.hu Abstract reordering operations and learns a Markov model over a sequence of operations. Our decoder uses the beam search algorithm in a stack-based decoder like most sequence-based SMT frameworks. Although the model is based on minimal translation units, we use phrases during search because they improve the search accuracy of our system. The earlier decoder (Durrani et al., 2011) was based on minimal units. But we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors (Durrani et al., 2013a) than MTU-based decoding. We have therefore shifted to phrase-based search on top of the OSM model. This paper is organized as follows. Section 2 gives a short description of the model and search as used in the OSM decoder. In Section 3 we give a description of the POS-based operation sequence model that we test for our German-English and English-German experiments. Section 4 describes our processing of the German and English data for German-English and English-German experiments. In Section 5 we describe the unsupervised transliteration mining that has been done for the Russian-English and"
W13-2213,J13-1005,1,0.871716,"Missing"
W13-2213,W09-0420,1,0.89655,"both sides are extracted. The POSbased OSM model is only used in the German-toEnglish and English-to-German experiments.4 So far, we only used coarse POS tags without gender and case information. 4 Constituent Parse Reordering Our German-to-English system used constituent parses for pre-ordering of the input. We parsed all of the parallel German to English data available, and the tuning, test and blind-test sets. We then applied reordering rules to these parses. We used the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data (training, tuning and test data). To produce the parses, we started with the generative BitPar parser trained on the Tiger treebank with optimizations of the grammar, as described by (Fraser et al., 2013). We then performed self-training using the high quality Europarl corpus - we parsed it, and then retrained the parser on the output. Decoder The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004). The decoder uses beam search to build up the translation from left to right. The hypotheses are arranged"
W13-2213,W10-1734,1,0.864372,"Missing"
W13-2213,schmid-etal-2004-smor,1,0.739052,"Missing"
W13-2213,W11-2123,0,0.045987,"source-side cepts and source-word deletion. However, it doesn’t provide a mechanism to deal with unaligned and discontinuous target cepts. These are handled through a 3-step process3 in which we modify the alignments to remove discontinuous and unaligned target MTUs. Please see Durrani et al. (2011) for details. After modifying the alignments, we convert each bilingual sentence pair and its alignments into a sequence of operations as described above and learn an OSM model. To this end, a Kneser-Ney (Kneser and Ney, 1995) smoothed 9-gram model is trained with SRILM (Stolcke, 2002) while KenLM (Heafield, 2011) is used at runtime. Figure 1: Bilingual Sentence with Alignments sentence pair and its alignments as a unique sequence of operations. An operation either jointly generates source and target words, or it performs reordering by inserting gaps or jumping to gaps. We then learn a Markov model over a sequence of operations o1 , o2 , . . . , oJ that encapsulate MTUs and reordering information as: posm (o1 , ..., oJ ) = J Y j=1 p(oj |oj−n+1 , ..., oj−1 ) 2.3 We use additional features for our model and employ the standard log-linear approach (Och and Ney, 2004) to combine and tune them. We search fo"
W13-2213,I08-2089,0,0.179256,"estimation of the translation models is: de–en ≈ 4.5M and ru–en ≈ 2M parallel sentences. We were able to use all the available data for cs-to-en (≈ 15.6M sentences). However, sub-sampled data was used for en-to-cs (≈ 3M sentences), en-to-fr (≈ 7.8M sentences) and es–en (≈ 3M sentences). Monolingual Language Model: We used all the available training data (including LDC Gigaword data) for the estimation of monolingual language models: en ≈ 287.3M sentences, fr ≈ 91M, es ≈ 65.7M, cs ≈ 43.4M and ru ≈ 21.7M sentences. All data except for ru-en and en-ru was true-cased. We followed the approach of Schwenk and Koehn (2008) by training language models from each sub-corpus separately and then linearly interpolated them using SRILM with weights optimized on the held-out dev-set. We concatenated the news-test sets from four years (2008-2011) to obtain a large dev-set5 in order to obtain more stable weights (Koehn and Haddow, 2012). Decoder Settings: For each extracted input phrase only 15-best translation options were used during decoding.6 We used a hard reordering limit 5 For Russian-English and English-Russian language pairs, we divided the tuning-set news-test 2012 into two halves and used the first half for tu"
W13-2213,W13-2230,1,0.864769,"Missing"
W13-2213,W12-3139,0,0.0378184,"odel: We used all the available training data (including LDC Gigaword data) for the estimation of monolingual language models: en ≈ 287.3M sentences, fr ≈ 91M, es ≈ 65.7M, cs ≈ 43.4M and ru ≈ 21.7M sentences. All data except for ru-en and en-ru was true-cased. We followed the approach of Schwenk and Koehn (2008) by training language models from each sub-corpus separately and then linearly interpolated them using SRILM with weights optimized on the held-out dev-set. We concatenated the news-test sets from four years (2008-2011) to obtain a large dev-set5 in order to obtain more stable weights (Koehn and Haddow, 2012). Decoder Settings: For each extracted input phrase only 15-best translation options were used during decoding.6 We used a hard reordering limit 5 For Russian-English and English-Russian language pairs, we divided the tuning-set news-test 2012 into two halves and used the first half for tuning and second for test. 6 We could not experiment with higher n-best translation options due to a bug that was not fixed in time and hindered us from scaling. Sub-sampling Because of scalability problems we were not able to use the entire data made available for build125 of 16 words which disallows a jump b"
W13-2213,E03-1076,0,0.439555,"Missing"
W13-2213,koen-2004-pharaoh,0,0.0671416,"ering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data (training, tuning and test data). To produce the parses, we started with the generative BitPar parser trained on the Tiger treebank with optimizations of the grammar, as described by (Fraser et al., 2013). We then performed self-training using the high quality Europarl corpus - we parsed it, and then retrained the parser on the output. Decoder The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004). The decoder uses beam search to build up the translation from left to right. The hypotheses are arranged in m stacks such that stack i maintains hypotheses that have already translated i many foreign words. The ultimate goal is to find the best scoring hypothesis, that translates all the words in the foreign sentence. During the hypothesis extension each extracted phrase is translated into a sequence of operations. The reordering opera4 This work is ongoing and we will present detailed experiments in the future. 124 ing the translation model in some cases. We used modified Moore-Lewis sampli"
W13-2213,J06-4004,0,0.0984652,"Missing"
W13-2213,J04-4002,0,0.0848361,"d with SRILM (Stolcke, 2002) while KenLM (Heafield, 2011) is used at runtime. Figure 1: Bilingual Sentence with Alignments sentence pair and its alignments as a unique sequence of operations. An operation either jointly generates source and target words, or it performs reordering by inserting gaps or jumping to gaps. We then learn a Markov model over a sequence of operations o1 , o2 , . . . , oJ that encapsulate MTUs and reordering information as: posm (o1 , ..., oJ ) = J Y j=1 p(oj |oj−n+1 , ..., oj−1 ) 2.3 We use additional features for our model and employ the standard log-linear approach (Och and Ney, 2004) to combine and tune them. We search for a target string E which maximizes a linear combination of feature functions: By coupling reordering with lexical generation, each (translation or reordering) decision depends on n − 1 previous (translation and reordering) decisions spanning across phrasal boundaries. The reordering decisions therefore influence lexical selection and vice versa. A heterogeneous mixture of translation and reordering operations enables us to memorize reordering patterns and lexicalized triggers unlike the classic N-gram model where translation and reordering are modeled se"
W13-2213,P11-1044,1,0.696753,"ing. We do not have such a list and making one is a cumbersome process. Instead, we use the unsupervised transliteration mining system of Sajjad et al. (2012) that takes a list of word pairs for training and extracts transliteration pairs that can be used for the training of the transliteration system. The procedure of mining transliteration pairs and transliterating OOVs is described as follows: We word-align the parallel corpus using GIZA++ in both direction and symmetrize the alignments using the grow-diag-final-and heuristic. We extract all word pairs which occur as 1to-1 alignments (like Sajjad et al. (2011)) and later refer to them as the list of word pairs. We train the unsupervised transliteration mining system on the list of word pairs and extract transliteration pairs. We use these mined pairs to build a transliteration system using the Moses toolkit. The transliteration system is applied in a post-processing step to transliterate OOVs. Please refer to Sajjad et al. (2013) for further details on our transliteration work. 6 7 Experiments Parallel Corpus: The amount of bitext used for the estimation of the translation models is: de–en ≈ 4.5M and ru–en ≈ 2M parallel sentences. We were able to u"
W13-2213,P12-1049,1,0.737125,"on system fails to translate out-of-vocabulary words (OOVs) as they are unknown to the training data. Most of the OOVs are named entities and simply passing them to the output often produces correct translations if source and target language use the same script. If the scripts are different transliterating them to the target language script could solve this problem. However, building a transliteration system requires a list of transliteration pairs for training. We do not have such a list and making one is a cumbersome process. Instead, we use the unsupervised transliteration mining system of Sajjad et al. (2012) that takes a list of word pairs for training and extracts transliteration pairs that can be used for the training of the transliteration system. The procedure of mining transliteration pairs and transliterating OOVs is described as follows: We word-align the parallel corpus using GIZA++ in both direction and symmetrize the alignments using the grow-diag-final-and heuristic. We extract all word pairs which occur as 1to-1 alignments (like Sajjad et al. (2011)) and later refer to them as the list of word pairs. We train the unsupervised transliteration mining system on the list of word pairs and"
W13-2213,D11-1017,0,\N,Missing
W13-2213,E12-1074,1,\N,Missing
W13-2213,C04-1024,1,\N,Missing
W13-2213,W13-2228,1,\N,Missing
W13-2228,C12-1121,0,0.0548234,"Missing"
W13-2228,J03-1002,0,0.0274782,"n of PRO that optimizes BLEU+1 at corpus level. Section 5 and Section 6 present English/Russian and Russian/English machine translation experiments respectively. Section 7 concludes. Introduction We describe the QCRI-Munich-EdinburghStuttgart (QCRI-MES) English to Russian and Russian to English systems submitted to the Eighth Workshop on Statistical Machine Translation. We experimented using the standard Phrase-based Statistical Machine Translation System (PSMT) as implemented in the Moses toolkit (Koehn et al., 2007). The typical pipeline for translation involves word alignment using GIZA++ (Och and Ney, 2003), phrase extraction, tuning and phrase-based decoding. Our system is different from standard PSMT in three ways: • We integrate an unsupervised transliteration mining system (Sajjad et al., 2012) into the GIZA++ word aligner (Sajjad et al., 2011). 219 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 219–224, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 2 Transliteration Mining 2.1.1 Estimating Transliteration Probabilities We use the algorithm for the estimation of transliteration probabilities of Sajjad et al. (2011). We modify"
W13-2228,P03-1021,0,0.0050144,"as a list of word pairs. The unsupervised transliteration mining system trains on the list of word pairs and mines transliteration pairs. We use the mined pairs to build a transliteration system using the Moses toolkit. The transliteration system is used in Algorithm 1 to generate transliteration probabilities of candidate word pairs and is also used in the postprocessing step to transliterate OOVs. We run GIZA++ with identical settings as described in Section 5.2. We interpolate for evPRO: Corpus-level BLEU Pairwise Ranking Optimization (PRO) (Hopkins and May, 2011) is an extension of MERT (Och, 2003) that can scale to thousands of parameters. It optimizes sentence-level BLEU+1 which is an add-one smoothed version of BLEU (Lin and Och, 2004). The sentence-level BLEU+1 has a bias towards producing short translations as add-one smoothing improves precision but does not change the brevity penalty. Nakov et al. (2012) fixed this by using several heuristics on brevity penalty, reference length and grounding the precision length. In our experiments, we use the improved version of PRO as provided by Nakov et al. (2012). We 221 MERT MIRA PRO PROv1 GIZA++ TA-GIZA++ OOV-TI 23.41 23.60 23.57 23.65 23"
W13-2228,P11-1044,1,0.923855,"QCRI-MES) English to Russian and Russian to English systems submitted to the Eighth Workshop on Statistical Machine Translation. We experimented using the standard Phrase-based Statistical Machine Translation System (PSMT) as implemented in the Moses toolkit (Koehn et al., 2007). The typical pipeline for translation involves word alignment using GIZA++ (Och and Ney, 2003), phrase extraction, tuning and phrase-based decoding. Our system is different from standard PSMT in three ways: • We integrate an unsupervised transliteration mining system (Sajjad et al., 2012) into the GIZA++ word aligner (Sajjad et al., 2011). 219 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 219–224, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 2 Transliteration Mining 2.1.1 Estimating Transliteration Probabilities We use the algorithm for the estimation of transliteration probabilities of Sajjad et al. (2011). We modify it to improve efficiency. In step 6 of Algorithm 1 instead of taking all f that coocur with e, we take only those that have a word length ratio in range of 0.8-1.2.1 This reduces cooc(e) by more than half and speeds up step 9 of Algorithm 1. The"
W13-2228,J93-2003,0,0.0261744,"Missing"
W13-2228,P11-1105,1,0.819552,"tion system on that. We compare its result with the Russian to English system trained on the un-processed parallel data. 6.1.2 Morphological Reduction English in comparison to Slavic group of languages is morphologically poor. For example, English has no morphological attributes for nouns and adjectives to express gender or case; verbs in English have no gender either. Russian, on the contrary, has rich morphology. It suffices to say that the Russian has 6 cases and 3 grammatical genders, which manifest themselves in different 2 We see similar gain in BLEU when using operation sequence model (Durrani et al., 2011) for decoding and transliterating OOVs in a post-processing step (Durrani et al., 2013). 222 Original corpus suffixes for nouns, pronouns, adjectives and some verb forms. When translating from Russian into English, a lot of these attributes become meaningless and excessive. It makes sense to reduce the number of morphological attributes before the text is supplied for the training of the MT system. We apply morphological reduction to nouns, pronouns, verbs, adjectives, prepositions and conjunctions. The rest of the POS (adverbs, particles, interjections and abbreviations) have no morphological"
W13-2228,P12-1049,1,0.919427,"on We describe the QCRI-Munich-EdinburghStuttgart (QCRI-MES) English to Russian and Russian to English systems submitted to the Eighth Workshop on Statistical Machine Translation. We experimented using the standard Phrase-based Statistical Machine Translation System (PSMT) as implemented in the Moses toolkit (Koehn et al., 2007). The typical pipeline for translation involves word alignment using GIZA++ (Och and Ney, 2003), phrase extraction, tuning and phrase-based decoding. Our system is different from standard PSMT in three ways: • We integrate an unsupervised transliteration mining system (Sajjad et al., 2012) into the GIZA++ word aligner (Sajjad et al., 2011). 219 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 219–224, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 2 Transliteration Mining 2.1.1 Estimating Transliteration Probabilities We use the algorithm for the estimation of transliteration probabilities of Sajjad et al. (2011). We modify it to improve efficiency. In step 6 of Algorithm 1 instead of taking all f that coocur with e, we take only those that have a word length ratio in range of 0.8-1.2.1 This reduces cooc(e) by more"
W13-2228,C08-1098,1,0.691413,"f English to Russian machine translation system evaluated on tst2012 and tst2013 using baseline GIZA++ alignment and transliteration augmented-GIZA++ alignment and post-processed the output by transliterating OOVs. Human evaluation in WMT13 is performed on TA-GIZA++ tested on tst2013 (marked with *) Table 1: BLEU scores of English to Russian machine translation system evaluated on tst2012 using baseline GIZA++ alignment and transliteration augmented-GIZA++. OOV-TI presents the score of the system trained using TA-GIZA++ after transliterating OOVs 5.4 tst2012 6.1.1 POS Tagging We use RFTagger (Schmid and Laws, 2008) for POS tagging. Despite the good quality of tagging provided by RFTagger, some errors seem to be unavoidable due to the ambiguity of certain grammatical forms in Russian. A good example of this is neuter nouns that have the same form in all cases, or feminine nouns, which have identical forms in singular genitive and plural nominative (Sharoff et al., 2008). Since Russian sentences have free word order, and the case of nouns cannot be determined on that basis, this imperfection can not be corrected during tagging or by postprocessing the tagger output. Russian/English Experiments In this sec"
W13-2228,W13-2213,1,0.727212,"n the un-processed parallel data. 6.1.2 Morphological Reduction English in comparison to Slavic group of languages is morphologically poor. For example, English has no morphological attributes for nouns and adjectives to express gender or case; verbs in English have no gender either. Russian, on the contrary, has rich morphology. It suffices to say that the Russian has 6 cases and 3 grammatical genders, which manifest themselves in different 2 We see similar gain in BLEU when using operation sequence model (Durrani et al., 2011) for decoding and transliterating OOVs in a post-processing step (Durrani et al., 2013). 222 Original corpus suffixes for nouns, pronouns, adjectives and some verb forms. When translating from Russian into English, a lot of these attributes become meaningless and excessive. It makes sense to reduce the number of morphological attributes before the text is supplied for the training of the MT system. We apply morphological reduction to nouns, pronouns, verbs, adjectives, prepositions and conjunctions. The rest of the POS (adverbs, particles, interjections and abbreviations) have no morphological attributes and are left unchanged. We apply morphological reduction to train, tune, de"
W13-2228,D11-1125,0,0.0171179,"ke Sajjad et al. (2011)) and later refer to them as a list of word pairs. The unsupervised transliteration mining system trains on the list of word pairs and mines transliteration pairs. We use the mined pairs to build a transliteration system using the Moses toolkit. The transliteration system is used in Algorithm 1 to generate transliteration probabilities of candidate word pairs and is also used in the postprocessing step to transliterate OOVs. We run GIZA++ with identical settings as described in Section 5.2. We interpolate for evPRO: Corpus-level BLEU Pairwise Ranking Optimization (PRO) (Hopkins and May, 2011) is an extension of MERT (Och, 2003) that can scale to thousands of parameters. It optimizes sentence-level BLEU+1 which is an add-one smoothed version of BLEU (Lin and Och, 2004). The sentence-level BLEU+1 has a bias towards producing short translations as add-one smoothing improves precision but does not change the brevity penalty. Nakov et al. (2012) fixed this by using several heuristics on brevity penalty, reference length and grounding the precision length. In our experiments, we use the improved version of PRO as provided by Nakov et al. (2012). We 221 MERT MIRA PRO PROv1 GIZA++ TA-GIZA"
W13-2228,I08-2089,0,0.333709,"s are less likely to be transliterations. 220 very sensitive to the value of λ. We use λ = 50 for our experiments. The procedure we described of estimation of transliteration probabilities and modification of EM is also followed in the opposite direction f-to-e. 3 call it PROv1 later on. 5 5.1 Dataset The amount of bitext used for the estimation of the translation model is ≈ 2M parallel sentences. We use newstest2012a for tuning and newstest2012b (tst2012) as development set. The language model is estimated using large monolingual corpus of Russian ≈ 21.7M sentences. We follow the approach of Schwenk and Koehn (2008) by training domain-specific language models separately and then linearly interpolate them using SRILM with weights optimized on the held-out development set. We divide the tuning set newstest2012a into two halves and use the first half for tuning and second for test in order to obtain stable weights (Koehn and Haddow, 2012). Transliteration System The unsupervised transliteration mining system (as described in Section 2) outputs a list of transliteration pairs. We consider transliteration word pairs as parallel sentences by putting a space after every character of the words and train a PSMT s"
W13-2228,W12-3139,0,0.0320278,"d for the estimation of the translation model is ≈ 2M parallel sentences. We use newstest2012a for tuning and newstest2012b (tst2012) as development set. The language model is estimated using large monolingual corpus of Russian ≈ 21.7M sentences. We follow the approach of Schwenk and Koehn (2008) by training domain-specific language models separately and then linearly interpolate them using SRILM with weights optimized on the held-out development set. We divide the tuning set newstest2012a into two halves and use the first half for tuning and second for test in order to obtain stable weights (Koehn and Haddow, 2012). Transliteration System The unsupervised transliteration mining system (as described in Section 2) outputs a list of transliteration pairs. We consider transliteration word pairs as parallel sentences by putting a space after every character of the words and train a PSMT system for transliteration. We apply the transliteration system to OOVs in a post-processing step on the output of the machine translation system. Russian is a morphologically rich language. Different cases of a word are generally represented by adding suffixes to the root form. For OOVs that are named entities, transliterati"
W13-2228,sharoff-etal-2008-designing,0,0.0184257,"n system evaluated on tst2012 using baseline GIZA++ alignment and transliteration augmented-GIZA++. OOV-TI presents the score of the system trained using TA-GIZA++ after transliterating OOVs 5.4 tst2012 6.1.1 POS Tagging We use RFTagger (Schmid and Laws, 2008) for POS tagging. Despite the good quality of tagging provided by RFTagger, some errors seem to be unavoidable due to the ambiguity of certain grammatical forms in Russian. A good example of this is neuter nouns that have the same form in all cases, or feminine nouns, which have identical forms in singular genitive and plural nominative (Sharoff et al., 2008). Since Russian sentences have free word order, and the case of nouns cannot be determined on that basis, this imperfection can not be corrected during tagging or by postprocessing the tagger output. Russian/English Experiments In this section, we present translation experiments in Russian to English direction. We morphologically reduce the Russian side of the parallel data in a pre-processing step and train the translation system on that. We compare its result with the Russian to English system trained on the un-processed parallel data. 6.1.2 Morphological Reduction English in comparison to S"
W13-2228,N03-1017,0,0.00764806,", , , , ) and transliterate the stemmed form. For morphologically reduced Russian (see Section 6.1), we follow the same procedure as OOVs are unknown to the POS tagger too and are (incorrectly) not reduced to their root forms. For OOVs that are not identified as named entities, we transliterate them without any pre-processing. 4 English/Russian Experiments 5.2 Baseline Settings We word-aligned the parallel corpus using GIZA++ (Och and Ney, 2003) with 5 iterations of Model1, 4 iterations of HMM and 4 iterations of Model4, and symmetrized the alignments using the grow-diag-final-and heuristic (Koehn et al., 2003). We built a phrase-based machine translation system using the Moses toolkit. Minimum error rate training (MERT), margin infused relaxed algorithm (MIRA) and PRO are used to optimize the parameters. 5.3 Main System Settings Our main system involves a pre-processing step – unsupervised transliteration mining, and a postprocessing step – transliteration of OOVs. For the training of the unsupervised transliteration mining system, we take the word alignments from our baseline settings and extract all word pairs which occur as 1-to-1 alignments (like Sajjad et al. (2011)) and later refer to them as"
W13-2228,C96-2141,0,0.0435274,"word alignment models. They combined the translation probabilities of the IBM models and the HMM model with the transliteration probabilities. Consider pta (f |e) = fta (f, e)/fta (e) is the translation probability of the word alignment models. The interpolated probability is calculated by adding the smoothed alignment frequency fta (f, e) to the transliteration probability weight by the factor λ. The modified translation probabilities is given by: Transliteration Augmented-GIZA++ GIZA++ aligns parallel sentences at word level. It applies the IBM models (Brown et al., 1993) and the HMM model (Vogel et al., 1996) in both directions i.e. source to target and target to source. It generates a list of translation pairs with translation probabilities, which is called the t-table. Sajjad et al. (2011) used a heuristic-based transliteration mining system and integrated it into the GIZA++ word aligner. We follow a similar procedure but use the unsupervised transliteration mining system of Sajjad et al. (2012). pˆ(f |e) = We define a transliteration sub-model and train it on the transliteration pairs mined by the unsupervised transliteration mining system. We integrate it into the GIZA++ word aligner. The prob"
W13-2228,W13-2230,1,0.735961,"ng The linguistic processing of Russian involves POS tagging and morphological reduction. We first tag the Russian data using a fine grained tagset. The tagger identifies lemmas and the set of morphological attributes attached to each word. We reduce the number of these attributes by deleting some of them, that are not relevant for English (for example, gender agreement of verbs). This generates a morphologically reduced Russian which is used in parallel with English for the training of the machine translation system. Further details on the morphological processing of Russian are described in Weller et al. (2013). Results Table 1 summarizes English/Russian results on tst2012. Improved word alignment gives up to 0.13 BLEU points improvement. PROv1 improves translation quality and shows 0.08 BLEU point increase in BLEU in comparison to the parameters tuned using PRO. The transliteration of OOVs consistently improve translation quality by at least 0.1 BLEU point for all systems.2 This adds to a cumulative gain of up to 0.2 BLEU points. We summarize results of our systems trained on GIZA++ and transliteration augmented-GIZA++ (TA-GIZA++) and tested on tst2012 and tst2013 in Table 2. Both systems use PROv1"
W13-2228,P07-2045,0,\N,Missing
W13-2228,C04-1072,0,\N,Missing
W13-2230,W10-1749,0,0.0262519,"highest usefulness scores for the reordering task. Then we trained a new grammar on the concatenation of the Tiger corpus and the automatic parses from Europarl. The usefulness score estimates the value of a parse tree for the reordering task. We calculated this score as the similarity between the word order achieved by applying the parse tree-based reordering rules of Fraser (2009) and the word order indicated by the automatic word alignment between the German and English sentences in Europarl. We used the Kendall’s Tau Distance as the similarity metric of two word orderings (as suggested by Birch and Osborne (2010)). Following this, we performed linguisticallyinformed compound splitting, using the system of Fritzinger and Fraser (2010), which disambiguates competing analyses from the high-recall Stuttgart Morphological Analyzer SMOR (Schmid et al., 2004) using corpus statistics. We also split German portmanteaus like zum → zu dem (meaning to the). DE-EN (OSM) DE-EN (OSM) BitPar not self-trained DE-EN (Moses) DE-EN (Moses) BitPar not self-trained EN-DE (Moses) BLEU (ci) 27.60 27.48 BLEU (cs) 26.12 25.99 system name 27.14 25.65 26.82 25.36 MES-Szegedreorder-split not submitted 19.68 18.97 MES-reorder MES"
W13-2230,P12-1050,0,0.0143602,"tuent parses for pre-reordering. For DE-EN we also deal with word formation issues such as compound splitting. We did not perform inflectional normalization or generation for German due to time constraints, instead focusing 236 system our efforts on these issues for French and Russian as previously described. German to English German has a wider diversity of clausal orderings than English, all of which need to be mapped to the English SVO order. This is a difficult problem to solve during inference, as shown for hierarchical SMT by Fabienne Braune and Fraser (2012) and for phrase-based SMT by Bisazza and Federico (2012). We syntactically parsed all of the source side sentences of the parallel German to English data available, and the tuning, test and blindtest sets. We then applied reordering rules to these parses. We use the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data. For parsing the German sentences, we used the generative phrase-structure parser BitPar with optimizations of the grammar, as described by Fraser et al. (2013). The parser was trained on the Tiger Tre"
W13-2230,P05-1022,0,0.0609343,".36 MES-Szegedreorder-split not submitted 19.68 18.97 MES-reorder MES not submitted Table 8: Results on WMT-2013 (blindtest) English to German The task of mapping English SVO order to the different clausal orders in German is difficult. For our English to German systems, we solved this by parsing the English and applying the system of Gojun and Fraser (2012) to reorder English into the correct German clausal order (depending on the clause type which is detected using the English parse, see (Gojun and Fraser, 2012) for further details). We primarily used the Charniak-Johnson generative parser (Charniak and Johnson, 2005) to parse the English Europarl data and the test data. However, due to time constraints we additionally used Berkeley parses of about 400K Europarl sentences and the other English parallel training data. We also left a small amount of the English parallel training data unparsed, which means that it was not reordered. For tune, test and blindtest (WMT2013), we used the Charniak-Johnson generative parser. Experiments and results We used all available training data for constrained systems; results for the WMT-2013 set are given in table 8. For the contrastive BitPar results, we reparsed WMT-2013."
W13-2230,N12-1047,0,0.0466778,"Moses system (DE-EN, EN-DE, EN-FR and FR-EN) or with an operation sequence model (RU-EN, DEEN), cf. Durrani et al. (2013b) for more details. An operation sequence model (OSM) is a stateof-the-art SMT-system that learns translation and reordering patterns by representing a sentence pair and its word alignment as a unique sequence of operations (see e.g. Durrani et al. (2011), Durrani et al. (2013a) for more details). For the Moses systems we used the old train-model perl scripts rather than the EMS, so we did not perform Good-Turing smoothing; parameter tuning was carried out with batch-mira (Cherry and Foster, 2012). 232 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 232–239, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 1 2 3 4 5 System Baseline Simplified French* Removal of empty lines Conversion of HTML special characters like &quot; to the corresponding characters Unification of words that were written both with an œ or with an oe to only one spelling Punctuation normalization and tokenization Putting together clitics and apostrophes like l ’ or d ’ to l’ and d’ la / l’ / les → le un / une → un Infl. form → lemma e. g. au → a` le Redu"
W13-2230,P05-1066,0,0.216656,"Missing"
W13-2230,P11-1105,1,0.789613,"eneral translation model, this method also allows the generation of inflected word forms which do not occur in the training data. 2 Experimental setup The translation experiments in this paper are carried out with either a standard phrase-based Moses system (DE-EN, EN-DE, EN-FR and FR-EN) or with an operation sequence model (RU-EN, DEEN), cf. Durrani et al. (2013b) for more details. An operation sequence model (OSM) is a stateof-the-art SMT-system that learns translation and reordering patterns by representing a sentence pair and its word alignment as a unique sequence of operations (see e.g. Durrani et al. (2011), Durrani et al. (2013a) for more details). For the Moses systems we used the old train-model perl scripts rather than the EMS, so we did not perform Good-Turing smoothing; parameter tuning was carried out with batch-mira (Cherry and Foster, 2012). 232 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 232–239, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 1 2 3 4 5 System Baseline Simplified French* Removal of empty lines Conversion of HTML special characters like &quot; to the corresponding characters Unification of words that we"
W13-2230,N13-1001,1,0.816849,"lly complex target language, we describe a two-step translation system built on non-inflected word stems with a post-processing component for predicting morphological features and the generation of inflected forms. In addition to the advantage of a more general translation model, this method also allows the generation of inflected word forms which do not occur in the training data. 2 Experimental setup The translation experiments in this paper are carried out with either a standard phrase-based Moses system (DE-EN, EN-DE, EN-FR and FR-EN) or with an operation sequence model (RU-EN, DEEN), cf. Durrani et al. (2013b) for more details. An operation sequence model (OSM) is a stateof-the-art SMT-system that learns translation and reordering patterns by representing a sentence pair and its word alignment as a unique sequence of operations (see e.g. Durrani et al. (2011), Durrani et al. (2013a) for more details). For the Moses systems we used the old train-model perl scripts rather than the EMS, so we did not perform Good-Turing smoothing; parameter tuning was carried out with batch-mira (Cherry and Foster, 2012). 232 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 232–239, c Sof"
W13-2230,2012.eamt-1.42,1,0.834142,"bmitted systems for DE-EN and EN-DE which used constituent parses for pre-reordering. For DE-EN we also deal with word formation issues such as compound splitting. We did not perform inflectional normalization or generation for German due to time constraints, instead focusing 236 system our efforts on these issues for French and Russian as previously described. German to English German has a wider diversity of clausal orderings than English, all of which need to be mapped to the English SVO order. This is a difficult problem to solve during inference, as shown for hierarchical SMT by Fabienne Braune and Fraser (2012) and for phrase-based SMT by Bisazza and Federico (2012). We syntactically parsed all of the source side sentences of the parallel German to English data available, and the tuning, test and blindtest sets. We then applied reordering rules to these parses. We use the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data. For parsing the German sentences, we used the generative phrase-structure parser BitPar with optimizations of the grammar, as described by Frase"
W13-2230,E12-1068,1,0.847569,"ng all necessary morphological features for the translation output, which are then used to generate fully inflected forms. This two-step setup decreases the complexity of the translation task by removing languagespecific features from the translation model. Furthermore, generating inflected forms based on word stems and morphological features allows to gener233 ate forms which do not occur in the parallel training data – this is not possible in a standard SMT setup. The idea of separating the translation into two steps to deal with complex morphology was introduced by Toutanova et al. (2008). Fraser et al. (2012) applied this method to the language pair English-German with an additional special focus on word formation issues such as the splitting and merging of portmanteau prepositions and compounds. The presented inflection prediction systems focuses on nominal inflection; verbal inflection is not addressed. Morphological analysis and resources The morphological analysis of the French training data is obtained using RFTagger, which is designed for annotating fine-grained morphological tags (Schmid and Laws, 2008). For generating inflected forms based on stems and morphological features, we use an ext"
W13-2230,J13-1005,1,0.858728,"Missing"
W13-2230,W09-0420,1,0.87823,"of clausal orderings than English, all of which need to be mapped to the English SVO order. This is a difficult problem to solve during inference, as shown for hierarchical SMT by Fabienne Braune and Fraser (2012) and for phrase-based SMT by Bisazza and Federico (2012). We syntactically parsed all of the source side sentences of the parallel German to English data available, and the tuning, test and blindtest sets. We then applied reordering rules to these parses. We use the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data. For parsing the German sentences, we used the generative phrase-structure parser BitPar with optimizations of the grammar, as described by Fraser et al. (2013). The parser was trained on the Tiger Treebank (Brants et al., 2002) along with utilizing the Europarl corpus as unlabeled data. At the training of Bitpar, we followed the targeted self-training approach (Katz-Brown et al., 2011) as follows. We parsed the whole Europarl corpus using a grammar trained on the Tiger corpus and extracted the 100best parse trees for each sentence. We sel"
W13-2230,W10-1734,1,0.788681,"us and the automatic parses from Europarl. The usefulness score estimates the value of a parse tree for the reordering task. We calculated this score as the similarity between the word order achieved by applying the parse tree-based reordering rules of Fraser (2009) and the word order indicated by the automatic word alignment between the German and English sentences in Europarl. We used the Kendall’s Tau Distance as the similarity metric of two word orderings (as suggested by Birch and Osborne (2010)). Following this, we performed linguisticallyinformed compound splitting, using the system of Fritzinger and Fraser (2010), which disambiguates competing analyses from the high-recall Stuttgart Morphological Analyzer SMOR (Schmid et al., 2004) using corpus statistics. We also split German portmanteaus like zum → zu dem (meaning to the). DE-EN (OSM) DE-EN (OSM) BitPar not self-trained DE-EN (Moses) DE-EN (Moses) BitPar not self-trained EN-DE (Moses) BLEU (ci) 27.60 27.48 BLEU (cs) 26.12 25.99 system name 27.14 25.65 26.82 25.36 MES-Szegedreorder-split not submitted 19.68 18.97 MES-reorder MES not submitted Table 8: Results on WMT-2013 (blindtest) English to German The task of mapping English SVO order to the diffe"
W13-2230,E12-1074,1,0.864449,"s. We also split German portmanteaus like zum → zu dem (meaning to the). DE-EN (OSM) DE-EN (OSM) BitPar not self-trained DE-EN (Moses) DE-EN (Moses) BitPar not self-trained EN-DE (Moses) BLEU (ci) 27.60 27.48 BLEU (cs) 26.12 25.99 system name 27.14 25.65 26.82 25.36 MES-Szegedreorder-split not submitted 19.68 18.97 MES-reorder MES not submitted Table 8: Results on WMT-2013 (blindtest) English to German The task of mapping English SVO order to the different clausal orders in German is difficult. For our English to German systems, we solved this by parsing the English and applying the system of Gojun and Fraser (2012) to reorder English into the correct German clausal order (depending on the clause type which is detected using the English parse, see (Gojun and Fraser, 2012) for further details). We primarily used the Charniak-Johnson generative parser (Charniak and Johnson, 2005) to parse the English Europarl data and the test data. However, due to time constraints we additionally used Berkeley parses of about 400K Europarl sentences and the other English parallel training data. We also left a small amount of the English parallel training data unparsed, which means that it was not reordered. For tune, test"
W13-2230,D11-1017,0,0.051958,"d reordering rules to these parses. We use the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data. For parsing the German sentences, we used the generative phrase-structure parser BitPar with optimizations of the grammar, as described by Fraser et al. (2013). The parser was trained on the Tiger Treebank (Brants et al., 2002) along with utilizing the Europarl corpus as unlabeled data. At the training of Bitpar, we followed the targeted self-training approach (Katz-Brown et al., 2011) as follows. We parsed the whole Europarl corpus using a grammar trained on the Tiger corpus and extracted the 100best parse trees for each sentence. We selected the parse tree among the 100 candidates which got the highest usefulness scores for the reordering task. Then we trained a new grammar on the concatenation of the Tiger corpus and the automatic parses from Europarl. The usefulness score estimates the value of a parse tree for the reordering task. We calculated this score as the similarity between the word order achieved by applying the parse tree-based reordering rules of Fraser (2009"
W13-2230,P10-1052,0,0.0314476,"Missing"
W13-2230,C12-1121,0,0.0602483,"Missing"
W13-2230,P11-1044,1,0.749892,"problem by stemming the OOVs based on a list of suffixes ( , , , , , ) and transliterating the stemmed forms. Voice Aspect Type Degree Type Formation Table 6: Rules for simplifying the morphological complexity for RU. training and extracts transliteration pairs that can be used for the training of the transliteration system. The procedure of mining transliteration pairs and transliterating OOVs is described as follows: We word-align the parallel corpus using GIZA++ and symmetrize the alignments using the grow-diagfinal-and heuristic. We extract all word pairs which occur as 1-to-1 alignments (Sajjad et al., 2011) and later refer to them as a list of word pairs. We train the unsupervised transliteration mining system on the list of word pairs and extract transliteration pairs. We use these mined pairs to build a transliteration system using the Moses toolkit. The transliteration system is applied as a post-processing step to transliterate OOVs. The morphological reduction of Russian (cf. section 5) does not process most of the OOVs as they are also unknown to the POS tagger. So OOVs that we get are in their original form. When translitExperiments and results We trained the systems separately on GIZA++"
W13-2230,P12-1049,1,0.744729,", particles, interjections and abbreviations) have no morphological attributes. The list of the original and the reduced attributes is given in Table 6. Transliteration mining to handle OOVs The machine translation system fails to translate out-ofvocabulary words (OOVs) as they are unknown to the training data. Most of the OOVs are named entities and transliterating them to the target language script could solve this problem. The transliteration system requires a list of transliteration pairs for training. As we do not have such a list, we use the unsupervised transliteration mining system of Sajjad et al. (2012) that takes a list of word pairs for Part of Speech Noun Pronoun Verb Adjective Preposition Conjunction Attributes RFTagger Type Gender Number Case Reduced attributes Type Gender Number Case nom,gen,dat,acc,instr,prep gen,notgen Animate Case 2 Person Gender Number Case Person Gender Number Case nom,gen,dat,acc,instr,prep nom,notnom Syntactic type Animated Type VForm Tense Person Number Gender Voice Definiteness Aspect Case Type Degree Gender Number Case Definiteness Type Formation Case Type Formation SYS GIZA++ TA-GIZA++ Original corpus WMT-2012 WMT-2013 32.51 25.5 33.40 25.9* SYS GIZA++ TA-GI"
W13-2230,W13-2228,1,0.735928,"ng system on the list of word pairs and extract transliteration pairs. We use these mined pairs to build a transliteration system using the Moses toolkit. The transliteration system is applied as a post-processing step to transliterate OOVs. The morphological reduction of Russian (cf. section 5) does not process most of the OOVs as they are also unknown to the POS tagger. So OOVs that we get are in their original form. When translitExperiments and results We trained the systems separately on GIZA++ and transliteration augmented-GIZA++ (TA-GIZA++) to compare their results; for more details see Sajjad et al. (2013). All systems are tuned using PROv1 (Nakov et al., 2012). The translation output is postprocessed to transliterate OOVs. Table 7 summarizes the results of RU-EN translation systems trained on the original corpus and on the morph-reduced corpus. Using TA-GIZA++ alignment gives the best results for both WMT2012 and WMT-2013, leading to an improvement of 0.4 BLEU points. The system built on the morph-reduced data leads to decreased BLEU results. However, the percentage of OOVs is reduced for both test sets when using the morph-reduced data set compared to the original data. An analysis of the out"
W13-2230,C08-1098,1,0.776757,"reas adjectives in English are not inflected at all. This causes data sparsity in coverage of French inflected forms. We try to overcome this problem by simplifying French inflected forms in a pre-processing step in order to adapt the French input better to the English output. Processing of the training and test data The pre-processing of the French input consists of two steps: (1) normalizing not well-formed data (cf. table 1) and (2) morphological simplification. In the second step, the normalized training data is annotated with Part-of-Speech tags (PoS-tags) and word lemmas using RFTagger (Schmid and Laws, 2008) which was trained on the French treebank (Abeill´e et al., 2003). French forms are then simplified according to the rules given in table 2. Data and experiments We trained a French to English Moses system on the preprocessed and BLEU (ci) 31.02 30.83 Table 3: Results of the French to English system (WMT-2012). The marked system (*) corresponds to the system submitted for manual evaluation. (cs: case-sensitive, ci: case-insensitive) Table 1: Text normalization for FR-EN. Definite determiners Indefinite determiners Adjectives Portmanteaus Verb participles inflected for gender and number ending"
W13-2230,schmid-etal-2004-smor,1,0.771053,"Missing"
W13-2230,I08-2089,0,0.135299,"h an œ or with an oe to only one spelling Punctuation normalization and tokenization Putting together clitics and apostrophes like l ’ or d ’ to l’ and d’ la / l’ / les → le un / une → un Infl. form → lemma e. g. au → a` le Reduced to non-inflected verb participle form ending in e´ d’ → de, qu’ → que, n’ → ne, ... Table 2: Rules for morphological simplification. The development data consists of the concatenated news-data sets from the years 2008-2011. Unless otherwise stated, we use all constrained data (parallel and monolingual). For the target-side language models, we follow the approach of Schwenk and Koehn (2008) and train a separate language model for each corpus and then interpolate them using weights optimized on development data. 3 French to English French has a much richer morphology than English; for example, adjectives in French are inflected with respect to gender and number whereas adjectives in English are not inflected at all. This causes data sparsity in coverage of French inflected forms. We try to overcome this problem by simplifying French inflected forms in a pre-processing step in order to adapt the French input better to the English output. Processing of the training and test data Th"
W13-2230,P08-1059,0,0.0269016,"step consists of predicting all necessary morphological features for the translation output, which are then used to generate fully inflected forms. This two-step setup decreases the complexity of the translation task by removing languagespecific features from the translation model. Furthermore, generating inflected forms based on word stems and morphological features allows to gener233 ate forms which do not occur in the parallel training data – this is not possible in a standard SMT setup. The idea of separating the translation into two steps to deal with complex morphology was introduced by Toutanova et al. (2008). Fraser et al. (2012) applied this method to the language pair English-German with an additional special focus on word formation issues such as the splitting and merging of portmanteau prepositions and compounds. The presented inflection prediction systems focuses on nominal inflection; verbal inflection is not addressed. Morphological analysis and resources The morphological analysis of the French training data is obtained using RFTagger, which is designed for annotating fine-grained morphological tags (Schmid and Laws, 2008). For generating inflected forms based on stems and morphological f"
W13-2230,W13-2213,1,\N,Missing
W14-3305,E03-1076,0,0.126755,"split, lemmatised German and then, we perform compound merging and generation of inflection as a postprocessing step. This way, we are able to create German compounds and inflectional variants that have not been seen in the parallel training data. 71 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 71–78, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics Compound Processing Compound splitting for SMT has been addressed by numerous different groups, for translation from German to English, e.g. using corpus-based frequencies (Koehn and Knight, 2003), using POSconstraints (Stymne et al., 2008), a lattice-based approach propagating the splitting decision to the decoder (Dyer, 2009), a rule-based morphological analyser (Fritzinger and Fraser, 2010) or unsupervised, language-independent segmentation (Macherey et al., 2011). Compound processing in the other translation direction, however, has been much less investigated. Popovi´c et al. (2006) describe a list-based approach, in which words are only re-combined if they have been seen as compounds in a huge corpus. However this approach is limited to the list’s coverage. The approach of Stymne"
W14-3305,E14-1061,1,0.867408,"ction, however, has been much less investigated. Popovi´c et al. (2006) describe a list-based approach, in which words are only re-combined if they have been seen as compounds in a huge corpus. However this approach is limited to the list’s coverage. The approach of Stymne (2009) overcomes this coverage issue by making use of a POS-markup which distinguishes former compound modifiers from former heads and thus allows for their adequate recombination after translation. An extension of this approach is reported in Stymne and Cancedda (2011) where a C RF-model is used for compound prediction. In Cap et al. (2014) their approach is extended through using source-language features and lemmatisation, allowing for maximal generalisation over compound parts. nominal inflection component and first experimental steps towards verbal re-inflection. Source-side Reordering One major problem in English to German translation is the divergent clausal ordering: in particular, German verbs tend to occur at the very end of clauses, whereas English sticks to a rigid SVO order in most cases. Collins et al. (2005), Fraser (2009) and Gojun and Fraser (2012) showed that restructuring the source language so that it correspon"
W14-3305,P07-2045,0,0.0128411,"Missing"
W14-3305,P05-1022,0,0.0180409,"that the compound processing systems are able to create a considerable number of compounds unseen in the parallel training data. In the future, we will investigate further combinations and extensions of our morphological components, including reordering, compound processing and verbal inflection. There are still many many interesting challenges to be solved in all of these areas, and this is especially true for verbal inflection. 8 Reordering For the system CimS-Syntax-RORI, English data parsed with E GRET was reordered using scripts written for parse trees produced by the constituent parser (Charniak and Johnson, 2005), using a model we trained on the standard Penn Treebank sections. Unfortunately, the reordering scripts could not be straightforwardly applied to E GRET parses and require more significant modifications than we first expected. We thus decided to parse the Europarl data (v7) with (Charniak and Johnson, 2005) instead and run our reordering scripts on it (CimS-RO). For evaluation purposes, we build a baseline system raw’ which has been trained only on Europarl. Tuning and testing setup is the same as for the systems described in Section 6 with the difference that the weights have been tuned on n"
W14-3305,N12-1047,0,0.0211633,"English. We did so for training, tuning and testing input. Syntax-based Translation model As a variant to the phrase-based systems, we applied the inflection prediction system to a string-to-tree system with GHKM extraction (Galley et al. (2004), Williams and Koehn (2012)). We used the same data-sets as for the phrase-based systems, and applied BitPar (Schmid, 2004) to obtain targetside trees. For this system, we used source-side reordering according to Gojun and Fraser (2012) relying on parses obtained with E GRET3 . Tuning For tuning of feature weights, we used batch-mira with ’–safe-hope’ (Cherry and Foster, 2012) until convergence (or maximal 25 runs). We used the 3,000 sentences of newstest2012 for tuning. Each experiment was tuned separately, optimising Bleu scores (Papineni et al., 2002) against a lemmatised version of the tuning reference. In the compound processing systems we integrated the C RF-based prediction and merging procedure into each tuning iteration and scored each output against the same unsplit and lemmatised reference as the other systems. Language Model We trained 5-gram language models based on all available German monolingual training data from the shared task (roughly 1.5 billio"
W14-3305,P05-1066,0,0.109243,"Missing"
W14-3305,P11-1140,0,0.0144577,"Workshop on Statistical Machine Translation, pages 71–78, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics Compound Processing Compound splitting for SMT has been addressed by numerous different groups, for translation from German to English, e.g. using corpus-based frequencies (Koehn and Knight, 2003), using POSconstraints (Stymne et al., 2008), a lattice-based approach propagating the splitting decision to the decoder (Dyer, 2009), a rule-based morphological analyser (Fritzinger and Fraser, 2010) or unsupervised, language-independent segmentation (Macherey et al., 2011). Compound processing in the other translation direction, however, has been much less investigated. Popovi´c et al. (2006) describe a list-based approach, in which words are only re-combined if they have been seen as compounds in a huge corpus. However this approach is limited to the list’s coverage. The approach of Stymne (2009) overcomes this coverage issue by making use of a POS-markup which distinguishes former compound modifiers from former heads and thus allows for their adequate recombination after translation. An extension of this approach is reported in Stymne and Cancedda (2011) wher"
W14-3305,N09-1046,0,0.0218904,"reate German compounds and inflectional variants that have not been seen in the parallel training data. 71 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 71–78, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics Compound Processing Compound splitting for SMT has been addressed by numerous different groups, for translation from German to English, e.g. using corpus-based frequencies (Koehn and Knight, 2003), using POSconstraints (Stymne et al., 2008), a lattice-based approach propagating the splitting decision to the decoder (Dyer, 2009), a rule-based morphological analyser (Fritzinger and Fraser, 2010) or unsupervised, language-independent segmentation (Macherey et al., 2011). Compound processing in the other translation direction, however, has been much less investigated. Popovi´c et al. (2006) describe a list-based approach, in which words are only re-combined if they have been seen as compounds in a huge corpus. However this approach is limited to the list’s coverage. The approach of Stymne (2009) overcomes this coverage issue by making use of a POS-markup which distinguishes former compound modifiers from former heads an"
W14-3305,J03-1002,0,0.00488442,"to be retransformed into fluent German text, i.e., compounds need to be re-combined and all words have to be reinflected. The whole procedure can be divided into the following steps: 1a) translation into lemmatised German representation (RI, RIVe) 1b) translation into split and lemmatised German (CoRi, CoRIVe) 2) compound merging (CoRI, CoRIVe): 3) nominal inflection prediction and generation of full forms using S MOR (all) 4) verbal re-inflection (RIVe, CoRIVe) 5) merging of portmanteaus (all) Phrase-based Translation model We performed word alignment using the multithreaded GIZA++ toolkit (Och and Ney, 2003; Gao and Vogel, 2008). For translation model training and decoding, we used the Moses toolkit (Koehn et al., 2007) to build phrase-based statistical machine translation systems, following the instructions for the baseline system for the shared task, using only default settings. 1 We could not parse the whole monolingual dataset due to time-constraints and thus used RFTagger as a substitute. 2 available from https://sites.google.com/ site/zhangh1982/egret. 3 Note that we observed some data-related issues on the Syntax-RORI experiments that we hope to resolve in the near future. 74 mert.log new"
W14-3305,E12-1068,1,0.916929,"issions to the 2014 Shared Task for the language pair EN→DE. We address the major problems that arise when translating into German: complex nominal and verbal morphology, productive compounding and flexible word ordering. Our morphologyaware translation systems handle word formation issues on different levels of morpho-syntactic modeling. 2 Related Work Re-Inflection The two-step translation approach we use was described by e.g. Toutanova et al. (2008) and Jeong et al. (2010), who use a number of morphological and syntactic features derived from both source and target language. More recently, Fraser et al. (2012) describe a similar approach for German using different C RF-based feature prediction models, one for each of the four grammatical features to be predicted for German words in noun phrases, namely number, gender, case and definiteness. This approach also handles wordformation issues such as portmanteau splitting and compounding. Weller et al. (2013) added subcategorization information in combination with source-side syntactic features in order to improve the prediction of case. De Gispert and Mariño (2008) generate verbal inflection for translation from English into Spanish. They use classifie"
W14-3305,P02-1040,0,0.0898851,"ring-to-tree system with GHKM extraction (Galley et al. (2004), Williams and Koehn (2012)). We used the same data-sets as for the phrase-based systems, and applied BitPar (Schmid, 2004) to obtain targetside trees. For this system, we used source-side reordering according to Gojun and Fraser (2012) relying on parses obtained with E GRET3 . Tuning For tuning of feature weights, we used batch-mira with ’–safe-hope’ (Cherry and Foster, 2012) until convergence (or maximal 25 runs). We used the 3,000 sentences of newstest2012 for tuning. Each experiment was tuned separately, optimising Bleu scores (Papineni et al., 2002) against a lemmatised version of the tuning reference. In the compound processing systems we integrated the C RF-based prediction and merging procedure into each tuning iteration and scored each output against the same unsplit and lemmatised reference as the other systems. Language Model We trained 5-gram language models based on all available German monolingual training data from the shared task (roughly 1.5 billion words) using the SRILM toolkit (Stolcke, 2002) with Kneser-Ney smoothing. We then used KenLM (Heafield, 2011) for faster processing. For each of our experiments, we trained a sepa"
W14-3305,W09-0420,1,0.871488,"orted in Stymne and Cancedda (2011) where a C RF-model is used for compound prediction. In Cap et al. (2014) their approach is extended through using source-language features and lemmatisation, allowing for maximal generalisation over compound parts. nominal inflection component and first experimental steps towards verbal re-inflection. Source-side Reordering One major problem in English to German translation is the divergent clausal ordering: in particular, German verbs tend to occur at the very end of clauses, whereas English sticks to a rigid SVO order in most cases. Collins et al. (2005), Fraser (2009) and Gojun and Fraser (2012) showed that restructuring the source language so that it corresponds to the expected structure of the target language is helpful for SMT. German verbs agree in number and person with their subjects. We thus have to derive this information from a noun phrase in nominative case (= the subject) near the verb. This information comes from the nominal inflection prediction described in section 3.1. We predict tense and mode of the verb using a maximum-entropy classifier which is trained on English and German contextual information. After deriving all information needed f"
W14-3305,W10-1734,1,0.842911,"hat have not been seen in the parallel training data. 71 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 71–78, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics Compound Processing Compound splitting for SMT has been addressed by numerous different groups, for translation from German to English, e.g. using corpus-based frequencies (Koehn and Knight, 2003), using POSconstraints (Stymne et al., 2008), a lattice-based approach propagating the splitting decision to the decoder (Dyer, 2009), a rule-based morphological analyser (Fritzinger and Fraser, 2010) or unsupervised, language-independent segmentation (Macherey et al., 2011). Compound processing in the other translation direction, however, has been much less investigated. Popovi´c et al. (2006) describe a list-based approach, in which words are only re-combined if they have been seen as compounds in a huge corpus. However this approach is limited to the list’s coverage. The approach of Stymne (2009) overcomes this coverage issue by making use of a POS-markup which distinguishes former compound modifiers from former heads and thus allows for their adequate recombination after translation. A"
W14-3305,C08-1098,0,0.0115114,"we disambiguated S MOR using POS tags we obtained through parsing the German section of the parallel training data with BitPar (Schmid, 73 No. CimS-RI CimS-CoRIP CimS-RIVe CimS-CoRIVe CimS-Syntax-RORI apprart splitting X X X X X nominal inflection X X X X X compound processing verbal inflection source-side reordering X X X X X Table 1: Overview of our submission systems.RI = nominal Re-Inflection, Co = Compound processing, Ve = Verbal inflection, RO = source-side Re-Ordering. Syntax = syntax-based SMT P = primary submission. 2004) and tagging the big monolingual training data using RFTagger (Schmid and Laws, 2008)1 . Note that we did not normalise German language e.g. with respect to old vs. new writing convention etc. as we did in previous submissions (e.g. (Fraser, 2009)). For the compound prediction C RFs using syntactic features derived from the source language, we parsed the English section of the parallel data using EGRET, a re-implementation of the Berkeley-Parser by Hui Zhang2 . Before training our models on the English data, we normalised all occurrences of British vs. American English variants to British English. We did so for training, tuning and testing input. Syntax-based Translation model"
W14-3305,N04-1035,0,0.0444681,"sions (e.g. (Fraser, 2009)). For the compound prediction C RFs using syntactic features derived from the source language, we parsed the English section of the parallel data using EGRET, a re-implementation of the Berkeley-Parser by Hui Zhang2 . Before training our models on the English data, we normalised all occurrences of British vs. American English variants to British English. We did so for training, tuning and testing input. Syntax-based Translation model As a variant to the phrase-based systems, we applied the inflection prediction system to a string-to-tree system with GHKM extraction (Galley et al. (2004), Williams and Koehn (2012)). We used the same data-sets as for the phrase-based systems, and applied BitPar (Schmid, 2004) to obtain targetside trees. For this system, we used source-side reordering according to Gojun and Fraser (2012) relying on parses obtained with E GRET3 . Tuning For tuning of feature weights, we used batch-mira with ’–safe-hope’ (Cherry and Foster, 2012) until convergence (or maximal 25 runs). We used the 3,000 sentences of newstest2012 for tuning. Each experiment was tuned separately, optimising Bleu scores (Papineni et al., 2002) against a lemmatised version of the tun"
W14-3305,schmid-etal-2004-smor,0,0.0523514,"01) to predict the morphological features (number, gender, case and strong/weak). The features that are part of the lemma of nouns (number, gender) are propagated over the rest of the linguistic phrase. In contrast, case depends on the role of the NP in the sentence (e.g. subject or direct/indirect object) and is thus to be determined entirely from the respective context in the sentence. The value for strong/weak depends on the combination of the other features. Based on the lemma and the predicted features, inflected forms are then generated using the rule-based morphological analyser S MOR (Schmid et al., 2004). This system is described in more detail in Fraser et al. (2012). 3.2 Verbal Inflection 3 Inflection Prediction German has a rich morphology, both for nominal and verbal inflection. It requires different forms of agreement, e.g., for adjectives and nouns or verbs and their subjects. Traditional phrase-based SMT systems often get such agreements wrong. In our systems, we explicitly model agreement using a two-step approach: first we translate from English into lemmatised German and then generate fully inflected forms in a second step. In this section, we describe our 4 Compound Processing In E"
W14-3305,W08-0509,0,0.0138683,"d into fluent German text, i.e., compounds need to be re-combined and all words have to be reinflected. The whole procedure can be divided into the following steps: 1a) translation into lemmatised German representation (RI, RIVe) 1b) translation into split and lemmatised German (CoRi, CoRIVe) 2) compound merging (CoRI, CoRIVe): 3) nominal inflection prediction and generation of full forms using S MOR (all) 4) verbal re-inflection (RIVe, CoRIVe) 5) merging of portmanteaus (all) Phrase-based Translation model We performed word alignment using the multithreaded GIZA++ toolkit (Och and Ney, 2003; Gao and Vogel, 2008). For translation model training and decoding, we used the Moses toolkit (Koehn et al., 2007) to build phrase-based statistical machine translation systems, following the instructions for the baseline system for the shared task, using only default settings. 1 We could not parse the whole monolingual dataset due to time-constraints and thus used RFTagger as a substitute. 2 available from https://sites.google.com/ site/zhangh1982/egret. 3 Note that we observed some data-related issues on the Syntax-RORI experiments that we hope to resolve in the near future. 74 mert.log news2012 Bleu ci news2013"
W14-3305,C04-1024,0,0.0267474,"d the English section of the parallel data using EGRET, a re-implementation of the Berkeley-Parser by Hui Zhang2 . Before training our models on the English data, we normalised all occurrences of British vs. American English variants to British English. We did so for training, tuning and testing input. Syntax-based Translation model As a variant to the phrase-based systems, we applied the inflection prediction system to a string-to-tree system with GHKM extraction (Galley et al. (2004), Williams and Koehn (2012)). We used the same data-sets as for the phrase-based systems, and applied BitPar (Schmid, 2004) to obtain targetside trees. For this system, we used source-side reordering according to Gojun and Fraser (2012) relying on parses obtained with E GRET3 . Tuning For tuning of feature weights, we used batch-mira with ’–safe-hope’ (Cherry and Foster, 2012) until convergence (or maximal 25 runs). We used the 3,000 sentences of newstest2012 for tuning. Each experiment was tuned separately, optimising Bleu scores (Papineni et al., 2002) against a lemmatised version of the tuning reference. In the compound processing systems we integrated the C RF-based prediction and merging procedure into each t"
W14-3305,E12-1074,1,0.939262,"d Cancedda (2011) where a C RF-model is used for compound prediction. In Cap et al. (2014) their approach is extended through using source-language features and lemmatisation, allowing for maximal generalisation over compound parts. nominal inflection component and first experimental steps towards verbal re-inflection. Source-side Reordering One major problem in English to German translation is the divergent clausal ordering: in particular, German verbs tend to occur at the very end of clauses, whereas English sticks to a rigid SVO order in most cases. Collins et al. (2005), Fraser (2009) and Gojun and Fraser (2012) showed that restructuring the source language so that it corresponds to the expected structure of the target language is helpful for SMT. German verbs agree in number and person with their subjects. We thus have to derive this information from a noun phrase in nominative case (= the subject) near the verb. This information comes from the nominal inflection prediction described in section 3.1. We predict tense and mode of the verb using a maximum-entropy classifier which is trained on English and German contextual information. After deriving all information needed for the generation of the ver"
W14-3305,W11-2123,0,0.0480288,"Each experiment was tuned separately, optimising Bleu scores (Papineni et al., 2002) against a lemmatised version of the tuning reference. In the compound processing systems we integrated the C RF-based prediction and merging procedure into each tuning iteration and scored each output against the same unsplit and lemmatised reference as the other systems. Language Model We trained 5-gram language models based on all available German monolingual training data from the shared task (roughly 1.5 billion words) using the SRILM toolkit (Stolcke, 2002) with Kneser-Ney smoothing. We then used KenLM (Heafield, 2011) for faster processing. For each of our experiments, we trained a separate language model on the whole data set, corresponding to the different underspecified representations of German used in our experiments, e.g. lemmatised for CimS-RI, lemmatised with split compounds for CimS-CoRI, etc. Testing After decoding, the underspecified representation has to be retransformed into fluent German text, i.e., compounds need to be re-combined and all words have to be reinflected. The whole procedure can be divided into the following steps: 1a) translation into lemmatised German representation (RI, RIVe)"
W14-3305,W08-0317,0,0.0192784,"compound merging and generation of inflection as a postprocessing step. This way, we are able to create German compounds and inflectional variants that have not been seen in the parallel training data. 71 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 71–78, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics Compound Processing Compound splitting for SMT has been addressed by numerous different groups, for translation from German to English, e.g. using corpus-based frequencies (Koehn and Knight, 2003), using POSconstraints (Stymne et al., 2008), a lattice-based approach propagating the splitting decision to the decoder (Dyer, 2009), a rule-based morphological analyser (Fritzinger and Fraser, 2010) or unsupervised, language-independent segmentation (Macherey et al., 2011). Compound processing in the other translation direction, however, has been much less investigated. Popovi´c et al. (2006) describe a list-based approach, in which words are only re-combined if they have been seen as compounds in a huge corpus. However this approach is limited to the list’s coverage. The approach of Stymne (2009) overcomes this coverage issue by maki"
W14-3305,2010.amta-papers.33,0,0.0248562,"experimental results on a verbal inflection component and a syntax-based variant including source-side reordering. We present the CimS submissions to the 2014 Shared Task for the language pair EN→DE. We address the major problems that arise when translating into German: complex nominal and verbal morphology, productive compounding and flexible word ordering. Our morphologyaware translation systems handle word formation issues on different levels of morpho-syntactic modeling. 2 Related Work Re-Inflection The two-step translation approach we use was described by e.g. Toutanova et al. (2008) and Jeong et al. (2010), who use a number of morphological and syntactic features derived from both source and target language. More recently, Fraser et al. (2012) describe a similar approach for German using different C RF-based feature prediction models, one for each of the four grammatical features to be predicted for German words in noun phrases, namely number, gender, case and definiteness. This approach also handles wordformation issues such as portmanteau splitting and compounding. Weller et al. (2013) added subcategorization information in combination with source-side syntactic features in order to improve t"
W14-3305,E09-3008,0,0.0177032,", 2003), using POSconstraints (Stymne et al., 2008), a lattice-based approach propagating the splitting decision to the decoder (Dyer, 2009), a rule-based morphological analyser (Fritzinger and Fraser, 2010) or unsupervised, language-independent segmentation (Macherey et al., 2011). Compound processing in the other translation direction, however, has been much less investigated. Popovi´c et al. (2006) describe a list-based approach, in which words are only re-combined if they have been seen as compounds in a huge corpus. However this approach is limited to the list’s coverage. The approach of Stymne (2009) overcomes this coverage issue by making use of a POS-markup which distinguishes former compound modifiers from former heads and thus allows for their adequate recombination after translation. An extension of this approach is reported in Stymne and Cancedda (2011) where a C RF-model is used for compound prediction. In Cap et al. (2014) their approach is extended through using source-language features and lemmatisation, allowing for maximal generalisation over compound parts. nominal inflection component and first experimental steps towards verbal re-inflection. Source-side Reordering One major"
W14-3305,P08-1059,0,0.0313341,"sk. In addition, we present experimental results on a verbal inflection component and a syntax-based variant including source-side reordering. We present the CimS submissions to the 2014 Shared Task for the language pair EN→DE. We address the major problems that arise when translating into German: complex nominal and verbal morphology, productive compounding and flexible word ordering. Our morphologyaware translation systems handle word formation issues on different levels of morpho-syntactic modeling. 2 Related Work Re-Inflection The two-step translation approach we use was described by e.g. Toutanova et al. (2008) and Jeong et al. (2010), who use a number of morphological and syntactic features derived from both source and target language. More recently, Fraser et al. (2012) describe a similar approach for German using different C RF-based feature prediction models, one for each of the four grammatical features to be predicted for German words in noun phrases, namely number, gender, case and definiteness. This approach also handles wordformation issues such as portmanteau splitting and compounding. Weller et al. (2013) added subcategorization information in combination with source-side syntactic featur"
W14-3305,P13-1058,1,0.826574,"Work Re-Inflection The two-step translation approach we use was described by e.g. Toutanova et al. (2008) and Jeong et al. (2010), who use a number of morphological and syntactic features derived from both source and target language. More recently, Fraser et al. (2012) describe a similar approach for German using different C RF-based feature prediction models, one for each of the four grammatical features to be predicted for German words in noun phrases, namely number, gender, case and definiteness. This approach also handles wordformation issues such as portmanteau splitting and compounding. Weller et al. (2013) added subcategorization information in combination with source-side syntactic features in order to improve the prediction of case. De Gispert and Mariño (2008) generate verbal inflection for translation from English into Spanish. They use classifiers trained not only on target language but also on source language features, which is even more crucial for the prediction of verbs than it is for nominal inflection. More recently, Williams and Koehn (2011) translate directly into target language surface forms. Agreement within NPs and PPs, and also between subject and verb is considered during the"
W14-3305,W11-2126,0,0.0145202,"hrases, namely number, gender, case and definiteness. This approach also handles wordformation issues such as portmanteau splitting and compounding. Weller et al. (2013) added subcategorization information in combination with source-side syntactic features in order to improve the prediction of case. De Gispert and Mariño (2008) generate verbal inflection for translation from English into Spanish. They use classifiers trained not only on target language but also on source language features, which is even more crucial for the prediction of verbs than it is for nominal inflection. More recently, Williams and Koehn (2011) translate directly into target language surface forms. Agreement within NPs and PPs, and also between subject and verb is considered during the decoding process: they use string-to-tree translation, where the target language (German) morphology is expressed as a set of unification constraints automatically learned from a morphologically annotated German corpus. 1 Introduction In our shared task submissions, we focus on the English to German translation direction: we address different levels of productivity of the German language, i.e., nominal and verbal inflection and productive word formati"
W14-3305,W11-2129,0,\N,Missing
W14-3305,W12-3150,0,\N,Missing
W14-5709,I08-1033,0,0.0159169,"ey (2000) use a parser for context-sensitive disambiguation, and Fritzinger and Fraser (2010) use corpus frequencies to find the best split for each compound. Other approaches use a two-step word alignment process: first, word alignment is performed on a split representation of the compounding language. Then, all former compound parts for which there is no aligned counterpart in the non-compounding language are merged back to the compound again. Finally, word alignment is re-run on this representation. See Koehn and Knight (2003) for experiments on German, DeNeefe et al. (2008) for Arabic and Bai et al. (2008) for Chinese. This blocks non-compositional compounds from being split if they are translated as one simplex English word in the training data (e.g. Heckensch¨utze, lit. ’hedge|shooter’; ’sniper’) and aligned correctly. However, cases like J¨agerzaun, ’lattice fence’ are not covered. In the present work, we identify compounds with a morphological analyser, disambiguated with corpus frequencies. Moreover, we restrict splitting to compositional compounds using distributional semantics. We are not aware of any previous work that takes semantics into account for compound splitting in SMT. 2.2 Dist"
W14-5709,bott-schulte-im-walde-2014-optimizing,1,0.806874,"Missing"
W14-5709,N12-1047,0,0.0416781,"This section gives an overview on the technical details of the SMT system and our data sets. Compound splitting is applied to all source-language data, i.e. the parallel data used to train the model, as well as the input for parameter tuning and testing.2 Translation Model Moses is a state-of-the-art toolkit for phrase-based SMT systems (Koehn et al., 2007). We use it with default settings to train a translation model and we do so separately for each of the different compound splittings. Word alignment is performed using GIZA++ (Och and Ney, 2003). Feature weights are tuned using Batch-Mira (Cherry and Foster, 2012) with ’-safe-hope’ until convergence. Training Data Our parallel training data contains the Europarl corpus (version 4, cf. Koehn (2005)) and also newspaper texts, overall ca. 1.5 million sentences3 (roughly 44 million words). In addition, we 1 Baum|schule: ‘tree|school’ (tree nursery) Compounds not contained in the parallel data are always split, as they cannot be translated otherwise. 3 Data from the shared task of the EACL 2009 workshop on statistical machine translation: www.statmt.org/wmt09 2 84 use an English corpus of roughly 227 million words (including the English part of the parallel"
W14-5709,W06-1207,0,0.0846585,"w a word by the company it keeps”, distributional semantics exploits the co-occurrence of words in corpora to explore the meanings and the similarities of the words, phrases, sentences, etc. of interest. Among many other tasks, distributional semantic information has been utilised to determine the degree of compositionality (or: semantic transparency) of various types of compounds, most notably regarding noun compounds (e.g., Zinsmeister and Heid (2004), Reddy et al. (2011), Schulte im Walde et al. (2013), Salehi et al. (2014)) and particle verbs (e.g., McCarthy et al. (2003), Bannard (2005), Cook and Stevenson (2006), K¨uhner and Schulte im Walde (2010), Bott and Schulte im Walde (2014), Salehi et al. (2014)). Typically, these approaches rely on co-occurrence information from a corpus (either referring to bagsof-words, or focusing on target-specific types of features), and compare the distributional features of the compounds with those of the constituents, in order to predict the degree of compositionality of the 82 SMT Preprocessing Holzzaun Jägerzaun Input Holz 0.311 Holz wooden Zaun 0.825 Zaun fence Jäger 0.015 Zaun 0.725 Step 1: Identify Component Words Step 2: Predict Similarity Scores Jägerzaun Step"
W14-5709,2008.amta-papers.7,0,0.050281,"require disambiguation: Nießen and Ney (2000) use a parser for context-sensitive disambiguation, and Fritzinger and Fraser (2010) use corpus frequencies to find the best split for each compound. Other approaches use a two-step word alignment process: first, word alignment is performed on a split representation of the compounding language. Then, all former compound parts for which there is no aligned counterpart in the non-compounding language are merged back to the compound again. Finally, word alignment is re-run on this representation. See Koehn and Knight (2003) for experiments on German, DeNeefe et al. (2008) for Arabic and Bai et al. (2008) for Chinese. This blocks non-compositional compounds from being split if they are translated as one simplex English word in the training data (e.g. Heckensch¨utze, lit. ’hedge|shooter’; ’sniper’) and aligned correctly. However, cases like J¨agerzaun, ’lattice fence’ are not covered. In the present work, we identify compounds with a morphological analyser, disambiguated with corpus frequencies. Moreover, we restrict splitting to compositional compounds using distributional semantics. We are not aware of any previous work that takes semantics into account for co"
W14-5709,W10-1734,1,0.961425,"tituents J¨ager (’hunter’) and Zaun (’fence’). Here, an erroneous splitting of the compound can lead to wrong generalizations or translation pairs, such as J¨ager → lattice, in the absence of other evidence about how to translate J¨ager. When splitting compounds for SMT, two important factors should thus be considered: (1) whether a compound is compositional and should be split, and if so (2) how the compound should be split. Most previous approaches mainly focused on the second task, how to split a compound, e.g. using frequency statistics (Koehn and Knight, 2003) or a rule-based morphology (Fritzinger and Fraser, 2010), and all of them showed improved SMT quality for compound splitting. The decision about whether the compound is compositional and should be split at all has not received much attention in the past. In this work, we examine the effect of only splitting compositional compounds, in contrast to splitting all compounds. To this end, we combine (A) an approach relying on the distributional similarity between compounds and their constituents, to predict the degree of compositionality and thus to determine whether to split the compound with (B) a combination of morphological and frequency-based featu"
W14-5709,W11-2123,0,0.0163357,"s (version 4, cf. Koehn (2005)) and also newspaper texts, overall ca. 1.5 million sentences3 (roughly 44 million words). In addition, we 1 Baum|schule: ‘tree|school’ (tree nursery) Compounds not contained in the parallel data are always split, as they cannot be translated otherwise. 3 Data from the shared task of the EACL 2009 workshop on statistical machine translation: www.statmt.org/wmt09 2 84 use an English corpus of roughly 227 million words (including the English part of the parallel data) to build a target-side 5-gram language model with SRILM (Stolcke, 2002) in combination with KENLM (Heafield, 2011). For parameter tuning, we use 1,025 sentences of news data. Standard Test set 1,026 sentences of news data (test set from the 2009 WMT Shared Task): this set is to measure the translation quality on a standard SMT test and make it comparable to other work. Noun/Verb Test set As our main focus lies on sentences containing compounds, we created a second test set which is rich in compounds. From the combined 2008-2013 Shared Task test sets, we extracted all sentences containing at least one noun compound for which we have compound-constituent similarity scores. Moreover, we excluded sentences co"
W14-5709,E03-1076,0,0.418448,"’) cannot be represented by the meanings of its constituents J¨ager (’hunter’) and Zaun (’fence’). Here, an erroneous splitting of the compound can lead to wrong generalizations or translation pairs, such as J¨ager → lattice, in the absence of other evidence about how to translate J¨ager. When splitting compounds for SMT, two important factors should thus be considered: (1) whether a compound is compositional and should be split, and if so (2) how the compound should be split. Most previous approaches mainly focused on the second task, how to split a compound, e.g. using frequency statistics (Koehn and Knight, 2003) or a rule-based morphology (Fritzinger and Fraser, 2010), and all of them showed improved SMT quality for compound splitting. The decision about whether the compound is compositional and should be split at all has not received much attention in the past. In this work, we examine the effect of only splitting compositional compounds, in contrast to splitting all compounds. To this end, we combine (A) an approach relying on the distributional similarity between compounds and their constituents, to predict the degree of compositionality and thus to determine whether to split the compound with (B)"
W14-5709,2005.mtsummit-papers.11,0,0.0339958,"ata, i.e. the parallel data used to train the model, as well as the input for parameter tuning and testing.2 Translation Model Moses is a state-of-the-art toolkit for phrase-based SMT systems (Koehn et al., 2007). We use it with default settings to train a translation model and we do so separately for each of the different compound splittings. Word alignment is performed using GIZA++ (Och and Ney, 2003). Feature weights are tuned using Batch-Mira (Cherry and Foster, 2012) with ’-safe-hope’ until convergence. Training Data Our parallel training data contains the Europarl corpus (version 4, cf. Koehn (2005)) and also newspaper texts, overall ca. 1.5 million sentences3 (roughly 44 million words). In addition, we 1 Baum|schule: ‘tree|school’ (tree nursery) Compounds not contained in the parallel data are always split, as they cannot be translated otherwise. 3 Data from the shared task of the EACL 2009 workshop on statistical machine translation: www.statmt.org/wmt09 2 84 use an English corpus of roughly 227 million words (including the English part of the parallel data) to build a target-side 5-gram language model with SRILM (Stolcke, 2002) in combination with KENLM (Heafield, 2011). For parameter"
W14-5709,W03-1810,0,0.218336,"1957; Harris, 1968) that ”you shall know a word by the company it keeps”, distributional semantics exploits the co-occurrence of words in corpora to explore the meanings and the similarities of the words, phrases, sentences, etc. of interest. Among many other tasks, distributional semantic information has been utilised to determine the degree of compositionality (or: semantic transparency) of various types of compounds, most notably regarding noun compounds (e.g., Zinsmeister and Heid (2004), Reddy et al. (2011), Schulte im Walde et al. (2013), Salehi et al. (2014)) and particle verbs (e.g., McCarthy et al. (2003), Bannard (2005), Cook and Stevenson (2006), K¨uhner and Schulte im Walde (2010), Bott and Schulte im Walde (2014), Salehi et al. (2014)). Typically, these approaches rely on co-occurrence information from a corpus (either referring to bagsof-words, or focusing on target-specific types of features), and compare the distributional features of the compounds with those of the constituents, in order to predict the degree of compositionality of the 82 SMT Preprocessing Holzzaun Jägerzaun Input Holz 0.311 Holz wooden Zaun 0.825 Zaun fence Jäger 0.015 Zaun 0.725 Step 1: Identify Component Words Step"
W14-5709,C00-2162,0,0.663192,"approaches. All lines of research improved translation performance due to compound splitting. In Koehn and Knight (2003), compounds are split through the identification of substrings from a corpus. The splitting is performed without linguistic knowledge (except for the insertion of the filler letters “(e)s”), which necessarily leads to many erroneous splittings. Multiple possible splitting options are disambiguated using the frequencies of the substrings. Starting from Koehn and Knight (2003), Stymne (2008) covers more morphological transformations and imposes POS constraints on the subwords. Nießen and Ney (2000) and Fritzinger and Fraser (2010) perform compound splitting by relying on morphological analysers to identify suitable split points. This has the advantage of returning only linguistically motivated splitting options, but the analyses are often ambiguous and require disambiguation: Nießen and Ney (2000) use a parser for context-sensitive disambiguation, and Fritzinger and Fraser (2010) use corpus frequencies to find the best split for each compound. Other approaches use a two-step word alignment process: first, word alignment is performed on a split representation of the compounding language."
W14-5709,J03-1002,0,0.00610431,"potentially infinite number of new forms. 4 Experimental Setting This section gives an overview on the technical details of the SMT system and our data sets. Compound splitting is applied to all source-language data, i.e. the parallel data used to train the model, as well as the input for parameter tuning and testing.2 Translation Model Moses is a state-of-the-art toolkit for phrase-based SMT systems (Koehn et al., 2007). We use it with default settings to train a translation model and we do so separately for each of the different compound splittings. Word alignment is performed using GIZA++ (Och and Ney, 2003). Feature weights are tuned using Batch-Mira (Cherry and Foster, 2012) with ’-safe-hope’ until convergence. Training Data Our parallel training data contains the Europarl corpus (version 4, cf. Koehn (2005)) and also newspaper texts, overall ca. 1.5 million sentences3 (roughly 44 million words). In addition, we 1 Baum|schule: ‘tree|school’ (tree nursery) Compounds not contained in the parallel data are always split, as they cannot be translated otherwise. 3 Data from the shared task of the EACL 2009 workshop on statistical machine translation: www.statmt.org/wmt09 2 84 use an English corpus of"
W14-5709,P02-1040,0,0.0997756,"Missing"
W14-5709,I11-1024,0,0.334105,"t of lexical semantic research over the past 20 years. Based on the distributional hypothesis (Firth, 1957; Harris, 1968) that ”you shall know a word by the company it keeps”, distributional semantics exploits the co-occurrence of words in corpora to explore the meanings and the similarities of the words, phrases, sentences, etc. of interest. Among many other tasks, distributional semantic information has been utilised to determine the degree of compositionality (or: semantic transparency) of various types of compounds, most notably regarding noun compounds (e.g., Zinsmeister and Heid (2004), Reddy et al. (2011), Schulte im Walde et al. (2013), Salehi et al. (2014)) and particle verbs (e.g., McCarthy et al. (2003), Bannard (2005), Cook and Stevenson (2006), K¨uhner and Schulte im Walde (2010), Bott and Schulte im Walde (2014), Salehi et al. (2014)). Typically, these approaches rely on co-occurrence information from a corpus (either referring to bagsof-words, or focusing on target-specific types of features), and compare the distributional features of the compounds with those of the constituents, in order to predict the degree of compositionality of the 82 SMT Preprocessing Holzzaun Jägerzaun Input Ho"
W14-5709,E14-1050,0,0.246781,". Based on the distributional hypothesis (Firth, 1957; Harris, 1968) that ”you shall know a word by the company it keeps”, distributional semantics exploits the co-occurrence of words in corpora to explore the meanings and the similarities of the words, phrases, sentences, etc. of interest. Among many other tasks, distributional semantic information has been utilised to determine the degree of compositionality (or: semantic transparency) of various types of compounds, most notably regarding noun compounds (e.g., Zinsmeister and Heid (2004), Reddy et al. (2011), Schulte im Walde et al. (2013), Salehi et al. (2014)) and particle verbs (e.g., McCarthy et al. (2003), Bannard (2005), Cook and Stevenson (2006), K¨uhner and Schulte im Walde (2010), Bott and Schulte im Walde (2014), Salehi et al. (2014)). Typically, these approaches rely on co-occurrence information from a corpus (either referring to bagsof-words, or focusing on target-specific types of features), and compare the distributional features of the compounds with those of the constituents, in order to predict the degree of compositionality of the 82 SMT Preprocessing Holzzaun Jägerzaun Input Holz 0.311 Holz wooden Zaun 0.825 Zaun fence Jäger 0.015"
W14-5709,schafer-bildhauer-2012-building,0,0.0426085,"Missing"
W14-5709,schmid-etal-2004-smor,0,0.115596,", whereas anfangen ‘begin’ is more opaque with respect to fangen ‘catch’. In contrast, einsetzen has both transparent (e.g. ‘insert’) and opaque (e.g. ‘begin’) verb senses with respect to setzen ‘put/sit (down)’. The high degree of ambiguity makes particle verbs a challenge for NLP. Moreover, particle and base verb can occur separately (er f¨angt an: ‘he begins’) or in one word (dass er anf¨angt: ‘that he begins’), depending on the clausal type. This makes consistent treatment of particle verbs difficult. 3.2 Identification of Component Parts We use the rule-based morphological analyser SMOR (Schmid et al., 2004) to identify compounds and their constituents in our parallel training data (cf. Section 4). It relies on a large lexicon of word lemmas and feature rules for productive morphological processes in German, i.e., compounding, derivation and 83 inflection. In this paper, we will not consider splitting into derivational affixes (as needed for, e.g., Arabic and Turkish), but instead identify simplex words that may also occur independently. Moreover, we only keep noun compounds and particle verbs consisting of two constituents. The resulting set consists of 93,299 noun compound types and 3,689 parti"
W14-5709,S13-1038,1,0.724142,"Missing"
W14-5709,P07-2045,0,\N,Missing
W15-1008,2009.eamt-1.9,0,0.0256613,"zed elements are often not adjacent. We use a morphology-aware SMT system which first translates into a lemmatized representation with a component to generate fully inflected forms in a second step, see Toutanova et al. (2008) and Fraser et al. (2012). The inflection step requires the modeling of the grammatical case of noun phrases, which corresponds to determining the syntactic function. Weller et al. (2013) describe modeling case in SMT; we extend their setup to cover the prediction of prepositions in both PP and NPs (i.e., the “empty” preposition). The presented work is similar to that of Agirre et al. (2009), but is applied to a fully statistical MT system. A detailed presentation of our work including a full literature survey can be found in Weller et al. (2015). Methodology To build the translation model, we use an abstract target-language representation in which nouns, adjectives and articles are lemmatized, and prepositions are substituted with place-holders. Additionally, “empty” place-holder prepositions are inserted at the beginning of noun phrases. To obtain a symmetric data structure, “empty” place-holders are also added to source-side NPs. When generating surface forms for the translati"
W15-1008,E12-1068,1,0.813073,"tep: all subcategorized elements of a verb are considered and allotted to their respective functions – as PPs with an overt preposition or as NPs with an “empty” preposition, e.g. to call for sth. → ∅ etw. erfordern. The language model and the translation rules often fail to correctly model subcategorization in standard SMT systems because verbs and their subcategorized elements are often not adjacent. We use a morphology-aware SMT system which first translates into a lemmatized representation with a component to generate fully inflected forms in a second step, see Toutanova et al. (2008) and Fraser et al. (2012). The inflection step requires the modeling of the grammatical case of noun phrases, which corresponds to determining the syntactic function. Weller et al. (2013) describe modeling case in SMT; we extend their setup to cover the prediction of prepositions in both PP and NPs (i.e., the “empty” preposition). The presented work is similar to that of Agirre et al. (2009), but is applied to a fully statistical MT system. A detailed presentation of our work including a full literature survey can be found in Weller et al. (2015). Methodology To build the translation model, we use an abstract target-l"
W15-1008,P08-1059,0,0.0327594,"ons in the post-processing step: all subcategorized elements of a verb are considered and allotted to their respective functions – as PPs with an overt preposition or as NPs with an “empty” preposition, e.g. to call for sth. → ∅ etw. erfordern. The language model and the translation rules often fail to correctly model subcategorization in standard SMT systems because verbs and their subcategorized elements are often not adjacent. We use a morphology-aware SMT system which first translates into a lemmatized representation with a component to generate fully inflected forms in a second step, see Toutanova et al. (2008) and Fraser et al. (2012). The inflection step requires the modeling of the grammatical case of noun phrases, which corresponds to determining the syntactic function. Weller et al. (2013) describe modeling case in SMT; we extend their setup to cover the prediction of prepositions in both PP and NPs (i.e., the “empty” preposition). The presented work is similar to that of Agirre et al. (2009), but is applied to a fully statistical MT system. A detailed presentation of our work including a full literature survey can be found in Weller et al. (2015). Methodology To build the translation model, we"
W15-1008,P13-1058,1,0.85305,"preposition, e.g. to call for sth. → ∅ etw. erfordern. The language model and the translation rules often fail to correctly model subcategorization in standard SMT systems because verbs and their subcategorized elements are often not adjacent. We use a morphology-aware SMT system which first translates into a lemmatized representation with a component to generate fully inflected forms in a second step, see Toutanova et al. (2008) and Fraser et al. (2012). The inflection step requires the modeling of the grammatical case of noun phrases, which corresponds to determining the syntactic function. Weller et al. (2013) describe modeling case in SMT; we extend their setup to cover the prediction of prepositions in both PP and NPs (i.e., the “empty” preposition). The presented work is similar to that of Agirre et al. (2009), but is applied to a fully statistical MT system. A detailed presentation of our work including a full literature survey can be found in Weller et al. (2015). Methodology To build the translation model, we use an abstract target-language representation in which nouns, adjectives and articles are lemmatized, and prepositions are substituted with place-holders. Additionally, “empty” place-ho"
W15-1008,W15-4923,1,0.781665,"fully inflected forms in a second step, see Toutanova et al. (2008) and Fraser et al. (2012). The inflection step requires the modeling of the grammatical case of noun phrases, which corresponds to determining the syntactic function. Weller et al. (2013) describe modeling case in SMT; we extend their setup to cover the prediction of prepositions in both PP and NPs (i.e., the “empty” preposition). The presented work is similar to that of Agirre et al. (2009), but is applied to a fully statistical MT system. A detailed presentation of our work including a full literature survey can be found in Weller et al. (2015). Methodology To build the translation model, we use an abstract target-language representation in which nouns, adjectives and articles are lemmatized, and prepositions are substituted with place-holders. Additionally, “empty” place-holder prepositions are inserted at the beginning of noun phrases. To obtain a symmetric data structure, “empty” place-holders are also added to source-side NPs. When generating surface forms for the translation output, a phrase with a place-holder preposition can be realized as a noun phrase (empty preposition) or as a prepositional phrase by generating the prepos"
W15-3007,W08-0509,0,0.0326054,"After decoding, some post-processing is required in order to retransform the underspecified representation into fluent German text. Our post-processing consists of the following steps: 1) translate into (split) underspecified German 2) merge compounds 3) predict nominal inflection 4) merge portmanteaus Finally, the output was recapitalised and detokenised using the shared task tools and all available German training data. We calculated BLEU scores using the NIST script version 11b. Phrase-based Translation Model For word alignment, we use the multi-threaded GIZA++ toolkit (Och and Ney, 2003; Gao and Vogel, 2008). 1 /mosesdecoder/scripts/ems/support/interpolate-lm.perl 87 Experiment submitted contrastive: Inflection submitted primary: Inflection Reordering Raw Raw Portmanteau Inflection Inflection Reordering Inflection Compounds Inflection Reordering Compounds news2014 BLEUci – – 19.92 19.83 19.86 20.35 19.08 19.65 news2015 BLEUci 21.46 21.65 21.44 21.54 21.49 21.64 20.43 21.19 Table 4: BLEU scores for all our systems. The upper part lists the submitted results (using a language model built on a subset of the available data), the lower part compares all our variants which have been computed after the"
W15-3007,E12-1074,1,0.928717,"grammatical case depends on the role of the NP in the sentence (e.g. subject or direct/indirect object) and is therefore 2.2 Reordering The different word order of clauses in English and German may often lead to misaligned verbal elements. While German verbs often occur in clause-final position, English verbs mostly appear in rigid SVO order. We parsed the English section of the parallel data with (Charniak and Johnson, 2005) using a model we trained on the standard Penn Treebank sections. The scripts we used for reordering the English input are similar to the ones we previously described in (Gojun and Fraser, 2012). Figure 2 illustrates how reordering 85 original source: re−ordered source: Meanwhile , we can offer the Commission a majority vote . Meanwhile , can we the Commission a majority vote offer . split target: Unterdessen können wir der Kommission ein Mehrheit Votum anbieten . original target: Unterdessen können wir der Kommission ein Mehrheitsvotum anbieten . Figure 2: Illustration of how re-ordering the English input may help to reduce crossing and long-distance alignments and how target-side compound splitting may transform 1:n into 1:1 alignments. More details can be found in (Cap et al., 201"
W15-3007,W11-2123,0,0.0197756,"ment with compound processing into each tuning iteration and thus scored the output against a non-split lemmatised reference. Language Model We trained 5-gram Language Models for each of the available German monolingual corpora and the German sections of the parallel data. For each corpus (the monolingual news corpora 07-14 and the parallel corpora europarl, commoncrawl and news), we built separate language models using the SRILM toolkit (Stolcke, 2002) with Kneser-Ney smoothing and then interpolated1 them using weights optimized on development data (cf. tuning set 08-13). We then used KenLM (Heafield, 2011) for faster processing. We performed this language model training for two different kinds of experiments: those without compound processing are trained on the underspecified (= lemmatised) representation, while those with compound processing are trained on a split underspecified representation. Testing After decoding, some post-processing is required in order to retransform the underspecified representation into fluent German text. Our post-processing consists of the following steps: 1) translate into (split) underspecified German 2) merge compounds 3) predict nominal inflection 4) merge portm"
W15-3007,E14-1061,1,0.680271,"d Fraser, 2012). Figure 2 illustrates how reordering 85 original source: re−ordered source: Meanwhile , we can offer the Commission a majority vote . Meanwhile , can we the Commission a majority vote offer . split target: Unterdessen können wir der Kommission ein Mehrheit Votum anbieten . original target: Unterdessen können wir der Kommission ein Mehrheitsvotum anbieten . Figure 2: Illustration of how re-ordering the English input may help to reduce crossing and long-distance alignments and how target-side compound splitting may transform 1:n into 1:1 alignments. More details can be found in (Cap et al., 2014a). the English input sentence can lead to less crossing and long-distance alignments. 2.3 3 Compound Processing Experimental Settings For the WMT shared task, we combined the three components which we have described in the previous section. An overview of all systems we trained can be found in Table 2. Data For all of our systems, we exclusively used data distributed for the WMT shared task 2015. We used all of the available monolingual data for German and all of the available parallel data for German and English. UTF8 Cleaning Even though the submitted training data is provided in UTF-8 enco"
W15-3007,E03-1076,0,0.124464,"nflection in German, only number and gender need to be modelled for French. to translating into English, which lead to improved translations. In (Gojun and Fraser, 2012), we switched the translation direction and reordered the English input sentence before translating into German, which in turn resulted in improved translation quality. Compound Processing In the past, there have been numerous attempts to address compound splitting for German to English. Almost every German to English SMT system nowadays incorporates some kind of compound processing, either using corpus-based word frequencies (Koehn and Knight, 2003), POS-contraints (Stymne et al., 2008), lattice-based approaches (Dyer, 2009) or language-independent segmentation (Macherey et al., 2011). In our work we have been using a rule-based morphological analyser combined with corpus statistics for compound splitting (Fritzinger and Fraser, 2010), a procedure which we have updated since that work. Details can be found in (Cap et al., 2014a). Data The EN–FR data set is much larger than that for EN–DE; after applying the same preprocessing steps, we obtained a parallel corpus of more than 36 million sentence pairs. For the language model, we used an a"
W15-3007,P07-2045,0,0.00969492,"Table 2: Names and components of our SMT systems; the submitted system are named CIMS-primary and CIMS. News Europarl CommonCrawl parallel data original encoding 272,807 1,920,209 2,399,123 4,592,139 203 24 17,508 17,735 length or ratio 1,381 17,637 7,489 37,221 not parseable 12,095 3,855 26,623 289,606 cleaned 259,128 1,898,693 2,347,503 4,505,324 Table 3: Overview of the parallel data after cleaning and pre-processing. English Variants The English source-side is mapped into British English in order to make the data as consistent as possible. Our translation models were trained using Moses (Koehn et al., 2007), following the instructions for a baseline shared task system, using default settigs. All our systems are trained identically – what differs is the degree to which the underlying training data has been modified. Linguistic Preprocessing The abstract representation for the nominal inflection requires the annotation of morphological features. After tokenization, we thus parsed all target-side data with BitPar (Schmid, 2004). To obtain the lemmas and suitable compound splittings, we applied SMOR (Schmid et al., 2004). Tuning We tuned feature weights using batchmira with ’safe–hope’ (Cherry and F"
W15-3007,P05-1022,0,0.037871,"oolkit (Lavergne et al., 2010). During feature prediction, the features that are set by the stem-markup (number, gender on nouns) are propagated over the rest of the linguistic phrase. In contrast, grammatical case depends on the role of the NP in the sentence (e.g. subject or direct/indirect object) and is therefore 2.2 Reordering The different word order of clauses in English and German may often lead to misaligned verbal elements. While German verbs often occur in clause-final position, English verbs mostly appear in rigid SVO order. We parsed the English section of the parallel data with (Charniak and Johnson, 2005) using a model we trained on the standard Penn Treebank sections. The scripts we used for reordering the English input are similar to the ones we previously described in (Gojun and Fraser, 2012). Figure 2 illustrates how reordering 85 original source: re−ordered source: Meanwhile , we can offer the Commission a majority vote . Meanwhile , can we the Commission a majority vote offer . split target: Unterdessen können wir der Kommission ein Mehrheit Votum anbieten . original target: Unterdessen können wir der Kommission ein Mehrheitsvotum anbieten . Figure 2: Illustration of how re-ordering the"
W15-3007,N12-1047,0,0.0211874,"t al., 2007), following the instructions for a baseline shared task system, using default settigs. All our systems are trained identically – what differs is the degree to which the underlying training data has been modified. Linguistic Preprocessing The abstract representation for the nominal inflection requires the annotation of morphological features. After tokenization, we thus parsed all target-side data with BitPar (Schmid, 2004). To obtain the lemmas and suitable compound splittings, we applied SMOR (Schmid et al., 2004). Tuning We tuned feature weights using batchmira with ’safe–hope’ (Cherry and Foster, 2012) until convergence (or up to 25 runs). We used the tuning data of all previous shared tasks from 2008 to 2013, which gave us 16,071 sentences for tuning. We tuned each experiment separately against an underspecified (i.e. lemmatised) version of the tuning reference optimising BLEU scores (Papineni et al., 2002). Note also that we integrated the CRF-based compound prediction and merging procedure for each experiment with compound processing into each tuning iteration and thus scored the output against a non-split lemmatised reference. Language Model We trained 5-gram Language Models for each of"
W15-3007,P10-1052,0,0.0427428,"Missing"
W15-3007,P11-1140,0,0.0160474,"s. In (Gojun and Fraser, 2012), we switched the translation direction and reordered the English input sentence before translating into German, which in turn resulted in improved translation quality. Compound Processing In the past, there have been numerous attempts to address compound splitting for German to English. Almost every German to English SMT system nowadays incorporates some kind of compound processing, either using corpus-based word frequencies (Koehn and Knight, 2003), POS-contraints (Stymne et al., 2008), lattice-based approaches (Dyer, 2009) or language-independent segmentation (Macherey et al., 2011). In our work we have been using a rule-based morphological analyser combined with corpus statistics for compound splitting (Fritzinger and Fraser, 2010), a procedure which we have updated since that work. Details can be found in (Cap et al., 2014a). Data The EN–FR data set is much larger than that for EN–DE; after applying the same preprocessing steps, we obtained a parallel corpus of more than 36 million sentence pairs. For the language model, we used an additional 45.9 million lines (news07-14 and newsdiscuss corpus). The language model was interpolated over separate language models built o"
W15-3007,P05-1066,0,0.107563,"Missing"
W15-3007,J03-1002,0,0.00633943,"esentation. Testing After decoding, some post-processing is required in order to retransform the underspecified representation into fluent German text. Our post-processing consists of the following steps: 1) translate into (split) underspecified German 2) merge compounds 3) predict nominal inflection 4) merge portmanteaus Finally, the output was recapitalised and detokenised using the shared task tools and all available German training data. We calculated BLEU scores using the NIST script version 11b. Phrase-based Translation Model For word alignment, we use the multi-threaded GIZA++ toolkit (Och and Ney, 2003; Gao and Vogel, 2008). 1 /mosesdecoder/scripts/ems/support/interpolate-lm.perl 87 Experiment submitted contrastive: Inflection submitted primary: Inflection Reordering Raw Raw Portmanteau Inflection Inflection Reordering Inflection Compounds Inflection Reordering Compounds news2014 BLEUci – – 19.92 19.83 19.86 20.35 19.08 19.65 news2015 BLEUci 21.46 21.65 21.44 21.54 21.49 21.64 20.43 21.19 Table 4: BLEU scores for all our systems. The upper part lists the submitted results (using a language model built on a subset of the available data), the lower part compares all our variants which have be"
W15-3007,N09-1046,0,0.0195409,"g into English, which lead to improved translations. In (Gojun and Fraser, 2012), we switched the translation direction and reordered the English input sentence before translating into German, which in turn resulted in improved translation quality. Compound Processing In the past, there have been numerous attempts to address compound splitting for German to English. Almost every German to English SMT system nowadays incorporates some kind of compound processing, either using corpus-based word frequencies (Koehn and Knight, 2003), POS-contraints (Stymne et al., 2008), lattice-based approaches (Dyer, 2009) or language-independent segmentation (Macherey et al., 2011). In our work we have been using a rule-based morphological analyser combined with corpus statistics for compound splitting (Fritzinger and Fraser, 2010), a procedure which we have updated since that work. Details can be found in (Cap et al., 2014a). Data The EN–FR data set is much larger than that for EN–DE; after applying the same preprocessing steps, we obtained a parallel corpus of more than 36 million sentence pairs. For the language model, we used an additional 45.9 million lines (news07-14 and newsdiscuss corpus). The language"
W15-3007,P02-1040,0,0.0923425,"the annotation of morphological features. After tokenization, we thus parsed all target-side data with BitPar (Schmid, 2004). To obtain the lemmas and suitable compound splittings, we applied SMOR (Schmid et al., 2004). Tuning We tuned feature weights using batchmira with ’safe–hope’ (Cherry and Foster, 2012) until convergence (or up to 25 runs). We used the tuning data of all previous shared tasks from 2008 to 2013, which gave us 16,071 sentences for tuning. We tuned each experiment separately against an underspecified (i.e. lemmatised) version of the tuning reference optimising BLEU scores (Papineni et al., 2002). Note also that we integrated the CRF-based compound prediction and merging procedure for each experiment with compound processing into each tuning iteration and thus scored the output against a non-split lemmatised reference. Language Model We trained 5-gram Language Models for each of the available German monolingual corpora and the German sections of the parallel data. For each corpus (the monolingual news corpora 07-14 and the parallel corpora europarl, commoncrawl and news), we built separate language models using the SRILM toolkit (Stolcke, 2002) with Kneser-Ney smoothing and then inter"
W15-3007,E12-1068,1,0.927953,"core correctly shows that there is not much difference in performance between the two systems. 6 Previous Work 7 Nominal Inflection The approach we use for nominal inflection prediction which was first described by (Toutanova et al., 2008). The approach consists of two steps: i) translate into an underspecified representation of German (most words being lemmatised) and ii) after translation predict inflectional endings depending on the actual context of the word(s). While developed for Russian and Arabic morphology, we adapted the approach of Toutanova et al. (2008) to the needs of German in (Fraser et al., 2012). In (Weller et al., 2013), we extended this work to use subcategorisation information and source-side syntactic features in order to improve the accuracy of case prediction. Note that we did not use this extension of our pipeline in the present shared task. Conclusion and Future Work In our submission to WMT 2015, we combined the three components nominal inflection, sourceside reordering and compound processing. We expected a positive effect on translation quality above the performance of each of these components when applied in isolation. While this effect was not evident in the obtained BLE"
W15-3007,C08-1098,0,0.0136356,"when judged by human annotators. This supports our hypothesis that morphological modeling in combination with reordering improves translation quality and is consistent with human evaluations of morphological modeling we have carried out in the past, see, e.g., (Weller et al., 2013; Cap et al., 2014a). 5 Additional Experiments: English to French translation In an additional set of experiments, we applied the nominal inflection system also to an English– French system. Nominal Inflection for French The general pipeline is the same as for translation into German. 88 We used RFTagger for French (Schmid and Laws, 2008) for morphological tagging and a French version of SMOR to generate inflected forms. The stem-markup on the French data corresponds to that of the German markup (number and gender on nouns). In contrast to four morphological features for nominal inflection in German, only number and gender need to be modelled for French. to translating into English, which lead to improved translations. In (Gojun and Fraser, 2012), we switched the translation direction and reordered the English input sentence before translating into German, which in turn resulted in improved translation quality. Compound Proces"
W15-3007,C04-1024,0,0.0110498,"h Variants The English source-side is mapped into British English in order to make the data as consistent as possible. Our translation models were trained using Moses (Koehn et al., 2007), following the instructions for a baseline shared task system, using default settigs. All our systems are trained identically – what differs is the degree to which the underlying training data has been modified. Linguistic Preprocessing The abstract representation for the nominal inflection requires the annotation of morphological features. After tokenization, we thus parsed all target-side data with BitPar (Schmid, 2004). To obtain the lemmas and suitable compound splittings, we applied SMOR (Schmid et al., 2004). Tuning We tuned feature weights using batchmira with ’safe–hope’ (Cherry and Foster, 2012) until convergence (or up to 25 runs). We used the tuning data of all previous shared tasks from 2008 to 2013, which gave us 16,071 sentences for tuning. We tuned each experiment separately against an underspecified (i.e. lemmatised) version of the tuning reference optimising BLEU scores (Papineni et al., 2002). Note also that we integrated the CRF-based compound prediction and merging procedure for each experi"
W15-3007,W11-2129,0,0.0188867,"re than 36 million sentence pairs. For the language model, we used an additional 45.9 million lines (news07-14 and newsdiscuss corpus). The language model was interpolated over separate language models built on the different corpora using the development set to obtain optimal weights. Results The results of the submitted systems are shown in the table below: Raw Nominal InflectionP BLEUci BLEUcs BLEUci BLEUcs 32.24 31.19 32.26 31.22 For compound merging, we translate from English into split and lemmatized German. Then, in a second step, compounds are merged using a CRFbased approach based on (Stymne and Cancedda, 2011) and then re-inflected using the nominal inflection procedure as described above. More details of our compound merging approach can be found in (Cap et al., 2014a). The nominal inflection system is our primary system. Due to the large amount of EN–FR parallel training data, we assume that here the BLEU score correctly shows that there is not much difference in performance between the two systems. 6 Previous Work 7 Nominal Inflection The approach we use for nominal inflection prediction which was first described by (Toutanova et al., 2008). The approach consists of two steps: i) translate into"
W15-3007,W08-0317,0,0.020342,"er need to be modelled for French. to translating into English, which lead to improved translations. In (Gojun and Fraser, 2012), we switched the translation direction and reordered the English input sentence before translating into German, which in turn resulted in improved translation quality. Compound Processing In the past, there have been numerous attempts to address compound splitting for German to English. Almost every German to English SMT system nowadays incorporates some kind of compound processing, either using corpus-based word frequencies (Koehn and Knight, 2003), POS-contraints (Stymne et al., 2008), lattice-based approaches (Dyer, 2009) or language-independent segmentation (Macherey et al., 2011). In our work we have been using a rule-based morphological analyser combined with corpus statistics for compound splitting (Fritzinger and Fraser, 2010), a procedure which we have updated since that work. Details can be found in (Cap et al., 2014a). Data The EN–FR data set is much larger than that for EN–DE; after applying the same preprocessing steps, we obtained a parallel corpus of more than 36 million sentence pairs. For the language model, we used an additional 45.9 million lines (news07-1"
W15-3007,P08-1059,0,0.0350702,"ounds are merged using a CRFbased approach based on (Stymne and Cancedda, 2011) and then re-inflected using the nominal inflection procedure as described above. More details of our compound merging approach can be found in (Cap et al., 2014a). The nominal inflection system is our primary system. Due to the large amount of EN–FR parallel training data, we assume that here the BLEU score correctly shows that there is not much difference in performance between the two systems. 6 Previous Work 7 Nominal Inflection The approach we use for nominal inflection prediction which was first described by (Toutanova et al., 2008). The approach consists of two steps: i) translate into an underspecified representation of German (most words being lemmatised) and ii) after translation predict inflectional endings depending on the actual context of the word(s). While developed for Russian and Arabic morphology, we adapted the approach of Toutanova et al. (2008) to the needs of German in (Fraser et al., 2012). In (Weller et al., 2013), we extended this work to use subcategorisation information and source-side syntactic features in order to improve the accuracy of case prediction. Note that we did not use this extension of o"
W15-3007,P13-1058,1,0.920801,"evaluation than a cluster containing a single system with a BLEU score of 22.6 (one BLEU point higher than our system). This shows clearly that BLEU underestimates the quality of our submission. Despite its comparatively low BLEU scores it is perceived to be of similar or better quality than systems with considerably higher BLEU scores when judged by human annotators. This supports our hypothesis that morphological modeling in combination with reordering improves translation quality and is consistent with human evaluations of morphological modeling we have carried out in the past, see, e.g., (Weller et al., 2013; Cap et al., 2014a). 5 Additional Experiments: English to French translation In an additional set of experiments, we applied the nominal inflection system also to an English– French system. Nominal Inflection for French The general pipeline is the same as for translation into German. 88 We used RFTagger for French (Schmid and Laws, 2008) for morphological tagging and a French version of SMOR to generate inflected forms. The stem-markup on the French data corresponds to that of the German markup (number and gender on nouns). In contrast to four morphological features for nominal inflection in"
W15-3007,W10-1734,1,\N,Missing
W15-3007,schmid-etal-2004-smor,0,\N,Missing
W15-4923,2009.eamt-1.9,0,0.417564,"In addition, we compare prepositions in the machine translation output with those in the reference translation for a selected subset. Finally, we discuss examples illustrating typical problems of translating prepositions. 2 Related Work Most research on translating prepositions has been reported for rule-based systems. Naskar and Bandyopadhyay (2006) outline a method to handle prepositions in an English-Bengali MT system using WordNet and an example base for idiomatic PPs. Gustavii (2005) uses bilingual features and selectional constraints to correct translations in a Swedish-English system. Agirre et al. (2009) model Basque prepositions and grammatical case using syntactic-semantic features such as subcategorization triples for a rule-based system which leads to an improved translation quality for prepositions. Shilon et al. (2012) extend this approach 177 input ∅ −→ what role ∅ −→ the giant planet has played in −→ the development of −→ the solar system lemmatized SMT output PREP welch<PWAT> Rolle<+NN><Fem><Sg> PREP die<+ART><Def> riesig<ADJ> Planet<+NN><Masc><Sg> gespielt<VVPP> hat<VAFIN> PREP die<+ART><Def> Entwicklung<+NN><Fem><Sg> PREP die<+ART><Def> Sonnensystem<+NN><Neut><Sg> prep ∅-Acc Acc Ac"
W15-4923,E12-1068,1,0.894077,"the governing verb and governed noun in the translation output match with the reference translation. Conceptually, this is loosely related to semantically focused metrics (e.g. MEANT, Lo and Wu (2011)), as we go beyond a “ﬂat” n-gram matching but evaluate a meaningful entity, in our case a preposition-noun-verb triple. 3 Methodology Our approach is integrated into an English-German morphology-aware SMT system which ﬁrst translates into a lemmatized representation with a component to generate fully inﬂected forms in a second step, an approach similar to the work by Toutanova et al. (2008) and Fraser et al. (2012). The inﬂection requires the modeling of the grammatical case of noun phrases (among other features), which corresponds to determining the syntactic function1 . Weller et al. (2013) describe modeling case in SMT; we want to treat all subcategorized elements of a verb in one step and extend their setup to cover the prediction of prepositions in both PP and NPs (i.e., the “empty” preposition). 3.1 Translation and Prediction Steps To build the translation model, we use an abstract target-language representation in which nouns, adjectives and articles are lemmatized and prepositions are substitute"
W15-4923,2005.eamt-1.16,0,0.0342591,"and (ii) how to predict prepositions in the translation output using a combination of source and targetside information. In addition, we compare prepositions in the machine translation output with those in the reference translation for a selected subset. Finally, we discuss examples illustrating typical problems of translating prepositions. 2 Related Work Most research on translating prepositions has been reported for rule-based systems. Naskar and Bandyopadhyay (2006) outline a method to handle prepositions in an English-Bengali MT system using WordNet and an example base for idiomatic PPs. Gustavii (2005) uses bilingual features and selectional constraints to correct translations in a Swedish-English system. Agirre et al. (2009) model Basque prepositions and grammatical case using syntactic-semantic features such as subcategorization triples for a rule-based system which leads to an improved translation quality for prepositions. Shilon et al. (2012) extend this approach 177 input ∅ −→ what role ∅ −→ the giant planet has played in −→ the development of −→ the solar system lemmatized SMT output PREP welch<PWAT> Rolle<+NN><Fem><Sg> PREP die<+ART><Def> riesig<ADJ> Planet<+NN><Masc><Sg> gespielt<VV"
W15-4923,P10-1052,0,0.168043,"Missing"
W15-4923,P11-1023,0,0.0612315,"hey use a classiﬁer trained on local contextual features to predict whether to generate or remove determiners for the target-side of translation rules. Another related task is error correction of second language learners, e.g. Rozovskaya and Roth (2013), which also comprises the correction of prepositions. In addition to the standard evaluation metric BLEU, we evaluate the accuracy of prepositions in cases where the governing verb and governed noun in the translation output match with the reference translation. Conceptually, this is loosely related to semantically focused metrics (e.g. MEANT, Lo and Wu (2011)), as we go beyond a “ﬂat” n-gram matching but evaluate a meaningful entity, in our case a preposition-noun-verb triple. 3 Methodology Our approach is integrated into an English-German morphology-aware SMT system which ﬁrst translates into a lemmatized representation with a component to generate fully inﬂected forms in a second step, an approach similar to the work by Toutanova et al. (2008) and Fraser et al. (2012). The inﬂection requires the modeling of the grammatical case of noun phrases (among other features), which corresponds to determining the syntactic function1 . Weller et al. (2013)"
W15-4923,W06-2113,0,0.0370603,"eneration model in an English-German morphology-aware SMT system. We study two aspects: (i) features for a meaningful abstract representation of prepositions and (ii) how to predict prepositions in the translation output using a combination of source and targetside information. In addition, we compare prepositions in the machine translation output with those in the reference translation for a selected subset. Finally, we discuss examples illustrating typical problems of translating prepositions. 2 Related Work Most research on translating prepositions has been reported for rule-based systems. Naskar and Bandyopadhyay (2006) outline a method to handle prepositions in an English-Bengali MT system using WordNet and an example base for idiomatic PPs. Gustavii (2005) uses bilingual features and selectional constraints to correct translations in a Swedish-English system. Agirre et al. (2009) model Basque prepositions and grammatical case using syntactic-semantic features such as subcategorization triples for a rule-based system which leads to an improved translation quality for prepositions. Shilon et al. (2012) extend this approach 177 input ∅ −→ what role ∅ −→ the giant planet has played in −→ the development of −→"
W15-4923,D13-1074,0,0.026895,"appropriate translation rules, whereas we generate prepositions in a post-processing step. A related task to generating prepositions is the generation of determiners, which are problematic when translating from languages without deﬁniteness morphemes, e.g. Czech or Russian. Tsvetkov et al. (2013) create synthetic translation options to augment a standard phrase-table. They use a classiﬁer trained on local contextual features to predict whether to generate or remove determiners for the target-side of translation rules. Another related task is error correction of second language learners, e.g. Rozovskaya and Roth (2013), which also comprises the correction of prepositions. In addition to the standard evaluation metric BLEU, we evaluate the accuracy of prepositions in cases where the governing verb and governed noun in the translation output match with the reference translation. Conceptually, this is loosely related to semantically focused metrics (e.g. MEANT, Lo and Wu (2011)), as we go beyond a “ﬂat” n-gram matching but evaluate a meaningful entity, in our case a preposition-noun-verb triple. 3 Methodology Our approach is integrated into an English-German morphology-aware SMT system which ﬁrst translates in"
W15-4923,schmid-etal-2004-smor,0,0.0792705,"setup and results of our experiments. In addition to the traditional metric BLEU, we assess the quality of the translated prepositions for a subset where relevant elements (verb, noun) match with the reference. Finally, we discuss some examples before concluding the paper. 6.1 Data and Experimental Setup We trained a standard phrase-based Moses system on 4.3M lines of EN–DE data (WMT’14) with a 10.3M sentence language model. For the lemmatized representation of the morphologyaware SMT system, the German part was parsed with BitPar (Schmid, 2004) and analyzed with the morphological tool SMOR (Schmid et al., 2004). The models for predicting inﬂectional features and prepositions were built with the Wapiti toolkit (Lavergne et al., 2010). The inﬂectional models (case, number, gender strong/weak) were trained on lemma and tag information of the German part Evaluation with BLEU Table 4 shows the results of experiments with the baseline system (a), a morphology-aware SMT system with no special treatment for prepositions4 . As a variant of the baseline system (b), we removed all prepositions from the translation output to be re-predicted. This does not lead to much change in BLEU, illustrating that the predi"
W15-4923,C04-1024,0,0.0189533,"reposition. 6 Experiments and Evaluation Here, we present the setup and results of our experiments. In addition to the traditional metric BLEU, we assess the quality of the translated prepositions for a subset where relevant elements (verb, noun) match with the reference. Finally, we discuss some examples before concluding the paper. 6.1 Data and Experimental Setup We trained a standard phrase-based Moses system on 4.3M lines of EN–DE data (WMT’14) with a 10.3M sentence language model. For the lemmatized representation of the morphologyaware SMT system, the German part was parsed with BitPar (Schmid, 2004) and analyzed with the morphological tool SMOR (Schmid et al., 2004). The models for predicting inﬂectional features and prepositions were built with the Wapiti toolkit (Lavergne et al., 2010). The inﬂectional models (case, number, gender strong/weak) were trained on lemma and tag information of the German part Evaluation with BLEU Table 4 shows the results of experiments with the baseline system (a), a morphology-aware SMT system with no special treatment for prepositions4 . As a variant of the baseline system (b), we removed all prepositions from the translation output to be re-predicted. Th"
W15-4923,W12-0514,0,0.164234,"Related Work Most research on translating prepositions has been reported for rule-based systems. Naskar and Bandyopadhyay (2006) outline a method to handle prepositions in an English-Bengali MT system using WordNet and an example base for idiomatic PPs. Gustavii (2005) uses bilingual features and selectional constraints to correct translations in a Swedish-English system. Agirre et al. (2009) model Basque prepositions and grammatical case using syntactic-semantic features such as subcategorization triples for a rule-based system which leads to an improved translation quality for prepositions. Shilon et al. (2012) extend this approach 177 input ∅ −→ what role ∅ −→ the giant planet has played in −→ the development of −→ the solar system lemmatized SMT output PREP welch<PWAT> Rolle<+NN><Fem><Sg> PREP die<+ART><Def> riesig<ADJ> Planet<+NN><Masc><Sg> gespielt<VVPP> hat<VAFIN> PREP die<+ART><Def> Entwicklung<+NN><Fem><Sg> PREP die<+ART><Def> Sonnensystem<+NN><Neut><Sg> prep ∅-Acc Acc Acc ∅-Nom Nom Nom Nom – – bei-Dat Dat Dat ∅-Gen Gen Gen morph. feat. – Acc.Fem.Sg.Wk Acc.Fem.Sg.Wk – Nom.Masc.Sg.St Nom.Masc.Sg.Wk Nom.Masc.Sg.Wk – – – Dat.Fem.Sg.St Dat.Fem.Sg.Wk – Gen.Neut.Sg.St Gen.Neut.Sg.Wk inﬂected gloss"
W15-4923,P08-1059,0,0.219634,"prepositions in cases where the governing verb and governed noun in the translation output match with the reference translation. Conceptually, this is loosely related to semantically focused metrics (e.g. MEANT, Lo and Wu (2011)), as we go beyond a “ﬂat” n-gram matching but evaluate a meaningful entity, in our case a preposition-noun-verb triple. 3 Methodology Our approach is integrated into an English-German morphology-aware SMT system which ﬁrst translates into a lemmatized representation with a component to generate fully inﬂected forms in a second step, an approach similar to the work by Toutanova et al. (2008) and Fraser et al. (2012). The inﬂection requires the modeling of the grammatical case of noun phrases (among other features), which corresponds to determining the syntactic function1 . Weller et al. (2013) describe modeling case in SMT; we want to treat all subcategorized elements of a verb in one step and extend their setup to cover the prediction of prepositions in both PP and NPs (i.e., the “empty” preposition). 3.1 Translation and Prediction Steps To build the translation model, we use an abstract target-language representation in which nouns, adjectives and articles are lemmatized and pr"
W15-4923,W13-2234,0,0.331521,"ler et al. (2014) use noun class information as tree labels in syntactic SMT to model selectional preferences of prepositions. The presented work is similar to that of Agirre et al. (2009), but is applied to a fully statistical MT system. The main difference is that Agirre et al. (2009) use linguistic information to select appropriate translation rules, whereas we generate prepositions in a post-processing step. A related task to generating prepositions is the generation of determiners, which are problematic when translating from languages without deﬁniteness morphemes, e.g. Czech or Russian. Tsvetkov et al. (2013) create synthetic translation options to augment a standard phrase-table. They use a classiﬁer trained on local contextual features to predict whether to generate or remove determiners for the target-side of translation rules. Another related task is error correction of second language learners, e.g. Rozovskaya and Roth (2013), which also comprises the correction of prepositions. In addition to the standard evaluation metric BLEU, we evaluate the accuracy of prepositions in cases where the governing verb and governed noun in the translation output match with the reference translation. Conceptu"
W15-4923,P13-1058,1,0.799055,"NT, Lo and Wu (2011)), as we go beyond a “ﬂat” n-gram matching but evaluate a meaningful entity, in our case a preposition-noun-verb triple. 3 Methodology Our approach is integrated into an English-German morphology-aware SMT system which ﬁrst translates into a lemmatized representation with a component to generate fully inﬂected forms in a second step, an approach similar to the work by Toutanova et al. (2008) and Fraser et al. (2012). The inﬂection requires the modeling of the grammatical case of noun phrases (among other features), which corresponds to determining the syntactic function1 . Weller et al. (2013) describe modeling case in SMT; we want to treat all subcategorized elements of a verb in one step and extend their setup to cover the prediction of prepositions in both PP and NPs (i.e., the “empty” preposition). 3.1 Translation and Prediction Steps To build the translation model, we use an abstract target-language representation in which nouns, adjectives and articles are lemmatized and prepositions are substituted with place-holders. Additionally, “empty” place-holder prepositions are inserted at the beginning of noun phrases. To obtain a symmetric data structure, place-holders for “empty”"
W15-4923,2014.amta-researchers.21,1,0.852767,"∅-Gen Gen Gen morph. feat. – Acc.Fem.Sg.Wk Acc.Fem.Sg.Wk – Nom.Masc.Sg.St Nom.Masc.Sg.Wk Nom.Masc.Sg.Wk – – – Dat.Fem.Sg.St Dat.Fem.Sg.Wk – Gen.Neut.Sg.St Gen.Neut.Sg.Wk inﬂected gloss welche Rolle which role der riesige Planet gespielt hat bei der Entwicklung the giant planet played has for the development des Sonnensystems of-the solar system Figure 1: Prediction of prepositions, morphological features and generation of inﬂected forms for the lemmatized SMT output. German cases: Acc-Accusative, Nom-Nominative, Dat-Dative, Gen-Genitive. with a statistical component for ranking translations. Weller et al. (2014) use noun class information as tree labels in syntactic SMT to model selectional preferences of prepositions. The presented work is similar to that of Agirre et al. (2009), but is applied to a fully statistical MT system. The main difference is that Agirre et al. (2009) use linguistic information to select appropriate translation rules, whereas we generate prepositions in a post-processing step. A related task to generating prepositions is the generation of determiners, which are problematic when translating from languages without deﬁniteness morphemes, e.g. Czech or Russian. Tsvetkov et al. ("
W15-4923,P11-2121,0,\N,Missing
W16-2203,P05-1022,0,0.12384,", the use of tense underlies strict rules, the use of tenses in German often follows from the register (spoken vs. written) or even from the author’s stylistic preferences (e.g. (Sammon, 2002), (Collins and Hollo, 2010)). 4.1.2 Example habenV AF IN sagenV V P P VAFIN, VVPP 1.Sg.Past.Subj if VP consists of an auxiliary (VAFIN) and a participle (VVPP) and if the finite verb is Past.Subj ⇒ konjunktivII (past subjunctive)’ 4.2.2 Mood Data The training instances are extracted from Europarl, News Commentary and Crawled corpus. The English part of the corpus is parsed with the constituent parser of (Charniak and Johnson, 2005), while the German data is stemmed (cf. Section 2.2). We use the automatically computed word alignment (Och and Ney, 2003) in order to identify verb pairs in a given sentence pair. We work with a set of 8 labels which includes six German tenses and the two subjunctive moods (see Table 3). In the training data, the labels are annotated by rule-based mapping of the German VPs. We use information about the verbs, their POS tags, as well as the morphological analysis of the finite verb to derive labels for each German VP (see Table 2 for an example mapping). The distribution of the labels in the c"
W16-2203,E14-1063,0,0.0167788,"al. (2013) found that a narrativity feature helps to translate the English past tense into one of the possible French tenses. Tense switch We observed sentence pairs in which the English is written in past tense, while in German, present tense is used. Obviously, there are contexts in which tense switches are allowed. We assume that these sentences are headlines which allow for this kind of tense variation. Evaluation of the verbs The final question we raise is how to evaluate translations with respect to information related to discourse such as tense and modality (or negation as discussed by Fancellu and Webber (2014)). Automatic evaluation such as BLEU is not appropriate since it compares the translation with the reference mainly on the lexical level. What about human evaluation? Our evaluators have a Kappa score of 0.33 which is rather low. The humans thus allow for a certain variance in tense/mood translation which metrics like BLEU cannot capture given only one reference translation. Ideally, we would have multiple references in which all possible tenses are given. Creating such an evaluation test set could be done by gap-filling method proposed by Hardmeier (2014) for evaluation of pronoun translation"
W16-2203,E12-1068,1,0.825832,"verb agrees with the subject. We show that this approach improves subject-verb agreement. We model tense/mood translation from English to German by means of a statistical classification model. Although our model shows good results on wellformed data, it does not systematically improve tense and mood in MT output. Reasons include the need for discourse knowledge, dependency on the domain, and stylistic variety in how tense/mood is translated. We present a thorough analysis of these problems. 1 In this paper, we reimplement the nominal inflection modeling for translation to German presented by Fraser et al. (2012) and combine it with the reordering of the source data (Gojun and Fraser, 2012). In a novel extension, we present a method for correction of the agreement errors, and an approach for modeling the translation of tense and mood from English into German. While the subject-verb agreement problems are dealt with successfully, modeling of tense/mood translation is problematic due to many reasons which we will analyze in detail. Introduction Statistical machine translation of English into German faces two main problems involving verbs: (i) correct placement of the verbs, and (ii) generation of the ap"
W16-2203,E12-1074,1,0.908121,"erb agreement. We model tense/mood translation from English to German by means of a statistical classification model. Although our model shows good results on wellformed data, it does not systematically improve tense and mood in MT output. Reasons include the need for discourse knowledge, dependency on the domain, and stylistic variety in how tense/mood is translated. We present a thorough analysis of these problems. 1 In this paper, we reimplement the nominal inflection modeling for translation to German presented by Fraser et al. (2012) and combine it with the reordering of the source data (Gojun and Fraser, 2012). In a novel extension, we present a method for correction of the agreement errors, and an approach for modeling the translation of tense and mood from English into German. While the subject-verb agreement problems are dealt with successfully, modeling of tense/mood translation is problematic due to many reasons which we will analyze in detail. Introduction Statistical machine translation of English into German faces two main problems involving verbs: (i) correct placement of the verbs, and (ii) generation of the appropriate inflection for the verb. The position of verbs in German and English"
W16-2203,D12-1026,0,0.122736,"nd Ye et al. (2006) observed that sequential dependence of the tenses is not as strong as expected. In the bilingual context, there seems to be a strong dependence on the tense in the source language. Statistics about the number of clauses in the sentences shown in Figure 4, shows that our data mostly consists of simple sentences containing only one clause (i.e. one finite verb). In other words, for most of the sentences, an intra-sentence tense sequence is simply not given. Inter-sentence tense modeling, i.e., across sentence boundaries, could be more reasonable, as for example, presented by Gong et al. (2012) for Chinese to English SMT. Language–pair specific features Ye et al. (2006) presented thoughts about the knowledge that human translators use. The aim was to use this knowledge to model tense translation for Chinese– English. For this specific language pair (and possibly for the corpus used), the knowledge about temporal ordering of the actions was the key information. On the other hand, for English–French, Meyer et al. (2013) found that a narrativity feature helps to translate the English past tense into one of the possible French tenses. Tense switch We observed sentence pairs in which the"
W16-2203,P14-6007,0,0.0273238,"or negation as discussed by Fancellu and Webber (2014)). Automatic evaluation such as BLEU is not appropriate since it compares the translation with the reference mainly on the lexical level. What about human evaluation? Our evaluators have a Kappa score of 0.33 which is rather low. The humans thus allow for a certain variance in tense/mood translation which metrics like BLEU cannot capture given only one reference translation. Ideally, we would have multiple references in which all possible tenses are given. Creating such an evaluation test set could be done by gap-filling method proposed by Hardmeier (2014) for evaluation of pronoun translation. Tense interchangeability It seems that in numerous contexts, tense translation can sometimes even be a matter of taste. Sammon (2002) states that in German the imperfect and perfect are interchangeable in many contexts, the difference between the two tenses being largely stylistic. A similar example is reported speech where Konjunktiv I, Konjunktiv II and indicative tenses are often used interchangeably (Csipak, 2015). Sequential problem It is also not very clear whether the tense/mood is to be dealt with as a 4 Guidelines for translations into German us"
W16-2203,P08-1087,0,0.0350425,"a et al. (2012) reported on different results achieved for different test sets. Another possibility is to use a classification model which predicts agreement features of the verbs using various contextual information as successfully applied on English–Spanish (Gispert and Mari˜no, 2008). Our attempt to build such a model for German, led to disappointing results: on the one hand, a more accurate identification of the subjects in the English constituent parse trees is required: the use of the dependency trees combined with pronoun resolution (similar to a simple pronoun resolution described in (Avramidis and Koehn, 2008)) might reduce this problem. More correct subject identification in the source language is however not sufficient: due to syntactic divergences, the German subject may match other constituents in the source language (e.g. object or preposition phrase). A prediction model having access to information extracted from both English dependency trees, as well as German MT parses (in combination with clues on the reliability of the extracted information) might give good results regarding the prediction of agreement features for German finite verbs. 6.2 Tense and mood Register/domain Looking at Figure"
W16-2203,P10-1052,0,0.172639,"Missing"
W16-2203,D13-1032,0,0.0604081,"Missing"
W16-2203,J03-1002,0,0.0115262,"from the author’s stylistic preferences (e.g. (Sammon, 2002), (Collins and Hollo, 2010)). 4.1.2 Example habenV AF IN sagenV V P P VAFIN, VVPP 1.Sg.Past.Subj if VP consists of an auxiliary (VAFIN) and a participle (VVPP) and if the finite verb is Past.Subj ⇒ konjunktivII (past subjunctive)’ 4.2.2 Mood Data The training instances are extracted from Europarl, News Commentary and Crawled corpus. The English part of the corpus is parsed with the constituent parser of (Charniak and Johnson, 2005), while the German data is stemmed (cf. Section 2.2). We use the automatically computed word alignment (Och and Ney, 2003) in order to identify verb pairs in a given sentence pair. We work with a set of 8 labels which includes six German tenses and the two subjunctive moods (see Table 3). In the training data, the labels are annotated by rule-based mapping of the German VPs. We use information about the verbs, their POS tags, as well as the morphological analysis of the finite verb to derive labels for each German VP (see Table 2 for an example mapping). The distribution of the labels in the corpora we use is given in Table 3. For each finite verb, a training instance with features from English and German paralle"
W16-2203,P02-1040,0,0.0958167,"ated with BLEU. The difference in performance gained on test sets from different domains (although small) raises the question whether the classifier is solely to be trained on in-domain data. Since we work with MT output of the news test set, we would have to train the classifier only on the news data. Due to the corpus size (272k sentences), we get into sparsity problems since many lexical features are used. A further reason for using additional (outof-domain) training data are low-frequent labels which then get more training instances. 5.2.1 Automatic evaluation In Table 7, the BLEU scores (Papineni et al., 2002) of the MT output with predicted verbal inflection are presented. Surface Baseline Verbal inflection Agreement Tense/mood In summary, the evaluation indicates that a single classifier leads to different results when applied on data from different domains. Furthermore, the initial experiments showed that having better results on the clean data does not necessarily lead to better results for the noisy MT output. BLEUci 21.59 22.00 22.05 22.08 21.95 Table 7: BLEU scores of MT outputs with corrected verbal inflection. 3 26 http://www.statmt.org/wmt15/ SRC1 BL 5.2.2 VI correct Verbal inflection den"
W16-2203,W12-3146,0,0.0392091,"Missing"
W16-2203,P98-2193,0,0.257303,"Missing"
W16-2203,schmid-etal-2004-smor,0,0.153058,"rect verbal inflection is unresolved. In fact, the reordering makes the agreement problems even worse due to movements of verbs away from their subjects (cf. Section 3.1). 2.2 Agreement − parse − find SV pairs Medikamente + können − map subject morph to verb 3.Pl Past.Subj Generate − SMOR − stem + morph features können + 3.Pl.Past.Subj könnten Figure 1: Processing pipeline. The verbal inflection modeling consists of two components: (i) a component for deriving agreement features person and number, and (ii) a component for predicting tense and mood. The inflected verbs are generated with SMOR (Schmid et al., 2004), a morphology generation tool for German. baseline by identifying finite verbs in the baseline MT output, predicting their morphological features and finally producing the correct inflected output (see Figure 1). Verbal morphological features include information about person/number, as well as tense and mood. Particularly the modeling of tense/mood translation is interesting: in this paper, we present a method to model the translation of English tense and mood into German considering all German tenses/moods in a single model. In addition, we present a detailed discussion which is, to our know"
W16-2203,P12-2039,0,0.0722527,"Missing"
W16-2203,W06-0107,0,0.0834361,"Missing"
W16-2203,W13-3305,0,\N,Missing
W16-2203,W15-2210,0,\N,Missing
W16-2205,2009.eamt-1.9,0,0.0329357,"phrase-table entries allows to create prepositions in contexts not observed in the parallel training data. The resulting phrase-table entries are unique for each context and provide the best selection of translation options in terms of complement realization on token-level. This variant significantly outperforms the baseline, and is slightly better than the system with inserted placeholder prepositions. 2 the number of missing/wrong content and function words. For the language pair English–German, the combined number of missing/wrong/added prepositions is one of the most observed error types. Agirre et al. (2009) were among the first to use rich linguistic information to model prepositions and grammatical case in Basque within a rule-based system, leading to an improved translation quality for prepositions. Their work is extended by Shilon et al. (2012) with a statistical component for ranking translations. Weller et al. (2013) use a combination of source-side and target-side features to predict grammatical case on the SMT output, but without taking into account different complement types (NP vs. PP). Weller et al. (2015) predict prepositions as a post-processing step to a translation system in which"
W16-2205,D07-1007,0,0.0242699,"target language to obtain more isomorphic parallel data. Also, we translate into the morphologically rich language, which requires morphological modeling with regard to, e.g., grammatical case and portmanteau prepositions (cf. section 3) to ensure morphologically correct output. Related Work Our work is related to three research areas: using source-side information, previous approaches to model case and prepositions and the synthesis of phrase-table entries. Source-side information has been applied to SMT before, often for the purpose of word sense disambiguation and improving lexical choice (Carpuat and Wu, 2007; Gimpel and Smith, 2008; Jeong et al., 2010; Tamchyna et al., 2014), but without a focus on synthesis or syntactic-semantic aspects such as subcategorization. Prepositions are difficult to translate and responsible for many errors, as has been shown in many evaluations of machine translation. For example, Williams et al. (2015) presented a detailed error analysis of their shared task submissions, listing Synthetic phrases have been implemented by Chahuneau et al. (2013) to translate into morphologically rich languages. They use a discriminative model based on source-side features (dependency"
W16-2205,D13-1174,0,0.0175928,"de information has been applied to SMT before, often for the purpose of word sense disambiguation and improving lexical choice (Carpuat and Wu, 2007; Gimpel and Smith, 2008; Jeong et al., 2010; Tamchyna et al., 2014), but without a focus on synthesis or syntactic-semantic aspects such as subcategorization. Prepositions are difficult to translate and responsible for many errors, as has been shown in many evaluations of machine translation. For example, Williams et al. (2015) presented a detailed error analysis of their shared task submissions, listing Synthetic phrases have been implemented by Chahuneau et al. (2013) to translate into morphologically rich languages. They use a discriminative model based on source-side features (dependency information and word clusters) to predict inflected target words based on which phrase-table entries 44 to aus[APPR-Dat] from unedel[ADJA] base Metall&lt;Neut>&lt;Pl>[NN] metals empty[APPR-Acc] emptyprep Gold&lt;Neut>&lt;Sg>[NN] gold into zu[PTKZU] to gold machen[VVINF] make transform nullprp base metals inflection of the respective phrase, too. Portmanteau prepositions (contracted forms of preposition and determiner) are split during the synthesizing and translation process, and ar"
W16-2205,W08-0302,0,0.0281093,"ain more isomorphic parallel data. Also, we translate into the morphologically rich language, which requires morphological modeling with regard to, e.g., grammatical case and portmanteau prepositions (cf. section 3) to ensure morphologically correct output. Related Work Our work is related to three research areas: using source-side information, previous approaches to model case and prepositions and the synthesis of phrase-table entries. Source-side information has been applied to SMT before, often for the purpose of word sense disambiguation and improving lexical choice (Carpuat and Wu, 2007; Gimpel and Smith, 2008; Jeong et al., 2010; Tamchyna et al., 2014), but without a focus on synthesis or syntactic-semantic aspects such as subcategorization. Prepositions are difficult to translate and responsible for many errors, as has been shown in many evaluations of machine translation. For example, Williams et al. (2015) presented a detailed error analysis of their shared task submissions, listing Synthetic phrases have been implemented by Chahuneau et al. (2013) to translate into morphologically rich languages. They use a discriminative model based on source-side features (dependency information and word clu"
W16-2205,W15-3024,0,0.0423433,"ch areas: using source-side information, previous approaches to model case and prepositions and the synthesis of phrase-table entries. Source-side information has been applied to SMT before, often for the purpose of word sense disambiguation and improving lexical choice (Carpuat and Wu, 2007; Gimpel and Smith, 2008; Jeong et al., 2010; Tamchyna et al., 2014), but without a focus on synthesis or syntactic-semantic aspects such as subcategorization. Prepositions are difficult to translate and responsible for many errors, as has been shown in many evaluations of machine translation. For example, Williams et al. (2015) presented a detailed error analysis of their shared task submissions, listing Synthetic phrases have been implemented by Chahuneau et al. (2013) to translate into morphologically rich languages. They use a discriminative model based on source-side features (dependency information and word clusters) to predict inflected target words based on which phrase-table entries 44 to aus[APPR-Dat] from unedel[ADJA] base Metall&lt;Neut>&lt;Pl>[NN] metals empty[APPR-Acc] emptyprep Gold&lt;Neut>&lt;Sg>[NN] gold into zu[PTKZU] to gold machen[VVINF] make transform nullprp base metals inflection of the respective phrase,"
W16-2205,2010.amta-papers.33,0,0.0258573,"llel data. Also, we translate into the morphologically rich language, which requires morphological modeling with regard to, e.g., grammatical case and portmanteau prepositions (cf. section 3) to ensure morphologically correct output. Related Work Our work is related to three research areas: using source-side information, previous approaches to model case and prepositions and the synthesis of phrase-table entries. Source-side information has been applied to SMT before, often for the purpose of word sense disambiguation and improving lexical choice (Carpuat and Wu, 2007; Gimpel and Smith, 2008; Jeong et al., 2010; Tamchyna et al., 2014), but without a focus on synthesis or syntactic-semantic aspects such as subcategorization. Prepositions are difficult to translate and responsible for many errors, as has been shown in many evaluations of machine translation. For example, Williams et al. (2015) presented a detailed error analysis of their shared task submissions, listing Synthetic phrases have been implemented by Chahuneau et al. (2013) to translate into morphologically rich languages. They use a discriminative model based on source-side features (dependency information and word clusters) to predict in"
W16-2205,P10-1052,0,0.0733414,"Missing"
W16-2205,schmid-etal-2004-smor,0,0.0300869,"Missing"
W16-2205,C04-1024,0,0.019651,"number, gender, case and strong/weak for inflecting the stemmed output, we trained 4 CRF sequence models on the target-side of the parallel data. These features are predicted as a sequence of labels (i.e. case/number/etc of consecutive words in an NP/PP) at sentence level. For the prediction of the placeholder prepositions, we trained a maximum entropy model on the parallel training data. In contrast to the morphological features, each preposition in a phrase is predicted independently. For all models, we used the toolkit Wapiti (Lavergne et al., 2010). The German data was parsed with BitPar (Schmid, 2004) and German inflected forms were generated with the morphological resource SMOR (Schmid et al., 2004). 6.2 7 In this section, we summarize the results and in particular, discuss the use of newly generated phrases. We also attempt to analyze potential side-effects on the phrase table and present additional experiments to better handle these effects. Baselines We consider two baselines: BASELINE -1: a standard phrase-based translation system trained on surface forms without any form of morphological modeling. BASELINE -2: a system with morphological modeling, as described in section 3. Portmante"
W16-2205,W12-0514,0,0.0242226,"t realization on token-level. This variant significantly outperforms the baseline, and is slightly better than the system with inserted placeholder prepositions. 2 the number of missing/wrong content and function words. For the language pair English–German, the combined number of missing/wrong/added prepositions is one of the most observed error types. Agirre et al. (2009) were among the first to use rich linguistic information to model prepositions and grammatical case in Basque within a rule-based system, leading to an improved translation quality for prepositions. Their work is extended by Shilon et al. (2012) with a statistical component for ranking translations. Weller et al. (2013) use a combination of source-side and target-side features to predict grammatical case on the SMT output, but without taking into account different complement types (NP vs. PP). Weller et al. (2015) predict prepositions as a post-processing step to a translation system in which prepositions are reduced to placeholders. They find, however, that the reduced representation leads to a general loss in translation quality. Experiments with annotating abstract information to the placeholders indicated that grammatical case pl"
W16-2205,W15-3021,0,0.014543,"aceholders. They find, however, that the reduced representation leads to a general loss in translation quality. Experiments with annotating abstract information to the placeholders indicated that grammatical case plays an important role during translation. We build on their observations, but in contrast with generating prepositions in a post-processing step, prepositions in our work are accessible to the system during decoding, and the phrase-table entries are optimized with regard to the source-sentence. Finnish is a highly inflective language with a very complex case and preposition system. Tiedemann et al. (2015) experimented with pseudo-tokens added to Finnish data to account for the fact that Finnish morphological markers (case) often correspond to a separate English word (typically a preposition). Due to the complexity of Finnish, only a subset of markers is considered. The pseudo-tokens are applied to a Finnish–English translation system, but a manual evaluation remains inconclusive about the effectiveness of their method. For the preposition-informed representation in our work, we adapt both source and target language to obtain more isomorphic parallel data. Also, we translate into the morphologi"
W16-2205,P08-1059,0,0.0388851,"features (dependency information and word clusters) to predict inflected target words based on which phrase-table entries 44 to aus[APPR-Dat] from unedel[ADJA] base Metall&lt;Neut>&lt;Pl>[NN] metals empty[APPR-Acc] emptyprep Gold&lt;Neut>&lt;Sg>[NN] gold into zu[PTKZU] to gold machen[VVINF] make transform nullprp base metals inflection of the respective phrase, too. Portmanteau prepositions (contracted forms of preposition and determiner) are split during the synthesizing and translation process, and are merged after the inflection step. For more details about modeling complex morphology, see for example Toutanova et al. (2008), Fraser et al. (2012) or Chahuneau et al. (2013). Figure 1: Example for preposition-informed representation with empty placeholders heading NPs. 4 Our first approach introduces a simple abstract representation that inserts pseudo-preposition markers to indicate the beginning of noun phrases. This representation serves two purposes: to adjust the source and target sides for structural mismatches of different complement types, and to provide information about syntactic functions and semantic roles via the annotation of grammatical case. Placeholders for empty prepositions are inserted at the be"
W16-2205,W13-2234,0,0.024745,"rovement in translation quality for several language pairs. In contrast, our approach concentrates on the generation of closed-class function words to obtain the most appropriate complement type given the source sentence. This includes generating word sequences not observed in the training data, i.e. adding/changing prepositions for a (different) PP or removing prepositions to form an NP. A task related to synthesizing prepositions is that of generating determiners, the translation of which is problematic when translating from a language like Russian that does not have definiteness morphemes. Tsvetkov et al. (2013) create synthetic translation options to augment the phrase-table. They use a classifier trained on local contextual features to predict whether to add or remove determiners for the target-side of translation rules. In contrast with determiners, which are local to their context, we model and generate function words with semantic content which are subject to complex interactions with verbs and other subcategorized elements throughout the sentence. 3 Preposition-Informed Representation Inflection Prediction System We work with an inflection prediction system which first translates into a stemmed"
W16-2205,P13-1058,1,0.845029,"eline, and is slightly better than the system with inserted placeholder prepositions. 2 the number of missing/wrong content and function words. For the language pair English–German, the combined number of missing/wrong/added prepositions is one of the most observed error types. Agirre et al. (2009) were among the first to use rich linguistic information to model prepositions and grammatical case in Basque within a rule-based system, leading to an improved translation quality for prepositions. Their work is extended by Shilon et al. (2012) with a statistical component for ranking translations. Weller et al. (2013) use a combination of source-side and target-side features to predict grammatical case on the SMT output, but without taking into account different complement types (NP vs. PP). Weller et al. (2015) predict prepositions as a post-processing step to a translation system in which prepositions are reduced to placeholders. They find, however, that the reduced representation leads to a general loss in translation quality. Experiments with annotating abstract information to the placeholders indicated that grammatical case plays an important role during translation. We build on their observations, bu"
W16-2205,E12-1068,1,\N,Missing
W16-2205,P11-2121,0,\N,Missing
W16-2205,W15-4923,1,\N,Missing
W16-2205,W14-3324,0,\N,Missing
W16-2210,P13-1141,1,0.857525,"Missing"
W16-2210,P07-1005,0,0.108569,"Missing"
W16-2210,N12-1047,0,0.0696872,"Missing"
W16-2210,N09-1025,0,0.0247122,"e X2 , practical X1 X2 i (r2 ) X → h X1 pratique X2 , X1 X2 practice i (r3 ) X → h X1 pratique X2 , X2 X1 process i F1 Une e´ tude de l’ (int´erˆet)X1 pratique (de notre approche)X2 . A study on the (interest)X1 practical (of our approach)X2 . E A study on the practical (interest)X1 (of our approach)X2 . The rule scoring heuristics defined by (Chiang, 2005) do not handle rule selection in a satisfactory way and many authors have come up with solutions. Models that use the syntactic structure of the source and target sentence have been proposed by (Marton and Resnik, 2008; Marton et al., 2012; Chiang et al., 2009; Chiang, 2010; Liu et al., 2011). These approaches exclusively take into account syntactic structure and do not model rule selection (see Section 6 for a detailed discussion). Following the work on phrase-sense disambiguation by (Carpuat and Wu, 2007), other authors improve rule selection by defining features on the structure of hierarchical rules and combining these with information about the source sentence (Chan et al., 2007; He et al., 2008; He et al., 2010; Cui et al., 2010). In these approaches, rule selection is the task of selecting the target side of a rule given its source side as w"
W16-2210,P10-1146,0,0.0275418,"2 i (r2 ) X → h X1 pratique X2 , X1 X2 practice i (r3 ) X → h X1 pratique X2 , X2 X1 process i F1 Une e´ tude de l’ (int´erˆet)X1 pratique (de notre approche)X2 . A study on the (interest)X1 practical (of our approach)X2 . E A study on the practical (interest)X1 (of our approach)X2 . The rule scoring heuristics defined by (Chiang, 2005) do not handle rule selection in a satisfactory way and many authors have come up with solutions. Models that use the syntactic structure of the source and target sentence have been proposed by (Marton and Resnik, 2008; Marton et al., 2012; Chiang et al., 2009; Chiang, 2010; Liu et al., 2011). These approaches exclusively take into account syntactic structure and do not model rule selection (see Section 6 for a detailed discussion). Following the work on phrase-sense disambiguation by (Carpuat and Wu, 2007), other authors improve rule selection by defining features on the structure of hierarchical rules and combining these with information about the source sentence (Chan et al., 2007; He et al., 2008; He et al., 2010; Cui et al., 2010). In these approaches, rule selection is the task of selecting the target side of a rule given its source side as well as context"
W16-2210,chrupala-etal-2008-learning,0,0.0702923,"Missing"
W16-2210,P10-2002,0,0.211377,"structure of the source and target sentence have been proposed by (Marton and Resnik, 2008; Marton et al., 2012; Chiang et al., 2009; Chiang, 2010; Liu et al., 2011). These approaches exclusively take into account syntactic structure and do not model rule selection (see Section 6 for a detailed discussion). Following the work on phrase-sense disambiguation by (Carpuat and Wu, 2007), other authors improve rule selection by defining features on the structure of hierarchical rules and combining these with information about the source sentence (Chan et al., 2007; He et al., 2008; He et al., 2010; Cui et al., 2010). In these approaches, rule selection is the task of selecting the target side of a rule given its source side as well as contextual information about the source sentence. This task is modeled as a multiclass classification problem. Because of the very large size of hierarchical grammars, the training procedure for discriminative rule selection models is typically very expensive: multiclass classification is performed over Introduction Hierarchical phrase-based machine translation (Chiang, 2005) performs non-local reordering in a formally syntax-based way. It allows flexible rule extraction an"
W16-2210,C08-1041,0,0.223471,"ns. Models that use the syntactic structure of the source and target sentence have been proposed by (Marton and Resnik, 2008; Marton et al., 2012; Chiang et al., 2009; Chiang, 2010; Liu et al., 2011). These approaches exclusively take into account syntactic structure and do not model rule selection (see Section 6 for a detailed discussion). Following the work on phrase-sense disambiguation by (Carpuat and Wu, 2007), other authors improve rule selection by defining features on the structure of hierarchical rules and combining these with information about the source sentence (Chan et al., 2007; He et al., 2008; He et al., 2010; Cui et al., 2010). In these approaches, rule selection is the task of selecting the target side of a rule given its source side as well as contextual information about the source sentence. This task is modeled as a multiclass classification problem. Because of the very large size of hierarchical grammars, the training procedure for discriminative rule selection models is typically very expensive: multiclass classification is performed over Introduction Hierarchical phrase-based machine translation (Chiang, 2005) performs non-local reordering in a formally syntax-based way. I"
W16-2210,J96-1002,0,0.335164,"Missing"
W16-2210,D10-1054,0,0.235429,"se the syntactic structure of the source and target sentence have been proposed by (Marton and Resnik, 2008; Marton et al., 2012; Chiang et al., 2009; Chiang, 2010; Liu et al., 2011). These approaches exclusively take into account syntactic structure and do not model rule selection (see Section 6 for a detailed discussion). Following the work on phrase-sense disambiguation by (Carpuat and Wu, 2007), other authors improve rule selection by defining features on the structure of hierarchical rules and combining these with information about the source sentence (Chan et al., 2007; He et al., 2008; He et al., 2010; Cui et al., 2010). In these approaches, rule selection is the task of selecting the target side of a rule given its source side as well as contextual information about the source sentence. This task is modeled as a multiclass classification problem. Because of the very large size of hierarchical grammars, the training procedure for discriminative rule selection models is typically very expensive: multiclass classification is performed over Introduction Hierarchical phrase-based machine translation (Chiang, 2005) performs non-local reordering in a formally syntax-based way. It allows flexible"
W16-2210,P13-2121,0,0.0440768,"Missing"
W16-2210,2009.iwslt-papers.4,0,0.020779,"er a hierarchical baseline while our global model with exhaustive training yields significant improvements on scientific and medical texts (see Section 4). In a second contribution, we successfully scale rule selection models to large scale translation tasks but fail to produce significant improvements in BLEU over a hierarchical baseline on these tasks. Because our approach needs scaling to a large amount of training examples, we need a classifier that is fast and supports online streaming. We use the high-speed classifier Vowpal Wabbit2 (VW) which we fully integrate in the syntax component (Hoang et al., 2009) of the Moses machine translation toolkit (Koehn et al., 2007). To allow researchers to replicate our results and improve on our work, we make our implementation publicly available as part of Moses. 2 Global Rule Selection Model The goal of rule selection is to choose the correct target side of a hierarchical rule, given a source side as well as other sources of information such as the shape of the rule or its context of application in the source sentence. The latter includes lexical features (e.g. the words surrounding the source span of an applied rule) or syntactic features (e.g. the positi"
W16-2210,D07-1007,0,0.0402698,"udy on the practical (interest)X1 (of our approach)X2 . The rule scoring heuristics defined by (Chiang, 2005) do not handle rule selection in a satisfactory way and many authors have come up with solutions. Models that use the syntactic structure of the source and target sentence have been proposed by (Marton and Resnik, 2008; Marton et al., 2012; Chiang et al., 2009; Chiang, 2010; Liu et al., 2011). These approaches exclusively take into account syntactic structure and do not model rule selection (see Section 6 for a detailed discussion). Following the work on phrase-sense disambiguation by (Carpuat and Wu, 2007), other authors improve rule selection by defining features on the structure of hierarchical rules and combining these with information about the source sentence (Chan et al., 2007; He et al., 2008; He et al., 2010; Cui et al., 2010). In these approaches, rule selection is the task of selecting the target side of a rule given its source side as well as contextual information about the source sentence. This task is modeled as a multiclass classification problem. Because of the very large size of hierarchical grammars, the training procedure for discriminative rule selection models is typically"
W16-2210,D07-1103,0,0.0635156,"Missing"
W16-2210,P07-2045,0,0.00618631,"ive training yields significant improvements on scientific and medical texts (see Section 4). In a second contribution, we successfully scale rule selection models to large scale translation tasks but fail to produce significant improvements in BLEU over a hierarchical baseline on these tasks. Because our approach needs scaling to a large amount of training examples, we need a classifier that is fast and supports online streaming. We use the high-speed classifier Vowpal Wabbit2 (VW) which we fully integrate in the syntax component (Hoang et al., 2009) of the Moses machine translation toolkit (Koehn et al., 2007). To allow researchers to replicate our results and improve on our work, we make our implementation publicly available as part of Moses. 2 Global Rule Selection Model The goal of rule selection is to choose the correct target side of a hierarchical rule, given a source side as well as other sources of information such as the shape of the rule or its context of application in the source sentence. The latter includes lexical features (e.g. the words surrounding the source span of an applied rule) or syntactic features (e.g. the position of an applied rule in the source parse tree). The rule sele"
W16-2210,P13-1111,0,0.0299038,"Missing"
W16-2210,W04-3250,0,0.233709,"Missing"
W16-2210,D08-1010,0,0.0427009,"Missing"
W16-2210,2011.mtsummit-papers.28,0,0.0360245,"h X1 pratique X2 , X1 X2 practice i (r3 ) X → h X1 pratique X2 , X2 X1 process i F1 Une e´ tude de l’ (int´erˆet)X1 pratique (de notre approche)X2 . A study on the (interest)X1 practical (of our approach)X2 . E A study on the practical (interest)X1 (of our approach)X2 . The rule scoring heuristics defined by (Chiang, 2005) do not handle rule selection in a satisfactory way and many authors have come up with solutions. Models that use the syntactic structure of the source and target sentence have been proposed by (Marton and Resnik, 2008; Marton et al., 2012; Chiang et al., 2009; Chiang, 2010; Liu et al., 2011). These approaches exclusively take into account syntactic structure and do not model rule selection (see Section 6 for a detailed discussion). Following the work on phrase-sense disambiguation by (Carpuat and Wu, 2007), other authors improve rule selection by defining features on the structure of hierarchical rules and combining these with information about the source sentence (Chan et al., 2007; He et al., 2008; He et al., 2010; Cui et al., 2010). In these approaches, rule selection is the task of selecting the target side of a rule given its source side as well as contextual information abo"
W16-2210,P08-1114,0,0.035715,"BLEU on these tasks. 1 (r1 ) X → h X1 pratique X2 , practical X1 X2 i (r2 ) X → h X1 pratique X2 , X1 X2 practice i (r3 ) X → h X1 pratique X2 , X2 X1 process i F1 Une e´ tude de l’ (int´erˆet)X1 pratique (de notre approche)X2 . A study on the (interest)X1 practical (of our approach)X2 . E A study on the practical (interest)X1 (of our approach)X2 . The rule scoring heuristics defined by (Chiang, 2005) do not handle rule selection in a satisfactory way and many authors have come up with solutions. Models that use the syntactic structure of the source and target sentence have been proposed by (Marton and Resnik, 2008; Marton et al., 2012; Chiang et al., 2009; Chiang, 2010; Liu et al., 2011). These approaches exclusively take into account syntactic structure and do not model rule selection (see Section 6 for a detailed discussion). Following the work on phrase-sense disambiguation by (Carpuat and Wu, 2007), other authors improve rule selection by defining features on the structure of hierarchical rules and combining these with information about the source sentence (Chan et al., 2007; He et al., 2008; He et al., 2010; Cui et al., 2010). In these approaches, rule selection is the task of selecting the target"
W16-2210,P02-1040,0,0.0953472,"Missing"
W16-2210,P06-1055,0,0.0763415,"Missing"
W16-2315,J07-2003,0,0.142484,"erarchical grammar that the system can use for serial concatenation of phrases as in monotonic phrase-based translation. In the Moses implementation, the decoder internally adds a sentence start terminal symbol &lt;s> and a sentence end terminal symbol &lt;/s> to the input before and after each sentence, respectively. Therefore, two more special rules S → h&lt;s>, &lt;s>i S → hS∼0 &lt;/s>, S∼0 &lt;/s>i 2.1 (2) are included which allow the decoder to finalize its translations. Hierarchical search is conducted with a customized version of the CYK+ parsing algorithm (Chappelier and Rajman, 1998) and cube pruning (Chiang, 2007). A hypergraph which represents the whole parsing space is built employing CYK+. Cube pruning operates in bottom-up topological order on this hypergraph and expands at most k derivations at each hypernode. All our experiments are run with the open source Moses implementation (Hoang et al., 2009) of the hierarchical phrase-based translation paradigm. 2 (1) System Overview Hierarchical Phrase-Based Translation In hierarchical phrase-based translation, a probabilistic synchronous context-free grammar is induced from bilingual training corpora. In addition to continuous lexical phrases as in stand"
W16-2315,W06-1607,0,0.0385299,"ted weight. Baseline Setup The features of our plain hierarchical phrase-based baseline are: CommonCrawl LM training data. A large Romanian CommonCrawl corpus has been released for the constrained track of the WMT16 shared task for machine translation of news. In our system, we utilize this corpus by adding it to the training data of the background LM. We append it to the concatenation of news2015, Europarl, and SETimes2 data and estimate a bigger background LM. • Rule translation log-probabilities in both target-to-source and source-to-target direction, smoothed with Good-Turing discounting (Foster et al., 2006). • Lexical translation log-probabilities in both target-to-source and source-to-target direction. • Seven binary features indicating absolute occurrence count classes of translation rules (with count classes 1, 2, 3, 4, 5-6, 7-10, >10). 6 Pruned individual LMs are trained with KenLM’s --prune '0 0 1' parameters. Weights for linear LM interpolation are optimized on newsdev2016_1. 313 Pruned vs. unpruned LMs. We compare pruned and unpruned language models. In the pruned versions of the models, singleton n-grams of order three and higher are discarded, whereas all n-grams are kept in the unprune"
W16-2315,W16-2304,0,0.12408,"cted from the parallel training corpus. Extracted rules of a standard hierarchical grammar are of the form X → hα, β ,∼ i where hα, β i 2.2 Data and Preprocessing Our system is trained using only permissible Romanian monolingual and English–Romanian parallel corpora provided by the organizers of the WMT16 shared task for machine translation of news: Europarl (Koehn, 2005), SETimes2 (Tyers and Alperen, 2010), News Crawl articles from 2015 (denoted as news2015 hereafter), and CommonCrawl (Buck et al., 2014). The target side of the data is preprocessed with tokro, LIMSI’s tokenizer for Romanian (Allauzen et al., 2016).5 The English source side is tokenized using the tokenizer.perl script from the Moses toolkit. Romanian and English sentences are both frequent-cased (with Moses’ truecase.perl). 5 https://perso.limsi.fr/aufrant/ software/tokro 312 • An indicator feature that fires on applications of the glue rule. • Word penalty. • Rule penalty. • A 5-gram language model. We split the development set newsdev2016 into two halves (newsdev2016_1 with the first 1000 sentences and newsdev2016_2 with the last 999 sentences). During the system building process, we measure progress by evaluating on newsdev2016_2 as"
W16-2315,2011.iwslt-evaluation.18,0,0.0230414,"e compare pruned and unpruned language models. In the pruned versions of the models, singleton n-grams of order three and higher are discarded, whereas all n-grams are kept in the unpruned versions. We follow the approach outlined by Huck et al. (2011) to augment the system with the synthetic parallel data. A foreground phrase table extracted from the human-generated parallel data is filled up with entries from a background phrase table extracted from the synthetic parallel data. An entry from the background table is only added if the foreground table does not already contain a similar entry (Bisazza et al., 2011). A binary feature distinguishes background phrases from foreground phrases. For the background phrase table, we extract only lexical phrases (i.e., phrases without non-terminals on their right-hand side) from the synthetic parallel data, no hierarchical phrases. The phrase length for entries of the background table is restricted to a maximum number of five terminal symbols on the source side. Lexical scores over the phrases extracted from synthetic data are calculated with a lexicon model learned from the human-generated parallel data, as proposed by Huck and Ney (2012). More hierarchical rul"
W16-2315,E14-2008,1,0.83418,"malized as a synchronous context-free grammar. We integrate several non-standard enhancements into our hierarchical phrase-based system and empirically evaluate their impact on translation quality. Our system is furthermore one component in a combination of systems by members of the HimL project and another EU-funded project, QT21.3 Measured in B LEU (Papineni et al., 2002), the QT21/HimL submission yields top translation quality amongst the shared task submissions.4 The QT21/HimL submission highlights the continued success of system combinations based on the Jane machine translation toolkit (Freitag et al., 2014a) in open evaluation campaigns (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). A description of the QT21/HimL combined submission is given by Peter et al. (2016). This paper describes the hierarchical phrase-based machine translation system built jointly by the University of Edinburgh and the University of Munich (LMU) for the shared translation task at the ACL 2016 First Conference on Machine Translation (WMT16). The WMT16 Edinburgh/LMU system was trained for translation of news domain texts from English into Romanian. We participated in the shared task for machine tran"
W16-2315,J93-2003,0,0.0655029,"Missing"
W16-2315,W14-3310,1,0.882823,"malized as a synchronous context-free grammar. We integrate several non-standard enhancements into our hierarchical phrase-based system and empirically evaluate their impact on translation quality. Our system is furthermore one component in a combination of systems by members of the HimL project and another EU-funded project, QT21.3 Measured in B LEU (Papineni et al., 2002), the QT21/HimL submission yields top translation quality amongst the shared task submissions.4 The QT21/HimL submission highlights the continued success of system combinations based on the Jane machine translation toolkit (Freitag et al., 2014a) in open evaluation campaigns (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). A description of the QT21/HimL combined submission is given by Peter et al. (2016). This paper describes the hierarchical phrase-based machine translation system built jointly by the University of Edinburgh and the University of Munich (LMU) for the shared translation task at the ACL 2016 First Conference on Machine Translation (WMT16). The WMT16 Edinburgh/LMU system was trained for translation of news domain texts from English into Romanian. We participated in the shared task for machine tran"
W16-2315,buck-etal-2014-n,0,0.0874284,"Missing"
W16-2315,2014.iwslt-evaluation.7,1,0.880814,"malized as a synchronous context-free grammar. We integrate several non-standard enhancements into our hierarchical phrase-based system and empirically evaluate their impact on translation quality. Our system is furthermore one component in a combination of systems by members of the HimL project and another EU-funded project, QT21.3 Measured in B LEU (Papineni et al., 2002), the QT21/HimL submission yields top translation quality amongst the shared task submissions.4 The QT21/HimL submission highlights the continued success of system combinations based on the Jane machine translation toolkit (Freitag et al., 2014a) in open evaluation campaigns (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). A description of the QT21/HimL combined submission is given by Peter et al. (2016). This paper describes the hierarchical phrase-based machine translation system built jointly by the University of Edinburgh and the University of Munich (LMU) for the shared translation task at the ACL 2016 First Conference on Machine Translation (WMT16). The WMT16 Edinburgh/LMU system was trained for translation of news domain texts from English into Romanian. We participated in the shared task for machine tran"
W16-2315,N12-1047,0,0.074748,"; Koehn et al., 2003) to the two trained alignments. We extract synchronous context-free grammar rules that are consistent with the symmetrized word alignment from the parallel training data. We train 5-gram language models (LMs) with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). KenLM (Heafield, 2011) is employed for LM training and scoring, and SRILM (Stolcke, 2002) for linear LM interpolation. Our translation model incorporates a number of different features in a log-linear combination (Och and Ney, 2002). We tune the feature weights with batch k-best M IRA (Cherry and Foster, 2012) to maximize B LEU (Papineni et al., 2002) on a development set. We run M IRA for 25 iterations on 200-best lists. 2.4 2.5 Enhancements We now describe modifications that we apply on top of the baseline. The results of the empirical evaluation will be given in Section 3. Linear LM interpolation vs. individual LMs as features in the log-linear combination. Rather than employing a linearly interpolated LM, we integrate the individual LMs trained over the separate corpora (news2015, Europarl, SETimes2) directly into the log-linear feature combination of the system and let M IRA optimize their wei"
W16-2315,D08-1089,0,0.0533428,"f words covered by non-terminals at extraction time. Phrase orientation model. We implemented a feature in Moses that resembles the phrase orientation model for hierarchical machine translation as described by Huck et al. (2013). The Huck et al. (2013) implementation had been released as part of the Jane toolkit (Vilar et al., 2010; Vilar et al., 2012; Huck et al., 2012). Our new Moses implementation technically operates in almost the same manner, except for minor implementation differences. Similarly to the type of lexicalized reordering models that are in common use in phrase-based systems (Galley and Manning, 2008), our model estimates the probabilities of orientation classes for each phrase (or: rule) from the training data. We use three orientation classes: monotone, swap, and discontinuous.7 Larger development data. Since no dedicated unseen test set was available during system building, newsdev2016 was split into its first half (newsdev2016_1) and its second half (newsdev2016_2) so that we could tune on the first half and keep the second half untouched for evaluating progress in translation quality with the various enhancements. For the final system (our primary submission), we took the best configu"
W16-2315,W08-0509,0,0.0437082,"_1 is utilized for tuning. 2.3 We discard rules with non-terminals on their right-hand side if they are singletons in the training data. The baseline language model is a linear interpolation of three 5-gram LMs trained over the Romanian news2015, Europarl, and SETimes2 training data, respectively, with pruning of singleton n-grams of order three and higher.6 We run the Moses chart-based decoder with cube pruning, configured at a maximum chart span of 25 and otherwise default settings. Training and Tuning We create word alignments by aligning the bilingual data in both directions with MGIZA++ (Gao and Vogel, 2008). We use a sequence of IBM word alignment models (Brown et al., 1993) with five iterations of EM training (Dempster et al., 1977) of Model 1, three iterations of Model 3, and three iterations of Model 4. After EM, we obtain a symmetrized alignment by applying the grow-diag-final-and heuristic (Och and Ney, 2003; Koehn et al., 2003) to the two trained alignments. We extract synchronous context-free grammar rules that are consistent with the symmetrized word alignment from the parallel training data. We train 5-gram language models (LMs) with modified Kneser-Ney smoothing (Kneser and Ney, 1995;"
W16-2315,2005.mtsummit-papers.11,0,0.104257,"S is the start symbol of the grammar. The generic non-terminal X is used as a placeholder for the gaps within the right-hand side of hierarchical translation rules as well as on all left-hand sides of the translation rules that are extracted from the parallel training corpus. Extracted rules of a standard hierarchical grammar are of the form X → hα, β ,∼ i where hα, β i 2.2 Data and Preprocessing Our system is trained using only permissible Romanian monolingual and English–Romanian parallel corpora provided by the organizers of the WMT16 shared task for machine translation of news: Europarl (Koehn, 2005), SETimes2 (Tyers and Alperen, 2010), News Crawl articles from 2015 (denoted as news2015 hereafter), and CommonCrawl (Buck et al., 2014). The target side of the data is preprocessed with tokro, LIMSI’s tokenizer for Romanian (Allauzen et al., 2016).5 The English source side is tokenized using the tokenizer.perl script from the Moses toolkit. Romanian and English sentences are both frequent-cased (with Moses’ truecase.perl). 5 https://perso.limsi.fr/aufrant/ software/tokro 312 • An indicator feature that fires on applications of the glue rule. • Word penalty. • Rule penalty. • A 5-gram language"
W16-2315,W15-3013,1,0.839627,"h machine-translated English counterparts is utilized for lightly-supervised training (Schwenk, 2008) of our English→Romanian hierarchical system. 7 Using Moses’ Experiment Management System (EMS) (Koehn, 2010), the phrase orientation model for hierarchical machine translation can be activated by simply adding a line phrase-orientation = true to the [TRAINING] section of the EMS configuration file. 8 Whenever available, we typically attempt to use large development sets (in the order of a few thousand sentences), e.g. for Edinburgh’s phrase-based systems for the German– English language pair (Haddow et al., 2015). 314 en→ro newsdev2016_1 newsdev2016_2 newstest2016 baseline with interpolated LM over news2015, Europarl, SETimes2 + three individual LMs (replacing the interpolated LM) + background LM over concatenation of news2015, Europarl, SETimes2 + CommonCrawl LM training data in background LM + all LMs unpruned + more hierarchical rules + phrase orientation model + lightly-supervised training (contrastive submission system) + tuning on full newsdev2016 (primary submission system) 22.1 21.6 22.2 23.1 23.4 23.1 24.4 24.8 24.5 26.6 26.6 27.1 28.3 28.6 29.0 29.5 30.2 30.9 23.0 22.9 23.3 24.4 24.4 24.7 25"
W16-2315,P02-1038,0,0.264252,"lignment by applying the grow-diag-final-and heuristic (Och and Ney, 2003; Koehn et al., 2003) to the two trained alignments. We extract synchronous context-free grammar rules that are consistent with the symmetrized word alignment from the parallel training data. We train 5-gram language models (LMs) with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). KenLM (Heafield, 2011) is employed for LM training and scoring, and SRILM (Stolcke, 2002) for linear LM interpolation. Our translation model incorporates a number of different features in a log-linear combination (Och and Ney, 2002). We tune the feature weights with batch k-best M IRA (Cherry and Foster, 2012) to maximize B LEU (Papineni et al., 2002) on a development set. We run M IRA for 25 iterations on 200-best lists. 2.4 2.5 Enhancements We now describe modifications that we apply on top of the baseline. The results of the empirical evaluation will be given in Section 3. Linear LM interpolation vs. individual LMs as features in the log-linear combination. Rather than employing a linearly interpolated LM, we integrate the individual LMs trained over the separate corpora (news2015, Europarl, SETimes2) directly into th"
W16-2315,W11-2123,0,0.0606968,"alignment models (Brown et al., 1993) with five iterations of EM training (Dempster et al., 1977) of Model 1, three iterations of Model 3, and three iterations of Model 4. After EM, we obtain a symmetrized alignment by applying the grow-diag-final-and heuristic (Och and Ney, 2003; Koehn et al., 2003) to the two trained alignments. We extract synchronous context-free grammar rules that are consistent with the symmetrized word alignment from the parallel training data. We train 5-gram language models (LMs) with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). KenLM (Heafield, 2011) is employed for LM training and scoring, and SRILM (Stolcke, 2002) for linear LM interpolation. Our translation model incorporates a number of different features in a log-linear combination (Och and Ney, 2002). We tune the feature weights with batch k-best M IRA (Cherry and Foster, 2012) to maximize B LEU (Papineni et al., 2002) on a development set. We run M IRA for 25 iterations on 200-best lists. 2.4 2.5 Enhancements We now describe modifications that we apply on top of the baseline. The results of the empirical evaluation will be given in Section 3. Linear LM interpolation vs. individual"
W16-2315,J03-1002,0,0.0115423,"singleton n-grams of order three and higher.6 We run the Moses chart-based decoder with cube pruning, configured at a maximum chart span of 25 and otherwise default settings. Training and Tuning We create word alignments by aligning the bilingual data in both directions with MGIZA++ (Gao and Vogel, 2008). We use a sequence of IBM word alignment models (Brown et al., 1993) with five iterations of EM training (Dempster et al., 1977) of Model 1, three iterations of Model 3, and three iterations of Model 4. After EM, we obtain a symmetrized alignment by applying the grow-diag-final-and heuristic (Och and Ney, 2003; Koehn et al., 2003) to the two trained alignments. We extract synchronous context-free grammar rules that are consistent with the symmetrized word alignment from the parallel training data. We train 5-gram language models (LMs) with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). KenLM (Heafield, 2011) is employed for LM training and scoring, and SRILM (Stolcke, 2002) for linear LM interpolation. Our translation model incorporates a number of different features in a log-linear combination (Och and Ney, 2002). We tune the feature weights with batch k-best M IRA ("
W16-2315,2009.iwslt-papers.4,0,0.0920231,"sentence, respectively. Therefore, two more special rules S → h&lt;s>, &lt;s>i S → hS∼0 &lt;/s>, S∼0 &lt;/s>i 2.1 (2) are included which allow the decoder to finalize its translations. Hierarchical search is conducted with a customized version of the CYK+ parsing algorithm (Chappelier and Rajman, 1998) and cube pruning (Chiang, 2007). A hypergraph which represents the whole parsing space is built employing CYK+. Cube pruning operates in bottom-up topological order on this hypergraph and expands at most k derivations at each hypernode. All our experiments are run with the open source Moses implementation (Hoang et al., 2009) of the hierarchical phrase-based translation paradigm. 2 (1) System Overview Hierarchical Phrase-Based Translation In hierarchical phrase-based translation, a probabilistic synchronous context-free grammar is induced from bilingual training corpora. In addition to continuous lexical phrases as in standard phrase-based translation, hierarchical phrases with (usually) up to two non-terminals are extracted from the word-aligned parallel training data. The non-terminal set of a standard hierarchical grammar comprises two symbols which are shared by source and target: the initial symbol S and one"
W16-2315,P02-1040,0,0.0975049,"erarchical phrase-based translation (Chiang, 2005) for English→Romanian, a statistical machine translation paradigm that is closely related to phrasebased translation, but allows for phrases with gaps. Conceptionally, the translation model is formalized as a synchronous context-free grammar. We integrate several non-standard enhancements into our hierarchical phrase-based system and empirically evaluate their impact on translation quality. Our system is furthermore one component in a combination of systems by members of the HimL project and another EU-funded project, QT21.3 Measured in B LEU (Papineni et al., 2002), the QT21/HimL submission yields top translation quality amongst the shared task submissions.4 The QT21/HimL submission highlights the continued success of system combinations based on the Jane machine translation toolkit (Freitag et al., 2014a) in open evaluation campaigns (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). A description of the QT21/HimL combined submission is given by Peter et al. (2016). This paper describes the hierarchical phrase-based machine translation system built jointly by the University of Edinburgh and the University of Munich (LMU) for the shar"
W16-2315,2012.amta-papers.8,1,0.924532,"ain a similar entry (Bisazza et al., 2011). A binary feature distinguishes background phrases from foreground phrases. For the background phrase table, we extract only lexical phrases (i.e., phrases without non-terminals on their right-hand side) from the synthetic parallel data, no hierarchical phrases. The phrase length for entries of the background table is restricted to a maximum number of five terminal symbols on the source side. Lexical scores over the phrases extracted from synthetic data are calculated with a lexicon model learned from the human-generated parallel data, as proposed by Huck and Ney (2012). More hierarchical rules. The baseline synchronous context-free grammar rules in the phrase table are extracted from the parallel training data with Moses’ default settings: a maximum of five symbols on the source side, a maximum span of ten words, and no right-hand side non-terminal at gaps that cover only a single word on the source side. We allow for extraction of more hierarchical rules by applying less strict rule extraction constraints: a maximum of ten symbols on the source side, a maximum span of twenty words, and no lower limit to the amount of words covered by non-terminals at extra"
W16-2315,W11-2211,1,0.857685,"exploring non-standard enhancements and non-default configuration settings such as: • Individual language models as features, rather than a single linearly interpolated language model; and another background language model estimated over concatenated corpora. • Large CommonCrawl language model training data. • Unpruned language models. • More hierarchical rules than in default systems, by means of imposing less strict extraction constraints. • A phrase orientation model for hierarchical translation (Huck et al., 2013). • Lightly-supervised training (Schwenk, 2008; Schwenk and Senellart, 2009; Huck et al., 2011). • Larger development data for tuning. S → hS∼0 X ∼1 , S∼0 X ∼1 i is incorporated into the hierarchical grammar that the system can use for serial concatenation of phrases as in monotonic phrase-based translation. In the Moses implementation, the decoder internally adds a sentence start terminal symbol &lt;s> and a sentence end terminal symbol &lt;/s> to the input before and after each sentence, respectively. Therefore, two more special rules S → h&lt;s>, &lt;s>i S → hS∼0 &lt;/s>, S∼0 &lt;/s>i 2.1 (2) are included which allow the decoder to finalize its translations. Hierarchical search is conducted with a cus"
W16-2315,2009.mtsummit-posters.17,0,0.0231433,"with a focus of interest on exploring non-standard enhancements and non-default configuration settings such as: • Individual language models as features, rather than a single linearly interpolated language model; and another background language model estimated over concatenated corpora. • Large CommonCrawl language model training data. • Unpruned language models. • More hierarchical rules than in default systems, by means of imposing less strict extraction constraints. • A phrase orientation model for hierarchical translation (Huck et al., 2013). • Lightly-supervised training (Schwenk, 2008; Schwenk and Senellart, 2009; Huck et al., 2011). • Larger development data for tuning. S → hS∼0 X ∼1 , S∼0 X ∼1 i is incorporated into the hierarchical grammar that the system can use for serial concatenation of phrases as in monotonic phrase-based translation. In the Moses implementation, the decoder internally adds a sentence start terminal symbol &lt;s> and a sentence end terminal symbol &lt;/s> to the input before and after each sentence, respectively. Therefore, two more special rules S → h&lt;s>, &lt;s>i S → hS∼0 &lt;/s>, S∼0 &lt;/s>i 2.1 (2) are included which allow the decoder to finalize its translations. Hierarchical search is"
W16-2315,W13-2258,1,0.952949,"nting the particularities of our hierarchical phrase-based system, with a focus of interest on exploring non-standard enhancements and non-default configuration settings such as: • Individual language models as features, rather than a single linearly interpolated language model; and another background language model estimated over concatenated corpora. • Large CommonCrawl language model training data. • Unpruned language models. • More hierarchical rules than in default systems, by means of imposing less strict extraction constraints. • A phrase orientation model for hierarchical translation (Huck et al., 2013). • Lightly-supervised training (Schwenk, 2008; Schwenk and Senellart, 2009; Huck et al., 2011). • Larger development data for tuning. S → hS∼0 X ∼1 , S∼0 X ∼1 i is incorporated into the hierarchical grammar that the system can use for serial concatenation of phrases as in monotonic phrase-based translation. In the Moses implementation, the decoder internally adds a sentence start terminal symbol &lt;s> and a sentence end terminal symbol &lt;/s> to the input before and after each sentence, respectively. Therefore, two more special rules S → h&lt;s>, &lt;s>i S → hS∼0 &lt;/s>, S∼0 &lt;/s>i 2.1 (2) are included wh"
W16-2315,2008.iwslt-papers.6,0,0.0482276,"e-based system, with a focus of interest on exploring non-standard enhancements and non-default configuration settings such as: • Individual language models as features, rather than a single linearly interpolated language model; and another background language model estimated over concatenated corpora. • Large CommonCrawl language model training data. • Unpruned language models. • More hierarchical rules than in default systems, by means of imposing less strict extraction constraints. • A phrase orientation model for hierarchical translation (Huck et al., 2013). • Lightly-supervised training (Schwenk, 2008; Schwenk and Senellart, 2009; Huck et al., 2011). • Larger development data for tuning. S → hS∼0 X ∼1 , S∼0 X ∼1 i is incorporated into the hierarchical grammar that the system can use for serial concatenation of phrases as in monotonic phrase-based translation. In the Moses implementation, the decoder internally adds a sentence start terminal symbol &lt;s> and a sentence end terminal symbol &lt;/s> to the input before and after each sentence, respectively. Therefore, two more special rules S → h&lt;s>, &lt;s>i S → hS∼0 &lt;/s>, S∼0 &lt;/s>i 2.1 (2) are included which allow the decoder to finalize its translat"
W16-2315,2015.mtsummit-papers.19,1,0.913146,"making documents originally written in English available to a large community of speakers in their native language, Romanian. Applications are for instance in the health care sector, where, as part of the Health in my Language project (HimL), several project partners intend to make public health information available in a wider variety of languages.2 The WMT task provides an interesting test bed for English→Romanian machine translation, though adaptation towards the specific domain (consumer health for HimL, rather than news) is also an important aspect that has to be considered in practice (Huck et al., 2015). We investigate the effectiveness of hierarchical phrase-based translation (Chiang, 2005) for English→Romanian, a statistical machine translation paradigm that is closely related to phrasebased translation, but allows for phrases with gaps. Conceptionally, the translation model is formalized as a synchronous context-free grammar. We integrate several non-standard enhancements into our hierarchical phrase-based system and empirically evaluate their impact on translation quality. Our system is furthermore one component in a combination of systems by members of the HimL project and another EU-fu"
W16-2315,N03-1017,0,0.0312287,"f order three and higher.6 We run the Moses chart-based decoder with cube pruning, configured at a maximum chart span of 25 and otherwise default settings. Training and Tuning We create word alignments by aligning the bilingual data in both directions with MGIZA++ (Gao and Vogel, 2008). We use a sequence of IBM word alignment models (Brown et al., 1993) with five iterations of EM training (Dempster et al., 1977) of Model 1, three iterations of Model 3, and three iterations of Model 4. After EM, we obtain a symmetrized alignment by applying the grow-diag-final-and heuristic (Och and Ney, 2003; Koehn et al., 2003) to the two trained alignments. We extract synchronous context-free grammar rules that are consistent with the symmetrized word alignment from the parallel training data. We train 5-gram language models (LMs) with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). KenLM (Heafield, 2011) is employed for LM training and scoring, and SRILM (Stolcke, 2002) for linear LM interpolation. Our translation model incorporates a number of different features in a log-linear combination (Och and Ney, 2002). We tune the feature weights with batch k-best M IRA (Cherry and Foster, 20"
W16-2315,W10-1738,1,0.878506,"on-terminal at gaps that cover only a single word on the source side. We allow for extraction of more hierarchical rules by applying less strict rule extraction constraints: a maximum of ten symbols on the source side, a maximum span of twenty words, and no lower limit to the amount of words covered by non-terminals at extraction time. Phrase orientation model. We implemented a feature in Moses that resembles the phrase orientation model for hierarchical machine translation as described by Huck et al. (2013). The Huck et al. (2013) implementation had been released as part of the Jane toolkit (Vilar et al., 2010; Vilar et al., 2012; Huck et al., 2012). Our new Moses implementation technically operates in almost the same manner, except for minor implementation differences. Similarly to the type of lexicalized reordering models that are in common use in phrase-based systems (Galley and Manning, 2008), our model estimates the probabilities of orientation classes for each phrase (or: rule) from the training data. We use three orientation classes: monotone, swap, and discontinuous.7 Larger development data. Since no dedicated unseen test set was available during system building, newsdev2016 was split into"
W16-2315,W16-2327,1,0.705098,"Missing"
W16-2315,P05-1033,0,\N,Missing
W16-2315,2013.iwslt-evaluation.16,1,\N,Missing
W16-2315,W16-2320,1,\N,Missing
W16-2320,W16-2304,1,0.833347,"factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additional word factor. 2 3.2 Preprocessing The data provided for the task was preprocessed once, by LIMSI, and shared with all the participants, in order to ensure consistency between systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn et al., 2007). On the Romanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based approach (Zens et al., 2002). In this framework, translation is divided into two steps. T"
W16-2320,W05-0909,0,0.583183,"ions from multiple hypotheses which are obtained from different translation approaches, i.e., the systems described in the previous section. A system combination implementation developed at RWTH Aachen University (Freitag et al., 2014a) is used to combine the outputs of the different engines. The consensus translations outperform the individual hypotheses in terms of translation quality. The first step in system combination is the generation of confusion networks (CN) from I input translation hypotheses. We need pairwise alignments between the input hypotheses, which are obtained from METEOR (Banerjee and Lavie, 2005). The hypotheses are then reordered to match a selected skeleton hypothesis in terms of word ordering. We generate I different CNs, each having one of the input systems as the skeleton hypothesis, and the final lattice is the union of all I generated CNs. In Figure 1 an example of a confusion network with I = 4 input translations is depicted. Decoding of a confusion network finds the best path in the network. Each arc is assigned a score of a linear model combination of M different models, which includes word penalty, 3-gram language model trained on the input hypotheses, a binary primary syst"
W16-2320,P13-2071,1,0.873371,"odel trained on all available data. Words in the Common Crawl dataset that appear fewer than 500 times were replaced by UNK, and all singleton ngrams of order 3 or higher were pruned. We also use a 7-gram class-based language model, trained on the same data. 512 word Edinburgh Phrase-based System Edinburgh’s phrase-based system is built using the Moses toolkit, with fast align (Dyer et al., 2013) for word alignment, and KenLM (Heafield et al., 2013) for language model training. In our Moses setup, we use hierarchical lexicalized reordering (Galley and Manning, 2008), operation sequence model (Durrani et al., 2013), domain indicator features, and binned phrase count features. We use all available parallel data for the translation model, and all available Romanian text for the language model. We use two different 5-gram language models; one built from all the monolingual target text concatenated, without pruning, and one 3 USFD Phrase-based System 4 http://www.quest.dcs.shef.ac.uk/ quest_files/features_blackbox_baseline_ 17 https://github.com/rsennrich/nematus 348 the large building the large home a big huge house house a newsdev2016/1 and newsdev2016/2. The first part was used as development set while t"
W16-2320,D15-1129,1,0.847985,"training and evaluation. The language model uses 3 stacked LSTM layers, with 350 nodes each. The BJM has a projection layer, and computes a forLMU The LMU system integrates a discriminative rule selection model into a hierarchical SMT system, as described in (Tamchyna et al., 2014). The rule selection model is implemented using the highspeed classifier Vowpal Wabbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule application with syntactic context information as feature templates. The features are the same as used by Braune et al. (2015) in their string-to-tree system, including both lexical and soft source syntax features. The translation model features comprise the standard hierarchical features (Chiang, 2005) with an additional feature for the rule selection model (Braune et al., 2016). Before training, we reduce the number of translation rules using significance testing (Johnson et al., 2007). To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based loc"
W16-2320,N13-1073,0,0.034805,"preordering model of (de Gispert et al., 2015). The preordering model is trained for 30 iterations on the full MGIZA-aligned training data. We use two language models, built using KenLM. The first is a 5-gram language model trained on all available data. Words in the Common Crawl dataset that appear fewer than 500 times were replaced by UNK, and all singleton ngrams of order 3 or higher were pruned. We also use a 7-gram class-based language model, trained on the same data. 512 word Edinburgh Phrase-based System Edinburgh’s phrase-based system is built using the Moses toolkit, with fast align (Dyer et al., 2013) for word alignment, and KenLM (Heafield et al., 2013) for language model training. In our Moses setup, we use hierarchical lexicalized reordering (Galley and Manning, 2008), operation sequence model (Durrani et al., 2013), domain indicator features, and binned phrase count features. We use all available parallel data for the translation model, and all available Romanian text for the language model. We use two different 5-gram language models; one built from all the monolingual target text concatenated, without pruning, and one 3 USFD Phrase-based System 4 http://www.quest.dcs.shef.ac.uk/ ques"
W16-2320,J04-2004,0,0.0194677,"en systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn et al., 2007). On the Romanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based approach (Zens et al., 2002). In this framework, translation is divided into two steps. To translate a source sentence into a target sentence, the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order. This generates a word lattice containing the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probabilit"
W16-2320,2011.mtsummit-papers.30,0,0.020392,"-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-based translation (HPBT) (Chiang, 2007) induces a weighted synchronous context-free grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the boundaries. We use the cube pruning algorithm (Huang and Chiang, 2007) for decoding. The system uses three backoff language models (LM) that are estimated with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 201"
W16-2320,N12-1047,0,0.591808,"rescoring. The phrase-based system is trained on all available parallel training data. The phrase 345 more specifically its implementation in XenC (Rousseau, 2013). As a result, one third of the initial corpus is removed. Finally, we make a linear interpolation of these models, using the SRILM toolkit (Stolcke, 2002). 3.3 training data using the Berkeley parser (Petrov et al., 2006). For model prediction during tuning and decoding, we use parsed versions of the development and test sets. We train the rule selection model using VW and tune the weights of the translation model using batch MIRA (Cherry and Foster, 2012). The 5-gram language model is trained using KenLM (Heafield et al., 2013) on the Romanian part of the Common Crawl corpus concatenated with the Romanian part of the training data. LMU-CUNI The LMU-CUNI contribution is a constrained Moses phrase-based system. It uses a simple factored setting: our phrase table produces not only the target surface form but also its lemma and morphological tag. On the input, we include lemmas, POS tags and information from dependency parses (lemma of the parent node and syntactic relation), all encoded as additional factors. The main difference from a standard p"
W16-2320,E14-2008,1,0.72015,"tems are combined using RWTH’s system combination approach. The final submission shows an improvement of 1.0 B LEU compared to the best single system on newstest2016. 1 Introduction Quality Translation 21 (QT21) is a European machine translation research project with the aim 1 http://www.statmt.org/wmt16/ translation-task.html 344 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 344–355, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics mented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). In the remainder of the paper, we present the technical details of the QT21/HimL combined machine translation system and the experimental results obtained with it. The paper is structured as follows: We describe the common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual en"
W16-2320,P05-1033,0,0.151933,"ative rule selection model into a hierarchical SMT system, as described in (Tamchyna et al., 2014). The rule selection model is implemented using the highspeed classifier Vowpal Wabbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule application with syntactic context information as feature templates. The features are the same as used by Braune et al. (2015) in their string-to-tree system, including both lexical and soft source syntax features. The translation model features comprise the standard hierarchical features (Chiang, 2005) with an additional feature for the rule selection model (Braune et al., 2016). Before training, we reduce the number of translation rules using significance testing (Johnson et al., 2007). To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based localisation feature is applied. ward recurrent state encoding the source and target history, a backward recurrent state encoding the source future, and a third LSTM layer to combin"
W16-2320,J07-2003,0,0.558191,"this model is to better condition lexical choices by using the source context and to improve morphological and topical coherence by modeling the (limited left-hand side) target context. We also take advantage of the target factors by using a 7-gram language model trained on sequences of Romanian morphological tags. Finally, our system also uses a standard lexicalized reordering model. 3.4 3.5 RWTH Aachen University: Hierarchical Phrase-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-based translation (HPBT) (Chiang, 2007) induces a weighted synchronous context-free grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the bou"
W16-2320,W14-3310,1,0.909876,"tems are combined using RWTH’s system combination approach. The final submission shows an improvement of 1.0 B LEU compared to the best single system on newstest2016. 1 Introduction Quality Translation 21 (QT21) is a European machine translation research project with the aim 1 http://www.statmt.org/wmt16/ translation-task.html 344 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 344–355, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics mented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). In the remainder of the paper, we present the technical details of the QT21/HimL combined machine translation system and the experimental results obtained with it. The paper is structured as follows: We describe the common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual en"
W16-2320,D14-1179,0,0.0138582,"Missing"
W16-2320,2014.iwslt-evaluation.7,1,0.925781,"tems are combined using RWTH’s system combination approach. The final submission shows an improvement of 1.0 B LEU compared to the best single system on newstest2016. 1 Introduction Quality Translation 21 (QT21) is a European machine translation research project with the aim 1 http://www.statmt.org/wmt16/ translation-task.html 344 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 344–355, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics mented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). In the remainder of the paper, we present the technical details of the QT21/HimL combined machine translation system and the experimental results obtained with it. The paper is structured as follows: We describe the common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual en"
W16-2320,D08-1089,0,0.0211464,", built using KenLM. The first is a 5-gram language model trained on all available data. Words in the Common Crawl dataset that appear fewer than 500 times were replaced by UNK, and all singleton ngrams of order 3 or higher were pruned. We also use a 7-gram class-based language model, trained on the same data. 512 word Edinburgh Phrase-based System Edinburgh’s phrase-based system is built using the Moses toolkit, with fast align (Dyer et al., 2013) for word alignment, and KenLM (Heafield et al., 2013) for language model training. In our Moses setup, we use hierarchical lexicalized reordering (Galley and Manning, 2008), operation sequence model (Durrani et al., 2013), domain indicator features, and binned phrase count features. We use all available parallel data for the translation model, and all available Romanian text for the language model. We use two different 5-gram language models; one built from all the monolingual target text concatenated, without pruning, and one 3 USFD Phrase-based System 4 http://www.quest.dcs.shef.ac.uk/ quest_files/features_blackbox_baseline_ 17 https://github.com/rsennrich/nematus 348 the large building the large home a big huge house house a newsdev2016/1 and newsdev2016/2. T"
W16-2320,N15-1105,0,0.046766,"Missing"
W16-2320,W08-0509,0,0.06624,"probability 0.2, and also drop out full words with probability 0.1. We clip the gradient norm to 1.0 (Pascanu et al., 2013). We train the models with Adadelta (Zeiler, 2012), reshuffling the training corpus between epochs. We validate the model every 10 000 minibatches via B LEU on a validation set, and perform early stopping on B LEU. Decoding is performed with beam search with a beam size of 12. A more detailed description of the system, and more experimental results, can be found in (Sennrich et al., 2016a). 3.10 3.11 USFD’s phrase-based system is built using the Moses toolkit, with MGIZA (Gao and Vogel, 2008) for word alignment and KenLM (Heafield et al., 2013) for language model training. We use all available parallel data for the translation model. A single 5-gram language model is built using all the target side of the parallel data and a subpart of the monolingual Romanian corpora selected with Xenc-v2 (Rousseau, 2013). For the latter we use all the parallel data as in-domain data and the first half of newsdev2016 as development set. The feature weights are tuned with MERT (Och, 2003) on the first half of newsdev2016. The system produces distinct 1000-best lists, for which we extend the featur"
W16-2320,W16-2315,1,0.820309,"vs et al., 2012) that features language-specific data filtering and cleaning modules. Tilde’s system was trained on all available parallel data. Two language models are trained using KenLM (Heafield, 2011): 1) a 5-gram model using the Europarl and SETimes2 corpora, and 2) a 3-gram model using the Common Crawl corpus. We also apply a custom tokenization tool that takes into account specifics of the Romanian language and handles non-translatable entities (e.g., file paths, 347 up with entries from a background phrase table extracted from the automatically produced News Crawl 2015 parallel data. Huck et al. (2016) give a more in-depth description of the Edinburgh/LMU hierarchical machine translation system, along with detailed experimental results. 3.9 built from only News Crawl 2015, with singleton 3-grams and above pruned out. The weights of all these features and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural Sy"
W16-2320,D07-1103,0,0.032902,"bbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule application with syntactic context information as feature templates. The features are the same as used by Braune et al. (2015) in their string-to-tree system, including both lexical and soft source syntax features. The translation model features comprise the standard hierarchical features (Chiang, 2005) with an additional feature for the rule selection model (Braune et al., 2016). Before training, we reduce the number of translation rules using significance testing (Johnson et al., 2007). To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based localisation feature is applied. ward recurrent state encoding the source and target history, a backward recurrent state encoding the source future, and a third LSTM layer to combine them. All layers have 350 nodes. The neural networks are implemented using an extension of the RWTHLM toolkit (Sundermeyer et al., 2014b). The parameter weights are optimized with MERT ("
W16-2320,W14-3360,0,0.0191919,"NMT system on newsdev2016/2, but lags behind on newstest2016. Removing the by itself weakest system shows a slight degradation on newsdev2016/2 and newstest2016, hinting that it still provides valuable information. Table 2 shows a comparison between all systems by scoring the translation output against each other in T ER and B LEU. We see that the neural networks outputs differ the most from all the other systems. Figure 1: System A: the large building; System B: the large home; System C: a big house; System D: a huge house; Reference: the big house. classes were generated using the method of Green et al. (2014). 4 System Combination System combination produces consensus translations from multiple hypotheses which are obtained from different translation approaches, i.e., the systems described in the previous section. A system combination implementation developed at RWTH Aachen University (Freitag et al., 2014a) is used to combine the outputs of the different engines. The consensus translations outperform the individual hypotheses in terms of translation quality. The first step in system combination is the generation of confusion networks (CN) from I input translation hypotheses. We need pairwise alig"
W16-2320,P07-2045,1,0.010375,", 2015) as well as neural network language and translation models. These models use a factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additional word factor. 2 3.2 Preprocessing The data provided for the task was preprocessed once, by LIMSI, and shared with all the participants, in order to ensure consistency between systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn et al., 2007). On the Romanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based"
W16-2320,P13-2121,0,0.0645203,"Missing"
W16-2320,W11-2123,0,0.124165,"nslation is divided into two steps. To translate a source sentence into a target sentence, the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order. This generates a word lattice containing the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probability of a sentence pair into a sequence of bilingual units called tuples. We train three Romanian 4-gram language models, pruning all singletons with KenLM (Heafield, 2011). We use the in-domain monolingual corpus, the Romanian side of the parallel corpora and a subset of the (out-of-domain) Common Crawl corpus as training data. We select indomain sentences from the latter using the MooreLewis (Moore and Lewis, 2010) filtering method, Translation Systems Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 LIMSI KIT The KIT system consists of a phrase-based machine translation system using additional models in rescoring. The phrase-based system is trained on all available parallel training data. The phras"
W16-2320,N04-1022,0,0.037676,"f the Romanian language and handles non-translatable entities (e.g., file paths, 347 up with entries from a background phrase table extracted from the automatically produced News Crawl 2015 parallel data. Huck et al. (2016) give a more in-depth description of the Edinburgh/LMU hierarchical machine translation system, along with detailed experimental results. 3.9 built from only News Crawl 2015, with singleton 3-grams and above pruned out. The weights of all these features and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural System Edinburgh’s neural machine translation system is an attentional encoder-decoder (Bahdanau et al., 2015), which we train with nematus.3 We use byte-pair-encoding (BPE) to achieve openvocabulary translation with a fixed vocabulary of subword symbols (Sennrich et al., 2016c). We produce additional parallel training data by automatically translating the monolingual Romanian News Crawl 2015 corpu"
W16-2320,2015.iwslt-papers.3,1,0.744353,"g. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add the source discriminative word lexica (Herrmann et al., 2015) as well as neural network language and translation models. These models use a factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additional word factor. 2 3.2 Preprocessing The data provided for the task was preprocessed once, by LIMSI, and shared with all the participants, in order to ensure consistency between systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn e"
W16-2320,J06-4004,0,0.106202,"Missing"
W16-2320,2009.iwslt-papers.4,0,0.0984189,"target history, a backward recurrent state encoding the source future, and a third LSTM layer to combine them. All layers have 350 nodes. The neural networks are implemented using an extension of the RWTHLM toolkit (Sundermeyer et al., 2014b). The parameter weights are optimized with MERT (Och, 2003) towards the B LEU metric. 3.6 3.8 The UEDIN-LMU HPBT system is a hierarchical phrase-based machine translation system (Chiang, 2005) built jointly by the University of Edinburgh and LMU Munich. The system is based on the open source Moses implementation of the hierarchical phrase-based paradigm (Hoang et al., 2009). In addition to a set of standard features in a log-linear combination, a number of non-standard enhancements are employed to achieve improved translation quality. Specifically, we integrate individual language models trained over the separate corpora (News Crawl 2015, Europarl, SETimes2) directly into the log-linear combination of the system and let MIRA (Cherry and Foster, 2012) optimize their weights along with all other features in tuning, rather than relying on a single linearly interpolated language model. We add another background language model estimated over a concatenation of all Ro"
W16-2320,P10-2041,0,0.0238386,"ontaining the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probability of a sentence pair into a sequence of bilingual units called tuples. We train three Romanian 4-gram language models, pruning all singletons with KenLM (Heafield, 2011). We use the in-domain monolingual corpus, the Romanian side of the parallel corpora and a subset of the (out-of-domain) Common Crawl corpus as training data. We select indomain sentences from the latter using the MooreLewis (Moore and Lewis, 2010) filtering method, Translation Systems Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 LIMSI KIT The KIT system consists of a phrase-based machine translation system using additional models in rescoring. The phrase-based system is trained on all available parallel training data. The phrase 345 more specifically its implementation in XenC (Rousseau, 2013). As a result, one third of the initial corpus is removed. Finally, we make a linear interpolation of these models, using the SRILM toolkit (Stolcke, 2002). 3.3 training data using"
W16-2320,P07-1019,0,0.236745,"grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the boundaries. We use the cube pruning algorithm (Huang and Chiang, 2007) for decoding. The system uses three backoff language models (LM) that are estimated with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 2013) trained on all data and with a output vocabulary of 143K words. The system produces 1000-best lists which are reranked using a LSTM-based (Hochreiter and Schmidhuber, 1997; Gers et al., 2000; Gers et al., 2003) language"
W16-2320,2012.amta-papers.19,1,0.778005,"common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual engines, followed by a brief overview of our system combination approach (Section 4). We then summarize our empirical results in Section 5, showing that we achieve better translation quality than with any individual engine. Finally, in Section 6, we provide a statistical analysis of certain linguistic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set usin"
W16-2320,W11-2211,1,0.902733,"ty words, and no lower limit to the amount of words covered by right-hand side non-terminals at extraction time. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. In order to promote better reordering decisions, we implemented a feature in Moses that resembles the phrase orientation model for hierarchical machine translation as described by Huck et al. (2013) and extend our system with it. The model scores orientation classes (monotone, swap, discontinuous) for each rule application in decoding. We finally follow the approach outlined by Huck et al. (2011) for lightly-supervised training of hierarchical systems. We automatically translate parts (1.2M sentences) of the monolingual Romanian News Crawl 2015 corpus to English with a Romanian→English phrase-based statistical machine translation system (Williams et al., 2016). The foreground phrase table extracted from the human-generated parallel data is filled RWTH Neural System The second system provided by the RWTH is an attention-based recurrent neural network similar to (Bahdanau et al., 2015). The implementation is based on Blocks (van Merri¨enboer et al., 2015) and Theano (Bergstra et al., 20"
W16-2320,W13-2264,1,0.852517,"stic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add the source discriminative word lexica (Herrmann et al., 2015) as well as neural network language and translation models. These models use a factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additio"
W16-2320,W13-2258,1,0.869431,"extraction, we impose less strict extraction constraints than the Moses defaults. We extract more hierarchical rules by allowing for a maximum of ten symbols on the source side, a maximum span of twenty words, and no lower limit to the amount of words covered by right-hand side non-terminals at extraction time. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. In order to promote better reordering decisions, we implemented a feature in Moses that resembles the phrase orientation model for hierarchical machine translation as described by Huck et al. (2013) and extend our system with it. The model scores orientation classes (monotone, swap, discontinuous) for each rule application in decoding. We finally follow the approach outlined by Huck et al. (2011) for lightly-supervised training of hierarchical systems. We automatically translate parts (1.2M sentences) of the monolingual Romanian News Crawl 2015 corpus to English with a Romanian→English phrase-based statistical machine translation system (Williams et al., 2016). The foreground phrase table extracted from the human-generated parallel data is filled RWTH Neural System The second system prov"
W16-2320,E99-1010,0,0.040797,"ion 5, showing that we achieve better translation quality than with any individual engine. Finally, in Section 6, we provide a statistical analysis of certain linguistic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add the source discriminative word lexica (Herrmann et al., 2015) as well as neural network language and translation models. These models use a factored word representation of the source and th"
W16-2320,P03-1021,0,0.501814,". To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based localisation feature is applied. ward recurrent state encoding the source and target history, a backward recurrent state encoding the source future, and a third LSTM layer to combine them. All layers have 350 nodes. The neural networks are implemented using an extension of the RWTHLM toolkit (Sundermeyer et al., 2014b). The parameter weights are optimized with MERT (Och, 2003) towards the B LEU metric. 3.6 3.8 The UEDIN-LMU HPBT system is a hierarchical phrase-based machine translation system (Chiang, 2005) built jointly by the University of Edinburgh and LMU Munich. The system is based on the open source Moses implementation of the hierarchical phrase-based paradigm (Hoang et al., 2009). In addition to a set of standard features in a log-linear combination, a number of non-standard enhancements are employed to achieve improved translation quality. Specifically, we integrate individual language models trained over the separate corpora (News Crawl 2015, Europarl, SE"
W16-2320,D14-1003,1,0.932306,"with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 2013) trained on all data and with a output vocabulary of 143K words. The system produces 1000-best lists which are reranked using a LSTM-based (Hochreiter and Schmidhuber, 1997; Gers et al., 2000; Gers et al., 2003) language model (Sundermeyer et al., 2012) and a LSTM-based bidirectional joined model (BJM) (Sundermeyer et al., 2014a). The models have a class-factored output layer (Goodman, 2001; Morin and Bengio, 2005) to speed up training and evaluation. The language model uses 3 stacked LSTM layers, with 350 nodes each. The BJM has a projection layer, and computes a forLMU The LMU system integrates a discriminative rule selection model into a hierarchical SMT system, as described in (Tamchyna et al., 2014). The rule selection model is implemented using the highspeed classifier Vowpal Wabbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule appli"
W16-2320,P06-1055,0,0.0121776,"anslation Systems Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 LIMSI KIT The KIT system consists of a phrase-based machine translation system using additional models in rescoring. The phrase-based system is trained on all available parallel training data. The phrase 345 more specifically its implementation in XenC (Rousseau, 2013). As a result, one third of the initial corpus is removed. Finally, we make a linear interpolation of these models, using the SRILM toolkit (Stolcke, 2002). 3.3 training data using the Berkeley parser (Petrov et al., 2006). For model prediction during tuning and decoding, we use parsed versions of the development and test sets. We train the rule selection model using VW and tune the weights of the translation model using batch MIRA (Cherry and Foster, 2012). The 5-gram language model is trained using KenLM (Heafield et al., 2013) on the Romanian part of the Common Crawl corpus concatenated with the Romanian part of the training data. LMU-CUNI The LMU-CUNI contribution is a constrained Moses phrase-based system. It uses a simple factored setting: our phrase table produces not only the target surface form but als"
W16-2320,2007.tmi-papers.21,0,0.0230136,"n 2. Section 3 covers the characteristics of the different individual engines, followed by a brief overview of our system combination approach (Section 4). We then summarize our empirical results in Section 5, showing that we achieve better translation quality than with any individual engine. Finally, in Section 6, we provide a statistical analysis of certain linguistic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add t"
W16-2320,P16-1161,1,0.729045,"omanian part of the training data. LMU-CUNI The LMU-CUNI contribution is a constrained Moses phrase-based system. It uses a simple factored setting: our phrase table produces not only the target surface form but also its lemma and morphological tag. On the input, we include lemmas, POS tags and information from dependency parses (lemma of the parent node and syntactic relation), all encoded as additional factors. The main difference from a standard phrasebased setup is the addition of a feature-rich discriminative translation model which is conditioned on both source- and target-side context (Tamchyna et al., 2016). The motivation for using this model is to better condition lexical choices by using the source context and to improve morphological and topical coherence by modeling the (limited left-hand side) target context. We also take advantage of the target factors by using a 7-gram language model trained on sequences of Romanian morphological tags. Finally, our system also uses a standard lexicalized reordering model. 3.4 3.5 RWTH Aachen University: Hierarchical Phrase-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-"
W16-2320,tufis-etal-2008-racais,0,0.107217,"Missing"
W16-2320,P16-1009,1,0.78198,"and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural System Edinburgh’s neural machine translation system is an attentional encoder-decoder (Bahdanau et al., 2015), which we train with nematus.3 We use byte-pair-encoding (BPE) to achieve openvocabulary translation with a fixed vocabulary of subword symbols (Sennrich et al., 2016c). We produce additional parallel training data by automatically translating the monolingual Romanian News Crawl 2015 corpus into English (Sennrich et al., 2016b), which we combine with the original parallel data in a 1-to-1 ratio. We use minibatches of size 80, a maximum sentence length of 50, word embeddings of size 500, and hidden layers of size 1024. We apply dropout to all layers (Gal, 2015), with dropout probability 0.2, and also drop out full words with probability 0.1. We clip the gradient norm to 1.0 (Pascanu et al., 2013). We train the models with Adadelta (Zeiler, 2012), reshufflin"
W16-2320,P12-3008,0,0.0597108,"Missing"
W16-2320,P16-1162,1,0.259658,"and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural System Edinburgh’s neural machine translation system is an attentional encoder-decoder (Bahdanau et al., 2015), which we train with nematus.3 We use byte-pair-encoding (BPE) to achieve openvocabulary translation with a fixed vocabulary of subword symbols (Sennrich et al., 2016c). We produce additional parallel training data by automatically translating the monolingual Romanian News Crawl 2015 corpus into English (Sennrich et al., 2016b), which we combine with the original parallel data in a 1-to-1 ratio. We use minibatches of size 80, a maximum sentence length of 50, word embeddings of size 500, and hidden layers of size 1024. We apply dropout to all layers (Gal, 2015), with dropout probability 0.2, and also drop out full words with probability 0.1. We clip the gradient norm to 1.0 (Pascanu et al., 2013). We train the models with Adadelta (Zeiler, 2012), reshufflin"
W16-2320,W10-1738,1,0.885055,"rget-side context (Tamchyna et al., 2016). The motivation for using this model is to better condition lexical choices by using the source context and to improve morphological and topical coherence by modeling the (limited left-hand side) target context. We also take advantage of the target factors by using a 7-gram language model trained on sequences of Romanian morphological tags. Finally, our system also uses a standard lexicalized reordering model. 3.4 3.5 RWTH Aachen University: Hierarchical Phrase-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-based translation (HPBT) (Chiang, 2007) induces a weighted synchronous context-free grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical ph"
W16-2320,P15-4020,1,0.815128,"data for the translation model. A single 5-gram language model is built using all the target side of the parallel data and a subpart of the monolingual Romanian corpora selected with Xenc-v2 (Rousseau, 2013). For the latter we use all the parallel data as in-domain data and the first half of newsdev2016 as development set. The feature weights are tuned with MERT (Och, 2003) on the first half of newsdev2016. The system produces distinct 1000-best lists, for which we extend the feature set with the 17 baseline black-box features from sentencelevel Quality Estimation (QE) produced with Quest++4 (Specia et al., 2015). The 1000-best lists are then reranked and the top-best hypothesis extracted using the nbest rescorer available within the Moses toolkit. 3.12 UvA We use a phrase-based machine translation system (Moses) with a distortion limit of 6 and lexicalized reordering. Before translation, the English source side is preordered using the neural preordering model of (de Gispert et al., 2015). The preordering model is trained for 30 iterations on the full MGIZA-aligned training data. We use two language models, built using KenLM. The first is a 5-gram language model trained on all available data. Words in"
W16-2320,W16-2327,1,0.84726,"Missing"
W16-2320,D13-1138,1,0.859072,"(Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the boundaries. We use the cube pruning algorithm (Huang and Chiang, 2007) for decoding. The system uses three backoff language models (LM) that are estimated with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 2013) trained on all data and with a output vocabulary of 143K words. The system produces 1000-best lists which are reranked using a LSTM-based (Hochreiter and Schmidhuber, 1997; Gers et al., 2000; Gers et al., 2003) language model (Sundermeyer et al., 2012) and a LSTM-based bidirectional joined model (BJM) (Sundermeyer et al., 2014a). The models have a class-factored output layer (Goodman, 2001; Morin and Bengio, 2005) to speed up training and evaluation. The language model uses 3 stacked LSTM layers, with 350 nodes each. The BJM has a projection layer, and computes a forLMU The LMU system integra"
W16-2320,2002.tmi-tutorials.2,0,0.0608664,"omanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based approach (Zens et al., 2002). In this framework, translation is divided into two steps. To translate a source sentence into a target sentence, the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order. This generates a word lattice containing the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probability of a sentence pair into a sequence of bilingual units called tuples. We train three Romanian 4-gram language models, pruning all"
W16-2325,2005.iwslt-1.8,0,0.152572,"Missing"
W16-2325,P07-2045,1,0.0213385,"p is fairly complex, following Bojar et al. (2013). The key components of C HIMERA are: This paper describes the phrase-based systems jointly submitted by CUNI and LMU to English-Czech and English-Romanian News translation tasks of WMT16. In contrast to previous years, we strictly limited our training data to the constraint datasets, to allow for a reliable comparison with other research systems. We experiment with using several additional models in our system, including a feature-rich discriminative model of phrasal translation. 1 English-Czech System • Moses, a phrase-based factored system (Koehn et al., 2007). • TectoMT, a deep-syntactic transfer-based ˇ system (Popel and Zabokrtsk´ y, 2010). • Depfix, a rule-based post-processing system (Rosa et al., 2012). The core of the system is Moses. We combine it with TectoMT in a simple way which we refer to as “poor man’s” system combination: we translate our development and test data with TectoMT first and then add the source sentences and their translations as additional (synthetic) parallel data to the Moses system. This new corpus is used to train a separate phrase table. At test time, we run Moses which uses both phrase tables and we correct its out"
W16-2325,W13-2208,1,0.840484,"Popel and Zabokrtsk´ y, 2010). • Depfix, a rule-based post-processing system (Rosa et al., 2012). The core of the system is Moses. We combine it with TectoMT in a simple way which we refer to as “poor man’s” system combination: we translate our development and test data with TectoMT first and then add the source sentences and their translations as additional (synthetic) parallel data to the Moses system. This new corpus is used to train a separate phrase table. At test time, we run Moses which uses both phrase tables and we correct its output using Depfix. The system is described in detail in Bojar et al. (2013). Our subsequent analysis in Tamchyna and Bojar (2015) shows that the contribution of TectoMT is essential for the performance of C HIMERA. In particular, TectoMT provides new translations which are otherwise not available to the phrase-based system and it also improves the morphological and syntactic coherence of translations. Introduction We have a long-term experience with English-toCzech machine translation and over the years, our systems have grown together from rather diverse set of system types to a single system combination called C HIMERA (Bojar et al., 2013). This system has been suc"
W16-2325,W15-3006,1,0.864481,"ectoMT is essential for the performance of C HIMERA. In particular, TectoMT provides new translations which are otherwise not available to the phrase-based system and it also improves the morphological and syntactic coherence of translations. Introduction We have a long-term experience with English-toCzech machine translation and over the years, our systems have grown together from rather diverse set of system types to a single system combination called C HIMERA (Bojar et al., 2013). This system has been successful in the previous three years of WMT (Bojar et al., 2013; Tamchyna et al., 2014; Bojar and Tamchyna, 2015) and we follow a similar design this year. Unlike previous years, we only use constrained data in system training, to allow for a more meaningful comparison with the competing systems. The gains thanks to the additional data in contrast to the gains thanks the system combination have been evaluated in terms of BLEU in Bojar and Tamchyna (2015). The details of our English-to-Czech system are in Section 2. In this work, we also present our system submission for English-Romanian translation. This system uses a factored setting similar to C HIMERA but lacks its two key components: the deepsyntacti"
W16-2325,P03-1021,0,0.0682765,"HIMERA. We have added the discriminative model which conditions both on the source and target context to the system and obtained a small but significant improvement in BLEU. Discriminative Translation Model We utilize the same discriminative model as for C HIMERA. For English-Romanian, we also use dependency parses of the source sentences and target-side context features as additional source of information in our official submission. 3.6 BLEU 26.2 26.6 28.0 28.1 28.3 Results Table 2 lists BLEU scores of various system settings. Each BLEU score is an average over 5 runs of system tuning (MERT, Och, 2003). The table shows how BLEU score develops as we add the individual components to the system: the 7gram morphological LM (“tagLM”), the 4-gram LM from Common Crawl (“ccrawl”), the lexicalized reordering (“RR”) and finally the discriminative translation model (“discTM”). We test for statistical significance using MultEval (Clark et al., 2011); we test each new component against the system without it (i.e., +tagLM is compared to baseline, +ccrawl is tested against +tagLM etc.). When the p-value is lower than 0.05, we mark the result in bold. 5 Acknowledgement This work has received funding from t"
W16-2325,W14-3363,0,0.0253533,"t increasing the phrase table limit (the maximum number of possible translations per source phrase) is necessary to obtain good performance. Our input is also factored (though the phrase tables do not condition on these additional factors) and contains the form, lemma and morphological tag. We use these factors to extract rich features for our discriminative context model. Linearly interpolated translation models. There is some evidence that when dealing with heterogeneous domains, it might be beneficial to construct the final TM as a linear, uniform interpolation of many small phrase tables (Carpuat et al., 2014). We experiment with splitting the data into 20 parts (without any domain selection, simply a random shuffle) and using linear interpolation to combine the partial models. The added benefit is that phrase extraction for all these parts can run in parallel (2h25m per part on average). The merging of these parts took 16h12m, which is still substantially faster than the single extraction (53h7m). 2.2 Discriminative Translation Model We add a feature-rich, discriminative model of phrasal translation to our system (Tamchyna et al., 2016). This classifier produces a single phrase translation probabi"
W16-2325,P11-2031,0,0.0511747,"ntences and target-side context features as additional source of information in our official submission. 3.6 BLEU 26.2 26.6 28.0 28.1 28.3 Results Table 2 lists BLEU scores of various system settings. Each BLEU score is an average over 5 runs of system tuning (MERT, Och, 2003). The table shows how BLEU score develops as we add the individual components to the system: the 7gram morphological LM (“tagLM”), the 4-gram LM from Common Crawl (“ccrawl”), the lexicalized reordering (“RR”) and finally the discriminative translation model (“discTM”). We test for statistical significance using MultEval (Clark et al., 2011); we test each new component against the system without it (i.e., +tagLM is compared to baseline, +ccrawl is tested against +tagLM etc.). When the p-value is lower than 0.05, we mark the result in bold. 5 Acknowledgement This work has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreements no. 644402 (HimL) and no. 645452 (QT21). This work has been using language resources stored and distributed by the LINDAT/CLARIN project of the Ministry of Education, Youth and Sports of the Czech Republic (project LM2015071). This work was partially s"
W16-2325,P13-2071,1,0.867673,"nd uses surface forms, lemmas and tags. On the target side, the model has access to limited context (similarly to an LM) and uses target surface forms, lemmas and tags. However, our English-Czech submission to WMT16 does not use target-context information due to time constraints. 2.4 Lexicalized Reordering and OSM We experiment with using a lexicalized reordering model (Koehn et al., 2005) in the common setting: model monotone/swap/discontinuous reordering, word-based extraction, bidirectional, conditioned both on the source and target language. We also train an operation sequence model (OSM, Durrani et al., 2013), which is a generative model that sees the translation process as a linear sequence of operations which generate a source and target sentence in parallel. The probability of a sequence of operations is defined according to an n-gram model, that is, the probability of an operation depends on the n − 1 preceding operations. We have trained our 5-gram model on surface forms, using the CzEng16pre corpus. Language Models Our LM configuration is based on the successful setting from previous years, however all LMs are trained using the constrained data; this is a major difference from our previous s"
W16-2325,2005.mtsummit-papers.11,0,0.0101213,"up in the same cluster, ranking #4 and #5 among all systems for this language pair. The hacked system • seems negligibly better (0.302 TrueSkill) than the one with the discriminative model (∗, reaching 0.299 TrueSkill). 3 English-Romanian System We also submitted a constrained phrase-based system for English→Romanian translation which is loosely inspired by the basic components of C HIMERA. Additionally, our submission uses the source- and target-context discriminative translation model as well. 3.1 Data and Pre-Processing We use all the data available to constrained submissions: Europarl v8 (Koehn, 2005) and SETIMES2 (Tiedemann, 2009) parallel corpora and News 2015 and Common Crawl monolingual corpora.1 We split the official development set into two halves; we use the first part for system tuning and the second part serves as our test set. Data pre-processing differs between English and Romanian. For English, we use Treex (Popel ˇ and Zabokrtsk´ y, 2010) to obtain morphological tags, lemmas and dependency parses of the sentences. For Romanian, we use the online tagger by Tufis et al. (2008) as run by our colleagues at LIMSI-CNRS for the joint QT21 Romanian system (Peter et al., 2016). 3.2 Fac"
W16-2325,W12-3146,0,0.156313,"Missing"
W16-2325,P16-1161,1,0.84112,"s a linear, uniform interpolation of many small phrase tables (Carpuat et al., 2014). We experiment with splitting the data into 20 parts (without any domain selection, simply a random shuffle) and using linear interpolation to combine the partial models. The added benefit is that phrase extraction for all these parts can run in parallel (2h25m per part on average). The merging of these parts took 16h12m, which is still substantially faster than the single extraction (53h7m). 2.2 Discriminative Translation Model We add a feature-rich, discriminative model of phrasal translation to our system (Tamchyna et al., 2016). This classifier produces a single phrase translation probability which is additionally conditioned on the full source sentence and limited left-hand-side target context. The probability is added as an additional feature to Moses’ log-linear model. The motivation for adding the context model is to improve lexical choice (which can be better inferred thanks to full source-context information) and morphological coherence. The model uses a rich feature set on both sides: In the source, the model has access to the full input sentence and uses surface forms, lemmas and tags. On the target side, th"
W16-2325,W15-4103,1,0.784163,"based post-processing system (Rosa et al., 2012). The core of the system is Moses. We combine it with TectoMT in a simple way which we refer to as “poor man’s” system combination: we translate our development and test data with TectoMT first and then add the source sentences and their translations as additional (synthetic) parallel data to the Moses system. This new corpus is used to train a separate phrase table. At test time, we run Moses which uses both phrase tables and we correct its output using Depfix. The system is described in detail in Bojar et al. (2013). Our subsequent analysis in Tamchyna and Bojar (2015) shows that the contribution of TectoMT is essential for the performance of C HIMERA. In particular, TectoMT provides new translations which are otherwise not available to the phrase-based system and it also improves the morphological and syntactic coherence of translations. Introduction We have a long-term experience with English-toCzech machine translation and over the years, our systems have grown together from rather diverse set of system types to a single system combination called C HIMERA (Bojar et al., 2013). This system has been successful in the previous three years of WMT (Bojar et a"
W16-2325,W14-3322,1,0.860386,"t the contribution of TectoMT is essential for the performance of C HIMERA. In particular, TectoMT provides new translations which are otherwise not available to the phrase-based system and it also improves the morphological and syntactic coherence of translations. Introduction We have a long-term experience with English-toCzech machine translation and over the years, our systems have grown together from rather diverse set of system types to a single system combination called C HIMERA (Bojar et al., 2013). This system has been successful in the previous three years of WMT (Bojar et al., 2013; Tamchyna et al., 2014; Bojar and Tamchyna, 2015) and we follow a similar design this year. Unlike previous years, we only use constrained data in system training, to allow for a more meaningful comparison with the competing systems. The gains thanks to the additional data in contrast to the gains thanks the system combination have been evaluated in terms of BLEU in Bojar and Tamchyna (2015). The details of our English-to-Czech system are in Section 2. In this work, we also present our system submission for English-Romanian translation. This system uses a factored setting similar to C HIMERA but lacks its two key c"
W16-2325,tufis-etal-2008-racais,0,0.0121309,"el as well. 3.1 Data and Pre-Processing We use all the data available to constrained submissions: Europarl v8 (Koehn, 2005) and SETIMES2 (Tiedemann, 2009) parallel corpora and News 2015 and Common Crawl monolingual corpora.1 We split the official development set into two halves; we use the first part for system tuning and the second part serves as our test set. Data pre-processing differs between English and Romanian. For English, we use Treex (Popel ˇ and Zabokrtsk´ y, 2010) to obtain morphological tags, lemmas and dependency parses of the sentences. For Romanian, we use the online tagger by Tufis et al. (2008) as run by our colleagues at LIMSI-CNRS for the joint QT21 Romanian system (Peter et al., 2016). 3.2 Factored Translation Similarly to C HIMERA, we train a factored phrase table which translates source surface forms to tuples (form, lemma, tag). Our input is factored and contains the form, lemma, morphological tag, 1 387 http://commoncrawl.org/ Setting baseline +tagLM +ccrawl +RM +discTM lemma of dependency parent and analytical function (“surface” syntactic role, e.g. Subj for subjects). These additional source-side factors are again not used by the phrase table and serve only as information"
W16-2325,W16-2320,1,\N,Missing
W17-4704,P98-1080,0,0.398697,"Missing"
W17-4704,W17-4706,1,0.894349,"dress this problem (Toutanova et al., 2008; Bojar and Kos, 2010; Fraser et al., 2012). In two-step SMT, a separate prediction model (such as a linear-chain CRF) is used to either directly predict the surface form (as in Toutanova et al. (2008)) or used to predict the grammatical features, following which morphological generation is performed (as in Bojar and Kos (2010); Fraser et al. (2012)). Our work differs from their work in that we do not use a separate prediction model, but instead rely on predicting the lemmas and surface-forms as a single sequence in a neural machine translation model. Huck et al. (2017b) recently proposed an approach related to two-step MT where the unseen surface forms are added as synthetic phrases directly in the system phrase table and a contextaware discriminative model is applied to score the unseen variants. Unlike our work, the authors report diminishing improvements as training data grows larger. Our approach learns a more robust underlying model thanks to the reduced data sparsity. Unlike Huck et al. (2017b), our improvements are therefore not only due to the ability to generate words which were not seen in the training data. Factored translation models (Koehn and"
W17-4704,E17-2059,1,0.880553,"Missing"
W17-4704,W10-1705,0,0.193071,"ference were found in a set of 328 unseen forms. results obtained in the TED setting, it seems that there is a tendency that compound handling leads to a slight improvement. As compounding is a productive word formation process that is challenging to cover even in large corpora, compound handling might be useful also when using larger data training corpora. 6 Related Work Generation of unseen morphological variants has been tackled in various ways in the context of phrase-based models and other SMT approaches. Notably, two-step SMT was proposed to address this problem (Toutanova et al., 2008; Bojar and Kos, 2010; Fraser et al., 2012). In two-step SMT, a separate prediction model (such as a linear-chain CRF) is used to either directly predict the surface form (as in Toutanova et al. (2008)) or used to predict the grammatical features, following which morphological generation is performed (as in Bojar and Kos (2010); Fraser et al. (2012)). Our work differs from their work in that we do not use a separate prediction model, but instead rely on predicting the lemmas and surface-forms as a single sequence in a neural machine translation model. Huck et al. (2017b) recently proposed an approach related to tw"
W17-4704,D07-1091,0,0.100921,"al. (2017b) recently proposed an approach related to two-step MT where the unseen surface forms are added as synthetic phrases directly in the system phrase table and a contextaware discriminative model is applied to score the unseen variants. Unlike our work, the authors report diminishing improvements as training data grows larger. Our approach learns a more robust underlying model thanks to the reduced data sparsity. Unlike Huck et al. (2017b), our improvements are therefore not only due to the ability to generate words which were not seen in the training data. Factored translation models (Koehn and Hoang, 2007) can deal with unseen word forms thanks to generation steps. One of the original goals of factored MT was in fact the scenario where the system produces lemmas and tags and then a generation step could be used to produce the inflected forms. Factored models failed to achieve this goal due to lemmas and tags being predicted independently, leading to many invalid combinations, and due to the involved combinatorial explosion. Garc´ıa-Mart´ınez et al. (2016) attempt to include target-side factors in neural MT. Unlike our simple technique, their approach requires modifications Different Domain and"
W17-4704,W11-2138,1,0.667633,"rable improvements. For English–German, the addition of compound handling yielded promising results. Furthermore, among the novel word forms for German, most were compounds – as compounding is a very productive process, this is also a challenging problem when using larger corpora. Exploring strategies for better segmentation and compound handling is an interesting task that we plan to investigate further. to the network architecture. The authors work with English-French translation and they report mixed results. Another successful attempt to learn novel inflections in SMT is back-translation (Bojar and Tamchyna, 2011). By using an MT system trained to translate lemmas in the opposite direction, it is possible to create synthetic parallel data which contain unseen word forms of known lemmas on the target side. There are two main downsides to this approach. The first is that the source language contains translation errors, which may affect translation quality. The second is that the substitution of different surface forms for the same target language lemma may result in incoherent translations, where the context no longer agrees with the chosen surface form. Sennrich et al. (2016a) propose to use back-transl"
W17-4704,E14-1061,1,0.885965,"leads to a further reduction. 4.5 src tokens 2309k 25150 28454 Table 4: Sizes of English-Czech corpora. Table 2: The most frequent fragments on word ends after BPE from the German surface data. vocabulary size 121.892 97.587 68.533 sents 114k 1385 1327 Experimental Evaluation In this section, we describe our experiments with English-Czech and English-German translation. Simple Compound Handling 5.1 Another factor contributing to a high vocabulary size is the productivity of German compounds; in SMT, compound handling has been found to improve translation quality, e.g. Stymne et al. (2011) and Cap et al. (2014). In addition to inflectional morphology, SMOR also provides a derivational analysis, including splitting into compound parts: for example, the compound H¨auser|markt (’house market’) is analyzed as Haus<NN&gt;Markt<+NN&gt;<...&gt;. In particular, the modifier is represented by its base form Haus, covering the non-concatenative process of “Umlautung” (Haus ↔ H¨auser). In the stemmed representation, this may already present an indirect advantage, as compounds fragmented through BPE splitting can match other stemmed occurrences of that word. An obvious idea at this point is to go a step further and add c"
W17-4704,2012.eamt-1.60,0,0.0148467,"vantage, as compounds fragmented through BPE splitting can match other stemmed occurrences of that word. An obvious idea at this point is to go a step further and add compound splitting to the pre-processing of the German data. Using the SMOR annotation, compounds are split at mid-word adjective and noun borders. For example, the word Meeres|boden (’sea bottom’) from table 1 is split into two subwords separated by the modifier’s tag: Czech We use the IWSLT training and test sets in English-Czech experiments2 . The training set consists of transcribed TED talks as collected in the WIT3 corpus (Cettolo et al., 2012). We use IWSLT test set 2012 as the held-out set and the 2013 test set for evaluation. Table 4 summarizes the basic data statistics. We use the Nematus toolkit for training the NMT systems (Sennrich et al., 2017). We run BPE training on both sides of the training data with 49500 splits. We set the vocabulary size to 50000 word types. The embedding size is set to 500, the dimension of the hidden layer is 1024. We optimize the model using Adam (Kingma and Ba, 2014) and we use the default early stopping criterion in Nematus. We do not apply drop-out anywhere in the model. Following Nadejde et al."
W17-4704,C04-1024,0,0.0161691,"tain the representation of interleaved lemmas and tag+feature sequences for German, we apply a slightly different pipeline than for the English– Czech setting. Instead of representing a word by a simple lemma and a morphological tag, we use a morphological analyzer covering also productive formation processes – the morphologically complex analyses of the lemma (“stem”) allow us to easily handle compounds, which pose a considerable challenge when translating into German. 4.1 Linguistic Resources The key linguistic knowledge sources to model German morphology are the constituency parser BitPar (Schmid, 2004) to obtain morphological analyses in the sentence context, and the morphological tool SMOR (Schmid et al., 2004) to analyze and generate inflected German surface forms. SMOR is a a morphological analyzer for German inflection and word formation processes implemented in finite state technology. In particular, it also covers productive word formation processes such as compounding or derivation. SMOR functions in two directions: surface form → stem+features and stem+features → surface form. Thus, when preparing the target-side training data, 33 input: there are a million different kinds of pizza"
W17-4704,schmid-etal-2004-smor,0,0.0940886,"ifferent pipeline than for the English– Czech setting. Instead of representing a word by a simple lemma and a morphological tag, we use a morphological analyzer covering also productive formation processes – the morphologically complex analyses of the lemma (“stem”) allow us to easily handle compounds, which pose a considerable challenge when translating into German. 4.1 Linguistic Resources The key linguistic knowledge sources to model German morphology are the constituency parser BitPar (Schmid, 2004) to obtain morphological analyses in the sentence context, and the morphological tool SMOR (Schmid et al., 2004) to analyze and generate inflected German surface forms. SMOR is a a morphological analyzer for German inflection and word formation processes implemented in finite state technology. In particular, it also covers productive word formation processes such as compounding or derivation. SMOR functions in two directions: surface form → stem+features and stem+features → surface form. Thus, when preparing the target-side training data, 33 input: there are a million different kinds of pizza . baseline: existuj´ı miliony druh˚u piz@@ zy . morphgen: VB-P—3P-AA— existovat NNIP1—–A—- mili´on NNIP2—–A—- dr"
W17-4704,E12-1068,1,0.86302,"a set of 328 unseen forms. results obtained in the TED setting, it seems that there is a tendency that compound handling leads to a slight improvement. As compounding is a productive word formation process that is challenging to cover even in large corpora, compound handling might be useful also when using larger data training corpora. 6 Related Work Generation of unseen morphological variants has been tackled in various ways in the context of phrase-based models and other SMT approaches. Notably, two-step SMT was proposed to address this problem (Toutanova et al., 2008; Bojar and Kos, 2010; Fraser et al., 2012). In two-step SMT, a separate prediction model (such as a linear-chain CRF) is used to either directly predict the surface form (as in Toutanova et al. (2008)) or used to predict the grammatical features, following which morphological generation is performed (as in Bojar and Kos (2010); Fraser et al. (2012)). Our work differs from their work in that we do not use a separate prediction model, but instead rely on predicting the lemmas and surface-forms as a single sequence in a neural machine translation model. Huck et al. (2017b) recently proposed an approach related to two-step MT where the un"
W17-4704,E17-3017,0,0.082642,"Missing"
W17-4704,P16-1009,0,0.422319,"cit information about morphological features of target-side words, and (iii) NMT systems cannot systematically generate unseen surface forms of known lemmas: while the combination of subword segments obtained with BPE splitting can technically generate new forms, this is not a linguistically informed way to generate new words, and is furthermore restricted to “simple” concatenative word formation processes. We propose a simple two-step approach to achieve morphological generalization in NMT. In the first step, we use an encoder-decoder NMT system with attention and BPE (Bahdanau et al., 2014; Sennrich et al., 2016b) to generate a sequence of interleaving morphological tags and lemmas. In the second step, we use a morphological generator to produce the final inflected output. This decomposition addresses all three of the problems outlined above: NMT systems have problems with large vocabulary sizes. Byte-pair encoding (BPE) is a popular approach to solving this problem, but while BPE allows the system to generate any target-side word, it does not enable effective generalization over the rich vocabulary in morphologically rich languages with strong inflectional phenomena. We introduce a simple approach t"
W17-4704,P16-1162,0,0.620335,"cit information about morphological features of target-side words, and (iii) NMT systems cannot systematically generate unseen surface forms of known lemmas: while the combination of subword segments obtained with BPE splitting can technically generate new forms, this is not a linguistically informed way to generate new words, and is furthermore restricted to “simple” concatenative word formation processes. We propose a simple two-step approach to achieve morphological generalization in NMT. In the first step, we use an encoder-decoder NMT system with attention and BPE (Bahdanau et al., 2014; Sennrich et al., 2016b) to generate a sequence of interleaving morphological tags and lemmas. In the second step, we use a morphological generator to produce the final inflected output. This decomposition addresses all three of the problems outlined above: NMT systems have problems with large vocabulary sizes. Byte-pair encoding (BPE) is a popular approach to solving this problem, but while BPE allows the system to generate any target-side word, it does not enable effective generalization over the rich vocabulary in morphologically rich languages with strong inflectional phenomena. We introduce a simple approach t"
W17-4704,P14-5003,0,0.100642,"Missing"
W17-4704,P08-1059,0,0.0485214,"y 27 matches with the reference were found in a set of 328 unseen forms. results obtained in the TED setting, it seems that there is a tendency that compound handling leads to a slight improvement. As compounding is a productive word formation process that is challenging to cover even in large corpora, compound handling might be useful also when using larger data training corpora. 6 Related Work Generation of unseen morphological variants has been tackled in various ways in the context of phrase-based models and other SMT approaches. Notably, two-step SMT was proposed to address this problem (Toutanova et al., 2008; Bojar and Kos, 2010; Fraser et al., 2012). In two-step SMT, a separate prediction model (such as a linear-chain CRF) is used to either directly predict the surface form (as in Toutanova et al. (2008)) or used to predict the grammatical features, following which morphological generation is performed (as in Bojar and Kos (2010); Fraser et al. (2012)). Our work differs from their work in that we do not use a separate prediction model, but instead rely on predicting the lemmas and surface-forms as a single sequence in a neural machine translation model. Huck et al. (2017b) recently proposed an a"
W17-4706,E17-2059,1,0.80988,"Missing"
W17-4706,2005.mtsummit-papers.11,0,0.172732,"Missing"
W17-4706,W10-1705,0,0.0891085,"ask. We note that our system was ranked first in the human evaluation of the news task, despite having a lower B LEU score than Edinburgh’s submission. B LEU, which tries to automatically predict how humans will evaluate quality, may unfairly penalize approaches like ours, but more study is needed. 4 Related Work The SMT literature has a wide diversity of approaches in dealing with translation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morph"
W17-4706,D07-1091,0,0.0240877,"the news translation task. We note that our system was ranked first in the human evaluation of the news task, despite having a lower B LEU score than Edinburgh’s submission. B LEU, which tries to automatically predict how humans will evaluate quality, may unfairly penalize approaches like ours, but more study is needed. 4 Related Work The SMT literature has a wide diversity of approaches in dealing with translation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010"
W17-4706,P07-2045,0,0.00473,"5.9 60.9 60.7 60.3 60.0 59.8 59.8 59.9 25.2 25.6 25.5 26.0 25.8 25.9 25.5 60.9 60.9 60.6 60.1 60.2 60.6 60.3 phrase-based (Huck et al., 2015) 22.6 – 22.1 – Table 6: English→German experimental results on Europarl (case-sensitive B LEU and T ER). 3 3.1 Machine Translation Experiments Experimental Setup We conduct an empirical evaluation using encoder-decoder NMT with attention and gated recurrent units as implemented in Nematus (Sennrich et al., 2017). We train and test on English–German Europarl data (Koehn, 2005). The data is tokenized and frequent-cased using scripts from the Moses toolkit (Koehn et al., 2007). Sentences with length >50 after tokenization are excluded from the training corpus, all other sentences (1.7 M) are considered in training under every word segmentation scheme. We set the amount of merge operations for BPE to 50K. Corpus statistics of the German data after different preprocessings are given in Table 5. On the English source side, we apply BPE separately, also with 50K merge operations. For comparison, we build a setup denoted as top 50K voc. (source & target) where we train on the tokenized corpus without any segmentation, limiting the vocabulary to the 50K most frequent wor"
W17-4706,E14-1061,1,0.86134,"ng morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor has also been tried, particularly for dealing with agglutinative languages (Virpioja et al., 2007). Our work is motivated by the same linguistic observations as theirs. Other studies, e.g., (Popovi´c et al., 2006; Stymne, 2008; Cap et al., 2014), model German compounds by splitting them into single simple words in the SMT training data, and then predicting where to merge simple words as a postprocessing step (after SMT decoding). This has similarities to our use of compound splitting and markers in NMT. 5 Conclusion Linguistically motivated target-side word segmentation improves neural machine translation into an inflected and compounding language. The system can learn linguistic word formation processes from the segmented data. For German, we have shown that cascading of suffix splitting—or suffix splitting and compound splitting—wi"
W17-4706,E12-1068,1,0.854517,"system was ranked first in the human evaluation of the news task, despite having a lower B LEU score than Edinburgh’s submission. B LEU, which tries to automatically predict how humans will evaluate quality, may unfairly penalize approaches like ours, but more study is needed. 4 Related Work The SMT literature has a wide diversity of approaches in dealing with translation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, u"
W17-4706,E03-1076,0,0.269925,"rd. For these relationships our approach may be able to automatically and cheaply add (weak) POS information, which might improve translation quality, but this will require further investigation in future work. We would also like to study the relationship between stemming quality and resulting NMT translation quality. Weissweiler and Fraser (2017) have introduced a new stemmer of German and showed that it performs better than Snowball using comparison with gold standards. This may serve as an interesting starting point. BPE word segmentation operates bottom-up from characters to larger units. Koehn and Knight (2003) have proposed a frequency-based word segmentation method that starts from the other end, top-down inspecting full words and looking into whether they are composed of parts which are proper words themselves. Any composed word is segmented into parts such that the geometric mean of word frequencies of its parts (counted in the original corpus) is maximized. This technique represents a suitable approach for compound splitting in natural language processing applications. It has been successfully applied in numerous statistical machine translation systems, mostly on the source language side, but s"
W17-4706,H05-1085,0,0.0191425,"rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor has also been tried, particularly for dealing with agglutinative languages (Virpioja et al., 2007). Our work is motivated by the same linguistic observations as theirs. Other studies, e.g., (Popovi´c et al., 2006; Stymne, 2008; Cap et al., 2014), model German compounds by splitting them into single simple words in the SMT training data, and then predicting where to merge simple wo"
W17-4706,P16-1160,0,0.0307758,"4 There is also starting to be interest in alternatives to BPE in NMT. The Google NMT system (Wu et al., 2016) used wordpiece splitting, which is similar to but different from BPE and would be interesting to evaluate in future work. Ataman et al. (2017) considered both supervised and unsupervised splitting of agglutinative morphemes in Turkish, which is closely related to our ideas. An important difference here is that Turkish is an agglutinative language, while German has fusional inflection and very productive compounding. We are also excited about early work on character-based NMT such as (Lee et al., 2016), which may eventually replace segmentation models like those in our work (or also replace BPE when linguistically aware segmentation is not available). However, at the current stage of research character-based approaches require very long training times and extensive optimization of hyperparameters to make them work, and still do not seem to be able to produce state-of-theart translation quality on a wide range of tasks. More research is needed in making characterbased NMT robust and accessible to many research groups. tems have each learned to translate in different ways, based on the respec"
W17-4706,2007.mtsummit-papers.29,0,0.111134,"urface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor has also been tried, particularly for dealing with agglutinative languages (Virpioja et al., 2007). Our work is motivated by the same linguistic observations as theirs. Other studies, e.g., (Popovi´c et al., 2006; Stymne, 2008; Cap et al., 2014), model German compounds by splitting them into single simple words in the SMT training data, and then predicting where to merge simple words as a postprocessing step (after SMT decoding). This has simila"
W17-4706,P03-1051,0,0.0457279,"anslation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor has also been tried, particularly for dealing with agglutinative languages (Virpioja et al., 2007). Our work is motivated by the same linguistic observations as theirs. Other studies, e.g., (Popovi´c et al., 2006; Stymne, 2008; Cap et al., 2014), model German compounds by splitting them into single simple words in the SMT training data, and"
W17-4706,2015.mtsummit-papers.19,1,0.909261,"Missing"
W17-4706,W07-0704,0,0.0265695,"Missing"
W17-4706,W17-4730,1,0.835218,"parameters to make them work, and still do not seem to be able to produce state-of-theart translation quality on a wide range of tasks. More research is needed in making characterbased NMT robust and accessible to many research groups. tems have each learned to translate in different ways, based on the respective segmentation of the training data. Our cascaded suffix + compound + BPE target word segmentation strategy was employed for LMU Munich’s participation in the WMT17 shared tasks on machine translation of news and of biomedical texts. We refer the reader to the system description paper (Huck et al., 2017a), where we include some interesting translation examples from the news translation task. We note that our system was ranked first in the human evaluation of the news task, despite having a lower B LEU score than Edinburgh’s submission. B LEU, which tries to automatically predict how humans will evaluate quality, may unfairly penalize approaches like ours, but more study is needed. 4 Related Work The SMT literature has a wide diversity of approaches in dealing with translation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms usi"
W17-4706,P02-1040,0,0.102024,"ntences after tokenization but before segmentation, which affects all setups equally. No sentences are discarded after that stage (Nematus’ maxlen > longest sequence in data). We configure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer (Kingma and Ba, 2015), a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer.3 We validate on the test2006 set after every 10 000 updates and do early stopping when the validation cost has not decreased for ten epochs. We evaluate case-sensitive with B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006), computed over postprocessed hypotheses against the raw references with mteval-v13a and tercom.7.25, respectively. Table 5: Target-side training corpus statistics. System test2007 test2008 B LEU T ER B LEU T ER top 50K voc. (source & target) BPE compound + BPE suffix + BPE suffix + compound + BPE suffix + prefix + compound + BPE suffix + prefix + compound, 50K 25.5 25.8 25.9 26.3 26.2 26.1 25.9 60.9 60.7 60.3 60.0 59.8 59.8 59.9 25.2 25.6 25.5 26.0 25.8 25.9 25.5 60.9 60.9 60.6 60.1 60.2 60.6 60.3 phrase-based (Huck et al., 2015) 22.6 – 22.1 – Table 6: English→G"
W17-4706,W17-4704,1,0.854893,"Missing"
W17-4706,N07-1007,0,0.0165009,"ng translation examples from the news translation task. We note that our system was ranked first in the human evaluation of the news task, despite having a lower B LEU score than Edinburgh’s submission. B LEU, which tries to automatically predict how humans will evaluate quality, may unfairly penalize approaches like ours, but more study is needed. 4 Related Work The SMT literature has a wide diversity of approaches in dealing with translation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeni"
W17-4706,E17-3017,0,0.0519559,"ource & target) BPE compound + BPE suffix + BPE suffix + compound + BPE suffix + prefix + compound + BPE suffix + prefix + compound, 50K 25.5 25.8 25.9 26.3 26.2 26.1 25.9 60.9 60.7 60.3 60.0 59.8 59.8 59.9 25.2 25.6 25.5 26.0 25.8 25.9 25.5 60.9 60.9 60.6 60.1 60.2 60.6 60.3 phrase-based (Huck et al., 2015) 22.6 – 22.1 – Table 6: English→German experimental results on Europarl (case-sensitive B LEU and T ER). 3 3.1 Machine Translation Experiments Experimental Setup We conduct an empirical evaluation using encoder-decoder NMT with attention and gated recurrent units as implemented in Nematus (Sennrich et al., 2017). We train and test on English–German Europarl data (Koehn, 2005). The data is tokenized and frequent-cased using scripts from the Moses toolkit (Koehn et al., 2007). Sentences with length >50 after tokenization are excluded from the training corpus, all other sentences (1.7 M) are considered in training under every word segmentation scheme. We set the amount of merge operations for BPE to 50K. Corpus statistics of the German data after different preprocessings are given in Table 5. On the English source side, we apply BPE separately, also with 50K merge operations. For comparison, we build a"
W17-4706,2007.mtsummit-papers.65,0,0.0294509,"or NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor has also been tried, particularly for dealing with agglutinative languages (Virpioja et al., 2007). Our work is motivated by the same linguistic observations as theirs. Other studies, e.g., (Popovi´c et al., 2006; Stymne, 2008; Cap et al., 2014), model German compounds by splitting them into single simple words in the SMT training data, and then predicting where to merge simple words as a postprocessing step (after SMT decoding). This has similarities to our use of compound splitting and markers in NMT. 5 Conclusion Linguistically motivated target-side word segmentation improves neural machine translation into an inflected and compounding language. The system can learn linguistic word form"
W17-4706,P13-1058,1,0.826422,"rst in the human evaluation of the news task, despite having a lower B LEU score than Edinburgh’s submission. B LEU, which tries to automatically predict how humans will evaluate quality, may unfairly penalize approaches like ours, but more study is needed. 4 Related Work The SMT literature has a wide diversity of approaches in dealing with translation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor"
W17-4706,P16-1162,0,0.162103,"n of morphosyntax, narrowing down its capabilities at modeling inflection and compounding. BPE also has no guidelines for splitting words into syllables. This way no phonetic or semantic substructures are taken into account. Therefore BPE splits often appear arbitrary to the human reader, since it appears frequently that subword units ignore syllable boundaries entirely. Word Segmentation Strategies Byte Pair Encoding A technique in the manner of the Byte Pair Encoding (BPE) compression algorithm (Gage, 1994) can be adopted in order to segment words into smaller subword units, as suggested by Sennrich et al. (2016b). The BPE word segmenter conceptionally proceeds by first splitting all words in the whole corpus into individual characters. The most frequent adjacent pairs of symbols are then consecutively merged, until a specified limit of merge operations has been reached. Merge operations are not applied across word boundaries. The merge operations learned on a training corpus can be stored and applied to other data, such as test sets. Nevertheless, NMT systems incorporating BPE word segmentation have achieved top translation quality in recent shared tasks (Sennrich et al., 2016a; Bojar et al., 2016)."
W17-4706,2006.amta-papers.25,0,0.0235575,"fore segmentation, which affects all setups equally. No sentences are discarded after that stage (Nematus’ maxlen > longest sequence in data). We configure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer (Kingma and Ba, 2015), a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer.3 We validate on the test2006 set after every 10 000 updates and do early stopping when the validation cost has not decreased for ten epochs. We evaluate case-sensitive with B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006), computed over postprocessed hypotheses against the raw references with mteval-v13a and tercom.7.25, respectively. Table 5: Target-side training corpus statistics. System test2007 test2008 B LEU T ER B LEU T ER top 50K voc. (source & target) BPE compound + BPE suffix + BPE suffix + compound + BPE suffix + prefix + compound + BPE suffix + prefix + compound, 50K 25.5 25.8 25.9 26.3 26.2 26.1 25.9 60.9 60.7 60.3 60.0 59.8 59.8 59.9 25.2 25.6 25.5 26.0 25.8 25.9 25.5 60.9 60.9 60.6 60.1 60.2 60.6 60.3 phrase-based (Huck et al., 2015) 22.6 – 22.1 – Table 6: English→German experimental results on E"
W17-4706,P10-1047,0,0.0160882,"2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor has also been tried, particularly for dealing with agglutinative languages (Virpioja et al., 2007). Our work is motivated by the same linguistic observations as theirs. Other studies, e.g., (Popovi´c et al., 2006; Stymne, 2008; Cap et al., 2014), model German compounds by splitting them into single simple words in the SMT training data, and then predicting where to merge simple words as a postprocessing step (after SMT decoding). This has similarities to our use of compound splitting and markers in NMT. 5 Conclusion Linguistically"
W17-4706,W16-2323,0,\N,Missing
W17-4706,P16-1161,1,\N,Missing
W17-4706,Q17-1026,0,\N,Missing
W17-4730,D15-1129,1,0.826054,"T setup only. In the human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 315–322 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics focusing on investigating linguistically informed methods that improve machine translation into target languages which exhibit a more complex morphosyntax than English (Huck et al., 2017b; Tamchyna et al., 2016a; Ramm and Fraser, 2016; Weller-Di Marco et al., 2016; Braune et al., 2015; Cap et al., 2014a; Fraser et al., 2012). We are taking advantage of our group’s longstanding experience regarding handling of complex morphosyntax in SMT, now enriching NMT with novel techniques that specifically tackle target-side morphosyntax. In the following section of this paper (Section 2), we sketch our linguistically motivated target word segmentation technique. Then we describe how we trained and configured our neural machine translation systems (Section 3). Before concluding the paper, we present empirical results on the two translation tasks, which involve machine translation of n"
W17-4730,E14-1061,1,0.828521,"human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 315–322 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics focusing on investigating linguistically informed methods that improve machine translation into target languages which exhibit a more complex morphosyntax than English (Huck et al., 2017b; Tamchyna et al., 2016a; Ramm and Fraser, 2016; Weller-Di Marco et al., 2016; Braune et al., 2015; Cap et al., 2014a; Fraser et al., 2012). We are taking advantage of our group’s longstanding experience regarding handling of complex morphosyntax in SMT, now enriching NMT with novel techniques that specifically tackle target-side morphosyntax. In the following section of this paper (Section 2), we sketch our linguistically motivated target word segmentation technique. Then we describe how we trained and configured our neural machine translation systems (Section 3). Before concluding the paper, we present empirical results on the two translation tasks, which involve machine translation of news articles and o"
W17-4730,W13-2213,1,0.857637,"machine translation shared tasks in recent years (Bojar et al., 2016, 2015, 2014, 2013), competing (and also collaborating) internationally in an open evaluation campaign with other leading research labs from both academia and industry. Research on various different types of machine translation models has previously been conducted at LMU. Core SMT paradigms for LMU’s past shared task participations include phrase-based models (Cap et al., 2015, 2014b; Weller et al., 2013; Sajjad et al., 2013), hierarchical phrasebased models (Huck et al., 2016; Peter et al., 2016), operation sequence models (Durrani et al., 2013), and hybrids of statistical approaches with rule-based and deep syntactic components (Tamchyna et al., 2016b). At this year’s EMNLP 2017 Second Conference on Machine Translation (WMT17),1 LMU participated in two shared tasks: the shared task 1 2 Our LMU Munich primary system is ranked second in B LEU on the submission website, http://matrix. statmt.org/matrix/systems_list/1869, being outpaced by Edinburgh’s WMT17 NMT setup only. In the human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine"
W17-4730,E12-1068,1,0.864452,"e LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 315–322 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics focusing on investigating linguistically informed methods that improve machine translation into target languages which exhibit a more complex morphosyntax than English (Huck et al., 2017b; Tamchyna et al., 2016a; Ramm and Fraser, 2016; Weller-Di Marco et al., 2016; Braune et al., 2015; Cap et al., 2014a; Fraser et al., 2012). We are taking advantage of our group’s longstanding experience regarding handling of complex morphosyntax in SMT, now enriching NMT with novel techniques that specifically tackle target-side morphosyntax. In the following section of this paper (Section 2), we sketch our linguistically motivated target word segmentation technique. Then we describe how we trained and configured our neural machine translation systems (Section 3). Before concluding the paper, we present empirical results on the two translation tasks, which involve machine translation of news articles and of health information te"
W17-4730,E14-2008,1,0.829296,"ed model from the preceding step, and optimize on only the small Devsets2008-14 corpus. 4. Right-to-left reranking. We rerank an nbest list from the system in the preceding step with a right-to-left (r2l) model, where the order of the target sequence is reversed. Liu et al. (2016) have proposed right-to-left reranking for NMT. Earlier work by Freitag et al. (2013) had already established that reverse word order models can be beneficial in phrase-based and hierarchical phrase-based translation. Freitag et al. (2013) utilized reverse word order models by means of a system combination framework (Freitag et al., 2014), though. splitting and compound splitting, but to omit prefix splitting. The English source side is simply BPEsegmented. 3 Neural Translation System Setup We utilize the Nematus implementation (Sennrich et al., 2017) to build encoder-decoder NMT systems with attention and gated recurrent units. We configure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer (Kingma and Ba, 2015), a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer, but not to source, target, and embeddings. We validate ever"
W17-4730,E03-1076,0,0.212051,"es that specifically tackle target-side morphosyntax. In the following section of this paper (Section 2), we sketch our linguistically motivated target word segmentation technique. Then we describe how we trained and configured our neural machine translation systems (Section 3). Before concluding the paper, we present empirical results on the two translation tasks, which involve machine translation of news articles and of health information texts (Section 4). 2 off. It otherwise behaves just like the Snowball stemming algorithm. 2. Next we apply the empirical compound splitter as described by Koehn and Knight (2003) and as implemented in the Perl script which is part of the Moses toolkit (Koehn et al., 2007). We choose a fairly aggressive configuration of the compound splitter4 in order to reduce the vocabulary size more than with its parameters as typically chosen for previous phrase-based translation setups in which German compound splitting was used. 3. Since the vocabulary size is still a bit large after suffix splitting and compound splitting, we adopt segmentation using the Byte Pair Encoding (BPE) technique (Gage, 1994; Sennrich et al., 2016c) on top of the other two word splitters. This last step"
W17-4730,2015.mtsummit-papers.19,1,0.84912,"ystem to suppress UNK tokens in inference at test time. For the shared task on machine translation of news (Bojar et al., 2017), we successively improved our initial baseline by incrementally applying the following steps: 1. Adding the News Commentary (NC) and Common Crawl (CC) parallel training data as provided for WMT17 by the organizers of the news translation shared task. We initialize the optimization on the larger corpus with the Europarl-trained baseline model. 5 http://data.statmt.org/rsennrich/ wmt16_backtranslations/en-de/ 317 system this seems to be mostly due to a domain mismatch (Huck et al., 2015). Once we add in the News Commentary and Common Crawl parallel data, we are able to massively improve the translation quality, by around six to seven B LEU points. Synthetic data gives us a boost of about another two B LEU points. After fine-tuning on Devsets200814 towards news articles, we observe a further gain of 0.4 B LEU on newstest2015 but no gain on newstest2016. Reranking with a right-to-left model is effective on all test sets again, with improvements in the range of 0.4 to 1.1 B LEU. Two LMU submissions have been judged by humans in the manual evaluation for the WMT17 news translatio"
W17-4730,W11-2132,0,0.130804,"suffix 1. First we apply a suffix splitter that separates common German morphological suffixes from the word stems. We modified the German Snowball stemming algorithm from NLTK3 for that purpose. Rather than stripping suffixes, our modified code splits them 3 http://www.nltk.org/_modules/nltk/ stem/snowball.html 4 -min-size 4 -min-count 2 -max-count 999999999 316 2. Adding synthetic training data. The use of automatically translated monolingual data as a supplementary training resource has proved to be effective in SMT for phrase-based, hierarchical, and neural systems (Ueffing et al., 2007; Lambert et al., 2011; Huck et al., 2011; Huck and Ney, 2012; Sennrich et al., 2016b). Sennrich et al. have publicly shared their backtranslations of monolingual WMT News Crawl corpora, which they created for their WMT16 participation (Sennrich et al., 2016a). We exploit the full amount of backtranslations of German data into English.5 We concatenate the synthetic data and the human-generated parallel training data (Europarl + NC + CC). The optimization is initialized with the pre-trained model from the preceding step. 3. Fine-tuning towards the domain of news articles. We employ the newstest development sets from"
W17-4730,W16-2315,1,0.869018,"omanian, Russian, or French. LMU has frequently participated in WMT machine translation shared tasks in recent years (Bojar et al., 2016, 2015, 2014, 2013), competing (and also collaborating) internationally in an open evaluation campaign with other leading research labs from both academia and industry. Research on various different types of machine translation models has previously been conducted at LMU. Core SMT paradigms for LMU’s past shared task participations include phrase-based models (Cap et al., 2015, 2014b; Weller et al., 2013; Sajjad et al., 2013), hierarchical phrasebased models (Huck et al., 2016; Peter et al., 2016), operation sequence models (Durrani et al., 2013), and hybrids of statistical approaches with rule-based and deep syntactic components (Tamchyna et al., 2016b). At this year’s EMNLP 2017 Second Conference on Machine Translation (WMT17),1 LMU participated in two shared tasks: the shared task 1 2 Our LMU Munich primary system is ranked second in B LEU on the submission website, http://matrix. statmt.org/matrix/systems_list/1869, being outpaced by Edinburgh’s WMT17 NMT setup only. In the human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). htt"
W17-4730,N16-1046,0,0.0814608,"Missing"
W17-4730,2012.amta-papers.8,1,0.824358,"er that separates common German morphological suffixes from the word stems. We modified the German Snowball stemming algorithm from NLTK3 for that purpose. Rather than stripping suffixes, our modified code splits them 3 http://www.nltk.org/_modules/nltk/ stem/snowball.html 4 -min-size 4 -min-count 2 -max-count 999999999 316 2. Adding synthetic training data. The use of automatically translated monolingual data as a supplementary training resource has proved to be effective in SMT for phrase-based, hierarchical, and neural systems (Ueffing et al., 2007; Lambert et al., 2011; Huck et al., 2011; Huck and Ney, 2012; Sennrich et al., 2016b). Sennrich et al. have publicly shared their backtranslations of monolingual WMT News Crawl corpora, which they created for their WMT16 participation (Sennrich et al., 2016a). We exploit the full amount of backtranslations of German data into English.5 We concatenate the synthetic data and the human-generated parallel training data (Europarl + NC + CC). The optimization is initialized with the pre-trained model from the preceding step. 3. Fine-tuning towards the domain of news articles. We employ the newstest development sets from the years 2008 to 2014 as a training c"
W17-4730,W17-4706,1,0.915939,"bsite, http://matrix. statmt.org/matrix/systems_list/1869, being outpaced by Edinburgh’s WMT17 NMT setup only. In the human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 315–322 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics focusing on investigating linguistically informed methods that improve machine translation into target languages which exhibit a more complex morphosyntax than English (Huck et al., 2017b; Tamchyna et al., 2016a; Ramm and Fraser, 2016; Weller-Di Marco et al., 2016; Braune et al., 2015; Cap et al., 2014a; Fraser et al., 2012). We are taking advantage of our group’s longstanding experience regarding handling of complex morphosyntax in SMT, now enriching NMT with novel techniques that specifically tackle target-side morphosyntax. In the following section of this paper (Section 2), we sketch our linguistically motivated target word segmentation technique. Then we describe how we trained and configured our neural machine translation systems (Section 3). Before concluding the paper"
W17-4730,P02-1040,0,0.0995222,"translation (Sutskever et al., 2014; Bahdanau et al., 2014) are now largely successful for many language pairs and domains. This has for instance become apparent with the University of Edinburgh’s excellent results in the WMT16 news translation shared task with neural systems (Sennrich et al., 2016a), which outperformed most other submitted systems, including Edinburgh’s own traditional SMT engines (Williams et al., 2016). LMU’s English→German neural machine translation systems confirm this trend. We have achieved competitive performance—in terms of translation quality as measured with B LEU (Papineni et al., 2002)—in both shared tasks that we participated in.2 A unique characteristic of the LMU English→German NMT systems is a linguistically informed, cascaded word segmentation technique that we developed and applied to the German target language side of the training data. Amongst other aspects, SMT research at LMU is This paper describes the LMU Munich English→German machine translation systems. We participated with neural translation engines in the WMT17 shared task on machine translation of news, as well as in the biomedical translation task. LMU Munich’s systems deliver competitive machine translati"
W17-4730,E17-2059,1,0.710966,"Missing"
W17-4730,W11-2211,1,0.819082,"ply a suffix splitter that separates common German morphological suffixes from the word stems. We modified the German Snowball stemming algorithm from NLTK3 for that purpose. Rather than stripping suffixes, our modified code splits them 3 http://www.nltk.org/_modules/nltk/ stem/snowball.html 4 -min-size 4 -min-count 2 -max-count 999999999 316 2. Adding synthetic training data. The use of automatically translated monolingual data as a supplementary training resource has proved to be effective in SMT for phrase-based, hierarchical, and neural systems (Ueffing et al., 2007; Lambert et al., 2011; Huck et al., 2011; Huck and Ney, 2012; Sennrich et al., 2016b). Sennrich et al. have publicly shared their backtranslations of monolingual WMT News Crawl corpora, which they created for their WMT16 participation (Sennrich et al., 2016a). We exploit the full amount of backtranslations of German data into English.5 We concatenate the synthetic data and the human-generated parallel training data (Europarl + NC + CC). The optimization is initialized with the pre-trained model from the preceding step. 3. Fine-tuning towards the domain of news articles. We employ the newstest development sets from the years 2008 to"
W17-4730,W16-2203,1,0.845551,"ems_list/1869, being outpaced by Edinburgh’s WMT17 NMT setup only. In the human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 315–322 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics focusing on investigating linguistically informed methods that improve machine translation into target languages which exhibit a more complex morphosyntax than English (Huck et al., 2017b; Tamchyna et al., 2016a; Ramm and Fraser, 2016; Weller-Di Marco et al., 2016; Braune et al., 2015; Cap et al., 2014a; Fraser et al., 2012). We are taking advantage of our group’s longstanding experience regarding handling of complex morphosyntax in SMT, now enriching NMT with novel techniques that specifically tackle target-side morphosyntax. In the following section of this paper (Section 2), we sketch our linguistically motivated target word segmentation technique. Then we describe how we trained and configured our neural machine translation systems (Section 3). Before concluding the paper, we present empirical results on the two transl"
W17-4730,2005.mtsummit-papers.11,0,0.349352,"Missing"
W17-4730,W13-2228,1,0.875938,"Missing"
W17-4730,E17-3017,0,0.0582441,"e the order of the target sequence is reversed. Liu et al. (2016) have proposed right-to-left reranking for NMT. Earlier work by Freitag et al. (2013) had already established that reverse word order models can be beneficial in phrase-based and hierarchical phrase-based translation. Freitag et al. (2013) utilized reverse word order models by means of a system combination framework (Freitag et al., 2014), though. splitting and compound splitting, but to omit prefix splitting. The English source side is simply BPEsegmented. 3 Neural Translation System Setup We utilize the Nematus implementation (Sennrich et al., 2017) to build encoder-decoder NMT systems with attention and gated recurrent units. We configure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer (Kingma and Ba, 2015), a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer, but not to source, target, and embeddings. We validate every 10 000 updates and do early stopping when the validation cost has not decreased over ten consecutive control points. Our initial baseline NMT system is trained using only data from the Europarl corpus (Koehn, 2005)"
W17-4730,W16-2205,1,0.890776,"Missing"
W17-4730,W16-2327,1,0.829844,"additional parallel training data from the in-domain sections of the UFAL Medical Corpus v.1.0. We have trained neural machine translation (NMT) models this year. Neural network models for machine translation (Sutskever et al., 2014; Bahdanau et al., 2014) are now largely successful for many language pairs and domains. This has for instance become apparent with the University of Edinburgh’s excellent results in the WMT16 news translation shared task with neural systems (Sennrich et al., 2016a), which outperformed most other submitted systems, including Edinburgh’s own traditional SMT engines (Williams et al., 2016). LMU’s English→German neural machine translation systems confirm this trend. We have achieved competitive performance—in terms of translation quality as measured with B LEU (Papineni et al., 2002)—in both shared tasks that we participated in.2 A unique characteristic of the LMU English→German NMT systems is a linguistically informed, cascaded word segmentation technique that we developed and applied to the German target language side of the training data. Amongst other aspects, SMT research at LMU is This paper describes the LMU Munich English→German machine translation systems. We participat"
W17-4730,P16-1009,0,0.436137,"for the biomedical task builds upon our news task system, but was domain-adapted towards the medical domain via the usage of additional parallel training data from the in-domain sections of the UFAL Medical Corpus v.1.0. We have trained neural machine translation (NMT) models this year. Neural network models for machine translation (Sutskever et al., 2014; Bahdanau et al., 2014) are now largely successful for many language pairs and domains. This has for instance become apparent with the University of Edinburgh’s excellent results in the WMT16 news translation shared task with neural systems (Sennrich et al., 2016a), which outperformed most other submitted systems, including Edinburgh’s own traditional SMT engines (Williams et al., 2016). LMU’s English→German neural machine translation systems confirm this trend. We have achieved competitive performance—in terms of translation quality as measured with B LEU (Papineni et al., 2002)—in both shared tasks that we participated in.2 A unique characteristic of the LMU English→German NMT systems is a linguistically informed, cascaded word segmentation technique that we developed and applied to the German target language side of the training data. Amongst other"
W17-4730,P16-1162,0,0.691355,"for the biomedical task builds upon our news task system, but was domain-adapted towards the medical domain via the usage of additional parallel training data from the in-domain sections of the UFAL Medical Corpus v.1.0. We have trained neural machine translation (NMT) models this year. Neural network models for machine translation (Sutskever et al., 2014; Bahdanau et al., 2014) are now largely successful for many language pairs and domains. This has for instance become apparent with the University of Edinburgh’s excellent results in the WMT16 news translation shared task with neural systems (Sennrich et al., 2016a), which outperformed most other submitted systems, including Edinburgh’s own traditional SMT engines (Williams et al., 2016). LMU’s English→German neural machine translation systems confirm this trend. We have achieved competitive performance—in terms of translation quality as measured with B LEU (Papineni et al., 2002)—in both shared tasks that we participated in.2 A unique characteristic of the LMU English→German NMT systems is a linguistically informed, cascaded word segmentation technique that we developed and applied to the German target language side of the training data. Amongst other"
W17-4730,P16-1161,1,0.885485,"Missing"
W17-4730,W16-2325,1,0.841956,"o collaborating) internationally in an open evaluation campaign with other leading research labs from both academia and industry. Research on various different types of machine translation models has previously been conducted at LMU. Core SMT paradigms for LMU’s past shared task participations include phrase-based models (Cap et al., 2015, 2014b; Weller et al., 2013; Sajjad et al., 2013), hierarchical phrasebased models (Huck et al., 2016; Peter et al., 2016), operation sequence models (Durrani et al., 2013), and hybrids of statistical approaches with rule-based and deep syntactic components (Tamchyna et al., 2016b). At this year’s EMNLP 2017 Second Conference on Machine Translation (WMT17),1 LMU participated in two shared tasks: the shared task 1 2 Our LMU Munich primary system is ranked second in B LEU on the submission website, http://matrix. statmt.org/matrix/systems_list/1869, being outpaced by Edinburgh’s WMT17 NMT setup only. In the human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 315–322 c Copenhagen, Denmark, September 711, 2017. 2"
W17-4730,P07-2045,0,\N,Missing
W17-4730,W14-3305,1,\N,Missing
W17-4730,W15-3007,1,\N,Missing
W17-4730,W16-2323,0,\N,Missing
W17-4730,W17-4717,1,\N,Missing
W18-1805,P17-1080,0,0.0221371,"ck et al., 2017b,a). Not all prior research on MRLs in traditional phrase-based MT can be readily transferred to NMT. One of the most promising attemps to date is following the theme of two-step MT. A second-step module generates inﬂections from lemmas and morphological tags. The ﬁrst-step NMT module outputs interleaved sequences of such lemmas and their respective tags (Burlot et al., 2016, 2017; Tamchyna et al., 2017). Research on how to best model morphology with neural networks is ongoing, in MT and in other areas of NLP (Botha and Blunsom, 2014; Ebert et al., 2016; Vania and Lopez, 2017; Belinkov et al., 2017; Garc´ıa-Mart´ınez et al., 2016; Garc´ıa-Mart´ınez et al., 2017; Burlot and Yvon, 2017). 2.2 Morphological Tagging of Lemmas: Utility and Limitations Morphological tagging is the task of marking up each token in an input sequence with the corresponding morphological features which describe its inﬂectional properties. In the case of morphologically poor languages, a word can usually be described sufﬁciently using information about its POS tag (Mueller et al., 2013). MRLs require a more detailed analysis. The term MRL refers to a language where word shapes encode a consistent number of syntacti"
W18-1805,W07-0735,0,0.134385,"problem and counteract data sparsity. Arabic is a prominent example of a language that typically undergoes heavy morphosyntactic analysis and preprocessing on the source side (Lee, 2004; Habash and Sadat, 2006; Hasan et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotation (Stymne et al., 2008; Huck and Birch, 2015) are more tractable alternatives. Phrase-based translation models, accompanied with n-gram language models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is mor"
W18-1805,W10-1705,0,0.0195291,"studied by Minkov et al. (2007). We differ in two ways: (1.) we implement a state-of-the-art neural tagger, rather than a Maximum Entropy Markov model, and (2.) we predict rich morphological POS, rather than surface forms. Studying the prediction of morphologically rich POS given lemmas is an interesting problem in its own right. It has implications for NLP applications involving the generation of MRL sentences including machine translation. A concrete application is to apply it in an end-to-end MT system. Similar morphological prediction systems have been applied by Toutanova et al. (2008), Bojar and Kos (2010) and Fraser et al. (2012) in phrase-based SMT. A pipeline of such a system is depicted in Figure 1. Given the promising results in this initial study, we plan to combine our tagger with a standard neural machine translation model, resulting in a multi-task system which produces pairs of lemmas and morphologically rich POS tags. An important beneﬁt of such a system over previous approaches which produce such pairs directly using a standard NMT model (e.g., Tamchyna et al. (2017)) is that we will be able to train it in a multi-task fashion, where some Proceedings of AMTA 2018, vol. 1: MT Researc"
W18-1805,W17-4703,0,0.0363397,"Missing"
W18-1805,W17-4705,0,0.0532634,"Missing"
W18-1805,D13-1174,0,0.0241702,"guage models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exhibited by the target-side MRL, thus taking the burden of the inﬂection selection away from the phrase-based decoder. Chahuneau et al. (2013) and Huck et al. (2017c), on the other hand, have speciﬁcally looked into how to produce unseen morphological variants without resorting to a factored generation step. To that end, they augment their phrase tables with synthetic entries. Other researchers have proposed two-step approaches to MT into MRLs, where the output of the ﬁrst step (the actual translation) lacks certain morphological features of the MRL, which in turn have to be predicted by a separate module in a second step in order to end up with inﬂected target language sentences (Toutanova et al., 2008; Fraser et al., 2012). Slight"
W18-1805,P11-1004,0,0.0199609,"nto MRLs, where the output of the ﬁrst step (the actual translation) lacks certain morphological features of the MRL, which in turn have to be predicted by a separate module in a second step in order to end up with inﬂected target language sentences (Toutanova et al., 2008; Fraser et al., 2012). Slightly less supervision might be required by another technique for tackling rich morphology on the target side: word segmentation, and subsequent modeling on a subword level. Inﬂected target words in the training data can e.g. be segmented into stems and morphological afﬁxes (Fishel and Kirik, 2010; Clifton and Sarkar, 2011; Passban et al., 2017). The segmentation of output hypotheses of the MT system needs to be reverted in postprocessing. In modern neural machine translation engines, word segmentation by means of a Byte Pair Encoding (BPE) style algorithm is a common trick to shrink the vocabulary size (Sennrich et al., 2016). Recent research has shown that NMT of MRLs beneﬁts from word segmentation techniques that are linguistically more informed than plain BPE (Ataman et al., 2017; Pinnis et al., 2017; Huck et al., 2017b,a). Not all prior research on MRLs in traditional phrase-based MT can be readily transfe"
W18-1805,N15-1140,0,0.0247419,"Missing"
W18-1805,2015.mtsummit-papers.22,0,0.037757,"Missing"
W18-1805,D16-1071,0,0.0588349,"Missing"
W18-1805,fishel-kirik-2010-linguistically,0,0.027136,"-step approaches to MT into MRLs, where the output of the ﬁrst step (the actual translation) lacks certain morphological features of the MRL, which in turn have to be predicted by a separate module in a second step in order to end up with inﬂected target language sentences (Toutanova et al., 2008; Fraser et al., 2012). Slightly less supervision might be required by another technique for tackling rich morphology on the target side: word segmentation, and subsequent modeling on a subword level. Inﬂected target words in the training data can e.g. be segmented into stems and morphological afﬁxes (Fishel and Kirik, 2010; Clifton and Sarkar, 2011; Passban et al., 2017). The segmentation of output hypotheses of the MT system needs to be reverted in postprocessing. In modern neural machine translation engines, word segmentation by means of a Byte Pair Encoding (BPE) style algorithm is a common trick to shrink the vocabulary size (Sennrich et al., 2016). Recent research has shown that NMT of MRLs beneﬁts from word segmentation techniques that are linguistically more informed than plain BPE (Ataman et al., 2017; Pinnis et al., 2017; Huck et al., 2017b,a). Not all prior research on MRLs in traditional phrase-based"
W18-1805,P16-5005,0,0.0489311,"Missing"
W18-1805,H05-1085,0,0.0299749,"erpart is morphologically underspeciﬁed, which complicates both statistical modeling and search. Data-driven approaches over MRLs furthermore suffer eminently from data sparsity issues under mediumto low-resource conditions. Many inﬂected forms are observed rarely. Source-side MRL. Rich morphology on the source side can to some extent be tackled via preprocessing. Syntactic and morphological analyzers can be employed, based on which a source sentence representation can be constructed which is more appropriate as the input to a translation system (Popovi´c and Ney, 2004; Popovi´c et al., 2005; Goldwater and McClosky, 2005). E.g., certain morphological features of the source words may be dismissed beforehand. Non-reversible modiﬁcations are uncritical on the source side and can potentially alleviate the modeling problem and counteract data sparsity. Arabic is a prominent example of a language that typically undergoes heavy morphosyntactic analysis and preprocessing on the source side (Lee, 2004; Habash and Sadat, 2006; Hasan et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the"
W18-1805,N06-2013,0,0.0131544,"be employed, based on which a source sentence representation can be constructed which is more appropriate as the input to a translation system (Popovi´c and Ney, 2004; Popovi´c et al., 2005; Goldwater and McClosky, 2005). E.g., certain morphological features of the source words may be dismissed beforehand. Non-reversible modiﬁcations are uncritical on the source side and can potentially alleviate the modeling problem and counteract data sparsity. Arabic is a prominent example of a language that typically undergoes heavy morphosyntactic analysis and preprocessing on the source side (Lee, 2004; Habash and Sadat, 2006; Hasan et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotati"
W18-1805,2015.iwslt-evaluation.4,1,0.86099,"oceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotation (Stymne et al., 2008; Huck and Birch, 2015) are more tractable alternatives. Phrase-based translation models, accompanied with n-gram language models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exhibited by the target-si"
W18-1805,W17-4730,1,0.910587,"ely limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exhibited by the target-side MRL, thus taking the burden of the inﬂection selection away from the phrase-based decoder. Chahuneau et al. (2013) and Huck et al. (2017c), on the other hand, have speciﬁcally looked into how to produce unseen morphological variants without resorting to a factored generation step. To that end, they augment their phrase tables with synthetic entries. Other researchers have proposed two-step approaches to MT into MRLs, where the output of the ﬁrst step (the actual translation) lacks certain morphological features of the MRL, which in turn have to be predicted by a separate module in a second step in order to end up with inﬂected target language sentences (Toutanova et al., 2008; Fraser et al., 2012). Slightly less supervision mi"
W18-1805,W17-4706,1,0.908664,"ely limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exhibited by the target-side MRL, thus taking the burden of the inﬂection selection away from the phrase-based decoder. Chahuneau et al. (2013) and Huck et al. (2017c), on the other hand, have speciﬁcally looked into how to produce unseen morphological variants without resorting to a factored generation step. To that end, they augment their phrase tables with synthetic entries. Other researchers have proposed two-step approaches to MT into MRLs, where the output of the ﬁrst step (the actual translation) lacks certain morphological features of the MRL, which in turn have to be predicted by a separate module in a second step in order to end up with inﬂected target language sentences (Toutanova et al., 2008; Fraser et al., 2012). Slightly less supervision mi"
W18-1805,E17-2059,1,0.637994,"ely limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exhibited by the target-side MRL, thus taking the burden of the inﬂection selection away from the phrase-based decoder. Chahuneau et al. (2013) and Huck et al. (2017c), on the other hand, have speciﬁcally looked into how to produce unseen morphological variants without resorting to a factored generation step. To that end, they augment their phrase tables with synthetic entries. Other researchers have proposed two-step approaches to MT into MRLs, where the output of the ﬁrst step (the actual translation) lacks certain morphological features of the MRL, which in turn have to be predicted by a separate module in a second step in order to end up with inﬂected target language sentences (Toutanova et al., 2008; Fraser et al., 2012). Slightly less supervision mi"
W18-1805,2005.mtsummit-papers.11,0,0.216382,"nd-to-end NLP system that involves our tagger, one would typically strive for a good match between the training data of the tagger and the training data of the other components, so as to achieve ideal interaction between them. But corpora that are manually annotated with lemma and ﬁne-grained POS will rarely ever be at hand for most tasks. Common practice in most practical scenarios would be to synthetically annotate the task-speciﬁc training corpus. We follow this real-world rationale and work with synthetic annotation in our study. Data and preprocessing. We train on the Europarl v7 corpus (Koehn, 2005). The conventional Europarl test sets (test2006, test2007, test2008) that had been released for the WMT shared task are used for development and testing.1 Our main tagging evaluation results will be reported on test2007, which we abbreviate as test in most tables, while test2006 serves as our dev set. The corpora are tokenized and frequent-cased using scripts from the Moses toolkit.2 They are then annotated with lemmas, POS tags, and morphological tags with the pretrained tagging model for German provided by the M AR M OT toolkit.3 M AR M OT is a CRF-based tagger with a reported accuracy of 97"
W18-1805,2012.amta-papers.9,0,0.045504,"dergoes heavy morphosyntactic analysis and preprocessing on the source side (Lee, 2004; Habash and Sadat, 2006; Hasan et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotation (Stymne et al., 2008; Huck and Birch, 2015) are more tractable alternatives. Phrase-based translation models, accompanied with n-gram language models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and"
W18-1805,D07-1091,0,0.0452999,"forehand. Non-reversible modiﬁcations are uncritical on the source side and can potentially alleviate the modeling problem and counteract data sparsity. Arabic is a prominent example of a language that typically undergoes heavy morphosyntactic analysis and preprocessing on the source side (Lee, 2004; Habash and Sadat, 2006; Hasan et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotation (Stymne et al., 2008; Huck and Birch, 2015) are more tractable alternatives. Phrase-based translation models, accompanied with n-gram language models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In synta"
W18-1805,D15-1025,0,0.0526097,"Missing"
W18-1805,N16-1030,0,0.0327702,"ree features described above. The one-hot vector representations are then projected into real-valued dense vector representations (embeddings). The lemma, the capitalization, and the sufﬁx embeddings are then concatenated in order to obtain a single vector representation for each input symbol. The central body of the architecture are three stacked bidirectional recurrent layers, using GRUs as recurrent cells. The choice of bidirectional recurrent layers over traditional feedforward layer was motivated by the promising results obtained in other labeling tasks, such as named entity recognition (Lample et al., 2016). The use of GRUs was preferred over LSTMs because their simpler internal structure allows for faster training, showing comparable results in preliminary experiments. Inspired by Heigold et al. (2016), we add skip connections between the ﬁrst and the third bidirectional recurrent layer to allow for direct propagation of information between layers at different levels of depth. At the top of the architecture, a time-distributed densely-connected layer produces one |T |-dimensional vector per time step, where |T |is the tagset size. Finally, the output label at each time step is given by a softma"
W18-1805,N04-4015,0,0.0738797,"lyzers can be employed, based on which a source sentence representation can be constructed which is more appropriate as the input to a translation system (Popovi´c and Ney, 2004; Popovi´c et al., 2005; Goldwater and McClosky, 2005). E.g., certain morphological features of the source words may be dismissed beforehand. Non-reversible modiﬁcations are uncritical on the source side and can potentially alleviate the modeling problem and counteract data sparsity. Arabic is a prominent example of a language that typically undergoes heavy morphosyntactic analysis and preprocessing on the source side (Lee, 2004; Habash and Sadat, 2006; Hasan et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas"
W18-1805,D13-1032,0,0.0667204,"Missing"
W18-1805,D15-1272,1,0.910056,"Missing"
W18-1805,W17-4708,0,0.0222711,"ed by Costa-Juss`a and Escolano (2016) would not generalize to other language pairs. 6 Conclusion This work introduces a system for morphological tagging over lemmatized (that is, completely unspeciﬁed) input sequences. A detailed intrinsic and extrinsic evaluation showed that our language independent tagger reaches a very high performance by jointly predicting up to 8 morphological features, leading up to 678 possible combinations (considering POS+morph labels). As a next step we will explore the implementation of a a multi-task system which produces pairs of lemmas and morphological labels. Niehues and Cho (2017) explored a multi-task NMT system producing coarse POS labels for the source language as well as words in the target language. We will instead produce lemmas in the target language, and at the same time use our tagger component to produce rich target POS. By giving our tagger access to the source sentences, we will overcome the limitations in our currently semantically underspeciﬁed representation, where, e.g., plural is not marked. Importantly, we will be able to train this system in a multitask fashion, where some training examples contain source language text (from parallel data), while oth"
W18-1805,P02-1040,0,0.102891,"al., 2017). We train and test on the English–German Europarl data. In the NMT systems’ training corpus, words are tokenized and frequent-cased, then segmented via byte-pair-encoding (BPE) (Sennrich et al., 2016) with 50K merge operations; likewise for lemmas, but with BPE operations extracted from the lemmatized data. We conﬁgure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer, a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer. Translation quality is measured case-sensitive with B LEU (Papineni et al., 2002). In Table 7, we use B LEU computed on lemmas (Lemma-B LEU), to show that we get a small gain in lexical choice (of the lemma) in the pipelined approach, where the NMT engine is trained to produce lemmas. However, the B LEU scores over fully inﬂected words in Table 8 suggest that a simple pipelined approach is not sufﬁcient for end-to-end MT. We looked at the MT output and saw that it was mostly coherent, but there was confusion on features like number, tense, and mood. The slightly improved lexical choice of the lemma does not compensate for the loss that derives from the inherent limitations"
W18-1805,popovic-ney-2004-towards,0,0.148929,"Missing"
W18-1805,W05-0806,0,0.120155,"Missing"
W18-1805,E17-3017,0,0.0333304,"Missing"
W18-1805,P16-1162,0,0.246992,"upervision might be required by another technique for tackling rich morphology on the target side: word segmentation, and subsequent modeling on a subword level. Inﬂected target words in the training data can e.g. be segmented into stems and morphological afﬁxes (Fishel and Kirik, 2010; Clifton and Sarkar, 2011; Passban et al., 2017). The segmentation of output hypotheses of the MT system needs to be reverted in postprocessing. In modern neural machine translation engines, word segmentation by means of a Byte Pair Encoding (BPE) style algorithm is a common trick to shrink the vocabulary size (Sennrich et al., 2016). Recent research has shown that NMT of MRLs beneﬁts from word segmentation techniques that are linguistically more informed than plain BPE (Ataman et al., 2017; Pinnis et al., 2017; Huck et al., 2017b,a). Not all prior research on MRLs in traditional phrase-based MT can be readily transferred to NMT. One of the most promising attemps to date is following the theme of two-step MT. A second-step module generates inﬂections from lemmas and morphological tags. The ﬁrst-step NMT module outputs interleaved sequences of such lemmas and their respective tags (Burlot et al., 2016, 2017; Tamchyna et al"
W18-1805,W08-0317,0,0.0311946,"san et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotation (Stymne et al., 2008; Huck and Birch, 2015) are more tractable alternatives. Phrase-based translation models, accompanied with n-gram language models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exh"
W18-1805,W17-4704,1,0.890649,"Missing"
W18-1805,P08-1059,0,0.138821,"This task was previously studied by Minkov et al. (2007). We differ in two ways: (1.) we implement a state-of-the-art neural tagger, rather than a Maximum Entropy Markov model, and (2.) we predict rich morphological POS, rather than surface forms. Studying the prediction of morphologically rich POS given lemmas is an interesting problem in its own right. It has implications for NLP applications involving the generation of MRL sentences including machine translation. A concrete application is to apply it in an end-to-end MT system. Similar morphological prediction systems have been applied by Toutanova et al. (2008), Bojar and Kos (2010) and Fraser et al. (2012) in phrase-based SMT. A pipeline of such a system is depicted in Figure 1. Given the promising results in this initial study, we plan to combine our tagger with a standard neural machine translation model, resulting in a multi-task system which produces pairs of lemmas and morphologically rich POS tags. An important beneﬁt of such a system over previous approaches which produce such pairs directly using a standard NMT model (e.g., Tamchyna et al. (2017)) is that we will be able to train it in a multi-task fashion, where some Proceedings of AMTA 20"
W18-1805,P17-1184,0,0.0149416,"Pinnis et al., 2017; Huck et al., 2017b,a). Not all prior research on MRLs in traditional phrase-based MT can be readily transferred to NMT. One of the most promising attemps to date is following the theme of two-step MT. A second-step module generates inﬂections from lemmas and morphological tags. The ﬁrst-step NMT module outputs interleaved sequences of such lemmas and their respective tags (Burlot et al., 2016, 2017; Tamchyna et al., 2017). Research on how to best model morphology with neural networks is ongoing, in MT and in other areas of NLP (Botha and Blunsom, 2014; Ebert et al., 2016; Vania and Lopez, 2017; Belinkov et al., 2017; Garc´ıa-Mart´ınez et al., 2016; Garc´ıa-Mart´ınez et al., 2017; Burlot and Yvon, 2017). 2.2 Morphological Tagging of Lemmas: Utility and Limitations Morphological tagging is the task of marking up each token in an input sequence with the corresponding morphological features which describe its inﬂectional properties. In the case of morphologically poor languages, a word can usually be described sufﬁciently using information about its POS tag (Mueller et al., 2013). MRLs require a more detailed analysis. The term MRL refers to a language where word shapes encode a consis"
W18-1805,W11-2126,0,0.0207826,"-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotation (Stymne et al., 2008; Huck and Birch, 2015) are more tractable alternatives. Phrase-based translation models, accompanied with n-gram language models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exhibited by the target-side MRL, thus taking the burden of the inﬂection selection away from the phrase-based decoder. Chahuneau et al. (2013) and Huck et al. (2017c), on the other hand, have speciﬁcally looked into how to produce unseen morphological variants without resorting to a factored generation step. To that end, they augment their phrase tables with synthetic entries. Other researchers have proposed two"
W18-1805,W14-1005,0,0.0606081,"Missing"
W18-6306,P13-4033,0,0.0187561,"on. Access to strong signals allows us to make clear comparisons between context-aware models. 1 Introduction Neural Machine Translation (NMT) (Bahdanau et al., 2015) is a state-of-the-art approach to MT. Standard NMT models translate an input language sentence to an output language sentence, and do not take into account discourse-level phenomena. Cross-sentence context has already proven useful for language modeling (Ji et al., 2015; Wang and Cho, 2016) and dialogue systems (Serban et al., 2016). It has also been of interest in Statistical Machine Translation (SMT) research (Hardmeier, 2012; Hardmeier et al., 2013; Carpuat and Simard, 2012), and NMT research (Wang et al., 2017; Jean et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Tu et al., 2017; Voita et al., 2018). Two important discourse phenomena for MT are coreference and coherence. Pronominal coreference relates to the issue of translating anaphoric 49 Proceedings of the Third Conference on Machine Translation (WMT), Volume 1: Research Papers, pages 49–60 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64006 work, we use oracles, where the context"
W18-6306,E17-3017,0,0.0254105,"59500 operations. All sentences with length above 60 tokens are discarded. Batch size is 80. All embeddings are tied (Press and Wolf, 2017) including the ones in the context part of the architecture. Dropout (Gal and Ghahramani, 2016) of 0.2 is applied and 0.1 on the embeddings. We apply layer (Ba et al., 2016) and weight normalization (Salimans and Kingma, 2016). The models are trained with early-stopping based on the development set’s cost. We report BLEU score on detokenized text. Our RNN-based model is implemented as an extension to Nematus2 (Sennrich et al., 2017). We used the Sockeye3 (Hieber et al., 2017) implementation of the Transformer. For the Transformer we use hyper-parameters as similar as possible to the ones in the Nematus models. We additionally use label smoothing of value 0.1. Both, the baseline and context-aware model have 4 layers. We didn’t do any special hyper-parameter tuning for the context-aware models, so further performance improvements are possible. The datasets and the source code for our context-aware models are publicly available4 . The final decoder representation is computed as si = fc (yi−1 , si−1 , ci , g ⊗ cci ). 4.2 Transformer context-aware model The Transformer"
W18-6306,W09-2404,0,0.101886,"herence in Neural Machine Translation: A Study Using Oracle Experiments Dario Stojanovski Alexander Fraser Center for Information and Language Processing LMU Munich {stojanovski,fraser}@cis.lmu.de Abstract pronouns and is tackled in several works (Guillou, 2016; Hardmeier and Federico, 2010; Le Nagard and Koehn, 2010) and is the central motivation for the DiscoMT shared task on cross-lingual pronoun prediction (Lo´aiciga et al., 2017). Coherence on the other hand, is important for producing consistent and coherent translations throughout a document, especially for domain-specific terminology (Carpuat, 2009; Ture et al., 2012; Gonzales et al., 2017) and it is helpful to properly disambiguate polysemous words. Modeling discourse-level phenomena for MT is a challenging endeavor because of difficulties in acquiring relevant linguistic signals. Measuring the effect of discourse-level phenomena with automatic metrics such as BLEU is also difficult as pointed out by Hardmeier (2012). In this paper, we address these issues by proposing several oracle experimental setups for evaluating the effect of coreference resolution (CR) and coherence in MT. Oracle experiments provide strong linguistic signals tha"
W18-6306,W12-3156,0,0.022333,"nals allows us to make clear comparisons between context-aware models. 1 Introduction Neural Machine Translation (NMT) (Bahdanau et al., 2015) is a state-of-the-art approach to MT. Standard NMT models translate an input language sentence to an output language sentence, and do not take into account discourse-level phenomena. Cross-sentence context has already proven useful for language modeling (Ji et al., 2015; Wang and Cho, 2016) and dialogue systems (Serban et al., 2016). It has also been of interest in Statistical Machine Translation (SMT) research (Hardmeier, 2012; Hardmeier et al., 2013; Carpuat and Simard, 2012), and NMT research (Wang et al., 2017; Jean et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Tu et al., 2017; Voita et al., 2018). Two important discourse phenomena for MT are coreference and coherence. Pronominal coreference relates to the issue of translating anaphoric 49 Proceedings of the Third Conference on Machine Translation (WMT), Volume 1: Research Papers, pages 49–60 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64006 work, we use oracles, where the context signals are strong and all"
W18-6306,W10-1737,0,0.0881909,"Missing"
W18-6306,D16-1245,0,0.103161,"Missing"
W18-6306,W17-4801,0,0.0498952,"Missing"
W18-6306,P16-1061,0,0.0284503,"one since it relies on the assumption that a polysemous word has already been seen in the text. However, if a word occurs in two consecutive sentences, it is likely that it will have the same translation. For the previous target sentence oracle, we use the gold standard previous target sentence as context and don’t modify the main source sentence. We also setup experiments with 2 and 3 previous target sentences as context. Fair For the fair coreference setup, we attempt to acquire gender and number knowledge by using a coreference resolution tool, namely CorefAnnotator from Stanford CoreNLP1 (Clark and Manning, 2016a,b). We run the model on entire documents. We only modified sentences that contain a pronoun which has an antecedent in the previous source sentence. Consequently, the pronoun is 1 Table 1: Coreference and coherence oracle samples. For detailed explanation of the examples, refer to Section 2. marked and the antecedent is inserted into the context of the given sentence. In this way, we don’t utilize any target side knowledge. For the fair coherence experiment, we don’t have access to target side information and we just put special emphasis on words that are polysemous candidates. As a result,"
W18-6306,D13-1032,0,0.0230937,"Missing"
W18-6306,E17-2025,0,0.013104,"rols the flow of information between the current decoder state and the context representation. which is computed as g = fg (yi−1 , si−1 , ci , cci ). 52 and 4627 sentences respectively. In the coreference oracle setup ≈ 7.8M training samples were modified and added the appropriate context, while in the coherence setup only ≈ 0.8M. The remaining samples are unchanged and have no context. We apply tokenization, truecasing and BPE splitting computed jointly on both languages with 59500 operations. All sentences with length above 60 tokens are discarded. Batch size is 80. All embeddings are tied (Press and Wolf, 2017) including the ones in the context part of the architecture. Dropout (Gal and Ghahramani, 2016) of 0.2 is applied and 0.1 on the embeddings. We apply layer (Ba et al., 2016) and weight normalization (Salimans and Kingma, 2016). The models are trained with early-stopping based on the development set’s cost. We report BLEU score on detokenized text. Our RNN-based model is implemented as an extension to Nematus2 (Sennrich et al., 2017). We used the Sockeye3 (Hieber et al., 2017) implementation of the Transformer. For the Transformer we use hyper-parameters as similar as possible to the ones in th"
W18-6306,W17-4702,0,0.0362758,"ion: A Study Using Oracle Experiments Dario Stojanovski Alexander Fraser Center for Information and Language Processing LMU Munich {stojanovski,fraser}@cis.lmu.de Abstract pronouns and is tackled in several works (Guillou, 2016; Hardmeier and Federico, 2010; Le Nagard and Koehn, 2010) and is the central motivation for the DiscoMT shared task on cross-lingual pronoun prediction (Lo´aiciga et al., 2017). Coherence on the other hand, is important for producing consistent and coherent translations throughout a document, especially for domain-specific terminology (Carpuat, 2009; Ture et al., 2012; Gonzales et al., 2017) and it is helpful to properly disambiguate polysemous words. Modeling discourse-level phenomena for MT is a challenging endeavor because of difficulties in acquiring relevant linguistic signals. Measuring the effect of discourse-level phenomena with automatic metrics such as BLEU is also difficult as pointed out by Hardmeier (2012). In this paper, we address these issues by proposing several oracle experimental setups for evaluating the effect of coreference resolution (CR) and coherence in MT. Oracle experiments provide strong linguistic signals that enable strongly visible effects on BLEU s"
W18-6306,2010.iwslt-papers.10,0,0.0670632,"Missing"
W18-6306,W17-4811,0,0.284186,"on Neural Machine Translation (NMT) (Bahdanau et al., 2015) is a state-of-the-art approach to MT. Standard NMT models translate an input language sentence to an output language sentence, and do not take into account discourse-level phenomena. Cross-sentence context has already proven useful for language modeling (Ji et al., 2015; Wang and Cho, 2016) and dialogue systems (Serban et al., 2016). It has also been of interest in Statistical Machine Translation (SMT) research (Hardmeier, 2012; Hardmeier et al., 2013; Carpuat and Simard, 2012), and NMT research (Wang et al., 2017; Jean et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Tu et al., 2017; Voita et al., 2018). Two important discourse phenomena for MT are coreference and coherence. Pronominal coreference relates to the issue of translating anaphoric 49 Proceedings of the Third Conference on Machine Translation (WMT), Volume 1: Research Papers, pages 49–60 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64006 work, we use oracles, where the context signals are strong and allow us to carry out clear analysis. We define three oracles which differ based on the c"
W18-6306,N12-1046,0,0.0765489,"al Machine Translation: A Study Using Oracle Experiments Dario Stojanovski Alexander Fraser Center for Information and Language Processing LMU Munich {stojanovski,fraser}@cis.lmu.de Abstract pronouns and is tackled in several works (Guillou, 2016; Hardmeier and Federico, 2010; Le Nagard and Koehn, 2010) and is the central motivation for the DiscoMT shared task on cross-lingual pronoun prediction (Lo´aiciga et al., 2017). Coherence on the other hand, is important for producing consistent and coherent translations throughout a document, especially for domain-specific terminology (Carpuat, 2009; Ture et al., 2012; Gonzales et al., 2017) and it is helpful to properly disambiguate polysemous words. Modeling discourse-level phenomena for MT is a challenging endeavor because of difficulties in acquiring relevant linguistic signals. Measuring the effect of discourse-level phenomena with automatic metrics such as BLEU is also difficult as pointed out by Hardmeier (2012). In this paper, we address these issues by proposing several oracle experimental setups for evaluating the effect of coreference resolution (CR) and coherence in MT. Oracle experiments provide strong linguistic signals that enable strongly v"
W18-6306,P18-1117,0,0.218523,"te-of-the-art approach to MT. Standard NMT models translate an input language sentence to an output language sentence, and do not take into account discourse-level phenomena. Cross-sentence context has already proven useful for language modeling (Ji et al., 2015; Wang and Cho, 2016) and dialogue systems (Serban et al., 2016). It has also been of interest in Statistical Machine Translation (SMT) research (Hardmeier, 2012; Hardmeier et al., 2013; Carpuat and Simard, 2012), and NMT research (Wang et al., 2017; Jean et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Tu et al., 2017; Voita et al., 2018). Two important discourse phenomena for MT are coreference and coherence. Pronominal coreference relates to the issue of translating anaphoric 49 Proceedings of the Third Conference on Machine Translation (WMT), Volume 1: Research Papers, pages 49–60 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64006 work, we use oracles, where the context signals are strong and allow us to carry out clear analysis. We define three oracles which differ based on the context supplied to the model. First, we define the previous"
W18-6306,D17-1301,0,0.453665,"een context-aware models. 1 Introduction Neural Machine Translation (NMT) (Bahdanau et al., 2015) is a state-of-the-art approach to MT. Standard NMT models translate an input language sentence to an output language sentence, and do not take into account discourse-level phenomena. Cross-sentence context has already proven useful for language modeling (Ji et al., 2015; Wang and Cho, 2016) and dialogue systems (Serban et al., 2016). It has also been of interest in Statistical Machine Translation (SMT) research (Hardmeier, 2012; Hardmeier et al., 2013; Carpuat and Simard, 2012), and NMT research (Wang et al., 2017; Jean et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Tu et al., 2017; Voita et al., 2018). Two important discourse phenomena for MT are coreference and coherence. Pronominal coreference relates to the issue of translating anaphoric 49 Proceedings of the Third Conference on Machine Translation (WMT), Volume 1: Research Papers, pages 49–60 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64006 work, we use oracles, where the context signals are strong and allow us to carry out clear analysis. We"
W18-6306,P16-1125,0,0.0300938,"advantage of context oracle signals can achieve considerable gains in BLEU, of up to 7.02 BLEU for coreference and 1.89 BLEU for coherence on subtitles translation. Access to strong signals allows us to make clear comparisons between context-aware models. 1 Introduction Neural Machine Translation (NMT) (Bahdanau et al., 2015) is a state-of-the-art approach to MT. Standard NMT models translate an input language sentence to an output language sentence, and do not take into account discourse-level phenomena. Cross-sentence context has already proven useful for language modeling (Ji et al., 2015; Wang and Cho, 2016) and dialogue systems (Serban et al., 2016). It has also been of interest in Statistical Machine Translation (SMT) research (Hardmeier, 2012; Hardmeier et al., 2013; Carpuat and Simard, 2012), and NMT research (Wang et al., 2017; Jean et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Tu et al., 2017; Voita et al., 2018). Two important discourse phenomena for MT are coreference and coherence. Pronominal coreference relates to the issue of translating anaphoric 49 Proceedings of the Third Conference on Machine Translation (WMT), Volume 1: Research Papers, pages 49–60 c Belgium, Br"
W18-6428,Q17-1010,0,0.299394,"sentence we induce its translation: where λ is a weighting constant and orth(w1 , w2 ) is the normalized Levenshtein distance of words w1 and w2 . As a contrastive set of experiments we added light supervision during the training of bilingual word embeddings in order to show performance differences compared to the fully unsupervised setup. To map monolingual spaces we used orthogonal mapping (Xing et al., 2015) with a seed lexicon of of 5000 word pairs, which was used as a baseline in (Conneau et al., 2017) as well. 2.1 Technical Details To train monolingual word embeddings we used fasttext (Bojanowski et al., 2017) which employs subword information for better quality representations. We used 512 dimensional embeddings and default values for the rest of the parameters. For both unsupervised and lightly supervised mapping we used MUSE (Conneau et al., 2017) with default parameters. We fine-tuned λ on the test set of WMT 2017 and used the method of (Mikolov et al., 2013) to mine frequent bigrams. trwbw (ws ) = arg max cos(e(ws ), e(w)) w∈Vt where e(w) is the vector representation of word w, cos(x, y) is the cosine similarity of two vectors and Vt is the target vocabulary. One problem with the approach aris"
W18-6428,N12-1047,0,0.0167383,"bw” experiment from Table 1. We use the Moses decoder to perform monotonic word-by-word translation without a language model (LM) or any other feature functions except for the single translation model (TM) score that we obtain from the cosine similarities. If we add a 4-gram LM and heuristically weight the LM feature function with a scaling factor of 0.1 and the TM with 0.9 (second line in Table 2), the translation quality improves by more than 2.5 BLEU points in both of the two translation directions. By using a small parallel development set (newstest2016) to tune the two weights with MIRA (Cherry and Foster, 2012) (third line), we barely improve over our guessed scaling factors of 0.1 for the LM and 0.9 for the TM. Optimized scaling factors are however more relevant when we allow for reordering (fourth line), since we then activate a third feature function, namely a distance-based distortion cost. This adds another scaling factor, and a good informed guess of reasonable values for three weights becomes increasingly difficult. Activated reordering with tuned weights boosts our translation quality further. We can go beyond simple word-by-word translation if we add our BWE bigrams to the TM, thus also ena"
W18-6428,W17-4730,1,0.775314,"n and Language Processing participated in the WMT 2018 news translation shared task for English↔German translation. Specifically, we participated in the unsupervised learning task which focuses on training MT models without access to any parallel data. The team has a strong track record at previous WMT shared tasks (Bojar et al., 2017, 2016, 2015, 2014, 2013) working on SMT systems (Cap et al., 2014, 2015; Weller et al., 2013; Sajjad et al., 2013; Huck et al., 2016; Peter et al., 2016; Tamchyna et al., 2016) and proposed a top scoring linguistically informed neural machine translation system (Huck et al., 2017) based on human evaluation at WMT17. Neural machine translation (NMT) is state-ofthe-art in automatic translation. Attention-based neural sequence-to-sequence models (Bahdanau et al., 2015) have been established as the basis for most recent work in MT and furthermore, have been used to obtain best scoring systems at WMT in recent years (Bojar et al., 2017, 2016). Previous work and the best scoring systems at WMT also showed that NMT can be scaled to millions of sentence pairs and even achieve human parity (Hassan et al., 2018). However, this comes The systems we use for our submissions are bas"
W18-6428,W16-2315,1,0.718664,"translated data based on bilingual word embeddings, denoising and on-the-fly backtranslation. 1 Introduction The LMU Munich’s Center for Information and Language Processing participated in the WMT 2018 news translation shared task for English↔German translation. Specifically, we participated in the unsupervised learning task which focuses on training MT models without access to any parallel data. The team has a strong track record at previous WMT shared tasks (Bojar et al., 2017, 2016, 2015, 2014, 2013) working on SMT systems (Cap et al., 2014, 2015; Weller et al., 2013; Sajjad et al., 2013; Huck et al., 2016; Peter et al., 2016; Tamchyna et al., 2016) and proposed a top scoring linguistically informed neural machine translation system (Huck et al., 2017) based on human evaluation at WMT17. Neural machine translation (NMT) is state-ofthe-art in automatic translation. Attention-based neural sequence-to-sequence models (Bahdanau et al., 2015) have been established as the basis for most recent work in MT and furthermore, have been used to obtain best scoring systems at WMT in recent years (Bojar et al., 2017, 2016). Previous work and the best scoring systems at WMT also showed that NMT can be scaled"
W18-6428,W18-6446,1,0.842817,"ram language model. The backbone of the unsupervised NMT methods is denoising and onthe-fly backtranslation which enable a standard NMT architecture to be trained by only leveraging monolingual data. The model for our submission is mostly based on the work of Lample et al. (2018b). Additionally, we explore how word-byword translated data based on BWEs can be utilized to improve the initial training and experiment with different ways of producing these translations. We also show that disabling denoising in the last stages of learning can provide for further improvements. We refer the reader to Huck et al. (2018) for our supervised systems for news and biomedical translation. 513 Proceedings of the Third Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 513–521 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64055 To further improve the quality of our algorithm, we exploited orthographic similarity of words. Braune et al. (2018) showed that the performance of inducing word translations can be significantly improved using orthography. Following the approach there, we obtained improvements, esp"
W18-6428,P07-2045,0,0.0187359,"e. By training bilingual word embeddings on this data we automatically allow the word-by-word algorithm to translate compound words to bigrams and vice-versa. 3 Unsupervised Phrase-based Translation We have investigated unsupervised phrase-based translation (PBT). The results have been worse than with the neural model in our experiments. In this section, we therefore only give a short outline of the methods which we have explored in that area. By means of a straightforward format conversion of the BWE lexicon, we can create a wordbased “phrase table” that can be loaded into the Moses decoder (Koehn et al., 2007). The cosine similarities from the BWE model become feature scores in the phrase table. Note that we refrained from normalizing the cosine similarities, but wrote their values directly to the table. 514 The model proposed in Lample et al. (2018b) consists of two main components, a denoising and a translation component. The denoising part acts as a language model and is trained to produce fluent output in a given language based on a noisy version of the input. We follow the implementation of Artetxe et al. (2018) where the noisy version of the input sentence is obtained by making random swaps o"
W18-6428,N15-1104,0,0.0355326,"mbeddings, trained in an unsupervised fashion, to jump-start both of our systems. As our baseline system we produce word-byword translations relying only on the embeddings. For each word ws in the source sentence we induce its translation: where λ is a weighting constant and orth(w1 , w2 ) is the normalized Levenshtein distance of words w1 and w2 . As a contrastive set of experiments we added light supervision during the training of bilingual word embeddings in order to show performance differences compared to the fully unsupervised setup. To map monolingual spaces we used orthogonal mapping (Xing et al., 2015) with a seed lexicon of of 5000 word pairs, which was used as a baseline in (Conneau et al., 2017) as well. 2.1 Technical Details To train monolingual word embeddings we used fasttext (Bojanowski et al., 2017) which employs subword information for better quality representations. We used 512 dimensional embeddings and default values for the rest of the parameters. For both unsupervised and lightly supervised mapping we used MUSE (Conneau et al., 2017) with default parameters. We fine-tuned λ on the test set of WMT 2017 and used the method of (Mikolov et al., 2013) to mine frequent bigrams. trwb"
W18-6428,W17-3204,0,0.0283197,"Missing"
W18-6428,J82-2005,0,0.777273,"Missing"
W18-6428,P02-1040,0,0.109099,"5 We also apply BPE splitting on this data before using it in training. After a certain number of iterations, we stop with the training of the initial model and “unplug” two components of the previous training procedure. Namely, we remove the word-by-word translated data since this is useful to jump-start the learning, but later presumably will impede learning more nuanced translations. We also observe better results if we disable the denoising component and continue the training by only doing onthe-fly backtranslation. This improved results on both translation directions by more than 1 BLEU (Papineni et al., 2002). However, in subsequent experiments we observed that this can also lead to unstable learning and decrease the performance since bad translation decisions can be reinforced. As a result, the final training procedure should be carefully controlled. As mentioned in Section 2, the model has problems translating named entities. This stems from the fact that it is dependent on BWEs, where two different named entities often mistakenly have similar representations, causing confusion. Following the improvements the word-by-word translation obtained by using orthographic similarity, we also try trainin"
W18-6428,W13-2228,1,0.765538,"as using word-by-word translated data based on bilingual word embeddings, denoising and on-the-fly backtranslation. 1 Introduction The LMU Munich’s Center for Information and Language Processing participated in the WMT 2018 news translation shared task for English↔German translation. Specifically, we participated in the unsupervised learning task which focuses on training MT models without access to any parallel data. The team has a strong track record at previous WMT shared tasks (Bojar et al., 2017, 2016, 2015, 2014, 2013) working on SMT systems (Cap et al., 2014, 2015; Weller et al., 2013; Sajjad et al., 2013; Huck et al., 2016; Peter et al., 2016; Tamchyna et al., 2016) and proposed a top scoring linguistically informed neural machine translation system (Huck et al., 2017) based on human evaluation at WMT17. Neural machine translation (NMT) is state-ofthe-art in automatic translation. Attention-based neural sequence-to-sequence models (Bahdanau et al., 2015) have been established as the basis for most recent work in MT and furthermore, have been used to obtain best scoring systems at WMT in recent years (Bojar et al., 2017, 2016). Previous work and the best scoring systems at WMT also showed that"
W18-6428,W16-2325,1,0.835038,"d embeddings, denoising and on-the-fly backtranslation. 1 Introduction The LMU Munich’s Center for Information and Language Processing participated in the WMT 2018 news translation shared task for English↔German translation. Specifically, we participated in the unsupervised learning task which focuses on training MT models without access to any parallel data. The team has a strong track record at previous WMT shared tasks (Bojar et al., 2017, 2016, 2015, 2014, 2013) working on SMT systems (Cap et al., 2014, 2015; Weller et al., 2013; Sajjad et al., 2013; Huck et al., 2016; Peter et al., 2016; Tamchyna et al., 2016) and proposed a top scoring linguistically informed neural machine translation system (Huck et al., 2017) based on human evaluation at WMT17. Neural machine translation (NMT) is state-ofthe-art in automatic translation. Attention-based neural sequence-to-sequence models (Bahdanau et al., 2015) have been established as the basis for most recent work in MT and furthermore, have been used to obtain best scoring systems at WMT in recent years (Bojar et al., 2017, 2016). Previous work and the best scoring systems at WMT also showed that NMT can be scaled to millions of sentence pairs and even achie"
W18-6428,W13-2230,1,0.856869,"osed techniques such as using word-by-word translated data based on bilingual word embeddings, denoising and on-the-fly backtranslation. 1 Introduction The LMU Munich’s Center for Information and Language Processing participated in the WMT 2018 news translation shared task for English↔German translation. Specifically, we participated in the unsupervised learning task which focuses on training MT models without access to any parallel data. The team has a strong track record at previous WMT shared tasks (Bojar et al., 2017, 2016, 2015, 2014, 2013) working on SMT systems (Cap et al., 2014, 2015; Weller et al., 2013; Sajjad et al., 2013; Huck et al., 2016; Peter et al., 2016; Tamchyna et al., 2016) and proposed a top scoring linguistically informed neural machine translation system (Huck et al., 2017) based on human evaluation at WMT17. Neural machine translation (NMT) is state-ofthe-art in automatic translation. Attention-based neural sequence-to-sequence models (Bahdanau et al., 2015) have been established as the basis for most recent work in MT and furthermore, have been used to obtain best scoring systems at WMT in recent years (Bojar et al., 2017, 2016). Previous work and the best scoring systems at"
W18-6446,P13-1141,0,0.0165164,"18. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64073 single hidden layer. We configure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer (Kingma and Ba, 2015), a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer, but not to source, target, and embeddings. We validate every 10 000 updates and do early stopping when the validation cost has not decreased over ten consecutive control points. from their respective meaning in out-of-domain corpora) are common (Carpuat et al., 2013; Irvine et al., 2013). Domain adaptation of conventional phrasebased machine translation systems is a wellexplored research area. Several different effective solutions which may be used in order to domain-adapt a phrase-based system have been proposed in the literature. (Inter alia, cf. Huck et al. (2015) for a few interesting empirical results and a list of some major bibliographic references.) Machine translation in academic research labs and also in industry is however going through a paradigm shift away from phrase-based technology and on towards artificial neural network models. Neural m"
W18-6446,W18-1805,1,0.839485,"on machine translation of news (Huck et al., 2017a). At WMT17, LMU’s primary submission was ranked first in the human evaluation (Bojar et al., 2017a). We presume that the high human rating of LMU’s WMT17 submission can mostly be attributed to our efforts toward better word segmentation. We anticipate similar benefits in the medical domain. Dedicated methods that tackle rich target-side morphology have also shown good results in phrase-based translation systems previously (Huck et al., 2017c). Future work on neural machine translation could for instance follow a two-step prediction paradigm (Conforti et al., 2018), or improve over our current version of linguistically informed word segmentation by means of a better linguistic analysis (Weissweiler and Fraser, 2017). In the present work, the linguistically informed word segmentation is not only employed on the target side for English→German machine translation, but in German→English systems also on the source language side. The English language side is always simply BPE-segmented. We learn the compound split model and the BPE merge operations from Europarl and use this word segmentation and vocabulary for all corpora. 5 5.1 5.2 English→German Transforme"
W18-6446,2005.mtsummit-papers.11,0,0.151966,"texts. The types of medical texts that we consider range from health information leaflets to professional biomedical research articles. Some of our latest research towards medical domain adapation of neural translation systems is inspired by the “fine-tuning” approach in combination with high-quality in-domain data. Specifically, we conducted successive optimization runs to domain-adapt a neural translation model. The 2 Domain Adaptation Medical texts differ in their style and in their topics from the typical content of many widely used training corpora, such as the parallel Europarl corpus (Koehn, 2005) or most of the large monolingual corpora that are distributed for the WMT shared task on machine translation of news (Bojar et al., 2018, 2017a, 2016, 2015). Medical documents also often contain a large amount of domain-specific technical terms in their vocabulary. Furthermore, sense shifts of words (away 1 http://www.statmt.org/wmt18/ biomedical-translation-task.html 2 http://www.statmt.org/wmt18/ translation-task.html 3 http://www.himl.eu 4 LMU’s unsupervised machine translation system for the news task is described in a separate paper (Stojanovski et al., 2018). 648 Proceedings of the Thir"
W18-6446,E03-1076,0,0.0910321,"development, as stated in the table. As a last step, we apply n-best list reranking (n = 50) with a rightto-left NMT model (“r2l reranking”). Ensembling did not yield any clear gains, so we deployed single models for English→German. The bottom row of Table 1 contains the B LEU scores of our last year’s primary system (Huck et al., 2017a) for the WMT17 biomedical task (Yepes et al., 2017). We improve over it by more than three points. ball stemming algorithm that separtates suffixes from the word stem, rather than stripping them. 2. Next we apply the empirical compound splitter as described by Koehn and Knight (2003). 3. We finally apply the Byte Pair Encoding (BPE) technique (Sennrich et al., 2016b) on top of the suffix-split and compound-split data in order to further reduce the vocabulary size. Special marker symbols allow us to revert the segmentation in postprocessing when German is the target language. Our linguistically informed word segmentation was already used on the target language side for LMU’s participation in the WMT17 shared task on machine translation of news (Huck et al., 2017a). At WMT17, LMU’s primary submission was ranked first in the human evaluation (Bojar et al., 2017a). We presume"
W18-6446,E17-3017,0,0.393967,"optimization run the parameters are initialized with the trained model parameters from the previous optimization. A crucial aspect is the availability of high-quality indomain training data, or alternatively, the collection thereof. If a general-domain or out-of-domain neural model from a first optimization run already exists, then fine-tuning allows for quick adjustment of the model to a specific domain by means of a short continued optimization on an in-domain corpus, most often with less data than in the first run. 3 3.1 3.2 Transformer We use the Sockeye implementation of the Transformer (Hieber et al., 2017). For the German→English translation direction we train small Transformer models and for English→German big models as outlined in Vaswani et al. (2017). All models have six encoder and decoder layers. The size of the layers and the embeddings is 512 for the small models and 1024 for the big ones. The dimensionality of the feed-forward networks is 2048 (small) and 4096 (big). We use 8 attention heads for the small and 16 for the big models. The models are trained with the Adam optimizer with an initial learning rate of 0.0002. The learning rate is reduced by a factor of 0.7 if not improved for"
W18-6446,2015.mtsummit-papers.19,1,0.910911,"probability 0.2 applied to the hidden layer, but not to source, target, and embeddings. We validate every 10 000 updates and do early stopping when the validation cost has not decreased over ten consecutive control points. from their respective meaning in out-of-domain corpora) are common (Carpuat et al., 2013; Irvine et al., 2013). Domain adaptation of conventional phrasebased machine translation systems is a wellexplored research area. Several different effective solutions which may be used in order to domain-adapt a phrase-based system have been proposed in the literature. (Inter alia, cf. Huck et al. (2015) for a few interesting empirical results and a list of some major bibliographic references.) Machine translation in academic research labs and also in industry is however going through a paradigm shift away from phrase-based technology and on towards artificial neural network models. Neural machine translation (Sutskever et al., 2014; Bahdanau et al., 2014) is the new state of the art for basically all medium- to highresource language pairs since around two to three years. The paradigm shift poses new challenges in domain adaptation, since most known techniques are rather specific to the phras"
W18-6446,W11-2132,0,0.114925,"stem, but participated with our system from WMT17 (Bojar et al., 2017a). The system was trained under “constrained” conditions, employing only permissible resources as defined by the shared task organizers. Huck et al. (2017a) provide a detailed description, along with experimental results. In short, we conducted the following steps in an incremental training regime (with consecutive optimizations, in a similar manner as presented above for the HimL Y3 system): 1. Optimize a Europarl baseline model. 2. Add News Commentary and Common Crawl. 3. Add synthetic training data (Ueffing et al., 2007; Lambert et al., 2011; Huck et al., 2011; Huck and Ney, 2012; Sennrich et al., 2016a). 4. Fine-tune towards the domain of news articles. For that purpose, several newstest development sets are employed as a training corpus. The learning rate is decreased. 5. Rerank n-best list with a right-to-left neural model (Liu et al., 2016), which is trained for reverse word order (Freitag et al., 2013). German→English Transformer System Our German→English Transformer model is an ensemble of three separate models, like in the English→German translation direction. We use the same training corpus, but with source and target sid"
W18-6446,W17-4730,1,0.398125,"Matthias Huck and Dario Stojanovski and Viktor Hangya and Alexander Fraser Center for Information and Language Processing LMU Munich Munich, Germany {mhuck,stojanovski,hangyav,fraser}@cis.lmu.de Abstract model was eventually deployed as the core component of the final English→German HimL translation engine in year 3 of the project (Y3). In this paper, we give a brief technical overview of the HimL Y3 engine’s neural translation model for English→German. We will show by how much the translation quality of medical texts improves compared to our previous year’s WMT17 biomedical task submission (Huck et al., 2017a). We then proceed to compare with a Transformer model (Vaswani et al., 2017) that we have trained after the end of the HimL project. We find that the Transformer model performs even better than the HimL Y3 engine, which was based on Nematus (Sennrich et al., 2017) with a single hidden layer. The good result encouraged us to try out the Transformer in the other translation direction, German→English. We will also report the German→English results. In addition to the English–German biomedical task, LMU Munich has participated in the WMT18 English–German news translation task (Bojar et al., 2018"
W18-6446,N16-1046,0,0.0395691,"Missing"
W18-6446,2012.amta-papers.8,1,0.776451,"om WMT17 (Bojar et al., 2017a). The system was trained under “constrained” conditions, employing only permissible resources as defined by the shared task organizers. Huck et al. (2017a) provide a detailed description, along with experimental results. In short, we conducted the following steps in an incremental training regime (with consecutive optimizations, in a similar manner as presented above for the HimL Y3 system): 1. Optimize a Europarl baseline model. 2. Add News Commentary and Common Crawl. 3. Add synthetic training data (Ueffing et al., 2007; Lambert et al., 2011; Huck et al., 2011; Huck and Ney, 2012; Sennrich et al., 2016a). 4. Fine-tune towards the domain of news articles. For that purpose, several newstest development sets are employed as a training corpus. The learning rate is decreased. 5. Rerank n-best list with a right-to-left neural model (Liu et al., 2016), which is trained for reverse word order (Freitag et al., 2013). German→English Transformer System Our German→English Transformer model is an ensemble of three separate models, like in the English→German translation direction. We use the same training corpus, but with source and target side switched. The preprocessing remains t"
W18-6446,P02-1040,0,0.103687,"ecture is flat, it has only one 649 tuning” (Section 2). First, we train a model on parallel corpora from the WMT news task. We then successively refine the model and adapt it to the medical domain. Consecutive optimization runs are initialized with the respective previous model parameters. For each refinement step, we replace the training data, first with larger corpora, then with corpora that better match the domain. The HimL tuning sets are used for validation, and we test separately on the Cochrane and NHS24 parts of the HimL devtest set.5 The translation quality (in case-sensitive B LEU (Papineni et al., 2002)) of different system setups after several development stages is presented in the top section of Table 1. WMT_parallel denotes the Europarl, News Commentary, and Common Crawl parallel training data as provided for WMT17 by the organizers of the news translation shared task. WMT_backtranslated_news_crawl denotes Edinburgh’s backtranslations of monolingual WMT News Crawl corpora from WMT16.6 Y3_base_general_data is a large collection of English–German bitext used in the HimL project. Cochrane-selected and NHS24-selected denote synthetic data mixes from HimL whose content is automatically filtere"
W18-6446,W17-4706,1,0.315058,"Matthias Huck and Dario Stojanovski and Viktor Hangya and Alexander Fraser Center for Information and Language Processing LMU Munich Munich, Germany {mhuck,stojanovski,hangyav,fraser}@cis.lmu.de Abstract model was eventually deployed as the core component of the final English→German HimL translation engine in year 3 of the project (Y3). In this paper, we give a brief technical overview of the HimL Y3 engine’s neural translation model for English→German. We will show by how much the translation quality of medical texts improves compared to our previous year’s WMT17 biomedical task submission (Huck et al., 2017a). We then proceed to compare with a Transformer model (Vaswani et al., 2017) that we have trained after the end of the HimL project. We find that the Transformer model performs even better than the HimL Y3 engine, which was based on Nematus (Sennrich et al., 2017) with a single hidden layer. The good result encouraged us to try out the Transformer in the other translation direction, German→English. We will also report the German→English results. In addition to the English–German biomedical task, LMU Munich has participated in the WMT18 English–German news translation task (Bojar et al., 2018"
W18-6446,E17-2059,1,0.900188,"Missing"
W18-6446,P16-1009,0,0.161609,"n = 50) with a rightto-left NMT model (“r2l reranking”). Ensembling did not yield any clear gains, so we deployed single models for English→German. The bottom row of Table 1 contains the B LEU scores of our last year’s primary system (Huck et al., 2017a) for the WMT17 biomedical task (Yepes et al., 2017). We improve over it by more than three points. ball stemming algorithm that separtates suffixes from the word stem, rather than stripping them. 2. Next we apply the empirical compound splitter as described by Koehn and Knight (2003). 3. We finally apply the Byte Pair Encoding (BPE) technique (Sennrich et al., 2016b) on top of the suffix-split and compound-split data in order to further reduce the vocabulary size. Special marker symbols allow us to revert the segmentation in postprocessing when German is the target language. Our linguistically informed word segmentation was already used on the target language side for LMU’s participation in the WMT17 shared task on machine translation of news (Huck et al., 2017a). At WMT17, LMU’s primary submission was ranked first in the human evaluation (Bojar et al., 2017a). We presume that the high human rating of LMU’s WMT17 submission can mostly be attributed to o"
W18-6446,P16-1162,0,0.307933,"n = 50) with a rightto-left NMT model (“r2l reranking”). Ensembling did not yield any clear gains, so we deployed single models for English→German. The bottom row of Table 1 contains the B LEU scores of our last year’s primary system (Huck et al., 2017a) for the WMT17 biomedical task (Yepes et al., 2017). We improve over it by more than three points. ball stemming algorithm that separtates suffixes from the word stem, rather than stripping them. 2. Next we apply the empirical compound splitter as described by Koehn and Knight (2003). 3. We finally apply the Byte Pair Encoding (BPE) technique (Sennrich et al., 2016b) on top of the suffix-split and compound-split data in order to further reduce the vocabulary size. Special marker symbols allow us to revert the segmentation in postprocessing when German is the target language. Our linguistically informed word segmentation was already used on the target language side for LMU’s participation in the WMT17 shared task on machine translation of news (Huck et al., 2017a). At WMT17, LMU’s primary submission was ranked first in the human evaluation (Bojar et al., 2017a). We presume that the high human rating of LMU’s WMT17 submission can mostly be attributed to o"
W18-6446,W18-6428,1,0.842817,"ra, such as the parallel Europarl corpus (Koehn, 2005) or most of the large monolingual corpora that are distributed for the WMT shared task on machine translation of news (Bojar et al., 2018, 2017a, 2016, 2015). Medical documents also often contain a large amount of domain-specific technical terms in their vocabulary. Furthermore, sense shifts of words (away 1 http://www.statmt.org/wmt18/ biomedical-translation-task.html 2 http://www.statmt.org/wmt18/ translation-task.html 3 http://www.himl.eu 4 LMU’s unsupervised machine translation system for the news task is described in a separate paper (Stojanovski et al., 2018). 648 Proceedings of the Third Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 648–654 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64073 single hidden layer. We configure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer (Kingma and Ba, 2015), a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer, but not to source, target, and embeddings. We validate every 10 000 updates and d"
W18-6477,N18-2030,1,0.788722,"by iterating over the words in S from left to right and pairing each word s ∈ S, in a greedy fashion, with the word t ∈ T that has the highest cosine similarity based on our dictionary. We then greedily eliminate t from T , so that it cannot be matched by a later word “s”. Then, the averaged word-pair similarity gives the final score. We remove stopwords, digits and punctuation from texts before calculating similarity. Note, this idea is similar to Word Movers Distance introduced in (Kusner et al., 2015) but simpler due to runtime considerations on huge corpora. As was shown in previous work (Braune et al., 2018), the quality of bilingual word similarity can be significantly improved by using orthographic cues, especially for rare words. We extend this idea to the sentence level by using a dictionary containing orthographically similar source-target Pre-Filtering The input data, released by the shared task organizers, contain a large amount of erroneous candidate sentence pairs which can be filtered out based on some simple heuristics. For detecting these instances we use the following rules and set the weight of these noisy candidate pairs to zero. Note, we ignore the candidates selected here in late"
W18-6477,W16-2365,0,0.0308135,"s with a probability proportional to their scores. Post-Ranking 3.1 In the third step we re-rank candidates from the previous step in order to reduce the number of redundant sentence pairs and to ensure that we have more fluent sentences. We apply these steps only to the source sentences due to speed considerations. Data A German-English dataset was released containing 1 billion (English) tokens. The corpus was crawled from the web as part of the ParaCrawl project. After extracting texts from web pages with BiTextor (Espl`a-Gomis and Forcada, 2010), documents and sentences were aligned using (Buck and Koehn, 2016) and Hunalign (Varga et al., 2007) respectively. The aligned sentence pairs are the candidates which have to be scored for the sampling process and used as training parallel data for the MT systems. The alignment scores of the candidate sentence pairs were also released which do not by themselves correlate strongly with sentence pair quality which we show in section 4. For more details of the data see the overview paper of the shared task (Koehn et al., 2018). As an additional data source we use monolingual German and English NewsCrawl sentences from the time period between 2011 and 2014 (Boja"
W18-6477,W12-3131,0,0.232531,"Missing"
W18-6477,P13-2121,0,0.048804,"Missing"
W18-6477,P18-4020,0,0.0374061,"Missing"
W18-6477,C16-1109,0,0.0568128,"Missing"
W18-6477,P07-2045,0,0.00680403,"Missing"
W18-6477,W18-6453,0,0.175436,"ect. After extracting texts from web pages with BiTextor (Espl`a-Gomis and Forcada, 2010), documents and sentences were aligned using (Buck and Koehn, 2016) and Hunalign (Varga et al., 2007) respectively. The aligned sentence pairs are the candidates which have to be scored for the sampling process and used as training parallel data for the MT systems. The alignment scores of the candidate sentence pairs were also released which do not by themselves correlate strongly with sentence pair quality which we show in section 4. For more details of the data see the overview paper of the shared task (Koehn et al., 2018). As an additional data source we use monolingual German and English NewsCrawl sentences from the time period between 2011 and 2014 (Bojar et al., 2014) which we use to train word embeddings and the language model. Monolingual Document Similarity The input corpus contains redundant sentences, i.e., sentences which have similar structure and meaning, and which are often generated based on predefined sentence templates. It is enough to use only one element from these clusters of redundant sentences since the rest does not have a big impact on the translation quality. Due to the huge size of the"
W18-6477,D17-1155,0,0.013517,"xtor which filters data based on sentence alignment scores and URL information. Similarly, word alignments and language modeling were used in (Denkowski et al., 2012) to select sentence pairs that are useful for training an MT system. Xu and Koehn (2017) proposed Zipporah, a logistic regression based model that uses bag-of-words translation features to measure fluency and adequacy in order to score sentence pairs. Another line of work is to select data based on the target domain. A static sentence-selection method was used for domain adaptation based on the internal sentence embedding of NMT (Wang et al., 2017) while van der Wees et al. (2017) used domain-based cross-entropy as a criterion to gradually fine-tune the NMT training in a dynamic manner. In contrast with previous work, we do not rely on any bilingual supervision, making our approach applicable to language pairs which lack initial parallel resources. Similarly to the work of Kajiwara and Komachi (2016), where word embeddings were used to mine monolingual sentence pairs for text simplification, we use a word level metric to compute sentence pair similarity in a computationally efficient way. Our approach consists of three steps. Due to the"
W18-6477,D17-1147,0,0.0777223,"Missing"
W18-6477,D17-1319,0,0.187944,"Corpus Filtering Viktor Hangya and Alexander Fraser Center for Information and Language Processing LMU Munich, Germany {hangyav, fraser}@cis.lmu.de Abstract sentence pairs for training both statistical and neural MT systems (Koehn et al., 2018). A lot of previous work has studied the problem of parallel data cleaning. Espl`a-Gomis and Forcada (2010) proposed BiTextor which filters data based on sentence alignment scores and URL information. Similarly, word alignments and language modeling were used in (Denkowski et al., 2012) to select sentence pairs that are useful for training an MT system. Xu and Koehn (2017) proposed Zipporah, a logistic regression based model that uses bag-of-words translation features to measure fluency and adequacy in order to score sentence pairs. Another line of work is to select data based on the target domain. A static sentence-selection method was used for domain adaptation based on the internal sentence embedding of NMT (Wang et al., 2017) while van der Wees et al. (2017) used domain-based cross-entropy as a criterion to gradually fine-tune the NMT training in a dynamic manner. In contrast with previous work, we do not rely on any bilingual supervision, making our approa"
W19-1425,P15-2044,0,0.0486182,"Missing"
W19-1425,J93-2003,0,0.0754235,"Missing"
W19-1425,Q16-1022,0,0.0464809,"Missing"
W19-1425,W03-0407,0,0.249056,"Missing"
W19-1425,D17-2008,0,0.0393799,"Missing"
W19-1425,N13-1073,0,0.0320339,".3 The idea of the cross-lingual transfer is to project tags from the annotated part of the parallel corpus to its unlabeled translation to produce training data for the under-resourced language. The success of cross-lingual transfer depends not only on the quality of the source language annotation, but also on the reliability of the annotation projection. We rely on standard statistical word alignment algorithms (Brown et al., 1993) as the basis of POS annotation projection from Russian to Ukrainian. The parallel corpus is aligned with fast align,10 an unsupervised word aligner introduced by Dyer et al. (2013). For phrasebased machine translation, the two alignment directions (forward and reverse) are typically combined to a symmetrized alignment. But for annotation projection, it is more convenient to use one-directional alignment with one Ukrainian token never being aligned to multiple tokens on the Russian side. The annotation projection across the alignment then becomes straightforward.11 No disambiguation heuristics are necessary, which could be a source of additional errors.12 The BLSTM tagger supervised with goldstandard Ukrainian annotation (Section 5.2.1) outperforms the cross-lingual tran"
W19-1425,L18-1344,0,0.0160892,"ing, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each of the considered scenarios: Low-resource scenario: When the amount of hand-labeled training data is small for the targeted language, how effectively can we further improve the tagger by employing auxiliary resources? Specifically, how helpful is the use of additional unlabeled corpora (self-training) and corpora in a different language (multilingual learning)? Zero-resource scenario: When there isn’t any hand-labeled training data available for the targeted language, how effectively can we"
W19-1425,W18-6125,0,0.0365398,"Missing"
W19-1425,I17-2003,0,0.0204776,"et al. (2018). We follow up on this line of research with our work. original idea and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each of the considered scenarios: Low-resource scenario: When the amount of hand-labeled training data is small for the targeted language, how effectively can we further improv"
W19-1425,K16-1018,0,0.0772158,"POS-tagging was first explored by Yarowsky and Ngai (2001) for crosslingual transfer from English to French. Our basic approach shares much of Yarowsky and Ngai’s 223 Proceedings of VarDial, pages 223–233 c Minneapolis, MN, June 7, 2019 2019 Association for Computational Linguistics language-specific component integrated with another cross-lingually shared component. We are however not aware of many prior studies that systematically explore annotation projection for cross-lingual transfer in neural POS-tagging of living spoken languages. Steps in this direction have been taken only lately by Fang and Cohn (2016), Plank and Agi´c (2018) and Anastasopoulos et al. (2018). We follow up on this line of research with our work. original idea and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapa"
W19-1425,C18-1214,0,0.024249,"gai (2001) for crosslingual transfer from English to French. Our basic approach shares much of Yarowsky and Ngai’s 223 Proceedings of VarDial, pages 223–233 c Minneapolis, MN, June 7, 2019 2019 Association for Computational Linguistics language-specific component integrated with another cross-lingually shared component. We are however not aware of many prior studies that systematically explore annotation projection for cross-lingual transfer in neural POS-tagging of living spoken languages. Steps in this direction have been taken only lately by Fang and Cohn (2016), Plank and Agi´c (2018) and Anastasopoulos et al. (2018). We follow up on this line of research with our work. original idea and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al."
W19-1425,C16-1012,0,0.0201308,"ection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each of the considered scenarios: Low-resource scenario: When the amount of hand-labeled training data is small for the targeted language, how effectively can we further improve the tagger by employing auxiliary resources? Specifically, how helpful is the use of additional unlabeled corpora (self-traini"
W19-1425,P16-1101,0,0.0322322,"the works of Wisniewski et al. (2014), examining annotation projection for a CRF tagging model (Lavergne et al., 2010) on living spoken languages, and of Agi´c et al. (2015). Meyer (2011) tags Old Russian via annotation projection from modern Russian translations. Sukhareva et al. (2017) POStag the extinct Hittite language through projection from German. Recent related work on neural POS-tagging has mostly focused on robustness through character-level modeling (Heigold et al., 2016, 2018; dos Santos and Zadrozny, 2014; Labeau et al., 2015) or on architectural improvements (Huang et al., 2015; Ma and Hovy, 2016; Yasunaga et al., 2018). Kim et al. (2017) have proposed an interesting neural tagging architecture that allows for multilingual learning with a Neural tagging model. Depending on the context, the part-of-speech of a word may vary. E.g., the English word “green” takes a different POS (adjective, noun, verb) in each of the following three sentences: The recipe requires green mangoes. She took 63 shots to reach the green. How can we green our campus? The need to resolve such ambiguities is one of the challenges in POS-tagging, and is the reason why the task requires sequence labeling instead of"
W19-1425,de-marneffe-etal-2014-universal,0,0.0252309,"Missing"
W19-1425,D17-1302,0,0.0442782,"ining annotation projection for a CRF tagging model (Lavergne et al., 2010) on living spoken languages, and of Agi´c et al. (2015). Meyer (2011) tags Old Russian via annotation projection from modern Russian translations. Sukhareva et al. (2017) POStag the extinct Hittite language through projection from German. Recent related work on neural POS-tagging has mostly focused on robustness through character-level modeling (Heigold et al., 2016, 2018; dos Santos and Zadrozny, 2014; Labeau et al., 2015) or on architectural improvements (Huang et al., 2015; Ma and Hovy, 2016; Yasunaga et al., 2018). Kim et al. (2017) have proposed an interesting neural tagging architecture that allows for multilingual learning with a Neural tagging model. Depending on the context, the part-of-speech of a word may vary. E.g., the English word “green” takes a different POS (adjective, noun, verb) in each of the following three sentences: The recipe requires green mangoes. She took 63 shots to reach the green. How can we green our campus? The need to resolve such ambiguities is one of the challenges in POS-tagging, and is the reason why the task requires sequence labeling instead of just a simple dictionary lookup. Another c"
W19-1425,de-marneffe-etal-2006-generating,0,0.041623,"Missing"
W19-1425,I11-1083,0,0.0246701,"e-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each of the considered scenarios: Low-resource scenario: When the amount of hand-labeled training data is small for the targeted language, how effectively can we further improve the tagger by employing auxiliary resources? Specifically, how helpful is the use of additional unlabeled corpora (self-training) and corpora in"
W19-1425,W08-1301,0,0.0683455,"Missing"
W19-1425,D15-1025,0,0.0739305,"Missing"
W19-1425,N06-1020,0,0.101571,"at, a tagger for the resource-poor language can be trained on the target side of the parallel corpus with its associated projected automatic sourceside annotation. This provides another solution in the case of a complete lack of gold-standard training data, the zero-resource scenario. Given sufficient amount of labeled data, it is possible to build high-performance tools with direct supervision, but since there are languages that do not have enough suitable data to train a model, it is reasonable to employ semi-supervised methods. Those include self-training, which was previously discussed by McClosky et al. (2006), inter alia. Self-training requires labeled and unlabeled data and can be applied to low-resource languages. “Semi-supervised and unsupervised methods are important because good labeled data is expensive, whereas there is no shortage of unlabeled data” (McClosky et al., 2006). 3.2 Multilingual Learning The multilingual learning method is suitable for under-resourced languages with little annotated data. The training set is enlarged through the texts of a related language. The idea is to shuffle original Ukrainian training sentences with the Russian labeled data to get more annotated texts. 3."
W19-1425,N16-1121,0,0.0208622,"beled corpora (self-training) and corpora in a different language (multilingual learning)? Zero-resource scenario: When there isn’t any hand-labeled training data available for the targeted language, how effectively can we harness knowledge from annotated corpora in a different, but related language? Specifically, is tagging quality close to supervised low-resource conditions attainable with either a plain foreign-language tagging model (zero-shot tagging) or via annotation projection from a foreign language (cross-lingual transfer)? To avoid unnecessarily noisy data, unlike previous authors, Lacroix et al. (2016) did not apply heuristics to fix certain word alignment links that pose difficulties to annotation projection. They demonstrated that it is simpler and more effective to ignore unaligned words as well as many-tomany alignments. In our work, we likewise settle on a simple technique based on a one-directional word alignment. Xi and Hwa (2005) have combined projected POS-annotation with a small manually annotated corpus in a low-resource scenario. Newer research on annotation projection for POS-tagging has looked at historical languages (Meyer, 2011; ¨ Sukhareva et al., 2017) and sign language (O"
W19-1425,W15-1834,0,0.057528,"Missing"
W19-1425,H05-1108,0,0.0625267,"d Cohn (2016), Plank and Agi´c (2018) and Anastasopoulos et al. (2018). We follow up on this line of research with our work. original idea and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each of the considered scenarios: Low-resource scenario: When the amount of hand-labeled training data is small for the"
W19-1425,P10-1052,0,0.0933039,"Missing"
W19-1425,petrov-etal-2012-universal,0,0.456498,"another cross-lingually shared component. We are however not aware of many prior studies that systematically explore annotation projection for cross-lingual transfer in neural POS-tagging of living spoken languages. Steps in this direction have been taken only lately by Fang and Cohn (2016), Plank and Agi´c (2018) and Anastasopoulos et al. (2018). We follow up on this line of research with our work. original idea and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation"
W19-1425,D18-1061,0,0.0919547,"Missing"
W19-1425,P16-2067,0,0.0894869,"Missing"
W19-1425,D14-1187,0,0.189103,"Missing"
W19-1425,P11-2052,0,0.0610042,"Missing"
W19-1425,H05-1107,0,0.0445223,"pervised low-resource conditions attainable with either a plain foreign-language tagging model (zero-shot tagging) or via annotation projection from a foreign language (cross-lingual transfer)? To avoid unnecessarily noisy data, unlike previous authors, Lacroix et al. (2016) did not apply heuristics to fix certain word alignment links that pose difficulties to annotation projection. They demonstrated that it is simpler and more effective to ignore unaligned words as well as many-tomany alignments. In our work, we likewise settle on a simple technique based on a one-directional word alignment. Xi and Hwa (2005) have combined projected POS-annotation with a small manually annotated corpus in a low-resource scenario. Newer research on annotation projection for POS-tagging has looked at historical languages (Meyer, 2011; ¨ Sukhareva et al., 2017) and sign language (Ostling et al., 2015). Notable exceptions are the works of Wisniewski et al. (2014), examining annotation projection for a CRF tagging model (Lavergne et al., 2010) on living spoken languages, and of Agi´c et al. (2015). Meyer (2011) tags Old Russian via annotation projection from modern Russian translations. Sukhareva et al. (2017) POStag t"
W19-1425,N01-1026,0,0.419985,"ted language). To better understand this scenario, we compare it with the lowresource scenario (i.e., availability of a small POSlabeled training corpus). We thoroughly compare four techniques, including: zero-shot tagging and cross-lingual annotation projection from a linguistically related higher-resource language (for the zero-resource scenario), as well as selftraining and multilingual learning (for the lowresource scenario). A controlled experimental design is established for our study. We aim for immediate compara2 Related Work Annotation projection for POS-tagging was first explored by Yarowsky and Ngai (2001) for crosslingual transfer from English to French. Our basic approach shares much of Yarowsky and Ngai’s 223 Proceedings of VarDial, pages 223–233 c Minneapolis, MN, June 7, 2019 2019 Association for Computational Linguistics language-specific component integrated with another cross-lingually shared component. We are however not aware of many prior studies that systematically explore annotation projection for cross-lingual transfer in neural POS-tagging of living spoken languages. Steps in this direction have been taken only lately by Fang and Cohn (2016), Plank and Agi´c (2018) and Anastasopo"
W19-1425,D15-1039,0,0.0221195,"a and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each of the considered scenarios: Low-resource scenario: When the amount of hand-labeled training data is small for the targeted language, how effectively can we further improve the tagger by employing auxiliary resources? Specifically, how helpful is the use o"
W19-1425,H01-1035,0,0.192274,"fer in neural POS-tagging of living spoken languages. Steps in this direction have been taken only lately by Fang and Cohn (2016), Plank and Agi´c (2018) and Anastasopoulos et al. (2018). We follow up on this line of research with our work. original idea and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each"
W19-1425,W96-0213,0,0.831596,": punctuation SYM: symbol X: other We utilize a Bidirectional Long Short-Term Memory (BLSTM) neural network model (Hochreiter and Schmidhuber, 1997) to build our sequence taggers. BLSTMs are recurrent neural networks (RNNs) that are capable of learning long-term dependencies, taking into account both the previous and the following context. RNNs generally show great results at processing sequential data. They are widely adopted in natural language processing, including the POS-tagging task (Wang et al., 2015). Other statistical sequence labeling methods, such as maximum entropy tagging models (Ratnaparkhi, 1996) or conditional random fields (Lafferty et al., 2001; Lavergne et al., 2010), are nowadays often outperformed by neural network methods (Collobert et al., 2011). 3.1 Table 1: Universal Dependencies tags. are not strong enough to be able to use a model trained for Russian to tag Ukrainian sentences (Section 5.2.4). 3.4 Self-Training The cross-lingual transfer approach relies on the availability of cross-lingual supervision and is suitable for languages that do not have any annotated data, but for which there is an available parallel corpus with a high-resource language. A POS-tagger for the hig"
W19-1425,N18-1089,0,0.0230428,"wski et al. (2014), examining annotation projection for a CRF tagging model (Lavergne et al., 2010) on living spoken languages, and of Agi´c et al. (2015). Meyer (2011) tags Old Russian via annotation projection from modern Russian translations. Sukhareva et al. (2017) POStag the extinct Hittite language through projection from German. Recent related work on neural POS-tagging has mostly focused on robustness through character-level modeling (Heigold et al., 2016, 2018; dos Santos and Zadrozny, 2014; Labeau et al., 2015) or on architectural improvements (Huang et al., 2015; Ma and Hovy, 2016; Yasunaga et al., 2018). Kim et al. (2017) have proposed an interesting neural tagging architecture that allows for multilingual learning with a Neural tagging model. Depending on the context, the part-of-speech of a word may vary. E.g., the English word “green” takes a different POS (adjective, noun, verb) in each of the following three sentences: The recipe requires green mangoes. She took 63 shots to reach the green. How can we green our campus? The need to resolve such ambiguities is one of the challenges in POS-tagging, and is the reason why the task requires sequence labeling instead of just a simple dictionar"
W19-1425,W17-2213,0,0.205784,"Missing"
W19-5344,J82-2005,0,0.772854,"Missing"
W19-5344,Q17-1010,0,0.0501673,"Crawl articles from 2007 to 2018. In the case of both languages the corpora contained a small set of sentences coming from foreign languages which we filtered out using a language detection tool2 . The datasets were tokenized and truecased with the standard scripts from the Moses toolkit (Koehn et al., 2007). For the bilingual word embeddings used by our PBT system we compound split the German corpus using compound-splitter.perl from the Moses toolkit with the following parameters: minimum word size 4; minimum count 5; maximum count 1000. To train monolingual word embeddings we used fasttext (Bojanowski et al., 2017), instead of word2vec (Mikolov et al., 2013), 2 de 270M 75M 270M 37M cs 67M 67M 67M 41M Table 1: Training data sizes in number of sentences. 5.2 PBT Experiments As mentioned earlier we initialize our PBT system with BWEs trained on compound split data. In Table 2 we show baseline word-by-word (wbw) results, i.e., we greedily translate each source word independently of the others using the most similar target word, according to the BWE-based dictionary, without any reordering. We compare BWEs trained with and without compound split data. The results of both approaches are low, which is due to t"
W19-5344,D18-1062,0,0.0378496,"Missing"
W19-5344,P07-2045,0,0.0114114,"ry of the 100 nearest target words for each source language word with their similarities which we convert to a phrase table. For more details on phrase-table creation see Section 3. One problem with the approach arises when translating German compound words which are combinations of two or more words that function as a single unit of meaning. In most of the cases, these words should be translated into multiple Czech words, but our generated dictionary 3 Unsupervised Phrase-based Translation We build on the BWEs to create an unsupervised phrase-based translation system using the Moses decoder (Koehn et al., 2007). In an initial step (iteration 0), a bilingual wordbased translation lexicon is obtained from the embeddings space and stored in a format compatible with Moses’ phrase table. The BWE cosine similarities serve as translation feature scores. We include multiple single-word target-side translation candidates per source-side token, given as the nearest neighbors in the bilingual embeddings space. An n-gram language model trained on target-side monolingual data is provided to Moses as another feature function. Moses then decodes with a variant of a beam search algorithm. We tune scaling factors to"
W19-5344,P18-1073,0,0.285165,"Processing LMU Munich {stojanovski,hangyav,mhuck,fraser}@cis.lmu.de Abstract Knowles (2017) also show that in low-resource setups neural models fail to match traditional phrasebased systems in terms of quality. This is the motivation for the unsupervised track at WMT19. The system we use to participate in the shared task is multipart and borrows on existing techniques for unsupervised learning. We make use of bilingual word embeddings (BWE), phrase-based translation (PBT), cross-lingual masked language models (MLM) and NMT models, all trained in an unsupervised way. Lample et al. (2018a) and Artetxe et al. (2018c) showed that, given proper bootstrapping, it is possible to train unsupervised NMT models by making use of two general techniques, denoising autoencoding and online backtranslation. Lample et al. (2018b) and Artetxe et al. (2018b) further showed that this is also possible for phrase-based statistical machine translation. A key technique that enables this is obtaining word-by-word translations by utilizing unsupervised bilingual word embeddings. Lample et al. (2018b) further simplified the bootstrapping step by showing that jointly trained BPE-level (Sennrich et al., 2016) embeddings are a be"
W19-5344,W18-6319,0,0.0233906,"sCrawl 2017-2018, and Czech NewsCrawl 2007-2018 monolingual data. For the unsupervised NMT model, we use NewsCrawl 2018 for German and NewsCrawl 2013-2018 for Czech. In this way, both models are trained with roughly equal amounts of German and Czech data. Details on the training data is in Table 1. For the NMT experiments, we use the code from (Lample and Conneau, 2019)3 . In the following we perform evaluation for both our unsupervised phrase-based and neural machine translation systems. We report BLEU scores on the detokenized translations of newstest2013 and newstest2019 using sacreBLEU 4 (Post, 2018). Incorporating PBT Synthetic Data The training curriculum to enable this model to work is to first pretrain a cross-lingual MLM. Subsequently, one can further bootstrap this model with back-translations from an unsupervised phrase-based system and finally, fine-tune this model with the unsupervised neural criteria. However, due to time constraints we first fine-tune the pretrained MLM with the NMT system. After several iterations of training, we include additional back-translations from the phrase-based system. We only used pseudo-parallel German→Czech translations. We continue using online b"
W19-5344,P16-1162,0,0.0710583,"le et al. (2018a) and Artetxe et al. (2018c) showed that, given proper bootstrapping, it is possible to train unsupervised NMT models by making use of two general techniques, denoising autoencoding and online backtranslation. Lample et al. (2018b) and Artetxe et al. (2018b) further showed that this is also possible for phrase-based statistical machine translation. A key technique that enables this is obtaining word-by-word translations by utilizing unsupervised bilingual word embeddings. Lample et al. (2018b) further simplified the bootstrapping step by showing that jointly trained BPE-level (Sennrich et al., 2016) embeddings are a better alternative, assuming closely related languages that potentially share surface forms. Lample et al. (2018b) also showed that a single shared encoder and decoder are sufficient for learning both translation directions. A general trend in NLP recently has been unsupervised masked language model pretraining. Devlin et al. (2018) showed that a wide range of NLP tasks are significantly improved by fine-tuning large MLM. They propose a way to train a Transformer language model which has access to left and right context as opposed to traditional LM which only have left contex"
W19-5344,W18-6428,1,0.787961,"vised translation such as denoising autoencoding and online back-translation. We bootstrap the model with masked language model pretraining and enhance it with back-translations from an unsupervised phrase-based system which is itself bootstrapped using unsupervised bilingual word embeddings. 1 Introduction In this paper we describe the system we developed at the LMU Munich Center for Information and Language Processing, which we used to participate in the unsupervised track of the news translation task at WMT19. The system builds on our last year’s submission to the unsupervised shared task (Stojanovski et al., 2018) and previous work on unsupervised machine translation (Lample et al., 2018a; Artetxe et al., 2018c; Lample et al., 2018b; Lample and Conneau, 2019). We submitted system runs for the German→Czech translation direction. The goal of the unsupervised track is to train machine translation models without access to any bilingual or comparable monolingual data. Supervised neural machine translation (NMT) has achieved state-of-the-art results (Bahdanau et al., 2015). With the introduction of the Transformer (Vaswani et al., 2017) the quality of automatic translations has been significantly improved. H"
W19-5345,N18-1118,0,0.0199961,"the beginning of the context sentence. We share the encoder layers up to and including the penultimate layer. Unlike Voita et al. (2018), we do not integrate the context in the encoder, but rather in the decoder. As a result, the last encoder layer is the standard Transformer encoder, but it is not shared across the main and context sentence. We modify the decoder by adding an additional Related Work There are large number of works in NMT focusing on integrating document-level information into otherwise sentence-level models (Jean et al., 2017; Wang et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita et al., 2018; Zhang et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Tu et al., 2018; Maruf and Haffari, 2018). These works have shown that improvements in pronoun translation are achieved by better handling coreference resolution. Smaller improvements are observed for coherence and cohesion. The main intuition behind the models in 401 is then added to all token-level source embeddings in the sentence to be translated in the same manner as the positional embeddings are added in the Transformer. A similar approach was proposed by Kobus et al. (2017) for domain adapta"
W19-5345,W17-3205,0,0.0274271,"ional features to the token-level embeddings. However, they assume a set of known domains in advance which is not the case in our work. We model the domain implicitly. document is also modeling the underlying domain. On an abstract level, one can presume that this is happening in sentence-level models as well, however access to larger context is likely to improve the ability to implicitly identify the domain. Domain adaptation and multi-domain NMT have been extensively studied (Kobus et al., 2017; Freitag and Al-Onaizan, 2016; Farajian et al., 2017; Sajjad et al., 2017; Zhang and Xiong, 2018; Chen et al., 2017; Tars and Fishel, 2018). However, most previous works assume that the domain of each sentence is known at training time, which is often not the case. Taking into consideration different discourselevel phenomena, we develop a Transformer (Vaswani et al., 2017) which can richly model the previous sentence, but also takes advantage of larger context. We borrow on previous work on context-aware NMT (Stojanovski and Fraser, 2018; Voita et al., 2018; Miculicich et al., 2018; Zhang et al., 2018) and add additional parameters in the encoder and decoder to account for the previous sentence. We limit t"
W19-5345,D18-1325,0,0.270482,"sively studied (Kobus et al., 2017; Freitag and Al-Onaizan, 2016; Farajian et al., 2017; Sajjad et al., 2017; Zhang and Xiong, 2018; Chen et al., 2017; Tars and Fishel, 2018). However, most previous works assume that the domain of each sentence is known at training time, which is often not the case. Taking into consideration different discourselevel phenomena, we develop a Transformer (Vaswani et al., 2017) which can richly model the previous sentence, but also takes advantage of larger context. We borrow on previous work on context-aware NMT (Stojanovski and Fraser, 2018; Voita et al., 2018; Miculicich et al., 2018; Zhang et al., 2018) and add additional parameters in the encoder and decoder to account for the previous sentence. We limit the context since we want this part of the model to be able to do coreference resolution which very often can be addressed by looking at the first previous sentence. We additionally take the 10 previous sentences and create a simple document representation by averaging their embeddings. This embedding is subsequently added to each source token in the sentence to be translated in the same fashion as positional embeddings are added to the token-level embeddings in the Tra"
W19-5345,W17-4713,0,0.0262994,"her added to the beginning of the sentence or concatenated as additional features to the token-level embeddings. However, they assume a set of known domains in advance which is not the case in our work. We model the domain implicitly. document is also modeling the underlying domain. On an abstract level, one can presume that this is happening in sentence-level models as well, however access to larger context is likely to improve the ability to implicitly identify the domain. Domain adaptation and multi-domain NMT have been extensively studied (Kobus et al., 2017; Freitag and Al-Onaizan, 2016; Farajian et al., 2017; Sajjad et al., 2017; Zhang and Xiong, 2018; Chen et al., 2017; Tars and Fishel, 2018). However, most previous works assume that the domain of each sentence is known at training time, which is often not the case. Taking into consideration different discourselevel phenomena, we develop a Transformer (Vaswani et al., 2017) which can richly model the previous sentence, but also takes advantage of larger context. We borrow on previous work on context-aware NMT (Stojanovski and Fraser, 2018; Voita et al., 2018; Miculicich et al., 2018; Zhang et al., 2018) and add additional parameters in the encod"
W19-5345,W18-6319,0,0.01334,"data mixed in with the parallel WMT data. 4.4 Training parameters 217M 253M 225M 261M Table 2: Number of model parameters. All models are big Transformer models. The number of parameters for all models are presented in Table 2. We train the models on 4 GTX 1080 Ti GPUs with 12GB RAM. We use Sockeye1 (Hieber et al., 2018) to train the baseline and our context-aware models. 5 Hyperparameters Empirical Evaluation We present the results we obtain with our models in Table 3. We report results on the English→German newstest2017, newstest2018 and newstest2019. We report BLEU scores using sacreBLEU2 (Post, 2018) on detokenized text. For the final submission, we processed quotation marks to match the German style. We train our baseline on the data presented in Table 1. We initially train on the ParaCrawl We train a big Transformer as a baseline. Embedding and hidden dimension size in the encoder and decoder is 1024. All attention sublayers use dot product attention and have 16 attention heads. The size of the feed-forward neural networks is 4096. The hidden dimension size of the contextaware encoder and context attention sublayer in the decoder is 512. All context-related attention sublayers have 8 at"
W19-5345,E17-2045,0,0.0594942,"ing of the sentence or concatenated as additional features to the token-level embeddings. However, they assume a set of known domains in advance which is not the case in our work. We model the domain implicitly. document is also modeling the underlying domain. On an abstract level, one can presume that this is happening in sentence-level models as well, however access to larger context is likely to improve the ability to implicitly identify the domain. Domain adaptation and multi-domain NMT have been extensively studied (Kobus et al., 2017; Freitag and Al-Onaizan, 2016; Farajian et al., 2017; Sajjad et al., 2017; Zhang and Xiong, 2018; Chen et al., 2017; Tars and Fishel, 2018). However, most previous works assume that the domain of each sentence is known at training time, which is often not the case. Taking into consideration different discourselevel phenomena, we develop a Transformer (Vaswani et al., 2017) which can richly model the previous sentence, but also takes advantage of larger context. We borrow on previous work on context-aware NMT (Stojanovski and Fraser, 2018; Voita et al., 2018; Miculicich et al., 2018; Zhang et al., 2018) and add additional parameters in the encoder and decoder to acc"
W19-5345,P16-1009,0,0.334765,"ed on ci and cci . The output is computed as follows: si = gi ⊗ ci + (1 − gi ) ⊗ cci and the gate is computed as: gi = σ(We ci + Wc cci ) where σ represents sigmoid activation and ⊗ element-wise multiplication. The gate enables the model to control how much information should be used from the main sentence and from the context sentence. Finally, the output of the gated sum is passed through a feed-forward neural network. 3.2 4 4.1 Experimental Setup Preprocessing The data is preprocessed by normalizing punctuation, tokenizing and truecasing with the scripts from Moses. We apply BPE splitting (Sennrich et al., 2016b) with 32K merge operations. BPE is computed jointly on both languages. Document-level context-aware Transformer We also extend the model with the ability to consume larger context. Miculicich et al. (2018) proposed a model capable of using large context using hierarchical attention. They tackle the memory requirements of such models by reusing already computed sentence representations. This introduces limitations as to how the random batching usually used to train NMT works, since it is necessary to have the previous sentences of a given sentence in a document already processed. Furthermore,"
W19-5345,W18-1820,0,0.0636364,"Missing"
W19-5345,P16-1162,0,0.30501,"ed on ci and cci . The output is computed as follows: si = gi ⊗ ci + (1 − gi ) ⊗ cci and the gate is computed as: gi = σ(We ci + Wc cci ) where σ represents sigmoid activation and ⊗ element-wise multiplication. The gate enables the model to control how much information should be used from the main sentence and from the context sentence. Finally, the output of the gated sum is passed through a feed-forward neural network. 3.2 4 4.1 Experimental Setup Preprocessing The data is preprocessed by normalizing punctuation, tokenizing and truecasing with the scripts from Moses. We apply BPE splitting (Sennrich et al., 2016b) with 32K merge operations. BPE is computed jointly on both languages. Document-level context-aware Transformer We also extend the model with the ability to consume larger context. Miculicich et al. (2018) proposed a model capable of using large context using hierarchical attention. They tackle the memory requirements of such models by reusing already computed sentence representations. This introduces limitations as to how the random batching usually used to train NMT works, since it is necessary to have the previous sentences of a given sentence in a document already processed. Furthermore,"
W19-5345,W18-6427,0,0.0392353,"Missing"
W19-5345,W18-6415,0,0.0246624,"man sentences. Furthermore, all sentences are removed where one of the following conditions is met: a word is over 40 characters long, HTML tags in text, sentence length less than 4 words, character ratio between source and target sentence is over 1:3 or 3:1, source or target sentence is not identical after removing non-numerical characters and sentence does not end in a punctuation mark. As a result, the size of the ParaCrawl corpus was reduced from 30M to 13.5M sentences. Unfortunately, due to time constraints, we were not able to reproduce the data filtering and data selection suggested by Junczys-Dowmunt (2018) which obtained the top BLEU scores at WMT18. They showed that the optimal number of sentences is 8M. We assume that the higher number of presumably noisy sentences is affecting our initial baseline. 4.3 4.5 We train the Transformer baseline with a warmup period and a learning rate of 10−4 . In all cases of continued training in the paper, we set the learning rate to 10−5 . We train the models with earlystopping based on the perplexity on the development set. We checkpoint the model every 4000 updates. The learning rate is reduced by a factor of 0.7 if no improvements are observed for 8 checkp"
W19-5345,W18-6306,1,0.927855,"in adaptation and multi-domain NMT have been extensively studied (Kobus et al., 2017; Freitag and Al-Onaizan, 2016; Farajian et al., 2017; Sajjad et al., 2017; Zhang and Xiong, 2018; Chen et al., 2017; Tars and Fishel, 2018). However, most previous works assume that the domain of each sentence is known at training time, which is often not the case. Taking into consideration different discourselevel phenomena, we develop a Transformer (Vaswani et al., 2017) which can richly model the previous sentence, but also takes advantage of larger context. We borrow on previous work on context-aware NMT (Stojanovski and Fraser, 2018; Voita et al., 2018; Miculicich et al., 2018; Zhang et al., 2018) and add additional parameters in the encoder and decoder to account for the previous sentence. We limit the context since we want this part of the model to be able to do coreference resolution which very often can be addressed by looking at the first previous sentence. We additionally take the 10 previous sentences and create a simple document representation by averaging their embeddings. This embedding is subsequently added to each source token in the sentence to be translated in the same fashion as positional embeddings are a"
W19-5345,kobus-etal-2017-domain,0,0.171789,"or Computational Linguistics these works is that they employ an additional encoder for contextual sentences and integrate the information in the encoder or decoder using a gating mechanism. Our model is similar to the context-aware Transformer models proposed in these works with some specifics which we discuss in Section 3. We also extend the Transformer model with a simple document representation which we assume provides for a domain signal. This could be useful for domain disambiguation and improved coherence and cohesion. This model is similar to previous work on domain adaptation for NMT (Kobus et al., 2017; Tars and Fishel, 2018) where special domain tokens are either added to the beginning of the sentence or concatenated as additional features to the token-level embeddings. However, they assume a set of known domains in advance which is not the case in our work. We model the domain implicitly. document is also modeling the underlying domain. On an abstract level, one can presume that this is happening in sentence-level models as well, however access to larger context is likely to improve the ability to implicitly identify the domain. Domain adaptation and multi-domain NMT have been extensively"
W19-5345,J82-2005,0,0.715168,"Missing"
W19-5345,D18-1512,0,0.100592,"Missing"
W19-5345,W17-4811,0,0.0347721,"ed, we add a special token at the beginning of the context sentence. We share the encoder layers up to and including the penultimate layer. Unlike Voita et al. (2018), we do not integrate the context in the encoder, but rather in the decoder. As a result, the last encoder layer is the standard Transformer encoder, but it is not shared across the main and context sentence. We modify the decoder by adding an additional Related Work There are large number of works in NMT focusing on integrating document-level information into otherwise sentence-level models (Jean et al., 2017; Wang et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita et al., 2018; Zhang et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Tu et al., 2018; Maruf and Haffari, 2018). These works have shown that improvements in pronoun translation are achieved by better handling coreference resolution. Smaller improvements are observed for coherence and cohesion. The main intuition behind the models in 401 is then added to all token-level source embeddings in the sentence to be translated in the same manner as the positional embeddings are added in the Transformer. A similar approach was proposed by Kobus et al. (20"
W19-5345,W18-6312,0,0.0441071,"Missing"
W19-5345,Q18-1029,0,0.0445327,"Voita et al. (2018), we do not integrate the context in the encoder, but rather in the decoder. As a result, the last encoder layer is the standard Transformer encoder, but it is not shared across the main and context sentence. We modify the decoder by adding an additional Related Work There are large number of works in NMT focusing on integrating document-level information into otherwise sentence-level models (Jean et al., 2017; Wang et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita et al., 2018; Zhang et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Tu et al., 2018; Maruf and Haffari, 2018). These works have shown that improvements in pronoun translation are achieved by better handling coreference resolution. Smaller improvements are observed for coherence and cohesion. The main intuition behind the models in 401 is then added to all token-level source embeddings in the sentence to be translated in the same manner as the positional embeddings are added in the Transformer. A similar approach was proposed by Kobus et al. (2017) for domain adaptation in RNN-based NMT. The work differs since they have special tokens which indicate the domain and they concat"
W19-5345,P18-1117,0,0.337614,"NMT have been extensively studied (Kobus et al., 2017; Freitag and Al-Onaizan, 2016; Farajian et al., 2017; Sajjad et al., 2017; Zhang and Xiong, 2018; Chen et al., 2017; Tars and Fishel, 2018). However, most previous works assume that the domain of each sentence is known at training time, which is often not the case. Taking into consideration different discourselevel phenomena, we develop a Transformer (Vaswani et al., 2017) which can richly model the previous sentence, but also takes advantage of larger context. We borrow on previous work on context-aware NMT (Stojanovski and Fraser, 2018; Voita et al., 2018; Miculicich et al., 2018; Zhang et al., 2018) and add additional parameters in the encoder and decoder to account for the previous sentence. We limit the context since we want this part of the model to be able to do coreference resolution which very often can be addressed by looking at the first previous sentence. We additionally take the 10 previous sentences and create a simple document representation by averaging their embeddings. This embedding is subsequently added to each source token in the sentence to be translated in the same fashion as positional embeddings are added to the token-le"
W19-5345,D17-1301,0,0.18795,"what is being encoded, we add a special token at the beginning of the context sentence. We share the encoder layers up to and including the penultimate layer. Unlike Voita et al. (2018), we do not integrate the context in the encoder, but rather in the decoder. As a result, the last encoder layer is the standard Transformer encoder, but it is not shared across the main and context sentence. We modify the decoder by adding an additional Related Work There are large number of works in NMT focusing on integrating document-level information into otherwise sentence-level models (Jean et al., 2017; Wang et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita et al., 2018; Zhang et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Tu et al., 2018; Maruf and Haffari, 2018). These works have shown that improvements in pronoun translation are achieved by better handling coreference resolution. Smaller improvements are observed for coherence and cohesion. The main intuition behind the models in 401 is then added to all token-level source embeddings in the sentence to be translated in the same manner as the positional embeddings are added in the Transformer. A similar approach wa"
W19-5345,D18-1049,0,0.098994,"Missing"
W19-5345,C18-1269,0,0.0168263,"r concatenated as additional features to the token-level embeddings. However, they assume a set of known domains in advance which is not the case in our work. We model the domain implicitly. document is also modeling the underlying domain. On an abstract level, one can presume that this is happening in sentence-level models as well, however access to larger context is likely to improve the ability to implicitly identify the domain. Domain adaptation and multi-domain NMT have been extensively studied (Kobus et al., 2017; Freitag and Al-Onaizan, 2016; Farajian et al., 2017; Sajjad et al., 2017; Zhang and Xiong, 2018; Chen et al., 2017; Tars and Fishel, 2018). However, most previous works assume that the domain of each sentence is known at training time, which is often not the case. Taking into consideration different discourselevel phenomena, we develop a Transformer (Vaswani et al., 2017) which can richly model the previous sentence, but also takes advantage of larger context. We borrow on previous work on context-aware NMT (Stojanovski and Fraser, 2018; Voita et al., 2018; Miculicich et al., 2018; Zhang et al., 2018) and add additional parameters in the encoder and decoder to account for the previous s"
W19-6614,P18-1008,0,0.030426,"016) with 32000 merge operations. We remove all samples where the source, target or context sentence has length over 50. We train small Transformer models as outlined in Vaswani et al. (2017) with 6 encoder and decoder layers. The source code for Dublin, Aug. 19-23, 2019 |p. 143 nt17 nt18 challenge baseline 26.9 40.0 21.7 ctx-base* 27.0† 40.2‡ 22.6† ctx-base** 27.2† 40.4† 22.0† pron-25→pron-0* 26.9 39.9 22.6† pron-25→pron-0** 27.4† 40.2 22.2† our models is publicly available 2 . We report mean scores across ten consecutive checkpoints with the lowest average perplexity on the development set (Chen et al., 2018). BLEU scores are computed on detokenized text. Evaluation of pronoun translation is done using two separate metrics. First, we use the challenge set provided by M¨uller et al. (2018) and report the overall pronoun accuracy. We refer to this metric as challenge set accuracy. The other metric is an F1 score for “it”, which we refer to as reference F1 . We predict translations and then compute micro-average F1 for “it”, using an alignment of the test set input to the reference. We compute alignments using fastalign (Dyer et al., 2013). We use all of the training, development and test data for th"
W19-6614,N13-1073,0,0.0442486,"ts with the lowest average perplexity on the development set (Chen et al., 2018). BLEU scores are computed on detokenized text. Evaluation of pronoun translation is done using two separate metrics. First, we use the challenge set provided by M¨uller et al. (2018) and report the overall pronoun accuracy. We refer to this metric as challenge set accuracy. The other metric is an F1 score for “it”, which we refer to as reference F1 . We predict translations and then compute micro-average F1 for “it”, using an alignment of the test set input to the reference. We compute alignments using fastalign (Dyer et al., 2013). We use all of the training, development and test data for the computation of the alignments. The evaluation was done using the script from Liu et al. (2018). Table 2: BLEU scores. * - initial learning rate is 10-4 , ** lr=10-5 . ctx-base: context-aware baseline, pron-{0,25,50,75}: percentage of samples with oracles. Each pron-{0,25} model fine-tuned for 140K updates. †- improvements statistically significant based on paired bootstrap resampling with p-value &lt; 0.01; ‡- p-value &lt; 0.05 6 Table 3: Reference F1 for “it” on newstest2017 and the pronoun challenge set. Notation as in Table 2 Results"
W19-6614,W18-1820,0,0.0213301,"biguous English pronoun “it” based on alignment. Previous work on curriculum learning for MT (Kocmi and Bojar, 2017; Zhang et al., 2018b; Wang et al., 2018) proposed methods which feed easier samples to the model first and later show more complex sentences. However, their focus is on improving convergence time while providing limited success on improving translation quality. In contrast with their work, we train models to better handle discourse-level phenomena. 3 Model We use the Transformer (Vaswani et al., 2017) as a baseline and implement a context-aware model on top of it using Sockeye1 (Hieber et al., 2018). The main and context sentence encoders are shared up until the penultimate layer, while the last encoder layers are separate. Since the initial layers are shared, the context sentence is marked with a special token so that the encoder knows when a context sentence is being encoded. Add & Norm Feed Forward + reason we present experiments training contextaware models with low and high initial learning rates. Note that our approach could be extended to other discourse-level phenomena, provided that useful oracles are easily obtainable. Our main contributions are: 1) We propose a curriculum lear"
W19-6614,kocmi-bojar-2017-curriculum,0,0.0174035,"un accuracy based on alignment of hypothesized translations with the reference. Voita et al. (2018) used attention scores which show a tendency of Transformerbased context-aware models to do anaphora resolution. However, M¨uller et al. (2018) report moderate improvements of the model on their pronoun test set. In order to provide a comprehensive evalProceedings of MT Summit XVII, volume 1 uation of our approach, we use BLEU, the pronoun challenge set from M¨uller et al. (2018), and F1 score for the ambiguous English pronoun “it” based on alignment. Previous work on curriculum learning for MT (Kocmi and Bojar, 2017; Zhang et al., 2018b; Wang et al., 2018) proposed methods which feed easier samples to the model first and later show more complex sentences. However, their focus is on improving convergence time while providing limited success on improving translation quality. In contrast with their work, we train models to better handle discourse-level phenomena. 3 Model We use the Transformer (Vaswani et al., 2017) as a baseline and implement a context-aware model on top of it using Sockeye1 (Hieber et al., 2018). The main and context sentence encoders are shared up until the penultimate layer, while the l"
W19-6614,C18-1051,0,0.0310009,"on of ambiguous pronouns depends on the antecedent). We experimentally show the importance of the learning rate when training context-aware models with regards to our curriculum learning approach on both pronoun and overall translation performance. For this Dublin, Aug. 19-23, 2019 |p. 140 2 Related Work Several works have proposed methods and models of including contextual information (Wang et al., 2017; Jean et al., 2017; Bawden et al., 2018; Tiedemann and Scherrer, 2017; Maruf and Haffari, 2018; Voita et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Zhang et al., 2018a; Kuang and Xiong, 2018; Kuang et al., 2018). In general, these models make use of extra-sentential attention conditioned on the main sentence being translated and use gates to control the flow of contextual information. The model we use is based on these general concepts as well. Improvements in BLEU cannot be conclusively attributed to improved anaphora resolution and therefore additional metrics are required. Several works have proposed methods of evaluation and have shown that context-aware NMT achieves improvements. M¨uller et al. (2018) propose an automatically created challenge set where a model scores German"
W19-6614,N18-1121,0,0.0216676,"on is done using two separate metrics. First, we use the challenge set provided by M¨uller et al. (2018) and report the overall pronoun accuracy. We refer to this metric as challenge set accuracy. The other metric is an F1 score for “it”, which we refer to as reference F1 . We predict translations and then compute micro-average F1 for “it”, using an alignment of the test set input to the reference. We compute alignments using fastalign (Dyer et al., 2013). We use all of the training, development and test data for the computation of the alignments. The evaluation was done using the script from Liu et al. (2018). Table 2: BLEU scores. * - initial learning rate is 10-4 , ** lr=10-5 . ctx-base: context-aware baseline, pron-{0,25,50,75}: percentage of samples with oracles. Each pron-{0,25} model fine-tuned for 140K updates. †- improvements statistically significant based on paired bootstrap resampling with p-value &lt; 0.01; ‡- p-value &lt; 0.05 6 Table 3: Reference F1 for “it” on newstest2017 and the pronoun challenge set. Notation as in Table 2 Results 6.1 Baseline We train a strong Transformer-based baseline which obtains different results than the baseline in M¨uller et al. (2018). We achieve higher BLEU"
W19-6614,P18-1118,0,0.0453513,"odel to do more aggressive anaphora resolution when encountering ambiguous pronouns in the source language (the translation of ambiguous pronouns depends on the antecedent). We experimentally show the importance of the learning rate when training context-aware models with regards to our curriculum learning approach on both pronoun and overall translation performance. For this Dublin, Aug. 19-23, 2019 |p. 140 2 Related Work Several works have proposed methods and models of including contextual information (Wang et al., 2017; Jean et al., 2017; Bawden et al., 2018; Tiedemann and Scherrer, 2017; Maruf and Haffari, 2018; Voita et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Zhang et al., 2018a; Kuang and Xiong, 2018; Kuang et al., 2018). In general, these models make use of extra-sentential attention conditioned on the main sentence being translated and use gates to control the flow of contextual information. The model we use is based on these general concepts as well. Improvements in BLEU cannot be conclusively attributed to improved anaphora resolution and therefore additional metrics are required. Several works have proposed methods of evaluation and have shown that context-aware NMT"
W19-6614,D18-1325,0,0.441709,"ot present in the sentence being translated, but is rather in a preceding sentence. Sentence-external anaphora are a problem in many domains (e.g., consider conversational texts). NMT models can be extended to receive the previous sentences of a document as input. Previous context-aware NMT models include (Jean et al., 2017; Wang © 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 et al., 2017; Tu et al., 2018; Voita et al., 2018; Stojanovski and Fraser, 2018; Zhang et al., 2018a; Miculicich et al., 2018). Previous work on evaluation has shown that context-aware NMT improves over sentence-level baselines, both in terms of BLEU and in terms of metrics tailored for pronoun evaluation (Bawden et al., 2018; Voita et al., 2018; M¨uller et al., 2018). In this work, we propose a technique for improving the ability of context-aware models to handle anaphora resolution. The technique is based on curriculum learning (Bengio et al., 2009) which proposes to train neural networks in a similar fashion to how humans learn. Curriculum learning is a method that proposes training neural networks by gradually fe"
W19-6614,W18-6307,0,0.0258723,"Missing"
W19-6614,P16-1162,0,0.0707586,"on with the previous sentence. In the final step, we train a model with the previous sentence as context. This step is necessary as the model is still biased to look for the gold standard pronouns. However, we experimentally show that better results are obtained with fewer steps using a low percentage of oracles. 5 Experimental Setup Following M¨uller et al. (2018), we conduct experiments on English→German WMT17 data and use newstest2017 and newstest2018 as test sets in addition to the pronoun challenge set. In terms of preprocessing, we tokenize and truecase the data and apply BPE splitting (Sennrich et al., 2016) with 32000 merge operations. We remove all samples where the source, target or context sentence has length over 50. We train small Transformer models as outlined in Vaswani et al. (2017) with 6 encoder and decoder layers. The source code for Dublin, Aug. 19-23, 2019 |p. 143 nt17 nt18 challenge baseline 26.9 40.0 21.7 ctx-base* 27.0† 40.2‡ 22.6† ctx-base** 27.2† 40.4† 22.0† pron-25→pron-0* 26.9 39.9 22.6† pron-25→pron-0** 27.4† 40.2 22.2† our models is publicly available 2 . We report mean scores across ten consecutive checkpoints with the lowest average perplexity on the development set (Chen"
W19-6614,W18-6306,1,0.828482,"l sentences. In many cases the antecedent noun is not present in the sentence being translated, but is rather in a preceding sentence. Sentence-external anaphora are a problem in many domains (e.g., consider conversational texts). NMT models can be extended to receive the previous sentences of a document as input. Previous context-aware NMT models include (Jean et al., 2017; Wang © 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 et al., 2017; Tu et al., 2018; Voita et al., 2018; Stojanovski and Fraser, 2018; Zhang et al., 2018a; Miculicich et al., 2018). Previous work on evaluation has shown that context-aware NMT improves over sentence-level baselines, both in terms of BLEU and in terms of metrics tailored for pronoun evaluation (Bawden et al., 2018; Voita et al., 2018; M¨uller et al., 2018). In this work, we propose a technique for improving the ability of context-aware models to handle anaphora resolution. The technique is based on curriculum learning (Bengio et al., 2009) which proposes to train neural networks in a similar fashion to how humans learn. Curriculum learning is a method that pr"
W19-6614,W17-4811,0,0.0630267,"ntecedent nouns and bias the model to do more aggressive anaphora resolution when encountering ambiguous pronouns in the source language (the translation of ambiguous pronouns depends on the antecedent). We experimentally show the importance of the learning rate when training context-aware models with regards to our curriculum learning approach on both pronoun and overall translation performance. For this Dublin, Aug. 19-23, 2019 |p. 140 2 Related Work Several works have proposed methods and models of including contextual information (Wang et al., 2017; Jean et al., 2017; Bawden et al., 2018; Tiedemann and Scherrer, 2017; Maruf and Haffari, 2018; Voita et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Zhang et al., 2018a; Kuang and Xiong, 2018; Kuang et al., 2018). In general, these models make use of extra-sentential attention conditioned on the main sentence being translated and use gates to control the flow of contextual information. The model we use is based on these general concepts as well. Improvements in BLEU cannot be conclusively attributed to improved anaphora resolution and therefore additional metrics are required. Several works have proposed methods of evaluation and have show"
W19-6614,Q18-1029,0,0.0470113,"because most models work on individual sentences. In many cases the antecedent noun is not present in the sentence being translated, but is rather in a preceding sentence. Sentence-external anaphora are a problem in many domains (e.g., consider conversational texts). NMT models can be extended to receive the previous sentences of a document as input. Previous context-aware NMT models include (Jean et al., 2017; Wang © 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 et al., 2017; Tu et al., 2018; Voita et al., 2018; Stojanovski and Fraser, 2018; Zhang et al., 2018a; Miculicich et al., 2018). Previous work on evaluation has shown that context-aware NMT improves over sentence-level baselines, both in terms of BLEU and in terms of metrics tailored for pronoun evaluation (Bawden et al., 2018; Voita et al., 2018; M¨uller et al., 2018). In this work, we propose a technique for improving the ability of context-aware models to handle anaphora resolution. The technique is based on curriculum learning (Bengio et al., 2009) which proposes to train neural networks in a similar fashion to how hum"
W19-6614,P18-1117,0,0.479908,"ls work on individual sentences. In many cases the antecedent noun is not present in the sentence being translated, but is rather in a preceding sentence. Sentence-external anaphora are a problem in many domains (e.g., consider conversational texts). NMT models can be extended to receive the previous sentences of a document as input. Previous context-aware NMT models include (Jean et al., 2017; Wang © 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 et al., 2017; Tu et al., 2018; Voita et al., 2018; Stojanovski and Fraser, 2018; Zhang et al., 2018a; Miculicich et al., 2018). Previous work on evaluation has shown that context-aware NMT improves over sentence-level baselines, both in terms of BLEU and in terms of metrics tailored for pronoun evaluation (Bawden et al., 2018; Voita et al., 2018; M¨uller et al., 2018). In this work, we propose a technique for improving the ability of context-aware models to handle anaphora resolution. The technique is based on curriculum learning (Bengio et al., 2009) which proposes to train neural networks in a similar fashion to how humans learn. Curriculu"
W19-6614,D17-1301,0,0.0368367,"in the context will make it easier to model the gender of antecedent nouns and bias the model to do more aggressive anaphora resolution when encountering ambiguous pronouns in the source language (the translation of ambiguous pronouns depends on the antecedent). We experimentally show the importance of the learning rate when training context-aware models with regards to our curriculum learning approach on both pronoun and overall translation performance. For this Dublin, Aug. 19-23, 2019 |p. 140 2 Related Work Several works have proposed methods and models of including contextual information (Wang et al., 2017; Jean et al., 2017; Bawden et al., 2018; Tiedemann and Scherrer, 2017; Maruf and Haffari, 2018; Voita et al., 2018; Stojanovski and Fraser, 2018; Miculicich et al., 2018; Zhang et al., 2018a; Kuang and Xiong, 2018; Kuang et al., 2018). In general, these models make use of extra-sentential attention conditioned on the main sentence being translated and use gates to control the flow of contextual information. The model we use is based on these general concepts as well. Improvements in BLEU cannot be conclusively attributed to improved anaphora resolution and therefore additional metrics are req"
W19-6614,P18-2048,0,0.0247582,"ed translations with the reference. Voita et al. (2018) used attention scores which show a tendency of Transformerbased context-aware models to do anaphora resolution. However, M¨uller et al. (2018) report moderate improvements of the model on their pronoun test set. In order to provide a comprehensive evalProceedings of MT Summit XVII, volume 1 uation of our approach, we use BLEU, the pronoun challenge set from M¨uller et al. (2018), and F1 score for the ambiguous English pronoun “it” based on alignment. Previous work on curriculum learning for MT (Kocmi and Bojar, 2017; Zhang et al., 2018b; Wang et al., 2018) proposed methods which feed easier samples to the model first and later show more complex sentences. However, their focus is on improving convergence time while providing limited success on improving translation quality. In contrast with their work, we train models to better handle discourse-level phenomena. 3 Model We use the Transformer (Vaswani et al., 2017) as a baseline and implement a context-aware model on top of it using Sockeye1 (Hieber et al., 2018). The main and context sentence encoders are shared up until the penultimate layer, while the last encoder layers are separate. Since th"
W19-6614,D18-1049,0,0.379015,"antecedent noun is not present in the sentence being translated, but is rather in a preceding sentence. Sentence-external anaphora are a problem in many domains (e.g., consider conversational texts). NMT models can be extended to receive the previous sentences of a document as input. Previous context-aware NMT models include (Jean et al., 2017; Wang © 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. Proceedings of MT Summit XVII, volume 1 et al., 2017; Tu et al., 2018; Voita et al., 2018; Stojanovski and Fraser, 2018; Zhang et al., 2018a; Miculicich et al., 2018). Previous work on evaluation has shown that context-aware NMT improves over sentence-level baselines, both in terms of BLEU and in terms of metrics tailored for pronoun evaluation (Bawden et al., 2018; Voita et al., 2018; M¨uller et al., 2018). In this work, we propose a technique for improving the ability of context-aware models to handle anaphora resolution. The technique is based on curriculum learning (Bengio et al., 2009) which proposes to train neural networks in a similar fashion to how humans learn. Curriculum learning is a method that proposes training neur"
