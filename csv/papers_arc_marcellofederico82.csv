2021.naacl-main.94,Towards Modeling the Style of Translators in Neural Machine Translation,2021,-1,-1,3,0,3524,yue wang,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"One key ingredient of neural machine translation is the use of large datasets from different domains and resources (e.g. Europarl, TED talks). These datasets contain documents translated by professional translators using different but consistent translation styles. Despite that, the model is usually trained in a way that neither explicitly captures the variety of translation styles present in the data nor translates new data in different and controllable styles. In this work, we investigate methods to augment the state of the art Transformer model with translator information that is available in part of the training data. We show that our style-augmented translation models are able to capture the style variations of translators and to generate translations with different styles on new data. Indeed, the generated variations differ significantly, up to +4.5 BLEU score difference. Despite that, human evaluation confirms that the translations are of the same quality."
2021.iwslt-1.1,{FINDINGS} {OF} {THE} {IWSLT} 2021 {EVALUATION} {CAMPAIGN},2021,-1,-1,6,0.14366,832,antonios anastasopoulos,Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021),0,"The evaluation campaign of the International Conference on Spoken Language Translation (IWSLT 2021) featured this year four shared tasks: (i) Simultaneous speech translation, (ii) Offline speech translation, (iii) Multilingual speech translation, (iv) Low-resource speech translation. A total of 22 teams participated in at least one of the tasks. This paper describes each shared task, data and evaluation metrics, and reports results of the received submissions."
2021.iwslt-1.31,A Statistical Extension of Byte-Pair Encoding,2021,-1,-1,2,0,5800,david vilar,Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021),0,"Sub-word segmentation is currently a standard tool for training neural machine translation (MT) systems and other NLP tasks. The goal is to split words (both in the source and target languages) into smaller units which then constitute the input and output vocabularies of the MT system. The aim of reducing the size of the input and output vocabularies is to increase the generalization capabilities of the translation model, enabling the system to translate and generate infrequent and new (unseen) words at inference time by combining previously seen sub-word units. Ideally, we would expect the created units to have some linguistic meaning, so that words are created in a compositional way. However, the most popular word-splitting method, Byte-Pair Encoding (BPE), which originates from the data compression literature, does not include explicit criteria to favor linguistic splittings nor to find the optimal sub-word granularity for the given training data. In this paper, we propose a statistically motivated extension of the BPE algorithm and an effective convergence criterion that avoids the costly experimentation cycle needed to select the best sub-word vocabulary size. Experimental results with morphologically rich languages show that our model achieves nearly-optimal BLEU scores and produces morphologically better word segmentations, which allows to outperform BPE{'}s generalization in the translation of sentences containing new words, as shown via human evaluation."
2020.nlpcovid19-2.5,{TICO}-19: the Translation Initiative for {CO}vid-19,2020,-1,-1,4,0.14366,832,antonios anastasopoulos,Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020,0,"The COVID-19 pandemic is the worst pandemic to strike the world in over a century. Crucial to stemming the tide of the SARS-CoV-2 virus is communicating to vulnerable populations the means by which they can protect themselves. To this end, the collaborators forming the Translation Initiative for COvid-19 (TICO-19) have made test and development data available to AI and MT researchers in 35 different languages in order to foster the development of tools and resources for improving access to information about COVID-19 in these languages. In addition to 9 high-resourced, {''}pivot{''} languages, the team is targeting 26 lesser resourced languages, in particular languages of Africa, South Asia and South-East Asia, whose populations may be the most vulnerable to the spread of the virus. The same data is translated into all of the languages represented, meaning that testing or development can be done for any pairing of languages in the set. Further, the team is converting the test and development data into translation memories (TMXs) that can be used by localizers from and to any of the languages."
2020.iwslt-1.1,{FINDINGS} {OF} {THE} {IWSLT} 2020 {EVALUATION} {CAMPAIGN},2020,-1,-1,8,0,11026,ebrahim ansari,Proceedings of the 17th International Conference on Spoken Language Translation,0,"The evaluation campaign of the International Conference on Spoken Language Translation (IWSLT 2020) featured this year six challenge tracks: (i) Simultaneous speech translation, (ii) Video speech translation, (iii) Offline speech translation, (iv) Conversational speech translation, (v) Open domain translation, and (vi) Non-native speech translation. A total of teams participated in at least one of the tracks. This paper introduces each track{'}s goal, data and evaluation metrics, and reports the results of the received submissions."
2020.iwslt-1.31,From Speech-to-Speech Translation to Automatic Dubbing,2020,31,1,1,1,3526,marcello federico,Proceedings of the 17th International Conference on Spoken Language Translation,0,"We present enhancements to a speech-to-speech translation pipeline in order to perform automatic dubbing. Our architecture features neural machine translation generating output of preferred length, prosodic alignment of the translation with the original speech segments, neural text-to-speech with fine tuning of the duration of each utterance, and, finally, audio rendering to enriches text-to-speech output with background noise and reverberation extracted from the original audio. We report and discuss results of a first subjective evaluation of automatic dubbing of excerpts of TED Talks from English into Italian, which measures the perceived naturalness of automatic dubbing and the relative importance of each proposed enhancement."
2020.iwslt-1.32,Joint Translation and Unit Conversion for End-to-end Localization,2020,31,0,3,0.472026,8881,georgiana dinu,Proceedings of the 17th International Conference on Spoken Language Translation,0,"A variety of natural language tasks require processing of textual data which contains a mix of natural language and formal languages such as mathematical expressions. In this paper, we take unit conversions as an example and propose a data augmentation technique which lead to models learning both translation and conversion tasks as well as how to adequately switch between them for end-to-end localization."
P19-1294,Training Neural Machine Translation to Apply Terminology Constraints,2019,0,4,3,0.472026,8881,georgiana dinu,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"This paper proposes a novel method to inject custom terminology into neural machine translation at run time. Previous works have mainly proposed modifications to the decoding algorithm in order to constrain the output to include run-time-provided target terms. While being effective, these constrained decoding methods add, however, significant computational overhead to the inference step, and, as we show in this paper, can be brittle when tested in realistic conditions. In this paper we approach the problem by training a neural MT system to learn how to use custom terminology when provided with the input. Comparative experiments show that our method is not only more effective than a state-of-the-art implementation of constrained decoding, but is also as fast as constraint-free decoding."
D19-5619,On the Importance of Word Boundaries in Character-level Neural Machine Translation,2019,23,2,4,1,1387,duygu ataman,Proceedings of the 3rd Workshop on Neural Generation and Translation,0,"Neural Machine Translation (NMT) models generally perform translation using a fixed-size lexical vocabulary, which is an important bottleneck on their generalization capability and overall translation quality. The standard approach to overcome this limitation is to segment words into subword units, typically using some external tools with arbitrary heuristics, resulting in vocabulary units not optimized for the translation task. Recent studies have shown that the same approach can be extended to perform NMT directly at the level of characters, which can deliver translation accuracy on-par with subword-based models, on the other hand, this requires relatively deeper networks. In this paper, we propose a more computationally-efficient solution for character-level NMT which implements a hierarchical decoding architecture where translations are subsequently generated at the level of words and characters. We evaluate different methods for open-vocabulary NMT in the machine translation task from English into five languages with distinct morphological typology, and show that the hierarchical decoding model can reach higher translation accuracy than the subword-level NMT model using significantly fewer parameters, while demonstrating better capacity in learning longer-distance contextual and grammatical dependencies than the standard character-level NMT model."
W18-6316,Neural Machine Translation into Language Varieties,2018,24,3,3,0,5082,surafel lakew,Proceedings of the Third Conference on Machine Translation: Research Papers,0,"Both research and commercial machine translation have so far neglected the importance of properly handling the spelling, lexical and grammar divergences occurring among language varieties. Notable cases are standard national varieties such as Brazilian and European Portuguese, and Canadian and European French, which popular online machine translation services are not keeping distinct. We show that an evident side effect of modeling such varieties as unique classes is the generation of inconsistent translations. In this work, we investigate the problem of training neural machine translation from English to specific pairs of language varieties, assuming both labeled and unlabeled parallel texts, and low-resource conditions. We report experiments from English to two pairs of dialects, European-Brazilian Portuguese and European-Canadian French, and two pairs of standardized varieties, Croatian-Serbian and Indonesian-Malay. We show significant BLEU score improvements over baseline systems when translation into similar languages is learned as a multilingual task with shared representations."
W18-2106,Challenges in Adaptive Neural Machine Translation,2018,0,0,1,1,3526,marcello federico,Proceedings of the {AMTA} 2018 Workshop on Translation Quality Estimation and Automatic Post-Editing,0,None
W18-1810,An Evaluation of Two Vocabulary Reduction Methods for Neural Machine Translation,2018,0,2,2,1,1387,duygu ataman,Proceedings of the 13th Conference of the Association for Machine Translation in the {A}mericas (Volume 1: Research Track),0,None
P18-2049,Compositional Representation of Morphologically-Rich Input for Neural Machine Translation,2018,24,1,2,1,1387,duygu ataman,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Neural machine translation (NMT) models are typically trained with fixed-size input and output vocabularies, which creates an important bottleneck on their accuracy and generalization capability. As a solution, various studies proposed segmenting words into sub-word units and performing translation at the sub-lexical level. However, statistical word segmentation methods have recently shown to be prone to morphological errors, which can lead to inaccurate translations. In this paper, we propose to overcome this problem by replacing the source-language embedding layer of NMT with a bi-directional recurrent neural network that generates compositional representations of the input at any desired level of granularity. We test our approach in a low-resource setting with five languages from different morphological typologies, and under different composition assumptions. By training NMT to compose word representations from character n-grams, our approach consistently outperforms (from 1.71 to 2.48 BLEU points) NMT learning embeddings of statistically generated sub-word units."
C18-1054,A Comparison of Transformer and Recurrent Neural Networks on Multilingual Neural Machine Translation,2018,28,3,3,0,5082,surafel lakew,Proceedings of the 27th International Conference on Computational Linguistics,0,"Recently, neural machine translation (NMT) has been extended to multilinguality, that is to handle more than one translation direction with a single system. Multilingual NMT showed competitive performance against pure bilingual systems. Notably, in low-resource settings, it proved to work effectively and efficiently, thanks to shared representation space that is forced across languages and induces a sort of transfer-learning. Furthermore, multilingual NMT enables so-called zero-shot inference across language pairs never seen at training time. Despite the increasing interest in this framework, an in-depth analysis of what a multilingual NMT model is capable of and what it is not is still missing. Motivated by this, our work (i) provides a quantitative and comparative analysis of the translations produced by bilingual, multilingual and zero-shot systems; (ii) investigates the translation quality of two of the currently dominant neural architectures in MT, which are the Recurrent and the Transformer ones; and (iii) quantitatively explores how the closeness between languages influences the zero-shot translation. Our analysis leverages multiple professional post-edits of automatic translations by several different systems and focuses both on automatic standard metrics (BLEU and TER) and on widely used error categories, which are lexical, morphology, and word order errors."
W17-4713,Multi-Domain Neural Machine Translation through Unsupervised Adaptation,2017,3,26,4,1,13779,amin farajian,Proceedings of the Second Conference on Machine Translation,0,None
W17-4716,Guiding Neural Machine Translation Decoding with External Knowledge,2017,24,15,4,0,13898,rajen chatterjee,Proceedings of the Second Conference on Machine Translation,0,None
W17-4723,{FBK}{'}s Participation to the {E}nglish-to-{G}erman News Translation Task of {WMT} 2017,2017,0,2,3,0.666667,5735,mattia gangi,Proceedings of the Second Conference on Machine Translation,0,None
E17-2045,Neural vs. Phrase-Based Machine Translation in a Multi-Domain Scenario,2017,9,8,5,1,13779,amin farajian,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"State-of-the-art neural machine translation (NMT) systems are generally trained on specific domains by carefully selecting the training sets and applying proper domain adaptation techniques. In this paper we consider the real world scenario in which the target domain is not predefined, hence the system should be able to translate text from multiple domains. We compare the performance of a generic NMT system and phrase-based statistical machine translation (PBMT) system by training them on a generic parallel corpus composed of data from different domains. Our results on multi-domain English-French data show that, in these realistic conditions, PBMT outperforms its neural counterpart. This raises the question: is NMT ready for deployment as a generic/multi-purpose MT backbone in real-world settings?"
P16-4009,{TM}op: a Tool for Unsupervised Translation Memory Cleaning,2016,12,1,5,0,9979,masoud sabet,Proceedings of {ACL}-2016 System Demonstrations,0,"We present TMop, the first open-source tool for automatic Translation Memory (TM) cleaning. The tool implements a fully unsupervised approach to the task, which allows spotting unreliable translation units (sentence pairs in different languages, which are supposed to be translations of each other) without requiring labeled training data. TMop includes a highly configurable and extensible set of filters capturing different aspects of translation quality. It has been evaluated on a test set composed of 1,000 translation units (TUs) randomly extracted from the English-Italian version of MyMemory, a large-scale public TM. Results indicate its effectiveness in automatic removing xe2x80x9cbadxe2x80x9d TUs, with comparable performance to a state-of-the-art supervised method (76.3 vs. 77.7 balanced accuracy)."
L16-1562,{WAGS}: A Beautiful {E}nglish-{I}talian Benchmark Supporting Word Alignment Evaluation on Rare Words,2016,25,0,4,0,8246,luisa bentivogli,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents WAGS (Word Alignment Gold Standard), a novel benchmark which allows extensive evaluation of WA tools on out-of-vocabulary (OOV) and rare words. WAGS is a subset of the Common Test section of the Europarl English-Italian parallel corpus, and is specifically tailored to OOV and rare words. WAGS is composed of 6,715 sentence pairs containing 11,958 occurrences of OOV and rare words up to frequency 15 in the Europarl Training set (5,080 English words and 6,878 Italian words), representing almost 3{\%} of the whole text. Since WAGS is focused on OOV/rare words, manual alignments are provided for these words only, and not for the whole sentences. Two off-the-shelf word aligners have been evaluated on WAGS, and results have been compared to those obtained on an existing benchmark tailored to full text alignment. The results obtained confirm that WAGS is a valuable resource, which allows a statistically sound evaluation of WA systems{'} performance on OOV and rare words, as well as extensive data analyses. WAGS is publicly released under a Creative Commons Attribution license."
J16-2001,{S}urveys: A Survey of Word Reordering in Statistical Machine Translation: Computational Models and Language Phenomena,2016,171,16,2,1,369,arianna bisazza,Computational Linguistics,0,"Word reordering is one of the most difficult aspects of statistical machine translation SMT, and an important factor of its quality and efficiency. Despite the vast amount of research published to date, the interest of the community in this problem has not decreased, and no single method appears to be strongly dominant across language pairs. Instead, the choice of the optimal approach for a new translation task still seems to be mostly driven by empirical trials.n n To orient the reader in this vast and complex research area, we present a comprehensive survey of word reordering viewed as a statistical modeling challenge and as a natural language phenomenon. The survey describes in detail how word reordering is modeled within different string-based and tree-based SMT frameworks and as a stand-alone task, including systematic overviews of the literature in advanced reordering modeling.n n We then question why some approaches are more successful than others in different language pairs. We argue that besides measuring the amount of reordering, it is important to understand which kinds of reordering occur in a given language pair. To this end, we conduct a qualitative analysis of word reordering phenomena in a diverse sample of language pairs, based on a large collection of linguistic knowledge. Empirical results in the SMT literature are shown to support the hypothesis that a few linguistic facts can be very useful to anticipate the reordering characteristics of a language pair and to select the SMT framework that best suits them."
D16-1025,Neural versus Phrase-Based Machine Translation Quality: a Case Study,2016,29,33,4,0,8246,luisa bentivogli,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,"Within the field of Statistical Machine Translation (SMT), the neural approach (NMT) has recently emerged as the first technology able to challenge the long-standing dominance of phrase-based approaches (PBMT). In particular, at the IWSLT 2015 evaluation campaign, NMT outperformed well established state-of-the-art PBMT systems on English-German, a language pair known to be particularly hard because of morphology and syntactic differences. To understand in what respects NMT provides better translation quality than PBMT, we perform a detailed analysis of neural versus phrase-based SMT outputs, leveraging high quality post-edits performed by professional translators on the IWSLT data. For the first time, our analysis provides useful insights on what linguistic phenomena are best modeled by neural models -- such as the reordering of verbs -- while pointing out other aspects that remain to be improved."
2016.amta-users.3,{MT} Adaptation from {TM}s in {M}odern{MT},2016,-1,-1,1,1,3526,marcello federico,Conferences of the Association for Machine Translation in the Americas: MT Users' Track,0,None
P15-2087,{MT} Quality Estimation for Computer-assisted Translation: Does it Really Help?,2015,17,4,3,0.218693,5084,marco turchi,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"The usefulness of translation quality estimation (QE) to increase productivity in a computer-assisted translation (CAT) framework is a widely held assumption (Specia, 2011; Huang et al., 2014). So far, however, the validity of this assumption has not been yet demonstrated through sound evaluations in realistic settings. To this aim, we report on an evaluation involving professional translators operating with a CAT tool in controlled but natural conditions. Contrastive experiments are carried out by measuring post-editing time differences when: i) translation suggestions are presented together with binary quality estimates, and ii) the same suggestions are presented without quality indicators. Translatorsxe2x80x99 productivity in the two conditions is analysed in a principled way, accounting for the main factors (e.g. differences in translatorsxe2x80x99 behaviour, quality of the suggestions) that directly impact on time measurements. While the general assumption about the usefulness of QE is verified, significance testing results reveal that real productivity gains can be observed only under specific conditions."
2015.mtsummit-users.5,{MT} quality estimation for e-commerce data,2015,-1,-1,2,0,27677,jose souza,Proceedings of Machine Translation Summit XV: User Track,0,None
2015.mtsummit-papers.21,Topic adaptation for machine translation of e-commerce content,2015,-1,-1,2,1,8880,prashant mathur,Proceedings of Machine Translation Summit XV: Papers,0,None
2015.iwslt-evaluation.1,The {IWSLT} 2015 Evaluation Campaign,2015,18,51,6,0,10592,mauro cettolo,Proceedings of the 12th International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
W14-0313,Online Word Alignment for Online Adaptive Machine Translation,2014,14,10,3,1,13779,amin farajian,Proceedings of the {EACL} 2014 Workshop on Humans and Computer-assisted Translation,0,"A hot task in the Computer Assisted Translation scenario is the integration of Machine Translation (MT) systems that adapt sentence after sentence to the postedits made by the translators. A main role in the MT online adaptation process is played by the information extracted from source and post-edited sentences, which in turn depends on the quality of the word alignment between them. In fact, this step is particularly crucial when the user corrects the MT output with words for which the system has no prior information. In this paper, we first discuss the application of popular state-of-the-art word aligners to this scenario and reveal their poor performance in aligning unknown words. Then, we propose a fast procedure to refine their outputs and to get more reliable and accurate alignments for unknown words. We evaluate our enhanced word-aligner on three language pairs, namely English-Italian, EnglishFrench, and English-Spanish, showing a consistent improvement in aligning unknown words up to 10% absolute Fmeasure."
D14-1172,Assessing the Impact of Translation Errors on Machine Translation Quality with Mixed-effects Models,2014,30,10,1,1,3526,marcello federico,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Learning from errors is a crucial aspect of improving expertise. Based on this notion, we discuss a robust statistical framework for analysing the impact of different error types on machine translation (MT) output quality. Our approach is based on linear mixed-effects models, which allow the analysis of error-annotated MT output taking into account the variability inherent to the specific experimental setting from which the empirical observations are drawn. Our experiments are carried out on different language pairs involving Chinese, Arabic and Russian as target languages. Interesting findings are reported, concerning the impact of different error types both at the level of human perception of quality and with respect to performance results measured with automatic metrics."
C14-2026,{MT}-{EQ}u{A}l: a Toolkit for Human Assessment of Machine Translation Output,2014,4,14,4,0.789474,39811,christian girardi,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: System Demonstrations",0,"MT-EQuAl (Machine Translation Errors, Quality, Alignment) is a toolkit for human assessment of Machine Translation (MT) output. MT-EQuAl implements three different tasks in an integrated environment: annotation of translation errors, translation quality rating (e.g. adequacy and fluency, relative ranking of alternative translations), and word alignment. The toolkit is webbased and multi-user, allowing large scale and remotely managed manual annotation projects. It incorporates a number of project management functions and sophisticated progress monitoring capabilities. The implemented evaluation tasks are configurable and can be adapted to several specific annotation needs. The toolkit is open source and released under Apache 2.0 license."
C14-2028,The {M}ate{C}at Tool,2014,7,36,1,1,3526,marcello federico,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: System Demonstrations",0,"We present a new web-based CAT tool providing translators with a professional work environment, integrating translation memories, terminology bases, concordancers, and machine translation. The tool is completely developed as open source software and has been already successfully deployed for business, research and education. The MateCat Tool represents today probably the best available open source platform for investigating, integrating, and evaluating under realistic conditions the impact of new machine translation technology on human post-editing."
2014.iwslt-evaluation.1,Report on the 11th {IWSLT} evaluation campaign,2014,-1,-1,5,0.934473,10592,mauro cettolo,Proceedings of the 11th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"The paper overviews the 11th evaluation campaign organized by the IWSLT workshop. The 2014 evaluation offered multiple tracks on lecture transcription and translation based on the TED Talks corpus. In particular, this year IWSLT included three automatic speech recognition tracks, on English, German and Italian, five speech translation tracks, from English to French, English to German, German to English, English to Italian, and Italian to English, and five text translation track, also from English to French, English to German, German to English, English to Italian, and Italian to English. In addition to the official tracks, speech and text translation optional tracks were offered, globally involving 12 other languages: Arabic, Spanish, Portuguese (B), Hebrew, Chinese, Polish, Persian, Slovenian, Turkish, Dutch, Romanian, Russian. Overall, 21 teams participated in the evaluation, for a total of 76 primary runs submitted. Participants were also asked to submit runs on the 2013 test set (progress test set), in order to measure the progress of systems with respect to the previous year. All runs were evaluated with objective metrics, and submissions for two of the official text translation tracks were also evaluated with human post-editing."
2014.iwslt-evaluation.5,{FBK}{'}s machine translation and speech translation systems for the {IWSLT} 2014 evaluation campaign,2014,-1,-1,4,0,29503,nicola bertoldi,Proceedings of the 11th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the systems submitted by FBK for the MT and SLT tracks of IWSLT 2014. We participated in the English-French and German-English machine translation tasks, as well as the English-French speech translation task. We report improvements in our English-French MT systems over last year{'}s baselines, largely due to improved techniques of combining translation and language models, and using huge language models. For our German-English system, we experimented with a novel domain adaptation technique. For both language pairs we also applied a novel word triggerbased model which shows slight improvements on EnglishFrench and German-English systems. Our English-French SLT system utilizes MT-based punctuation insertion, recasing, and ASR-like synthesized MT training data."
2014.iwslt-evaluation.7,Combined spoken language translation,2014,55,6,16,0.540541,3519,markus freitag,Proceedings of the 11th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"EU-BRIDGE is a European research project which is aimed at developing innovative speech translation technology. One of the collaborative efforts within EU-BRIDGE is to produce joint submissions of up to four different partners to the evaluation campaign at the 2014 International Workshop on Spoken Language Translation (IWSLT). We submitted combined translations to the GermanâEnglish spoken language translation (SLT) track as well as to the GermanâEnglish, EnglishâGerman and EnglishâFrench machine translation (MT) tracks. In this paper, we present the techniques which were applied by the different individual translation systems of RWTH Aachen University, the University of Edinburgh, Karlsruhe Institute of Technology, and Fondazione Bruno Kessler. We then show the combination approach developed at RWTH Aachen University which combined the individual systems. The consensus translations yield empirical gains of up to 2.3 points in BLEU and 1.2 points in TER compared to the best individual system."
2014.eamt-1.10,{M}ate{C}at,2014,-1,-1,1,1,3526,marcello federico,Proceedings of the 17th Annual conference of the European Association for Machine Translation,0,None
2014.eamt-1.39,Complexity of spoken versus written language for machine translation,2014,-1,-1,2,0,40400,nicholas ruiz,Proceedings of the 17th Annual conference of the European Association for Machine Translation,0,None
2014.amta-tutorials.3,{M}ate{C}at: an open source {CAT} tool for {MT} post-editing,2014,-1,-1,1,1,3526,marcello federico,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: Tutorials,0,None
2014.amta-tutorials.4,Working with {M}ate{C}at: user manual and installation guide,2014,-1,-1,1,1,3526,marcello federico,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: Tutorials,0,None
2014.amta-researchers.12,Online multi-user adaptive statistical machine translation,2014,-1,-1,3,1,8880,prashant mathur,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: MT Researchers Track,0,"In this paper we investigate the problem of adapting a machine translation system to the feedback provided by multiple post-editors. It is well know that translators might have very different post-editing styles and that this variability hinders the application of online learning methods, which indeed assume a homogeneous source of adaptation data. We hence propose multi-task learning to leverage bias information from each single post-editors in order to constrain the evolution of the SMT system. A new framework for significance testing with sentence level metrics is described which shows that Multi-Task learning approaches outperforms existing online learning approaches, with significant gains of 1.24 and 1.88 TER score over a strong online adaptive baseline, on a test set of post-edits produced by four translators texts and on a popular benchmark with multiple references, respectively."
2014.amta-researchers.13,The repetition rate of text as a predictor of the effectiveness of machine translation adaptation,2014,26,7,3,0.934473,10592,mauro cettolo,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: MT Researchers Track,0,"Since the effectiveness of MT adaptation relies on the text repetitiveness, the question on how to measure repetitions in a text naturally arises. This work deals with the issue of looking for and evaluating text features that might help the prediction of the impact of MT adaptation on translation quality. In particular, the repetition rate metric, we recently proposed, is compared to other features employed in very related NLP tasks. The comparison is carried out through a regression analysis between feature values and MT performance gains by dynamically adapted versus non-adapted MT engines, on five different translation tasks. The main outcome of experiments is that the repetition rate correlates better than any other considered feature with the MT gains yielded by the online adaptation, although using all features jointly results in better predictions than with any single feature."
2014.amta-researchers.20,Assessing the impact of speech recognition errors on machine translation quality,2014,-1,-1,2,0,40400,nicholas ruiz,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: MT Researchers Track,0,"In spoken language translation, it is crucial that an automatic speech recognition (ASR) system produces outputs that can be adequately translated by a statistical machine translation (SMT) system. While word error rate (WER) is the standard metric of ASR quality, the assumption that each ASR error type is weighted equally is violated in a SMT system that relies on structured input. In this paper, we outline a statistical framework for analyzing the impact of specific ASR error types on translation quality in a speech translation pipeline. Our approach is based on linear mixed-effects models, which allow the analysis of ASR errors on a translation quality metric. The mixed-effects models take into account the variability of ASR systems and the difficulty of each speech utterance being translated in a specific experimental setting. We use mixed-effects models to verify that the ASR errors that compose the WER metric do not contribute equally to translation quality and that interactions exist between ASR errors that cumulatively affect a SMT system{'}s ability to translate an utterance. Our experiments are carried out on the English to French language pair using eight ASR systems and seven post-edited machine translation references from the IWSLT 2013 evaluation campaign. We report significant findings that demonstrate differences in the contributions of specific ASR error types toward speech translation quality and suggest further error types that may contribute to translation difficulty."
W13-2231,Coping with the Subjectivity of Human Judgements in {MT} Quality Estimation,2013,28,21,3,0.199054,5084,marco turchi,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"Supervised approaches to NLP tasks rely on high-quality data annotations, which typically result from expensive manual labelling procedures. For some tasks, however, the subjectivity of human judgements might reduce the usefulness of the annotation for real-world applications. In Machine Translation (MT) Quality Estimation (QE), for instance, using humanannotated data to train a binary classifier that discriminates between good (useful for a post-editor) and bad translations is not trivial. Focusing on this binary task, we show that subjective human judgements can be effectively replaced with an automatic annotation procedure. To this aim, we compare binary classifiers trained on different data: the human-annotated dataset from the 7 th Workshop on Statistical Machine Translation (WMT-12), and an automatically labelled version of the same corpus. Our results show that human labels are less suitable for the task."
W13-2237,Online Learning Approaches in Computer Assisted Translation,2013,31,22,3,1,8880,prashant mathur,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"We present a novel online learning approach for statistical machine translation tailored to the computer assisted translation scenario. With the introduction of a simple online feature, we are able to adapt the translation model on the fly to the corrections made by the translators. Additionally, we do online adaption of the feature weights with a large margin algorithm. Our results show that our online adaptation technique outperforms the static phrase based statistical machine translation system by 6 BLEU points absolute, and a standard incremental adaptation approach by 2 BLEU points absolute."
W13-2257,Efficient Solutions for Word Reordering in {G}erman-{E}nglish Phrase-Based Statistical Machine Translation,2013,36,8,2,1,369,arianna bisazza,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"Despite being closely related languages, German and English are characterized by important word order differences. Longrange reordering of verbs, in particular, represents a real challenge for state-of-theart SMT systems and is one of the main reasons why translation quality is often so poor in this language pair. In this work, we review several solutions to improve the accuracy of German-English word reordering while preserving the efficiency of phrase-based decoding. Among these, we consider a novel technique to dynamically shape the reordering search space and effectively capture long-range reordering phenomena. Through an extensive evaluation including diverse translation quality metrics, we show that these solutions can significantly narrow the gap between phrase-based and hierarchical SMT."
Q13-1027,Dynamically Shaping the Reordering Search Space of Phrase-Based Statistical Machine Translation,2013,36,10,2,1,369,arianna bisazza,Transactions of the Association for Computational Linguistics,0,"Defining the reordering search space is a crucial issue in phrase-based SMT between distant languages. In fact, the optimal trade-off between accuracy and complexity of decoding is nowadays reached by harshly limiting the input permutation space. We propose a method to dynamically shape such space and, thus, capture long-range word movements without hurting translation quality nor decoding time. The space defined by loose reordering constraints is dynamically pruned through a binary classifier that predicts whether a given input word should be translated right after another. The integration of this model into a phrase-based decoder improves a strong Arabic-English baseline already including state-of-the-art early distortion cost (Moore and Quirk, 2007) and hierarchical phrase orientation models (Galley and Manning, 2008). Significant improvements in the reordering of verbs are achieved by a system that is notably faster than the baseline, while bleu and meteor remain stable, or even increase, at a very high distortion limit."
2013.mtsummit-wptp.13,Issues in incremental adaptation of statistical {MT} from human post-edits,2013,19,7,4,1,10592,mauro cettolo,Proceedings of the 2nd Workshop on Post-editing Technology and Practice,0,"This work investigates a crucial aspect for the integration of MT technology into a CAT environment, that is the ability of MT systems to adapt from the user feedback. In particular, we consider the scenario of an MT system tuned for a specific translation project that after each day of work adapts from the post-edited translations created by the user. We apply and compare different state-of-the-art adaptation methods on post-edited translations generated by two professionals during two days of work with a CAT tool embedding MT suggestions. Both translators worked at the same legal document from English into Italian and German, respectively. Although exactly the same amount of translations was available each day for each language , the application of the same adaptation methods resulted in quite different outcomes. This suggests that adaptation strategies should not be applied blindly, but rather taking into account language specific issues, such as data sparsity."
2013.mtsummit-papers.2,Generative and Discriminative Methods for Online Adaptation in {SMT},2013,-1,-1,5,0,36552,katharina waschle,Proceedings of Machine Translation Summit XIV: Papers,0,None
2013.mtsummit-papers.4,Project Adaptation for {MT}-Enhanced Computer Assisted Translation,2013,-1,-1,3,1,10592,mauro cettolo,Proceedings of Machine Translation Summit XIV: Papers,0,None
2013.mtsummit-papers.5,Cache-based Online Adaptation for Machine Translation Enhanced Computer Assisted Translation,2013,23,36,3,1,29503,nicola bertoldi,Proceedings of Machine Translation Summit XIV: Papers,0,None
2013.iwslt-evaluation.1,Report on the 10th {IWSLT} evaluation campaign,2013,-1,-1,5,1,10592,mauro cettolo,Proceedings of the 10th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"The paper overviews the tenth evaluation campaign organized by the IWSLT workshop. The 2013 evaluation offered multiple tracks on lecture transcription and translation based on the TED Talks corpus. In particular, this year IWSLT included two automatic speech recognition tracks, on English and German, three speech translation tracks, from English to French, English to German, and German to English, and three text translation track, also from English to French, English to German, and German to English. In addition to the official tracks, speech and text translation optional tracks were offered involving 12 other languages: Arabic, Spanish, Portuguese (B), Italian, Chinese, Polish, Persian, Slovenian, Turkish, Dutch, Romanian, Russian. Overall, 18 teams participated in the evaluation for a total of 217 primary runs submitted. All runs were evaluated with objective metrics on a current test set and two progress test sets, in order to compare the progresses against systems of the previous years. In addition, submissions of one of the official machine translation tracks were also evaluated with human post-editing."
2013.iwslt-evaluation.16,{EU}-{BRIDGE} {MT}: text translation of talks in the {EU}-{BRIDGE} project,2013,52,8,15,0.540541,3519,markus freitag,Proceedings of the 10th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"EU-BRIDGE1 is a European research project which is aimed at developing innovative speech translation technology. This paper describes one of the collaborative efforts within EUBRIDGE to further advance the state of the art in machine translation between two European language pairs, EnglishâFrench and GermanâEnglish. Four research institutions involved in the EU-BRIDGE project combined their individual machine translation systems and participated with a joint setup in the machine translation track of the evaluation campaign at the 2013 International Workshop on Spoken Language Translation (IWSLT). We present the methods and techniques to achieve high translation quality for text translation of talks which are applied at RWTH Aachen University, the University of Edinburgh, Karlsruhe Institute of Technology, and Fondazione Bruno Kessler. We then show how we have been able to considerably boost translation performance (as measured in terms of the metrics BLEU and TER) by means of system combination. The joint setups yield empirical gains of up to 1.4 points in BLEU and 2.8 points in TER on the IWSLT test sets compared to the best single systems."
2013.iwslt-evaluation.20,{FBK}{'}s machine translation systems for the {IWSLT} 2013 evaluation campaign,2013,-1,-1,5,1,29503,nicola bertoldi,Proceedings of the 10th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the systems submitted by FBK for the MT track of IWSLT 2013. We participated in the English-French as well as the bidirectional Persian-English translation tasks. We report substantial improvements in our English-French systems over last year{'}s baselines, largely due to improved techniques of combining translation and language models. For our Persian-English and English-Persian systems, we observe substantive improvements over baselines submitted by the workshop organizers, due to enhanced language-specific text normalization and the creation of a large monolingual news corpus in Persian."
W12-3122,Match without a Referee: Evaluating {MT} Adequacy without Reference Translations,2012,24,31,3,0.833333,3127,yashar mehdad,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"We address two challenges for automatic machine translation evaluation: a) avoiding the use of reference translations, and b) focusing on adequacy estimation. From an economic perspective, getting rid of costly hand-crafted reference translations (a) permits to alleviate the main bottleneck in MT evaluation. From a system evaluation perspective, pushing semantics into MT (b) is a necessity in order to complement the shallow methods currently used overcoming their limitations. Casting the problem as a cross-lingual textual entailment application, we experiment with different benchmarks and evaluation settings. Our method shows high correlation with human judgements and good results on all datasets without relying on reference translations."
W12-3155,Evaluating the Learning Curve of Domain Adaptive Statistical Machine Translation Systems,2012,9,6,3,1,29503,nicola bertoldi,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"The new frontier of computer assisted translation technology is the effective integration of statistical MT within the translation workflow. In this respect, the SMT ability of incrementally learning from the translations produced by users plays a central role. A still open problem is the evaluation of SMT systems that evolve over time. In this paper, we propose a new metric for assessing the quality of an adaptive MT component that is derived from the theory of learning curves: the percentage slope."
P12-2024,Detecting Semantic Equivalence and Information Disparity in Cross-lingual Documents,2012,17,14,3,0.833333,3127,yashar mehdad,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We address a core aspect of the multilingual content synchronization task: the identification of novel, more informative or semantically equivalent pieces of information in two documents about the same topic. This can be seen as an application-oriented variant of textual entailment recognition where: i) T and H are in different languages, and ii) entailment relations between T and H have to be checked in both directions. Using a combination of lexical, syntactic, and semantic features to train a cross-lingual textual entailment system, we report promising results on different datasets."
P12-1050,Modified Distortion Matrices for Phrase-Based Statistical Machine Translation,2012,32,6,2,1,369,arianna bisazza,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"This paper presents a novel method to suggest long word reorderings to a phrase-based SMT decoder. We address language pairs where long reordering concentrates on few patterns, and use fuzzy chunk-based rules to predict likely reorderings for these phenomena. Then we use reordered n-gram LMs to rank the resulting permutations and select the n-best for translation. Finally we encode these reorderings by modifying selected entries of the distortion cost matrix, on a per-sentence basis. In this way, we expand the search space by a much finer degree than if we simply raised the distortion limit. The proposed techniques are tested on Arabic-English and German-English using well-known SMT benchmarks."
federico-etal-2012-iwslt,The {IWSLT} 2011 Evaluation Campaign on Automatic Talk Translation,2012,18,30,1,1,3526,marcello federico,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We report here on the eighth evaluation campaign organized in 2011 by the IWSLT workshop series. That IWSLT 2011 evaluation focused on the automatic translation of public talks and included tracks for speech recognition, speech translation, text translation, and system combination. Unlike in previous years, all data supplied for the evaluation has been publicly released on the workshop website, and is at the disposal of researchers interested in working on our benchmarks and in comparing their results with those published at the workshop. This paper provides an overview of the IWSLT 2011 evaluation campaign, and describes the data supplied, the evaluation infrastructure made available to participants, and the subjective evaluation carried out."
E12-1045,Cutting the Long Tail: Hybrid Language Models for Translation Style Adaptation,2012,28,9,2,1,369,arianna bisazza,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"In this paper, we address statistical machine translation of public conference talks. Modeling the style of this genre can be very challenging given the shortage of available in-domain training data. We investigate the use of a hybrid LM, where infrequent words are mapped into classes. Hybrid LMs are used to complement word-based LMs with statistics about the language style of the talks. Extensive experiments comparing different settings of the hybrid LM are reported on publicly available benchmarks based on TED talks, from Arabic to English and from English to French. The proposed models show to better exploit in-domain data than conventional word-based LMs for the target language modeling component of a phrase-based statistical machine translation system."
2012.iwslt-papers.14,{MDI} adaptation for the lazy: avoiding normalization in {LM} adaptation for lecture translation,2012,21,4,2,1,43824,nick ruiz,Proceedings of the 9th International Workshop on Spoken Language Translation: Papers,0,"This paper provides a fast alternative to Minimum Discrimination Information-based language model adaptation for statistical machine translation. We provide an alternative to computing a normalization term that requires computing full model probabilities (including back-off probabilities) for all n-grams. Rather than re-estimating an entire language model, our Lazy MDI approach leverages a smoothed unigram ratio between an adaptation text and the background language model to scale only the n-gram probabilities corresponding to translation options gathered by the SMT decoder. The effects of the unigram ratio are scaled by adding an additional feature weight to the log-linear discriminative model. We present results on the IWSLT 2012 TED talk translation task and show that Lazy MDI provides comparable language model adaptation performance to classic MDI."
2012.eamt-1.56,Crowd-based {MT} Evaluation for non-{E}nglish Target Languages,2012,-1,-1,4,0,12388,michael paul,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,None
2012.eamt-1.60,{WIT}3: Web Inventory of Transcribed and Translated Talks,2012,15,320,3,1,10592,mauro cettolo,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"We describe here a Web inventory named WIT 3 that offers access to a collection of transcribed and translated talks. The core of WIT 3 is the TED Talks corpus, that basically redistributes the original content published by the TED Conference website (http://www.ted.com). Since 2007, the TED Conference, based in California, has been posting all video recordings of its talks together with subtitles in English and their translations in more than 80 languages. Aside from its cultural and social relevance, this content, which is published under the Creative Commons BYNC-ND license, also represents a precious language resource for the machine translation research community, thanks to its size, variety of topics, and covered languages. This effort repurposes the original content in a way which is more convenient for machine translation researchers."
2012.amta-tutorials.6,Practical Domain Adaptation in {SMT},2012,-1,-1,1,1,3526,marcello federico,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Tutorials,0,"Several studies have recently reported significant productivity gains by human translators when besides translation memory (TM) matches they do also receive suggestions from a statistical machine translation (SMT) engine. In fact, an increasing number of language service providers and in-house translation services of large companies is nowadays integrating SMT in their workflow. The technology transfer of state-of-the-art SMT technology from research to industry has been relatively fast and simple also thanks to development of open source software, such as MOSES, GIZA++, and IRSTLM. While a translator is working on a specific translation project, she evaluates the utility of translating versus post-editing a segment based on the adequacy and fluency provided by the SMT engine, which in turn depends on the considered language pair, linguistic domain of the task, and the amount of available training data. Statistical models, like those employed in SMT, rely on a simple assumption: data used to train and tune the models represent the target translation task. Unfortunately, this assumption cannot be satisfied for most of the real application cases, simply because for most of the language pairs and domains there is no sufficient data to adequately train an SMT system. Hence, common practice is to train SMT systems by merging together parallel and monolingual data from the target domain with as much as possible data from any other available source. This workaround is simple and gives practical benefits but is often not the best way to exploit the available data. This tutorial copes with the optimal use of in-domain and out-of-domain data to achieve better SMT performance on a given application domain. Domain adaptation, in general, refers to statistical modeling and machine learning techniques that try to cope with the unavoidable mismatch between training and task data that typically occurs in real life applications. Our tutorial will survey several application cases in which domain adaptation can be applied, and presents adaptation techniques that best fit each case. In particular, we will cover adaptation methods for n-gram language models and translation models in phrase-based SMT. The tutorial will provide some high-level theoretical background in domain adaptation, it will discuss practical application cases, and finally show how the presented methods can be applied with two widely used software tools: Moses and IRSTLM. The tutorial is suited for any practitioner of statistical machine translation. No particular programming or mathematical background is required."
2012.amta-papers.22,Measuring User Productivity in Machine Translation Enhanced Computer Assisted Translation,2012,-1,-1,1,1,3526,marcello federico,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"This paper addresses the problem of reliably measuring productivity gains by professional translators working with a machine translation enhanced computer assisted translation tool. In particular, we report on a field test we carried out with a commercial CAT tool in which translation memory matches were supplemented with suggestions from a commercial machine translation engine. The field test was conducted with 12 professional translators working on real translation projects. Productivity of translators were measured with two indicators, post-editing speed and post-editing effort, on two translation directions, English{--}Italian and English{--}German, and two linguistic domains, legal and information technology. Besides a detailed statistical analysis of the experimental results, we also discuss issues encountered in running the test."
W11-2133,Topic Adaptation for Lecture Translation through Bilingual Latent Semantic Models,2011,46,15,2,1,43824,nick ruiz,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"This work presents a simplified approach to bilingual topic modeling for language model adaptation by combining text in the source and target language into very short documents and performing Probabilistic Latent Semantic Analysis (PLSA) during model training. During inference, documents containing only the source language can be used to infer a full topic-word distribution on all words in the target language's vocabulary, from which we perform Minimum Discrimination Information (MDI) adaptation on a background language model (LM). We apply our approach on the English-French IWSLT 2010 TED Talk exercise, and report a 15% reduction in perplexity and relative BLEU and NIST improvements of 3% and 2.4%, respectively over a baseline only using a 5-gram background LM over the entire translation task. Our topic modeling approach is simpler to construct than its counterparts."
W11-2144,The {U}ppsala-{FBK} systems at {WMT} 2011,2011,17,5,4,1,670,christian hardmeier,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"This paper presents our submissions to the shared translation task at WMT 2011. We created two largely independent systems for English-to-French and Haitian Creole-to-English translation to evaluate different features and components from our ongoing research on these language pairs. Key features of our systems include anaphora resolution, hierarchical lexical reordering, data selection for language modelling, linear transduction grammars for word alignment and syntax-based decoding with monolingual dependency information."
P11-1134,Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment,2011,29,44,3,0.833333,3127,yashar mehdad,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"This paper explores the use of bilingual parallel corpora as a source of lexical knowledge for cross-lingual textual entailment. We claim that, in spite of the inherent difficulties of the task, phrase tables extracted from parallel data allow to capture both lexical relations between single words, and contextual information useful for inference. We experiment with a phrasal matching method in order to: i) build a system portable across languages, and ii) evaluate the contribution of lexical knowledge in isolation, without interaction with other inference mechanisms. Results achieved on an English-Spanish corpus obtained from the RTE3 dataset support our claim, with an overall accuracy above average scores reported by RTE participants on monolingual data. Finally, we show that using parallel corpora to extract paraphrase tables reveals their potential also in the monolingual setting, improving the results achieved with other sources of lexical knowledge."
J11-2009,Book Review: Cross-Language Information Retrieval by Jian-Yun Nie,2011,-1,-1,1,1,3526,marcello federico,Computational Linguistics,0,None
2011.mtsummit-papers.1,Methods for Smoothing the Optimizer Instability in {SMT},2011,-1,-1,3,1,10592,mauro cettolo,Proceedings of Machine Translation Summit XIII: Papers,0,None
2011.mtsummit-papers.59,Getting Expert Quality from the Crowd for Machine Translation Evaluation,2011,-1,-1,2,0.627305,8246,luisa bentivogli,Proceedings of Machine Translation Summit XIII: Papers,0,None
2011.iwslt-evaluation.1,Overview of the {IWSLT} 2011 evaluation campaign,2011,25,52,1,1,3526,marcello federico,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"We report here on the eighth Evaluation Campaign organized by the IWSLT workshop. This year, the IWSLT evaluation focused on the automatic translation of public talks and included tracks for speech recognition, speech translation, text translation, and system combination. Unlike previous years, all data supplied for the evaluation has been publicly released on the workshop website, and is at the disposal of researchers interested in working on our benchmarks and in comparing their results with those published at the workshop. This paper provides an overview of the IWSLT 2011 Evaluation Campaign, which includes: descriptions of the supplied data and evaluation specifications of each track, the list of participants specifying their submitted runs, a detailed description of the subjective evaluation carried out, the main findings of each exercise drawn from the results and the system descriptions prepared by the participants, and, finally, several detailed tables reporting all the evaluation results."
2011.iwslt-evaluation.18,Fill-up versus interpolation methods for phrase-based {SMT} adaptation,2011,21,74,3,1,369,arianna bisazza,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper compares techniques to combine diverse parallel corpora for domain-specific phrase-based SMT system training. We address a common scenario where little in-domain data is available for the task, but where large background models exist for the same language pair. In particular, we focus on phrase table fill-up: a method that effectively exploits background knowledge to improve model coverage, while preserving the more reliable information coming from the in-domain corpus. We present experiments on an emerging transcribed speech translation task {--} the TED talks. While performing similarly in terms of BLEU and NIST scores to the popular log-linear and linear interpolation techniques, filled-up translation models are more compact and easy to tune by minimum error training."
2011.iwslt-evaluation.24,Left language model state for syntactic machine translation,2011,15,13,5,0,10335,kenneth heafield,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"Many syntactic machine translation decoders, including Moses, cdec, and Joshua, implement bottom-up dynamic programming to integrate N-gram language model probabilities into hypothesis scoring. These decoders concatenate hypotheses according to grammar rules, yielding larger hypotheses and eventually complete translations. When hypotheses are concatenated, the language model score is adjusted to account for boundary-crossing n-grams. Words on the boundary of each hypothesis are encoded in state, consisting of left state (the first few words) and right state (the last few words). We speed concatenation by encoding left state using data structure pointers in lieu of vocabulary indices and by avoiding unnecessary queries. To increase the decoder{'}s opportunities to recombine hypothesis, we minimize the number of words encoded by left state. This has the effect of reducing search errors made by the decoder. The resulting gain in model score is smaller than for right state minimization, which we explain by observing a relationship between state minimization and language model probability. With a fixed cube pruning pop limit, we show a 3-6{\%} reduction in CPU time and improved model scores. Reducing the pop limit to the point where model scores tie the baseline yields a net 11{\%} reduction in CPU time."
2011.eamt-1.34,Bootstrapping {A}rabic-{I}talian {SMT} through Comparable Texts and Pivot Translation,2011,14,6,3,1,10592,mauro cettolo,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"This paper describes efforts towards the development of an Arabic to Italian SMT system for the news domain. Since only very little parallel data are available for this language pair, we investigated both the exploitation of comparable corpora and pivot translation. Experimental evaluation was conducted on a new benchmark developed by extending two Arabic-to-English NIST evaluation sets. Preliminary results show potentials of both approaches with respect to performance achieved by a popular state-of-the-art Web-based translation service."
W10-1710,{FBK} at {WMT} 2010: Word Lattices for Morphological Reduction and Chunk-Based Reordering,2010,10,16,3,1,670,christian hardmeier,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"FBK participated in the WMT 2010 Machine Translation shared task with phrase-based Statistical Machine Translation systems based on the Moses decoder for English-German and German-English translation. Our work concentrates on exploiting the available language modelling resources by using linear mixtures of large 6-gram language models and on addressing linguistic differences between English and German with methods based on word lattices. In particular, we use lattices to integrate a morphological analyser for German into our system, and we present some initial work on rule-based word reordering."
W10-1735,Chunk-Based Verb Reordering in {VSO} Sentences for {A}rabic-{E}nglish Statistical Machine Translation,2010,17,15,2,1,369,arianna bisazza,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"In Arabic-to-English phrase-based statistical machine translation, a large number of syntactic disfluencies are due to wrong long-range reordering of the verb in VSO sentences, where the verb is anticipated with respect to the English word order. In this paper, we propose a chunk-based reordering technique to automatically detect and displace clause-initial verbs in the Arabic side of a word-aligned parallel corpus. This method is applied to preprocess the training data, and to collect statistics about verb movements. From this analysis, specific verb reordering lattices are then built on the test sentences before decoding them. The application of our reordering methods on the training and test sets results in consistent BLEU score improvements on the NIST-MT 2009 Arabic-English benchmark."
N10-1045,Towards Cross-Lingual Textual Entailment,2010,9,53,3,0.740741,3127,yashar mehdad,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"This paper investigates cross-lingual textual entailment as a semantic relation between two text portions in different languages, and proposes a prospective research direction. We argue that cross-lingual textual entailment (CLTE) can be a core technology for several cross-lingual NLP applications and tasks. Through preliminary experiments, we aim at proving the feasibility of the task, and providing a reliable baseline. We also introduce new applications for CLTE that will be explored in future work."
N10-1064,Statistical Machine Translation of Texts with Misspelled Words,2010,18,20,3,1,29503,nicola bertoldi,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,This paper investigates the impact of misspelled words in statistical machine translation and proposes an extension of the translation engine for handling misspellings. The enhanced system decodes a word-based confusion network representing spelling variations of the input text.n n We present extensive experimental results on two translation tasks of increasing complexity which show how misspellings of different types do affect performance of a statistical machine translation decoder and to what extent our enhanced system is able to recover from such errors.
2010.iwslt-papers.3,Mining parallel fragments from comparable texts,2010,11,24,2,1,10592,mauro cettolo,Proceedings of the 7th International Workshop on Spoken Language Translation: Papers,0,"This paper proposes a novel method for exploiting comparable documents to generate parallel data for machine translation. First, each source document is paired to each sentence of the corresponding target document; second, partial phrase alignments are computed within the paired texts; finally, fragment pairs across linked phrase-pairs are extracted. The algorithm has been tested on two recent challenging news translation tasks. Results show that mining for parallel fragments is more effective than mining for parallel sentences, and that comparable in-domain texts can be more valuable than parallel out-of-domain texts."
2010.iwslt-papers.10,Modelling pronominal anaphora in statistical machine translation,2010,15,73,2,1,670,christian hardmeier,Proceedings of the 7th International Workshop on Spoken Language Translation: Papers,0,"Current Statistical Machine Translation (SMT) systems translate texts sentence by sentence without considering any cross-sentential context. Assuming independence between sentences makes it difficult to take certain translation decisions when the necessary information cannot be determined locally. We argue for the necessity to include crosssentence dependencies in SMT. As a case in point, we study the problem of pronominal anaphora translation by manually evaluating German-English SMT output. We then present a word dependency model for SMT, which can represent links between word pairs in the same or in different sentences. We use this model to integrate the output of a coreference resolution system into English-German SMT with a view to improving the translation of anaphoric pronouns."
2010.iwslt-evaluation.1,Overview of the {IWSLT} 2010 evaluation campaign,2010,0,64,2,0,12388,michael paul,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper gives an overview of the evaluation campaign results of the 7th International Workshop on Spoken Language Translation (IWSLT 2010)1. This year, we focused on three spoken language tasks: (1) public speeches on a variety of topics (TALK) from English to French, (2) spoken dialog in travel situations (DIALOG) between Chinese and English, and (3) traveling expressions (BTEC) from Arabic, Turkish, and French to English. In total, 28 teams (including 7 firsttime participants) took part in the shared tasks, submitting 60 primary and 112 contrastive runs. Automatic and subjective evaluations of the primary runs were carried out in order to investigate the impact of different communication modalities, spoken language styles and semantic context on automatic speech recognition (ASR) and machine translation (MT) system performances."
2010.iwslt-evaluation.5,{FBK} @ {IWSLT} 2010,2010,8,4,4,1,369,arianna bisazza,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This year FBK took part in the BTEC translation task, with source languages Arabic and Turkish and target language English, and in the new TALK task, source English and target French. We worked in the framework of phrase-based statistical machine translation aiming to improve coverage of models in presence of rich morphology, on one side, and to make better use of available resources through data selection techniques. New morphological segmentation rules were developed for Turkish-English. The combination of several Turkish segmentation schemes into a lattice input led to an improvement wrt to last year. The use of additional training data was explored for Arabic-English, while on the English to French task improvement was achieved over a strong baseline by automatically selecting relevant and high quality data from the available training corpora."
W09-0432,Domain Adaptation for Statistical Machine Translation with Monolingual Resources,2009,15,124,2,1,29503,nicola bertoldi,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,"Domain adaptation has recently gained interest in statistical machine translation to cope with the performance drop observed when testing conditions deviate from training conditions. The basic idea is that in-domain training data can be exploited to adapt all components of an already developed system. Previous work showed small performance gains by adapting from limited in-domain bilingual data. Here, we aim instead at significant performance gains by exploiting large but cheap monolingual in-domain data, either in the source or in the target language. We propose to synthesize a bilingual corpus by translating the monolingual adaptation data into the counterpart language. Investigations were conducted on a state-of-the-art phrase-based system trained on the Spanish--English part of the UN corpus, and adapted on the corresponding Europarl data. Translation, re-ordering, and language models were estimated after translating in-domain texts with the baseline. By optimizing the interpolation of these models on a development set the BLEU score was improved from 22.60% to 28.10% on a test set."
2009.iwslt-papers.1,Morphological pre-processing for {T}urkish to {E}nglish statistical machine translation,2009,11,32,2,1,369,arianna bisazza,Proceedings of the 6th International Workshop on Spoken Language Translation: Papers,0,"We tried to cope with the complex morphology of Turkish by applying different schemes of morphological word segmentation to the training and test data of a phrase-based statistical machine translation system. These techniques allow for a considerable reduction of the training dictionary, and lower the out-of-vocabulary rate of the test set. By minimizing differences between lexical granularities of Turkish and English we can produce more refined alignments and a better modeling of the translation task. Morphological segmentation is highly language dependent and requires a fair amount of linguistic knowledge in its development phase. Yet it is fast and light-weight {--} does not involve syntax {--} and appears to benefit our IWSLT09 system: our best segmentation scheme associated to a simple lexical approximation technique achieved a 50{\%} reduction of out-of-vocabulary rate and over 5 point BLEU improvement above the baseline."
2009.iwslt-papers.5,Online language model adaptation for spoken dialog translation,2009,16,8,4,0,23855,german sanchistrilles,Proceedings of the 6th International Workshop on Spoken Language Translation: Papers,0,"This paper focuses on the problem of language model adaptation in the context of Chinese-English cross-lingual dialogs, as set-up by the challenge task of the IWSLT 2009 Evaluation Campaign. Mixtures of n-gram language models are investigated, which are obtained by clustering bilingual training data according to different available human annotations, respectively, at the dialog level, turn level, and dialog act level. For the latter case, clustering of IWSLT data was in fact induced through a comparable Italian-English parallel corpus provided with dialog act annotations. For the sake of adaptation, mixture weight estimation is performed either at the level of single source sentence or test set. Estimated weights are then transferred to the target language mixture model. Experimental results show that, by training different specific language models weighted according to the actual input instead of using a single target language model, significant gains in terms of perplexity and BLEU can be achieved."
2009.iwslt-evaluation.5,FBK at IWSLT 2009,2009,16,3,5,1,29503,nicola bertoldi,Proceedings of the 6th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper reports on the participation of FBK at the IWSLT 2009 Evaluation. This year we worked on the Arabic-English and Turkish-English BTEC tasks with a special effort on linguistic preprocessing techniques involving morphological segmentation. In addition, we investigated the adaptation problem in the development of systems for the Chinese-English and English-Chinese challenge tasks; in particular, we explored different ways for clustering training data into topic or dialog-specific subsets: by producing (and combining) smaller but more focused models, we intended to make better use of the available training data, with the ultimate purpose of improving translation quality."
2008.iwslt-papers.1,Phrase-based statistical machine translation with pivot languages.,2008,20,50,3,1,29503,nicola bertoldi,Proceedings of the 5th International Workshop on Spoken Language Translation: Papers,0,"Translation with pivot languages has recently gained attention as a means to circumvent the data bottleneck of statistical machine translation (SMT). This paper tries to give a mathematically sound formulation of the various approaches presented in the literature and introduces new methods for training alignment models through pivot languages. We present experimental results on Chinese-Spanish translation via English, on a popular traveling domain task. In contrast to previous literature, we report experimental results by using parallel corpora that are either disjoint or overlapped on the pivot language side. Finally, our original method for generating training data through random sampling shows to perform as well as the best methods based on the coupling of translation systems."
2008.iwslt-evaluation.4,{FBK} @ {IWSLT}-2008.,2008,6,4,3,1,29503,nicola bertoldi,Proceedings of the 5th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper reports on the participation of FBK at the IWSLT 2008 Evaluation. Main effort has been spent on the Chinese-Spanish Pivot task. We implemented four methods to perform pivot translation. The results on the IWSLT 2008 test data show that our original method for generating training data through random sampling outperforms the best methods based on coupling translation systems. FBK also participated in the Chinese-English Challenge task and the Chinese-English and Chinese-Spanish BTEC tasks, employing the standard state-of-the-art MT system Moses Toolkit."
2008.amta-papers.3,Shallow-Syntax Phrase-Based Translation: Joint versus Factored String-to-Chunk Models,2008,-1,-1,2,1,10592,mauro cettolo,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"This work extends phrase-based statistical MT (SMT) with shallow syntax dependencies. Two string-to-chunks translation models are proposed: a factored model, which augments phrase-based SMT with layered dependencies, and a joint model, that extends the phrase translation table with microtags, i.e. per-word projections of chunk labels. Both rely on n-gram models of target sequences with different granularity: single words, micro-tags, chunks. In particular, n-grams defined over syntactic chunks should model syntactic constraints coping with word-group movements. Experimental analysis and evaluation conducted on two popular Chinese-English tasks suggest that the shallow-syntax joint-translation model has potential to outperform state-of-the-art phrase-based translation, with a reasonable computational overhead."
W07-0712,Efficient Handling of N-gram Language Models for Statistical Machine Translation,2007,9,70,1,1,3526,marcello federico,Proceedings of the Second Workshop on Statistical Machine Translation,0,"Statistical machine translation, as well as other areas of human language processing, have recently pushed toward the use of large scale n-gram language models. This paper presents efficient algorithmic and architectural solutions which have been tested within the Moses decoder, an open source toolkit for statistical machine translation. Experiments are reported with a high performing baseline, trained on the Chinese-English NIST 2006 Evaluation task and running on a standard Linux 64-bit PC architecture. Comparative tests show that our representation halves the memory required by SRI LM Toolkit, at the cost of 44% slower translation speed. However, as it can take advantage of memory mapping on disk, the proposed implementation seems to scale-up much better to very large language models: decoding with a 289-million 5-gram language model runs in 2.1Gb of RAM."
P07-2045,{M}oses: Open Source Toolkit for Statistical Machine Translation,2007,13,3819,5,0.0286043,4417,philipp koehn,Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,0,"We describe an open-source toolkit for statistical machine translation whose novel contributions are (a) support for linguistically motivated factors, (b) confusion network decoding, and (c) efficient data formats for translation models and language models. In addition to the SMT decoder, the toolkit also includes a wide variety of tools for training, tuning and applying the system to many translation tasks."
2007.mtsummit-papers.15,Better n-best translations through generative n-gram language models,2007,-1,-1,2,1,4084,boxing chen,Proceedings of Machine Translation Summit XI: Papers,0,None
2007.mtsummit-papers.28,{POS}-based reordering models for statistical machine translation,2007,21,7,3,1,49423,deepa gupta,Proceedings of Machine Translation Summit XI: Papers,0,"We present a novel word reordering model for phrase-based statistical machine translation suited to cope with long-span word movements. In particular, reordering of nouns, verbs and adjectives is modeled by taking into account target-to-source word alignments and the distances between source as well as target words. The proposed model was applied as a set of additional feature functions to re-score N-best translation candidates generated by a statistical machine translation system featuring state-of-the-art lexicalized reordering models. Experiments showed relative BLEU score improvement up to 7.3% on the BTEC Japanese-to-English task, and up to 1.1% on the Europarl German-to-English task."
2007.iwslt-1.11,{FBK}@{IWSLT} 2007,2007,9,3,4,1,29503,nicola bertoldi,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"This paper reports on the participation of FBK (formerly ITC-irst) at the IWSLT 2007 Evaluation. FBK participated in three tasks, namely Chinese-to-English, Japanese-to-English, and Italian-to-English. With respect to last year, translation systems were developed with the Moses Toolkit and the IRSTLM library, both available as open source software. Moreover, several novel ideas were investigated: the use of confusion networks in input to manage ambiguity in punctuation, the estimation of an additional language model by means of the Google{'}s Web 1T 5-gram collection, the combination of true case and lower case language models, and finally the use of multiple phrase-tables. By working on top of a state-of-the art baseline, experiments showed that the above methods accounted for significant BLEU score improvements."
W06-3101,Morpho-syntactic Information for Automatic Error Analysis of Statistical Machine Translation Output,2006,16,33,7,0,5059,maja popovic,Proceedings on the Workshop on Statistical Machine Translation,0,"Evaluation of machine translation output is an important but difficult task. Over the last years, a variety of automatic evaluation measures have been studied, some of them like Word Error Rate (WER), Position Independent Word Error Rate (PER) and BLEU and NIST scores have become widely used tools for comparing different systems as well as for evaluating improvements within one system. However, these measures do not give any details about the nature of translation errors. Therefore some analysis of the generated output is needed in order to identify the main problems and to focus the research efforts. On the other hand, human evaluation is a time consuming and expensive task. In this paper, we investigate methods for using of morpho-syntactic information for automatic evaluation: standard error measures WER and PER are calculated on distinct word classes and forms in order to get a better idea about the nature of translation errors and possibilities for improvements."
W06-3113,How Many Bits Are Needed To Store Probabilities for Phrase-Based Translation?,2006,10,22,1,1,3526,marcello federico,Proceedings on the Workshop on Statistical Machine Translation,0,"State of the art in statistical machine translation is currently represented by phrase-based models, which typically incorporate a large number of probabilities of phrase-pairs and word n-grams. In this work, we investigate data compression methods for efficiently encoding n-gram and phrase-pair probabilities, that are usually encoded in 32-bit floating point numbers. We measured the impact of compression on translation quality through a phrase-based decoder trained on two distinct tasks: the translation of European Parliament speeches from Spanish to English, and the translation of news agencies from Chinese to English. We show that with a very simple quantization scheme all probabilities can be encoded in just 4 bits with a relative loss in BLEU score on the two tasks by 1.0% and 1.6%, respectively."
W06-2601,Maximum Entropy Tagging with Binary and Real-Valued Features,2006,8,0,2,0,49693,vanessa sandrini,Proceedings of the Workshop on Learning Structured Information in Natural Language Applications,0,None
E06-2002,A Web-based Demonstrator of a Multi-lingual Phrase-based Translation System,2006,10,3,5,1,5711,roldano cattoni,Demonstrations,0,"This paper describes a multi-lingual phrase-based Statistical Machine Translation system accessible by means of a Web page. The user can issue translation requests from Arabic, Chinese or Spanish into English. The same phrase-based statistical technology is employed to realize the three supported language-pairs. New language-pairs can be easily added to the demonstrator. The Web-based interface allows the use of the translation system to any computer connected to the Internet."
2006.iwslt-papers.4,Reordering rules for phrase-based statistical machine translation,2006,20,22,3,1,4084,boxing chen,Proceedings of the Third International Workshop on Spoken Language Translation: Papers,0,"This paper proposes the use of rules automatically extracted from word aligned training data to model word reordering phenomena in phrase-based statistical machine translation. Scores computed from matching rules are used as additional feature functions in the rescoring stage of the automatic translation process from various languages to English, in the ambit of a popular traveling domain task. Rules are defined either on Part-of-Speech or words. Part-ofSpeech rules are extracted from and applied to Chinese, while lexicalized rules are extracted from and applied to Chinese, Japanese and Arabic. Both Part-of-Speech and lexicalized rules yield an absolute improvement of the BLEU score of 0.4-0.9 points without affecting the NIST score, on the Chinese-to-English translation task. On other language pairs which differ a lot in the word order, the use of lexicalized rules allows to observe significant improvements as well."
2006.iwslt-evaluation.7,The {ITC}-irst {SMT} system for {IWSLT} 2006,2006,7,10,5,1,4084,boxing chen,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper reports on the participation of ITC-irst to the evaluation campaign of the International Workshop on Spoken Language Translation 2006. Our two-pass system is the evolution of the one we employed for the 2005 campaign: in the first pass, an N-best list of translations is generated for each source sentence by means of a beam-search decoder; in the second pass, N-best lists are rescored and reranked exploiting additional feature functions. Main updates brought to the 2005 system involve novel additional features which are here described. Results on development sets are analyzed and commented."
2006.iwslt-evaluation.8,The {JHU} workshop 2006 {IWSLT} system,2006,10,17,4,0,34780,wade shen,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the SMT we built during the 2006 JHU Summer Workshop for the IWSLT 2006 evaluation. Our effort focuses on two parts of the speech translation problem: 1) efficient decoding of word lattices and 2) novel applications of factored translation models to IWSLT-specific problems. In this paper, we present results from the open-track Chinese-to-English condition. Improvements of 5-10% relative BLEU are obtained over a high performing baseline. We introduce a new open-source decoder that implements the state-of-the-art in statistical machine translation."
2006.eamt-1.10,Exploiting Word Transformation in Statistical Machine Translation from {S}panish to {E}nglish,2006,5,0,2,1,49423,deepa gupta,Proceedings of the 11th Annual conference of the European Association for Machine Translation,0,None
2005.iwslt-1.11,The {ITC}-irst {SMT} System for {IWSLT}-2005,2005,10,34,5,1,4084,boxing chen,Proceedings of the Second International Workshop on Spoken Language Translation,0,None
2004.iwslt-papers.2,Minimum error training of log-linear translation models,2004,13,17,2,1,10592,mauro cettolo,Proceedings of the First International Workshop on Spoken Language Translation: Papers,0,"Recent work on training of log-linear interpolation models for statistical machine translation reported performance improvements by optimizing parameters with respect to translation quality, rather than to likelihood oriented criteria. This work presents an alternative and more direct training procedure for log-linear interpolation models. In addition, we point out the subtle interaction between log-linear models and the beam search algorithm. Experimental results are reported on two Chinese-English evaluation sets, C-Star 2003 and Nist 2003, by using a statistical phrase-based model derived from Model 4. By optimizing parameters with respect to the BLUE score, performance relative improvements by 9.6% and 2.8% were achieved, respectively."
2004.iwslt-evaluation.1,Overview of the {IWSLT} evaluation campaign,2004,25,56,2,0,51985,yasuhiro akiba,Proceedings of the First International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper gives an overview of the evaluation campaign results of the IWSLT04 1 workshop, which is organized by the C-STAR 2 consortium to investigate novel speech translation technologies and their evaluation. The objectives of this workshop is to provide a framework for the applicability validation of existing machine translation evaluation methodologies to evaluate speech translation technologies. The workshop also strives to find new directions in how to improve current methods."
2004.iwslt-evaluation.8,The {ITC}-irst statistical machine translation system for {IWSLT}-,2004,20,19,4,1,29503,nicola bertoldi,Proceedings of the First International Workshop on Spoken Language Translation: Evaluation Campaign,0,"Focus of this paper is the system for statistical machine translation developed at ITC-irst. It has been employed in the evaluation campaign of the International Workshop on Spoken Language Translation 2004 in all the three data set conditions of the Chinese-English track. Both the statistical model underlying the system and the system architecture are presented. Moreover, details are given on how the submitted runs have been produced."
W02-1038,Bootstrapping Named Entity Recognition for {I}talian Broadcast News,2002,8,4,1,1,3526,marcello federico,Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing ({EMNLP} 2002),0,"This paper presents the development of a Named Entity (NE) recognition system for the Italian broadcast news domain. A statistical model is introduced based on a trigram language model defined on words and NE classes. The estimation of the NE model is carried out with a very little list of 2,360 manually tagged NEs and a large untagged newspaper corpus. An iterative training procedure is applied which goes through the estimation of simpler models, whose parameters are used to initialize the complete NE model. In the end, NE recognition experiments are reported, on broadcast news transcripts generated by a speech recognition system."
federico-etal-2000-development,Development and Evaluation of an {I}talian Broadcast News Corpus,2000,3,28,1,1,3526,marcello federico,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"This paper reports on the development and evaluation of an Italian broadcast news corpus at ITC-irst, under a contract with the European Language resources Distribution Agency (ELDA). The corpus consists of 30 hours of recordings transcribed and annotated with conventions similar to those adopted by the Linguistic Data Consortium for the DARPA HUB-4 corpora. The corpus will be completed and released to ELDA by April 2000."
