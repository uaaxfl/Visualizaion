2021.naacl-main.135,Mask Attention Networks: Rethinking and Strengthen Transformer,2021,-1,-1,4,1,3651,zhihao fan,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Transformer is an attention-based neural network, which consists of two sublayers, namely, Self-Attention Network (SAN) and Feed-Forward Network (FFN). Existing research explores to enhance the two sublayers separately to improve the capability of Transformer for text representation. In this paper, we present a novel understanding of SAN and FFN as Mask Attention Networks (MANs) and show that they are two special cases of MANs with static mask matrices. However, their static mask matrices limit the capability for localness modeling in text representation learning. We therefore introduce a new layer named dynamic mask attention network (DMAN) with a learnable mask matrix which is able to model localness adaptively. To incorporate advantages of DMAN, SAN, and FFN, we propose a sequential layered structure to combine the three types of layers. Extensive experiments on various tasks, including neural machine translation and text summarization demonstrate that our model outperforms the original Transformer."
2021.naacl-main.431,Discrete Argument Representation Learning for Interactive Argument Pair Identification,2021,-1,-1,2,0,4520,lu ji,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"In this paper, we focus on identifying interactive argument pairs from two posts with opposite stances to a certain topic. Considering opinions are exchanged from different perspectives of the discussing topic, we study the discrete representations for arguments to capture varying aspects in argumentation languages (e.g., the debate focus and the participant behavior). Moreover, we utilize hierarchical structure to model post-wise information incorporating contextual knowledge. Experimental results on the large-scale dataset collected from CMV show that our proposed framework can significantly outperform the competitive baselines. Further analyses reveal why our model yields superior performance and prove the usefulness of our learned representations."
2021.findings-emnlp.127,An Edge-Enhanced Hierarchical Graph-to-Tree Network for Math Word Problem Solving,2021,-1,-1,3,0,6745,qinzhuo wu,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Math word problem solving has attracted considerable research interest in recent years. Previous works have shown the effectiveness of utilizing graph neural networks to capture the relationships in the problem. However, these works did not carefully take the edge label information and the long-range word relationship across sentences into consideration. In addition, during generation, they focus on the most relevant areas of the currently generated word, while neglecting the rest of the problem. In this paper, we propose a novel Edge-Enhanced Hierarchical Graph-to-Tree model (EEH-G2T), in which the math word problems are represented as edge-labeled graphs. Specifically, an edge-enhanced hierarchical graph encoder is used to incorporate edge label information. This encoder updates the graph nodes hierarchically in two steps: sentence-level aggregation and problem-level aggregation. Furthermore, a tree-structured decoder with a split attention mechanism is applied to guide the model to pay attention to different parts of the input problem. Experimental results on the MAWPS and Math23K dataset showed that our EEH-G2T can effectively improve performance compared with state-of-the-art methods."
2021.findings-acl.121,{K-Adapter}: {I}nfusing {K}nowledge into {P}re-{T}rained {M}odels with {A}dapters,2021,-1,-1,4,1,7795,ruize wang,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.findings-acl.203,Leveraging Argumentation Knowledge Graph for Interactive Argument Pair Identification,2021,-1,-1,2,0,8005,jian yuan,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.emnlp-main.17,A Partition Filter Network for Joint Entity and Relation Extraction,2021,-1,-1,5,0,8662,zhiheng yan,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"In joint entity and relation extraction, existing work either sequentially encode task-specific features, leading to an imbalance in inter-task feature interaction where features extracted later have no direct contact with those that come first. Or they encode entity features and relation features in a parallel manner, meaning that feature representation learning for each task is largely independent of each other except for input sharing. We propose a partition filter network to model two-way interaction between tasks properly, where feature encoding is decomposed into two steps: partition and filter. In our encoder, we leverage two gates: entity and relation gate, to segment neurons into two task partitions and one shared partition. The shared partition represents inter-task information valuable to both tasks and is evenly shared across two tasks to ensure proper two-way interaction. The task partitions represent intra-task information and are formed through concerted efforts of both gates, making sure that encoding of task-specific features is dependent upon each other. Experiment results on six public datasets show that our model performs significantly better than previous approaches. In addition, contrary to what previous work has claimed, our auxiliary experiments suggest that relation prediction is contributory to named entity prediction in a non-negligible way. The source code can be found at https://github.com/Coopercoppers/PFN."
2021.emnlp-main.22,Learning Implicit Sentiment in Aspect-based Sentiment Analysis with Supervised Contrastive Pre-Training,2021,-1,-1,5,0,8678,zhengyan li,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Aspect-based sentiment analysis aims to identify the sentiment polarity of a specific aspect in product reviews. We notice that about 30{\%} of reviews do not contain obvious opinion words, but still convey clear human-aware sentiment orientation, which is known as implicit sentiment. However, recent neural network-based approaches paid little attention to implicit sentiment entailed in the reviews. To overcome this issue, we adopt Supervised Contrastive Pre-training on large-scale sentiment-annotated corpora retrieved from in-domain language resources. By aligning the representation of implicit sentiment expressions to those with the same sentiment label, the pre-training process leads to better capture of both implicit and explicit sentiment orientation towards aspects in reviews. Experimental results show that our method achieves state-of-the-art performance on SemEval2014 benchmarks, and comprehensive analysis validates its effectiveness on learning implicit sentiment."
2021.ccl-1.74,åºäºå¤è´¨å¿å¼è´¨å¾å­¦ä¹ çç¤¾äº¤ç½ç»ç¨æ·å»ºæ¨¡(User Representation Learning based on Multi-centroid Heterogeneous Graph Neural Networks),2021,-1,-1,6,0,11833,shangyi ning,Proceedings of the 20th Chinese National Conference on Computational Linguistics,0,"{``}ç¨æ·å»ºæ¨¡å·²ç»å¼èµ·äºå­¦æ¯çåå·¥ä¸ççå¹¿æ³å
³æ³¨ãç°æçæ¹æ³å¤§å¤ä¾§éäºå°ç¨æ·é´çäººé
å
³ç³»èå
¥ç¤¾åº,èç¨æ·çæçå
å®¹(å¦å¸å­)å´æ²¡æå¾å°å¾å¥½çç ç©¶ãå¨æ¬æä¸­,æä»¬éè¿å®é
èæ
ä¼ æ­ç¸å
³çåæè¡¨æ,å¨èæ
ä¼ æ­è¿ç¨ä¸­å¯¹ç¨æ·å±æ§è¿è¡ç ç©¶çéè¦ä½ç¨,å¹¶ä¸æåºäºç¨æ·èµææ°æ®çç­éæ¹æ³ãåæ¶,æä»¬æåºäºä¸ç§éè¿å¼æå¤è´¨å¿å¾æ± ä¸ºç¨æ·æè·æ´å¤ä¸åç¤¾åºç¹å¾çå»ºæ¨¡ãæä»¬é¦å
æé äºä¸ä¸ªç±ç¨æ·åå
³é®å­ç»æçå¼è´¨å¾,å¹¶å¨å
¶ä¸éç¨äºä¸ä¸ªå¼è´¨å¾ç¥ç»ç½ç»ãä¸ºäºæ¹ä¾¿ç¨æ·å»ºæ¨¡çå¾è¡¨ç¤º,æåºäºä¸ç§å¤è´¨å¿å¾æ± åæºå¶,å°å¤è´¨å¿çéç¾¤ç¹å¾èå
¥å°è¡¨ç¤ºå­¦ä¹ ä¸­ãå¨ä¸ä¸ªåºåæ°æ®éä¸çå¤§éå®éªè¡¨æäºè¯¥æ¹æ³çæææ§ã{''}"
2021.acl-long.99,Align Voting Behavior with Public Statements for Legislator Representation Learning,2021,-1,-1,2,0,12844,xinyi mou,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Ideology of legislators is typically estimated by ideal point models from historical records of votes. It represents legislators and legislation as points in a latent space and shows promising results for modeling voting behavior. However, it fails to capture more specific attitudes of legislators toward emerging issues and is unable to model newly-elected legislators without voting histories. In order to mitigate these two problems, we explore to incorporate both voting behavior and public statements on Twitter to jointly model legislators. In addition, we propose a novel task, namely hashtag usage prediction to model the ideology of legislators on Twitter. In practice, we construct a heterogeneous graph for the legislative context and use relational graph neural networks to learn the representation of legislators with the guidance of historical records of their voting and hashtag usage. Experiment results indicate that our model yields significant improvements for the task of roll call vote prediction. Further analysis further demonstrates that legislator representation we learned captures nuances in statements."
2021.acl-long.455,Math Word Problem Solving with Explicit Numerical Values,2021,-1,-1,3,0,6745,qinzhuo wu,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"In recent years, math word problem solving has received considerable attention and achieved promising results, but previous methods rarely take numerical values into consideration. Most methods treat the numerical values in the problems as number symbols, and ignore the prominent role of the numerical values in solving the problem. In this paper, we propose a novel approach called NumS2T, which enhances math word problem solving performance by explicitly incorporating numerical values into a sequence-to-tree network. In addition, a numerical properties prediction mechanism is used to capture the category and comparison information of numerals and measure their importance in global expressions. Experimental results on the Math23K and APE datasets demonstrate that our model achieves better performance than existing state-of-the-art models."
2021.acl-demo.41,{T}ext{F}lint: Unified Multilingual Robustness Evaluation Toolkit for Natural Language Processing,2021,-1,-1,32,0,13613,xiao wang,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations,0,"TextFlint is a multilingual robustness evaluation toolkit for NLP tasks that incorporates universal text transformation, task-specific transformation, adversarial attack, subpopulation, and their combinations to provide comprehensive robustness analyses. This enables practitioners to automatically evaluate their models from various aspects or to customize their evaluations as desired with just a few lines of code. TextFlint also generates complete analytical reports as well as targeted augmented data to address the shortcomings of the model in terms of its robustness. To guarantee acceptability, all the text transformations are linguistically based and all the transformed data selected (up to 100,000 texts) scored highly under human evaluation. To validate the utility, we performed large-scale empirical evaluations (over 67,000) on state-of-the-art deep learning models, classic supervised methods, and real-world systems. The toolkit is already available at https://github.com/textflint with all the evaluation results demonstrated at textflint.io."
2020.findings-emnlp.422,Automatic Term Name Generation for Gene Ontology: Task and Dataset,2020,-1,-1,4,0,19942,yanjian zhang,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"Terms contained in Gene Ontology (GO) have been widely used in biology and bio-medicine. Most previous research focuses on inferring new GO terms, while the term names that reflect the gene function are still named by the experts. To fill this gap, we propose a novel task, namely term name generation for GO, and build a large-scale benchmark dataset. Furthermore, we present a graph-based generative model that incorporates the relations between genes, words and terms for term name generation, which exhibits great advantages over the strong baselines."
2020.emnlp-main.320,Leveraging Declarative Knowledge in Text and First-Order Logic for Fine-Grained Propaganda Detection,2020,24,0,5,1,7795,ruize wang,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"We study the detection of propagandistic text fragments in news articles. Instead of merely learning from input-output datapoints in training data, we introduce an approach to inject declarative knowledge of fine-grained propaganda techniques. Specifically, we leverage the declarative knowledge expressed in both first-order logic and natural language. The former refers to the logical consistency between coarse- and fine-grained predictions, which is used to regularize the training process with propositional Boolean expressions. The latter refers to the literal definition of each propaganda technique, which is utilized to get class representations for regularizing the model parameters. We conduct experiments on Propaganda Techniques Corpus, a large manually annotated dataset for fine-grained propaganda detection. Experiments show that our method achieves superior performance, demonstrating that leveraging declarative knowledge can help the model to make more accurate predictions."
2020.emnlp-main.729,{P}ath{QG}: Neural Question Generation from Facts,2020,-1,-1,2,0,3655,siyuan wang,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Existing research for question generation encodes the input text as a sequence of tokens without explicitly modeling fact information. These models tend to generate irrelevant and uninformative questions. In this paper, we explore to incorporate facts in the text for question generation in a comprehensive way. We present a novel task of question generation given a query path in the knowledge graph constructed from the input text. We divide the task into two steps, namely, query representation learning and query-based question generation. We formulate query representation learning as a sequence labeling problem for identifying the involved facts to form a query and employ an RNN-based generator for question generation. We first train the two modules jointly in an end-to-end fashion, and further enforce the interaction between these two modules in a variational framework. We construct the experimental datasets on top of SQuAD and results show that our model outperforms other state-of-the-art approaches, and the performance margin is larger when target questions are complex. Human evaluation also proves that our model is able to generate relevant and informative questions."
2020.coling-main.182,An Enhanced Knowledge Injection Model for Commonsense Generation,2020,-1,-1,3,1,3651,zhihao fan,Proceedings of the 28th International Conference on Computational Linguistics,0,"Commonsense generation aims at generating plausible everyday scenario description based on a set of provided concepts. Digging the relationship of concepts from scratch is non-trivial, therefore, we retrieve prototypes from external knowledge to assist the understanding of the scenario for better description generation. We integrate two additional modules into the pretrained encoder-decoder model for prototype modeling to enhance the knowledge injection procedure. We conduct experiment on CommonGen benchmark, experimental results show that our method significantly improves the performance on all the metrics."
2020.coling-main.204,Keep it Consistent: Topic-Aware Storytelling from an Image Stream via Iterative Multi-agent Communication,2020,-1,-1,2,1,7795,ruize wang,Proceedings of the 28th International Conference on Computational Linguistics,0,"Visual storytelling aims to generate a narrative paragraph from a sequence of images automatically. Existing approaches construct text description independently for each image and roughly concatenate them as a story, which leads to the problem of generating semantically incoherent content. In this paper, we propose a new way for visual storytelling by introducing a topic description task to detect the global semantic context of an image stream. A story is then constructed with the guidance of the topic description. In order to combine the two generation tasks, we propose a multi-agent communication framework that regards the topic description generator and the story generator as two agents and learn them simultaneously via iterative updating mechanism. We validate our approach on VIST dataset, where quantitative results, ablations, and human evaluation demonstrate our method{'}s good ability in generating stories with higher quality compared to state-of-the-art methods."
2020.coling-main.561,Modeling Evolution of Message Interaction for Rumor Resolution,2020,-1,-1,2,0,4812,lei chen,Proceedings of the 28th International Conference on Computational Linguistics,0,"Previous work for rumor resolution concentrates on exploiting time-series characteristics or modeling topology structure separately. However, how local interactive pattern affects global information assemblage has not been explored. In this paper, we attempt to address the problem by learning evolution of message interaction. We model confrontation and reciprocity between message pairs via discrete variational autoencoders which effectively reflects the diversified opinion interactivity. Moreover, we capture the variation of message interaction using a hierarchical framework to better integrate information flow of a rumor cascade. Experiments on PHEME dataset demonstrate our proposed model achieves higher accuracy than existing methods."
2020.acl-main.528,Simplify the Usage of Lexicon in {C}hinese {NER},2020,-1,-1,4,0,9145,ruotian ma,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Recently, many works have tried to augment the performance of Chinese named entity recognition (NER) using word lexicons. As a representative, Lattice-LSTM has achieved new benchmark results on several public Chinese NER datasets. However, Lattice-LSTM has a complex model architecture. This limits its application in many industrial areas where real-time NER responses are needed. In this work, we propose a simple but effective method for incorporating the word lexicon into the character representations. This method avoids designing a complicated sequence modeling architecture, and for any neural NER model, it requires only subtle adjustment of the character representation layer to introduce the lexicon information. Experimental studies on four benchmark Chinese NER datasets show that our method achieves an inference speed up to 6.15 times faster than those of state-of-the-art methods, along with a better performance. The experimental results also show that the proposed method can be easily incorporated with pre-trained models like BERT."
P19-1652,Bridging by Word: Image Grounded Vocabulary Construction for Visual Captioning,2019,0,1,2,1,3651,zhihao fan,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Image Captioning aims at generating a short description for an image. Existing research usually employs the architecture of CNN-RNN that views the generation as a sequential decision-making process and the entire dataset vocabulary is used as decoding space. They suffer from generating high frequent n-gram with irrelevant words. To tackle this problem, we propose to construct an image-grounded vocabulary, based on which, captions are generated with limitation and guidance. In specific, a novel hierarchical structure is proposed to construct the vocabulary incorporating both visual information and relations among words. For generation, we propose a word-aware RNN cell incorporating vocabulary information into the decoding process directly. Reinforce algorithm is employed to train the generator using constraint vocabulary as action space. Experimental results on MS COCO and Flickr30k show the effectiveness of our framework compared to some state-of-the-art models."
D19-5514,"Extract, Transform and Filling: A Pipeline Model for Question Paraphrasing based on Template",2019,0,0,3,0,26568,yunfan gu,Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019),0,"Question paraphrasing aims to restate a given question with different expressions but keep the original meaning. Recent approaches are mostly based on neural networks following a sequence-to-sequence fashion, however, these models tend to generate unpredictable results. To overcome this drawback, we propose a pipeline model based on templates. It follows three steps, a) identifies template from the input question, b) retrieves candidate templates, c) fills candidate templates with original topic words. Experiment results on two self-constructed datasets show that our model outperforms the sequence-to-sequence model in a large margin and the advantage is more promising when the size of training sample is small."
D19-1096,A Lexicon-Based Graph Neural Network for {C}hinese {NER},2019,0,6,6,0.47619,8645,tao gui,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"Recurrent neural networks (RNN) used for Chinese named entity recognition (NER) that sequentially track character and word information have achieved great success. However, the characteristic of chain structure and the lack of global semantics determine that RNN-based models are vulnerable to word ambiguities. In this work, we try to alleviate this problem by introducing a lexicon-based graph neural network with global semantics, in which lexicon knowledge is used to connect characters to capture the local composition, while a global relay node can capture global sentence semantics and long-range dependency. Based on the multiple graph-based interactions among characters, potential words, and the whole-sentence semantics, word ambiguities can be effectively tackled. Experiments on four NER datasets show that the proposed model achieves significant improvements against other baseline models."
D19-1508,Enhancing Dialogue Symptom Diagnosis with Global Attention and Symptom Graph,2019,0,0,5,0,27084,xinzhu lin,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"Symptom diagnosis is a challenging yet profound problem in natural language processing. Most previous research focus on investigating the standard electronic medical records for symptom diagnosis, while the dialogues between doctors and patients that contain more rich information are not well studied. In this paper, we first construct a dialogue symptom diagnosis dataset based on an online medical forum with a large amount of dialogues between patients and doctors. Then, we provide some benchmark models on this dataset to boost the research of dialogue symptom diagnosis. In order to further enhance the performance of symptom diagnosis over dialogues, we propose a global attention mechanism to capture more symptom related information, and build a symptom graph to model the associations between symptoms rather than treating each symptom independently. Experimental results show that both the global attention and symptom graph are effective to boost dialogue symptom diagnosis. In particular, our proposed model achieves the state-of-the-art performance on the constructed dataset."
W18-5212,Incorporating Topic Aspects for Online Comment Convincingness Evaluation,2018,0,0,2,0,26568,yunfan gu,Proceedings of the 5th Workshop on Argument Mining,0,"In this paper, we propose to incorporate topic aspects information for online comments convincingness evaluation. Our model makes use of graph convolutional network to utilize implicit topic information within a discussion thread to assist the evaluation of convincingness of each single comment. In order to test the effectiveness of our proposed model, we annotate topic information on top of a public dataset for argument convincingness evaluation. Experimental results show that topic information is able to improve the performance for convincingness evaluation. We also make a move to detect topic aspects automatically."
P18-2033,Task-oriented Dialogue System for Automatic Diagnosis,2018,0,14,1,1,3654,zhongyu wei,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"In this paper, we make a move to build a dialogue system for automatic diagnosis. We first build a dataset collected from an online medical forum by extracting symptoms from both patients{'} self-reports and conversational data between patients and doctors. Then we propose a task-oriented dialogue system framework to make diagnosis for patients automatically, which can converse with patients to collect additional symptoms beyond their self-reports. Experimental results on our dataset show that additional symptoms extracted from conversation can greatly improve the accuracy for disease identification and our dialogue system is able to collect these symptoms automatically and make a better diagnosis."
J18-4008,A Joint Model of Conversational Discourse Latent Topics on Microblogs,2018,103,0,3,0.645161,4437,jing li,Computational Linguistics,0,"Conventional topic models are ineffective for topic extraction from microblog messages, because the data sparseness exhibited in short messages lacking structure and contexts results in poor message-level word co-occurrence patterns. To address this issue, we organize microblog messages as conversation trees based on their reposting and replying relations, and propose an unsupervised model that jointly learns word distributions to represent: (1) different roles of conversational discourse, and (2) various latent topics in reflecting content information. By explicitly distinguishing the probabilities of messages with varying discourse roles in containing topical words, our model is able to discover clusters of discourse words that are indicative of topical content. In an automatic evaluation on large-scale microblog corpora, our joint model yields topics with better coherence scores than competitive topic models from previous studies. Qualitative analysis on model outputs indicates that our model induces meaningful representations for both discourse and topics. We further present an empirical study on microblog summarization based on the outputs of our joint model. The results show that the jointly modeled discourse and topic representations can effectively indicate summary-worthy content in microblog conversations."
D18-1090,Automatic Essay Scoring Incorporating Rating Schema via Reinforcement Learning,2018,0,1,2,0,10164,yucheng wang,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Automatic essay scoring (AES) is the task of assigning grades to essays without human interference. Existing systems for AES are typically trained to predict the score of each single essay at a time without considering the rating schema. In order to address this issue, we propose a reinforcement learning framework for essay scoring that incorporates quadratic weighted kappa as guidance to optimize the scoring system. Experiment results on benchmark datasets show the effectiveness of our framework."
C18-1150,A Reinforcement Learning Framework for Natural Question Generation using Bi-discriminators,2018,0,8,2,1,3651,zhihao fan,Proceedings of the 27th International Conference on Computational Linguistics,0,"Visual Question Generation (VQG) aims to ask natural questions about an image automatically. Existing research focus on training model to fit the annotated data set that makes it indifferent from other language generation tasks. We argue that natural questions need to have two specific attributes from the perspectives of content and linguistic respectively, namely, natural and human-written. Inspired by the setting of discriminator in adversarial learning, we propose two discriminators, one for each attribute, to enhance the training. We then use the reinforcement learning framework to incorporate scores from the two discriminators as the reward to guide the training of the question generator. Experimental results on a benchmark VQG dataset show the effectiveness and robustness of our model compared to some state-of-the-art models in terms of both automatic and human evaluation metrics."
C18-1314,Incorporating Argument-Level Interactions for Persuasion Comments Evaluation using Co-attention Model,2018,0,2,2,0,4520,lu ji,Proceedings of the 27th International Conference on Computational Linguistics,0,"In this paper, we investigate the issue of persuasiveness evaluation for argumentative comments. Most of the existing research explores different text features of reply comments on word level and ignores interactions between participants. In general, viewpoints are usually expressed by multiple arguments and exchanged on argument level. To better model the process of dialogical argumentation, we propose a novel co-attention mechanism based neural network to capture the interactions between participants on argument level. Experimental results on a publicly available dataset show that the proposed model significantly outperforms some state-of-the-art methods for persuasiveness evaluation. Further analysis reveals that attention weights computed in our model are able to extract interactive argument pairs from the original post and the reply."
W16-2820,A Preliminary Study of Disputation Behavior in Online Debating Forum,2016,5,2,1,1,3654,zhongyu wei,Proceedings of the Third Workshop on Argument Mining ({A}rg{M}ining2016),0,None
P16-3019,An Efficient Cross-lingual Model for Sentence Classification Using Convolutional Neural Network,2016,0,2,2,0,10446,yandi xia,Proceedings of the {ACL} 2016 Student Research Workshop,0,None
P16-2032,Is This Post Persuasive? Ranking Argumentative Comments in Online Forum,2016,9,34,1,1,3654,zhongyu wei,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,None
C16-1054,Using Relevant Public Posts to Enhance News Article Summarization,2016,21,10,2,0,9098,chen li,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"A news article summary usually consists of 2-3 key sentences that reflect the gist of that news article. In this paper we explore using public posts following a new article to improve automatic summary generation for the news article. We propose different approaches to incorporate information from public posts, including using frequency information from the posts to re-estimate bigram weights in the ILP-based summarization model and to re-weight a dependency tree edge{'}s importance for sentence compression, directly selecting sentences from posts as the final summary, and finally a strategy to combine the summarization results generated from news articles and posts. Our experiments on data collected from Facebook show that relevant public posts provide useful information and can be effectively leveraged to improve news article summarization results."
P15-2009,Using Tweets to Help Sentence Compression for News Highlights Generation,2015,20,2,1,1,3654,zhongyu wei,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,We explore using relevant tweets of a given news article to help sentence compression for generating compressive news highlights. We extend an unsupervised dependency-tree based sentence compression approach by incorporating tweet information to weight the tree edge in terms of informativeness and syntactic importance. The experimental results on a public corpus that contains both news articles and relevant tweets show that our proposed tweets guided sentence compression method can improve the summarization performance significantly compared to the baseline generic sentence compression method.
D15-1259,Using Content-level Structures for Summarizing Microblog Repost Trees,2015,31,8,3,0.645161,4437,jing li,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"A microblog repost tree provides strong clues on how an event described therein develops. To help social media users capture the main clues of events on microblogging sites, we propose a novel repost tree summarization framework by effectively differentiating two kinds of messages on repost trees called leaders and followers, which are derived from contentlevel structure information, i.e., contents of messages and the reposting relations. To this end, Conditional Random Fields (CRF) model is used to detect leaders across repost tree paths. We then present a variant of random-walk-based summarization model to rank and select salient messages based on the result of leader detection. To reduce the error propagation cascaded from leader detection, we improve the framework by enhancing the random walk with adjustment steps for sampling from leader probabilities given all the reposting messages. For evaluation, we construct two annotated corpora, one for leader detection, and the other for repost tree summarization. Experimental results confirm the effectiveness of our method."
P14-5017,Web Information Mining and Decision Support Platform for the Modern Service Industry,2014,10,1,3,1,21327,binyang li,Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"This demonstration presents an intelligent information platform MODEST. MODEST will provide enterprises with the services of retrieving news from websites, extracting commercial information, exploring customersxe2x80x99 opinions, and analyzing collaborative/competitive social networks. In this way, enterprises can improve the competitive abilities and facilitate potential collaboration activities. At the meanwhile, MODEST can also help governments to acquire information about one single company or the entire board timely, and make prompt strategies for better support. Currently, MODEST is applied to the pillar industries of Hong Kong, including innovative finance, modem logistics, information technology, etc."
zhou-etal-2014-cuhk,The {CUHK} Discourse {T}ree{B}ank for {C}hinese: Annotating Explicit Discourse Connectives for the {C}hinese {T}ree{B}ank,2014,28,5,3,1,39109,lanjun zhou,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The lack of open discourse corpus for Chinese brings limitations for many natural language processing tasks. In this work, we present the first open discourse treebank for Chinese, namely, the Discourse Treebank for Chinese (DTBC). At the current stage, we annotated explicit intra-sentence discourse connectives, their corresponding arguments and senses for all 890 documents of the Chinese Treebank 5. We started by analysing the characteristics of discourse annotation for Chinese, adapted the annotation scheme of Penn Discourse Treebank 2 (PDTB2) to Chinese language while maintaining the compatibility as far as possible. We made adjustments to 3 essential aspects according to the previous study of Chinese linguistics. They are sense hierarchy, argument scope and semantics of arguments. Agreement study showed that our annotation scheme could achieve highly reliable results."
D14-1123,Exploiting Community Emotion for Microblog Event Detection,2014,25,14,4,0,37269,gaoyan ou,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Microblog has become a major platform for information about real-world events. Automatically discovering realworld events from microblog has attracted the attention of many researchers. However, most of existing work ignore the importance of emotion information for event detection. We argue that peoplexe2x80x99s emotional reactions immediately reflect the occurringofreal-worldeventsand shouldbeimportant for event detection. In this study, we focus on the problem of communityrelated event detection by community emotions. To address the problem, we propose a novel framework which include the following three key components: microblog emotion classification, community emotion aggregation and community emotion burst detection. We evaluate our approach on real microblog data sets. Experimental results demonstrate the effectiveness of the proposed framework."
C14-1083,Utilizing Microblogs for Automatic News Highlights Extraction,2014,34,28,1,1,3654,zhongyu wei,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"Story highlights form a succinct single-document summary consisting of 3-4 highlight sentences that reflect the gist of a news article. Automatically producing news highlights is very challenging. We propose a novel method to improve news highlights extraction by using microblogs. The hypothesis is that microblog posts, although noisy, are not only indicative of important pieces of information in the news story, but also inherently xe2x80x9cshort and sweetxe2x80x9d resulting from the artificial compression effect due to the length limit. Given a news article, we formulate the problem as two rank-then-extract tasks: (1) we find a set of indicative tweets and use them to assist the ranking of news sentences for extraction; (2) we extract top ranked tweets as a substitute of sentence extraction. Results based on our news-tweets pairing corpus indicate that the method significantly outperform some strong baselines for single-document summarization."
P13-2011,An Empirical Study on Uncertainty Identification in Social Media Context,2013,17,11,1,1,3654,zhongyu wei,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Uncertainty text detection is important to many social-media-based applications since more and more users utilize social media platforms (e.g., Twitter, Facebook, etc.) as information source to produce or derive interpretations based on them. However, existing uncertainty cues are ineffective in social media context because of its specific characteristics. In this paper, we propose a variant of annotation scheme for uncertainty identification and construct the first uncertainty corpus based on tweets. We then conduct experiments on the generated tweets corpus to study the effectiveness of different types of features for uncertainty text identification."
he-etal-2012-quantising,Quantising Opinions for Political Tweets Analysis,2012,13,18,3,0,69,yulan he,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"There have been increasing interests in recent years in analyzing tweet messages relevant to political events so as to understand public opinions towards certain political issues. We analyzed tweet messages crawled during the eight weeks leading to the UK General Election in May 2010 and found that activities at Twitter is not necessarily a good predictor of popularity of political parties. We then proceed to propose a statistical model for sentiment detection with side information such as emoticons and hash tags implying tweet polarities being incorporated. Our results show that sentiment analysis based on a simple keyword matching against a sentiment lexicon or a supervised classifier trained with distant supervision does not correlate well with the actual election results. However, using our proposed statistical model for sentiment analysis, we were able to map the public opinion in Twitter with the actual offline sentiment in real world."
C12-2138,Cross-Lingual Identification of Ambiguous Discourse Connectives for Resource-Poor Language,2012,19,7,4,0,39109,lanjun zhou,Proceedings of {COLING} 2012: Posters,0,"The lack of annotated corpora brings limitations in research of discourse classification for many languages. In this paper, we present the first effort towards recognizing ambiguities of discourse connectives, which is fundamental to discourse classification for resource-poor language such as Chinese. A language independent framework is proposed utilizing bilingual dictionaries, Penn Discourse Treebank and parallel data between English and Chinese. We start from translating the English connectives to Chinese using a bi-lingual dictionary. Then, the ambiguities in terms of senses a connective may signal are estimated based on the ambiguities of English connectives and word alignment information. Finally, the ambiguity between discourse usage and non-discourse usage were disambiguated using the co-training algorithm. Experimental results showed the proposed method not only built a high quality connective lexicon for Chinese but also achieved a high performance in recognizing the ambiguities. We also present a discourse corpus for Chinese which will soon become the first Chinese discourse corpus publicly available."
D11-1015,Unsupervised Discovery of Discourse Relations for Eliminating Intra-sentence Polarity Ambiguities,2011,21,51,4,0,39109,lanjun zhou,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"Polarity classification of opinionated sentences with both positive and negative sentiments is a key challenge in sentiment analysis. This paper presents a novel unsupervised method for discovering intra-sentence level discourse relations for eliminating polarity ambiguities. Firstly, a discourse scheme with discourse constraints on polarity was defined empirically based on Rhetorical Structure Theory (RST). Then, a small set of cuephrase-based patterns were utilized to collect a large number of discourse instances which were later converted to semantic sequential representations (SSRs). Finally, an unsupervised method was adopted to generate, weigh and filter new SSRs without cue phrases for recognizing discourse relations. Experimental results showed that the proposed methods not only effectively recognized the defined discourse relations but also achieved significant improvement by integrating discourse information in sentence-level polarity classification."
