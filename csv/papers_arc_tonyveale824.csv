S18-1093,{I}rony{M}agnet at {S}em{E}val-2018 Task 3: A {S}iamese network for Irony detection in Social media,2018,0,1,2,1,28830,aniruddha ghosh,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"This paper describes our system, entitled IronyMagnet, for the 3rd Task of the SemEval 2018 workshop, {``}Irony Detection in English Tweets{''}. In Task 1, irony classification task has been considered as a binary classification task. Now for the first time, finer categories of irony are considered as part of a shared task. In task 2, three types of irony are considered; {``}Irony by contrast{''} - ironic instances where evaluative expression portrays inverse polarity (positive, negative) of the literal proposition; {``}Situational irony{''} - ironic instances where output of a situation do not comply with its expectation; {``}Other verbal irony{''} - instances where ironic intent does not rely on polarity contrast or unexpected outcome. We proposed a Siamese neural network for irony detection, which is consisted of two subnetworks, each containing a long short term memory layer(LSTM) and an embedding layer initialized with vectors from Glove word embedding 1 . The system achieved a f-score of 0.72, and 0.50 in task 1, and task 2 respectively."
S17-2011,Idiom Savant at {S}emeval-2017 Task 7: Detection and Interpretation of {E}nglish Puns,2017,7,3,4,0,32229,samuel doogan,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"This paper describes our system, entitled Idiom Savant, for the 7th Task of the Semeval 2017 workshop, {``}Detection and interpretation of English Puns{''}. Our system consists of two probabilistic models for each type of puns using Google n-gram and Word2Vec. Our system achieved f-score of calculating, 0.663, and 0.07 in homographic puns and 0.8439, 0.6631, and 0.0806 in heterographic puns in task 1, task 2, and task 3 respectively."
D17-1050,"Magnets for Sarcasm: Making Sarcasm Detection Timely, Contextual and Very Personal",2017,15,23,2,1,28830,aniruddha ghosh,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"Sarcasm is a pervasive phenomenon in social media, permitting the concise communication of meaning, affect and attitude. Concision requires wit to produce and wit to understand, which demands from each party knowledge of norms, context and a speaker{'}s mindset. Insight into a speaker{'}s psychological profile at the time of production is a valuable source of context for sarcasm detection. Using a neural architecture, we show significant gains in detection accuracy when knowledge of the speaker{'}s mood at the time of production can be inferred. Our focus is on sarcasm detection on Twitter, and show that the mood exhibited by a speaker over tweets leading up to a new post is as useful a cue for sarcasm as the topical context of the post itself. The work opens the door to an empirical exploration not just of sarcasm in text but of the sarcastic state of mind."
W16-1105,Round Up The Usual Suspects: Knowledge-Based Metaphor Generation,2016,-1,-1,1,1,28831,tony veale,Proceedings of the Fourth Workshop on Metaphor in {NLP},0,None
W16-0425,Fracking Sarcasm using Neural Network,2016,27,54,2,1,28830,aniruddha ghosh,"Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"Precise semantic representation of a sentence and definitive information extraction are key steps in the accurate processing of sentence meaning, especially for figurative phenomena such as sarcasm, Irony, and metaphor cause literal meanings to be discounted and secondary or extended meanings to be intentionally profiled. Semantic modelling faces a new challenge in social media, because grammatical inaccuracy is commonplace yet many previous state-of-the-art methods exploit grammatical structure. For sarcasm detection over social media content, researchers so far have counted on Bag-of-Words(BOW), N-grams etc. In this paper, we propose a neural network semantic model for the task of sarcasm detection. We also review semantic modelling using Support Vector Machine (SVM) that employs constituency parsetrees fed and labeled with syntactic and semantic information. The proposed neural network model composed of Convolution Neural Network(CNN) and followed by a Long short term memory (LSTM) network and finally a Deep neural network(DNN). The proposed model outperforms state-of-the-art textbased methods for sarcasm detection, yielding an F-score of .92."
W15-1410,Fighting Words and Antagonistic Worlds,2015,-1,-1,1,1,28831,tony veale,Proceedings of the Third Workshop on Metaphor in {NLP},0,None
S15-2080,{S}em{E}val-2015 Task 11: Sentiment Analysis of Figurative Language in {T}witter,2015,11,76,3,1,28830,aniruddha ghosh,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This report summarizes the objectives and evaluation of the SemEval 2015 task on the sentiment analysis of figurative language on Twitter (Task 11). This is the first sentiment analysis task wholly dedicated to analyzing figurative language on Twitter. Specifically, three broad classes of figurative language are considered: irony, sarcasm and metaphor. Gold standard sets of 8000 training tweets and 4000 test tweets were annotated using workers on the crowdsourcing platform CrowdFlower. Participating systems were required to provide a fine-grained sentiment score on an 11-point scale (-5 to 5, including 0 for neutral intent) for each tweet, and systems were evaluated against the gold standard using both a Cosinesimilarity and a Mean-Squared-Error measure."
W14-2307,A Service-Oriented Architecture for Metaphor Processing,2014,28,11,1,1,28831,tony veale,Proceedings of the Second Workshop on Metaphor in {NLP},0,"Metaphor is much more than a pyrotechnical flourish of language or a fascinating conceptual puzzle: it is a cognitive lever that allows speakers to leverage their knowledge of one domain to describe, reframe and understand another. Though NLP researchers tend to view metaphor as a problem to be solved, metaphor is perhaps more fittingly seen as a solution to be used, that is, as an important tool in the support of creative thinking and the generation of diverse linguistic outputs. Since it pays to think of metaphor as a foundational cognitive service, one that can be exploited in a wide array of creative computational tasks, we present here a view of metaphor as a public Web service that can be freely called on demand."
S13-2025,{S}em{E}val-2013 Task 4: Free Paraphrases of Noun Compounds,2013,15,22,6,0,16715,iris hendrickx,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"In this paper, we describe SemEval-2013 Task 4: the definition, the data, the evaluation and the results. The task is to capture some of the meaning of English noun compounds via paraphrasing. Given a two-word noun compound, the participating system is asked to produce an explicitly ranked list of its free-form paraphrases. The list is automatically compared and evaluated against a similarly ranked list of paraphrases proposed by human annotators, recruited and managed through Amazonxe2x80x99s Mechanical Turk. The comparison of raw paraphrases is sensitive to syntactic and morphological variation. The xe2x80x9cgoldxe2x80x9d ranking is based on the relative popularity of paraphrases among annotators. To make the ranking more reliable, highly similar paraphrases are grouped, so as to downplay superficial differences in syntax and morphology. Three systems participated in the task. They all beat a simple baseline on one of the two evaluation measures, but not on both measures. This shows that the task is difficult."
P13-1065,Creating Similarity: Lateral Thinking for Vertical Similarity Judgments,2013,30,14,1,1,28831,tony veale,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Just as observing is more than just seeing, comparing is far more than mere matching. It takes understanding, and even inventiveness, to discern a useful basis for judging two ideas as similar in a particular context, especially when our perspective is shaped by an act of linguistic creativity such as metaphor, simile or analogy. Structured resources such as WordNet offer a convenient hierarchical means for converging on a common ground for comparison, but offer little support for the divergent thinking that is needed to creatively view one concept as another. We describe such a means here, by showing how the web can be used to harvest many divergent views for many familiar ideas. These lateral views complement the vertical views of WordNet, and support a system for idea exploration called Thesaurus Rex. We show also how Thesaurus Rex supports a novel, generative similarity measure for WordNet."
P12-3002,Specifying Viewpoint and Information Need with Affective Metaphors: A System Demonstration of the Metaphor-Magnet Web App/Service,2012,6,7,1,1,28831,tony veale,Proceedings of the {ACL} 2012 System Demonstrations,0,"Metaphors pervade our language because they are elastic enough to allow a speaker to express an affective viewpoint on a topic without committing to a specific meaning. This balance of expressiveness and indeterminism means that metaphors are just as useful for eliciting information as they are for conveying information. We explore here, via a demonstration of a system for metaphor interpretation and generation called Metaphor Magnet, the practical uses of metaphor as a basis for formulating affective information queries. We also consider the kinds of deep and shallow stereotypical knowledge that are needed for such a system, and demonstrate how they can be acquired from corpora and the web."
P12-2015,"A Context-sensitive, Multi-faceted Model of Lexico-Conceptual Affect",2012,16,15,1,1,28831,tony veale,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Since we can 'spin' words and concepts to suit our affective needs, context is a major determinant of the perceived affect of a word or concept. We view this re-profiling as a selective emphasis or de-emphasis of the qualities that underpin our shared stereotype of a concept or a word meaning, and construct our model of the affective lexicon accordingly. We show how a large body of affective stereotypes can be acquired from the web, and also show how these are used to create and interpret affective metaphors."
P11-4003,Exploiting Readymades in Linguistic Creativity: A System Demonstration of the Jigsaw Bard,2011,10,6,1,1,28831,tony veale,Proceedings of the {ACL}-{HLT} 2011 System Demonstrations,0,"Large lexical resources, such as corpora and databases of Web ngrams, are a rich source of pre-fabricated phrases that can be reused in many different contexts. However, one must be careful in how these resources are used, and noted writers such as George Orwell have argued that the use of canned phrases encourages sloppy thinking and results in poor communication. Nonetheless, while Orwell prized home-made phrases over the readymade variety, there is a vibrant movement in modern art which shifts artistic creation from the production of novel artifacts to the clever reuse of readymades or objets trouves. We describe here a system that makes creative reuse of the linguistic readymades in the Google ngrams. Our system, the Jigsaw Bard, thus owes more to Marcel Duchamp than to George Orwell. We demonstrate how textual readymades can be identified and harvested on a large scale, and used to drive a modest form of linguistic creativity."
P11-1029,Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity,2011,38,46,1,1,28831,tony veale,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"Information retrieval (IR) and figurative language processing (FLP) could scarcely be more different in their treatment of language and meaning. IR views language as an open-ended set of mostly stable signs with which texts can be indexed and retrieved, focusing more on a text's potential relevance than its potential meaning. In contrast, FLP views language as a system of unstable signs that can be used to talk about the world in creative new ways. There is another key difference: IR is practical, scalable and robust, and in daily use by millions of casual users. FLP is neither scalable nor robust, and not yet practical enough to migrate beyond the lab. This paper thus presents a mutually beneficial hybrid of IR and FLP, one that enriches IR with new operators to enable the non-literal retrieval of creative expressions, and which also transplants FLP into a robust, scalable framework in which practical applications of linguistic creativity can be implemented."
S10-1007,{S}em{E}val-2 Task 9: The Interpretation of Noun Compounds Using Paraphrasing Verbs and Prepositions,2010,28,27,6,1,45588,cristina butnariu,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"Previous research has shown that the meaning of many noun-noun compounds N1 N2 can be approximated reasonably well by paraphrasing clauses of the form 'N2 that ... N1', where '...' stands for a verb with or without a preposition. For example, malaria mosquito is a 'mosquito that carries malaria'. Evaluating the quality of such paraphrases is the theme of Task 9 at SemEval-2010. This paper describes some background, the task definition, the process of data collection and the task results. We also venture a few general conclusions before the participating teams present their systems at the SemEval-2010 workshop. There were 5 teams who submitted 7 systems."
S10-1051,{UCD}-Goggle: A Hybrid System for Noun Compound Paraphrasing,2010,11,8,3,1,37245,guofu li,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"This paper addresses the problem of ranking a list of paraphrases associated with a noun-noun compound as closely as possible to human raters (Butnariu et al., 2010). UCD-Goggle tackles this task using semantic knowledge learnt from the Google n-grams together with human-preferences for paraphrases mined from training data. Empirical evaluation shows that UCD-Goggle achieves 0.432 Spearman correlation with human judgments."
W09-2416,{S}em{E}val-2010 Task 9: The Interpretation of Noun Compounds Using Paraphrasing Verbs and Prepositions,2009,22,39,6,1,45588,cristina butnariu,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"We present a brief overview of the main challenges in understanding the semantics of noun compounds and consider some known methods. We introduce a new task to be part of SemEval-2010: the interpretation of noun compounds using paraphrasing verbs and prepositions. The task is meant to provide a standard testbed for future research on noun compound semantics. It should also promote paraphrase-based approaches to the problem, which can benefit many NLP applications."
E09-1095,Growing Finely-Discriminating Taxonomies from Seeds of Varying Quality and Size,2009,18,8,1,1,28831,tony veale,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"Concept taxonomies offer a powerful means for organizing knowledge, but this organization must allow for many overlapping and fine-grained perspectives if a general-purpose taxonomy is to reflect concepts as they are actually employed and reasoned about in everyday usage. We present here a means of bootstrapping finely-discriminating taxonomies from a variety of different starting points, or seeds, that are acquired from three different sources: WordNet, ConceptNet and the web at large."
P08-1060,Multilingual Harvesting of Cross-Cultural Stereotypes,2008,17,10,1,1,28831,tony veale,Proceedings of ACL-08: HLT,1,"People rarely articulate explicitly what a native speaker of a language is already assumed to know. So to acquire the stereotypical knowledge that underpins much of what is said in a given culture, one must look to what is implied by language rather than what is overtly stated. Similes are a convenient vehicle for this kind of knowledge, insofar as they mark out the most salient aspects of the most frequently evoked concepts. In this paper we perform a multilingual exploration of the space of common-place similes, by mining a large body of Chinese similes from the web and comparing these to the English similes harvested by Veale and Hao (2007). We demonstrate that while the simile-frame is inherently leaky in both languages, a multilingual analysis allows us to filter much of the noise that otherwise hinders the knowledge extraction process. In doing so, we can also identify a core set of stereotypical descriptions that exist in both languages and accurately map these descriptions onto a multilingual lexical ontology like HowNet. Finally, we demonstrate that conceptual descriptions that are derived from common-place similes are extremely compact and predictive of ontological structure."
veale-hao-2008-acquiring,Acquiring Naturalistic Concept Descriptions from the Web,2008,14,1,1,1,28831,tony veale,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Many of the beliefs that one uses to reason about everyday entities and events are neither strictly true or even logically consistent. Rather, people appear to rely on a large body of folk knowledge in the form of stereotypical associations, clich{\'e}s and other kinds of naturalistic descriptions, many of which express views of the world that are second-hand, overly-simplified and, in some cases, non-literal to the point of being poetic. These descriptions pervade our language yet one rarely finds them in authoritative linguistic resources like dictionaries and encyclopaedias. We describe here how such naturalistic descriptions can be harvested from the web in the guise of explicit similes and related text patterns, and empirically demonstrate that these descriptions do broadly capture the way people see the world, at least from the perspective of category organization in an ontology."
C08-1011,A Concept-Centered Approach to Noun-Compound Interpretation,2008,15,29,2,1,45588,cristina butnariu,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"A noun-compound is a compressed proposition that requires an audience to recover the implicit relationship between two concepts that are expressed as nouns. Listeners recover this relationship by considering the most typical relations afforded by each concept. These relational possibilities are evident at a linguistic level in the syntagmatic patterns that connect nouns to the verbal actions that act upon, or are facilitated by, these nouns. We present a model of noun-compound interpretation that first learns the relational possibilities for individual nouns from corpora, and which then uses these to hypothesize about the most likely relationship that underpins a noun compound."
C08-1119,A Fluid Knowledge Representation for Understanding and Generating Creative Metaphors,2008,18,39,1,1,28831,tony veale,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"Creative metaphor is a phenomenon that stretches and bends the conventions of semantic description, often to humorous and poetic extremes. The computational modeling of metaphor thus requires a knowledge representation that is just as stretchable and semantically accommodating. We present here a flexible knowledge representation for metaphor interpretation and generation, called Talking Points, and describe how talking points can be acquired on a large scale from WordNet (Fellbaum, 1998) and from the web. We show how talking points can be fluidly connected to form a slipnet, and demonstrate that talking points provide an especially concise representation for concepts in general."
S07-1083,{UCD}-S1: A hybrid model for detecting semantic relations between noun pairs in text,2007,5,3,2,1,45588,cristina butnariu,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"We describe a supervised learning approach to categorizing inter-noun relations, based on Support Vector Machines, that builds a different classifier for each of seven semantic relations. Each model uses the same learning strategy, while a simple voting procedure based on five trained discriminators with various blends of features determines the final categorization. The features that characterize each of the noun pairs are a blend of lexical-semantic categories extracted from WordNet and several flavors of syntactic patterns extracted from various corpora, including Wikipedia and the WMTS corpus."
P07-1008,Making Lexical Ontologies Functional and Context-Sensitive,2007,7,25,1,1,28831,tony veale,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"Human categorization is neither a binary nor a context-free process. Rather, some concepts are better examples of a category than others, while the criteria for category membership may be satisfied to different degrees by different concepts in different contexts. In light of these empirical facts, WordNetxe2x80x99s static category structure appears both excessively rigid and unduly fragile for processing real texts. In this paper we describe a syntagmatic, corpus-based approach to redefining WordNetxe2x80x99s categories in a functional, gradable and context-sensitive fashion. We describe how the diagnostic properties for these definitions are automatically acquired from the web, and how the increased flexibility in categorization that arises from these redefinitions offers a robust account of metaphor comprehension in the mold of Glucksbergxe2x80x99s (2001) theory of category-inclusion. Furthermore, we demonstrate how this competence with figurative categorization can effectively be governed by automatically-generated ontological constraints, also acquired from the web."
P06-2021,Using {W}ord{N}et to Automatically Deduce Relations between Words in Noun-Noun Compounds,2006,6,12,2,0,45609,fintan costello,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"We present an algorithm for automatically disambiguating noun-noun compounds by deducing the correct semantic relation between their constituent words. This algorithm uses a corpus of 2,500 compounds annotated with WordNet senses and covering 139 different semantic relations (we make this corpus available online for researchers interested in the semantics of noun-noun compounds). The algorithm takes as input the WordNet senses for the nouns in a compound, finds all parent senses (hypernyms) of those senses, and searches the corpus for other compounds containing any pair of those senses. The relation with the highest proportional co-occurrence with any sense pair is returned as the correct relation for the compound. This algorithm was tested using a 'leave-one-out' procedure on the corpus of compounds. The algorithm identified the correct relations for compounds with high precision: in 92% of cases where a relation was found with a proportional co-occurrence of 1.0, it was the correct relation for the compound being disambiguated."
I05-1029,Analogy as Functional Recategorization: Abstraction with {H}ow{N}et Semantics,2005,16,2,1,1,28831,tony veale,Second International Joint Conference on Natural Language Processing: Full Papers,0,"One generally accepted hallmark of creative thinking is an ability to look beyond conventional labels and recategorize a concept based on its behaviour and functional potential. So while taxonomies are useful in any domain of reasoning, they typically represent the conventional label set that creative thinking attempts to look beyond. So if a linguistic taxonomy like WordNet [1] is to be useful in driving linguistic creativity, it must support some basis for recategorization, to allow an agent to reorganize its category structures in a way that unlocks the functional potential of objects, or that recognizes similarity between literally dissimilar ideas. In this paper we consider how recategorization can be used to generate analogies using the HowNet [2] ontology, a lexical resource like WordNet that in addition to being bilingual (Chinese/English) also provides explicit semantic definitions for each of the terms that it defines."
seco-etal-2004-concept,Concept Creation in Lexical Ontologies,2004,4,1,2,0,50119,nuno seco,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"The compositional mechanisms involved in the comprehension and creation of concepts is of much interest to the communities studying Cognitive Science and Artificial Intelligence. Nevertheless, comprehension has been largely studied while the creation or production of novel concepts has been somewhat forgotten. We present a model for concept generation using a well known lexical ontology xe2x80x94 WordNet xe2x80x94 along with the results of our experiments that evaluate the creative characteristics of the generated concepts. We also explain how these ideas may be applied to other areas of research, namely to Information Retrieval systems."
veale-2004-polysemy,Polysemy and Category Structure in {W}ord{N}et: An Evidential Approach,2004,3,3,1,1,28831,tony veale,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"While polysemy is a form of ambiguity that can complicate natural language processing, it is also a rich lexical resource that yields useful insights into the mapping between words and concepts. WordNet, a comprehensive lexical knowledge-base of English word meanings, is replete with instances of polysemy, but also contains many instances of homonymy, and fails to distinguish between both kinds of ambiguity. We propose in this paper an alternative to the distributional approach for recognizing polysemous sense-pairs in WordNet. Our approach does not rely on the systematicity of regular polysemy to identify the families of words that instantiate a particular metonymic pattern, but seeks instead local ontological evidence for each word, on a case by case basis."
hayes-etal-2004-enriching,Enriching {W}ord{N}et Via Generative Metonymy and Creative Polysemy,2004,8,2,2,0,51922,jer hayes,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,Metonymy is a creative process that establishes relationships based on contiguity or semantic relatedness between concepts. We outline a mechanism for deriving new concepts from WordNet using metonymy. We argue that by exploiting polysemy in WordNet we can take advantage of the metonymic relations between concepts. The focus of our metonymy generation work has been the creation of noun{\-} noun compounds that do not already exist in WordNet and which can be profitably added to WordNet. The mechanism of metonymy generation we outline takes a source compound and creates new compounds by exploiting the polysemy associated with hyponyms of the head of the source compound. We argue that metonymy generation is a sound basis for concept creation as the newly created compounds are semantically related to the source concept. We demonstrate that metonymy generation based on polysemy is superior to a method of metonymy generation that ignores polysemy. These new concepts can be used to augment WordNet.
C04-1195,Creative Discovery in Lexical Ontologies,2004,6,5,1,1,28831,tony veale,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"Compound terms play a surprisingly key role in the organization of lexical ontologies. However, their inclusion forces one to address the issues of completeness and consistency that naturally arise from this organizational role. In this paper we show how creative exploration in the space of literal compounds can reveal not only additional compound terms to systematically balance an ontology, but can also discover new and potentially innovative concepts in their own right."
W03-1404,Systematicity and the Lexicon in Creative Metaphor,2003,15,6,1,1,28831,tony veale,Proceedings of the {ACL} 2003 Workshop on the Lexicon and Figurative Language,0,"Aptness is an umbrella term that covers a multitude of issues in the interpretation and generation of creative metaphor. In this paper we concentrate on one of these issues --- the notion of lexical systematicity --- and explore its role in ascertaining the coherence of creative metaphor relative to the structure of the target concept being described. We argue that all else being equal, the most apt metaphors are those that resonate most with the way the target concept is literally and metaphorically organized. As such, the lexicon plays a key role in enforcing and recognizing aptness, insofar as this existing organization will already have been lexicalized. We perform our exploration in the context of WordNet, and describe how relational structures can be automatically extracted from this lexical taxonomy to facilitate the interpretation of creative metaphors."
1996.amta-1.1,An example-based approach to machine translation,1996,-1,-1,3,0,55747,brona collins,Conference of the Association for Machine Translation in the Americas,0,None
1996.amta-1.17,"Space, metaphor and schematization in sign: sign language translation in the {ZARDOZ} system",1996,-1,-1,1,1,28831,tony veale,Conference of the Association for Machine Translation in the Americas,0,None
W94-0333,Sign-Language Generation in {ZARDOZ}: An {E}nglish to Sign-Language Translation System,1994,0,0,1,1,28831,tony veale,Proceedings of the Seventh International Workshop on Natural Language Generation,0,None
