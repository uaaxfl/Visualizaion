P13-4004,{A}nno{M}arket: An Open Cloud Platform for {NLP},2013,11,6,4,1,41364,valentin tablan,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"This paper presents AnnoMarket, an open cloud-based platform which enables researchers to deploy, share, and use language processing components and resources, following the data-as-a-service and software-as-a-service paradigms. The focus is on multilingual text analysis resources and services, based on an opensource infrastructure and compliant with relevant NLP standards. We demonstrate how the AnnoMarket platform can be used to develop NLP applications with little or no programming, to index the results for enhanced browsing and search, and to evaluate performance. Utilising AnnoMarket is straightforward, since cloud infrastructural issues are dealt with by the platform, completely transparently to the user: load balancing, efficient data upload and storage, deployment on the virtual machines, security, and fault tolerance."
damljanovic-etal-2010-identification,Identification of the Question Focus: Combining Syntactic Analysis and Ontology-based Lookup through the User Interaction,2010,21,33,3,0,43117,danica damljanovic,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Most question-answering systems contain a classifier module which determines a question category, based on which each question is assigned an answer type. However, setting up syntactic patterns for this classification is a big challenge. In addition, in the case of ontology-based systems, the answer type should be aligned to the queried knowledge structure. In this paper, we present an approach for determining the answer type semi-automatically. We first identify the question focus using syntactic parsing, and then try to identify the answer type by combining the head of the focus with the ontology-based lookup. When this combination is not enough to make conclusions automatically, the user is engaged into a dialog in order to resolve the answer type. User selections are saved and used for training the system in order to improve its performance over time. Further on, the answer type is used to show the feedback and the concise answer to the user. Our approach is evaluated using 250 questions from the Mooney Geoquery dataset."
yankova-etal-2008-framework,A Framework for Identity Resolution and Merging for Multi-source Information Extraction,2008,13,2,3,0,48205,milena yankova,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In the context of ontology-based information extraction, identity resolution is the process of deciding whether an instance extracted from text refers to a known entity in the target domain (e.g. the ontology). We present an ontology-based framework for identity resolution which can be customized to different application domains and extraction tasks. Rules for identify resolution, which compute similarities between target and source entities based on class information and instance properties and values, can be defined for each class in the ontology. We present a case study of the application of the framework to the problem of multi-source job vacancy extraction"
tablan-etal-2006-creating,Creating Tools for Morphological Analysis of {S}umerian,2006,-1,-1,4,1,41364,valentin tablan,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Sumerian is a long-extinct language documented throughout the ancient MiddleEast, arguably the first language for which we have written evidence, and is a language isolate (i.e. no related languages have so far been identified). The Electronic Text Corpus of Sumerian Literature (ETCSL), based at theUniversity of Oxford, aims to make accessible on the web over 350 literary workscomposed during the late third and early second millennia BCE. The transliterations and translations can be searched, browsed and read online using the tools of the website. In this paper we describe the creation of linguistic analysis and corpus search tools for Sumerian, as part of the development of the ETCSL. This is designed to enable Sumerian scholars, students and interested laymen to analyse the texts online and electronically, and to further knowledge about the language."
tablan-etal-2006-user,User-friendly ontology authoring using a controlled language,2006,9,27,3,1,41364,valentin tablan,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"In recent years, following the rapid development in the Semantic Web and Knowledge Management research, ontologies have become more in demand in Natural Language Processing. An increasing number of systems use ontologies either internally, for modelling the domain of the application, or as data structures that hold the output resulting from the work of the system, in the form of knowledge bases. While there are many ontology editing tools aimed at expert users, there are very few which are accessible to users wishing to create simple structures without delving into the intricacies of knowledge representation languages. The approach described in this paper allows users to create and edit ontologies simply by using a restricted version of the English language. The controlled language described within is based on an open vocabulary and a restricted set of grammatical constructs. Sentences written in this language unambiguously map into a number of knowledge representation formats including OWL and RDF-S to allow round-trip ontology management."
W05-0610,Using Uneven Margins {SVM} and Perceptron for Information Extraction,2005,17,52,3,0,48270,yaoyong li,Proceedings of the Ninth Conference on Computational Natural Language Learning ({C}o{NLL}-2005),0,"The classification problem derived from information extraction (IE) has an imbalanced training set. This is particularly true when learning from smaller datasets which often have a few positive training examples and many negative ones. This paper takes two popular IE algorithms -- SVM and Perceptron -- and demonstrates how the introduction of an uneven margins parameter can improve the results on imbalanced training data in IE. Our experiments demonstrate that the uneven margin was indeed helpful, especially when learning from few examples. Essentially, the smaller the training set is, the more beneficial the uneven margin can be. We also compare our systems to other state-of-the-art algorithms on several benchmarking corpora for IE."
I05-3023,Perceptron Learning for {C}hinese Word Segmentation,2005,5,4,4,0,48270,yaoyong li,Proceedings of the Fourth {SIGHAN} Workshop on {C}hinese Language Processing,0,"We explored a simple, fast and effective learning algorithm, the uneven margins Perceptron, for Chinese word segmentation. We adopted the character-based classification framework and transformed the task into several binary classification problems. We participated the close and open tests for all the four corpora. For the open test we only used the utf-8 code knowledge for discrimination among Latin characters, Arabic numbers and all other characters. Our system performed well on the as, cityu and msr corpora but was clearly worse than the best result on the pku corpus."
maynard-etal-2004-automatic,Automatic Language-Independent Induction of Gazetteer Lists,2004,8,17,3,1,25114,diana maynard,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Adaptation of existing Information Extraction (IE) systems to new languages and domains is the focus of much current research, but progress is often hindered by the lack of available resources to enable developers to get a new system up and running fast. It has previously been shown that a good set of gazetteer lists can have a vital role here, but creation of lists for a new language or domain can be time-consuming and laborious. In this paper we demonstrate a tool for inducing gazetteer lists from a small set of annotated corpora and creating a baseline IE system. We also describe an extension to this, using bootstrapping techniques in order to generate much larger volumes of noisy training texts. High quality results have been achieved in this way on Hindi, Chinese and Arabic."
guthrie-etal-2004-large,Large Scale Experiments for Semantic Labeling of Noun Phrases in Raw Text,2004,8,2,5,0,37309,louise guthrie,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,This paper gives a brief overview of the results of our work during the Summer 2003 Workshop of the Center for Language and Speech Processing at the Johns Hopkins University in Baltimore Maryland. The goal of the project was to determine the feasibility of extending named entity recognition to common nouns and determine whether or not it is possible to assign automatically a predetermined set of semantic tags and approach human performance in the task.
W03-1505,{NE} Recognition Without Training Data on a Language You Don{'}t Speak,2003,6,23,3,1,25114,diana maynard,Proceedings of the {ACL} 2003 Workshop on Multilingual and Mixed-language Named Entity Recognition,0,"In this paper we describe an experiment to adapt a named entity recognition system from English to Cebuano as part of the TIDES surprise language program. With 4 person-days of effort, and with no previous knowledge of which language would be involved, no knowledge of the language in question once it was announced, and no training data available, we adapted the ANNIE system for Cebuano and achieved an F-measure of 77.5%."
W03-0803,{OLLIE}: On-Line Learning for Information Extraction,2003,15,5,4,1,41364,valentin tablan,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Software Engineering and Architecture of Language Technology Systems ({SEALTS}),0,"This paper reports work aimed at developing an open, distributed learning environment, OLLIE, where researchers can experiment with different Machine Learning (ML) methods for Information Extraction. Once the required level of performance is reached, the ML algorithms can be used to speed up the manual annotation process. OLLIE uses a browser client while data storage and ML training is performed on servers. The different ML algorithms use a unified programming interface; the integration of new ones is straightforward."
W03-0101,Experiments with geographic knowledge for information extraction,2003,7,46,6,0,52034,dimitar manov,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Analysis of Geographic References,0,"Here we present work on using spatial knowledge in conjunction with information extraction (IE). Considerable volume of location data was imported in a knowledge base (KB) with entities of general importance used for semantic annotation, indexing, and retrieval of text. The Semantic Web knowledge representation standards are used, namely RDF(S). An extensive upper-level ontology with more than two hundred classes is designed. With respect to the locations, the goal was to include the most important categories considering public and tasks not specially related to geography or related areas. The locations data is derived from number of publicly available resources and combined to assure best performance for domain-independent named-entity recognition in text. An evaluation and comparison to high performance IE application is given."
E03-2009,Multilingual adaptations of a reusable information extraction tool,2003,5,19,2,1,25114,diana maynard,Demonstrations,0,"In this demo we will present GATE, an architecture and framework for language engineering, and ANNIE, an information extraction system developed within it. We will demonstrate how ANNIE has been adapted to perform NE recognition in different languages, including Indic and Slavonic languages as well as Western European ones, and how the resources can be reused for new applications and languages."
E03-2013,Robust Generic and Query-based Summarization,2003,7,50,3,0.680272,5986,horacio saggion,Demonstrations,0,We present a robust summarisation system developed within the GATE architecture that makes use of robust components for semantic tagging and coreference resolution provided by GATE. Our system combines GATE components with well established statistical techniques developed for the purpose of text summarisation research. The system supports generic and query-based summarisation addressing the need for user adaptation.
E03-2014,"Event-Coreference across Multiple, Multi-lingual Sources in the Mumis Project",2003,5,4,3,0.680272,5986,horacio saggion,Demonstrations,0,"We present our work on information extraction from multiple, multi-lingual sources for the Multimedia Indexing and Searching Environment (MUMIS), a project aiming at developing technology to produce formal annotations about essential events in multimedia programme material. The novelty of our approach consists on the use of a merging or cross-document coreference algorithm that aims at combining the output delivered by the information extraction systems."
W02-0403,Using a text engineering framework to build an extendable and portable {IE}-based summarisation system,2002,11,18,4,1,25114,diana maynard,Proceedings of the {ACL}-02 Workshop on Automatic Summarization,0,"In this paper we describe how information extraction technology has been used to build a summarisation system in the domain of occupational health and safety. The core of the application is based on named entity recognition using pattern-action semantic grammar rules. Co-occurrence of the named entities is used as a criteria to identify the sentences to be included in the summary. The system is developed and automatically evaluated within the GATE framework, and can easily be extended or ported to new domains."
W02-0108,Using {GATE} as an Environment for Teaching {NLP},2002,12,18,2,1,11076,kalina bontcheva,Proceedings of the {ACL}-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics,0,"In this paper we argue that the GATE architecture and visual development environment can be used as an effective tool for teaching language engineering and computational linguistics. Since GATE comes with a customisable and extendable set of components, it allows students to get hands-on experience with building NLP applications. GATE also has tools for corpus annotation and performance evaluation, so students can go through the entire application development process within its graphical development environment. Finally, it offers comprehensive Unicode-compliant multilingual support, thus allowing students to create components for languages other than English. Unlike other NLP teaching tools which were designed specifically and only for this purpose, GATE is a system developed for and used actively in language engineering research. This unique duality allows students to contribute to research projects and gain skills in embedding HLT in practical applications."
P02-1022,{GATE}: an Architecture for Development of Robust {HLT} applications,2002,10,309,1,1,41365,hamish cunningham,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"In this paper we present GATE, a framework and graphical development environment which enables users to develop and deploy language engineering components and resources in a robust fashion. The GATE architecture has enabled us not only to develop a number of successful applications for various language processing tasks (such as Information Extraction), but also to build and annotate corpora and carry out evaluations on the applications generated. The framework can be used to develop applications and resources in multiple languages, based on its thorough Unicode support."
saggion-etal-2002-extracting,Extracting Information for Automatic Indexing of Multimedia Material,2002,12,5,2,0.680272,5986,horacio saggion,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper discusses our work on information extraction (IE) from multi-lingual, multi-media, multi-genre Language Resources, in a domain where there are many different event types. This work is being carried out in the context of MUMIS, an EU-funded project that aims at the development of basic technology for the creation of a composite index from multiple and multi-lingual sources. Our approach to IE relies on a finite state machinery provided by GATE, a General Architecture for Text Engineering, pipelined with full syntactic analysis and discourse interpretation implemented in Prolog."
tablan-etal-2002-unicode,A {U}nicode-based Environment for Creation and Use of Language Resources,2002,8,21,4,1,41364,valentin tablan,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"GATE is a Unicode-aware architecture, development environment and framework for building systems that process human language. It is often thought that the character sets problem has been solved by the arrival of the Unicode standard. This standard is an important advance, but in practice the ability to process text in a large number of the Worldxe2x80x99s languages is still limited. This paper describes work done in the context of the GATE project that makes use of Unicode and plugs some of the gaps for language processing R&D. First we look at storing and decoding of Unicode compliant linguistic resources. The new capabilities for processing textual data and taking advantage of the Unicode standard are detailed next. Finally, the solutions used to add Unicode displaying and editing capabilities for the graphical interface are described."
pastra-etal-2002-feasible,How feasible is the reuse of grammars for Named Entity Recognition?,2002,9,26,4,0,46284,katerina pastra,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"In this paper, we investigate whether reusing existing grammars for NE recognition instead of creating them from scratch is a viable solution to time constraints in developing grammars. We discuss three possible factors that hinder grammar reuse and we present our corresponding empirical results, that encourage more widespread use of valuable existing resources."
baker-etal-2002-emille,"{EMILLE}, A 67-Million Word Corpus of Indic Languages: Data Collection, Mark-up and Harmonisation",2002,10,32,4,0,53453,paul baker,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"The paper describes developments to date on the EMILLE Project (Enabling Minority Language Engineering) being carried out at the Universities of Lancaster and Sheffield. EMILLE was established to construct a 67 million word corpus of South Asian languages. In addition to undertaking this corpus construction, the project has had to address a number of related issues in the context of establishing a language engineering (LE) environment for South Asian language processing, such as translating 8-bit language data into Unicode and producing a number of basic LE tools. The development of tools on EMILLE has contributed to the on-going development of the LE architecture GATE."
W01-1004,"Using {HLT} for Acquiring, Retrieving and Publishing Knowledge in {AKT}",2001,0,3,4,1,11076,kalina bontcheva,Proceedings of the {ACL} 2001 Workshop on Human Language Technology and Knowledge Management,0,None
W01-1017,The Automatic Generation of Formal Annotations in a Multimedia Indexing and Searching Environment,2001,11,20,3,0,2109,thierry declerck,Proceedings of the {ACL} 2001 Workshop on Human Language Technology and Knowledge Management,0,"We describe in this paper the MU-MIS Project (Multimedia Indexing and Searching Environment), which is concerned with the development and integration of base technologies, demonstrated within a laboratory prototype, to support automated multimedia indexing and to facilitate search and retrieval from multimedia databases. We stress the role linguistically motivated annotations, coupled with domain-specific information, can play within this environment. The project will demonstrate that innovative technology components can operate on multilingual, multisource, and multimedia information and create a meaningful and queryable database."
W00-1501,Experience using {GATE} for {NLP} {R}{\\&}{D},2000,11,23,1,1,41365,hamish cunningham,Proceedings of the {COLING}-2000 Workshop on Using Toolsets and Architectures To Build {NLP} Systems,0,"GATE, a General Architecture for Text Engineering, aims to provide a software infrastructure for researchers and developers working in NLP. GATE has now been widely available for four years. In this paper we review the objectives which motivated the creation of GATE and the functionality and design of the current system. We discuss the strengths and weaknesses of the current system, identify areas for improvement."
W00-1503,An Experiment in Unifying Audio-Visual and Textual Infrastructures for Language Processing Research and Development,2000,2,4,3,1,11076,kalina bontcheva,Proceedings of the {COLING}-2000 Workshop on Using Toolsets and Architectures To Build {NLP} Systems,0,"This paper describes an experimental integration of two infrastructures (Eudico and GATE) which were developed independently of each other; for different media (video/speech vs. text) and applications. The integration resulted into gaining an in-depth understanding of the functionality and operation of each of the two systems in isolation, and the benefits of their combined use. It also highlighted some issues (e.g., distributed access) which need to be addressed in future work. The experiment also showed clearly the advantages of modularity and generality adopted in both systems."
cunningham-etal-2000-software,Software Infrastructure for Language Resources: a Taxonomy of Previous Work and a Requirements Analysis,2000,60,24,1,1,41365,hamish cunningham,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"This paper presents a taxonomy of previous work on infrastructures, architectures and development environments for representing and processing Language Resources (LRs), corpora, and annotations. This classification is then used to derive a set of requirements for a Software Architecture for Language Engineering (SALE). The analysis shows that a SALE should address common problems and support typical activities in the development, deployment, and maintenance of LE software. The results will be used in the next phase of construction of an infrastructure for LR production, distribution, and access."
2000.bcs-1.11,{EMILLE}: building a corpus of {S}outh {A}sian languages,2000,-1,-1,4,0,52010,anthony mcenery,Proceedings of the International Conference on Machine Translation and Multilingual Applications in the new Millennium: MT 2000,0,None
W98-1208,Implementing a Sense Tagger in a General Architecture for Text Engineering,1998,28,0,1,1,41365,hamish cunningham,New Methods in Language Processing and Computational Natural Language Learning,0,"We describe two systems: GATE (General Architecture for Text Engineering), an architecture to aid in the production and delivery of language engineering systems which significantly reduces development time and ease of reuse in such systems. We also describe a sense tagger which we implemented within the GATE architecture, and which achieves high accuracy (92% of all words in text to a broad semantic level). We used the implementation of the sense tagger as a real-world task on which to evaluate the usefulness of the GATE architecture and identified strengths and weaknesses in the architecture."
A97-2017,{GATE} - a General Architecture for Text Engineering,1997,34,126,1,1,41365,hamish cunningham,Fifth Conference on Applied Natural Language Processing: Descriptions of System Demonstrations and Videos,0,"Much progress has been made in the provision of reusable data resources for Natural Language Engineering, such as grammars, lexicons, thesauruscs. Although a number of projects have addressed the provision of reusable algorithmic resources (or 'tools'), takeup of these resources has been relatively slow. This paper describes GATE, a General Architecture for Text Engineering, which is a freely-available system designed to help alleviate the problem."
A97-1035,Software Infrastructure for Natural Language Processing,1997,9,62,1,1,41365,hamish cunningham,Fifth Conference on Applied Natural Language Processing,0,"We classify and review current approaches to software infrastructure for research, development and delivery of NLP systems. The task is motivated by a discussion of current trends in the field of NLP and Language Engineering. We describe a system called GATE (a General Architecture for Text Engineering) that provides a software infrastructure on top of which heterogeneous NLP processing modules may be evaluated and refined individually, or may be combined into larger application systems. GATE aims to support both researchers and developers working on component technologies (e.g. parsing, tagging, morphological analysis) and those working on developing end-user applications (e.g. information extraction, text summarisation, document generation, machine translation, and second language learning). GATE promotes reuse of component technology, permits specialisation and collaboration in large-scale projects, and allows for the comparison and evaluation of alternative technologies. The first release of GATE is now available."
X96-1027,{TIPSTER}-Compatible Projects at {S}heffield,1996,-1,-1,1,1,41365,hamish cunningham,"TIPSTER TEXT PROGRAM PHASE II: Proceedings of a Workshop held at Vienna, Virginia, May 6-8, 1996",0,None
C96-2187,{GATE}-a General Architecture for Text Engineering,1996,-1,-1,1,1,41365,hamish cunningham,{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics,0,None
