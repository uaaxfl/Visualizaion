2021.nodalida-main.1,{W}iki{BERT} Models: Deep Transfer Learning for Many Languages,2021,-1,-1,4,0,2607,sampo pyysalo,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"Deep neural language models such as BERT have enabled substantial recent advances in many natural language processing tasks. However, due to the effort and computational cost involved in their pre-training, such models are typically introduced only for a small number of high-resource languages such as English. While multilingual models covering large numbers of languages are available, recent work suggests monolingual training can produce better models, and our understanding of the tradeoffs between mono- and multilingual training is incomplete. In this paper, we introduce a simple, fully automated pipeline for creating language-specific BERT models from Wikipedia data and introduce 42 new such models, most for languages up to now lacking dedicated deep neural language models. We assess the merits of these models using cloze tests and the state-of-the-art UDify parser on Universal Dependencies data, contrasting performance with results using the multilingual BERT (mBERT) model. We find that the newly introduced WikiBERT models outperform mBERT in cloze tests for nearly all languages, and that UDify using WikiBERT models outperforms the parser using mBERT on average, with the language-specific models showing substantially improved performance for some languages, yet limited improvement or a decrease in performance for others. All of the methods and models introduced in this work are available under open licenses from https://github.com/turkunlp/wikibert."
2021.nodalida-main.14,Fine-grained Named Entity Annotation for {F}innish,2021,-1,-1,3,0,2645,jouni luoma,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"We introduce a corpus with fine-grained named entity annotation for Finnish, following the OntoNotes guidelines to create a resource that is cross-lingually compatible with existing annotations for other languages. We combine and extend two NER corpora recently introduced for Finnish and revise their custom annotation scheme through a combination of automatic and manual processing steps. The resulting corpus consists of nearly 500,000 tokens annotated for over 50,000 mentions categorized into the 18 OntoNotes name and numeric entity types. We evaluate this resource and demonstrate its compatibility with the English OntoNotes annotations by training state-of-the-art mono-, bi- and multilingual deep learning models, finding both that the corpus allows highly accurate recognition of OntoNotes types at 93{\%} F-score and that a comparable level of tagging accuracy can be achieved by a bilingual Finnish-English NER model."
2021.nodalida-main.29,{F}innish Paraphrase Corpus,2021,-1,-1,2,1,2608,jenna kanerva,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"In this paper, we introduce the first fully manually annotated paraphrase corpus for Finnish containing 53,572 paraphrase pairs harvested from alternative subtitles and news headings. Out of all paraphrase pairs in our corpus 98{\%} are manually classified to be paraphrases at least in their given context, if not in all contexts. Additionally, we establish a manual candidate selection method and demonstrate its feasibility in high quality paraphrase selection in terms of both cost and quality."
2021.motra-1.11,Quantitative Evaluation of Alternative Translations in a Corpus of Highly Dissimilar {F}innish Paraphrases,2021,-1,-1,4,0,2646,lihsin chang,Proceedings for the First Workshop on Modelling Translation: Translatology in the Digital Age,0,None
2020.lrec-1.470,"The {FISKM{\\\O}} Project: Resources and Tools for {F}innish-{S}wedish Machine Translation and Cross-Linguistic Research""",2020,-1,-1,6,0,2675,jorg tiedemann,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper presents FISKM{\""O}, a project that focuses on the development of resources and tools for cross-linguistic research and machine translation between Finnish and Swedish. The goal of the project is the compilation of a massive parallel corpus out of translated material collected from web sources, public and private organisations and language service providers in Finland with its two official languages. The project also aims at the development of open and freely accessible translation services for those two languages for the general purpose and for domain-specific use. We have released new data sets with over 3 million translation units, a benchmark test set for MT development, pre-trained neural MT models with high coverage and competitive performance and a self-contained MT plugin for a popular CAT tool. The latter enables offline translation without dependencies on external services making it possible to work with highly sensitive data without compromising security concerns."
2020.lrec-1.497,{U}niversal {D}ependencies v2: An Evergrowing Multilingual Treebank Collection,2020,17,3,3,0,10682,joakim nivre,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. The annotation consists in a linguistically motivated word segmentation; a morphological layer comprising lemmas, universal part-of-speech tags, and standardized morphological features; and a syntactic layer focusing on syntactic relations between predicates, arguments and modifiers. In this paper, we describe version 2 of the universal guidelines (UD v2), discuss the major changes from UD v1 to UD v2, and give an overview of the currently available treebanks for 90 languages."
2020.iwpt-1.17,{T}urku Enhanced Parser Pipeline: From Raw Text to Enhanced Graphs in the {IWPT} 2020 Shared Task,2020,-1,-1,2,1,2608,jenna kanerva,Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies,0,"We present the approach of the TurkuNLP group to the IWPT 2020 shared task on Multilingual Parsing into Enhanced Universal Dependencies. The task involves 28 treebanks in 17 different languages and requires parsers to generate graph structures extending on the basic dependency trees. Our approach combines language-specific BERT models, the UDify parser, neural sequence-to-sequence lemmatization and a graph transformation approach encoding the enhanced structure into a dependency tree. Our submission averaged 84.5{\%} ELAS, ranking first in the shared task. We make all methods and resources developed for this study freely available under open licenses from https://turkunlp.org."
W19-6204,Is Multilingual {BERT} Fluent in Language Generation?,2019,6,5,4,0,2649,samuel ronnqvist,Proceedings of the First NLPL Workshop on Deep Learning for Natural Language Processing,0,"The multilingual BERT model is trained on 104 languages and meant to serve as a universal language model and tool for encoding sentences. We explore how well the model performs on several languages across several tasks: a diagnostic classification probing the embeddings for a particular syntactic property, a cloze task testing the language modelling ability to fill in gaps in a sentence, and a natural language generation task testing for the ability to produce coherent text fitting a given context. We find that the currently available multilingual BERT model is clearly inferior to the monolingual counterparts, and cannot in many cases serve as a substitute for a well-trained monolingual model. We find that the English and German models perform well at generation, whereas the multilingual model is lacking, in particular, for Nordic languages. The code of the experiments in the paper is available at: https://github.com/TurkuNLP/bert-eval"
W19-6125,Template-free Data-to-Text Generation of {F}innish Sports News,2019,24,0,5,1,2608,jenna kanerva,Proceedings of the 22nd Nordic Conference on Computational Linguistics,0,"News articles such as sports game reports are often thought to closely follow the underlying game statistics, but in practice they contain a notable amount of background knowledge, interpretation, insight into the game, and quotes that are not present in the official statistics. This poses a challenge for automated data-to-text news generation with real-world news corpora as training data. We report on the development of a corpus of Finnish ice hockey news, edited to be suitable for training of end-to-end news generation methods, as well as demonstrate generation of text, which was judged by journalists to be relatively close to a viable product. The new dataset and system source code are available for research purposes."
D19-5728,Neural Dependency Parsing of Biomedical Text: {T}urku{NLP} entry in the {CRAFT} Structural Annotation Task,2019,0,0,3,0,26540,thang ngo,Proceedings of The 5th Workshop on BioNLP Open Shared Tasks,0,"We present the approach taken by the TurkuNLP group in the CRAFT Structural Annotation task, a shared task on dependency parsing. Our approach builds primarily on the Turku neural parser, a native dependency parser that ranked among the best in the recent CoNLL tasks on parsing Universal Dependencies. To adapt the parser to the biomedical domain, we considered and evaluated a number of approaches, including the generation of custom word embeddings, combination with other in-domain resources, and the incorporation of information from named entity recognition. We achieved a labeled attachment score of 89.7{\%}, the best result among task participants."
W18-6006,Mind the Gap: Data Enrichment in Dependency Parsing of Elliptical Constructions,2018,0,1,2,0,23458,kira droganova,Proceedings of the Second Workshop on Universal Dependencies ({UDW} 2018),0,"In this paper, we focus on parsing rare and non-trivial constructions, in particular ellipsis. We report on several experiments in enrichment of training data for this specific construction, evaluated on five languages: Czech, English, Finnish, Russian and Slovak. These data enrichment methods draw upon self-training and tri-training, combined with a stratified sampling method mimicking the structural complexity of the original treebank. In addition, using these same methods, we also demonstrate small improvements over the CoNLL-17 parsing shared task winning system for four of the five languages, not only restricted to the elliptical constructions."
W18-6012,Enhancing {U}niversal {D}ependency Treebanks: A Case Study,2018,0,4,3,0,10682,joakim nivre,Proceedings of the Second Workshop on Universal Dependencies ({UDW} 2018),0,"We evaluate two cross-lingual techniques for adding enhanced dependencies to existing treebanks in Universal Dependencies. We apply a rule-based system developed for English and a data-driven system trained on Finnish to Swedish and Italian. We find that both systems are accurate enough to bootstrap enhanced dependencies in existing UD treebanks. In the case of Italian, results are even on par with those of a prototype language-specific system."
W18-5611,Evaluation of a Prototype System that Automatically Assigns Subject Headings to Nursing Narratives Using Recurrent Neural Network,2018,0,0,7,1,23682,hans moen,Proceedings of the Ninth International Workshop on Health Text Mining and Information Analysis,0,"We present our initial evaluation of a prototype system designed to assist nurses in assigning subject headings to nursing narratives {--} written in the context of documenting patient care in hospitals. Currently nurses may need to memorize several hundred subject headings from standardized nursing terminologies when structuring and assigning the right section/subject headings to their text. Our aim is to allow nurses to write in a narrative manner without having to plan and structure the text with respect to sections and subject headings, instead the system should assist with the assignment of subject headings and restructuring afterwards. We hypothesize that this could reduce the time and effort needed for nursing documentation in hospitals. A central component of the system is a text classification model based on a long short-term memory (LSTM) recurrent neural network architecture, trained on a large data set of nursing notes. A simple Web-based interface has been implemented for user interaction. To evaluate the system, three nurses write a set of artificial nursing shift notes in a fully unstructured narrative manner, without planning for or consider the use of sections and subject headings. These are then fed to the system which assigns subject headings to each sentence and then groups them into paragraphs. Manual evaluation is conducted by a group of nurses. The results show that about 70{\%} of the sentences are assigned to correct subject headings. The nurses believe that such a system can be of great help in making nursing documentation in hospitals easier and less time consuming. Finally, various measures and approaches for improving the system are discussed."
L18-1290,Parse Me if You Can: Artificial Treebanks for Parsing Experiments on Elliptical Constructions,2018,0,0,4,0,23458,kira droganova,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
K18-2001,{C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to {U}niversal {D}ependencies,2018,0,1,6,0,5828,daniel zeman,Proceedings of the {C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"Every year, the Conference on Computational Natural Language Learning (CoNLL) features a shared task, in which participants train and test their learning systems on the same data sets. In 2018, one of two tasks was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on test input. All test sets followed a unified annotation scheme, namely that of Universal Dependencies. This shared task constitutes a 2nd edition{---}the first one took place in 2017 (Zeman et al., 2017); the main metric from 2017 has been kept, allowing for easy comparison, also in 2018, and two new main metrics have been used. New datasets added to the Universal Dependencies collection between mid-2017 and the spring of 2018 have contributed to increased difficulty of the task this year. In this overview paper, we define the task and the updated evaluation methodology, describe data preparation, report and analyze the main results, and provide a brief categorization of the different approaches of the participating systems."
K18-2013,{T}urku Neural Parser Pipeline: An End-to-End System for the {C}o{NLL} 2018 Shared Task,2018,0,10,2,1,2608,jenna kanerva,Proceedings of the {C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"In this paper we describe the TurkuNLP entry at the CoNLL 2018 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies. Compared to the last year, this year the shared task includes two new main metrics to measure the morphological tagging and lemmatization accuracies in addition to syntactic trees. Basing our motivation into these new metrics, we developed an end-to-end parsing pipeline especially focusing on developing a novel and state-of-the-art component for lemmatization. Our system reached the highest aggregate ranking on three main metrics out of 26 teams by achieving 1st place on metric involving lemmatization, and 2nd on both morphological tagging and parsing."
W17-6511,Fully Delexicalized Contexts for Syntax-Based Word Embeddings,2017,23,0,3,1,2608,jenna kanerva,Proceedings of the Fourth International Conference on Dependency Linguistics (Depling 2017),0,None
W17-6514,Assessing the Annotation Consistency of the {U}niversal {D}ependencies Corpora,2017,12,0,4,0,4403,mariecatherine marneffe,Proceedings of the Fourth International Conference on Dependency Linguistics (Depling 2017),0,None
W17-4808,Cross-Lingual Pronoun Prediction with Deep Recurrent Neural Networks v2.0,2017,0,0,3,1,14166,juhani luotolahti,Proceedings of the Third Workshop on Discourse in Machine Translation,0,"In this paper we present our system in the DiscoMT 2017 Shared Task on Crosslingual Pronoun Prediction. Our entry builds on our last year{'}s success, our system based on deep recurrent neural networks outperformed all the other systems with a clear margin. This year we investigate whether different pre-trained word embeddings can be used to improve the neural systems, and whether the recently published Gated Convolutions outperform the Gated Recurrent Units used last year."
W17-2310,End-to-End System for Bacteria Habitat Extraction,2017,16,6,6,1,31930,farrokh mehryary,{B}io{NLP} 2017,0,"We introduce an end-to-end system capable of named-entity detection, normalization and relation extraction for extracting information about bacteria and their habitats from biomedical literature. Our system is based on deep learning, CRF classifiers and vector space models. We train and evaluate the system on the BioNLP 2016 Shared Task Bacteria Biotope data. The official evaluation shows that the joint performance of our entity detection and relation extraction models outperforms the winning team of the Shared Task by 19pp on F1-score, establishing a new top score for the task. We also achieve state-of-the-art results in the normalization task. Our system is open source and freely available at \url{https://github.com/TurkuNLP/BHE}."
W17-2347,Detecting mentions of pain and acute confusion in {F}innish clinical text,2017,-1,-1,6,1,23682,hans moen,{B}io{NLP} 2017,0,"We study and compare two different approaches to the task of automatic assignment of predefined classes to clinical free-text narratives. In the first approach this is treated as a traditional mention-level named-entity recognition task, while the second approach treats it as a sentence-level multi-label classification task. Performance comparison across these two approaches is conducted in the form of sentence-level evaluation and state-of-the-art methods for both approaches are evaluated. The experiments are done on two data sets consisting of Finnish clinical text, manually annotated with respect to the topics pain and acute confusion. Our results suggest that the mention-level named-entity recognition approach outperforms sentence-level classification overall, but the latter approach still manages to achieve the best prediction scores on several annotation classes."
W17-0510,"Applying {BLAST} to Text Reuse Detection in {F}innish Newspapers and Journals, 1771-1910",2017,-1,-1,6,0,32145,aleksi vesanto,Proceedings of the {N}o{D}a{L}i{D}a 2017 Workshop on Processing Historical Language,0,None
W17-0218,Creating register sub-corpora for the {F}innish {I}nternet Parsebank,2017,12,0,5,1,2652,veronika laippala,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
W17-0233,{D}ep{\\_}search: Efficient Search Tool for Large Dependency Parsebanks,2017,0,0,3,1,14166,juhani luotolahti,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
W17-0249,A System for Identifying and Exploring Text Repetition in Large Historical Document Corpora,2017,4,1,2,0,32145,aleksi vesanto,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
K17-3001,{C}o{NLL} 2017 Shared Task: Multilingual Parsing from Raw Text to {U}niversal {D}ependencies,2017,28,32,6,0,5828,daniel zeman,Proceedings of the {C}o{NLL} 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"The Conference on Computational Natural Language Learning (CoNLL) features a shared task, in which participants train and test their learning systems on the same data sets. In 2017, the task was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on input. All test sets followed a unified annotation scheme, namely that of Universal Dependencies. In this paper, we define the task and evaluation methodology, describe how the data sets were prepared, report and analyze the main results, and provide a brief categorization of the different approaches of the participating systems."
K17-3012,{T}urku{NLP}: Delexicalized Pre-training of Word Embeddings for Dependency Parsing,2017,4,1,3,1,2608,jenna kanerva,Proceedings of the {C}o{NLL} 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"We present the TurkuNLP entry in the CoNLL 2017 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies. The system is based on the UDPipe parser with our focus being in exploring various techniques to pre-train the word embeddings used by the parser in order to improve its performance especially on languages with small training sets. The system ranked 11th among the 33 participants overall, being 8th on the small treebanks, 10th on the large treebanks, 12th on the parallel test sets, and 26th on the surprise languages."
E17-5001,{U}niversal {D}ependencies,2017,0,3,3,0,10682,joakim nivre,Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Tutorial Abstracts,0,"Universal Dependencies (UD) is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages. This tutorial gives an introduction to the UD framework and resources, from basic design principles to annotation guidelines and existing treebanks. We also discuss tools for developing and exploiting UD treebanks and survey applications of UD in NLP and linguistics."
W16-3009,Deep Learning with Minimal Training Data: {T}urku{NLP} Entry in the {B}io{NLP} Shared Task 2016,2016,0,20,5,1,31930,farrokh mehryary,Proceedings of the 4th {B}io{NLP} Shared Task Workshop,0,None
W16-2913,Syntactic analyses and named entity recognition for {P}ub{M}ed and {P}ub{M}ed Central {---} up-to-the-minute,2016,21,8,4,1,26510,kai hakala,Proceedings of the 15th Workshop on Biomedical Natural Language Processing,0,"Although advanced text mining methods specifically adapted to the biomedical domain are continuously being developed, their applications on large scale have been scarce. One of the main reasons for this is the lack of computational resources and workforce required for processing large text corpora. In this paper we present a publicly available resource distributing preprocessed biomedical literature including sentence splitting, tokenization, part-of-speech tagging, syntactic parses and named entity recognition. The aim of this work is to support the future development of largescale text mining resources by eliminating the time consuming but necessary preprocessing steps. This resource covers the whole of PubMed and PubMed Central Open Access section, currently containing 26M abstracts and 1.4M full articles, constituting over 388M analyzed sentences. The resource is based on a fully automated pipeline, guaranteeing that the distributed data is always up-to-date. The resource is available at https://turkunlp. github.io/pubmed_parses/."
W16-2326,"Phrase-Based {SMT} for {F}innish with More Data, Better Models and Alternative Alignment and Translation Tools",2016,27,3,4,0,2675,jorg tiedemann,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper summarises the contributions of the teams at the University of Helsinki, Uppsala University and the University of Turku to the news translation tasks for translating from and to Finnish. Our models address the problem of treating morphology and data coverage in various ways. We introduce a new efficient tool for word alignment and discuss factorisations, gappy language models and reinflection techniques for generating proper Finnish output. The results demonstrate once again that training data is the most effective way to increase translation performance."
W16-2353,Cross-Lingual Pronoun Prediction with Deep Recurrent Neural Networks,2016,8,3,3,1,14166,juhani luotolahti,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"In this paper we present our winning system in the WMT16 Shared Task on CrossLingual Pronoun Prediction, where the objective is to predict a missing target language pronoun based on the target and source sentences. Our system is a deep recurrent neural network, which reads both the source language and target language context with a softmax layer making the final prediction. Our system achieves the best macro recall on all four language pairs. The margin to the next best system ranges between less than 1pp and almost 12pp depending on the language pair."
L16-1262,{U}niversal {D}ependencies v1: A Multilingual Treebank Collection,2016,0,257,3,0,10682,joakim nivre,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages."
L16-1374,{U}niversal {D}ependencies for {P}ersian,2016,8,4,2,0,35106,mojgan seraji,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"The Persian Universal Dependency Treebank (Persian UD) is a recent effort of treebanking Persian with Universal Dependencies (UD), an ongoing project that designs unified and cross-linguistically valid grammatical representations including part-of-speech tags, morphological features, and dependency relations. The Persian UD is the converted version of the Uppsala Persian Dependency Treebank (UPDT) to the universal dependencies framework and consists of nearly 6,000 sentences and 152,871 word tokens with an average sentence length of 25 words. In addition to the universal dependencies syntactic annotation guidelines, the two treebanks differ in tokenization. All words containing unsegmented clitics (pronominal and copula clitics) annotated with complex labels in the UPDT have been separated from the clitics and appear with distinct labels in the Persian UD. The treebank has its original syntactic annotation scheme based on Stanford Typed Dependencies. In this paper, we present the approaches taken in the development of the Persian UD."
W15-3021,Morphological Segmentation and {OPUS} for {F}innish-{E}nglish Machine Translation,2015,16,5,2,0,2675,jorg tiedemann,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,This paper describes baseline systems for Finnish-English and English-Finnish machine translation using standard phrasebased and factored models including morphological features. We experiment with compound splitting and morphological segmentation and study the effect of adding noisy out-of-domain data to the parallel and the monolingual training data. Our results stress the importance of training data and demonstrate the effectiveness of morphological pre-processing of Finnish.
W15-2124,Towards Universal Web Parsebanks,2015,25,4,5,1,14166,juhani luotolahti,Proceedings of the Third International Conference on Dependency Linguistics (Depling 2015),0,"Recently, there has been great interest both in the development of cross-linguistically applicable annotation schemes and in the application of syntactic parsers at web scale to create parsebanks of online texts. The combination of these two trends to create massive, consistently annotated parsebanks in many languages holds enormous potential for the quantitative study of many linguistic phenomena, but these opportunities have been only partially realized in previous work. In this work, we take a key step toward universal web parsebanks through a single-language case study introducing the first retrainable parser applied to the Universal Dependencies representation and its application to create a Finnish web-scale parsebank. We further integrate this data into an online dependency search system and demonstrate its applicability by showing linguistically motivated search examples and by using the dependency syntax information to analyze the language of the web corpus. We conclude with a discussion of the requirements of extending from this case study on Finnish to create consistently annotated web-scale parsebanks for a large number of languages."
W15-1815,Towards the Classification of the {F}innish {I}nternet Parsebank: Detecting Translations and Informality,2015,22,0,6,1,2652,veronika laippala,Proceedings of the 20th Nordic Conference of Computational Linguistics ({NODALIDA} 2015),0,"This paper presents the first results on detecting informality, machine and human translations in the Finnish Internet Parsebank, a project developing a large-scale, web-based corpus with full morphological and syntactic analyses. The paper aims at classifying the Parsebank according to these criteria, as well as studying the linguistic characteristics of the classes. The features used include both lexical and morpho-syntactic properties, such as syntactic n-grams. The results are practically applicable, with an AUC range of 85xe2x80x9085% for the human, 98% for the machine translated texts and 73% for the informal texts. While word-based classification performs well for the indomain experiments, delexicalized methods with morpho-syntactic features prove to be more tolerant to variation caused by genre or source language. In addition, the results show that the features used in the classification provide interesting pointers for further, more detailed studies on the linguistic characteristics of these texts."
W15-1818,Sentence Compression For Automatic Subtitling,2015,13,0,2,1,14166,juhani luotolahti,Proceedings of the 20th Nordic Conference of Computational Linguistics ({NODALIDA} 2015),0,"This paper investigates sentence compression for automatic subtitle generation using supervised machine learning. We present a method for sentence compression as well as discuss generation of training data from compressed Finnish sentences, and different approaches to the problem. The method we present outperforms state-of-the-art baseline in both automatic and human evaluation. On real data, 44.9% of the sentences produced by the compression algorithm have been judged to be useable as-is or after minor edits."
W15-1821,{U}niversal {D}ependencies for {F}innish,2015,22,9,5,0.355436,2607,sampo pyysalo,Proceedings of the 20th Nordic Conference of Computational Linguistics ({NODALIDA} 2015),0,"There has been substantial recent interest in annotation schemes that can be applied consistently to many languages. Building on several recent efforts to unify morphological and syntactic annotation, the Universal Dependencies (UD) project seeks to introduce a cross-linguistically applicable part-of-speech tagset, feature inventory, and set of dependency relations as well as a large number of uniformly annotated treebanks. We present Universal Dependencies for Finnish, one of the ten languages in the recent first release of UD project treebank data. We detail the mapping of previously introduced annotation to the UD standard, describing specific challenges and their resolution. We additionally present parsing experiments comparing the performance of a stateof-the-art parser trained on a languagespecific annotation schema to performance on the corresponding UD annotation. The results show improvement compared to the source annotation, indicating that the conversion is accurate and supporting the feasibility of UD as a parsing target. The introduced tools and resources are available under open licenses from http://bionlp.utu.fi/ud-finnish.html."
S15-2161,{T}urku: Semantic Dependency Parsing as a Sequence Classification,2015,19,0,3,1,2608,jenna kanerva,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper presents the University of Turku entry to the SemEval-2015 task on BroadCoverage Semantic Dependency Parsing. The system uses an existing transition-based parser as a sequence classifier to jointly predict all arguments of one candidate predicate at a time. Compared to our 2014 entry, the 2015 system gains about 3pp in terms of F-score for a fraction of the development time. Depending on the subtask, the difference between our entry and the winning system ranges between 1 and 5pp."
P15-4016,Sharing annotations better: {REST}ful Open Annotation,2015,21,6,4,0.355436,2607,sampo pyysalo,Proceedings of {ACL}-{IJCNLP} 2015 System Demonstrations,0,"Annotations are increasingly created and shared online and connected with web resources such as databases of real-world entities. Recent collaborative efforts to provide interoperability between online annotation tools and resources have introduced the Open Annotation (OA) model, a general framework for representing annotations based on web standards. Building on the OA model, we propose to share annotations over a minimal web interface that conforms to the Representational State Transfer architectural style and uses the JSON for Linking Data representation (JSON-LD). We introduce tools supporting this approach and apply it to several existing annotation clients and servers, demonstrating direct interoperability between tools and resources that were previously unable to exchange information. The specification and tools are available from http://restoa.github.io/."
N15-3011,{SETS}: Scalable and Efficient Tree Search in Dependency Graphs,2015,3,5,4,1,14166,juhani luotolahti,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations,0,"We present a syntactic analysis query toolkit geared specifically towards massive dependency parsebanks and morphologically rich languages. The query language allows arbitrary tree queries, including negated branches, and is suitable for querying analyses with rich morphological annotation. Treebanks of over a million words can be comfortably queried on a low-end netbook, and a parsebank with over 100M words on a single consumer-grade server. We also introduce a web-based interface for interactive querying. All contributions are available under open licenses."
W14-1501,Post-hoc Manipulations of Vector Space Models with Application to Semantic Role Labeling,2014,22,9,2,1,2608,jenna kanerva,Proceedings of the 2nd Workshop on Continuous Vector Space Models and their Compositionality ({CVSC}),0,"In this paper, we introduce several vector space manipulation methods that are applied to trained vector space models in a post-hoc fashion, and present an application of these techniques in semantic role labeling for Finnish and English. Specifically, we show that the vectors can be circularly shifted to encode syntactic information and subsequently averaged to produce representations of predicate senses and arguments. Further, we show that it is possible to effectively learn a linear transformation between the vector representations of predicates and their arguments, within the same vector space."
W14-1118,Care Episode Retrieval,2014,18,4,3,1,23682,hans moen,Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi),0,"The documentation of a care episode consists of clinical notes concerning patient care, concluded with a discharge summary. Care episodes are stored electronically and used throughout the health care sector by patients, administrators and professionals from different areas, primarily for clinical purposes, but also for secondary purposes such as decision support and research. A common use case is, given a xe2x80x93 possibly unfinished xe2x80x93 care episode, to retrieve the most similar care episodes among the records. This paper presents several methods for information retrieval, focusing on care episode retrieval, based on textual similarity, where similarity is measured through domain-specific modelling of the distributional semantics of words. Models include variants of random indexing and a semantic neural network model called word2vec. A novel method is introduced that utilizes the ICD-10 codes attached to care episodes to better induce domain-specificity in the semantic model. We report on an experimental evaluation of care episode retrieval that circumvents the lack of human judgements regarding episode relevance by exploiting (1) ICD10 codes of care episodes and (2) semantic similarity between their discharge summaries. Results suggest that several of the methods proposed outperform a state-ofthe art search engine (Lucene) on the retrieval task."
S14-2121,{T}urku: Broad-Coverage Semantic Parsing with Rich Features,2014,10,4,3,1,2608,jenna kanerva,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"In this paper we introduce our system capable of producing semantic parses of sentences using three different annotation formats. The system was used to participate in the SemEval-2014 Shared Task on broad-coverage semantic dependency parsing and it was ranked third with an overall F1-score of 80.49%. The system has a pipeline architecture, consisting of three separate supervised classification steps."
S14-2143,{UTU}: Disease Mention Recognition and Normalization with {CRF}s and Vector Space Representations,2014,8,7,3,1,31931,suwisa kaewphan,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"In this paper we present our system participating in the SemEval-2014 Task 7 in both subtasks A and B, aiming at recognizing and normalizing disease and symptom mentions from electronic medical records respectively. In subtask A, we used an existing NER system, NERsuite, with our own feature set tailored for this task. For subtask B, we combined word vector representations and supervised machine learning to map the recognized mentions to the corresponding UMLS concepts. Our system was placed 2nd and 5th out of 21 participants on subtasks A and B respectively showing competitive performance."
de-marneffe-etal-2014-universal,Universal {S}tanford dependencies: A cross-linguistic typology,2014,29,189,5,0.205466,4403,mariecatherine marneffe,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Revisiting the now de facto standard Stanford dependency representation, we propose an improved taxonomy to capture grammatical relations across languages, including morphologically rich ones. We suggest a two-layered taxonomy: a set of broadly attested universal grammatical relations, to which language-specific relations can be added. We emphasize the lexicalist stance of the Stanford Dependencies, which leads to a particular, partially new treatment of compounding, prepositions, and morphology. We show how existing dependency schemes for several languages map onto the universal taxonomy proposed here and close with consideration of practical implications of dependency representation choices for NLP applications, in particular parsing."
W13-5609,Towards a Dependency-Based {P}rop{B}ank of General {F}innish,2013,20,5,9,1,39309,katri haverinen,Proceedings of the 19th Nordic Conference of Computational Linguistics ({NODALIDA} 2013),0,"In this work, we present the first results of a project aiming at a Finnish Proposition Bank, an annotated corpus of semantic roles. The annotation is based on an existing treebank of Finnish, the Turku Dependency Treebank, annotated using the well-known Stanford Dependency scheme. We describe the use of the dependency treebank for PropBanking purposes and show that both annotation layers present in the treebank are highly useful for the annotation of semantic roles. We also discuss the specific features of Finnish influencing the development of a PropBank as well as the methods employed in the annotation, and finally, we present preliminary evaluation of the annotation quality."
W13-5626,Building a Large Automatically Parsed Corpus of {F}innish,2013,9,1,1,1,2610,filip ginter,Proceedings of the 19th Nordic Conference of Computational Linguistics ({NODALIDA} 2013),0,"We describe the methods and resources used to build FinnTreeBank-3, a 76.4 million token corpus of Finnish with automatically produced morphological and dependency syntax analyses. Starting from a definition of the target dependency scheme, we show how existing resources are transformed to conform to this definition and subsequently used to develop a parsing pipeline capable of processing a large-scale corpus. An independent formal evaluation demonstrates high accuracy of both morphological and syntactic annotation layers. The parsed corpus is freely available within the FIN-CLARIN infrastructure project."
W13-3728,Predicting Conjunct Propagation and Other Extended {S}tanford Dependencies,2013,27,7,5,0,40504,jenna nyblom,Proceedings of the Second International Conference on Dependency Linguistics ({D}ep{L}ing 2013),0,"In this work, we present a data-driven method to enhance syntax trees with additional dependencies as defined in the wellknown Stanford Dependencies scheme, so as to give more information about the structure of the sentence. This hybrid method utilizes both machine learning and a rule-based approach, and achieves a performance of 93.1% in F1-score, as evaluated using an existing treebank of Finnish. The resulting tool will be integrated into an existing Finnish parser and made publicly available at the address http://bionlp.utu.fi/."
W13-2004,{EVEX} in {ST}{'}13: Application of a large-scale text mining resource to event extraction and network construction,2013,17,27,5,1,26510,kai hakala,Proceedings of the {B}io{NLP} Shared Task 2013 Workshop,0,"During the past few years, several novel text mining algorithms have been developed in the context of the BioNLP Shared Tasks on Event Extraction. These algorithms typically aim at extracting biomolecular interactions from text by inspecting only the context of one sentence. However, when humans interpret biomolecular research articles, they usually build upon extensive background knowledge of their favorite genes and pathways. To make such world knowledge available to a text mining algorithm, it could first be applied to all available literature to subsequently make a more informed decision on which predictions are consistent with the current known data. In this paper, we introduce our participation in the latest Shared Task using the largescale text mining resource EVEX which we previously implemented using state-ofthe-art algorithms, and which was applied to the whole of PubMed and PubMed Central. We participated in the Genia Event Extraction (GE) and Gene Regulation Network (GRN) tasks, ranking first in the former and fifth in the latter."
W13-1908,Evaluating Large-scale Text Mining Applications Beyond the Traditional Numeric Performance Measures,2013,19,2,3,1,40987,sofie landeghem,Proceedings of the 2013 Workshop on Biomedical Natural Language Processing,0,"Text mining methods for the biomedical domain have matured substantially and are currently being applied on a large scale to support a variety of applications in systems biology, pathway curation, data integration and gene summarization. Community-wide challenges in the BioNLP research field provide goldstandard datasets and rigorous evaluation criteria, allowing for a meaningful comparison between techniques as well as measuring progress within the field. However, such evaluations are typically conducted on relatively small training and test datasets. On a larger scale, systematic erratic behaviour may occur that severely influences hundreds of thousands of predictions. In this work, we perform a critical assessment of a large-scale text mining resource, identifying systematic errors and determining their underlying causes through semi-automated analyses and manual evaluations 1 ."
Q13-1034,Joint Morphological and Syntactic Analysis for Richly Inflected Languages,2013,50,49,5,0,16528,bernd bohnet,Transactions of the Association for Computational Linguistics,0,"Joint morphological and syntactic analysis has been proposed as a way of improving parsing accuracy for richly inflected languages. Starting from a transition-based model for joint part-of-speech tagging and dependency parsing, we explore different ways of integrating morphological features into the model. We also investigate the use of rule-based morphological analyzers to provide hard or soft lexical constraints and the use of word clusters to tackle the sparsity of lexical features. Evaluation on five morphologically rich languages (Czech, Finnish, German, Hungarian, and Russian) shows consistent improvements in both morphological and syntactic accuracy for joint prediction over a pipeline model, with further improvements thanks to lexical constraints and word clusters. The final results improve the state of the art in dependency parsing for all languages."
W12-2410,"{P}ub{M}ed-Scale Event Extraction for Post-Translational Modifications, Epigenetics and Protein Structural Relations",2012,35,10,5,1,28457,jari bjorne,{B}io{NLP}: Proceedings of the 2012 Workshop on Biomedical Natural Language Processing,0,"Recent efforts in biomolecular event extraction have mainly focused on core event types involving genes and proteins, such as gene expression, protein-protein interactions, and protein catabolism. The BioNLP'11 Shared Task extended the event extraction approach to sub-protein events and relations in the Epigenetics and Post-translational Modifications (EPI) and Protein Relations (REL) tasks. In this study, we apply the Turku Event Extraction System, the best-performing system for these tasks, to all PubMed abstracts and all available PMC full-text articles, extracting 1.4M EPI events and 2.2M REL relations from 21M abstracts and 372K articles. We introduce several entity normalization algorithms for genes, proteins, protein complexes and protein components, aiming to uniquely identify these biological entities. This normalization effort allows direct mapping of the extracted events and relations with post-translational modifications from UniProt, epigenetics from PubMeth, functional domains from InterPro and macromolecular structures from PDB. The extraction of such detailed protein information provides a unique text mining dataset, offering the opportunity to further deepen the information provided by existing PubMed-scale event extraction efforts. The methods and data introduced in this study are freely available from bionlp.utu.fi."
W11-0204,{EVEX}: A {P}ub{M}ed-Scale Resource for Homology-Based Generalization of Text Mining Predictions,2011,21,31,2,1,40987,sofie landeghem,Proceedings of {B}io{NLP} 2011 Workshop,0,"In comparative genomics, functional annotations are transferred from one organism to another relying on sequence similarity. With more than 20 million citations in PubMed, text mining provides the ideal tool for generating additional large-scale homology-based predictions. To this end, we have refined a recent dataset of biomolecular events extracted from text, and integrated these predictions with records from public gene databases. Accounting for lexical variation of gene symbols, we have implemented a disambiguation algorithm that uniquely links the arguments of 11.2 million biomolecular events to well-defined gene families, providing interesting opportunities for query expansion and hypothesis generation. The resulting MySQL database, including all 19.2 million original events as well as their homology-based variants, is publicly available at http://bionlp.utu.fi/."
W10-1904,Scaling up Biomedical Event Extraction to the Entire {P}ub{M}ed,2010,20,27,2,1,28457,jari bjorne,Proceedings of the 2010 Workshop on Biomedical Natural Language Processing,0,"We present the first full-scale event extraction experiment covering the titles and abstracts of all PubMed citations. Extraction is performed using a pipeline composed of state-of-the-art methods: the BANNER named entity recognizer, the McClosky-Charniak domain-adapted parser, and the Turku Event Extraction System. We analyze the statistical properties of the resulting dataset and present evaluations of the core event extraction as well as negation and speculation detection components of the system. Further, we study in detail the set of extracted events relevant to the apoptosis pathway to gain insight into the biological relevance of the result. The dataset, consisting of 19.2 million occurrences of 4.5 million unique events, is freely available for use in research at http://bionlp.utu.fi/."
W10-1819,Dependency-Based {P}rop{B}anking of Clinical {F}innish,2010,16,11,2,1,39309,katri haverinen,Proceedings of the Fourth Linguistic Annotation Workshop,0,"In this paper, we present a PropBank of clinical Finnish, an annotated corpus of verbal propositions and arguments. The clinical PropBank is created on top of a previously existing dependency treebank annotated in the Stanford Dependency (SD) scheme and covers 90% of all verb occurrences in the treebank.n n We establish that the PropBank scheme is applicable to clinical Finnish as well as compatible with the SD scheme, with an overwhelming proportion of arguments being governed by the verb. This allows argument candidates to be restricted to direct verb dependents, substantially simplifying the PropBank construction.n n The clinical Finnish PropBank is freely available at the address http://bionlp.utu.fi."
W09-4605,Learning to Extract Biological Event and Relation Graphs,2009,24,5,2,1,28457,jari bjorne,Proceedings of the 17th Nordic Conference of Computational Linguistics ({NODALIDA} 2009),0,"While the overwhelming majority of information extraction efforts in the biomedical domain have focused on the extraction of simple binary interactions between named entity pairs, some recently published corpora provide complex, nested and typed event annotations that aim to accurately capture the diversity of biological relationships. We present the first machine learning approach for extracting such relationships, utilizing both a graph kernel and a novel, task-specific feature set. We show that relationships can be predicted with 77% F-score, or 83% if their type and direction is disregarded. Using both gold standard and generated parses, we determine the impact of parsing on extraction performance. Finally, we convert our predicted complex relationships to binary interactions, recovering binary annotation with 62% F-score, relating the new method to the large body of work available on binary interactions."
W09-4611,Parsing Clinical {F}innish: Experiments with Rule-Based and Statistical Dependency Parsers,2009,15,9,2,1,39309,katri haverinen,Proceedings of the 17th Nordic Conference of Computational Linguistics ({NODALIDA} 2009),0,"In this paper, we present a new syntactically annotated corpus consisting of daily notes from an intensive care unit in a Finnish hospital. Using the corpus, we perform experiments with both rule-based and statistical parsers. We apply an existing rule-based parser specifically developed for this clinical language and create a set of conversion rules for transforming the constituency scheme of this parser into the dependency scheme of the corpus. The statistical parser is induced from the corpus using the MaltParser system. We find that even with a modestly-sized corpus, the statistical parser achieves results comparable to those previously reported on a number of languages using considerably larger corpora. The accurate constituency-to-dependency conversion improves the applicability of the rule-based parser by inferring grammatical roles, thus deepening its analyses."
W09-1402,Extracting Complex Biological Events with Rich Graph-Based Feature Sets,2009,17,163,3,1,28457,jari bjorne,Proceedings of the {B}io{NLP} 2009 Workshop Companion Volume for Shared Task,0,"We describe a system for extracting complex events among genes and proteins from biomedical literature, developed in context of the BioNLP'09 Shared Task on Event Extraction. For each event, its text trigger, class, and arguments are extracted. In contrast to the prevailing approaches in the domain, events can be arguments of other events, resulting in a nested structure that better captures the underlying biological statements. We divide the task into independent steps which we approach as machine learning problems. We define a wide array of features and in particular make extensive use of dependency parse graphs. A rule-based post-processing step is used to refine the output in accordance with the restrictions of the extraction task. In the shared task evaluation, the system achieved an F-score of 51.95% on the primary task, the best performance among the participants."
W08-0601,A Graph Kernel for Protein-Protein Interaction Extraction,2008,24,72,5,0,47007,antti airola,Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing,0,"In this paper, we propose a graph kernel based approach for the automated extraction of protein-protein interactions (PPI) from scientific literature. In contrast to earlier approaches to PPI extraction, the introduced all-dependency-paths kernel has the capability to consider full, general dependency graphs. We evaluate the proposed method across five publicly available PPI corpora providing the most comprehensive evaluation done for a machine learning based PPI-extraction system. Our method is shown to achieve state-of-the-art performance with respect to comparable evaluations, achieving 56.4 F-score and 84.8 AUC on the AImed corpus. Further, we identify several pitfalls that can make evaluations of PPI-extraction systems incomparable, or even invalid. These include incorrect cross-validation strategies and problems related to comparing F-score results achieved on different evaluation resources."
W07-1004,On the unification of syntactic annotations under the {S}tanford dependency scheme: A case study on {B}io{I}nfer and {GENIA},2007,19,29,2,1,2607,sampo pyysalo,"Biological, translational, and clinical language processing",0,"Several incompatible syntactic annotation schemes are currently used by parsers and corpora in biomedical information extraction. The recently introduced Stanford dependency scheme has been suggested to be a suitable unifying syntax formalism. In this paper, we present a step towards such unification by creating a conversion from the Link Grammar to the Stanford scheme. Further, we create a version of the BioInfer corpus with syntactic annotation in this scheme. We present an application-oriented evaluation of the transformation and assess the suitability of the scheme and our conversion to the unification of the syntactic annotations of BioInfer and the GENIA Treebank.n n We find that a highly reliable conversion is both feasible to create and practical, increasing the applicability of both the parser and the corpus to information extraction."
W06-3605,A Probabilistic Search for the Best Solution Among Partially Completed Candidates,2006,-1,-1,1,1,2610,filip ginter,Proceedings of the Workshop on Computationally Hard Problems and Joint Inference in Speech and Language Processing,0,None
W04-1203,Analysis of Link Grammar on Biomedical Dependency Corpus Targeted at Protein-Protein Interactions,2004,9,35,2,0,2607,sampo pyysalo,Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications ({NLPBA}/{B}io{NLP}),0,"In this paper, we present an evaluation of the Link Grammar parser on a corpus consisting of sentences describing protein-protein interactions. We introduce the notion of an interaction subgraph, which is the subgraph of a dependency graph expressing a protein-protein interaction. We measure the performance of the parser for recovery of dependencies, fully correct linkages and interaction subgraphs. We analyze the causes of parser failure and report specific causes of error, and identify potential modifications to the grammar to address the identified issues. We also report and discuss the effect of an extension to the dictionary of the parser."
