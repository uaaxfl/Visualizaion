2004.jeptalnrecital-long.31,brants-hansen-2002-developments,0,0.0201066,"Missing"
2004.jeptalnrecital-long.31,salmon-alt-romary-2004-towards,1,0.831119,"Missing"
2020.lrec-1.752,W16-2606,0,0.0341846,"Missing"
2020.lrec-1.752,W15-1807,1,0.859441,"Missing"
2020.lrec-1.752,C90-3030,0,0.285306,"Missing"
2020.lrec-1.752,N18-1088,0,0.038237,"Missing"
2020.lrec-1.752,N16-2013,0,0.0872904,"Missing"
afonso-etal-2002-floresta,J93-2004,0,\N,Missing
afonso-etal-2002-floresta,santos-bick-2000-providing,1,\N,Missing
bick-2004-named,M98-1004,0,\N,Missing
bick-2004-named,M98-1012,0,\N,Missing
bick-2004-named,M98-1014,0,\N,Missing
bick-2004-named,M98-1021,0,\N,Missing
bick-2004-named,M98-1018,0,\N,Missing
bick-2006-turning,A97-1011,0,\N,Missing
bick-2010-frag,schluter-van-genabith-2008-treebank,0,\N,Missing
bick-2010-frag,W09-1008,0,\N,Missing
bick-2010-frag,P05-1038,0,\N,Missing
bick-2010-frag,E95-1021,0,\N,Missing
bick-2014-ml,W99-0705,0,\N,Missing
bick-2014-ml,P98-2128,0,\N,Missing
bick-2014-ml,C98-2123,0,\N,Missing
bick-2014-ml,C96-2148,0,\N,Missing
bick-2014-ml,bick-etal-2012-annotation,1,\N,Missing
bick-etal-2012-annotation,panunzi-etal-2004-using,1,\N,Missing
C12-1073,cinkova-etal-2012-database,1,0.339745,"ake [[Human 2] ˆ [Animal]] ({up}) [[Human 1 |Sound |Event]] causes the mind of [[Human 2 |Animal]] to return to a state of full conscious awareness and alertness after sleep [Anything] wake [Emotion] ({in} Human) [[Anything]] causes [[Human]] to feel or become aware of [[Emotion]] waking * ({up}) [Human|Animal]’s returning to a state of full conscious awareness and alertness after sleep Table 1: Example patterns defined for the verbs gleam and wake. 2.1 Pilot Sample English Verbs We have performed our experiments using a newly developed lexical resource called VPS-30-En, recently published by Cinková et al. (2012). VPS-30-En (Verb Pattern Sample, 30 English verbs, henceforth VPS) is a pilot lexical resource of 30 English lexical verb entries enriched with semantically annotated corpus samples. VPS is publicly available on the web page http://ufal.mff.cuni.cz/spr/pdev30verbs.1 The data describes regular contextual patterns of use of the selected verbs in the BNC (2007). VPS has arisen as a practical result of previous studies published by Hanks, drawing on his PDEV, see e.g. (Hanks and Pustejovsky, 2005). VPS contains the verbs showed in Table 2. VPS is a collection of 30 revised PDEV verbs in which the"
C12-1073,de-marneffe-etal-2006-generating,0,0.0251484,"Missing"
D07-1120,W06-2923,1,0.911539,"gPars, a languageindependent treebanklearner developed in the context of the CoNLLX 2006 shared task (http://nextens.uvt.nl/~conll/), was in spired by the Constraint Grammar (CG) parsing approach (Karlsson et al. 1995) in the sense that it prioritized the identification of syntactic function over syntactic form, basing the dependency poten tial of a word on &quot;edge&quot; labels like subject, object etc. rather than the other way around. The system also used other features typical of CG systems, such as BARRIER conditions, tag chains of vari able length, implicit clause boundaries and tag sets (Bick 2006). For the 2007 task only one such fea ture was newly introduced  a directedness marker for a few major functions, splitting subject, adver bial and adnominal labels into pairs of left and Can an independent, rulebased parser be made to conform to different, dataimposed descriptive conventions without too great a loss in accuracy? Does a rulesbased dependency parser have a better chance than a machinelearned one to identify longdistance relations and global sentence structure, thus providing valuable arbiter information to the latter? Obviously, both points rule out a test involving ma"
D07-1120,W07-2416,0,0.0447764,"Missing"
D07-1120,W04-3111,0,0.175448,"Missing"
D07-1120,J93-2004,0,\N,Missing
D07-1120,D07-1096,0,\N,Missing
R15-1008,W99-1003,0,0.134819,"Missing"
R15-1008,stymne-ahrenberg-2010-using,0,\N,Missing
santos-bick-2000-providing,C90-2057,1,\N,Missing
santos-bick-2000-providing,W98-1605,1,\N,Missing
W01-1702,santos-bick-2000-providing,1,0.821294,"Missing"
W06-2923,dzeroski-etal-2006-towards,0,0.107479,"Missing"
W06-2923,afonso-etal-2002-floresta,1,0.86014,"describes LingPars, a Constraint Gram mar-inspired language-independent treebank-learn er developed from scratch between January 9th and March 9th 2006 in the context of the CoNLL-X 2006 shared task (http://nextens.uvt.nl/~conll/), or ganized by Sabine Buchholz, Erwin Marsi, Yval Krymolowski and Amit Dubey. Training treebanks and test data were provided for 13 different lan guages: Arabic (Smrž et al. 2002), Chinese (Chen et al. 2003), Czech (Hajič et al. 2001), Danish (Kromann 2003), Dutch (van der Beek et al. 2002), German (Brants et.al 2002), Japanese (Kawata and Bartels), Portuguese (Afonso et al. 2002), Slovene (Džerosky et al. 2006), Spanish (Palomar et al. 2004), Swedish (Nilsson et al. 2005), Turkish Language independence versus theory independence While manual annotation and/or linguistic, rulebased parsers are necessary for the creation of its training data, only a machine learning based parser (as targeted in the CoNNL shared task) can hope to be truly language independent in its design. The question is, however, if this necessarily implies in dependence of linguistic/descriptive theory. In our own approach, LingPars, we thus depart ed from the Constraint Grammar descriptive model ("
W06-2923,W03-2405,0,\N,Missing
W07-2405,C90-3030,0,0.0733621,"Missing"
W07-2405,2001.mtsummit-papers.48,0,0.0898979,"Missing"
W09-4630,P02-1031,0,0.0999573,"Missing"
W09-4630,S07-1008,0,0.0709488,"Missing"
W09-4630,taule-etal-2008-ancora,0,0.0148327,"level of abstraction often implies less consensus on category definitions in the linguistic community, and in semantic role annotation the level of agreement among different proKristiina Jokinen and Eckhard Bick (Eds.) NODALIDA 2009 Conference Proceedings, pp. 215–218 M. Pilar Valverde Ibáñez Departamento de Lengua Española Universidade de Santiago de Compostela pilar.valverde@usc.es jects, as well as inter-annotator agreement and annotation consistency is affected by this tendency. For Spanish, the ADESSE database (García-Miguel and Albertuz 2005) uses a set of 143 roles, the AnCora corpus (Taulé et al. 2008) 20 roles and the Sensem corpus (Alonso et al. 2007) 24 roles. Only the AnCora corpus assigns a semantic role to all the complements of the clause, while the rest only treat valency-bound complements. In our corpus, we use a set of 52 semantic roles, adopting the set of roles used by Bick (2007) for the annotation of Portuguese texts. These cover the major categories of the tectogrammatical annotation layer of the Prague Dependency Treebank (Hajicova et al. 2000), as well as those of the Spanish AnCora project. The rules of the grammar use syntactic-semantic information available in the input"
W09-4642,J90-1003,0,\N,Missing
W11-4606,P98-1013,0,0.525385,"Missing"
W11-4606,E06-2013,0,0.0338117,"Missing"
W11-4606,A00-2008,0,0.0793094,"Missing"
W11-4606,J05-1004,0,0.314884,"Missing"
W11-4606,N04-3006,0,0.0804572,"Missing"
W11-4606,C98-1013,0,\N,Missing
W11-4606,J02-3001,0,\N,Missing
W11-4606,braasch-olsen-2004-sto,0,\N,Missing
W13-5607,P01-1045,0,0.084957,"mal chunking np's will not contain postnominal pp's or relative clauses. If a chunk does swallow another chunk, the latter will lose its edges. Depending on linguistic design, this may occur in the handling of prepositions or quantifying adverbials. Minimal chunking is often used as an intermediate step in NLP, after part-of-speech (POS) tagging, and before deeper structural or functional analysis. Thus, Abney's chunk parser would first create a stream of such minimal chunks, then use an &quot;attacher&quot; to link words within chunks, and chunks to each other in order to create a complete parse tree. Kübler & Hinrichs (2001) use a similar 2-step method, but focus on syntactic function assignment as a vehicle to extend nonrecursive chunks to full parse structures on the background of a treebank instance database. In our own approach, we implement a third strategy, where (syntactic) function comes before (syntactic) form, and links are created before chunks. Chunk edges are assigned based on functional relations, and chunking depth becomes a design option rather than a clear, methodologically desired, processing stage distinction. In the context of this paper, we will therefore extend the meaning of chunking to inc"
W13-5607,W00-0726,0,0.220216,"Missing"
W13-5607,P02-1055,0,0.0749734,"Missing"
W15-1807,W99-1002,0,0.566098,"s to make a grammar interact with a given text type. Descriptively, this limitation meant that CG as such could not be used for higherlevel annotation such as anaphora or discourse relations, and that grammars were agnostic of genre and task types. Following Karlsson&apos;s original proposal, two standards for CG rule compilers emerged in the late 90&apos;ies. The first, CG1, was used by Karlsson&apos;s team at Helsinki University and commercially by the spinoff company LingSoft for English (ENGCG), Swedish and German (GERCG) taggers, as well as for applied products such as Scandinavian grammar checkers (Arppe, 2000; Birn, 2000 for Swedish, Hagen et al., 2001 for Norwegian). The second compiler, CG2, was programmed and distributed by Pasi Tapainen (1996), who made several notational improvements3 to the rule formalisms (in particular, regarding BARRIER conditions, SET definitions and REPLACE operations), but left the basic topological interpretation of constraints unchanged. Five years later, a third company, GrammarSoft ApS, in cooperation with the University of Southern Denmark, launched an open source CG compiler, vislcg, which was backward compatible with CG2, but also introduced a few new features"
W15-1807,W99-1003,0,0.0486003,"rammar interact with a given text type. Descriptively, this limitation meant that CG as such could not be used for higherlevel annotation such as anaphora or discourse relations, and that grammars were agnostic of genre and task types. Following Karlsson&apos;s original proposal, two standards for CG rule compilers emerged in the late 90&apos;ies. The first, CG1, was used by Karlsson&apos;s team at Helsinki University and commercially by the spinoff company LingSoft for English (ENGCG), Swedish and German (GERCG) taggers, as well as for applied products such as Scandinavian grammar checkers (Arppe, 2000; Birn, 2000 for Swedish, Hagen et al., 2001 for Norwegian). The second compiler, CG2, was programmed and distributed by Pasi Tapainen (1996), who made several notational improvements3 to the rule formalisms (in particular, regarding BARRIER conditions, SET definitions and REPLACE operations), but left the basic topological interpretation of constraints unchanged. Five years later, a third company, GrammarSoft ApS, in cooperation with the University of Southern Denmark, launched an open source CG compiler, vislcg, which was backward compatible with CG2, but also introduced a few new features4, in partic"
W15-1807,W99-0705,0,0.0793747,"2/VISLCG compiler standard did achieve a tag granularity and accuracy that allowed them to support external modules for both constituent and dependency tree generation, they remained topological in nature and did not permit explicit reference to linguistic relations and structure in the formalism itself. The same is true for virtually all related work outside the CG community itself, where the basic idea of CG constraints has sometimes been exploited to enhance or hybridize HMMstyle probabilistic methods (e.g. Graña et al., 2003) or combined with machine learning (Lindberg & Eineborg, 1998; Lager, 1999), but always in the form of (mostly closecontext) topological rather than structuralrelational rules and always with discrete tag and string constants. It is only with the CG3 compiler presented here, that these and most of the other abovementioned design issues have been addressed in a principled way and inside the CG formalism itself. CG3 5 (or VISL CG3 because of its backward compatibility with VISLCG) was developed over a period of 6 years, where new features were designed and implemented continually, while existing features were tested in reallife parsing applications. In the follo"
W15-1807,P98-2128,0,0.019117,"aint grammars using the CG 2/VISLCG compiler standard did achieve a tag granularity and accuracy that allowed them to support external modules for both constituent and dependency tree generation, they remained topological in nature and did not permit explicit reference to linguistic relations and structure in the formalism itself. The same is true for virtually all related work outside the CG community itself, where the basic idea of CG constraints has sometimes been exploited to enhance or hybridize HMMstyle probabilistic methods (e.g. Graña et al., 2003) or combined with machine learning (Lindberg & Eineborg, 1998; Lager, 1999), but always in the form of (mostly closecontext) topological rather than structuralrelational rules and always with discrete tag and string constants. It is only with the CG3 compiler presented here, that these and most of the other abovementioned design issues have been addressed in a principled way and inside the CG formalism itself. CG3 5 (or VISL CG3 because of its backward compatibility with VISLCG) was developed over a period of 6 years, where new features were designed and implemented continually, while existing features were tested in reallife parsing applications"
W15-1807,C98-2123,0,\N,Missing
W15-1807,W13-5607,1,\N,Missing
W16-6314,afonso-etal-2002-floresta,1,0.869729,"Missing"
W16-6314,de-marneffe-etal-2006-generating,0,0.169273,"Missing"
W17-0223,A00-2008,0,0.154739,"provide a statistical break-down of frames and roles for both the corpus as a whole and across different text types. 1 Introduction The syntactic potential and semantic structure of a language&apos;s lexicon can either be encoded explicitly in a dictionary or ontology, or implicitly through annotated data. Rule-based natural-language processing (NLP) will typically rely on the former, machine-learning (ML) systems on the latter. For the semantic annotation of predicate-argument structures, two wellknown English ressources each addressing one of these two approaches are FrameNet (Baker et al. 1998, Johnson & Fillmore 2000, Ruppenhofer et al. 2010) and PropBank (Palmer et al. 2005), respectively. While FrameNet categorizes verb senses into frames with semantically restricted &quot;slot-filler&quot; arguments, PropBank departs from syntactically annotated corpus data to assign both roles and argument structure to each verb consecutively. The data-driven approach of PropBank promises better coverage and statistical balance1, and therefore better automatic ML tagging, but its semantic role inventory and numbered arguments are highly predicate-dependent, and do not support semantic generalization and interpretation as well a"
W17-0223,P09-1033,0,0.0639316,"Missing"
W17-0223,J05-1004,0,0.546594,"Missing"
W17-6523,afonso-etal-2002-floresta,1,0.780987,"motivates our interest in participating in the project. Since it is a well documented project, we asked ourselves to which extent the general UD guidelines were enough to represent the features of each individual language, in particular we asked 1 http://universaldependencies.org ourselves whether they were enough to properly represent the grammatical features of Portuguese. The release of the UD treebanks version 1.2, in November 2015, was the first release to include a Portuguese treebank. The UD_Portuguese treebank is based on the corpus Bosque, part of the Floresta Sint´a(c)tica project (Afonso et al., 2002), version used in the CoNLL-X Shared Task in dependency parsing (2006); the CoNLL version was taken and converted to the Prague dependency style as a part of HamleDT (since 2011). Later versions of HamleDT added a conversion to the Stanford dependencies (2014) and to Universal Dependencies (HamleDT 3.0, 2015). The conversion path from the original Bosque still goes through the CoNLL-X format and the Prague dependencies, which may occasionally lead to loss of information. In the release 1.3 of UD, in May 2016, one additional Portuguese treebank was added, the UD Portuguese-BR, a conversion of t"
W17-6523,W15-1807,1,0.895198,"Missing"
W17-6523,W16-6314,1,0.73439,"0, 2015). The conversion path from the original Bosque still goes through the CoNLL-X format and the Prague dependencies, which may occasionally lead to loss of information. In the release 1.3 of UD, in May 2016, one additional Portuguese treebank was added, the UD Portuguese-BR, a conversion of the original work of (McDonald et al., 2013), as per the description in (et al., 2016). This paper describes the consolidation of the UD_Portuguese treebank in the UD Framework. For that, between September 2015 and March 2016, a set of UD conversion rules for the CG input was written, as described in (Bick, 2016), and applied to the updated version of the dependency-style Bosque (Linguateca version 7.5 of March 2016). For a team effort starting in October 2016, we were given a version of the this converted corpus, and through consistency-checking and discussion, aiming at full compatibility with UD specification, converged to a further round of manual treebank corrections and conversion rules 197 Proceedings of the Fourth International Conference on Dependency Linguistics (Depling 2017), pages 197-206, Pisa, Italy, September 18-20 2017 changes. The first version of our data, fully UD 1.4 compliant, wa"
W17-6523,W06-2920,0,0.0971909,"al Natural Language Learning (CoNLL), has a long history of shared tasks in which training and test data are provided by the organizers, allowing participating systems to be evaluated and compared in a systematic way. Many reasons supported our decision to re-use the Bosque corpus, instead of creating an entire new corpus from scratch. The Bosque corpus -– created and maintained by Linguateca 2 -– was already annotated with dependencies and was manually revised, saving us time. Besides, it was already used in previous editions of CONLL – CONLL-X Shared task on Multilingual Dependency Parsing (Buchholz and Marsi, 2006) –, and it is distributed in different versions, annotated with different tagsets and formats.3 The existence of different versions of the same material fosters the study about different tagsest and its impacts in NLP systems. Finally, the fact that we had on the team two researchers who had already worked on previous versions of Bosque also contributed to this choice. However, the conversion to UD scheme was much more complicated than initially planned. Different tagsets usually correspond to different reifications of grammars, which indicates different conceptualizations of a language. For t"
W17-6523,L16-1262,0,0.0658834,"Missing"
W17-6523,C90-3030,0,0.720124,"conversion to UD scheme was much more complicated than initially planned. Different tagsets usually correspond to different reifications of grammars, which indicates different conceptualizations of a language. For this reason, a conversion of tagsets is rarely a purely mechanical task of substitution. In our improved conversion, we address both structural links (dependencies labels) and part-of-speech tagsets, following the Universal Dependencies guidelines for 2 http://www.linguateca.pt There is the original Bosque tagset and the CONLL 2006 tagset; there is also the CG (constraint grammar, (Karlsson, 1990)) format, the AD format (phrase structure tree), the graphical and tgrep format, the Penn TreeBank and TIGER fomat. All these versions are available from http://www.linguateca.pt/Floresta/download.html and http:// corpora.di.uminho.pt/linguateca/FS/fs.html. 3 198 version 2.0. This conversion also deals with phenomena that needs manual revision, such as apposition, copular sentences and multiword expressions (MWE) structures, among others. We first describe how and why we chose the corpus we decided to work from, then we describe the process we used to improve this data. Very many small and not"
W17-6523,N15-3011,0,0.0262457,"ependency is mostly used when no other relation is applicable. We also plan to check the coverage of the classes of verbs, nouns, adjectives and adverbs, against OpenWordNet-PT.6 5 tag ADJ count 11560 ADP 36614 ADV 8742 AUX 6315 CCONJ 5222 DET 35076 INTJ 43 NOUN 41353 NUM 4312 PART PRON 4 7236 PROPN 18984 PUNCT SCONJ 29983 2201 SYM VERB 415 19482 Improving Bosque analyses To allow us to analyze the representations and the effects of the automatically applied choices in the pipeline, we feed the result of processed sentences to the interface developed and distributed by the Turku BioNLP Group (Luotolahti et al., 2015).7 This has been very helpful, as one can tell immediately how big the issues are within the corpus. The UD project provides a validation script that allows us to check some basic generic facts, such as that every sentence has a root and that CoNLL representations have always the same number of fields or that there are no multiple values for the same tag. Some of these are mandatory, a corpus needs to be validated to be part of the distribution. But more sophisticated constraints, both on the level of POS tags and of dependencies, can also be checked. The Turku search tools make use of a sophi"
W17-6523,P13-2017,0,0.0701457,"Missing"
W17-6902,P98-1013,0,0.380164,"oun frames and adnominal roles in the corpus. 1 Introduction There is a long linguistic tradition of frame and role annotation for verbal predications, rooted in verb sense classifications on the one hand (e.g. Levin 1993), and the concept of semantic roles (also called thematic or case roles, Fillmore 1968) on the other. In a frame-based framework, verb categories and semantic roles are seen as interdependent, and predications are annotated for both, usually involving both valency-bound arguments and free (adverbial) satellites of a given verb. Two crucial resources in the area are FrameNet (Baker et al. 1998, Ruppenhofer et al. 2010) and PropBank (Palmer et al. 2005). The former is more lexicographical in its conception and focuses on a one-by-one exhaustive description of individual frames, the latter offers exhaustive proposition annotation of running corpus sentences, with an eye on applications such as Machine Learning (ML). For Danish, both a FrameNet and a frame tagger (DanGram) have been published (Bick 2011), but unlike some work on larger languages, e.g. the German Salsa corpus (Rehbein et al. 2012), these Danish tools addressed only verbal frames, largely ignoring nominal predications."
W17-6902,J05-1004,0,0.202339,"on There is a long linguistic tradition of frame and role annotation for verbal predications, rooted in verb sense classifications on the one hand (e.g. Levin 1993), and the concept of semantic roles (also called thematic or case roles, Fillmore 1968) on the other. In a frame-based framework, verb categories and semantic roles are seen as interdependent, and predications are annotated for both, usually involving both valency-bound arguments and free (adverbial) satellites of a given verb. Two crucial resources in the area are FrameNet (Baker et al. 1998, Ruppenhofer et al. 2010) and PropBank (Palmer et al. 2005). The former is more lexicographical in its conception and focuses on a one-by-one exhaustive description of individual frames, the latter offers exhaustive proposition annotation of running corpus sentences, with an eye on applications such as Machine Learning (ML). For Danish, both a FrameNet and a frame tagger (DanGram) have been published (Bick 2011), but unlike some work on larger languages, e.g. the German Salsa corpus (Rehbein et al. 2012), these Danish tools addressed only verbal frames, largely ignoring nominal predications. The work presented here strives to resolve this problem in a"
W17-6902,C98-1013,0,\N,Missing
Y11-1024,clement-etal-2004-morphology,0,0.0841607,"Missing"
Y11-1024,quasthoff-etal-2006-corpus,0,0.0249755,"Missing"
Y11-1024,J01-2001,0,\N,Missing
Y11-1024,E95-1021,0,\N,Missing
Y12-1006,erk-pado-2006-shalmaneser,0,0.0235332,"Missing"
Y12-1006,E06-2013,0,0.0208462,"Missing"
Y12-1006,A00-2008,0,0.0414229,"Missing"
Y12-1006,bick-etal-2012-annotation,1,0.833814,"Missing"
Y12-1006,J05-1004,0,0.00684218,"f NER and semantic role annotation. The system that comes closest to the task at hand, is the Danish DanGram system which implements a framenet-based verbal classification and semantic role annotation (Bick 2011), with a category inventory of ~500 verb frames and ~50 semantic roles. For our present task, we have attempted to port lexical material from this system, and adopted its verb classification scheme, which in turn was inspired by the VerbNet classes proposed by Kipper et al. (2006), ultimately with roots in (Levine 1993), and a smaller and thus more tractable granularity than PropBank (Palmer et al. 2005). Our semantic role inventory, following the one implemented for Portuguese by (Bick 2007), is also much smaller than PropBank&apos;s, the rationale being that mediumsized category sets allow for a reasonable level of abstraction compared to the underlying lexical items, and by roughly matching the granularity of other linguistic abstractions (syntactic function inventory, PoS/morphological categories) are well suited to be integrated with the latter in automatic disambuguation systems. 2 Frame role distinctors: valency, syntactic function and semantic classes In this vein, the distinctional backbo"
Y12-1006,N04-3006,0,0.021175,"Missing"
Y13-1046,bick-etal-2012-annotation,1,0.888306,"Missing"
Y13-1046,Y11-1024,1,0.886148,"Missing"
Y13-1046,P98-2128,0,0.190193,"Missing"
Y13-1046,W99-0705,0,\N,Missing
Y13-1046,C98-2123,0,\N,Missing
Y13-1046,C96-2148,0,\N,Missing
