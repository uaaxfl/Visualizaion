2007.sigdial-1.23,P96-1009,0,0.0102055,"or collecting dialog corpora using subjects. In Section 3, we introduce the Let’s Go spoken dialog system, which we use to collect both our subject and user corpora. In Section 4, we describe the specific in-lab experiment we conducted with recruited sub125 jects. We then introduce the evaluation measures used for our corpora comparisons in Section 5, followed by a presentation of our results in Section 6. Finally, we further discuss and summarize our results in Section 7. 2 Literature Review In this section we survey a set of spoken dialog papers involving human subject experiments (namely, (Allen et al., 1996), (Batliner et al., 2003), (Bohus and Rudnicky, 2006), (Giorgino et al., 2004), (Gruenstein et al., 2006), (Hof et al., 2006), (Lemon et al., 2006), (Litman and Pan, 2002), (M¨oller et al., 2006), (Rieser et al., 2005), (Roque et al., 2006), (Singh et al., 2000), (Tomko and Rosenfeld, 2006), (Walker et al., 2001), (Walker et al., 2000)), in order to define a “standard” laboratory setting for use in our own experiments with subjects. We survey the literature from four perspectives: subject recruitment, experimental environment, task design, and experimental policies. Subject Recruitment. Recrui"
2007.sigdial-1.23,W07-0305,1,0.107624,"Missing"
2007.sigdial-1.23,W06-1301,0,0.0236486,"ect both our subject and user corpora. In Section 4, we describe the specific in-lab experiment we conducted with recruited sub125 jects. We then introduce the evaluation measures used for our corpora comparisons in Section 5, followed by a presentation of our results in Section 6. Finally, we further discuss and summarize our results in Section 7. 2 Literature Review In this section we survey a set of spoken dialog papers involving human subject experiments (namely, (Allen et al., 1996), (Batliner et al., 2003), (Bohus and Rudnicky, 2006), (Giorgino et al., 2004), (Gruenstein et al., 2006), (Hof et al., 2006), (Lemon et al., 2006), (Litman and Pan, 2002), (M¨oller et al., 2006), (Rieser et al., 2005), (Roque et al., 2006), (Singh et al., 2000), (Tomko and Rosenfeld, 2006), (Walker et al., 2001), (Walker et al., 2000)), in order to define a “standard” laboratory setting for use in our own experiments with subjects. We survey the literature from four perspectives: subject recruitment, experimental environment, task design, and experimental policies. Subject Recruitment. Recruiting subjects involves deciding who to recruit, where to recruit, and how many subjects to recruit. In the studies we surveye"
2007.sigdial-1.23,2005.sigdial-1.11,0,0.0117317,"iment we conducted with recruited sub125 jects. We then introduce the evaluation measures used for our corpora comparisons in Section 5, followed by a presentation of our results in Section 6. Finally, we further discuss and summarize our results in Section 7. 2 Literature Review In this section we survey a set of spoken dialog papers involving human subject experiments (namely, (Allen et al., 1996), (Batliner et al., 2003), (Bohus and Rudnicky, 2006), (Giorgino et al., 2004), (Gruenstein et al., 2006), (Hof et al., 2006), (Lemon et al., 2006), (Litman and Pan, 2002), (M¨oller et al., 2006), (Rieser et al., 2005), (Roque et al., 2006), (Singh et al., 2000), (Tomko and Rosenfeld, 2006), (Walker et al., 2001), (Walker et al., 2000)), in order to define a “standard” laboratory setting for use in our own experiments with subjects. We survey the literature from four perspectives: subject recruitment, experimental environment, task design, and experimental policies. Subject Recruitment. Recruiting subjects involves deciding who to recruit, where to recruit, and how many subjects to recruit. In the studies we surveyed, the number of subjects recruited for each experiment ranged from 10 to 72. Most of the stu"
2007.sigdial-1.23,2005.sigdial-1.6,0,0.238946,"es Institute, Carnegie Mellon University, Pittsburgh PA, 15213, USA 3 Computer Science Department, Carnegie Mellon University, Pittsburgh PA, 15213, USA 4 Dept. of Computer Science & LRDC, University of Pittsburgh, Pittsburgh, PA 15260, USA hua@cs.pitt.edu, {antoine,dbohus,max}@cs.cmu.edu, litman@cs.pitt.edu 1 Abstract interactions with early system prototypes, are often used to better design system functionalities. Once obtained, such corpora are often then used in machine learning approaches to tasks such as dialog strategy optimization (e.g. (Lemon et al., 2006)), or user simulation (e.g. (Schatzmann et al., 2005)). During system evaluation, user satisfaction surveys are often carried out with humans after interacting with a system (Hone and Graham, 2000); given a dialog corpus obtained from such interactions, evaluation frameworks such as PARADISE (Walker et al., 2000) can then be used to predict user satisfaction from measures that can be directly computed from the corpus. Empirical spoken dialog research often involves the collection and analysis of a dialog corpus. However, it is not well understood whether and how a corpus of dialogs collected using recruited subjects differs from a corpus of dial"
2020.acl-main.182,P18-1103,0,0.0146828,"(Gai and Young, 2014), and partially observable Markov decision process (Roy et al., 2000) are often used in spoken dialog systems to optimize dialog management by explicitly estimating uncertainty in policy assignments. However, these approaches are either computationally intensive (Gal and Ghahramani, 2015) or require significant work on refining policy representations (Gai and Young, 2014). Moreover, most current uncertainty studies in dialog focus on the dialog management component. End-to-end (E2E) dialog retrieval models jointly encode a dialog and a candidate response (Wu et al., 2016; Zhou et al., 2018), assuming the ground truth is always present in the candidate set, which is not the case in production. Larson et al. (2019) recently showed that classifiers that perform well on in-scope intent classification for task-oriented dialog systems struggle to identify out-of-scope queries. The response selection task in the most recent Dialog System Technology Challenge (Chulaka Gunasekara and Lasecki, 2019) also explicitly mentions that “none 1 Our datasets for the NOTA task are released at https://github.com/yfeng21/nota prediction of the proposed utterances is a good candidate” should be a vali"
2020.acl-main.182,D19-1131,0,0.0445571,"Missing"
2020.acl-main.182,W15-4640,0,0.210603,"2020 c July 5 - 10, 2020. 2020 Association for Computational Linguistics practice in dialog production systems (IBM). The idea of adding the NOTA option to a candidate set is also widely used in other language technology fields like speaker verification (Pathak and Raj, 2013). However, the effect of adding NOTA is rarely introduced in dialog retrieval research problems. To the best of our knowledge, we are the first to scientifically evaluate a variety of conventional approaches for retrieving NOTA in the dialog field. 3 3.1 Methods Ubuntu Dataset All of the experiments herein use the Ubuntu (Lowe et al., 2015) Dialog Corpus, which contains multiturn, goal-oriented chat logs on the Ubuntu forum. For next utterance retrieval purposes, we use the training data version that was preprocessed by Mehri and Eskenazi (2019), where all negative training samples (500,127) were removed, and, for each context, 9 distractor responses were randomly chosen from the dataset to form the candidate response set, together with the ground truth response. For the uncertainty task, we use a special token NOTA to represent the “none of the above” choice, as in multiple-choice questions. More details on this NOTA setup can"
2020.acl-main.182,D19-1184,1,0.851283,"anguage technology fields like speaker verification (Pathak and Raj, 2013). However, the effect of adding NOTA is rarely introduced in dialog retrieval research problems. To the best of our knowledge, we are the first to scientifically evaluate a variety of conventional approaches for retrieving NOTA in the dialog field. 3 3.1 Methods Ubuntu Dataset All of the experiments herein use the Ubuntu (Lowe et al., 2015) Dialog Corpus, which contains multiturn, goal-oriented chat logs on the Ubuntu forum. For next utterance retrieval purposes, we use the training data version that was preprocessed by Mehri and Eskenazi (2019), where all negative training samples (500,127) were removed, and, for each context, 9 distractor responses were randomly chosen from the dataset to form the candidate response set, together with the ground truth response. For the uncertainty task, we use a special token NOTA to represent the “none of the above” choice, as in multiple-choice questions. More details on this NOTA setup can be found in Sections 4.1 and 4.2. The modified training dataset has 499,873 dialog contexts, and each has 10 candidate responses. The validation and test sets remain unchanged, with 19,561 validation samples a"
2020.acl-main.182,P00-1013,0,\N,Missing
2020.acl-main.182,P17-1046,0,\N,Missing
2020.acl-main.182,W19-4107,0,\N,Missing
2020.acl-main.64,P02-1040,0,\N,Missing
2020.acl-main.64,W14-3348,0,\N,Missing
2020.acl-main.64,P97-1035,0,\N,Missing
2020.acl-main.64,W04-1013,0,\N,Missing
2020.acl-main.64,D16-1230,0,\N,Missing
2020.acl-main.64,P17-1061,1,\N,Missing
2020.acl-main.64,W19-5944,1,\N,Missing
2020.sigdial-1.28,P15-2073,0,0.0238418,"alysis of the FED dataset identifies the dialog qualities most important to human annotators. (3) DialoGPT is shown to implicitly capture an understanding of dialog quality. (4) The FED metric has moderate to strong correlation with human judgement by leveraging DialoGPT, without training data or reference responses. 2 2.1 formance can largely be explained by the one-tomany nature of dialog (Zhao et al., 2017). To avoid comparing to a single reference response, several authors have proposed using multiple reference responses. Multiple reference responses can be obtained with retrieval models (Galley et al., 2015; Sordoni et al., 2015) or through data collection (Gupta et al., 2019). These multi-reference metrics show performance improvement, but it is infeasible to thoroughly cover the space of all potential responses. The FED metric does not rely on a ground-truth response. Lowe et al. (2017) train ADEM to produce a quality score conditioned on the dialog context, the reference response and the generated response. Venkatesh et al. (2018) present a framework for evaluating Alexa prize conversations which attains moderate correlation with user ratings. Both methods are trained on explicit quality anno"
2020.sigdial-1.28,W19-5944,1,0.928356,"t is costly. During development, systems are generally optimized for poorly correlated automatic metrics which can result in sub-par performance (Dinan et al., 2019). Automatic metrics must be meaningful and interpretable so that they can be used to compare dialog systems, understanding their respective strengths and weaknesses, and effectively guide dialog research. Dialog evaluation is difficult for several reasons: (1) The one-to-many nature of dialog (Zhao et al., 2017) makes word-overlap metrics ineffective for scoring valid responses that deviate from the ground-truth (Liu et al., 2016; Gupta et al., 2019). (2) Dialog quality is inherently multifaceted (Walker et al., 1997; See et al., 2019) and an interpretable metric should measure several qualities (e.g., interesting, relevant, fluent). (3) Dialog systems have begun to be evaluated in an interactive setting (Ram et al., 2018; Adiwardana et al., 2020) where a real user has a back-and-forth conversation with a system. Interactive evaluation is not constrained to a static corpus and better captures the performance of a system in a realistic setting. However, the existing automatic metrics compare to a ground-truth response, making them unsuitab"
2020.sigdial-1.28,P19-1478,0,0.0355756,"Missing"
2020.sigdial-1.28,D16-1230,0,0.20226,"t require training data and (3) measures fine-grained dialog qualities at both the turn and whole dialog levels. FED attains moderate to strong correlation with human judgement at both levels. 1 Introduction Evaluation metrics often define the research direction of a field. As dialog systems begin to demonstrate human-level performance, the development and adoption of meaningful and interpretable automatic evaluation measures is essential (Zhang et al., 2019; Adiwardana et al., 2020). Since standard metrics (e.g., BLEU, METEOR) have been shown to be ineffective for dialog (Deriu et al., 2019; Liu et al., 2016), human evaluation is often used. However, it is typically only used as a final evaluation since it is costly. During development, systems are generally optimized for poorly correlated automatic metrics which can result in sub-par performance (Dinan et al., 2019). Automatic metrics must be meaningful and interpretable so that they can be used to compare dialog systems, understanding their respective strengths and weaknesses, and effectively guide dialog research. Dialog evaluation is difficult for several reasons: (1) The one-to-many nature of dialog (Zhao et al., 2017) makes word-overlap metr"
2020.sigdial-1.28,P17-1103,0,0.116707,"g data or reference responses. 2 2.1 formance can largely be explained by the one-tomany nature of dialog (Zhao et al., 2017). To avoid comparing to a single reference response, several authors have proposed using multiple reference responses. Multiple reference responses can be obtained with retrieval models (Galley et al., 2015; Sordoni et al., 2015) or through data collection (Gupta et al., 2019). These multi-reference metrics show performance improvement, but it is infeasible to thoroughly cover the space of all potential responses. The FED metric does not rely on a ground-truth response. Lowe et al. (2017) train ADEM to produce a quality score conditioned on the dialog context, the reference response and the generated response. Venkatesh et al. (2018) present a framework for evaluating Alexa prize conversations which attains moderate correlation with user ratings. Both methods are trained on explicit quality annotations. In contrast, the FED metric proposed here requires no supervision. Mehri and Eskenazi (2020) introduce USR, an unsupervised and reference-free evaluation metric for dialog generation. Similar to FED, USR uses pre-trained models to assess several dialog qualities. However, they"
2020.sigdial-1.28,2020.acl-main.64,1,0.878599,"se multi-reference metrics show performance improvement, but it is infeasible to thoroughly cover the space of all potential responses. The FED metric does not rely on a ground-truth response. Lowe et al. (2017) train ADEM to produce a quality score conditioned on the dialog context, the reference response and the generated response. Venkatesh et al. (2018) present a framework for evaluating Alexa prize conversations which attains moderate correlation with user ratings. Both methods are trained on explicit quality annotations. In contrast, the FED metric proposed here requires no supervision. Mehri and Eskenazi (2020) introduce USR, an unsupervised and reference-free evaluation metric for dialog generation. Similar to FED, USR uses pre-trained models to assess several dialog qualities. However, they are limited to five qualities with hand-designed models and unsupervised tasks for each quality. In comparison, FED is more general and encapsulates eighteen dialog qualities. Related Work Automatic Dialog Evaluation Standard automatic metrics for language generation have been shown to correlate poorly with human judgement of dialog (Liu et al., 2016; Lowe et al., 2017; Gupta et al., 2019). This poor per226 2.2"
2020.sigdial-1.28,D19-1013,0,0.0613497,"Missing"
2020.sigdial-1.28,N19-1170,0,0.438883,"tomatic metrics which can result in sub-par performance (Dinan et al., 2019). Automatic metrics must be meaningful and interpretable so that they can be used to compare dialog systems, understanding their respective strengths and weaknesses, and effectively guide dialog research. Dialog evaluation is difficult for several reasons: (1) The one-to-many nature of dialog (Zhao et al., 2017) makes word-overlap metrics ineffective for scoring valid responses that deviate from the ground-truth (Liu et al., 2016; Gupta et al., 2019). (2) Dialog quality is inherently multifaceted (Walker et al., 1997; See et al., 2019) and an interpretable metric should measure several qualities (e.g., interesting, relevant, fluent). (3) Dialog systems have begun to be evaluated in an interactive setting (Ram et al., 2018; Adiwardana et al., 2020) where a real user has a back-and-forth conversation with a system. Interactive evaluation is not constrained to a static corpus and better captures the performance of a system in a realistic setting. However, the existing automatic metrics compare to a ground-truth response, making them unsuitable for assessing interactive conversations. To address these three problems, this paper"
2020.sigdial-1.28,N15-1020,0,0.0231634,"aset identifies the dialog qualities most important to human annotators. (3) DialoGPT is shown to implicitly capture an understanding of dialog quality. (4) The FED metric has moderate to strong correlation with human judgement by leveraging DialoGPT, without training data or reference responses. 2 2.1 formance can largely be explained by the one-tomany nature of dialog (Zhao et al., 2017). To avoid comparing to a single reference response, several authors have proposed using multiple reference responses. Multiple reference responses can be obtained with retrieval models (Galley et al., 2015; Sordoni et al., 2015) or through data collection (Gupta et al., 2019). These multi-reference metrics show performance improvement, but it is infeasible to thoroughly cover the space of all potential responses. The FED metric does not rely on a ground-truth response. Lowe et al. (2017) train ADEM to produce a quality score conditioned on the dialog context, the reference response and the generated response. Venkatesh et al. (2018) present a framework for evaluating Alexa prize conversations which attains moderate correlation with user ratings. Both methods are trained on explicit quality annotations. In contrast, t"
2020.sigdial-1.28,P97-1035,0,0.822386,"poorly correlated automatic metrics which can result in sub-par performance (Dinan et al., 2019). Automatic metrics must be meaningful and interpretable so that they can be used to compare dialog systems, understanding their respective strengths and weaknesses, and effectively guide dialog research. Dialog evaluation is difficult for several reasons: (1) The one-to-many nature of dialog (Zhao et al., 2017) makes word-overlap metrics ineffective for scoring valid responses that deviate from the ground-truth (Liu et al., 2016; Gupta et al., 2019). (2) Dialog quality is inherently multifaceted (Walker et al., 1997; See et al., 2019) and an interpretable metric should measure several qualities (e.g., interesting, relevant, fluent). (3) Dialog systems have begun to be evaluated in an interactive setting (Ram et al., 2018; Adiwardana et al., 2020) where a real user has a back-and-forth conversation with a system. Interactive evaluation is not constrained to a static corpus and better captures the performance of a system in a realistic setting. However, the existing automatic metrics compare to a ground-truth response, making them unsuitable for assessing interactive conversations. To address these three p"
2020.sigdial-1.28,P17-1061,1,0.92407,"log (Deriu et al., 2019; Liu et al., 2016), human evaluation is often used. However, it is typically only used as a final evaluation since it is costly. During development, systems are generally optimized for poorly correlated automatic metrics which can result in sub-par performance (Dinan et al., 2019). Automatic metrics must be meaningful and interpretable so that they can be used to compare dialog systems, understanding their respective strengths and weaknesses, and effectively guide dialog research. Dialog evaluation is difficult for several reasons: (1) The one-to-many nature of dialog (Zhao et al., 2017) makes word-overlap metrics ineffective for scoring valid responses that deviate from the ground-truth (Liu et al., 2016; Gupta et al., 2019). (2) Dialog quality is inherently multifaceted (Walker et al., 1997; See et al., 2019) and an interpretable metric should measure several qualities (e.g., interesting, relevant, fluent). (3) Dialog systems have begun to be evaluated in an interactive setting (Ram et al., 2018; Adiwardana et al., 2020) where a real user has a back-and-forth conversation with a system. Interactive evaluation is not constrained to a static corpus and better captures the per"
2021.eancs-1.3,N16-1014,0,0.0690063,"Missing"
2021.eancs-1.3,W15-4640,0,0.0744291,"Missing"
2021.eancs-1.3,I17-1099,0,0.0226116,"ectives, the three aspects used to characterize them are: (1) Does the metric use a pretrained language model? (2) What data was used to train the metric? (3) Does the metric require a reference response or is it reference-free? In most metrics, triplet ranking loss is used as a training objective, and it requires the model to give higher scores to appropriate responses. BERT (Devlin et al., 2019) and its variant RoBERTa (Liu et al., 2019) are the most popular pretrained language models utilized in state-of-the-art metrics, followed by GPT-2 language model (Radford et al., 2019). DailyDialog (Li et al., 2017) and PersonaChat (Zhang et al., 2018) are two widely-used datasets for training metrics. Briefly, conversation topics of DailyDialog are about day-to-day life, while Personachat consists of dialogs where each participant is assigned a persona and the goal is to become familiar with the other individual. Wordoverlap metrics are ineffective for dialog (Liu et al., 2016b) largely due to the one-to-many nature of dialog (Zhao et al., 2017a). Thus, reference-free metrics have been proposed to circumvent the oneto-many problem. Amongst the 24 metrics assessed here, we have 11 reference-free evaluati"
2021.eancs-1.3,2021.findings-acl.91,0,0.0747542,"Missing"
2021.eancs-1.3,2020.tacl-1.52,0,0.0787985,"Missing"
2021.eancs-1.3,P02-1040,0,0.111469,"Missing"
2021.eancs-1.3,2021.emnlp-main.529,0,0.083271,"Missing"
2021.eancs-1.3,2020.coling-main.368,0,0.035942,"Missing"
2021.eancs-1.3,N19-1170,0,0.0289594,"MAUDE DEB GRADE DynaEval USR USL-H DialogRPT HolisticEval PredictiveEngage FED FlowScore FBD 0.285 0.275 0.584 0.678 -0.023* 0.589 0.486 0.283 0.670 -0.033* 0.485 - 0.260 0.364 0.663 0.697 -0.009* 0.645 0.537 0.332 0.764 0.060* 0.507 - Table 4: Results on HolisticEval-DailyDialog. All values are statistically significant to p < 0.05, unless marked by *. Performance on Various Dialog Qualities MAUDE 0.4 GRADE USR FED HolisticEval 0.3 FlowScore USL-H QuestEval DEB DynaEval 0.2 PredictiveEngage DialogRPT Spearman Correlation Since dialog quality is inherently multi-faceted (Walker et al., 1997; See et al., 2019), it is inadequate to only evaluate dialog metrics on the overall response score. Therefore, this paper also presents the correlation of the metrics with various dialog qualities in Table 4 and Figure 1. HolisticEval-DailyDialog annotates the context coherence of responses. For the FED data, we present results on 8 fine-grained turn-level qualitites, and results on dialog-level qualities could be found in Appendix. For metrics that produce fine-grained scores, we use the corresponding finegrained score to measure correlation. For example, because PredictiveEngage evaluates the engaging quality"
2021.eancs-1.3,2020.acl-main.704,0,0.0383599,"Missing"
2021.eancs-1.3,W18-6456,0,0.0301022,"Missing"
2021.eancs-1.3,2020.acl-main.220,0,0.0157317,"future work. 1 Introduction Evaluation is a crucial component of the research process. Evaluation metrics are used to shine light on the best models and thus they strongly influence the research directions of a field. Standard automatic language evaluation metrics (e.g., BLEU, METEOR) have been shown to be ineffective for evaluating dialog (Liu et al., 2016b; Deriu et al., 2021). To this end, recent research has proposed a number of automatic metrics specifically designed to evaluate dialog (Tao et al., 2018; Ghazarian et al., 2019; Lan et al., 2020; Pang et al., 2020; Ghazarian et al., 2020; Sinha et al., 2020; Huang et al., 2020; Mehri and Eskenazi, 2020b,a; Zhang et al., 2021b). These metrics address the weaknesses of the standard language evaluation metrics. They have also been shown to better correlate with human judgement. However, most of these metrics were devel1 https://github.com/exe1023/ DialEvalMetrics 15 1 Proceedings of the First Workshop on Evaluations and Assessments of Neural Conversation Systems, pages 15–33 Nov 11, 2021. ©2021 Association for Computational Linguistics future evaluation metrics on a number of datasets. 2 In general, these datasets are constructed using the followin"
2021.eancs-1.3,2020.acl-demos.30,0,0.0221274,"ing dialog dataset, the response generation model used would also influence the characteristics of responses. Distinguishing between responses with very different quality is easier, since the low quality response may not even follow grammar rules or the dialog context. On the other hand, it will be challenging to give appropriate scores to responses from state-of-the-art dialog systems. In the 10 datasets, responses in the data labeled by GRADE, FED, and DSTC9 data come from models with relatively better empirical performance such as Transformer Seq2Seq model (Vaswani et al., 2017), DialoGPT (Zhang et al., 2020), and Meena (Adiwardana et al., 2020b). 4 3 Experiments Testing Datasets This section describes the assessment of the evaluation metrics. Wherever possible, the released pretrained model was used to reproduce results. Since RUBER, BERT-RUBER and PONE do not release their pretrained models, those models were trained on DailyDialog. For USR, we use the released model which is trained on TopicalChat. For PredictiveEngage, the original paper combined the model with RUBER for the best performance. In this assessment only the engagement score model is used for comparison to the other metrics. FlowSc"
2021.eancs-1.3,P17-1061,1,0.840415,"2019) are the most popular pretrained language models utilized in state-of-the-art metrics, followed by GPT-2 language model (Radford et al., 2019). DailyDialog (Li et al., 2017) and PersonaChat (Zhang et al., 2018) are two widely-used datasets for training metrics. Briefly, conversation topics of DailyDialog are about day-to-day life, while Personachat consists of dialogs where each participant is assigned a persona and the goal is to become familiar with the other individual. Wordoverlap metrics are ineffective for dialog (Liu et al., 2016b) largely due to the one-to-many nature of dialog (Zhao et al., 2017a). Thus, reference-free metrics have been proposed to circumvent the oneto-many problem. Amongst the 24 metrics assessed here, we have 11 reference-free evaluation metrics. We refer readers to Appendix A for detailed discussion of aforementioned characteristics of assessed metrics. For data that does not contain referenced responses, only reference-free metrics were assessed. The characteristics of the quality-annotated data significantly influence the performance of the metrics since dialog metrics might be originally developed and trained on data in a very different domain than the test dom"
2021.eancs-1.3,P97-1035,0,0.807095,"Missing"
2021.sigdial-1.51,2020.acl-main.3,0,0.144409,"et al., 2014), RNNs with external memory (Peng et al., 2015), encoder labeler LSTMs (Kurata et al., 2016) and joint pointer and attention seq2seq networks (Zhao and Feng, 2018). With the introduction of large-scale pre-trained language models (Devlin et al., 2019; Radford et al., 2019), strong slot filling results have been achieved with simple architectures (Chen et al., 2019). Several approaches have been proposed for zeroshot slot filling. Bapna et al. (2017) leverage slot names and descriptions to align slots across domains. Shah et al. (2019) leverage examples for zero-shot slot filling. Liu et al. (2020) achieve strong results in zero-shot slot filling with a coarseto-fine approach in combination with template regularization. We use the Coach+TR model (Liu et al., 2020) as a baseline in our zero-shot experiments. Working on the hypothesis that pre-trained language models, such as BERT (Devlin et al., 2019), do not effectively capture the intricacies of dialog, recent work has attempted to mitigate this issue. Coope et al. (2020) use ConveRT (Henderson et al., 2019), a lightweight model pre-trained on dialog data, in combination with CNN and conditional random field (CRF) to outperform BERT. M"
2021.sigdial-1.51,2020.acl-main.11,0,0.0437233,"Missing"
2021.sigdial-1.51,N19-1423,0,0.523058,"ed. The downstream task can be adapted with knowledge of the properties and capabilities of the pretrained models. Likewise, the pre-trained model can be adapted with knowledge of the downstream task/data. is assumed that the underlying pre-trained models possess a degree of generality that allows transfer to a variety of tasks. We posit that this assumption is flawed. Consequently this paper demonstrates the importance of incorporating inductive biases that achieve stronger alignment between the pretrained model and the downstream task. Introduction The advent of pre-trained language models (Devlin et al., 2019; Radford et al., 2019) has transformed natural language processing. The dominant paradigm has shifted away from designing task-specific architectures towards transfer learning. Fine-tuning pre-trained models on downstream datasets achieves strong performance on a variety of natural language understanding tasks (Wang et al., 2018). Generally, prior to fine-tuning, the pre-trained models are adapted to the specifics of the downstream task through minor architectural modifications (e.g., adding a classification layer) (Chen et al., 2019; Mehri et al., 2020). By avoiding major task-specific chang"
2021.sigdial-1.51,2020.findings-emnlp.196,0,0.0796432,"Missing"
2021.sigdial-1.51,W18-5446,0,0.0883706,"Missing"
2021.sigdial-1.51,2020.acl-demos.30,0,0.502737,"ng objective, it is likely to be more effective if the downstream fine-tuning and inference algorithms are modified to rank rather than to classify. By simultaneously adapting both the downstream task and the pretrained model, we intend to achieve stronger alignment without sacrificing the inherent scalability of the transfer learning paradigm (i.e., avoiding task-specific pre-trained models). We address the task of slot filling, a natural language understanding task with the goal of identifying values for pre-defined attributes (slots) in a natural language utterance. We leverage a DialoGPT (Zhang et al., 2020), a generative language model, pre-trained on open-domain dialog data. To achieve strong alignment between the slot filling task and DialoGPT, we (1) reformulate slot filling as a natural language response generation task, and (2) augment the DialoGPT architecture with a copy-mechanism, constrained decoding and a post-processing heuristic. The resulting model, G EN SF (Generative Slot Filling), is shown to achieve state-of-the-art results on two slot filling datasets. G EN SF achieves the strongest performance gains in few-shot and zero-shot settings, highlighting the importance of stronger al"
2021.sigdial-1.51,P18-2068,0,0.0284136,"ttps://github. com/shikib/generative_slot_filling. 2 Related Work Slot filling is the task of identifying values for predefined attributes, or slots, in a natural language utterance (Tur and De Mori, 2011). Slot filling is a vital natural language understanding component of task-oriented dialog systems (Young, 2002, 2010). A variety of architectures have been explored for the task of slot filling, including CNNs (Vu, 2016), deep LSTMs (Yao et al., 2014), RNNs with external memory (Peng et al., 2015), encoder labeler LSTMs (Kurata et al., 2016) and joint pointer and attention seq2seq networks (Zhao and Feng, 2018). With the introduction of large-scale pre-trained language models (Devlin et al., 2019; Radford et al., 2019), strong slot filling results have been achieved with simple architectures (Chen et al., 2019). Several approaches have been proposed for zeroshot slot filling. Bapna et al. (2017) leverage slot names and descriptions to align slots across domains. Shah et al. (2019) leverage examples for zero-shot slot filling. Liu et al. (2020) achieve strong results in zero-shot slot filling with a coarseto-fine approach in combination with template regularization. We use the Coach+TR model (Liu et"
2021.sigdial-1.52,D18-1547,0,0.0608588,"Missing"
2021.sigdial-1.52,N19-1423,0,0.508909,"Rastogi et al., 2020b). A long-standing challenge in dialog research is to flexibly adapt systems to new dialog domains and tasks (Zhao and Eskenazi, 2018; Mosig et al., 2020). Consider a system that has been trained to handle several different tasks (e.g., restaurant reservations, ride booking, weather, etc.). How can this dialog system be extended to handle a new task (e.g., hotel booking), without collecting additional data? This paper tackles this challenge and aims to address the problem of zero-shot generalization using the schema-guided paradigm. The advent of large-scale pre-training (Devlin et al., 2019; Radford et al., 2019) has led to significant progress in domain adaptation across areas in NLP, including natural language understanding (Wang et al., 2018, 2019), open-domain dialog (Zhang et al., 2020; Adiwardana et al., 2020) and language understanding for task-oriented dialog (Wu et al., 2019; Mehri et al., 2020). Generalization in end-to-end task-oriented dialog has proven to be significantly more difficult, particularly in zero-shot settings where there is no training data (Mosig et al., 2020). We posit that it is inherently difficult to generalize to unseen dialog tasks be499 Proceedi"
2021.sigdial-1.52,H90-1021,0,0.681531,"Missing"
2021.sigdial-1.52,P19-1253,0,0.0170578,"(2020) through (1) an improved schema representation and (2) a collection of modifications to the model. The improved schema representation better models realistic user behaviors in dialog, and therefore results in better alignment of the dialog and the schema. Our model modifications result in the model being able to learn better fine-grained relationships during alignment (e.g., through better negative sampling and wordlevel attention) and better handle zero-shot transfer (e.g., by removing the linear layer). In contrast to prior work on zero-shot generalizability (Zhao and Eskenazi, 2018; Qian and Yu, 2019), our approach is shown to effectively transfer between the vastly dissimilar domains of the STAR corpus (Mosig et al., 2020) (e.g., trivia or spaceship maintenance). Rather than modelling a cross-domain mapping and leveraging similar concepts across different domains, the schema-guided paradigm decouples the domain-specific (i.e., the dialog policy) and domain-agnostic (i.e., language understanding) aspects of dialog systems. Through the schema-guided paradigm, we achieve strong performance in the zero-shot setting and take an important step towards zero-shot dialog. 6 Conclusion This paper s"
2021.sigdial-1.52,2020.emnlp-main.148,0,0.0550385,"Missing"
2021.sigdial-1.52,N19-1178,0,0.0197704,"09) consists of a task specification that defines the behavior of a system depending on various user actions. Plan-based dialog systems decouple the task-specific dialog policy from the task-agnostic components of the system. This allows a system to be extended to a new task by updating the task specification. The schema-guided paradigm shares a similar motivation, and aims to disentangle the dialog policy in neural, data-driven dialog systems. Several approaches have been presented to discover dialog structure graphs (similar to the schemas in this paper) from data in an unsupervised manner (Shi et al., 2019; Qiu et al., 2020; Xu et al., 2020; Hu et al., 2019). These approaches have been used to enhance generation for opendomain dialog (Qiu et al., 2020; Hu et al., 2019). To the best of our knowledge, these dialog structures have neither been used for generation in taskoriented dialog nor in zero-shot settings. While our schemas are similar to these structure graphs, they are hand-crafted similar to those in plan-based dialog systems. Future work may extend our work by leveraging unsupervised structure graph discovery as an alternative to hand-crafted schemas. 3 Task Definition We address the pro"
2021.sigdial-1.52,W18-5446,0,0.0646149,"Missing"
2021.sigdial-1.52,P19-1078,0,0.110516,"r, etc.). How can this dialog system be extended to handle a new task (e.g., hotel booking), without collecting additional data? This paper tackles this challenge and aims to address the problem of zero-shot generalization using the schema-guided paradigm. The advent of large-scale pre-training (Devlin et al., 2019; Radford et al., 2019) has led to significant progress in domain adaptation across areas in NLP, including natural language understanding (Wang et al., 2018, 2019), open-domain dialog (Zhang et al., 2020; Adiwardana et al., 2020) and language understanding for task-oriented dialog (Wu et al., 2019; Mehri et al., 2020). Generalization in end-to-end task-oriented dialog has proven to be significantly more difficult, particularly in zero-shot settings where there is no training data (Mosig et al., 2020). We posit that it is inherently difficult to generalize to unseen dialog tasks be499 Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 499–508 July 29–31, 2021. ©2021 Association for Computational Linguistics cause of the dialog policy. Traditionally, an end-to-end dialog system must perform three distinct tasks. First, it must understand"
2021.sigdial-1.52,2020.acl-demos.30,0,0.0328477,"een trained to handle several different tasks (e.g., restaurant reservations, ride booking, weather, etc.). How can this dialog system be extended to handle a new task (e.g., hotel booking), without collecting additional data? This paper tackles this challenge and aims to address the problem of zero-shot generalization using the schema-guided paradigm. The advent of large-scale pre-training (Devlin et al., 2019; Radford et al., 2019) has led to significant progress in domain adaptation across areas in NLP, including natural language understanding (Wang et al., 2018, 2019), open-domain dialog (Zhang et al., 2020; Adiwardana et al., 2020) and language understanding for task-oriented dialog (Wu et al., 2019; Mehri et al., 2020). Generalization in end-to-end task-oriented dialog has proven to be significantly more difficult, particularly in zero-shot settings where there is no training data (Mosig et al., 2020). We posit that it is inherently difficult to generalize to unseen dialog tasks be499 Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 499–508 July 29–31, 2021. ©2021 Association for Computational Linguistics cause of the dialog policy. Traditio"
2021.sigdial-1.52,W18-5001,1,0.859606,"im to satisfy user goals pertaining to certain tasks, such as booking flights (Hemphill et al., 1990), providing transit information (Raux et al., 2005), or acting as a tour guide (Budzianowski et al., 2018). Neural models for task-oriented dialog have become the dominant paradigm (Williams and Zweig, 2016; Wen et al., 2016; Zhao et al., 2017). These data-driven approaches can potentially learn complex patterns from large dialog corpora without hand-crafted rules. However, the resulting models struggle to generalize beyond the training data and underperform on unseen dialog tasks and domains (Zhao and Eskenazi, 2018; Rastogi et al., 2020b). A long-standing challenge in dialog research is to flexibly adapt systems to new dialog domains and tasks (Zhao and Eskenazi, 2018; Mosig et al., 2020). Consider a system that has been trained to handle several different tasks (e.g., restaurant reservations, ride booking, weather, etc.). How can this dialog system be extended to handle a new task (e.g., hotel booking), without collecting additional data? This paper tackles this challenge and aims to address the problem of zero-shot generalization using the schema-guided paradigm. The advent of large-scale pre-training"
2021.sigdial-1.52,W17-5505,1,0.85208,"Missing"
D16-1192,N04-1025,1,0.900282,"fficulty using logistic regression, and examine rankings generated by aggregating pairwise difficulty labels using a Bayesian rating system to form a final ranking. We also compare rankings derived for sentences assessed with and without context, and find that contextual features can help predict differences in relative difficulty judgments across these two conditions. 1 Introduction The reading difficulty, or readability, of a text is an estimate of linguistic complexity and is typically based on lexical and syntactic features, such as text length, word frequency, and grammatical complexity (Collins-Thompson and Callan, 2004; Schwarm and Ostendorf, 2005; Kidwell et al., 2011; Kanungo and Orr, 2009). Such estimates are often expressed as age- or grade-level measures and are useful for a range of educational and research applications. For example, instructors often wish to select stories or books that are appropriately matched to student grade level. Many measures have been designed to calculate readability at the document level (e.g., for web pages, articles, or books) (Collins-Thompson and Callan, 2004; Schwarm and Ostendorf, 2005), as well as the paragraph or passage level (Kidwell et al., 2011; Kanungo and Orr,"
D16-1192,C12-1049,0,0.0401848,"Missing"
D16-1192,W08-0909,1,0.904508,"ity of single sentences. 1872 2 Related Work Recent approaches to estimating readability have used a variety of linguistic features and prediction models (Collins-Thompson, 2014). The Lexile Framework (Stenner, 1996) uses word frequency estimates in a large corpus as a proxy for lexical difficulty, and sentence length as a grammatical feature. Methods based on statistical machine learning, such as the reading difficulty measures developed by Collins-Thompson and Callan (CollinsThompson and Callan, 2004) and (Schwarm and Ostendorf, 2005) used a feature set based on language models. Later work (Heilman et al., 2008) incorporated grammatical features by parsing the sentences in a text, and creating subtrees of one- to three-level depth as separate features. Such features allow more detailed, direct analysis of the sentence structure itself instead of traditional proxies for syntactic complexity likes sentence length. The linguistic features proposed in these works capture specific aspects of language difficulty applied at the document level, whereas our work investigates the effectiveness of these feature types for characterizing aspects of difficulty at the sentence level. Methods have been proposed to m"
D16-1192,W14-1821,0,0.157275,"Missing"
D16-1192,D08-1020,0,0.0795208,"g difficulty rankings of longer texts from pairwise preferences has been performed in other contexts. Tanaka-Ishii et al. (2010) explored an approach for sorting texts by readability based on 1873 pairwise preferences. Later, Chen et al. (2013) also proposed a model to obtain passage readability ranking by aggregating pairwise comparisons made by crowdworkers. In De Clercq et al.(2014), pairwise judgments of whole passages were obtained from crowdworkers and were found to give comparable results in aggregate to those obtained from experts. A pairwise ranking of text readability was created in Pitler and Nenkova (2008) in which readability was defined by subjective questions asked to the reader after finishing the article, such as “How well-written is this article?”. All of the above previous work was focused on ordering longer text passages, not single sentences as we do here. Finally, research in the Machine Translation field has explored pairwise prediction of the best translation between two sentence options. For example, in Song and Cohn (2011), a pairwise prediction model was built using n-gram precision and recall, as well as function, content, and word counts. However, unlike pairwise prediction of"
D16-1192,D10-1048,0,0.0976605,"Missing"
D16-1192,P05-1065,0,0.759147,"and examine rankings generated by aggregating pairwise difficulty labels using a Bayesian rating system to form a final ranking. We also compare rankings derived for sentences assessed with and without context, and find that contextual features can help predict differences in relative difficulty judgments across these two conditions. 1 Introduction The reading difficulty, or readability, of a text is an estimate of linguistic complexity and is typically based on lexical and syntactic features, such as text length, word frequency, and grammatical complexity (Collins-Thompson and Callan, 2004; Schwarm and Ostendorf, 2005; Kidwell et al., 2011; Kanungo and Orr, 2009). Such estimates are often expressed as age- or grade-level measures and are useful for a range of educational and research applications. For example, instructors often wish to select stories or books that are appropriately matched to student grade level. Many measures have been designed to calculate readability at the document level (e.g., for web pages, articles, or books) (Collins-Thompson and Callan, 2004; Schwarm and Ostendorf, 2005), as well as the paragraph or passage level (Kidwell et al., 2011; Kanungo and Orr, 2009). However, much less wo"
D16-1192,W13-1506,0,0.0128902,"nships can include the number of coreferences present in a text. Coh-Metrix (Graesser et al., 2011) measures text cohesiveness, accounting for both the reading difficulty of the text and other lexical and syntactic measures as well as a measure of prior knowledge needed for comprehension, and the genre of the text. Coh-Metrix uses co-reference detection as a factor in the cohesiveness of a text, typically at the document or passage level. Such cohesiveness factors account for the difficulty of constructing the mental representation of texts with more complex internal structure. TextEvaluator (Sheehan et al., 2013; Sheehan et al., 2014) is designed to help educators select materials for instruction. The tool includes several components in its evaluation of text, including narrativity, style, and cohesion, beyond traditional difficulty and is again at the whole document level. This approach illustrates that the difficulty of a text relies on the relationships within it. This motivates the need to consider context when measuring difficulty. Generating reading difficulty rankings of longer texts from pairwise preferences has been performed in other contexts. Tanaka-Ishii et al. (2010) explored an approach"
D16-1192,W11-2113,0,0.153141,"m crowdworkers and were found to give comparable results in aggregate to those obtained from experts. A pairwise ranking of text readability was created in Pitler and Nenkova (2008) in which readability was defined by subjective questions asked to the reader after finishing the article, such as “How well-written is this article?”. All of the above previous work was focused on ordering longer text passages, not single sentences as we do here. Finally, research in the Machine Translation field has explored pairwise prediction of the best translation between two sentence options. For example, in Song and Cohn (2011), a pairwise prediction model was built using n-gram precision and recall, as well as function, content, and word counts. However, unlike pairwise prediction of difficulty, the prediction is done with respect to a reference sentence, or set of reference sentences. 3 Data Collection and Processing We now describe methods used to create our dataset of sentences, to collect pairwise assessments of difficulty, and to aggregate these pairwise preferences into a complete ranking. 3.1 Data Set The study sentences were drawn from a corpus combining the American National Corpus (Reppen et al., 2005), t"
D16-1192,J10-2002,0,0.0188212,"structure. TextEvaluator (Sheehan et al., 2013; Sheehan et al., 2014) is designed to help educators select materials for instruction. The tool includes several components in its evaluation of text, including narrativity, style, and cohesion, beyond traditional difficulty and is again at the whole document level. This approach illustrates that the difficulty of a text relies on the relationships within it. This motivates the need to consider context when measuring difficulty. Generating reading difficulty rankings of longer texts from pairwise preferences has been performed in other contexts. Tanaka-Ishii et al. (2010) explored an approach for sorting texts by readability based on 1873 pairwise preferences. Later, Chen et al. (2013) also proposed a model to obtain passage readability ranking by aggregating pairwise comparisons made by crowdworkers. In De Clercq et al.(2014), pairwise judgments of whole passages were obtained from crowdworkers and were found to give comparable results in aggregate to those obtained from experts. A pairwise ranking of text readability was created in Pitler and Nenkova (2008) in which readability was defined by subjective questions asked to the reader after finishing the artic"
D16-1192,N10-2012,0,0.0183983,"luded the percentage of non-stop words (using NLTK list), the total number of words and the total number of characters as features. We included the percentage of words in the text found in the Revised Dale-Chall word list (Dale and Chall, 2000) to capture the presence of more difficult words in the sentence. Because sentences that contain rarer sequences of words are likely to be more difficult, and the likelihood of the sentence based on a large corpus should reflect this, we included the n-gram likelihood of each sentence, over each of 1-5 n-grams, as a feature. The Microsoft WebLM service (Wang et al., 2010) was used to calculate the n-gram likelihood. In the field of psycholinguistics, Age of Acquisition (AoA) refers to the age at which a word is first learned by a child. A database of 51,715 words collected by (Kuperman et al., 2012) provides a rich resource for use in reading difficulty measures. With this dataset, we computed several additional features: the average, maximum, and standard deviation of the aggregated AoA for all words in a sentence that were present in the database. Since the data set also includes the number of syllables in each word, and as (Kincaid et al., 1975) proposes th"
D16-1192,D11-1038,0,0.0343971,"et al., 2014) classified individual sentences that would be understood by second-language learners. Another work (Kilgarriff et al., 2008) identified sentences that would be good dictionary examples by looking for specific desirable features. Davenport et al. 2014 used a traditional method of readability (Flesch-Kincaid), within the larger context of exploring relationships between the difficulty of tweets in a geographic area and demographics. Research in text simplification has applied sentence-level models of difficulty as part of simplification-based optimization objectives. For example, Woodsend and Lapata (2011) use word and syllable count as proxy features for sentence difficulty when implicitly comparing different simplified variants of a sentence. Other approaches have considered the relationship of reading difficulty to structures within in the whole text. These relationships can include the number of coreferences present in a text. Coh-Metrix (Graesser et al., 2011) measures text cohesiveness, accounting for both the reading difficulty of the text and other lexical and syntactic measures as well as a measure of prior knowledge needed for comprehension, and the genre of the text. Coh-Metrix uses"
D16-1192,P05-1022,0,\N,Missing
D19-1184,D18-1547,0,0.0298999,"Missing"
D19-1184,W15-4640,0,0.118286,"e varied input. Second, the pre-trained representations, which are all obtained through various language modelling objectives, do not necessarily capture properties of dialog at several levels of granularity (e.g., belief state, entities, coreferences, high-level user goals). Though large-scale pre-training improves the strength and generality of latent representations, this effect is minimized when transferring to dialog tasks or out-of-domain data. To this end, this paper explores an alternate mechanism of learning strong and general representations for the task of next utterance retrieval (Lowe et al., 2015). We propose Multi-Granularity Training (MGT), which simultaneously trains multiple levels of representation. It later combines these latent repre1752 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 1752–1761, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics sentations to obtain more general models of dialog. Different granularities of representation capture different properties of the input. For example, a high-granularity representation"
D19-1184,P19-1373,1,0.82006,"pre-trained representations of language have been applied to numerous tasks. Of particular interest are applications of these representations to dialog tasks. As part of the 2nd ConvAI challenge (Dinan et al., 2019), the best performing models on both human and automated evaluations (Wolf et al., 2019) were fine-tuned versions of OpenAI’s GPT (Radford et al., 2018). Despite strong performance gains, transferring OpenAI’s GPT required fine-tuning the full model because the dialog data was in a different domain and required different information to be contained in the representations. Recently, Mehri et al. (2019) introduce several dialog specific pre-training objec1753 tives that obtain strong performance gains across multiple downstream dialog tasks. 2.2 Next Utterance Retrieval Lowe et al. (2015) construct Ubuntu, the largest retrieval corpus for dialog, and present the dual encoder architecture as a baseline architecture. Kadlec et al. (2015) present several strong baseline architectures for this dataset. Zhou et al. (2016) present the Multiview architecture which, with the aim of constructing broader representation, learns both word-level representations and utterance-level representations. Sequen"
D19-1184,D14-1162,0,0.0854854,"are clipped to 5.0. A checkpoint is saved after each epoch, and the best checkpoint is selected using performance on the validation set. 4.2.2 Ubuntu Setup Each encoder is a single layer, uni-directional LSTM with an embedding dimension of 300 and a hidden size of 150. The Adam optimizer (Kingma and Ba, 2015) with a learning rate of 0.005 is used to train the model for 20 epochs. The vocabulary is 10002 words, the batch size is 128, and gradients are clipped to 5.0. Only the last 160 words of each dialog context are used. The word embeddings are initialized with pre-trained GloVe embeddings (Pennington et al., 2014). A checkpoint is saved after each epoch, and the best checkpoint is selected using performance on the validation set. 4.2.3 Deep Attention Matching Experiment MGT is a training procedure which is agnostic to the underlying model architecture. Though the majority of the experiments presented in this paper use the dual encoder architecture (Lowe et al., 2015), MGT is applied on top of the state-of-theart architecture for Ubuntu: the Deep Attention Matching Network (DAM) (Zhou et al., 2018). When applying MGT to DAM, the sampling of negative candidates is done using the baseline dual encoder arc"
D19-1184,N18-1202,0,0.30732,"ambiguity in natural language. A large focus area of dialog research is the development of neural architectures which learn effective representations of the input (Zhou et al., 2016; Wu et al., 2016; Zhou et al., 2018). With the goal of training a model for next utterance retrieval, Zhou et al. (2018) use a deep self-attention network to produce a representation of each utterance within a dialog and follow it with an attention between utterances and 3D convolutional layers. Recent work has explored the use of large-scale self-supervised pre-training on very large corpora (Kiros et al., 2015; Peters et al., 2018; Devlin et al., 2018; Radford et al., 2018) as a means of improving natural language representations. These pretrained models have yielded state-of-the-art results on several downstream NLP tasks (Wang et al., 2018): text classification, natural language inference, and question answering. Though such methods have proven useful across several downstream tasks (Wang et al., 2018), using them for dialog requires expensive fine-tuning of the complex models (Dinan et al., 2019; Alberti et al., 2019). The need for this fine-tuning is due to the pre-training procedure. First, the domain and style of"
D19-1184,W18-5446,0,0.0345006,"Missing"
D19-1184,W13-4065,0,0.013462,"oblem in natural language processing (NLP) (Montague, 1973; Davidson and Harman, 2012). Neural models typically encode an input into a latent vector, which is then used by upper layers. As such, improving the quality or generality of the learned representations will typically improve performance on the final task due to the increased representative power of the model. Constructing meaningful representations of dialog is challenging. To effectively represent the dialog context, a latent dialog representation must contain the information necessary to (1) estimate a belief state over user goals (Williams et al., 2013), (2) track entity mentions (Zhao et al., 2017), (3) resolve anaphora co-references (Mitkov, 2014), (4) model the communicative purpose of an utterance (Core and Allen, 1997) and (5) resolve ambiguity in natural language. A large focus area of dialog research is the development of neural architectures which learn effective representations of the input (Zhou et al., 2016; Wu et al., 2016; Zhou et al., 2018). With the goal of training a model for next utterance retrieval, Zhou et al. (2018) use a deep self-attention network to produce a representation of each utterance within a dialog and follow"
D19-1184,W17-5505,1,0.894704,"Missing"
D19-1184,D16-1036,0,0.0454862,"Missing"
D19-1184,P18-1103,0,0.0865459,"dialog is challenging. To effectively represent the dialog context, a latent dialog representation must contain the information necessary to (1) estimate a belief state over user goals (Williams et al., 2013), (2) track entity mentions (Zhao et al., 2017), (3) resolve anaphora co-references (Mitkov, 2014), (4) model the communicative purpose of an utterance (Core and Allen, 1997) and (5) resolve ambiguity in natural language. A large focus area of dialog research is the development of neural architectures which learn effective representations of the input (Zhou et al., 2016; Wu et al., 2016; Zhou et al., 2018). With the goal of training a model for next utterance retrieval, Zhou et al. (2018) use a deep self-attention network to produce a representation of each utterance within a dialog and follow it with an attention between utterances and 3D convolutional layers. Recent work has explored the use of large-scale self-supervised pre-training on very large corpora (Kiros et al., 2015; Peters et al., 2018; Devlin et al., 2018; Radford et al., 2018) as a means of improving natural language representations. These pretrained models have yielded state-of-the-art results on several downstream NLP tasks (Wa"
H05-1103,N04-1025,0,0.0425663,"Missing"
H05-1103,C94-1103,0,0.0395603,"Missing"
K19-1054,D08-1035,0,0.503268,"as topic modeling approaches such as Latent Dirichlet Allocation (LDA) (Blei et al., 2003), but here the inherent topics are constrained to the linear discourse structure. To model interactions between lexical distributions, we use a dynamic prior, which assumes that the word probabilities change smoothly across topics. To model segment length characteristics, we assign prior variables conditioned on document modality. The linear segmentation constraint has been used to make inference tractable by exhaustively exploring the segmentation space to obtain the exact maximum-likelihood estimation (Eisenstein and Barzilay, 2008). Given a multi-document setting, this is not feasible, as segments can share topics. We address this issue using a beam search algorithm, which allows the inference procedure to recover from early mistakes. In our experiments, we show that BeamSeg is able to perform well when segmenting learning materials, where previously single-document models obtained better results (Mota et al., 2018). We also observe that topic identification is more accurately determined in a joint model, as opposed to a pipeline approach (performing the tasks sequentially), indicating that both problems should be model"
K19-1054,P13-1167,0,0.0189886,"s’ subject with two annotators. A 0.69 Fleiss-kappa (Shrout and Fleiss, 1979) agreement value was obtained, showing that annotators had a similar perception of whether segments share the same topic. Most of the disagreement cases are due to considering textual and plot-based explanations as different topics. N −k X 1 WD = |ref − hyp |= 6 0, N −k where N is the length of the document and k the window size. WD is a penalty score between 0 (the best value) and 1. For consistency, we take the output segmentations from all systems and evaluate it using the same software (the python module segeval (Fournier, 2013)). The WD average results for the baseline are in Table 1. In the Biography dataset, MultiSeg is the best performing model, improving the WD of Bayesseg-MD by 0.05. In the AVL dataset, the best results are obtained by Bayesseg-MD. The difference to the second best result, Bayesseg, is 0.02. For the Physics dataset, the single-document model Bayesseg achieves the best results with a WD difference of 0.01. These results show that the performance of the algorithms varies across the different datasets. This suggests that the different modeling approaches do not generalize well to the different cha"
K19-1054,P03-1071,0,0.358352,"our contributions as follows: 2 Related Work Following the lexical cohesion theory, segmentation algorithms identify spans of text with prominent vocabulary changes. The main difference between algorithms is how lexical cohesion is implemented: some resort to lexical similarity; the remaining follow a probabilistic approach. Lexical approaches rely on a similarity metric between sentences, usually the cosine. A classic method is TextTiling (Hearst, 1997), which assumes that topic boundaries are found in consecutive sentences with a low similarity value; several other works built on this idea (Galley et al., 2003; Balagopalan et al., 2012). C99 (Choi, 2000) is another lexical approach, and uses a similarity matrix in a divisive clustering to obtain segments. MinCut (Malioutov and Barzilay, 2006) casts segmentation in a minimum cut graph partitioning problem. The graph has a node for each sentence; edges are weighted using lexical similarity. Long-distance textual relationships are modeled by connecting all sentences. Affinity Propagation Segmentation (Kazantseva and Szpakowicz, 2011) also models such relationships but uses affinity propagation clustering (Frey and Dueck, 2007). The algorithm creates a"
K19-1054,Q19-1011,0,0.0175104,"ximizes the segment similarity sum function. Alemi and Ginsparg (2015) proposed the Content Vector Segmentation (CVS) sentence vector representation based on segment word embeddings. Using this representation in C99 improves bag-ofwords results. In another line of research, Wang et al. (2017) combined learning to rank and a convolutional neural network to learn a coherence function between text pairs; higher-ranked pairs are likely to be segments. Despite a promising approach, stateof-the-art results were not achieved. Also following an approach using neural networks, is the SECTOR algorithm (Arnold et al., 2019), which uses a topic embedding trained based on utterance topic classification. Following the network architecture from (Koshorek et al., 2018), two stacked LSTM layers are used to decode word embedding representation of utterances. To recover segmentation, a TextTiling approach is applied to the topic embedding layer. The evaluation results show that SECTOR is able to improve a C99 baseline. • A novel joint model for topic segmentation and identification with a dynamic prior. • An inference procedure based on a beam search algorithm. • A study on how different modality-based segment length pr"
K19-1054,J97-1003,0,0.866503,"model, as opposed to a pipeline approach (performing the tasks sequentially), indicating that both problems should be modeled simultaneously. We summarize our contributions as follows: 2 Related Work Following the lexical cohesion theory, segmentation algorithms identify spans of text with prominent vocabulary changes. The main difference between algorithms is how lexical cohesion is implemented: some resort to lexical similarity; the remaining follow a probabilistic approach. Lexical approaches rely on a similarity metric between sentences, usually the cosine. A classic method is TextTiling (Hearst, 1997), which assumes that topic boundaries are found in consecutive sentences with a low similarity value; several other works built on this idea (Galley et al., 2003; Balagopalan et al., 2012). C99 (Choi, 2000) is another lexical approach, and uses a similarity matrix in a divisive clustering to obtain segments. MinCut (Malioutov and Barzilay, 2006) casts segmentation in a minimum cut graph partitioning problem. The graph has a node for each sentence; edges are weighted using lexical similarity. Long-distance textual relationships are modeled by connecting all sentences. Affinity Propagation Segme"
K19-1054,A00-2004,0,0.816428,"g the lexical cohesion theory, segmentation algorithms identify spans of text with prominent vocabulary changes. The main difference between algorithms is how lexical cohesion is implemented: some resort to lexical similarity; the remaining follow a probabilistic approach. Lexical approaches rely on a similarity metric between sentences, usually the cosine. A classic method is TextTiling (Hearst, 1997), which assumes that topic boundaries are found in consecutive sentences with a low similarity value; several other works built on this idea (Galley et al., 2003; Balagopalan et al., 2012). C99 (Choi, 2000) is another lexical approach, and uses a similarity matrix in a divisive clustering to obtain segments. MinCut (Malioutov and Barzilay, 2006) casts segmentation in a minimum cut graph partitioning problem. The graph has a node for each sentence; edges are weighted using lexical similarity. Long-distance textual relationships are modeled by connecting all sentences. Affinity Propagation Segmentation (Kazantseva and Szpakowicz, 2011) also models such relationships but uses affinity propagation clustering (Frey and Dueck, 2007). The algorithm creates a factor graph and maximizes the segment simil"
K19-1054,D11-1026,0,0.0265474,"ssumes that topic boundaries are found in consecutive sentences with a low similarity value; several other works built on this idea (Galley et al., 2003; Balagopalan et al., 2012). C99 (Choi, 2000) is another lexical approach, and uses a similarity matrix in a divisive clustering to obtain segments. MinCut (Malioutov and Barzilay, 2006) casts segmentation in a minimum cut graph partitioning problem. The graph has a node for each sentence; edges are weighted using lexical similarity. Long-distance textual relationships are modeled by connecting all sentences. Affinity Propagation Segmentation (Kazantseva and Szpakowicz, 2011) also models such relationships but uses affinity propagation clustering (Frey and Dueck, 2007). The algorithm creates a factor graph and maximizes the segment similarity sum function. Alemi and Ginsparg (2015) proposed the Content Vector Segmentation (CVS) sentence vector representation based on segment word embeddings. Using this representation in C99 improves bag-ofwords results. In another line of research, Wang et al. (2017) combined learning to rank and a convolutional neural network to learn a coherence function between text pairs; higher-ranked pairs are likely to be segments. Despite"
K19-1054,N13-1019,0,0.509497,"words are assigned to topics such that probability mass is distributed on a small set of topically relevant words. In order to adapt this idea to segmentation, the model needs to be able to determine if sentences belong to the same topic (or mixture of topics). An example of such adaptation is the single-document segmentation model PLDA (Purver et al., 2006), where topic proportions are shared by sentences within the same segment. Segmentation is then determined through a binary topic shift sentence variable. Models such as TopicTiling (Riedl and Biemann, 2012), Structured Topic Model (STM) (Du et al., 2013), and NTSeg (Jameel and Lam, 2013) extend this LDA-based approach to segmentation. In all these approaches, topic identification is not possible since all segments are a mixture of topics. 3 In this paper, we adopt a probabilistic multidocument view on segmentation. Only two other models follow this approach: MultiSeg (Jeong and Titov, 2010) and Bayesseg-MD (Mota et al., 2016). MultiSeg uses a two-level LDA model where documents are generated using local and global topics. Local topics are specific to a document; global topics are shared between documents. Documents are mixtures of topics, but"
K19-1054,N18-2075,0,0.254601,"ntation based on segment word embeddings. Using this representation in C99 improves bag-ofwords results. In another line of research, Wang et al. (2017) combined learning to rank and a convolutional neural network to learn a coherence function between text pairs; higher-ranked pairs are likely to be segments. Despite a promising approach, stateof-the-art results were not achieved. Also following an approach using neural networks, is the SECTOR algorithm (Arnold et al., 2019), which uses a topic embedding trained based on utterance topic classification. Following the network architecture from (Koshorek et al., 2018), two stacked LSTM layers are used to decode word embedding representation of utterances. To recover segmentation, a TextTiling approach is applied to the topic embedding layer. The evaluation results show that SECTOR is able to improve a C99 baseline. • A novel joint model for topic segmentation and identification with a dynamic prior. • An inference procedure based on a beam search algorithm. • A study on how different modality-based segment length priors influence segmentation. 583 Just as we introduced average velocity we will now describe average acceleration. Notice when velocity changes"
K19-1054,N09-1040,0,0.858066,"cceleration need not coincide. Figure 1: Examples of segment excerpts from video, slide presentation, and PDF documents describing the accelaration topic. Words in bold depict shared vocabulary across segments. from the same segment are assigned the same topic. The inference procedure affords an exact maximum-likelihood estimation by exploring the segmentation space with a dynamic programming algorithm. This approach cannot be applied to multi-document segmentation since the hidden topic variables are integrated out; other single-document models following this approach also have this problem (Eisenstein, 2009; Malmasi et al., 2017). Bayesseg-MD sidesteps this problem by using lexically similar sentences from other documents. The word counts of such sentences are added to the segment likelihood estimation to reduce data sparseness. Despite using all documents for segment likelihood estimations, topic identification is not available. In this paper, we address these issues by designing an inference algorithm that explicitly tracks segment topic assignments. Probabilistic approaches to segmentation follow a setup similar to the LDA model: words are assigned to topics such that probability mass is dist"
K19-1054,P06-1004,0,0.182693,"ifference between algorithms is how lexical cohesion is implemented: some resort to lexical similarity; the remaining follow a probabilistic approach. Lexical approaches rely on a similarity metric between sentences, usually the cosine. A classic method is TextTiling (Hearst, 1997), which assumes that topic boundaries are found in consecutive sentences with a low similarity value; several other works built on this idea (Galley et al., 2003; Balagopalan et al., 2012). C99 (Choi, 2000) is another lexical approach, and uses a similarity matrix in a divisive clustering to obtain segments. MinCut (Malioutov and Barzilay, 2006) casts segmentation in a minimum cut graph partitioning problem. The graph has a node for each sentence; edges are weighted using lexical similarity. Long-distance textual relationships are modeled by connecting all sentences. Affinity Propagation Segmentation (Kazantseva and Szpakowicz, 2011) also models such relationships but uses affinity propagation clustering (Frey and Dueck, 2007). The algorithm creates a factor graph and maximizes the segment similarity sum function. Alemi and Ginsparg (2015) proposed the Content Vector Segmentation (CVS) sentence vector representation based on segment"
K19-1054,P17-1134,0,0.248385,"ot coincide. Figure 1: Examples of segment excerpts from video, slide presentation, and PDF documents describing the accelaration topic. Words in bold depict shared vocabulary across segments. from the same segment are assigned the same topic. The inference procedure affords an exact maximum-likelihood estimation by exploring the segmentation space with a dynamic programming algorithm. This approach cannot be applied to multi-document segmentation since the hidden topic variables are integrated out; other single-document models following this approach also have this problem (Eisenstein, 2009; Malmasi et al., 2017). Bayesseg-MD sidesteps this problem by using lexically similar sentences from other documents. The word counts of such sentences are added to the segment likelihood estimation to reduce data sparseness. Despite using all documents for segment likelihood estimations, topic identification is not available. In this paper, we address these issues by designing an inference algorithm that explicitly tracks segment topic assignments. Probabilistic approaches to segmentation follow a setup similar to the LDA model: words are assigned to topics such that probability mass is distributed on a small set"
K19-1054,D17-1139,0,0.0198192,"s are weighted using lexical similarity. Long-distance textual relationships are modeled by connecting all sentences. Affinity Propagation Segmentation (Kazantseva and Szpakowicz, 2011) also models such relationships but uses affinity propagation clustering (Frey and Dueck, 2007). The algorithm creates a factor graph and maximizes the segment similarity sum function. Alemi and Ginsparg (2015) proposed the Content Vector Segmentation (CVS) sentence vector representation based on segment word embeddings. Using this representation in C99 improves bag-ofwords results. In another line of research, Wang et al. (2017) combined learning to rank and a convolutional neural network to learn a coherence function between text pairs; higher-ranked pairs are likely to be segments. Despite a promising approach, stateof-the-art results were not achieved. Also following an approach using neural networks, is the SECTOR algorithm (Arnold et al., 2019), which uses a topic embedding trained based on utterance topic classification. Following the network architecture from (Koshorek et al., 2018), two stacked LSTM layers are used to decode word embedding representation of utterances. To recover segmentation, a TextTiling ap"
K19-1054,W09-3027,0,0.0486669,"Missing"
K19-1054,J02-1002,0,0.588749,"nt prior configurations are in Table 2. In the table, the LMP and SLP columns correspond to the language model and segment length priors. In the Biography dataset, we can see that using the dynamic LMP instead of the independent improves the the Beta-Bernoulli and Gamma-Poisson results by 0.01 and 0.09, respectively. In the AVL dataset, the dynamic LMP improves the best WD results of the independent LMP by 0.02. When comparing the scope results of the dynamic LMP in the AVL dataset, we observe further improvements when To measure performance, we use the standard Window Difference (WD) metric (Pevzner and Hearst, 2002). WD slides a window through a document and penalizes segmentations according to the difference between the number of expected segment boundaries and the predicted ones. This gives partial credit to near-miss situations. The 587 Table 3: Number of exact segment boundary matches between hypothesis and reference segmentations. Table 2: BeamSeg average WD results. The SLP column depicts the Beta-Bernoulli (BB), and GammaPoisson (GP) distributions. The scope indicates if the SLP is modality-based (M) or if there is one variable for the whole dataset (D). The Biography dataset has one modality, and"
K19-1054,P06-1003,0,0.0988903,"Missing"
K19-1054,W12-3307,0,0.0945838,"to segmentation follow a setup similar to the LDA model: words are assigned to topics such that probability mass is distributed on a small set of topically relevant words. In order to adapt this idea to segmentation, the model needs to be able to determine if sentences belong to the same topic (or mixture of topics). An example of such adaptation is the single-document segmentation model PLDA (Purver et al., 2006), where topic proportions are shared by sentences within the same segment. Segmentation is then determined through a binary topic shift sentence variable. Models such as TopicTiling (Riedl and Biemann, 2012), Structured Topic Model (STM) (Du et al., 2013), and NTSeg (Jameel and Lam, 2013) extend this LDA-based approach to segmentation. In all these approaches, topic identification is not possible since all segments are a mixture of topics. 3 In this paper, we adopt a probabilistic multidocument view on segmentation. Only two other models follow this approach: MultiSeg (Jeong and Titov, 2010) and Bayesseg-MD (Mota et al., 2016). MultiSeg uses a two-level LDA model where documents are generated using local and global topics. Local topics are specific to a document; global topics are shared between"
L16-1618,W15-2708,1,0.792185,"so confirmed that the amount of workers agreeing on a given instance is a good indicator of correctness. Given the aforementioned idiosyncrasies of the corpus, and in order to allow other researchers to make better use of this data, this resource is made available through the LRE Map4 with all the metadata associated with the annotation (annotator ID, time-on-task, expansion information, selfreported confidence). Additional work with this corpus can be found in Correia et al. (2014a), a small experiment on automatic classification of metadiscourse with an earlier version of the corpus; and in Correia et al. (2015), where it was exploited for understanding the use of metadiscourse in different levels of English proficiency. Future work includes using metaTED to build classifiers of metadiscourse that will identify and assign a function to the explicit cues given by speakers in a presentation transcript. 3912 4 http://www.resourcebook.eu 7. Acknowledgments This work was supported by national funds through Fundac¸a˜ o para a Ciˆencia e a Tecnologia (UID/CEC/50021/2013), Instituto Superior T´ecnico (BL184/2015), and Carnegie Mellon|Portugal program (SFRH/BD/51156/2010). 8. Bibliographical References ¨ Adel"
L16-1618,J93-2004,0,0.0609885,"ory (its form and its function in language), they do not contribute to the goal of corpora building. Even in the cases where some kind of annotation was performed, they are not freely available and/or are comprised of a limited number of examples used only to support the category organization decisions. Therefore, it is also important to look at approaches that represent extensive annotation efforts. From this standpoint, two distinct data-driven projects are broadly used and discussed. One is the Penn Discourse TreeBank (PDTB) (Webber and Joshi, 1998), built directly on top of Penn TreeBank (Marcus et al., 1993), composed of extracts from the Wall Street Journal. PDTB enriched the Penn TreeBank with discourse connectives annotation (conjunctions and adverbials), and organized them according to meaning (Miltsakaki et al., 2008), considering categories such as giving examples (I NSTANTIATION), making reformulations and clarifications (R ESTATEMENT), comparing (C ONTRAST), or showing cause (REASON). The second project is the RST Discourse Treebank (RSTDT) (Marcu, 2000), a semantics-free theoretical framework of discourse relations, intended to be “general enough to be applicable to naturally occurring t"
L16-1618,N03-1030,0,0.0154262,"d to be “general enough to be applicable to naturally occurring texts and concise enough to facilitate an algorithmic approach to discourse analysis”. Similarly to PDTB, the RSTDT is a discourse-annotated corpus intended to be used by the NLP community, based on Wall Street Journal articles extracted from the Penn Treebank. The difference between PDTB and the RSTDT is the discourse framework: in the latter case this is the Rhetorical Structure Theory (Mann and Thompson, 1988), which includes categories such as E X AMPLE , D EFINITION , or S UMMARY . Additionally, in the sequence of this work, Soricut and Marcu (2003) developed SPADE1 . SPADE stands for Sentence-level PArsing for DiscoursE and, as the name states, processes one sentence at a time and outputs one discourse parse tree per sentence. Even though PDTB and RSTDT make available two extensive corpora of different discourse functions, they have two drawbacks. Firstly, they do not address the metalinguistic aspects of language, i.e., do not make distinction between explicit and implicit use of the several discourse functions they analyze, as discussed in Section 1.; and, secondly, they are both built upon Wall Street Journal articles, meaning that t"
L16-1618,W98-0315,0,0.0441113,"ence. While the aforementioned studies discuss metadiscursive theory (its form and its function in language), they do not contribute to the goal of corpora building. Even in the cases where some kind of annotation was performed, they are not freely available and/or are comprised of a limited number of examples used only to support the category organization decisions. Therefore, it is also important to look at approaches that represent extensive annotation efforts. From this standpoint, two distinct data-driven projects are broadly used and discussed. One is the Penn Discourse TreeBank (PDTB) (Webber and Joshi, 1998), built directly on top of Penn TreeBank (Marcus et al., 1993), composed of extracts from the Wall Street Journal. PDTB enriched the Penn TreeBank with discourse connectives annotation (conjunctions and adverbials), and organized them according to meaning (Miltsakaki et al., 2008), considering categories such as giving examples (I NSTANTIATION), making reformulations and clarifications (R ESTATEMENT), comparing (C ONTRAST), or showing cause (REASON). The second project is the RST Discourse Treebank (RSTDT) (Marcu, 2000), a semantics-free theoretical framework of discourse relations, intended t"
L16-1618,P12-1067,0,0.0367532,"Missing"
N04-1028,H94-1039,0,0.611441,"Missing"
N07-1058,N04-4015,0,0.0221141,"Missing"
N07-1058,J93-2004,0,0.0489535,"ability measure relies on being able to automatically identify grammatical constructions in text. Doing so is a multi-step process that begins by syntactically parsing the document. The Stanford Parser (Klein and Manning, 2002) was used to produce constituent structure trees. The choice of parser is not essential to the approach, although the accuracy of parsing does play a role in successful identification of certain grammatical patterns. PCFG scores from the parser were also used to filter out some of the illformed text present in the test corpora. The default training set of Penn Treebank (Marcus et al. 1993) was used for the parser because the domain and style of those texts actually matches fairly well with the domain and style of the texts on which a reading level predictor for second language learners might be used. Once a document is parsed, the predictor uses Tgrep2 (Rohde, 2005), a tree structure searching tool, to identify instances of the target patterns. A Tgrep2 pattern defines dominance, sisterhood, precedence, and other relationships between nodes in the parse tree for a sentence. A pattern can also place constraints on the terminal symbols (e.g., words and punctuation), such that a p"
N07-1058,P05-1065,0,0.710256,"utoring system (Heilman, et al. 2006), aims to provide authentic reading materials of the appropriate difficulty level, in terms of both vocabulary and grammar, for English as a Second Language students. An automatic measure of readability that incorporated both lexical and grammatical features was thus needed. For first language (L1) learners (i.e., children learning their native tongue), reading level has been predicted using a variety of techniques, based on models of a student’s lexicon, grammatical surface features such as sentence length (Flesch, 1948), or combinations of such features (Schwarm and Ostendorf, 2005). It was shown by CollinsThompson and Callan (2004) that a vocabularybased language modeling approach was effective at predicting the readability of grades 1 to 12 of Web documents of varying length, even with high levels of noise. Prior work on first language readability by Schwarm and Ostendorf (2005) incorporated grammatical surface features such as parse tree depth and average number of verb phrases. This work combining grammatical and lexical features was promising, but it was not clear to what extent the grammatical features improved predictions. Also, discussions with L2 instructors sug"
N07-1058,N04-1025,1,\N,Missing
N09-1071,N04-1027,0,0.0238342,"what to say but also when to say it. Decades of research on Conversation Analysis and psycholinguistics (Duncan, 1972; Sacks et al., 1974; Orestr¨om, 1983; Schegloff, 2000; Wesseling and van Son, 2005) have shown that human turn-taking behavior relies on a wide range of rules and signals at many different levels of language, from prosody to syntax, semantics, and discourse structure. In contrast, turn-taking in spoken dialog systems is often reduced to ad hoc rules only based on very low level features. This simplistic approach leads to inefficient, unnatural, and possibly confusing behavior (Porzel and Baudis, 2004; Ward et al., 2005). ∗ This research was conducted when the first author was a student at the Language Technologies Institute. 629 Recently, more complex models of turn-taking have been proposed (Cassell et al., 2001; Thorisson, 2002; Kronild, 2006). Yet, these models still rely extensively on hand-coded expert knowledge and do not lend themselves to data-driven optimization. Furthermore, to our knowledge, no such model has been deployed in a widely used system outside of the laboratory. In this paper, we propose a flexible, practical model of turn-taking behavior that builds upon previous wo"
N09-1071,W08-0101,1,0.74704,"Missing"
N09-1071,P94-1001,0,0.0690505,"d Feldstein: U SER and SY ST EM represent states where one and only one of the participants claims the floor, F REES and F REEU states where no participant claims the floor (following, resp., a SY ST EM and U SER state), and BOT HS and BOT HU states where both participants claim the floor (following, resp. a SY ST EM and U SER state). However, we apply this model to the control of a conversational agent, with a goal similar to that of Cassel, Thorisson, and Kronild. One important distinction is that we define the states in terms of the participants’ intentions and obligations (in the sense of Traum and Allen (1994)) rather than the surface level observation of speech vs silence. For example, the state is U SER when the user has the obligation to speak (to respond to a system question) or the intention to speak, while at the same time, the system does not hold the floor. This does not necessarily mean that the user is speaking, for example at pauses during a user utterance. As can be seen in Figure 1, not all transitions are valid. First, there is no direct transition between any of the intermediate states (the two F REE states and two BOT H states). The assumption is that to go from any of these state t"
N19-1123,D18-1547,0,0.206878,"Missing"
N19-1123,E17-2029,0,0.0298589,"dialogs (Das et al., 2017), grounded dialog (Mordatch and Abbeel, 2017) etc. As discussed in Section 1, these methods consider the output vocabulary at every decoding step to be the action space; they suffer from limitations such as deviation from natural language and sub-optimal convergence. Finally, research in latent variable dialog models is closely related to our work, which strives to learn meaningful latent variables for E2E dialog systems. Prior work has shown that learning with latent variables leads to benefits like diverse response decoding (Serban et al., 2017b; Zhao et al., 2017; Cao and Clark, 2017), interpretable decision-making (Wen et al., 2017; Zhao et al., 2018) and zero-shot domain transfer (Zhao and Eskenazi, 2018). Also, driven by similar motivations of this work, prior studies have explored to utilize a coarse discrete node, either handcrafted or learned, to decouple the word generation process from dialog policy in E2E systems for better dialog policy (He et al., 2018; Yarats and Lewis, 2017). Our work differs from prior work for two reasons: (1) latent action in previous work is only auxiliary, small-scale and mostly learned in a supervised or semi-supervised setting. This pap"
N19-1123,P17-1045,0,0.0372458,"context. The format of the dialog context is domain dependent. It can vary from tex1209 Figure 1: High-level comparison between word-level and latent-action reinforcement learning in a sample multiturn dialog. The decoder network generates the response given the latent code z. Dashed line denotes places where policy gradients from task rewards are applied to the model. tual raw dialog history (Vinyals and Le, 2015) to visual and textual context (Das et al., 2017). Training with RL usually has 2 steps: supervised pretraining and policy gradient reinforcement learning (Williams and Zweig, 2016; Dhingra et al., 2017; Li et al., 2016). Specifically, the supervised learning step maximizes the log likelihood on the training dialogs, where θ is the model parameter: LSL (θ) = Ex,c [log pθ (x|c)] (1) Then the following RL step uses policy gradients, e.g. the REINFORCE algorithm (Williams, 1992) to update the model parameters with respect to task-dependent goals. We assume that we have an environment that the dialog agent can interact with and that there is a turn-level reward rt at every turn t of the dialog. We can then write the expected discounted return under a dialog model θ as P J(θ) = E[ T0 γ t rt ], wh"
N19-1123,D18-1256,0,0.522141,"te as the word-level RL. Word-level RL, however, has been shown to have several major limitations in learning dialog strategies. The foremost one is that direct application of word-level RL leads to degenerate behavior: the response decoder deviates from human language and generates utterances that are incomprehensible (Lewis et al., 2017; Das et al., 2017; Kottur et al., 2017). A second issue is that since a multi-turn dialog can easily span hundreds of words, word-level RL suffers from credit assignment over a long horizon, leading to slow and suboptimal convergence (Kaelbling et al., 1996; He et al., 2018). This paper proposes Latent Action Reinforcement Learning (LaRL), a novel framework that overcomes the limitations of word-level RL for E2E dialog models, marrying the benefits of a traditional modular approach in an unsupervised manner. The key idea is to develop E2E models that can invent their own discourse-level ac1208 Proceedings of NAACL-HLT 2019, pages 1208–1218 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics tions. These actions must be expressive enough to capture response semantics in complex domains (i.e. have the capacity to represen"
N19-1123,W14-4340,0,0.0400757,"e.g. it is crucial to reduce the exposure bias in the latent action space and discrete latent actions are more suitable than continuous ones to serve as action spaces for RL dialog agents. 2 Related Work Prior RL research in modular dialog management has focused on policy optimization over hand-crafted action spaces in task-oriented domains (Walker, 2000; Young et al., 2007). A dialog manager is formulated as a Partially Observable Markov Decision Process (POMDP) (Young et al., 2013), where the dialog state is estimated via dialog state tracking models from the raw dialog context (Lee, 2013; Henderson et al., 2014; Ren et al., 2018). RL techniques are then used to find the optimal dialog policy (Gasic and Young, 2014; Su et al., 2017; Williams et al., 2017). Recent deep-learning modular dialog models have also explored joint optimization over dialog policy and state tracking to achieve stronger performance (Wen et al., 2016; Zhao and Eskenazi, 2016; Liu and Lane, 2017). A related line of work is reinforcement learning for E2E dialog systems. Due to the flexibility of encoder-decoder dialog models, prior work has applied reinforcement learning to more complex domains and achieved higher dialog-level rew"
N19-1123,D17-1321,0,0.0228036,"inyals and Le, 2015; Sordoni et al., 2015). To apply RL to E2E systems, the action space is typically defined as the entire vocabulary; every response output word is considered to be an action selection step (Li et al., 2016), which we denote as the word-level RL. Word-level RL, however, has been shown to have several major limitations in learning dialog strategies. The foremost one is that direct application of word-level RL leads to degenerate behavior: the response decoder deviates from human language and generates utterances that are incomprehensible (Lewis et al., 2017; Das et al., 2017; Kottur et al., 2017). A second issue is that since a multi-turn dialog can easily span hundreds of words, word-level RL suffers from credit assignment over a long horizon, leading to slow and suboptimal convergence (Kaelbling et al., 1996; He et al., 2018). This paper proposes Latent Action Reinforcement Learning (LaRL), a novel framework that overcomes the limitations of word-level RL for E2E dialog models, marrying the benefits of a traditional modular approach in an unsupervised manner. The key idea is to develop E2E models that can invent their own discourse-level ac1208 Proceedings of NAACL-HLT 2019, pages 1"
N19-1123,W13-4069,0,0.0279701,"l insights, e.g. it is crucial to reduce the exposure bias in the latent action space and discrete latent actions are more suitable than continuous ones to serve as action spaces for RL dialog agents. 2 Related Work Prior RL research in modular dialog management has focused on policy optimization over hand-crafted action spaces in task-oriented domains (Walker, 2000; Young et al., 2007). A dialog manager is formulated as a Partially Observable Markov Decision Process (POMDP) (Young et al., 2013), where the dialog state is estimated via dialog state tracking models from the raw dialog context (Lee, 2013; Henderson et al., 2014; Ren et al., 2018). RL techniques are then used to find the optimal dialog policy (Gasic and Young, 2014; Su et al., 2017; Williams et al., 2017). Recent deep-learning modular dialog models have also explored joint optimization over dialog policy and state tracking to achieve stronger performance (Wen et al., 2016; Zhao and Eskenazi, 2016; Liu and Lane, 2017). A related line of work is reinforcement learning for E2E dialog systems. Due to the flexibility of encoder-decoder dialog models, prior work has applied reinforcement learning to more complex domains and achieved"
N19-1123,D17-1259,0,0.133032,"the proposed latent actions achieve superior empirical performance improvement over previous word-level policy gradient methods on both DealOrNoDeal and MultiWoz dialogs. Our detailed analysis also provides insights about various latent variable approaches for policy learning and can serve as a foundation for developing better latent actions in future research. 1 1 Introduction Optimizing dialog strategies in multi-turn dialog models is the cornerstone of building dialog systems that more efficiently solve real-world challenges, e.g. providing information (Young, 2006), winning negotiations (Lewis et al., 2017), improving engagement (Li et al., 2016) etc. A classic solution employs reinforcement learning (RL) to learn a dialog policy that models the optimal action distribution conditioned on the dialog state (Williams and Young, 2007). However, since there are infinite human language possibilities, an enduring challenge has been to define what the 1 Data and code are available at https://github. com/snakeztc/NeuralDialog-LaRL action space is. For traditional modular systems, the action space is defined by hand-crafted semantic representations such as dialog acts and slotvalues (Raux et al., 2005; Ch"
N19-1123,D16-1127,0,0.706118,"or empirical performance improvement over previous word-level policy gradient methods on both DealOrNoDeal and MultiWoz dialogs. Our detailed analysis also provides insights about various latent variable approaches for policy learning and can serve as a foundation for developing better latent actions in future research. 1 1 Introduction Optimizing dialog strategies in multi-turn dialog models is the cornerstone of building dialog systems that more efficiently solve real-world challenges, e.g. providing information (Young, 2006), winning negotiations (Lewis et al., 2017), improving engagement (Li et al., 2016) etc. A classic solution employs reinforcement learning (RL) to learn a dialog policy that models the optimal action distribution conditioned on the dialog state (Williams and Young, 2007). However, since there are infinite human language possibilities, an enduring challenge has been to define what the 1 Data and code are available at https://github. com/snakeztc/NeuralDialog-LaRL action space is. For traditional modular systems, the action space is defined by hand-crafted semantic representations such as dialog acts and slotvalues (Raux et al., 2005; Chen et al., 2013) and the goal is to obta"
N19-1123,D15-1166,0,0.0390974,"layers E1:M (z1:M ), whereas the decoder’s initial state is a vector of size RD . Previous work integrated this matrix with the decoder by summing PM over the latent embeddings, i.e. x = pθd ( 1 Em (zm )), denoted as Summation Fusion for later discussion (Zhao et al., 2018). A limitation of this method is that it could lose fine-grained order information in each latent dimension and have issues with long responses that involve multiple dialog acts. Therefore, we propose a novel method, Attention Fusion, to combine categorical latent actions with the decoder. We apply the attention mechanism (Luong et al., 2015) over latent actions as the following. Let i be the step index during decoding. Then we have: αmi = softmax(hTi Wa Em (zm )) (10) ci = M X αmi Em (zm ) (11) m=1   h e hi = tanh(Ws i ) ci p(wi |hi , ci ) = softmax(Wo hei ) (12) (13) The decoder’s next state is updated by hi+1 = RNN(hi , wi+1 ), hei ) and h0 is computed via summation-fusion. Thus attention fusion lets the decoder focus on different latent dimensions at each generation step. 4.2 Optimization Approaches Full ELBO: Now given a training dataset {x, c}, our base optimization method is via stochastic variational inference by maximiz"
N19-1123,D18-1299,1,0.89521,"Missing"
N19-1123,N15-1020,0,0.0855056,"Missing"
N19-1123,W18-5001,1,0.681943,"sider the output vocabulary at every decoding step to be the action space; they suffer from limitations such as deviation from natural language and sub-optimal convergence. Finally, research in latent variable dialog models is closely related to our work, which strives to learn meaningful latent variables for E2E dialog systems. Prior work has shown that learning with latent variables leads to benefits like diverse response decoding (Serban et al., 2017b; Zhao et al., 2017; Cao and Clark, 2017), interpretable decision-making (Wen et al., 2017; Zhao et al., 2018) and zero-shot domain transfer (Zhao and Eskenazi, 2018). Also, driven by similar motivations of this work, prior studies have explored to utilize a coarse discrete node, either handcrafted or learned, to decouple the word generation process from dialog policy in E2E systems for better dialog policy (He et al., 2018; Yarats and Lewis, 2017). Our work differs from prior work for two reasons: (1) latent action in previous work is only auxiliary, small-scale and mostly learned in a supervised or semi-supervised setting. This paper focuses on unsupervised learning of latent variables and learns variables that are expressive enough to capture the entire"
N19-1123,P18-1101,1,0.904314,"etc. As discussed in Section 1, these methods consider the output vocabulary at every decoding step to be the action space; they suffer from limitations such as deviation from natural language and sub-optimal convergence. Finally, research in latent variable dialog models is closely related to our work, which strives to learn meaningful latent variables for E2E dialog systems. Prior work has shown that learning with latent variables leads to benefits like diverse response decoding (Serban et al., 2017b; Zhao et al., 2017; Cao and Clark, 2017), interpretable decision-making (Wen et al., 2017; Zhao et al., 2018) and zero-shot domain transfer (Zhao and Eskenazi, 2018). Also, driven by similar motivations of this work, prior studies have explored to utilize a coarse discrete node, either handcrafted or learned, to decouple the word generation process from dialog policy in E2E systems for better dialog policy (He et al., 2018; Yarats and Lewis, 2017). Our work differs from prior work for two reasons: (1) latent action in previous work is only auxiliary, small-scale and mostly learned in a supervised or semi-supervised setting. This paper focuses on unsupervised learning of latent variables and learns va"
N19-1123,P17-1061,1,0.865693,"al., 2017), visual dialogs (Das et al., 2017), grounded dialog (Mordatch and Abbeel, 2017) etc. As discussed in Section 1, these methods consider the output vocabulary at every decoding step to be the action space; they suffer from limitations such as deviation from natural language and sub-optimal convergence. Finally, research in latent variable dialog models is closely related to our work, which strives to learn meaningful latent variables for E2E dialog systems. Prior work has shown that learning with latent variables leads to benefits like diverse response decoding (Serban et al., 2017b; Zhao et al., 2017; Cao and Clark, 2017), interpretable decision-making (Wen et al., 2017; Zhao et al., 2018) and zero-shot domain transfer (Zhao and Eskenazi, 2018). Also, driven by similar motivations of this work, prior studies have explored to utilize a coarse discrete node, either handcrafted or learned, to decouple the word generation process from dialog policy in E2E systems for better dialog policy (He et al., 2018; Yarats and Lewis, 2017). Our work differs from prior work for two reasons: (1) latent action in previous work is only auxiliary, small-scale and mostly learned in a supervised or semi-superv"
P14-5001,D10-1036,0,0.108076,"al leg: 0.21; physical therapist: 0.15; rehabilitation: 0.08; … (Chinese) 義肢: 0.41; 物理治療師: 0.15; 康復:0.10; 阿富汗: 0.08, … English Keywords from Bilingual Perspectives: prosthesis, artificial, leg, rehabilitation, orthopedic, … Figure 1. An example BiKEA keyword analysis for an article. accommodate words with similar meaning. And Huang and Ku (2013) weigh PageRank edges based on nodes’ degrees of reference. In contrast, we bridge PageRank graphs of parallel articles to facilitate statistics re-distribution or interaction between the involved languages. In studies more closely related to our work, Liu et al. (2010) and Zhao et al. (2011) present PageRank algorithms leveraging article topic information for keyword identification. The main differences from our current work are that the article topics we exploit are specified by humans not by automated systems, and that our PageRank graphs are built and connected bilingually. In contrast to the previous research in keyword extraction, we present a system that automatically learns topical keyword preferences and constructs and inter-connects PageRank graphs in bilingual context, expected to yield better and more accurate keyword lists for articles. To the b"
P14-5001,W03-1726,0,0.0163731,"Missing"
P14-5001,I13-1117,1,0.809982,"我們只是給他們 提供義肢。 花了很多年的程序 才讓這計劃成為現在的模樣。… Word Alignment Information: physical (物理), therapist (治療師), social (社會), reintegration (重返), physical (身體), rehabilitation (康 復), prosthesis (義肢), … Scores of Topical Keyword Preferences for Words: (English) prosthesis: 0.32; artificial leg: 0.21; physical therapist: 0.15; rehabilitation: 0.08; … (Chinese) 義肢: 0.41; 物理治療師: 0.15; 康復:0.10; 阿富汗: 0.08, … English Keywords from Bilingual Perspectives: prosthesis, artificial, leg, rehabilitation, orthopedic, … Figure 1. An example BiKEA keyword analysis for an article. accommodate words with similar meaning. And Huang and Ku (2013) weigh PageRank edges based on nodes’ degrees of reference. In contrast, we bridge PageRank graphs of parallel articles to facilitate statistics re-distribution or interaction between the involved languages. In studies more closely related to our work, Liu et al. (2010) and Zhao et al. (2011) present PageRank algorithms leveraging article topic information for keyword identification. The main differences from our current work are that the article topics we exploit are specified by humans not by automated systems, and that our PageRank graphs are built and connected bilingually. In contrast to"
P14-5001,J00-2011,0,0.145924,"idging is to take language divergence into account and to allow for language-wise interaction over word statistics. BiKEA, then in bilingual context, iterates with learned word keyness scores to find keywords. In our prototype, BiKEA returns keyword candidates of the article for keyword evaluation (see Figure 1); alternatively, the keywords returned by BiKEA can be used as candidates for social tagging the article or used as input to an article recommendation system. 2 Related Work Keyword extraction has been an area of active research and applied to NLP tasks such as document categorization (Manning and Schutze, 2000), indexing (Li et al., 2004), and text mining on social networking services ((Li et al., 2010); (Zhao et al., 2011); (Wu et al., 2010)). The body of KEA focuses on learning word statistics in document collection. Approaches such as tfidf and entropy, using local document and/or across-document information, pose strong baselines. On the other hand, Mihalcea and Tarau (2004) apply PageRank, connecting words locally, to extract essential words. In our work, we leverage globally learned keyword preferences in PageRank to identify keywords. Recent work has been done on incorporating semantics into"
P14-5001,J03-1002,0,0.00588597,"to [1/v,1/ v, …,1/v] repeat Figure 4. Constructing PageRank word graph. Step (3) in Figure 3 linearly combines word graphs EWe and EWc using α. We use α to balance language properties or statistics, and BiKEA backs off to monolingual KEA if α is one. In Step (4) of Figure 3 for each word alignment (wic, wje), we construct a link between the word nodes with the weight BiWeight. The inter-language link is to reinforce language similarities and respect language divergence while the weight aims to elevate the crosslanguage statistics interaction. Word alignments are derived using IBM models 1-5 (Och and Ney, 2003). The inter-language link is directed from wic to wje, basically from language c to e based on the directional word-aligning entry (wic, wje). The bridging is expected to help keyword extraction in language e with the statistics in language c. Although alternative approach can be used for bridging, our approach is intuitive, and most importantly in compliance with the directional spirit of PageRank. Step (6) sets KP of keyword preference model using topical preference scores learned from Section 3.2, while Step (7) initializes KN of PageRank scores or, in our case, word keyness scores. Then we"
P14-5001,N03-1017,0,0.00743078,"Missing"
P14-5001,H05-1059,0,0.0146916,"Missing"
P14-5001,N10-1101,0,0.0307704,"text, iterates with learned word keyness scores to find keywords. In our prototype, BiKEA returns keyword candidates of the article for keyword evaluation (see Figure 1); alternatively, the keywords returned by BiKEA can be used as candidates for social tagging the article or used as input to an article recommendation system. 2 Related Work Keyword extraction has been an area of active research and applied to NLP tasks such as document categorization (Manning and Schutze, 2000), indexing (Li et al., 2004), and text mining on social networking services ((Li et al., 2010); (Zhao et al., 2011); (Wu et al., 2010)). The body of KEA focuses on learning word statistics in document collection. Approaches such as tfidf and entropy, using local document and/or across-document information, pose strong baselines. On the other hand, Mihalcea and Tarau (2004) apply PageRank, connecting words locally, to extract essential words. In our work, we leverage globally learned keyword preferences in PageRank to identify keywords. Recent work has been done on incorporating semantics into PageRank. For example, Liu et al. (2010) construct PageRank synonym graph to 3 The BiKEA System Submitting natural language articles t"
P14-5001,W08-1404,0,0.0608117,"Missing"
P17-1061,D16-1230,0,0.227895,"ith the same topics. Then the 10 candidate references are filtered by two experts, which serve as the ground truth to train the reference response classifier. The result is 6.69 extra references in average per context. The average number of distinct reference dialog acts is 4.2. Table 1 shows the results. pling from the softmax. For CVAE/kgCVAE, we sample N times from the latent z and only use greedy decoders so that the randomness comes entirely from the latent variable z. 5.2 Quantitative Analysis Automatically evaluating an open-domain generative dialog model is an open research challenge (Liu et al., 2016). Following our one-tomany hypothesis, we propose the following metrics. We assume that for a given dialog context c, there exist Mc reference responses rj , j ∈ [1, Mc ]. Meanwhile a model can generate N hypothesis responses hi , i ∈ [1, N ]. The generalized responselevel precision/recall for a given dialog context is: PN maxj∈[1,Mc ] d(rj , hi ) precision(c) = i=1 N PMc j=1 maxi∈[1,N ] d(rj , hi )) recall(c) = Mc Metrics perplexity (KL) BLEU-1 prec BLEU-1 recall BLEU-2 prec BLEU-2 recall BLEU-3 prec BLEU-3 recall BLEU-4 prec BLEU-4 recall A-bow prec A-bow recall E-bow prec E-bow recall DA pr"
P17-1061,P02-1040,0,0.12473,"all BLEU-3 prec BLEU-3 recall BLEU-4 prec BLEU-4 recall A-bow prec A-bow recall E-bow prec E-bow recall DA prec DA recall where d(rj , hi ) is a distance function which lies between 0 to 1 and measures the similarities between rj and hi . The final score is averaged over the entire test dataset and we report the performance with 3 types of distance functions in order to evaluate the systems from various linguistic points of view: 1. Smoothed Sentence-level BLEU (Chen and Cherry, 2014): BLEU is a popular metric that measures the geometric mean of modified ngram precision with a length penalty (Papineni et al., 2002; Li et al., 2015). We use BLEU-1 to 4 as our lexical similarity metric and normalize the score to 0 to 1 scale. Baseline 35.4 (n/a) 0.405 0.336 0.300 0.281 0.272 0.254 0.226 0.215 0.387 0.337 0.701 0.684 0.736 0.514 CVAE 20.2 (11.36) 0.372 0.381 0.295 0.322 0.265 0.292 0.223 0.248 0.389 0.361 0.705 0.709 0.704 0.604 kgCVAE 16.02 (13.08) 0.412 0.411 0.350 0.356 0.310 0.318 0.262 0.272 0.373 0.336 0.711 0.712 0.721 0.598 Table 1: Performance of each model on automatic measures. The highest score in each row is in bold. Note that our BLEU scores are normalized to [0, 1]. 2. Cosine Distance of Ba"
P17-1061,D14-1162,0,0.115016,"me that xo and xbow are conditionally independent given z and c: p(x, z|c) = p(xo |z, c)p(xbow |z, c)p(z|c). Due to the conditional independence assumption, the latent variable is forced to capture global information about the target response. Let f = MLPb (z, x) ∈ RV where V is vocabulary size, and we have: log p(xbow |z, c) = log |x| Y e fx t PV f j j e t=1 4.2 We trained with the following hyperparameters (according to the loss on the validate dataset): word embedding has size 200 and is shared across everywhere. We initialize the word embedding from Glove embedding pre-trained on Twitter (Pennington et al., 2014). The utterance encoder has a hidden size of 300 for each direction. The context encoder has a hidden size of 600 and the response decoder has a hidden size of 400. The prior network and the MLP for predicting y both have 1 hidden layer of size 400 and tanh non-linearity. The latent variable z has a size of 200. The context window k is 10. All the initial weights are sampled from a uniform distribution [-0.08, 0.08]. The mini-batch size is 30. The models are trained end-to-end using the Adam optimizer (Kingma and Ba, 2014) with a learning rate of 0.001 and gradient clipping at 5. We selected t"
P17-1061,W14-3346,0,0.0891219,"Missing"
P17-1061,P16-1094,0,0.35993,"search has found that encoder-decoder models tend to generate generic and dull responses (e.g., I don’t know), rather than meaningful and specific answers (Li et al., 2015; Serban et al., 2016b). There have been many attempts to explain and solve this limitation, and they can be broadly divided into two categories (see Section 2 for details): (1) the first category argues that the dialog history is only one of the factors that decide the next response. Other features should be extracted and provided to the models as conditionals in order to generate more specific responses (Xing et al., 2016; Li et al., 2016a); (2) the second category aims to improve the encoder-decoder model itself, including decoding with beam search and its variations (Wiseman and Rush, 2016), encouraging responses that have long-term payoff (Li et al., 2016b), etc. Building upon the past work in dialog managers and encoder-decoder models, the key idea of this paper is to model dialogs as a one-to-many problem at the discourse level. Previous studies indicate that there are many factors in open-domain dialogs that decide the next response, and it is nontrivial to extract all of them. Intuitively, given a similar dialog history"
P17-1061,D16-1127,0,0.506991,"search has found that encoder-decoder models tend to generate generic and dull responses (e.g., I don’t know), rather than meaningful and specific answers (Li et al., 2015; Serban et al., 2016b). There have been many attempts to explain and solve this limitation, and they can be broadly divided into two categories (see Section 2 for details): (1) the first category argues that the dialog history is only one of the factors that decide the next response. Other features should be extracted and provided to the models as conditionals in order to generate more specific responses (Xing et al., 2016; Li et al., 2016a); (2) the second category aims to improve the encoder-decoder model itself, including decoding with beam search and its variations (Wiseman and Rush, 2016), encouraging responses that have long-term payoff (Li et al., 2016b), etc. Building upon the past work in dialog managers and encoder-decoder models, the key idea of this paper is to model dialogs as a one-to-many problem at the discourse level. Previous studies indicate that there are many factors in open-domain dialogs that decide the next response, and it is nontrivial to extract all of them. Intuitively, given a similar dialog history"
P17-1061,N15-1020,0,0.191802,"Missing"
P17-1061,D16-1137,0,0.0282858,"Missing"
P17-1061,W16-3649,0,0.0165551,"es than baseline approaches and exhibit competence in discourse-level decision-making. 1 Introduction The dialog manager is one of the key components of dialog systems, which is responsible for modeling the decision-making process. Specifically, it typically takes a new utterance and the dialog context as input, and generates discourse-level decisions (Bohus and Rudnicky, 2003; Williams and Young, 2007). Advanced dialog managers usually have a list of potential actions that enable them to have diverse behavior during a conversation, e.g. different strategies to recover from non-understanding (Yu et al., 2016). However, the conventional approach of designing a dialog manager (Williams and Young, 2007) does not 654 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 654–664 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1061 cific responses. Li et al., (2016a) captured speakers’ characteristics by encoding background information and speaking style into the distributed embeddings, which are used to re-rank the generated response from an encoder-decoder model. Xing et al., (2016) m"
P17-1061,W16-3601,1,0.0265829,"e decoder then predicts the words in x sequentially. L(θ, φ; x, c, y) = −KL(qφ (z|x, c, y)kPθ (z|c)) + Eqφ (z|c,x,y) [log p(x|z, c, y)] 3.2 Knowledge-Guided CVAE (kgCVAE) In practice, training CVAE is a challenging optimization problem and often requires large amount of data. On the other hand, past research in spoken dialog systems and discourse analysis has suggested that many linguistic cues capture crucial features in representing natural conversation. For example, dialog acts (Poesio and Traum, 1998) have been widely used in the dialog managers (Litman and Allen, 1987; Raux et al., 2005; Zhao and Eskenazi, 2016) to represent the propositional function of the system. Therefore, we conjecture that it will be beneficial for the model to learn meaningful latent z if it is provided with explicitly extracted discourse features during the training. In order to incorporate the linguistic features into the basic CVAE model, we first denote the set of linguistic features as y. Then we assume that the generation of x depends on c, z and y. y relies on z and c as shown in Figure 2. Specifically, during training the initial state of the response decoder is s0 = Wi [z, c, y] + bi and the input at every step is [et"
P17-1061,J00-3003,0,\N,Missing
P18-1101,N16-1162,0,0.092384,"Missing"
P18-1101,P16-1094,0,0.196182,". The dialog manager of a conventional dialog system outputs the system’s next action in a semantic frame that usually contains hand-crafted dialog acts and slot values (Williams and Young, 2007). Then a natural language generation module is used to generate the system’s output in natural language based on the given semantic frame. This approach suffers from generalization to more complex domains because it soon become intractable to man1 Data and code are available at https://github. com/snakeztc/NeuralDialog-LAED. Although generative dialog models have advanced rapidly (Serban et al., 2016; Li et al., 2016; Zhao et al., 2017), they cannot provide interpretable system actions as in the conventional dialog systems. This inability limits the effectiveness of generative dialog models in several ways. First, having interpretable system actions enables human to understand the behavior of a dialog system and better interpret the system intentions. Also, modeling the high-level decision-making policy in dialogs enables useful generalization and dataefficient domain adaptation (Gaˇsi´c et al., 2010). Therefore, the motivation of this paper is to develop an unsupervised neural recognition model that can"
P18-1101,I17-1099,0,0.0420051,"re-processed by Mikolov (Mikolov et al., 2010). The second dataset is the Stanford Multi-Domain Dialog (SMD) dataset that contains 3,031 human-Woz, task-oriented dialogs collected from 3 different domains (navigation, weather and scheduling) (Eric and Manning, 2017). The other two datasets are chat-oriented data: Daily Dialog (DD) and Switchboard (SW) (Godfrey and Holliman, 1997), which are used to test whether our methods can generalize beyond task-oriented dialogs but also to to open-domain chatting. DD contains 13,118 multi-turn human-human dialogs annotated with dialog acts and emotions. (Li et al., 2017). SW has 2,400 human-human telephone conversations that are annotated with topics and dialog acts. SW is a more challenging dataset because it is transcribed from speech which contains complex spoken language phenomenon, e.g. hesitation, self-repair etc. 4.1 Comparing Discrete Sentence Representation Models The first experiment used PTB and DD to evaluate the performance of the proposed methods in learning discrete sentence representations. We implemented DI-VAE and DI-VST using GRURNN (Chung et al., 2014) and trained them using Adam (Kingma and Ba, 2014). Besides the proposed methods, the fol"
P18-1101,W10-4334,0,0.0863674,"Missing"
P18-1101,J93-2004,0,0.060596,"dialog generation. First LCVAE encourages I(x, z|c) (Agakov, 2005), which learns z that capture context-dependent semantics. More intuitively, z in CVAE is trained to generate x via p(x|z, c) so the meaning of learned z can only be interpreted along with its context c. Therefore this violates our goal of learning context-independent semantics. Our methods learn qR (z|x) that only depends on x and trains qR separately to ensure the semantics of z are interpretable standalone. 4 Experiments and Results The proposed methods are evaluated on four datasets. The first corpus is Penn Treebank (PTB) (Marcus et al., 1993) used to evaluate sentence VAEs (Bowman et al., 2015). We used the version pre-processed by Mikolov (Mikolov et al., 2010). The second dataset is the Stanford Multi-Domain Dialog (SMD) dataset that contains 3,031 human-Woz, task-oriented dialogs collected from 3 different domains (navigation, weather and scheduling) (Eric and Manning, 2017). The other two datasets are chat-oriented data: Daily Dialog (DD) and Switchboard (SW) (Godfrey and Holliman, 1997), which are used to test whether our methods can generalize beyond task-oriented dialogs but also to to open-domain chatting. DD contains 13,1"
P18-1101,P17-1061,1,0.604597,"ger of a conventional dialog system outputs the system’s next action in a semantic frame that usually contains hand-crafted dialog acts and slot values (Williams and Young, 2007). Then a natural language generation module is used to generate the system’s output in natural language based on the given semantic frame. This approach suffers from generalization to more complex domains because it soon become intractable to man1 Data and code are available at https://github. com/snakeztc/NeuralDialog-LAED. Although generative dialog models have advanced rapidly (Serban et al., 2016; Li et al., 2016; Zhao et al., 2017), they cannot provide interpretable system actions as in the conventional dialog systems. This inability limits the effectiveness of generative dialog models in several ways. First, having interpretable system actions enables human to understand the behavior of a dialog system and better interpret the system intentions. Also, modeling the high-level decision-making policy in dialogs enables useful generalization and dataefficient domain adaptation (Gaˇsi´c et al., 2010). Therefore, the motivation of this paper is to develop an unsupervised neural recognition model that can discover interpretab"
P18-1101,P17-1029,0,0.026976,"earning regularized continuous sentence representation, which enables sentence generation by sampling the latent space (Bowman et al., 2015; Kim et al., 2017). There is less work on discrete sentence representations due to the difficulty of passing gradients through discrete outputs. The recently developed Gumbel Softmax (Jang et al., 2016; Maddison et al., 2016) and vector quantization (van den Oord et al., 2017) enable us to train discrete variables. Notably, discrete variable models have been proposed to discover document topics (Miao et al., 2016) and semi-supervised sequence transaction (Zhou and Neubig, 2017) Our work differs from these as follows: (1) we focus on learning interpretable variables; in prior research the semantics of latent variables are mostly ignored in the dialog generation setting. (2) we improve the learning objective for discrete VAEs and overcome the well-known posterior collapsing issue (Bowman et al., 2015; Chen et al., 2016). (3) we focus on unsupervised learning of salient features in dialog responses instead of hand-crafted features. 3 Proposed Methods Our formulation contains three random variables: the dialog context c, the response x and the latent action z. The conte"
P18-1101,D07-1043,0,0.060605,"Missing"
P18-1101,J00-3003,0,0.74685,"Missing"
P18-1101,W07-0305,1,\N,Missing
P18-1101,W17-5506,0,\N,Missing
P19-1373,P17-1080,0,0.0310014,") T αgt = hT−1 rgt (5) αj = hT−1 T rj (6) where fu , fc and fr are three distinct biLSTM models that are to be trained. The final loss function is: L = − log p(uT |u1 , ...uT −1 ) = − log 3.2 exp(αgt ) P exp(αgt ) + K j=1 exp(αj ) (7) ! Next-Utterance Generation NUG is the task of generating the next utterance conditioned on the past dialog context. Sequenceto-sequence models (Sutskever et al., 2014; Bahdanau et al., 2015) have been used for pretraining (Dai and Le, 2015; McCann et al., 2017), and have been shown to learn representations that are useful for downstream tasks (Adi et al., 2016; Belinkov et al., 2017). The hierarchical recurrent encoder-decoder architecture (Serban et al., 2016) was used during NUG pretraining. Although the decoder is used in pretraining, only the hierarchical context encoder is transferred to the downstream tasks. Similarly to NUR, the optimization goal of NUG is to maximize the log-likelihood of the next utterance given 3838 the previous utterances. However, it differs in that it factors the conditional distribution to word-level in an auto-regressive manner. Specifically, let the word tokens in uT be [w1 , ...wN ]. The dialog context is encoded as in Eq 8 with an uttera"
P19-1373,D18-1547,0,0.411977,"er (Serban et al., 2016) with four different unsupervised pretraining objectives. Two of the objectives, nextutterance generation (Vinyals and Le, 2015) and retrieval (Lowe et al., 2016), have been explored in previous work. The other two pretraining objectives, masked-utterance retrieval and inconsistency identification, are novel. The pretrained dialog encoder is then evaluated on several downstream tasks that probe the quality of the learned context representation by following the typical pretrain & fine-tune procedure. Pretraining and downstream evaluation use the MultiWoz dialog dataset (Budzianowski et al., 2018), which contains over 10,000 dialogs spanning 6 different domains. The downstream tasks include next-utterance generation (NUG), nextutterance retrieval (NUR), dialog act prediction (DAP), and belief state prediction (BSP). The pretraining objectives are assessed under four different hypotheses: (1) that pretraining will improve downstream tasks with fine-tuning on the entire available data, (2) that pretraining will result in better convergence, (3) that pretraining will perform strongly with limited data and (4) that pretraining facilitates domain generalizability. The results here show that"
P19-1373,P17-1168,0,0.0324356,"ence, models that are less data hungry and have better domain generalizability. 1 Introduction Learning meaningful representations of multi-turn dialog contexts is the cornerstone of dialog systems. In order to generate an appropriate response, a system must be able to aggregate information over multiple turns, such as estimating a belief state over user goals (Williams et al., 2013) and resolving anaphora co–references (Mitkov, 2014). In the past, significant effort has gone into developing better neural dialog architectures to improve context modeling given the same in-domain training data (Dhingra et al., 2017; Zhou et al., 2016). Recent advances in pretraining on massive amounts of text data have led to state-of-theart results on a range of natural language processing (NLP) tasks (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018) including natural language inference, question answering and text classification. These promising results suggest a new direction for improving context modeling by creating general purpose natural language representations that are useful for many different downstream tasks. ∗ * Equal contribution. Yet pretraining methods are still in their infancy. We do not"
P19-1373,W14-4337,0,0.0581682,"ional belief state vector. Belief state prediction (BSP) is a multi-class classification task, highly dependant on strong dialog context representations. The belief state vector represents the values of 27 entities, all of which can be inferred from the dialog context. To obtain the 1784dimensional label, the entity values are encoded as a one-hot encoded vector and concatenated. The entities are shown in Appendix ??. Performance is measured using the F-1 score for entities with nonempty values. This approach is analogous to the one used in the evaluation of Dialog State Tracking Challenge 2 (Henderson et al., 2014). This task measures the ability of a system to maintain a complete and accurate state representation of the dialog context. With a 1784dimensional output, the hidden representation for this task must be sufficiently general. Therefore, any pretrained representations that lack generality will struggle on belief state prediction. 4.2 Dialog Act Prediction Next-Utterance Generation NUG is the task of producing the next utterance conditioned on the dialog history. We evaluate the ability of our models to generate system utterances using BLEU-4 (Papineni et al., 2002). This task requires both a st"
P19-1373,P18-1031,0,0.0894116,"results on a range of natural language processing (NLP) tasks (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018) including natural language inference, question answering and text classification. These promising results suggest a new direction for improving context modeling by creating general purpose natural language representations that are useful for many different downstream tasks. ∗ * Equal contribution. Yet pretraining methods are still in their infancy. We do not yet fully understand their properties. For example, many pretraining methods are variants of language modeling (Howard and Ruder, 2018; Radford et al., 2018; Devlin et al., 2018), e.g. predicting the previous word, next word or the masked word, given the sentence context. This approach treats natural language as a simple stream of word tokens. It relies on a complex model to discover high-level dependencies, through the use of massive corpora and expensive computation. Recently the BERT model (Devlin et al., 2018) achieved state-of-the-art performance on several NLP benchmarks. It introduces a sentence-pair level pretraining objective, i.e. predicting whether two sentences should come after one another. This is a step toward"
P19-1373,W15-4640,0,0.0785003,"and generality of the learned representations. For clarity of discussion, the following notation is used: an arbitrary T -turn dialog segment is represented by a list of utterances c = [u1 , ...uT ], where ui is an utterance. Further, we denote the set of all observed dialog responses in the data by R = {r1 , ...rM }. The pretraining objectives, discussed below, are next-utterance retrieval (NUR), next-utterance generation (NUG), masked-utterance retrieval (MUR), and inconsistency identification (InI). 3.1 Next-Utterance Retrieval NUR has been extensively explored both as an independent task (Lowe et al., 2015, 2016) and as an auxiliary loss in a multi-tasking setup (Wolf et al., 2019). Given a dialog context, the aim of NUR is to select the correct next utterance from a set of k candidate responses. NUR can be thought of as being analogous to language modelling, except that the utterances, rather than the words, are the indivisible atomic units. Language modelling pretraining has produced strong representations of language (Radford et al., 2018; Peters et al., 2018), thereby motivating the choice of NUR as a pretraining objective. For this task we use a hierarchical encoder to produce a representa"
P19-1373,W16-3634,0,0.378481,"modeling the relationship amongst multiple utterances. This paper takes a first step in the creation of a systematic analysis framework of pretraining methods for dialog systems. Concretely, 3836 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3836–3845 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics we pretrain a hierarchical dialog encoder (Serban et al., 2016) with four different unsupervised pretraining objectives. Two of the objectives, nextutterance generation (Vinyals and Le, 2015) and retrieval (Lowe et al., 2016), have been explored in previous work. The other two pretraining objectives, masked-utterance retrieval and inconsistency identification, are novel. The pretrained dialog encoder is then evaluated on several downstream tasks that probe the quality of the learned context representation by following the typical pretrain & fine-tune procedure. Pretraining and downstream evaluation use the MultiWoz dialog dataset (Budzianowski et al., 2018), which contains over 10,000 dialogs spanning 6 different domains. The downstream tasks include next-utterance generation (NUG), nextutterance retrieval (NUR),"
P19-1373,P02-1040,0,0.103969,"State Tracking Challenge 2 (Henderson et al., 2014). This task measures the ability of a system to maintain a complete and accurate state representation of the dialog context. With a 1784dimensional output, the hidden representation for this task must be sufficiently general. Therefore, any pretrained representations that lack generality will struggle on belief state prediction. 4.2 Dialog Act Prediction Next-Utterance Generation NUG is the task of producing the next utterance conditioned on the dialog history. We evaluate the ability of our models to generate system utterances using BLEU-4 (Papineni et al., 2002). This task requires both a strong global context representation to initialize the decoder’s hidden state and strong local utterance representations. 4.4 5 Experiments and Results This section presents the experiments and results aimed at capturing the capabilities and properties of the above pretraining objectives by evaluating on a variety of downstream tasks. All unsupervised pretraining objectives are trained on the full MultiWoz dataset (Budzianowski et al., 2018). Data usage for downstream fine-tuning differs, depending on the property being measured. 5.1 Dialog act prediction (DAP), muc"
P19-1373,N18-1202,0,0.490572,"s. In order to generate an appropriate response, a system must be able to aggregate information over multiple turns, such as estimating a belief state over user goals (Williams et al., 2013) and resolving anaphora co–references (Mitkov, 2014). In the past, significant effort has gone into developing better neural dialog architectures to improve context modeling given the same in-domain training data (Dhingra et al., 2017; Zhou et al., 2016). Recent advances in pretraining on massive amounts of text data have led to state-of-theart results on a range of natural language processing (NLP) tasks (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018) including natural language inference, question answering and text classification. These promising results suggest a new direction for improving context modeling by creating general purpose natural language representations that are useful for many different downstream tasks. ∗ * Equal contribution. Yet pretraining methods are still in their infancy. We do not yet fully understand their properties. For example, many pretraining methods are variants of language modeling (Howard and Ruder, 2018; Radford et al., 2018; Devlin et al., 2018), e.g. predictin"
P19-1373,P16-2067,0,0.0229742,"two novel objectives. (2) a comprehensive analysis of the effects of pretraining on dialog context representations, assessed on four different downstream tasks. 2 Related Work This work is closely related to research in auxiliary multi-task learning and transfer learning with pretraining for NLP systems. Training with Auxiliary Tasks Incorporating a useful auxiliary loss function to complement the primary objective has been shown to improve the performance of deep neural network models, including, but not limited to, error detection (Rei and Yannakoudakis, 2017), crosslingual speech tagging (Plank et al., 2016), domain independent sentiment classification (Yu and Jiang, 2016), latent variable inference for dialog generation (Zhao et al., 2017) and opinion extraction (Ding et al., 2017). Some auxiliary loss functions are designed to improve performance on a specific task. For instance, Yu and Jiang (2016) pretrained a model for sentiment classification with the auxiliary task of identifying whether a negative or positive word occurred in the sentence. In some cases, auxiliary loss is created to encourage a model’s general representational power. Trinh et al. (2018) found that a model can capture far"
P19-1373,W18-5446,0,0.0712902,"Missing"
P19-1373,W13-4065,0,0.0273372,"uated on a set of downstream dialog tasks using the MultiWoz dataset and strong performance improvement is observed. Further evaluation shows that our pretraining objectives result in not only better performance, but also better convergence, models that are less data hungry and have better domain generalizability. 1 Introduction Learning meaningful representations of multi-turn dialog contexts is the cornerstone of dialog systems. In order to generate an appropriate response, a system must be able to aggregate information over multiple turns, such as estimating a belief state over user goals (Williams et al., 2013) and resolving anaphora co–references (Mitkov, 2014). In the past, significant effort has gone into developing better neural dialog architectures to improve context modeling given the same in-domain training data (Dhingra et al., 2017; Zhou et al., 2016). Recent advances in pretraining on massive amounts of text data have led to state-of-theart results on a range of natural language processing (NLP) tasks (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018) including natural language inference, question answering and text classification. These promising results suggest a new direct"
P19-1373,D16-1023,0,0.0484651,"of pretraining on dialog context representations, assessed on four different downstream tasks. 2 Related Work This work is closely related to research in auxiliary multi-task learning and transfer learning with pretraining for NLP systems. Training with Auxiliary Tasks Incorporating a useful auxiliary loss function to complement the primary objective has been shown to improve the performance of deep neural network models, including, but not limited to, error detection (Rei and Yannakoudakis, 2017), crosslingual speech tagging (Plank et al., 2016), domain independent sentiment classification (Yu and Jiang, 2016), latent variable inference for dialog generation (Zhao et al., 2017) and opinion extraction (Ding et al., 2017). Some auxiliary loss functions are designed to improve performance on a specific task. For instance, Yu and Jiang (2016) pretrained a model for sentiment classification with the auxiliary task of identifying whether a negative or positive word occurred in the sentence. In some cases, auxiliary loss is created to encourage a model’s general representational power. Trinh et al. (2018) found that a model can capture far longer dependencies when pretrained with a suitable auxiliary task"
P19-1373,P17-1061,1,0.852634,"fferent downstream tasks. 2 Related Work This work is closely related to research in auxiliary multi-task learning and transfer learning with pretraining for NLP systems. Training with Auxiliary Tasks Incorporating a useful auxiliary loss function to complement the primary objective has been shown to improve the performance of deep neural network models, including, but not limited to, error detection (Rei and Yannakoudakis, 2017), crosslingual speech tagging (Plank et al., 2016), domain independent sentiment classification (Yu and Jiang, 2016), latent variable inference for dialog generation (Zhao et al., 2017) and opinion extraction (Ding et al., 2017). Some auxiliary loss functions are designed to improve performance on a specific task. For instance, Yu and Jiang (2016) pretrained a model for sentiment classification with the auxiliary task of identifying whether a negative or positive word occurred in the sentence. In some cases, auxiliary loss is created to encourage a model’s general representational power. Trinh et al. (2018) found that a model can capture far longer dependencies when pretrained with a suitable auxiliary task. This paper falls in line with the second goal by creating learning"
P19-1373,D16-1036,0,0.0899307,"Missing"
P19-1373,W17-5004,0,0.0366012,"ing objectives for dialog context representation, including two novel objectives. (2) a comprehensive analysis of the effects of pretraining on dialog context representations, assessed on four different downstream tasks. 2 Related Work This work is closely related to research in auxiliary multi-task learning and transfer learning with pretraining for NLP systems. Training with Auxiliary Tasks Incorporating a useful auxiliary loss function to complement the primary objective has been shown to improve the performance of deep neural network models, including, but not limited to, error detection (Rei and Yannakoudakis, 2017), crosslingual speech tagging (Plank et al., 2016), domain independent sentiment classification (Yu and Jiang, 2016), latent variable inference for dialog generation (Zhao et al., 2017) and opinion extraction (Ding et al., 2017). Some auxiliary loss functions are designed to improve performance on a specific task. For instance, Yu and Jiang (2016) pretrained a model for sentiment classification with the auxiliary task of identifying whether a negative or positive word occurred in the sentence. In some cases, auxiliary loss is created to encourage a model’s general representational power. Trinh"
W07-0305,E03-2001,0,0.0490602,"Missing"
W07-0305,2005.sigdial-1.14,1,0.570476,"Missing"
W07-0305,N07-4008,0,0.0431217,"Missing"
W07-0305,H94-1039,0,0.0825901,"Missing"
W07-0305,W03-2123,0,\N,Missing
W07-0305,N07-2003,1,\N,Missing
W08-0101,P05-3022,0,0.0454964,"Missing"
W08-0101,W07-0305,1,\N,Missing
W08-0101,J86-3001,0,\N,Missing
W08-0909,A00-2018,0,0.0287014,"Missing"
W08-0909,1993.eamt-1.1,0,0.204398,"Missing"
W08-0909,N07-1058,1,0.496045,"l assumes that grammatical difficulty is adequately captured by a small number of constructions chosen according to detailed knowledge of English grammar. In that work, the constructions were selected from an English as a Second Language grammar textbook, a labor- and knowledge-intensive task that may be less practical for other languages. We aim to identify the appropriate scale of measurement for reading difficulty–nominal, ordinal, or interval–by comparing the effectiveness of statistical models for each type of data. We also extend previous work combining lexical and grammatical features (Heilman et al., 2007) by making it possible to include a large number of grammatical features derived from syntactic structures without requiring significant linguistic or pedagogical content knowledge, such as a reference guide for the grammar of the language of interest. 2 2.1 Types of Features Lexical Features This section and the following section describe the lexical and grammatical features used in our reading difficulty models. The lexical features are the relative frequencies of word unigrams. The use of word unigrams is a standard approach in text classification (Yang and Pedersen, 1997), and has also bee"
W08-0909,P03-1054,0,0.0113967,"reached or the given depth is reached. An example feature for level 2 is a subtree in which a prepositional phrase node dominates a preposition node and noun phrase node, and the preposition node in turn dominates a preposition, and the noun phrase dominates determiner, adjective, and noun nodes. We used a maximum depth of 3 in our experiments. Features of deeper levels occur less frequently in general, and deeper levels were avoided 73 due to data sparseness. A depth first search algorithm extracts candidate grammatical features from the training corpus. First, a context-free grammar parser (Klein and Manning, 2003) derives parse trees for all texts in the training corpus. The algorithm traverses these parses, at each node counting all subtree features up to the given depth that are rooted at that node. The subtree features are sorted by their overall counts in the corpus. In our experiments, frequencies of the most common 1000 subtrees were chosen as the final features. These included 64 level 0 features corresponding to nonterminal symbols, 334 level 1 features, 461 level 2 features, and 141 level 3 features. Deeper levels have more possible features, but sparsity at level 3 resulted in fewer level 3 f"
W08-0909,P05-1065,0,0.791006,"Missing"
W08-0910,H05-1103,1,0.0562187,"system also provides vocabulary exercises after each reading for additional practice and review of target words. Currently, students complete cloze, or fill-in-the-blank, exercises for each target word in the readings. Other types of exercises are certainly possible. For extra review, students also complete exercises for target words from previous readings. Students receive immediate feedback on the practice and review exercises. Currently, sets of the exercises are manually authored for each target word and stored in a database, but we are exploring automated question generation techniques (Brown et al., 2005; Liu et al., 2005). At runtime, the system selects practice and review exercises from this repository. reading comprehension. The REAP Tutor (Brown and Eskenazi, 2004; Heilman et al., 2006) for ESL vocabulary takes a slightly different approach. Rather than teachers choosing texts as in the REAP Search system, the REAP Tutor itself selects individualized practice readings from a digital library. The readings contain target vocabulary words that a given student needs to learn based on a student model. While the individualized REAP Tutor has the potential to better match the needs of each stude"
W08-0910,W05-0201,0,0.0275443,"s vocabulary exercises after each reading for additional practice and review of target words. Currently, students complete cloze, or fill-in-the-blank, exercises for each target word in the readings. Other types of exercises are certainly possible. For extra review, students also complete exercises for target words from previous readings. Students receive immediate feedback on the practice and review exercises. Currently, sets of the exercises are manually authored for each target word and stored in a database, but we are exploring automated question generation techniques (Brown et al., 2005; Liu et al., 2005). At runtime, the system selects practice and review exercises from this repository. reading comprehension. The REAP Tutor (Brown and Eskenazi, 2004; Heilman et al., 2006) for ESL vocabulary takes a slightly different approach. Rather than teachers choosing texts as in the REAP Search system, the REAP Tutor itself selects individualized practice readings from a digital library. The readings contain target vocabulary words that a given student needs to learn based on a student model. While the individualized REAP Tutor has the potential to better match the needs of each student since each stude"
W08-0910,W08-0909,1,\N,Missing
W09-2106,N06-2020,0,0.0424358,"Missing"
W09-3950,P01-1066,0,\N,Missing
W09-3950,P08-5002,1,\N,Missing
W10-0703,S07-1037,0,0.0676474,"Missing"
W10-0703,D07-1043,0,0.0206679,"n-expert clustering would have to agree with the 4 experts with a similar result. 4 5 Evaluation of global-view vs. local-view approaches In order to evaluate our two approaches, we created a gold-standard (GS). Since the task of WSI is strongly influenced by an annotator‟s grain size preference for the senses, four expert annotators were asked to create the GS. The literature offers many metrics to compare two annotators‟ clustering solutions (Purity and Entropy (Zhao and Karypis, 2001), clustering F-Measure (Fung et al., 2003) and many others). SemEval-2 includes a WSI task where V-Measure (Rosenberg and Hirschberg, 2007) is used to evaluate the clustering solutions. V-Measure involves two metrics, homogeneity and completeness, that can be thought of as precision and recall. Perfect homogeneity is obtained if the solutions have clusters whose data points belong to a single cluster in the GS. Perfect completeness is obtained if the clusters in the GS contain data points that belong to a single cluster in the evaluated solution. The V-Measure is a (weighted) harmonic mean of the homogeneity and of the completeness metrics. Table 1 shows interannotator agreement (ITA) among four experts on the test dataset, using"
W10-0703,D08-1027,0,0.382675,"Missing"
W10-0703,D07-1107,0,0.0369087,"Missing"
W10-0703,D09-1030,0,\N,Missing
W10-1007,W05-0201,0,0.378468,"ttempts to identify sentences matching those criteria. Thus, the content generated for a closed cloze is the stem (by deletion of the key), and a set of distractors. In the case of some systems, a human content author may manually tailor the resulting stems to meet further needs. Identifying suitable sentences from natural language corpora is desirable because the sentences that are found will be authentic. Depending on the choice of corpora, sentences should also be well-formed and suitable in terms of reading level and content. Newspaper text is one popular source (Hoshino & Nakagawa, 2005; Liu et al., 2005; Lee & Seneff, 2007). Pino et al. (2008) use documents from a corpus of texts retrieved from the internet and subsequently filtered according to readability level, category, and appropriateness of content. Using a broader corpus increases the number and variability of potential matching sentences, but also lowers the confidence that sentences will be well-formed and contain appropriate language (Brown & Eskenazi, 2004). 2.1 Tag-based Sentence Search Several cloze item authoring tools (Liu et al. 2005; Higgins, 2006) implement specialized tag-based sentence search. This goes back to the origin"
W10-1007,W05-0203,0,0.0309874,"f pre-processed text and attempts to identify sentences matching those criteria. Thus, the content generated for a closed cloze is the stem (by deletion of the key), and a set of distractors. In the case of some systems, a human content author may manually tailor the resulting stems to meet further needs. Identifying suitable sentences from natural language corpora is desirable because the sentences that are found will be authentic. Depending on the choice of corpora, sentences should also be well-formed and suitable in terms of reading level and content. Newspaper text is one popular source (Hoshino & Nakagawa, 2005; Liu et al., 2005; Lee & Seneff, 2007). Pino et al. (2008) use documents from a corpus of texts retrieved from the internet and subsequently filtered according to readability level, category, and appropriateness of content. Using a broader corpus increases the number and variability of potential matching sentences, but also lowers the confidence that sentences will be well-formed and contain appropriate language (Brown & Eskenazi, 2004). 2.1 Tag-based Sentence Search Several cloze item authoring tools (Liu et al. 2005; Higgins, 2006) implement specialized tag-based sentence search. This goes"
W10-1007,P03-1054,0,0.00644732,"Missing"
W10-1007,W08-0909,1,\N,Missing
W10-1007,P05-3009,0,\N,Missing
W11-1417,N04-3002,1,0.794081,"positively correlated with motivation assessments (DelaRosa and Eskenazi, 2011). Also, in a separate study with the REAP tutor, attempts to manipulate reading motivation by presenting more interesting stories were shown to improve vocabulary learning (Heilman et al., 2010). In addition to influencing learning outcomes, motivational state may also affect which interventions will be effective during tutoring. For example, Ward and Litman (2011) have shown that motivation can significantly affect which students benefit from a reflective reading following interactive tutoring with a the Itspoke (Litman and Silliman, 2004) tutor. Maxine Eskenazi Language Technologies Institute Carnegie Mellon University Pittsburgh, Pa., 15213 max@cmu.edu An accurate way to measure student motivation during tutoring could therefore be valuable to Intelligent Tutoring System (ITS) researchers. Several self-report instruments have been developed which measure various aspects of motivation (e.g. (Pintrich and DeGroot, 1990; McKenna and Kear, 1990)). However, these instruments are too intrusive to be administered during tutoring, for fear of fatally disrupting learning. We would prefer a non-intrusive measure which would allow an IT"
W11-1417,W02-0109,0,0.049875,"g scores for various subsets measures, as well as of questions. for the change-in-motivation score, calculated as post-minus-pre. 138 Finally, the student’s use of “velocity” will be counted as a cohesive tie because of its semantic similarity to “acceleration,” from the preceding turn. The algorithm therefore counts four ties in Table 1. As described more completely in (Ward and Litman, 2008), semantic similarity cohesive ties are counted by measuring two words’ proximity in the WordNet (Miller et al., 1990) hierarchy. We use a simple path distance similarity measure, as implemented in NLTK (Loper and Bird, 2002). This measure counts the number of edges N in the shortest path between two words in WordNet, and calculates similarity as 1 / (1 + N). Our implementation of this semantic similarity measure allows setting a threshold θ, such that only word pairs with stronger-than-threshold similarity are counted. Table 3 shows some semantic similarity pairs counted with a threshold of 0.3. We obtain a normalized cohesion score for each dialog by dividing the tie count by the number of turns in the dialog. We then sum the line normalized counts over all the dialogs for each student, resulting in a perstudent"
W11-1417,H05-1122,0,0.0695707,"f videos. 136 Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications, pages 136–141, c Portland, Oregon, 24 June 2011. 2011 Association for Computational Linguistics the tutor and student partners in a tutoring dialog which was shown to be correlated with task success in several corpora of tutorial dialogs. Measures of cohesion have also been used in a variety of NLP tasks such as measuring text readability (e.g. (Pitler and Nenkova, 2008)), measuring stylistic differences in text (Mccarthy et al., 2006), and for topic segmentation in tutorial dialog (Olney and Cai, 2005). Given the previously mentioned results relating motivation to educational task success, these links between task success and cohesion lead us to hypothesize a direct correlation between motivation and cohesion when using the Itspoke tutor. We will first briefly describe the Itspoke tutor, and the corpus of tutoring dialogs used in this study. We will then describe the instrument we used to measure motivation both before and immediately after tutoring, then we will describe the algorithm used to measure cohesion in the tutoring dialogs. Finally, we show results of correlations between the mea"
W11-1417,D08-1020,0,0.0251169,"on, Ward and Litman (2006; 2008) investigated a measure of lexical similarity between 1 In this experiment, the task was to watch a series of videos. 136 Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications, pages 136–141, c Portland, Oregon, 24 June 2011. 2011 Association for Computational Linguistics the tutor and student partners in a tutoring dialog which was shown to be correlated with task success in several corpora of tutorial dialogs. Measures of cohesion have also been used in a variety of NLP tasks such as measuring text readability (e.g. (Pitler and Nenkova, 2008)), measuring stylistic differences in text (Mccarthy et al., 2006), and for topic segmentation in tutorial dialog (Olney and Cai, 2005). Given the previously mentioned results relating motivation to educational task success, these links between task success and cohesion lead us to hypothesize a direct correlation between motivation and cohesion when using the Itspoke tutor. We will first briefly describe the Itspoke tutor, and the corpus of tutoring dialogs used in this study. We will then describe the instrument we used to measure motivation both before and immediately after tutoring, then we"
W11-1417,P07-1102,0,0.0197503,"ers are likely to adopt the terms used by a WOZ dialog system, and that this tendency is at least as strong as with human dialog partners. Similarly, Parent and Eskenazi (2010) showed that users of the Let’s Go (Raux et al., 2005) spoken dialog system quickly entrain to its lexical choices. 3 We thank an anonymous reviewer for prompting this discussion. 4 This definition conflates studies of priming, alignment, convergence and accommodation. As with measures of dialog similarity, dialog entrainment has been found to be related to satisfaction and success in task oriented dialogs. For example, Reitter and Moore (2007) found that lexical and syntactic repetition predicted task success in the MapTask corpus. Similarly, Ward and Litman (2007) found that lexical and acoustic-prosodic entrainment are correlated with task success in the Itspoke dialog system. Interestingly, in that work entrainment was more strongly correlated with task success than a measure of dialog cohesion similar to the one used in the current paper. This raises the question of whether such a measure of dialog entrainment might also be a better predictor of motivation than the current measure of cohesion. We hope in future work to further"
W11-2002,2007.sigdial-1.23,1,\N,Missing
W12-1606,P04-1009,0,0.0901143,"Missing"
W12-1606,2005.sigdial-1.6,0,0.194629,"ous data-driven approaches have still required a certain amount of human effort. Most intention-level models take a semantically annotated corpus to produce user intention without introducing errors (Cuayahuitl et al., 2005; Jung et al., 2009). Surface-level approaches need transcribed data to train their surface form and error generating models (Jung et al., 2009; Schatzmann et al., 2007b). A few studies have attempted to directly simulate the intention, surface, and error by applying their statistical methods on the recognized data rather than on the transcribed data (Georgila et al., 2006; Schatzmann et al., 2005). Although such approaches can avoid human intervention, the sole incorporation of erroneous user action can propagate those errors to the higher-level discourse features which are computed from them, and thus could result in less realistic user behavior. In this work, the true user action is treated as a hidden variable and, further, its associated dialog history is also viewed as latent so that the uncertainty of the true user action is properly controlled in a principled manner. Syed and Williams (2008) adopted the Expectation Maximization algorithm for parameter learning for a latent varia"
W12-1606,N07-2038,0,0.0294109,"Section 3 elaborates on our proposed unsupervised approach to user simulation. Section 4 explains the experimental setup. Section 5 presents and discusses the results. Finally, Section 6 concludes with a brief summary and suggestions for future research. 2 Related Work Previous user simulation studies can be roughly categorized into rule-based methods (Chung, 2005; 50 Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 50–59, c Seoul, South Korea, 5-6 July 2012. 2012 Association for Computational Linguistics Lopez-Cozar et al., 2006; Schatzmann et al., 2007a) and data-driven methods (Cuayahuitl et al., 2005; Eckert et al., 1997; Jung et al., 2009; Levin et al., 2000; Georgila et al., 2006; Pietquin, 2004). Rulebased methods generally allow for more control over their designs for the target domain while data-driven methods afford more portability from one domain to another and are attractive for modeling user behavior based on real data. Although development costs for data-driven methods are typically lower than those of rule-based methods, previous data-driven approaches have still required a certain amount of human effort. Most intention-level"
W12-1606,P08-2031,0,0.212986,"thods on the recognized data rather than on the transcribed data (Georgila et al., 2006; Schatzmann et al., 2005). Although such approaches can avoid human intervention, the sole incorporation of erroneous user action can propagate those errors to the higher-level discourse features which are computed from them, and thus could result in less realistic user behavior. In this work, the true user action is treated as a hidden variable and, further, its associated dialog history is also viewed as latent so that the uncertainty of the true user action is properly controlled in a principled manner. Syed and Williams (2008) adopted the Expectation Maximization algorithm for parameter learning for a latent variable model. But their method still requires a small amount of transcribed data to learn the observation confusability, and it suffers from overfitting as a general property of maximum likelihood. To address this problem, we propose a Bayesian learning method, which requires no transcribed data. 3 Unsupervised Approach to User Simulation Before describing each component in detail, we present the overall process of user simulation with an example in the Let’s Go domain in Figure 1. To begin a dialog, the user"
W12-1606,2005.sigdial-1.4,0,0.396692,"all the parents P of i and δ(·, ·) denotes Kronecker delta. Note that k0 θk,k0 = 1. Given this notation, the goal model Λ can be written in the following form: Y δ(g,k) g ∼ p(g|Λ) = λk (2) k 3.2 User Model Having generated a user goal, the next task is to infer an appropriate user action for the given goal and system action. This is what the user model does. Since one of key properties of our unsupervised approach is that the true user actions are not observable, the user model should maintain a belief over the dialog state by taking into consideration the observed user actions. Inspired by (Williams et al., 2005), to keep the complexity of the user model tractable, a dynamic Bayesian network is adopted with several conditional independence assumptions, giving rise to the graphical structure which is shown in Figure 2. Unlike belief tracking in a dialog system, the user goal in a user simulation is pre-determined before the beginning of the dialog. As with most previous studies, this property allows the user model to deal with a predicate-level action consisting of a speech act and a concept (e.g. [Inform(Source), Inform(Time)]) and is only concerned about whether a given field is specified or not in t"
W12-1606,J08-4002,0,\N,Missing
W12-1626,W12-1606,1,0.717793,"verify the proposed method, three months of data from the Let’s Go domain were used to train the user action model and the observation model. The training data consists of 2,718 dialogs and 23,044 turns in total. To evaluate the user action model, we compared overall system performance with three different configurations: 1) the uniform distribution, 2) the user action model without historical information5 which is comparable to the bigram model of (Keizer et al., 2008), 3) the user action model with historical information included. For system performance evaluation, we used a user simulator (Lee and Eskenazi, 2012) which provides a large number of dialogs with statistically similar conditions. Also, the simulated user enables us to examine how performance changes over a variety of error levels. This simulated user supports four error levels and each model was evaluated by generating 2,000 dialogs at each error level. System performance was measured in terms of average dialog success rate. A dialog is considered to be successful if the system provides the bus schedule information that satisfies the user goal. To measure the effectiveness of the calibration method, we conducted two experiments. First, we"
W12-1626,P00-1013,0,0.0606559,"aches (Gasic and Young, 2011; Williams, 2010; Young et al., 2010) and Bayesian network (BN)-based methods (Raux and Ma, 2011; Thomson and Young, 2010a). The partition-based approaches attempt to group user goals into a small number of partitions and split a partition only when a distinction is required by observations. This property endows it with the high scalability that is suitable for fairly complex domains. However, the parameter learning procedures for the partition-based methods is still limited to hand-crafting or the use of a simple maximum likelihood estimation (Keizer et al., 2008; Roy et al., 2000; Thomson and Young, 2010a; Williams, 2008). In contrast, several unsupervised methods which do not require human transcription and annotation have been recently proposed to learn BN-based models (Jurcicek et al., 2010; Syed and Williams, 2008; Thomson et al., 2010b). In this paper we describe an unsupervised process that can be applied to the partition-based methods. We adopt a dynamic Bayesian network to learn the user action model which defines the likelihood of user actions for a given context. In addition, we propose a simple confidence score calibration method to improve the observation"
W12-1626,P08-2031,0,0.154751,"artitions and split a partition only when a distinction is required by observations. This property endows it with the high scalability that is suitable for fairly complex domains. However, the parameter learning procedures for the partition-based methods is still limited to hand-crafting or the use of a simple maximum likelihood estimation (Keizer et al., 2008; Roy et al., 2000; Thomson and Young, 2010a; Williams, 2008). In contrast, several unsupervised methods which do not require human transcription and annotation have been recently proposed to learn BN-based models (Jurcicek et al., 2010; Syed and Williams, 2008; Thomson et al., 2010b). In this paper we describe an unsupervised process that can be applied to the partition-based methods. We adopt a dynamic Bayesian network to learn the user action model which defines the likelihood of user actions for a given context. In addition, we propose a simple confidence score calibration method to improve the observation model which represents the probability of an observation given the true user action. This paper is structured as follows. Section 2 describes previous research and the novelty of our approach. Section 3 and Section 4 elaborate on our proposed"
W12-1626,2005.sigdial-1.4,0,0.0508855,"Section 5 explains the experimental setup. Section 6 presents and discusses the results. Finally, Section 7 concludes with a brief summary and suggestions for future research. 189 Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 189–196, c Seoul, South Korea, 5-6 July 2012. 2012 Association for Computational Linguistics 2 Background and Related Work In order to reduce the complexity of the belief states over the POMDP states, the following factorization of the belief state has been commonly applied to the belief update procedure (Williams et al., 2005): b(gt , ut , ht ) ∝ p(ot |ut ) |{z } X observation model ht−1 p(ht |ht−1 , ut , st ) | {z } p(u |g , s , h ) |t t {zt t−1} user action model X dialog history model X gt−1 p(gt |gt−1 , st−1 ) (1) | {z } user goal model b(gt−1 , ut−1 , ht−1 ) ut−1 where gt , st , ut , ht , ot represents the user goal, the system action, the user action, the dialog history, and the observed user action for each time slice, respectively. The user goal model describes how the user goal evolves. In the partition-based approaches, this model is further approximated by assuming that the user does not change their min"
W12-1626,J08-4002,0,\N,Missing
W12-1810,N07-4008,0,\N,Missing
W13-1503,W10-1001,0,0.0272578,"is is what brought us to examine the effect of translation and simplification on learning. These two techniques, thanks to the use of NLP, could be totally automated in the future. Research in machine translation (MT) goes back several decades and many types of statistical models have been employed (Koehn, 2010). If all of the documents to be translated are in one given domain, then sufficiently good automatically translations can be obtained. Automated simplification is a newer domain. There has been significant progress in simplifying documents for use by specific disadvantaged populations (Alusio et al 2010, Bach et al, 2011, Chandrasekar and Srinivas, 1997, Inui et al, 2003, Medero and Ostendorf, 2011, Yaskar et al 2010). Like Alusio and colleagues, who work with low-literacy populations, and a few other authors, we are concerned not only about the quality of the simplification, but also about whether the simplified documents actually help disadvantaged readers. We could have also looked at summarization, which uses some of the same techniques that are used for simplification. In some early unpublished studies, we found that students experienced difficulty when asked to summarize a passage. The"
W13-1503,I11-1053,0,0.0239795,"us to examine the effect of translation and simplification on learning. These two techniques, thanks to the use of NLP, could be totally automated in the future. Research in machine translation (MT) goes back several decades and many types of statistical models have been employed (Koehn, 2010). If all of the documents to be translated are in one given domain, then sufficiently good automatically translations can be obtained. Automated simplification is a newer domain. There has been significant progress in simplifying documents for use by specific disadvantaged populations (Alusio et al 2010, Bach et al, 2011, Chandrasekar and Srinivas, 1997, Inui et al, 2003, Medero and Ostendorf, 2011, Yaskar et al 2010). Like Alusio and colleagues, who work with low-literacy populations, and a few other authors, we are concerned not only about the quality of the simplification, but also about whether the simplified documents actually help disadvantaged readers. We could have also looked at summarization, which uses some of the same techniques that are used for simplification. In some early unpublished studies, we found that students experienced difficulty when asked to summarize a passage. They usually responde"
W13-1503,N07-4002,0,0.357651,"ords. Prince (1996) also claimed that the more proficient students benefit more from translation on short-term lexical recall tasks, since it is easier for them to get rid of the L1 scaffolding. These studies and others have been hampered by the ability to accurately measure the extent of the subjects’ use of translation. The REAP software described below has afforded a more precise estimate of use and of retention of vocabulary items. Simplification has had more widespread acceptance. Simplified texts have often been provided to language learners either along with the original text or alone (Burstein et al, 2007, Petersen and Ostendorf, 2007). These texts have been used as reading comprehension exercises or text21 book reading materials (Crossley, et al. 2007). According to Oh (2008), simplification typically uses shorter sentences, simpler grammar and controlled vocabulary. The use of simplified texts has been shown to significantly help students’ reading comprehension (Yano, et al. 1994, Oh 2008). However, there has not been any research specifically about whether reading the simplified texts, rather than the original ones, will affect the students’ vocabulary acquisition. There are a few disadvant"
W13-1503,W08-0910,1,0.834706,"ed in the past in two ways:  it uses L1  it covers several-word contexts, rather than just one word. To tease apart these two characteristics, we became interested in simplification, which shares the second characteristic, but not the first. 3 The REAP tutor The studies in this paper used the CMU REAP intelligent tutor. That tutor provides curriculum for vocabulary acquisition for non-native students while serving as a platform for research studies (Brown and Eskenazi, 2005). REAP gives students texts retrieved from the Internet that are matched to their reading level and their preferences (Heilman et al., 2008) and helps them acquire new words from context (Juffs et al., 2006). REAP incorporates several features like pop-up word definitions, examples of the word in other contexts, text-to-speech synthesis of words and translation of words to the student’s native language. REAP presents the reading in any web browser (see Figure 1). Upon registration, students enter their native language. To get a definition, clicking on a word brings up a pop-up window showing the definition and examples of use of that word and a button for hearing the pronunciation of the word. Focus words, the words that the teach"
W13-1503,W03-1602,0,0.0431719,"ication on learning. These two techniques, thanks to the use of NLP, could be totally automated in the future. Research in machine translation (MT) goes back several decades and many types of statistical models have been employed (Koehn, 2010). If all of the documents to be translated are in one given domain, then sufficiently good automatically translations can be obtained. Automated simplification is a newer domain. There has been significant progress in simplifying documents for use by specific disadvantaged populations (Alusio et al 2010, Bach et al, 2011, Chandrasekar and Srinivas, 1997, Inui et al, 2003, Medero and Ostendorf, 2011, Yaskar et al 2010). Like Alusio and colleagues, who work with low-literacy populations, and a few other authors, we are concerned not only about the quality of the simplification, but also about whether the simplified documents actually help disadvantaged readers. We could have also looked at summarization, which uses some of the same techniques that are used for simplification. In some early unpublished studies, we found that students experienced difficulty when asked to summarize a passage. They usually responded by simply cutting and pasting the first sentence"
W13-1503,J10-4005,0,0.0174161,"hown positive results for many word-centric learning aids, it is interesting to expand the offerings to context-level aids. We were also curious to see if the use of the REAP platform (Brown and Eskenazi, 2005) could help add to the knowledge of the role of translation in L2 vocabulary learning. This is what brought us to examine the effect of translation and simplification on learning. These two techniques, thanks to the use of NLP, could be totally automated in the future. Research in machine translation (MT) goes back several decades and many types of statistical models have been employed (Koehn, 2010). If all of the documents to be translated are in one given domain, then sufficiently good automatically translations can be obtained. Automated simplification is a newer domain. There has been significant progress in simplifying documents for use by specific disadvantaged populations (Alusio et al 2010, Bach et al, 2011, Chandrasekar and Srinivas, 1997, Inui et al, 2003, Medero and Ostendorf, 2011, Yaskar et al 2010). Like Alusio and colleagues, who work with low-literacy populations, and a few other authors, we are concerned not only about the quality of the simplification, but also about wh"
W13-1503,N10-1056,0,0.0560361,"Missing"
W13-4066,W12-1626,1,0.770744,"case of a hypothesis with a high confidence. On the contrary, if the quality of the confidence score is very poor, a successful dialog will only be possible via heavy use of confirmation. Thus a model trained on a wellcalibrated dataset is likely to perform well on the poorly-calibrated dataset because of backup confirmation. Whereas, a model trained on the poorly-calibrated dataset will not perform well on the well-calibrated dataset due to the mismatch of the confidence score as well as the scarceness of confirmation information. The group A datasets have been shown to be poorly calibrated (Lee and Eskenazi, 2012); this is also shown in Fig. 2. Group B datasets are relatively well-calibrated, however. The importance of wide coverage and wellcalibrated data can be observed by examining the results of entry1 and entry2 (Fig. 1) which are trained on group A and B datasets, respectively. 3.2 Figure 2: Estimated empirical accuracy of confidence score for from slot. Ideally calibrated confidence score should be directly proportional to empirical accuracy. Feature-Rich Discriminative Model Design Most previous approaches are based on generative temporal modeling where the current dialog state is estimated usi"
W13-4066,W13-4069,1,0.434017,"ffectiveness of feature-rich discriminative modeling can be observed by comparing the results of DMALL and PBM (Fig. 1) which are discriminative and generative models, respectively. Note that interesting relational constraints, e.g. whether or not departure and arrival places are valid on a route, can be incorporated by adopting a structured model such as Conditional Random Field (CRF). But CRF was not used for the challenge since the bus information that was provided is not compatible with every dataset. The effectiveness of a structured model has been investigated in a separate publication (Lee, 2013). 3.3 Generalization Improvement Techniques Even though the incorporation of a set of rich features helps overcome the weaknesses of previous approaches, it also implies a risk of overfitting training datasets due to its increased capacity of function class. Overfitting is a serious hazard especially for test datasets that are severely dissimilar to training datasets. As noted above, since the test datasets of the challenge are intentionally arranged to have various mismatches, it is crucial that we prevent a model from overfitting training datasets. In the rest of this section, we describe va"
W13-4066,W11-2002,1,\N,Missing
W13-4066,W11-2016,0,\N,Missing
W14-1210,N07-1058,1,0.815131,"en. Early measures of readability such as the Flesch-Kincaid grade level formula (Kincaid et al., 1975) use counts of surface features of the text such as number of words and number of sentences. While these older measures are less sophisticated than more modern reading level classifiers, they are still widely used and reported and recent work has shown that they can be a good first approxiˇ mation of more complex measures (Stajner et al., 2012). More recent approaches use more complicated features and machine learning techniques to learn classifiers that can predict readability. For example, Heilman et al. (2007) combine a naive Bayes classifier that uses a vocabulary-based language model with a k-Nearest Neighbors classifier using grammatical features and interpolate the two to predict reading grade level. Feng et al. (2010) and Franc¸ois and Miltsakaki (2012) examine a large number of possible textual features at various levels and compare SVM and Linear Regression classifiers to predict grade level. Vajjala and Meurers 2.3 Automated Text Simplification Systems Corpora for Text Simplification Presently there are limited resources for statistical simplification methods that need to train on a paralle"
W14-1210,W10-1607,0,0.0245701,"viduals’ reading and comprehension of the texts. Siddharthan and Katsos (2012) recently studied sentence recall to test comprehension; and Temnikova and Maneva (2013) evaluated simplifications using the readers’ ability to answer multiple choice questions about the text. 2 Since the mid-90s several systems have been developed to automatically simplify texts. Early systems used hand-crafted syntactic simplification rules; for example, Chandrasekar et al. (1996), one of the earliest attempts at automated simplification. Rule-based systems continue to be used, amongst others, Siddharthan (2006), Aluisio and Gasperin (2010), and Bott et al. (2012). Many of the more recent systems are statistically-based adapting techniques developed for statistical machine translation. Zhu et al. (2010) train a probabilistic model of a variety of sentence simplification rules using expectation maximization with a parallel corpus of aligned sentences from Wikipedia and Simple Wikipedia. Woodsend and Lapata (2011) present a system that uses quasi-synchronous grammar rules learned from Simple Wikipedia edit histories. They solve an integer linear programming (ILP) problem to select both which sentences are simplified (based on a mo"
W14-1210,W10-0710,0,0.0313188,"ext simplifications. Crowdsourcing has, however, been used to evaluate the quality of automatically generated simplifications. Feblowitz and Kauchak (2013) used AMT to collect human judgements of the simplifications generated by their system and De Clercq et al. (2014) performed an extensive evaluation of crowdsourced readability judgements compared to expert judgements. Crowdsourcing has also been used to generate translations. The recent statistical machine translation-inspired approaches to automated simplification motivate the possibility of using crowdsourcing to collect simplifications. Ambati and Vogel (2010) and Zaidan and Callison-Burch (2011) both demonstrate the feasibility of collecting quality translations using AMT. Post et al. (2012) generated parallel corpora between English and six Indian languages using AMT. 3 • A large and accessible set of original everyday documents to: • provide a training and test set for automated text simplification • A set of multiple human-generated simplifications at different reading levels for the same set of original documents to provide: • accessible training data for automated text simplification systems • the ability to model how the same document is sim"
W14-1210,W13-2902,0,0.0420844,"fic reading levels. The research needs that this corpus aims to meet are: (2007) present an analysis of a corpus of 104 original and abridged news articles, and Barzilay and Elhadad (2003) present a system for aligning sentences trained on a corpus of parallel Encyclopedia Britannica and Britannica Elementary articles. Other work generates parallel corpora of original and simplified texts in languages other than English for which Simple Wikipedia is not available. For example, Klerke and Søgaard (2012) built a sentence-aligned corpus from 3701 original and simplified Danish news articles, and Klaper et al. (2013) collected 256 parallel German and simple German articles. 2.4 Crowdsourcing for Text Simplification and Corpus Generation Crowdsourcing uses the aggregate of work performed by many non-expert workers on small tasks to generate high quality results for some larger task. To the best of our knowledge crowdsourcing has not previously been explored in detail to generate text simplifications. Crowdsourcing has, however, been used to evaluate the quality of automatically generated simplifications. Feblowitz and Kauchak (2013) used AMT to collect human judgements of the simplifications generated by t"
W14-1210,W03-1004,0,0.0400187,"s which are most important to them. Creating a corpus of everyday documents will allow automated simplification techniques to be applied to texts from this domain. In addition, systems trained using Simple Wikipedia only target a single reading level - that of Simple Wikipedia. A corpus containing multiple different simplifications at different reading levels for any given original will allow text simplification systems to target specific reading levels. The research needs that this corpus aims to meet are: (2007) present an analysis of a corpus of 104 original and abridged news articles, and Barzilay and Elhadad (2003) present a system for aligning sentences trained on a corpus of parallel Encyclopedia Britannica and Britannica Elementary articles. Other work generates parallel corpora of original and simplified texts in languages other than English for which Simple Wikipedia is not available. For example, Klerke and Søgaard (2012) built a sentence-aligned corpus from 3701 original and simplified Danish news articles, and Klaper et al. (2013) collected 256 parallel German and simple German articles. 2.4 Crowdsourcing for Text Simplification and Corpus Generation Crowdsourcing uses the aggregate of work perf"
W14-1210,klerke-sogaard-2012-dsim,0,0.0377438,"plifications at different reading levels for any given original will allow text simplification systems to target specific reading levels. The research needs that this corpus aims to meet are: (2007) present an analysis of a corpus of 104 original and abridged news articles, and Barzilay and Elhadad (2003) present a system for aligning sentences trained on a corpus of parallel Encyclopedia Britannica and Britannica Elementary articles. Other work generates parallel corpora of original and simplified texts in languages other than English for which Simple Wikipedia is not available. For example, Klerke and Søgaard (2012) built a sentence-aligned corpus from 3701 original and simplified Danish news articles, and Klaper et al. (2013) collected 256 parallel German and simple German articles. 2.4 Crowdsourcing for Text Simplification and Corpus Generation Crowdsourcing uses the aggregate of work performed by many non-expert workers on small tasks to generate high quality results for some larger task. To the best of our knowledge crowdsourcing has not previously been explored in detail to generate text simplifications. Crowdsourcing has, however, been used to evaluate the quality of automatically generated simplif"
W14-1210,W12-2910,0,0.0209649,"n of the texts. Siddharthan and Katsos (2012) recently studied sentence recall to test comprehension; and Temnikova and Maneva (2013) evaluated simplifications using the readers’ ability to answer multiple choice questions about the text. 2 Since the mid-90s several systems have been developed to automatically simplify texts. Early systems used hand-crafted syntactic simplification rules; for example, Chandrasekar et al. (1996), one of the earliest attempts at automated simplification. Rule-based systems continue to be used, amongst others, Siddharthan (2006), Aluisio and Gasperin (2010), and Bott et al. (2012). Many of the more recent systems are statistically-based adapting techniques developed for statistical machine translation. Zhu et al. (2010) train a probabilistic model of a variety of sentence simplification rules using expectation maximization with a parallel corpus of aligned sentences from Wikipedia and Simple Wikipedia. Woodsend and Lapata (2011) present a system that uses quasi-synchronous grammar rules learned from Simple Wikipedia edit histories. They solve an integer linear programming (ILP) problem to select both which sentences are simplified (based on a model learned from aligned"
W14-1210,C96-2183,0,0.728193,"f. To evaluate the performance of a simplification system which aims to make texts easier to read and understand, it is also useful to measure improvement in individuals’ reading and comprehension of the texts. Siddharthan and Katsos (2012) recently studied sentence recall to test comprehension; and Temnikova and Maneva (2013) evaluated simplifications using the readers’ ability to answer multiple choice questions about the text. 2 Since the mid-90s several systems have been developed to automatically simplify texts. Early systems used hand-crafted syntactic simplification rules; for example, Chandrasekar et al. (1996), one of the earliest attempts at automated simplification. Rule-based systems continue to be used, amongst others, Siddharthan (2006), Aluisio and Gasperin (2010), and Bott et al. (2012). Many of the more recent systems are statistically-based adapting techniques developed for statistical machine translation. Zhu et al. (2010) train a probabilistic model of a variety of sentence simplification rules using expectation maximization with a parallel corpus of aligned sentences from Wikipedia and Simple Wikipedia. Woodsend and Lapata (2011) present a system that uses quasi-synchronous grammar rule"
W14-1210,W12-3152,0,0.0214003,"Kauchak (2013) used AMT to collect human judgements of the simplifications generated by their system and De Clercq et al. (2014) performed an extensive evaluation of crowdsourced readability judgements compared to expert judgements. Crowdsourcing has also been used to generate translations. The recent statistical machine translation-inspired approaches to automated simplification motivate the possibility of using crowdsourcing to collect simplifications. Ambati and Vogel (2010) and Zaidan and Callison-Burch (2011) both demonstrate the feasibility of collecting quality translations using AMT. Post et al. (2012) generated parallel corpora between English and six Indian languages using AMT. 3 • A large and accessible set of original everyday documents to: • provide a training and test set for automated text simplification • A set of multiple human-generated simplifications at different reading levels for the same set of original documents to provide: • accessible training data for automated text simplification systems • the ability to model how the same document is simplified to different reading levels • An accessible location to share simplifications of the same documents that have been generated by"
W14-1210,W13-2901,0,0.112137,"es developed for statistical machine translation. Zhu et al. (2010) train a probabilistic model of a variety of sentence simplification rules using expectation maximization with a parallel corpus of aligned sentences from Wikipedia and Simple Wikipedia. Woodsend and Lapata (2011) present a system that uses quasi-synchronous grammar rules learned from Simple Wikipedia edit histories. They solve an integer linear programming (ILP) problem to select both which sentences are simplified (based on a model learned from aligned Wikipedia-Simple Wikipedia articles) and what the best simplification is. Feblowitz and Kauchak (2013) use parallel sentences from Wikipedia and Simple Wikipedia to learn synchronous tree substitution grammar rules. 2.1 2.2 Related Work Readability Evaluation Measures of readability are important because they help us assess the reading level of any document, provide a target for simplification systems, and help evaluate and compare the performance of different simplification systems. Several measures of readability have been proposed; DuBay (2004) counted 200 such measures developed by the 1980s and the number has grown, with more advanced automated measures introduced since then. Early measur"
W14-1210,W12-2203,0,0.023342,"pus. Section 6 shows how the extended corpus will be made accessible. Section 7 concludes and outlines the future work that we will undertake to develop the extended corpus. (2012) reported significantly higher accuracy on a similar task using Multi-level Perceptron classification. The above two methods of measuring readability can be computed directly using the text of a document itself. To evaluate the performance of a simplification system which aims to make texts easier to read and understand, it is also useful to measure improvement in individuals’ reading and comprehension of the texts. Siddharthan and Katsos (2012) recently studied sentence recall to test comprehension; and Temnikova and Maneva (2013) evaluated simplifications using the readers’ ability to answer multiple choice questions about the text. 2 Since the mid-90s several systems have been developed to automatically simplify texts. Early systems used hand-crafted syntactic simplification rules; for example, Chandrasekar et al. (1996), one of the earliest attempts at automated simplification. Rule-based systems continue to be used, amongst others, Siddharthan (2006), Aluisio and Gasperin (2010), and Bott et al. (2012). Many of the more recent s"
W14-1210,C10-2032,0,0.0128415,"es are less sophisticated than more modern reading level classifiers, they are still widely used and reported and recent work has shown that they can be a good first approxiˇ mation of more complex measures (Stajner et al., 2012). More recent approaches use more complicated features and machine learning techniques to learn classifiers that can predict readability. For example, Heilman et al. (2007) combine a naive Bayes classifier that uses a vocabulary-based language model with a k-Nearest Neighbors classifier using grammatical features and interpolate the two to predict reading grade level. Feng et al. (2010) and Franc¸ois and Miltsakaki (2012) examine a large number of possible textual features at various levels and compare SVM and Linear Regression classifiers to predict grade level. Vajjala and Meurers 2.3 Automated Text Simplification Systems Corpora for Text Simplification Presently there are limited resources for statistical simplification methods that need to train on a parallel corpus of original and simplified texts. As mentioned in the previous section, common data sources are Simple Wikipedia revision histories and aligned sentences from parallel Wikipedia and Simple Wikipedia articles."
W14-1210,W13-2903,0,0.014202,"and outlines the future work that we will undertake to develop the extended corpus. (2012) reported significantly higher accuracy on a similar task using Multi-level Perceptron classification. The above two methods of measuring readability can be computed directly using the text of a document itself. To evaluate the performance of a simplification system which aims to make texts easier to read and understand, it is also useful to measure improvement in individuals’ reading and comprehension of the texts. Siddharthan and Katsos (2012) recently studied sentence recall to test comprehension; and Temnikova and Maneva (2013) evaluated simplifications using the readers’ ability to answer multiple choice questions about the text. 2 Since the mid-90s several systems have been developed to automatically simplify texts. Early systems used hand-crafted syntactic simplification rules; for example, Chandrasekar et al. (1996), one of the earliest attempts at automated simplification. Rule-based systems continue to be used, amongst others, Siddharthan (2006), Aluisio and Gasperin (2010), and Bott et al. (2012). Many of the more recent systems are statistically-based adapting techniques developed for statistical machine tra"
W14-1210,W12-2207,0,0.0249146,"Missing"
W14-1210,W12-2019,0,0.0258147,"Missing"
W14-1210,P11-1122,0,0.0259006,"Missing"
W14-1210,C10-1152,0,0.479219,"sibility and affect their well-being. The need to present people with texts that are at a reading level which is suitable for them has motivated research into measuring readability of any given text in order to assess whether automatic simplification has rendered a more difficult text into a more readable one. Readability can be measured using tools which assess the reading level of a text. We define simplification as the process of changing a text to lower its reading level without removing necessary information or producing an ungrammatical result. This is similar to the definition of (cf. (Zhu et al., 2010)), except that we avoid defining a specific, limited, set of simplification operations. The Related Work section details research into measures of readability and work on automatic simplification systems. We have begun to construct a large, accessible corpus of everyday documents. This corpus will eventually contain thousands of these documents, each having statistics characterising its contents, and multiple readability measures. Multiple different simplifications will be collected for the original documents and their content statistics and readability measures will be included in the corpus."
W15-2708,N04-1025,0,0.144089,"oss different vocabulary levels allows one to analyze its use independently of the syntactic structures that the speaker uses. Although there is no commonly accepted measure of lexical complexity (Th´eriault, 2015), strategies typically rely on word unigrams to assure that only lexical clues are captured, since already capture grammatical properties (Vermeer, 2000; Heilman et al., 2007; Yasseri et al., 2011; Vajjala and Meurers, 2012). A drawback of such solutions is their inability of representing multiword expressions, like fixed phrases or idioms. This study uses the predictor described in Collins-Thompson and Callan (2004), which is available online4 . This approach is a specialized Naive Bayes classifier with lexical unigram features only (for the previously mentioned reasons), which creates a model of the lexicon for each grade level – between 1st and 12th . https://www.mturk.com/mturk/welcome Confidence measured on a sample of 100 segments 4 72 http://reap.cs.cmu.edu/demo/readability2012/ 300 Talks 0.4 Segments 246 200 160 181 150 100 0 68 52 50 0 17 4 4 5 36 79 55 13 6 8 9 0.3 0.25 0.2 0.15 4 6 0 1 7 Level Talks Segments 0.35 Agreement 250 10 0.1 3 11 4 5 6 7 8 Level 9 10 11 12 Figure 1: Level distribution"
W15-2708,W14-1821,0,0.0221224,"Missing"
W15-2708,N07-1058,1,0.798307,"y involves many aspects of language, such as lexis, syntax, semantics (Pil´an et al., 2014; Dascalu, 2014). This paper, however, is concerned with the lexical complexity component only. Comparing the occurrences of metadiscourse across different vocabulary levels allows one to analyze its use independently of the syntactic structures that the speaker uses. Although there is no commonly accepted measure of lexical complexity (Th´eriault, 2015), strategies typically rely on word unigrams to assure that only lexical clues are captured, since already capture grammatical properties (Vermeer, 2000; Heilman et al., 2007; Yasseri et al., 2011; Vajjala and Meurers, 2012). A drawback of such solutions is their inability of representing multiword expressions, like fixed phrases or idioms. This study uses the predictor described in Collins-Thompson and Callan (2004), which is available online4 . This approach is a specialized Naive Bayes classifier with lexical unigram features only (for the previously mentioned reasons), which creates a model of the lexicon for each grade level – between 1st and 12th . https://www.mturk.com/mturk/welcome Confidence measured on a sample of 100 segments 4 72 http://reap.cs.cmu.edu"
W15-2708,W12-2019,0,0.0228575,"lexis, syntax, semantics (Pil´an et al., 2014; Dascalu, 2014). This paper, however, is concerned with the lexical complexity component only. Comparing the occurrences of metadiscourse across different vocabulary levels allows one to analyze its use independently of the syntactic structures that the speaker uses. Although there is no commonly accepted measure of lexical complexity (Th´eriault, 2015), strategies typically rely on word unigrams to assure that only lexical clues are captured, since already capture grammatical properties (Vermeer, 2000; Heilman et al., 2007; Yasseri et al., 2011; Vajjala and Meurers, 2012). A drawback of such solutions is their inability of representing multiword expressions, like fixed phrases or idioms. This study uses the predictor described in Collins-Thompson and Callan (2004), which is available online4 . This approach is a specialized Naive Bayes classifier with lexical unigram features only (for the previously mentioned reasons), which creates a model of the lexicon for each grade level – between 1st and 12th . https://www.mturk.com/mturk/welcome Confidence measured on a sample of 100 segments 4 72 http://reap.cs.cmu.edu/demo/readability2012/ 300 Talks 0.4 Segments 246"
W15-2708,W98-0315,0,0.412828,"d according to the categories that appeared in the TED talks. More precisely, we consider 16 acts: Intaraprawat and Steffensen (1995) also touched on the topic of metadiscourse and its relations to level, analyzing how 12 English as second language students used organizational language in their essays. When dividing them in good and poor, the authors observed that good essays contained proportionally more metadiscourse. Regarding annotation of metadiscourse, and discourse in general, two distinct data-driven projects are broadly referred to and used. One is the Penn Discourse TreeBank (PDTB) (Webber and Joshi, 1998), built directly on top of Penn TreeBank (Marcus et al., 1993), composed of extracts from the Wall Street Journal. PDTB enriched the Penn TreeBank with discourse connectives annotation (conjunctions and adverbials), and organized them according to meaning (Miltsakaki et al., 2008). Given its goal to reach out to the NLP community and serve as training data, the resulting senses taxonomy is composed of lowlevel and fine-grained concepts. • • • • • • • • • • • • • • COM – Commenting on Linguistic Form/Meaning CLAR – Clarifying DEF – Definitions (originally Manage Terminology) INTRO – Introducing"
W15-2708,J93-2004,0,0.0495883,"e precisely, we consider 16 acts: Intaraprawat and Steffensen (1995) also touched on the topic of metadiscourse and its relations to level, analyzing how 12 English as second language students used organizational language in their essays. When dividing them in good and poor, the authors observed that good essays contained proportionally more metadiscourse. Regarding annotation of metadiscourse, and discourse in general, two distinct data-driven projects are broadly referred to and used. One is the Penn Discourse TreeBank (PDTB) (Webber and Joshi, 1998), built directly on top of Penn TreeBank (Marcus et al., 1993), composed of extracts from the Wall Street Journal. PDTB enriched the Penn TreeBank with discourse connectives annotation (conjunctions and adverbials), and organized them according to meaning (Miltsakaki et al., 2008). Given its goal to reach out to the NLP community and serve as training data, the resulting senses taxonomy is composed of lowlevel and fine-grained concepts. • • • • • • • • • • • • • • COM – Commenting on Linguistic Form/Meaning CLAR – Clarifying DEF – Definitions (originally Manage Terminology) INTRO – Introducing Topic DELIM – Delimiting Topic CONC – Concluding ENUM – Enume"
W15-2708,D11-1061,0,\N,Missing
W15-2708,C10-1113,0,\N,Missing
W15-2708,W06-1603,0,\N,Missing
W15-2708,P09-1053,0,\N,Missing
W15-2708,S15-2011,0,\N,Missing
W15-2708,N12-1034,0,\N,Missing
W15-2708,S15-2021,0,\N,Missing
W15-2708,E06-1042,0,\N,Missing
W15-2708,W13-2515,0,\N,Missing
W15-2708,P12-1091,0,\N,Missing
W15-2708,P05-1074,0,\N,Missing
W15-2708,P13-1024,0,\N,Missing
W15-2708,Q14-1034,0,\N,Missing
W15-2708,P10-1040,0,\N,Missing
W15-2708,S15-2001,0,\N,Missing
W15-2708,D13-1008,0,\N,Missing
W15-2708,U06-1019,0,\N,Missing
W15-2708,D13-1145,0,\N,Missing
W15-2708,D13-1090,0,\N,Missing
W15-2708,P14-1023,0,\N,Missing
W15-2708,S12-1051,0,\N,Missing
W15-2708,D13-1183,0,\N,Missing
W15-2708,W06-3506,0,\N,Missing
W15-2708,D12-1050,0,\N,Missing
W15-2708,I05-5011,0,\N,Missing
W15-2708,J13-3001,0,\N,Missing
W15-2708,D09-1033,0,\N,Missing
W15-4606,C08-2003,0,0.0262797,"ng due to the degradation in quality of the dialog when overlapping speech is produced in the wrong place. For this, a traditional SDS often uses a simplified turn-taking model with rigid turn taking. They only respond when users have finished speaking. Thus past research has mostly focused on end-of-turn detection, finding the end of the user utterance as quickly as possible while minimizing the chance of wrongly interrupting the users. We refer here to the interruption issue as false cut-ins (FCs). Recent research in incremental dialog processing promises more flexible turn-taking behavior (Atterer et al., 2008; Breslin et al., 2013). Here, the automatic speech recognizer (ASR) and natural language understanding (NLU) incrementally 2 Related Work and Limitations This work is closely related to end-of-turn detection and incremental processing (IP) dialog systems. There are several methods for detecting the endof-turn. Raux (2008) built a decision tree for final pause duration using ASR and NLU features. At runtime, the system first dynamically chooses the final pause duration threshold based on the dialog state and then predicts end-of-turn if final pause duration is longer than that threshold. Other"
W15-4606,W13-4065,1,0.920039,"Missing"
W15-4606,W08-0101,1,0.800182,"n speed of response (Raux and Eske42 Proceedings of the SIGDIAL 2015 Conference, pages 42–50, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics responding, as shown on Figure 1: nazi, 2009). Another approach examined prosodic and semantic features such as pitch and speaking rate in human-human conversation for turn-yielding cues (Gravano, 2009). The key limitation of those methods is that the decision made by the end-of-turn detector is treated as a “hard” decision, obliging developers to compromise in a tradeoff between response latency and FC rate (Raux and Eskenazi, 2008). Although adding more complex prosodic and semantic features can improve the performance of the detector, it also increases computation cost and requires significant knowledge of the SDS, which can limit the accessibility for non-expert developers. For IP, Kim (2014) has demonstrated the possibility of learning turn-taking from human dialogs using inverse reinforcement learning. Other work has focused on incremental NLU (DeVault et al., 2009), showing that the correct interpretation of users’ meaning can be predicted before end-of-turn. Another topic is modeling user and system barge-in. Self"
W15-4606,N09-1071,1,0.902828,"Missing"
W15-4606,W13-4063,0,0.0636466,"Missing"
W15-4606,W09-3902,0,0.283743,"Missing"
W15-4630,2007.sigdial-1.23,1,0.765828,"2013 to the REAL workshop on June 21, 2014, and beyond, this paper traces how REAL was managed, the proposals we received, what happened at the workshop, what follow up we have had and how we measure success. Introduction 2 Motivation Speech and spoken dialog researchers often note that whereas industry has access to a wealth of ecologically valid speech data, the academic community lags far behind. The lag in quantity of data can impede research on system evaluation and in training the machine learning (ML) system components. This chasm can be filled by using recruited subjects. But studies (Ai et al., 2007) have found that the resulting data does not resemble real user data. Paid users follow the rules, but are usuThis paper describes the REAL Challenge (REAL), including the motivations for the challenge and preliminary results from the first year and prospects for the near future. The ultimate goal of REAL is to bring about a steady stream of data from real users talking to spoken dialogue systems, that can be used for academic research. The immediate goal of the first year of REAL is to bring together high school and undergraduate students, who have fresh ideas of how people will 209 Proceedin"
W16-3601,D15-1001,0,0.0182184,"Missing"
W16-3601,W10-4334,0,0.0740659,"Missing"
W16-3601,W14-4340,0,0.0672644,"updates the parameters in θi . Only after every C updates, the new weights of θi are copied over to θi− . Furthermore, DQN utilizes experience replay to store all previous experience tuples (s, a, r, s0 ). Before a new model update, the algorithm samples a minibatch of experiences of size M from the memory and computes the gradient of the following loss function: L(θi ) = E(s,a,r,s0 ) [(y DQN − Q(s, a; θi ))2 ] (1) a Proposed Model Overview End-to-end learning refers to models that can back-propagate error signals from the end output to the raw inputs. Prior work in end-to-end state tracking (Henderson et al., 2014) learns a sequential classifier that estimates the dialog state based on ASR output without the need of an NLU. Instead of treating state tracking as a standard supervised learning task, we propose to unify dialog state tracking with the dialog policy so that both are treated as actions available to a reinforcement learning agent. Specifically, we learn an optimal policy that either generates a verbal response or modifies the current estimated dialog state based on the new observations. This formulation makes it possible to obtain a state tracker even without the labelled data required for DST"
W16-3601,P15-1152,0,0.0512337,"Missing"
W16-3601,W13-4065,0,0.295404,"nguage understanding (the NLU) maps the user utterances to some semantic representation. This information is further processed by the dialog state tracker (DST), which accumulates the input of the turn along with the dialog history. The DST outputs the current dialog state and the dialog policy selects the next system action based on the dialog state. Then natural language generation (NLG) maps the selected action to its surface form which 1 Proceedings of the SIGDIAL 2016 Conference, pages 1–10, c Los Angeles, USA, 13-15 September 2016. 2016 Association for Computational Linguistics matched (Williams et al., 2013). Therefore one of the basic assumptions of DSTC is that the state tracker’s performance will translate to better dialog policy performance. Lee (2014) showed positive results following this assumption by showing a positive correlation between end-to-end dialog performance and state tracking performance. tems faces several challenges. The foremost challenge is that a task-oriented system must learn a strategic dialog policy that can achieve the goal of a given task which is beyond the ability of standard supervised learning (Li et al., 2014). The second challenge is that often a task-oriented"
W16-3601,W14-4342,0,\N,Missing
W16-6007,W13-4065,0,0.123063,"large corpora cover a wide set of research domains. It is also extremely difficult for any one group to devote time to collecting and curating a significant amount of real user data. The users must be found and kept interested, and the interface must be created and maintained. Challenges Besides creating new corpora for advanced dialog research, DialPort encounters new research challenges. • Advanced Dialog State Representation Learning: Traditional dialog states are represented as sets of symbolic variables that are related to domain-specific ontology and are tracked by statistical methods (Williams et al., 2013). Such an approach soon becomes intractable if we want to capture all the essential dialog state features within nested multi-domain conversations, such as modeling user preferences and tracking discourse features. DialPort must address this challenge if it is to effectively serve as a portal to many systems. • Dialog Policy that Combines Various Types of Agents: DialPort is powered by multiple dialog agents from research labs around the world. It is different from the traditional sin32 Proceedings of EMNLP 2016 Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to R"
W16-6007,W16-3601,1,0.836922,"nts as well as external knowledge resources. To date, the DialPort portal has successfully connected to two dialog systems and several public knowledge APIs. We present current progress and envision our future plan. 2 1 Introduction Much fundamental research in the spoken dialog domain remains to be done, including adaption for user modeling and management of complex dialogs. In recent years, there has been increasing interest in applying deep learning to modeling the process of human-computer conversation (Vinyals and Le, 2015; Serban et al., 2015; Wen et al., 2016; Williams and Zweig, 2016; Zhao and Eskenazi, 2016). One of the prerequisites for the success of these methods is having a large conversation corpus to train on. In order to advance the research in these uphill areas of study with the state-of-the-art data-driven methods, large corpora of multi-type real user dialogs are needed. At present, few existing large corpora cover a wide set of research domains. It is also extremely difficult for any one group to devote time to collecting and curating a significant amount of real user data. The users must be found and kept interested, and the interface must be created and maintained. Challenges Beside"
W17-5505,D14-1181,0,0.00478845,"Missing"
W17-5505,H05-1029,0,0.0344586,"Pennsylvania, USA {tianchez,arlu,kyusongl,max+}@cs.cmu.edu Abstract list of dialog acts that covers the expected communicative functions from the system. Although the above approach has been successfully applied to many practical systems, it has limited ability to generalize to out-of-domain (OOD) requests and to scale up to new domains. For example, even within in a simple domain, real users often make requests that are not included in the semantic specifications. Due to this, proper error handling strategies that guide users back to the in-domain conversation are crucial to dialog success (Bohus and Rudnicky, 2005). Past error handling strategies were limited to a set of predefined dialog acts, e.g. request repeat, clarification etc., which constrained the system’s capability in keeping users engaged. Moreover, there has been an increased interest in extending task-oriented systems to multiple topics (Lee et al., 2009; Gaˇsi´c et al., 2015b) and multiple skills, e.g. grouping heterogeneous types of dialogs into a single system (Zhao et al., 2016). Both cases require the system to be flexible enough to extend to new slots and actions. Our goal is to move towards a domain-general task-oriented SDS framewo"
W17-5505,D16-1127,0,0.0507463,"gh the slots metric already covers the KB queries, here the precision/recall/Fscore of system utterances that contain KB queries are also explicitly measured, due to their importance. Specifically, this action measures whether the system is able to generate the special [kbquery] symbol to initiate a KB query, as well as how accurate the corresponding KB query arguments are. BLEU (Papineni et al., 2002): compares the ngram precision with length penalty, and has been a popular score used to evaluate the performance of natural language generation (Wen et al., 2015) and open-domain dialog models (Li et al., 2016). Corpus-level BLEU-4 is reported. Training Details For all experiments, the word embedding size was 100. The sizes of the LSTM hidden states for both the encoder and decoder were 500 with 1 layer. The attention context size was also 500. We tied the CNN weights for the encoding system and user utterances. Each CNN has 3 filter windows, 1, 2, and 3, with 100 feature maps each. We trained the model end-to-end using Adam (Kingma and Ba, 2014), with a learning rate of 1e-3 and a batch size of 40. To combat overfitting, we apply dropout (Zaremba et al., 2014) to the LSTM layer outputs and the CNN"
W17-5505,D15-1166,0,0.0533622,"ource sequence. An attention mechanism proposed (Bahdanau et al., 2014) in the machine translation community has helped encoderdecoder models improve state-of-art performance in various tasks (Bahdanau et al., 2014; Xu et al., 2015). Attention allows the decoder to look over every hidden state in the encoder and dynamically decide the importance of each hidden state at each decoding step, which significantly improves the model’s ability to handle long-term dependency. We experiment decoders both with and without attention. Attention is computed similarly multiplicative attention described in (Luong et al., 2015). We denote the hidden state of the decoder at time step j by sj , and the hidden state outputs of the encoder at turn i by hi . We then predict the next word by (CNNs) proposed in (Kim, 2014). Specifically, each word in an utterance x is mapped to its word embedding, so that an utterance is represented as a matrix R ∈ R|x|×D , in which D is the size of the word embedding. Then L filters of size 1,2,3 conduct convolutions on R to obtain a feature map, c, of n-gram features in window size 1,2,3. Then c is passed through a nonlinear ReLu (Glorot et al., 2011) layer, followed by a max-pooling lay"
W17-5505,W03-0430,0,0.119032,"onducted to evaluate the performance of the proposed systems in the real world. Due to the limited number of real users, only two best performing system were compared, EI+Attn and EI+Attn+Chat. Users were able to talk to a web interface to the dialog systems via speech. Google 33 Chrome Speech API 2 served as the ASR and textto-speech (TTS) modules. Turn-taking was done via the built-in Chrome voice activity detection (VAD) plus a finite state machine-based end-ofturn detector (Zhao et al., 2015). Lastly, a hybrid named entity recognizer (NER) was trained using Conditional Random Field (CRF) (McCallum and Li, 2003) and rules to extract 4 types of entities (location, hour, minute, pm/am) for the EI process. The experiment setup is as follows: when a user logs into the website, the system prompts the user with a goal, which is a randomly chosen combination of departure place, arrival place and time (e.g. leave from CMU and go to the airport at 10:30 AM). The system also instructs the user to say goodbye if the he/she thinks the goal is achieved or wants to give up. The user begins a conversation with one of the two evaluated systems, with a 50/50 chance of choosing either system (not visible to the user)."
W17-5505,E17-2075,0,0.0817275,"unified the special KB query actions via deep reinforcement learning (Zhao and Eskenazi, 2016) and soft attention over the database (Dhingra et al., 2016). The third branch strives to solve both problems at the same time by building an end-to-end model that maps an observable dialog history directly to the word sequences of the system’s response. By using an encoder-decoder model, it has been successfully applied to open-domain conversational models (Serban et al., 2015; Li et al., 2015, 2016; Zhao et al., 2017), as well as to task oriented systems (Bordes and Weston, 2016; Yang et al., 2016; Eric and Manning, 2017). In order to better predict the next correct system action, this branch has focused on investigating various neural network architectures to improve the machine’s ability to reason over user input and model longterm dialog context. Related Work This paper is closely related to the third branch, but differs in the following ways: 1) these models are slot-value independent by leveraging domaingeneral entity recognizer, which is more extensible to OOV entities, 2) these models emphasize the interactive nature of dialog and address out-ofdomain handling by interleaving chatting in taskoriented co"
W17-5505,P02-1040,0,0.0978991,"’s performance in generating the correct slot-values. The slot-values mostly occur in grounding utterances (e.g. explicit/implicit confirm) and KB queries. We compute precision, recall, and F-score. KB Queries: Although the slots metric already covers the KB queries, here the precision/recall/Fscore of system utterances that contain KB queries are also explicitly measured, due to their importance. Specifically, this action measures whether the system is able to generate the special [kbquery] symbol to initiate a KB query, as well as how accurate the corresponding KB query arguments are. BLEU (Papineni et al., 2002): compares the ngram precision with length penalty, and has been a popular score used to evaluate the performance of natural language generation (Wen et al., 2015) and open-domain dialog models (Li et al., 2016). Corpus-level BLEU-4 is reported. Training Details For all experiments, the word embedding size was 100. The sizes of the LSTM hidden states for both the encoder and decoder were 500 with 1 layer. The attention context size was also 500. We tied the CNN weights for the encoding system and user utterances. Each CNN has 3 filter windows, 1, 2, and 3, with 100 feature maps each. We traine"
W17-5505,N15-1020,0,0.0833927,"Missing"
W17-5505,W03-0419,0,0.449483,"Missing"
W17-5505,W15-4654,0,0.0282705,"ractive nature of dialog and address out-ofdomain handling by interleaving chatting in taskoriented conversations, 3) instead of testing on a synthetic dataset, this approach focuses on real world use by testing the system on human users via spoken interface. Past research in developing domain-general dialog systems can be broadly divided into three branches. The first one focuses on learning domain-independent dialog state representation while still using hand-crafted dialog act system actions. Researchers proposed the idea of extracting slot-value independent statistics as the dialog state (Wang et al., 2015; Gaˇsi´c et al., 2015a), so that the dialog state representation can be shared across systems serving different knowledge sources. Another approach uses RNNs to auto28 3 Proposed Method Our proposed framework consists of three steps as shown in Figure 2: a) entity indexing (EI), b) slot-value independent encoder-decoder (SiED), c) system utterance lexicalization (UL). The intuition is to leverage domain-general named entity recognition (NER) (Tjong Kim Sang and De Meulder, 2003) techniques to extract salient entities in the raw dialog history and convert the lexical values of the entities int"
W17-5505,W15-4606,1,0.854765,"challenges, such as automatic speech recognition (ASR) errors, OOD requests, etc. Therefore, a real user study was conducted to evaluate the performance of the proposed systems in the real world. Due to the limited number of real users, only two best performing system were compared, EI+Attn and EI+Attn+Chat. Users were able to talk to a web interface to the dialog systems via speech. Google 33 Chrome Speech API 2 served as the ASR and textto-speech (TTS) modules. Turn-taking was done via the built-in Chrome voice activity detection (VAD) plus a finite state machine-based end-ofturn detector (Zhao et al., 2015). Lastly, a hybrid named entity recognizer (NER) was trained using Conditional Random Field (CRF) (McCallum and Li, 2003) and rules to extract 4 types of entities (location, hour, minute, pm/am) for the EI process. The experiment setup is as follows: when a user logs into the website, the system prompts the user with a goal, which is a randomly chosen combination of departure place, arrival place and time (e.g. leave from CMU and go to the airport at 10:30 AM). The system also instructs the user to say goodbye if the he/she thinks the goal is achieved or wants to give up. The user begins a con"
W17-5505,D15-1199,0,0.0373207,"recision, recall, and F-score. KB Queries: Although the slots metric already covers the KB queries, here the precision/recall/Fscore of system utterances that contain KB queries are also explicitly measured, due to their importance. Specifically, this action measures whether the system is able to generate the special [kbquery] symbol to initiate a KB query, as well as how accurate the corresponding KB query arguments are. BLEU (Papineni et al., 2002): compares the ngram precision with length penalty, and has been a popular score used to evaluate the performance of natural language generation (Wen et al., 2015) and open-domain dialog models (Li et al., 2016). Corpus-level BLEU-4 is reported. Training Details For all experiments, the word embedding size was 100. The sizes of the LSTM hidden states for both the encoder and decoder were 500 with 1 layer. The attention context size was also 500. We tied the CNN weights for the encoding system and user utterances. Each CNN has 3 filter windows, 1, 2, and 3, with 100 feature maps each. We trained the model end-to-end using Adam (Kingma and Ba, 2014), with a learning rate of 1e-3 and a batch size of 40. To combat overfitting, we apply dropout (Zaremba et a"
W17-5505,W16-3601,1,0.932179,"query the KB. Moreover, we show the extensibility of the proposed model by adding chatting capability to a task-oriented encoder-decoder SDS for better OOD recovery. This approach was assessed on the Let’s Go Bus Information data from the 1st Dialog State Tracking Challenge (Williams et al., 2013), and we report performance on both offline metrics and real human users. Results show that this model attains good performance for both of these metrics. 2 matically learn a distributed vector representation of the dialog state by accumulating the observations at each turn (Williams and Zweig, 2016; Zhao and Eskenazi, 2016; Dhingra et al., 2016; Williams et al., 2017). The learned dialog state is then used by the dialog policy to select the next action. The second branch of research develops a domain-general action space for dialog policy. Prior work replaced the domain-specific dialog acts with domain-independent natural language semantic schema as the action space of dialog managers (Eshghi and Lemon, 2014), e.g. Dynamic Syntax (Kempson et al., 2000). More recently, Wen, et al. (2016) have shown the feasibility of using an RNN as the decoder to generate the system utterances word by word, and the dialog polic"
W17-5505,W16-6007,1,0.845603,"emantic specifications. Due to this, proper error handling strategies that guide users back to the in-domain conversation are crucial to dialog success (Bohus and Rudnicky, 2005). Past error handling strategies were limited to a set of predefined dialog acts, e.g. request repeat, clarification etc., which constrained the system’s capability in keeping users engaged. Moreover, there has been an increased interest in extending task-oriented systems to multiple topics (Lee et al., 2009; Gaˇsi´c et al., 2015b) and multiple skills, e.g. grouping heterogeneous types of dialogs into a single system (Zhao et al., 2016). Both cases require the system to be flexible enough to extend to new slots and actions. Our goal is to move towards a domain-general task-oriented SDS framework that is flexible enough to expand to new domains and skills by removing domain-specific assumptions on the dialog state and dialog acts (Bordes and Weston, 2016). To achieve this goal, the neural encoderdecoder model(Cho et al., 2014; Sutskever et al., 2014) is a suitable choice, since it has achieved promising results in modeling open-domain conversations (Vinyals and Le, 2015; Sordoni et al., 2015). It encodes the dialog history us"
W17-5505,P17-1061,1,0.832514,"g end-to-end task-oriented dialog models that are able to interface with external KB, prior work has unified the special KB query actions via deep reinforcement learning (Zhao and Eskenazi, 2016) and soft attention over the database (Dhingra et al., 2016). The third branch strives to solve both problems at the same time by building an end-to-end model that maps an observable dialog history directly to the word sequences of the system’s response. By using an encoder-decoder model, it has been successfully applied to open-domain conversational models (Serban et al., 2015; Li et al., 2015, 2016; Zhao et al., 2017), as well as to task oriented systems (Bordes and Weston, 2016; Yang et al., 2016; Eric and Manning, 2017). In order to better predict the next correct system action, this branch has focused on investigating various neural network architectures to improve the machine’s ability to reason over user input and model longterm dialog context. Related Work This paper is closely related to the third branch, but differs in the following ways: 1) these models are slot-value independent by leveraging domaingeneral entity recognizer, which is more extensible to OOV entities, 2) these models emphasize the"
W17-5505,W13-4065,0,0.505635,"n task success rate with human users. 1 Introduction Task-oriented spoken dialog systems have transformed human-computer interaction by enabling people interact with computers via spoken language (Raux et al., 2005; Young, 2006; Bohus and Rudnicky, 2003). The task-oriented SDS is usually domain-specific. The system creators first map the user utterances into semantic frames that contain domain-specific slots and intents using spoken language understanding (SLU) (De Mori et al., 2008). Then a set of domain-specific dialog state variables is tracked to retain the context information over turns (Williams et al., 2013). Lastly, the dialog policy decides the next move from a 27 Proceedings of the SIGDIAL 2017 Conference, pages 27–36, c Saarbr¨ucken, Germany, 15-17 August 2017. 2017 Association for Computational Linguistics A na`‘ive implementation of an encoderdecoder-based task-oriented system would use RNNs to encode the raw dialog history and generate the next system utterance using a separate RNN decoder. However, while this implementation might achieve good performance in an offline evaluation of a closed dataset, it would certainly fail when used by humans. There are several reasons for this: 1) real u"
W17-5505,W03-2111,0,0.0816835,"reasons that the above data augmentation process is appealing. First, the model effectively learns an OOD recovery strategy from D∗ , i.e. it first gives chatting answers to users’ OOD requests and then tries to pull users back to the main-task conversation. Second, chat data usually has a larger vocabulary and more diverse natural language expressions, which can reduce the chance of OOVs and enable the model to learn more robust word embeddings and language models. Past work has shown that simple supervised learning is usually inadequate for learning robust sequential decision-making policy (Williams and Young, 2003; Ross et al., 2011). This is because the model is only exposed to the expert demonstration, but not to examples of how to recover from its own mistakes or users’ OOD requests. We present a simple yet effective technique that leverages the extensibility of the encoder-decoder model in order to obtain a more robust policy in the setting of supervised learning. Specifically, we artificially augment a task-oriented dialog dataset with chat data from an open-domain conversation corpus. This has been shown to be effective in improving the performance of task-oriented systems (Yu et al., 2017). Let"
W17-5505,P17-1062,0,\N,Missing
W17-5521,L16-1435,1,0.845456,"f Engineering, University of Cambridge, Cambridge, UK {kyusongl,tianchez,yulund,edcai,arlu,max}@cs.cmu.edu 1 {pincus, traum}@ict.usc.edu 2 {su259,lmr46,mg436,sjy11}@eng.cam.ac.uk Abstract what users might expect, given their exposure to the Amazon ECHO1 and Google HOME2 , etc. In order to get a flow of users started, DialPort developers expanded the number of connected systems to make the portal offerings more attractive and relevant. They also made the interface easier to use. By the end of March 2017, in addition to the above systems, the portal also included Mr. Clue, a word game from USC (Pincus and Traum, 2016), a restaurant opinion bot (Let’s Discuss, CMU), and a bus information system derived from Let’s Go (Raux et al., 2005). The portal offers users the option of typing or talking and of seeing an agent or just hearing it. With few connected systems in previous versions it was difficult to assess the portal’s switching mechanisms. The increased number of systems challenges the portal to make better decisions and have better a switching strategy. It also demands changes in the frequency of recommendations to connected systems. And it challenged the nature of the agent: some users prefer no visual"
W17-5521,P94-1001,1,0.116125,"the use of a visual agent, the absence of both graphical and speech response, feedback and portal behavior. Some ES need graphics to supplement their verbal information. Since Mr Clue keeps score and timing of users’ answers, its instructions and scores are shown on a blackboard. Let’s Go shows a map with the bus trajectory from departure to arrival. Feedback and communication The portal gives users feedback for: available topics, system state, and present system state. Skylar doesn’t interrupt the dialog with a list of topics. Rather 171 to the way in which they made their earlier requests (Traum and Allen, 1994). For example, the weather system should produce the natural Yes it’s going to rain instead of a full weather report, for the third question above. We thus keep the user’s initial request intent in the global dialog context and share it with the relevant ESes. The recommendation policy has been improved in two ways: 1) All participating system developers agreed that Skylar should give ES recommendations on a rotating basis so that all systems are recommended equally. Skylar no longer makes a recommendation at the end of each system turn. Recommendations are made about every four turns and, as"
W17-5521,P17-4013,1,0.820805,"atabase of restaurant reviews obtained from Zomato and Yelp. We formed a list of general discussion points for restaurants (service, atmosphere, etc). For each discussion point, a list of relevant keywords was compiled using WordNet, thesaurus, and by categorizing the most frequently words found in reviews. Cambridge The Cambridge restaurant information system helps users find a restaurant in Cambridge, UK based on the area, the price range or the food type. The current database has just over 100 restaurants and is implemented using the multi-domain statistical dialogue system toolkit PyDial (Ultes et al., 2017). To connect PyDial to Dialport, PyDial’s dialogue server interface is used. It is implemented as an HTTP server expecting JSON messages from the Dialport client. The system runs a trained dialogue policy based on the GP-SARSA algorithm (Gaˇsi´c et al., 2010). Other Systems QuBot, a chatbot from Pohang University and CMU, is used for out-of-domain handling. Let’sForecast, from CMU, uses the NOAA website. Let’s Eat from CMU is based on Yelp, finding restaurants for cities that Cambridge does not cover and for Cambridge if that system is down. Let’s Go, derived from the Let’s Go system (Raux et"
W17-5521,W10-4334,1,\N,Missing
W18-5001,P15-1107,0,0.0605165,"Missing"
W18-5001,D15-1166,0,0.0473725,"serves the purpose perfectly. Another advantage is that using zx predicted by R as input enables the discourselevel encoder to use knowledge from latent actions as well. Our discourse-level encoder is a 1layer LSTM-RNN (Hochreiter and Schmidhuber, 1997), which takes in a list of output [z1 , z2 ..zK ] from R and encodes them into [v1 , v2 , ...vK ], where K is the number of utterances in the context. The last hidden state vK is used as the predicted latent action zc . Response Decoders: we experiment with two types of LSTM-RNN decoders. The first is an RNN decoder with an attention mechanism (Luong et al., 2015), enabling the decoder to dynamically look up information from the context. Specifically, we flatten the dialog context into a sequence of words [w11 , ...w1J ...wKJ ]. Using output from the R and the discourse-level LSTMRNN, each word here is represented by mkj = hkj + Wv vk . Let the hidden state of the decoder at step t be st , then our attention mechanism computes the Softmax output via: kj∈I(w,x) g = softmax(uT tanh(Wα si )) 5 Datasets for ZSDG Two dialog datasets were used for evaluation. 5.1 SimDial Data We developed SimDial2 , which is a multi-domain dialog generator that can generate"
W18-5001,N18-1020,0,0.118185,"og-ZSDG 1 Proceedings of the SIGDIAL 2018 Conference, pages 1–10, c Melbourne, Australia, 12-14 July 2018. 2018 Association for Computational Linguistics In this case, a task is described by a demonstration or a sequence of instructions, and the system needs to learn to break down the instructions into previously learned skills. Also generating outof-vocabulary (OOV) words from recurrent neural networks (RNNs) can be seen as a form of ZSL, where the OOV words are unseen labels. Prior work has used delexicalized tags (Zhao et al., 2017) and copy-mechanism (Gu et al., 2016; Merity et al., 2016; Elsahar et al., 2018) to enable RNN output words that are not in its vocabulary. Finally, ZSL has been applied to individual components in the dialog system pipeline. Chen et al. (Chen et al., 2016) developed an intent classifier that can predict new intent labels that are not included in the training data. Bapna et al. (Bapna et al., 2017) extended that idea to the slot-filling module to track novel slot types. Both papers leverage a natural language description for the label (intent or slot-type) in order to learn a semantic embedding of the label space. Then, given any new labels, the model can still make predi"
W18-5001,P02-1040,0,0.10549,"n task-oriented dialogs (Eric and Manning, 2017a). We then augment both baseline models with the proposed cross-domain AM training procedure and denote them as +Attn+AM and +Copy+AM. Evaluating generative dialog systems is challenging since the model can generate free-form responses. Fortunately, we have access to the internal semantic frames of the SimDial data, so we use the automatic measures used in (Zhao et al., 2017) that employ four metrics to quantify the performance of a task-oriented dialog model. BLEU is the corpus-level BLEU-4 between the generated response and the reference ones (Papineni et al., 2002). Entity F1 checks if a generated response contains the correct entities (slots) in the reference response. Act F1 measures whether the generated responses reflect the dialog acts in the reference responses, which compensates for BLEU’s limitation of looking for exact word choices. A onevs-rest support vector machine (Scholkopf and Smola, 2001) with bi-gram features is trained to 6 tag the dialogs in a response. KB F1 checks all the key words in a KB query that the system issues to the√KB backend. Finally, we introduce BEAK = 4 bleu × ent × act × kb, the geometric mean of these four scores, to"
W18-5001,E17-2075,0,0.297481,"that models the semantics of dialog responses. This in turns enables the GEDM to generate responses in the target domains even when it has never observed full dialogs in them. Finally the proposed methods and baselines are evaluated on two dialog datasets. The first one is a new synthetic dialog dataset generated by SimDial, which was developed for this study. SimDial enables us to easily generate task-oriented dialogs in a large number of domains, and provides a test bed to evaluate different ZSDG approaches. We further test our methods on a recently released multi-domain human-human corpus (Eric and Manning, 2017b) to validate whether performance can generalize to real-world conversations. Experimental results show that our methods are effective in incorporating knowledge from domain descriptions and achieve strong ZSDG performance. 2 Related Work Perhaps the most closely related topic is zeroshot learning (ZSL) for classification (Larochelle et al., 2008), which has focused on classifying unseen labels. A common approach is to represent the labels as attributes instead of class indexes (Palatucci et al., 2009). As a result, at test time, the model can first predict the semantic attributes in the inpu"
W18-5001,D17-1236,0,0.0471411,"more challenging. First since SimDial simulates communication noise, the dialogs that are generated can be very long (more than 50 turns) and the simulated agent can carry out error recovery strategies to correctly infer the users’ goals. This challenges end-to-end models αkj,t = softmax(mTkj tanh(Wα st )) (3) X set = αkj,t mkj (4) kj pvocab (wt |st ) = softmax(MLP(st , set )) (7) (5) 2 The second type is the LSTM-RNN with a copy 5 https://github.com/snakeztc/SimDial 5.2 to model long dialog contexts. SimDial also simulates spoken language phenomena, e.g. self-repair, hesitation. Prior work (Eshghi et al., 2017) has shown that this type of utterance-level noise deteriorates end-to-end dialog system performance. Stanford Multi-Domain Dialog Data The second dataset is the Stanford multi-domain dialog (SMD) dataset (Eric and Manning, 2017b) of 3031 human-human dialogs in three domains: weather, navigation and scheduling. One speaker plays the role of a driver. The other plays the car’s AI assistant and talks to the driver to complete tasks, e.g. setting directions on a GPS. Average dialog length is 5.25 utterances; vocabulary size is 1601. We use SMD to validate whether our proposed methods generalize t"
W18-5001,P16-1154,0,0.243007,"ttps://github. com/snakeztc/NeuralDialog-ZSDG 1 Proceedings of the SIGDIAL 2018 Conference, pages 1–10, c Melbourne, Australia, 12-14 July 2018. 2018 Association for Computational Linguistics In this case, a task is described by a demonstration or a sequence of instructions, and the system needs to learn to break down the instructions into previously learned skills. Also generating outof-vocabulary (OOV) words from recurrent neural networks (RNNs) can be seen as a form of ZSL, where the OOV words are unseen labels. Prior work has used delexicalized tags (Zhao et al., 2017) and copy-mechanism (Gu et al., 2016; Merity et al., 2016; Elsahar et al., 2018) to enable RNN output words that are not in its vocabulary. Finally, ZSL has been applied to individual components in the dialog system pipeline. Chen et al. (Chen et al., 2016) developed an intent classifier that can predict new intent labels that are not included in the training data. Bapna et al. (Bapna et al., 2017) extended that idea to the slot-filling module to track novel slot types. Both papers leverage a natural language description for the label (intent or slot-type) in order to learn a semantic embedding of the label space. Then, given an"
W18-5001,W16-3601,1,0.837582,"in the domain so it is best for SR to cover more responses that are unique to this domain. SRs assume that there is a discourselevel pattern that can be shared between the source and target domains, so that a system only needs Figure 1 shows an overview of the model we use to tackle ZSDG. The base model is a standard encoder-decoder F where an encoder F e maps c and d into a distributed representation zc = F e (c, d) and the decoder F d generates the response x given zc . We denote the embedding space that zc resides in as the latent action space. We follow the KB-as-an-environment approach (Zhao and Eskenazi, 2016) where the generated x include both system verbal utterances and API queries that interface with back-end databases. This base model has been proven to be effective in human interactive evaluation for taskoriented dialogs (Zhao et al., 2017). We have two high-level goals: (1) learn a crossdomain F that can be reused in all source domains and potentially shared with target domains as well. (2) create a mechanism to incorporate knowledge from the domain descriptions into F so that it can generate novel responses when tested on the target domains. To achieve the first goal, we combine c and d by"
W18-5001,W17-5505,1,0.950507,"onses which, in turn, lets a neural dialog generation model generalize to new domains. We evaluate our methods on a new synthetic dialog dataset, and an existing human-human dialog dataset. Results show that our method has superior performance in learning dialog models that rapidly adapt their behavior to new domains and suggests promising future research.1 1 Introduction The generative end-to-end dialog model (GEDM) is one of the most powerful methods of learning dialog agents from raw conversational data in both chat-oriented and task-oriented domains (Serban et al., 2016; Wen et al., 2016; Zhao et al., 2017). Its base model is an encoder-decoder network (Cho et al., 2014) that uses an encoder network to encode the dialog context and generate the next response via a decoder network. Yet prior work in GEDMs has overlooked an important issue, i.e. the data scarcity problem. In fact, the data 1 Code and data are avaliable at https://github. com/snakeztc/NeuralDialog-ZSDG 1 Proceedings of the SIGDIAL 2018 Conference, pages 1–10, c Melbourne, Australia, 12-14 July 2018. 2018 Association for Computational Linguistics In this case, a task is described by a demonstration or a sequence of instructions, and"
W18-5001,W17-5506,0,\N,Missing
W18-5028,W10-0719,0,0.0470991,"Missing"
W19-5921,P02-1040,0,0.105983,"aurant, taxi, train. Individual conversations span one to five of the domains. Dialogs were collected using the Wizard-of-Oz framework, where one participant plays the role of an automated system. Each dialog consists of a goal and multiple user and system utterances. Each turn is annotated with two binary vectors: a belief state vector and a dialog act vector. A single turn may have multiple positive values in both the belief state and dialog act vectors. The belief state and dialog act vectors are of dimensions 94 and 593, respectively. Several metrics are used to evaluate the models. BLEU (Papineni et al., 2002) is used to com(10) By pre-training the modules and using their structured outputs, the higher-level model does not have to re-learn and re-model the dialog structure (i.e., representing the belief state and dialog acts). Instead, it can focus on the more abstract modelling that is necessary for the task, including recognizing and encoding complex natural language input, modelling a policy, and effectively converting a latent representation into a natural language output according to the policy. The SFN architecture may seem complicated due to the redundancy of the inputs. For example, the con"
W19-5921,D17-1259,0,0.319232,"g systems, including Na¨ıve Fusion, Multitask Fusion and Structured Fusion Networks (SFNs). This paper will show that SFNs Introduction End-to-end neural dialog systems have shown strong performance (Vinyals and Le, 2015; Dinan et al., 2019). However such models suffer from a variety of shortcomings, including: a data-hungry nature (Zhao and Eskenazi, 2018), a tendency to produce generic responses (Li et al., 2016b), an inability to generalize (Mo et al., 2018; Zhao and Eskenazi, 2018), a lack of controllability (Hu et al., 2017), and divergent behavior when tuned with reinforcement learning (Lewis et al., 2017). Traditional dialog systems, which are generally free of these problems, consist of three distinct components: the natural language understanding (NLU), which produces a structured representation of an ∗ * Equal contribution. 165 Proceedings of the SIGDial 2019 Conference, pages 165–177 c Stockholm, Sweden, 11-13 September 2019. 2019 Association for Computational Linguistics obtain strong results on the MultiWOZ dataset (Budzianowski et al., 2018) both with and without the use of reinforcement learning. Due to the explicit structure of the model, SFNs are shown to exhibit several valuable pro"
W19-5921,P16-1094,0,0.0682632,"Missing"
W19-5921,D16-1127,0,0.510124,"t, several neural dialog modules are constructed to serve the role of the NLU, the DM and the NLG. Next, a number of methods are proposed for incorporating these dialog modules into end-to-end dialog systems, including Na¨ıve Fusion, Multitask Fusion and Structured Fusion Networks (SFNs). This paper will show that SFNs Introduction End-to-end neural dialog systems have shown strong performance (Vinyals and Le, 2015; Dinan et al., 2019). However such models suffer from a variety of shortcomings, including: a data-hungry nature (Zhao and Eskenazi, 2018), a tendency to produce generic responses (Li et al., 2016b), an inability to generalize (Mo et al., 2018; Zhao and Eskenazi, 2018), a lack of controllability (Hu et al., 2017), and divergent behavior when tuned with reinforcement learning (Lewis et al., 2017). Traditional dialog systems, which are generally free of these problems, consist of three distinct components: the natural language understanding (NLU), which produces a structured representation of an ∗ * Equal contribution. 165 Proceedings of the SIGDial 2019 Conference, pages 165–177 c Stockholm, Sweden, 11-13 September 2019. 2019 Association for Computational Linguistics obtain strong resul"
W19-5921,W16-3603,0,0.0277483,"ormation (MMI) as the objective function, as a way of encouraging informative agent responses. Serban et al. (2016) proposes to better capture the semantics of dialog with the use of a hierarchical encoder decoder (HRED), comprised of an utterance encoder, a conversational context encoder, and a decoder. Li et al. (2016b) incorporate a number of heuristics into the reward function, to encourage useful conversational properties such as informativity, coherence and forward-looking. Li et al. (2016a) encodes a speaker’s persona as a distributed embedding and uses it to improve dialog generation. Liu and Lane (2016) simultaneously learn intent modelling, slot filling and language modelling. Zhao et al. (2017) enables task-oriented systems to make slot-value-independent decisions and improves out-of-domain recovery through the use of entity indexing and delexicalization. Wu et al. (2017) present Recurrent Entity Networks which use action templates and reasons about abstract entities in an end-to-end manner. Zhao and Eskenazi (2018) present the Action Matching algorithm, which maps utterances to a cross-domain embedding space to improve zero-shot generaliz166 Generation Problems 3.1 NLG (i.e., a conditione"
W19-5921,P19-1373,1,0.82753,"sentation of an ∗ * Equal contribution. 165 Proceedings of the SIGDial 2019 Conference, pages 165–177 c Stockholm, Sweden, 11-13 September 2019. 2019 Association for Computational Linguistics obtain strong results on the MultiWOZ dataset (Budzianowski et al., 2018) both with and without the use of reinforcement learning. Due to the explicit structure of the model, SFNs are shown to exhibit several valuable properties including improved performance in reduced data scenarios, better domain generalizability and robustness to divergence during reinforcement learning (Lewis et al., 2017). ability. Mehri et al. (2019) explore several dialog specific pre-training objectives that improve performance on dowstrean dialog tasks, including generation. Chen et al. (2019) present a hierarchical self-attention network, conditioned on graph structured dialog acts and pre-trained with BERT (Devlin et al., 2018). 2 Despite their relative success, end-to-end neural dialog systems have been shown to suffer from a number of shortcomings. (Li et al., 2016b) introduced the dull response problem, which describes how neural dialog systems tend to produce generic and uninformative responses (e.g., ”I don’t know”). Zhao and Es"
W19-5921,W18-5001,1,0.932564,"cture of traditional dialog systems into neural dialog models. First, several neural dialog modules are constructed to serve the role of the NLU, the DM and the NLG. Next, a number of methods are proposed for incorporating these dialog modules into end-to-end dialog systems, including Na¨ıve Fusion, Multitask Fusion and Structured Fusion Networks (SFNs). This paper will show that SFNs Introduction End-to-end neural dialog systems have shown strong performance (Vinyals and Le, 2015; Dinan et al., 2019). However such models suffer from a variety of shortcomings, including: a data-hungry nature (Zhao and Eskenazi, 2018), a tendency to produce generic responses (Li et al., 2016b), an inability to generalize (Mo et al., 2018; Zhao and Eskenazi, 2018), a lack of controllability (Hu et al., 2017), and divergent behavior when tuned with reinforcement learning (Lewis et al., 2017). Traditional dialog systems, which are generally free of these problems, consist of three distinct components: the natural language understanding (NLU), which produces a structured representation of an ∗ * Equal contribution. 165 Proceedings of the SIGDial 2019 Conference, pages 165–177 c Stockholm, Sweden, 11-13 September 2019. 2019 Ass"
W19-5921,W17-5505,1,0.91993,"Missing"
W19-5921,N19-1123,1,0.843621,"m of the overwhelming implicit language model in image captioning model decoders. They state that the decoder learns a language generation model along with a policy, however, during the process of captioning certain inputs, the decoder’s implicit language model overwhelms the policy and, as such, generates a specific output regardless of the input (e.g., if it generates ’giraffe’, it may always output ’a giraffe standing in a field’, regardless of the image). In dialog modelling, this problem is observed in the output of dialog models finetuned with reinforcement learning (Lewis et al., 2017; Zhao et al., 2019). Using reinforcement learning to fine-tune a decoder, will likely place a strong emphasis on improving the decoder’s policy and un-learn the implicit language model of the decoder. To this end, Zhao et al. (2019) proposes Latent Action Reinforcement Learning which does not update the decoder during reinforcement learning. The methods proposed in this paper aim to mitigate these issues by explicitly modelling structure. Particularly interesting is that the structured models will reduce the effect of the overwhelming implicit language model by explicitly modelling the 2.1 2.2 Related Work Gener"
W19-5944,P17-1103,0,0.312983,"Missing"
W19-5944,W15-4640,0,0.0293006,"Missing"
W19-5944,W07-0734,0,0.153317,"for diversity evaluation. This paper is the first, to our knowledge, to create a large test set of several human-generated references for each context. We believe that it is also the first to perform human correlation studies on a variety of automatic metrics for both quality and diversity. Related work The need for reliable and consistent automatic evaluation methodologies has lead to increasing interest in dialog system evaluation in recent years. In domains such as machine translation and captioning, n-gram overlap metrics such as BLEU (Papineni et al., 2002), ROUGE (Lin, 2004) and METEOR (Lavie and Agarwal, 2007) correlate well with human judgement. Several embedding-based metrics have been proposed as well, including Greedy Matching (Rus and Lintean, 2012) and Vector Extrema (Forgues et al., 2014). These automatic metrics, however, do not generalize well to open-domain dialog due to the wide spectrum of correct responses, commonly known as the one-to-many problem (Zhao et al., 2017b). Recent work has proposed several trainable evaluation metrics to address this issue. RUBER (Tao et al., 2018) evaluates generated re1 Evaluating diversity in dialog model responses has been studied recently. The most co"
W19-5944,N16-1014,0,0.551515,"collect human annotations for evaluation, which can be expensive and time consuming. To demonstrate the effectiveness of multi-reference evaluation, we augment the test set of DailyDialog with multiple references. A series of experiments show that the use of multiple references results in improved correlation between several automatic metrics and human judgement for both the quality and the diversity of system output. 1 Table 1: Example of a dialog context where appropriate responses do not share words and meaning with a single-reference response. which is known as the dull-response problem (Li et al., 2016c). As a result, single-reference evaluations correlate weakly with human judgments of quality (Liu et al., 2016). To address these problems, this paper proposes to carry out automatic evaluation using multiple reference responses instead of a single-reference. Multiple reference evaluation is attractive for several reasons. First, the additional information in the multiple reference response can be used to provide more robust quality evaluation under the one-to-many condition. Second, we can use the multiple references to better measure the diversity of the model, which is a widely studied to"
W19-5944,P02-1040,0,0.10475,"evaluation and an examination of multiple references for diversity evaluation. This paper is the first, to our knowledge, to create a large test set of several human-generated references for each context. We believe that it is also the first to perform human correlation studies on a variety of automatic metrics for both quality and diversity. Related work The need for reliable and consistent automatic evaluation methodologies has lead to increasing interest in dialog system evaluation in recent years. In domains such as machine translation and captioning, n-gram overlap metrics such as BLEU (Papineni et al., 2002), ROUGE (Lin, 2004) and METEOR (Lavie and Agarwal, 2007) correlate well with human judgement. Several embedding-based metrics have been proposed as well, including Greedy Matching (Rus and Lintean, 2012) and Vector Extrema (Forgues et al., 2014). These automatic metrics, however, do not generalize well to open-domain dialog due to the wide spectrum of correct responses, commonly known as the one-to-many problem (Zhao et al., 2017b). Recent work has proposed several trainable evaluation metrics to address this issue. RUBER (Tao et al., 2018) evaluates generated re1 Evaluating diversity in dialo"
W19-5944,P16-1094,0,0.257136,"collect human annotations for evaluation, which can be expensive and time consuming. To demonstrate the effectiveness of multi-reference evaluation, we augment the test set of DailyDialog with multiple references. A series of experiments show that the use of multiple references results in improved correlation between several automatic metrics and human judgement for both the quality and the diversity of system output. 1 Table 1: Example of a dialog context where appropriate responses do not share words and meaning with a single-reference response. which is known as the dull-response problem (Li et al., 2016c). As a result, single-reference evaluations correlate weakly with human judgments of quality (Liu et al., 2016). To address these problems, this paper proposes to carry out automatic evaluation using multiple reference responses instead of a single-reference. Multiple reference evaluation is attractive for several reasons. First, the additional information in the multiple reference response can be used to provide more robust quality evaluation under the one-to-many condition. Second, we can use the multiple references to better measure the diversity of the model, which is a widely studied to"
W19-5944,W15-4915,0,0.0811064,"ce evaluation is attractive for several reasons. First, the additional information in the multiple reference response can be used to provide more robust quality evaluation under the one-to-many condition. Second, we can use the multiple references to better measure the diversity of the model, which is a widely studied topic in open-domain response generation (Kulikov et al., 2018; Li et al., 2016a; Zhang et al., 2018; Li et al., 2016b; Zhao et al., 2017a; Gao et al., 2019). Prior explorations in this area either rely on synthetically created or small scale reference sets (Galley et al., 2015; Qin and Specia, 2015), or perform experiments only on a small set of metrics focused on only response quality (Sugiyama et al., 2019). Our investigations for using multiple references for automatic evaluation covers the Introduction Dialog agents trained end-to-end to hold open-domain conversations have recently progressed rapidly, generating substantial interest (Ghazvininejad et al., 2018; Serban et al., 2017, 2016a; Sordoni et al., 2015; Vinyals and Le, 2015). Development of these systems is driven by available data and benchmarks based on only a single ground truth reference response for a given context. Howev"
W19-5944,D16-1127,0,0.229445,"collect human annotations for evaluation, which can be expensive and time consuming. To demonstrate the effectiveness of multi-reference evaluation, we augment the test set of DailyDialog with multiple references. A series of experiments show that the use of multiple references results in improved correlation between several automatic metrics and human judgement for both the quality and the diversity of system output. 1 Table 1: Example of a dialog context where appropriate responses do not share words and meaning with a single-reference response. which is known as the dull-response problem (Li et al., 2016c). As a result, single-reference evaluations correlate weakly with human judgments of quality (Liu et al., 2016). To address these problems, this paper proposes to carry out automatic evaluation using multiple reference responses instead of a single-reference. Multiple reference evaluation is attractive for several reasons. First, the additional information in the multiple reference response can be used to provide more robust quality evaluation under the one-to-many condition. Second, we can use the multiple references to better measure the diversity of the model, which is a widely studied to"
W19-5944,D11-1054,0,0.125707,"Missing"
W19-5944,I17-1099,0,0.0896937,"also disproportionately benefit models that produce generic responses with more probable words (e.g., “I don’t know”) 379 Proceedings of the SIGDial 2019 Conference, pages 379–391 c Stockholm, Sweden, 11-13 September 2019. 2019 Association for Computational Linguistics following aspects - 1) We propose methodology for evaluating both the quality and the diversity of generated responses using multiple references. 2) The proposed evaluation framework is metricagnostic and the experiments cover a large spectrum of existing metrics, and 3) We augmented the exiting test set of DailyDialog dataset (Li et al., 2017) with multiple references and perform human judgment correlation studies with humangenerated references. Our extensive experimental results show that using multiple test references leads to significantly better correlation of automated metrics with human judgment in terms of both response quality and diversity. This suggests that the use of multiple references serves to make automatic metrics more reliable mechanisms for evaluating open-domain dialog systems. Moreover, follow up studies are conducted to better understand the nature of the multi-reference evaluation, such as the number of refer"
W19-5944,W12-2018,0,0.138195,"t. We believe that it is also the first to perform human correlation studies on a variety of automatic metrics for both quality and diversity. Related work The need for reliable and consistent automatic evaluation methodologies has lead to increasing interest in dialog system evaluation in recent years. In domains such as machine translation and captioning, n-gram overlap metrics such as BLEU (Papineni et al., 2002), ROUGE (Lin, 2004) and METEOR (Lavie and Agarwal, 2007) correlate well with human judgement. Several embedding-based metrics have been proposed as well, including Greedy Matching (Rus and Lintean, 2012) and Vector Extrema (Forgues et al., 2014). These automatic metrics, however, do not generalize well to open-domain dialog due to the wide spectrum of correct responses, commonly known as the one-to-many problem (Zhao et al., 2017b). Recent work has proposed several trainable evaluation metrics to address this issue. RUBER (Tao et al., 2018) evaluates generated re1 Evaluating diversity in dialog model responses has been studied recently. The most commonly used metric is Distinct (Li et al., 2016a), which calculates the ratios of unique n-grams in generated responses. Distinct is, however, comp"
W19-5944,W04-1013,0,0.116266,"of multiple references for diversity evaluation. This paper is the first, to our knowledge, to create a large test set of several human-generated references for each context. We believe that it is also the first to perform human correlation studies on a variety of automatic metrics for both quality and diversity. Related work The need for reliable and consistent automatic evaluation methodologies has lead to increasing interest in dialog system evaluation in recent years. In domains such as machine translation and captioning, n-gram overlap metrics such as BLEU (Papineni et al., 2002), ROUGE (Lin, 2004) and METEOR (Lavie and Agarwal, 2007) correlate well with human judgement. Several embedding-based metrics have been proposed as well, including Greedy Matching (Rus and Lintean, 2012) and Vector Extrema (Forgues et al., 2014). These automatic metrics, however, do not generalize well to open-domain dialog due to the wide spectrum of correct responses, commonly known as the one-to-many problem (Zhao et al., 2017b). Recent work has proposed several trainable evaluation metrics to address this issue. RUBER (Tao et al., 2018) evaluates generated re1 Evaluating diversity in dialog model responses h"
W19-5944,P17-1061,1,0.116349,"address these problems, this paper proposes to carry out automatic evaluation using multiple reference responses instead of a single-reference. Multiple reference evaluation is attractive for several reasons. First, the additional information in the multiple reference response can be used to provide more robust quality evaluation under the one-to-many condition. Second, we can use the multiple references to better measure the diversity of the model, which is a widely studied topic in open-domain response generation (Kulikov et al., 2018; Li et al., 2016a; Zhang et al., 2018; Li et al., 2016b; Zhao et al., 2017a; Gao et al., 2019). Prior explorations in this area either rely on synthetically created or small scale reference sets (Galley et al., 2015; Qin and Specia, 2015), or perform experiments only on a small set of metrics focused on only response quality (Sugiyama et al., 2019). Our investigations for using multiple references for automatic evaluation covers the Introduction Dialog agents trained end-to-end to hold open-domain conversations have recently progressed rapidly, generating substantial interest (Ghazvininejad et al., 2018; Serban et al., 2017, 2016a; Sordoni et al., 2015; Vinyals and"
W19-5944,N15-1020,0,0.192498,"i et al., 2016b; Zhao et al., 2017a; Gao et al., 2019). Prior explorations in this area either rely on synthetically created or small scale reference sets (Galley et al., 2015; Qin and Specia, 2015), or perform experiments only on a small set of metrics focused on only response quality (Sugiyama et al., 2019). Our investigations for using multiple references for automatic evaluation covers the Introduction Dialog agents trained end-to-end to hold open-domain conversations have recently progressed rapidly, generating substantial interest (Ghazvininejad et al., 2018; Serban et al., 2017, 2016a; Sordoni et al., 2015; Vinyals and Le, 2015). Development of these systems is driven by available data and benchmarks based on only a single ground truth reference response for a given context. However, such single-reference evaluation does not account for all the plausible responses for any given conversational context (Table 1). This is known as the one-to-many response problem (Zhao et al., 2017a). Computing word-overlap metrics against a single-reference response may penalize perfectly valid responses (Deriu et al., 2019) (e.g., “Was anything stolen?”, “Is anyone hurt”) that deviate from the particular target"
W19-5944,N18-1188,0,0.0309466,"en-domain dialog due to the wide spectrum of correct responses, commonly known as the one-to-many problem (Zhao et al., 2017b). Recent work has proposed several trainable evaluation metrics to address this issue. RUBER (Tao et al., 2018) evaluates generated re1 Evaluating diversity in dialog model responses has been studied recently. The most commonly used metric is Distinct (Li et al., 2016a), which calculates the ratios of unique n-grams in generated responses. Distinct is, however, computed across contexts and does not measure if a model can generate multiple valid responses for a context. Xu et al. (2018) proposed Mean Diversity Score (MDS) and Probabilistic Diversity Score (PDS) metrics for diversity evaluation over groups https://github.com/prakharguptaz/multirefeval 380 and then averaged over all contexts. A lower SelfBLEU implies greater diversity since system outputs are not similar to one another. of multiple references over a set of retrieved references. Hashimoto et al. (2019) proposed a metric for a unified evaluation of quality and diversity of outputs, which however depends on human judgements. Zhao et al. (2017a) proposed precision/recall metrics calculated using multiple hypothese"
W19-5944,2015.eamt-1.16,0,\N,Missing
W19-5944,D16-1230,0,\N,Missing
W19-5944,N19-1169,0,\N,Missing
W19-5944,K16-1002,0,\N,Missing
