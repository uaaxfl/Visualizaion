2020.bucc-1.4,P17-1042,0,0.0190009,". 6 https://www.gsk.or.jp/catalog/gsk2010-a/ We eliminated the compound words from the dictionary. 23 Figure 1: Tree Structure of Iwanami Kokugo Jiten Table 2: Concept-tags and Their Corresponding Class, Division, Section of “子供 (child or children) ”from WLSP Concept number Class Division Section Article 1.2050 Nominal words Agent Human Young or old 1.2130 Nominal words Agent Family Child or descendant linear projection matrix W was learned when we used a linear transformation matrix. VecMap is an implementation of a framework of Artetxe et al. to learn cross-lingual word embedding mappings (Artetxe et al., 2017)(Artetxe et al., 2018a)(Artetxe et al., 2018b). 1. Generate a word-sense-tag and concept-tag corpora respectively, and learn word-sense or concept embeddings for each corpus from them using word2vec 7 (Mikolov et al., 2013a; Mikolov et al., 2013c; Mikolov et al., 2013d) (cf. Figure 3). 4. Experiment 2. Learn a linear projection matrix W from the vector space of the word-senses to that of the concepts using pairs of the embeddings for monosemous common nouns, which are generated in the last step. 4.1. Experimental Setting We utilized BCCWJ tagged with word senses of Iwanami Kokugo Jiten and BCC"
2020.bucc-1.4,P18-1073,0,0.0207769,"r.jp/catalog/gsk2010-a/ We eliminated the compound words from the dictionary. 23 Figure 1: Tree Structure of Iwanami Kokugo Jiten Table 2: Concept-tags and Their Corresponding Class, Division, Section of “子供 (child or children) ”from WLSP Concept number Class Division Section Article 1.2050 Nominal words Agent Human Young or old 1.2130 Nominal words Agent Family Child or descendant linear projection matrix W was learned when we used a linear transformation matrix. VecMap is an implementation of a framework of Artetxe et al. to learn cross-lingual word embedding mappings (Artetxe et al., 2017)(Artetxe et al., 2018a)(Artetxe et al., 2018b). 1. Generate a word-sense-tag and concept-tag corpora respectively, and learn word-sense or concept embeddings for each corpus from them using word2vec 7 (Mikolov et al., 2013a; Mikolov et al., 2013c; Mikolov et al., 2013d) (cf. Figure 3). 4. Experiment 2. Learn a linear projection matrix W from the vector space of the word-senses to that of the concepts using pairs of the embeddings for monosemous common nouns, which are generated in the last step. 4.1. Experimental Setting We utilized BCCWJ tagged with word senses of Iwanami Kokugo Jiten and BCCWJ tagged with concep"
2020.bucc-1.4,P14-1006,0,0.0122899,"ed in the source language corpus into the target language using Wiktionary. Then they filtered out the noises of these pairs and trained the model with this corpus in which these pairs are replaced with placeholders to ensure that translations of the same word have the same vector representation. Third approach is cross-lingual training. These approaches train their embeddings on a parallel corpus and optimize a cross-lingual constraint between embeddings of different languages that encourages embeddings of similar words to be close to each other in a shared vector space. Hermann and Blunsom (Hermann and Blunsom, 2014) trained two models to output sentence embeddings for input sentences in two different languages. They retrained these models with sentence embeddings using a least-squares method. Final approach is joint optimization. They not only consider a cross-lingual constraint, but also jointly optimize mono-lingual and cross-lingual objectives. Klementiev et al. (Klementiev et al., 2012) was the first research using joint optimization. Zou (Zou et al., 2013) used a matrix factorization approach to learn cross-lingual word representations for English and Chinese and utilized the representaRecently, cor"
2020.bucc-1.4,C12-1089,0,0.0364516,"parallel corpus and optimize a cross-lingual constraint between embeddings of different languages that encourages embeddings of similar words to be close to each other in a shared vector space. Hermann and Blunsom (Hermann and Blunsom, 2014) trained two models to output sentence embeddings for input sentences in two different languages. They retrained these models with sentence embeddings using a least-squares method. Final approach is joint optimization. They not only consider a cross-lingual constraint, but also jointly optimize mono-lingual and cross-lingual objectives. Klementiev et al. (Klementiev et al., 2012) was the first research using joint optimization. Zou (Zou et al., 2013) used a matrix factorization approach to learn cross-lingual word representations for English and Chinese and utilized the representaRecently, corpora that have tags from more than one tag set are increasing. For example, “ The Balanced Corpus of Contemporary Written Japanese ”(BCCWJ) (Maekawa et al., 2014) is tagged with concept tags from “ Word List by Semantic Principles ” (WLSP) (National Institute for Japanese Language and Linguistics, 1964) after tagged with sense tags from“ Iwanami Kokugo Jiten (Nishio et al., 1994)"
2020.bucc-1.4,N13-1090,0,0.0170422,"of “子供 (child or children) ”from WLSP Concept number Class Division Section Article 1.2050 Nominal words Agent Human Young or old 1.2130 Nominal words Agent Family Child or descendant linear projection matrix W was learned when we used a linear transformation matrix. VecMap is an implementation of a framework of Artetxe et al. to learn cross-lingual word embedding mappings (Artetxe et al., 2017)(Artetxe et al., 2018a)(Artetxe et al., 2018b). 1. Generate a word-sense-tag and concept-tag corpora respectively, and learn word-sense or concept embeddings for each corpus from them using word2vec 7 (Mikolov et al., 2013a; Mikolov et al., 2013c; Mikolov et al., 2013d) (cf. Figure 3). 4. Experiment 2. Learn a linear projection matrix W from the vector space of the word-senses to that of the concepts using pairs of the embeddings for monosemous common nouns, which are generated in the last step. 4.1. Experimental Setting We utilized BCCWJ tagged with word senses of Iwanami Kokugo Jiten and BCCWJ tagged with concepts of WLSP. Table 3 shows the number of word tokens, unique words, unique word senses, and unique concepts. 3. Apply the matrix W to the word-sense embeddings and obtain the projected concept embedding"
2020.bucc-1.4,W14-1613,0,0.01155,"ation method needs two tagged corpora. Keywords: Bilingual Word Embedding, Concept Embeddings, Word Embeddings, Dictionary 1. Introduction 2013b) have shown that vector spaces can encode meaningful relations between words and that the geometric relations that hold between words are similar across languages. Because they do not assume the use of specific language, their method can be used to extend and refine dictionaries for any language pairs. Second approach is pseudo-cross-lingual. These approaches create a pseudocross-lingual corpus by mixing contexts of different languages. Xiao and Guo (Xiao and Guo, 2014) proposed the first pseudo-cross-lingual method that utilized translation pairs. They first translated all words that appeared in the source language corpus into the target language using Wiktionary. Then they filtered out the noises of these pairs and trained the model with this corpus in which these pairs are replaced with placeholders to ensure that translations of the same word have the same vector representation. Third approach is cross-lingual training. These approaches train their embeddings on a parallel corpus and optimize a cross-lingual constraint between embeddings of different lan"
2020.bucc-1.4,D13-1141,0,0.0411079,"different languages that encourages embeddings of similar words to be close to each other in a shared vector space. Hermann and Blunsom (Hermann and Blunsom, 2014) trained two models to output sentence embeddings for input sentences in two different languages. They retrained these models with sentence embeddings using a least-squares method. Final approach is joint optimization. They not only consider a cross-lingual constraint, but also jointly optimize mono-lingual and cross-lingual objectives. Klementiev et al. (Klementiev et al., 2012) was the first research using joint optimization. Zou (Zou et al., 2013) used a matrix factorization approach to learn cross-lingual word representations for English and Chinese and utilized the representaRecently, corpora that have tags from more than one tag set are increasing. For example, “ The Balanced Corpus of Contemporary Written Japanese ”(BCCWJ) (Maekawa et al., 2014) is tagged with concept tags from “ Word List by Semantic Principles ” (WLSP) (National Institute for Japanese Language and Linguistics, 1964) after tagged with sense tags from“ Iwanami Kokugo Jiten (Nishio et al., 1994). ” Because these tags are tagged referring to different dictionaries, t"
2020.findings-emnlp.121,O14-4001,1,0.877406,"Missing"
2020.findings-emnlp.121,Q14-1022,0,0.153812,"pus, a series of temporal competitions (TempEval-1,2,3) (Verhagen et al., 2009, 2010; UzZaman et al., 2012) are attracting growing research efforts. Temporal relation classification (TRC) is the task to predict a temporal relation (after, before, includes, etc.) of a TLINK from a source mention to a target mention. Less effort has been paid to explore the sharing information across ‘local’ pairs and TLINK categories. In recent years, a variety of dense annotation schemas are proposed to overcome the ‘sparse’ annotation in the original Timebank. A typical one is the Timebank-Dense (TD) corpus (Chambers et al., 2014), which performs We demonstrate our proposal with the above adjacent-sentence excerpt in Timebank-Dense. ‘(es , et )’ denotes a directed TLINK from the source es to target et in this paper. Considering the ‘manhunt (e1 )’ centric chain: {(e1 , DCT ), (e1 , e2 ), (e1 , t1 ), (e1 , e3 )}2 , ‘manhunt’ holds a ‘includes’ relation to ‘continues’. 1 Time-to-Time (T2T) is not included in this paper, as we focus on event centric representations. 2 As DCT is not explicitly mentioned in documents, we always place (ei , DCT ) on the top of a SECT chain DCT : 1998-02-27 An intense manhunt (e1 ) conducted"
2020.findings-emnlp.121,P17-2001,1,0.932839,"TLINKs. 2) Our model exploits a multi-task learning framework with two common layers trained by a combined category-specific loss to overcome the data isolation among TLINK categories. The experimental results suggest the effectiveness of our proposal on two datasets. All the codes of our model and two baselines is released. 3 2 2.1 Related Work Temporal Relation Classification Most existing temporal relation classification approaches focus on extracting various features from the textual sentence in the local pair-wise setting. Inspired by the success of neural networks in various NLP tasks, Cheng and Miyao (2017); Meng et al. (2017); Vashishtha et al. (2019); Han et al. (2019b,a) propose a series of neural networks to achieve accuracy with less feature engineering. However, these neural models still drop in the pairwise setting. Meng and Rumshisky (2018) propose a global context layer (GCL) to store/read the solved TLINK history upon a pre-trained pair-wise classifier. However, they find slow converge when training the GCL and pair-wise classifier simultaneously. Minor improvement is observed compared to their pair-wise classifier. Our model is distinguished from their work in three focuses: 1) We con"
2020.findings-emnlp.121,N19-1423,0,0.0726018,"ings of the Association for Computational Linguistics: EMNLP 2020, pages 1352–1357 c November 16 - 20, 2020. 2020 Association for Computational Linguistics We assume that dynamically updating the representation of ‘manhunt’ in the early step ‘(e1 , e2 )’ will benefit the prediction for the later step (e1 , e3 ) to ‘search’. ‘manhunt’ is supposed to hold the same ‘includes’ relation to ‘search’, as the search should be included in the continuing manhunt. Our model further exploits a multi-task learning framework to leverage all three categories of TLINKs in the SECT chain scope. A common BERT (Devlin et al., 2019) encoder layer is applied to retrieve token embeddings. The global RNN layer manages the dynamic event and TLINK presentations in the chain. Finally, our system feeds the TLINK representations into their corresponding category-specific (E2D, E2T and E2E) classifiers to calculate a combined loss. The contribution of this work is listed as follows: 1) We present a novel source event centric model to dynamically manage event representations across TLINKs. 2) Our model exploits a multi-task learning framework with two common layers trained by a combined category-specific loss to overcome the data"
2020.findings-emnlp.121,K19-1062,0,0.0164696,"o common layers trained by a combined category-specific loss to overcome the data isolation among TLINK categories. The experimental results suggest the effectiveness of our proposal on two datasets. All the codes of our model and two baselines is released. 3 2 2.1 Related Work Temporal Relation Classification Most existing temporal relation classification approaches focus on extracting various features from the textual sentence in the local pair-wise setting. Inspired by the success of neural networks in various NLP tasks, Cheng and Miyao (2017); Meng et al. (2017); Vashishtha et al. (2019); Han et al. (2019b,a) propose a series of neural networks to achieve accuracy with less feature engineering. However, these neural models still drop in the pairwise setting. Meng and Rumshisky (2018) propose a global context layer (GCL) to store/read the solved TLINK history upon a pre-trained pair-wise classifier. However, they find slow converge when training the GCL and pair-wise classifier simultaneously. Minor improvement is observed compared to their pair-wise classifier. Our model is distinguished from their work in three focuses: 1) We constrains the model in a reasonable scope, i.e. 3 https://github.c"
2020.findings-emnlp.121,D19-1041,0,0.119089,"Missing"
2020.findings-emnlp.121,P19-1441,0,0.105091,"random/ NeuralTime Figure 1: The overview of the proposed model. SECT chain. 2) We manages dynamic event representations, while their model stores/reads pair history 3) Our model integrates category-specific classifiers by multi-task learning, while they use the categories as the features in one single classifier. 2.2 Multi-task Transfer Learning For the past three years, several successful transfer learning models (ELMO, GPT and BERT) (Peters et al., 2018; Radford et al.; Devlin et al., 2019) have been proposed, which significantly improved the state-of-the-art on a wide range of NLP tasks. (Liu et al., 2019) propose a single-task batch multitask learning approach over a common BERT to leverage a large mount of cross-task data in the fine-tuning stage. In this work, our model deals with various categories of TLINKs (E2E, E2T and E2D) in a batch of SECT chains to calculate the combined loss with the category-specific classifiers. 2.3 Non-English Temporal Corpora Less attention has been paid for non-English temporal corpora. Until 2014, Asahara et al. starts the first corpus-based study BCCWJ-Timebank (BT) on Japanese temporal information annotation. We explore the feasibility of our model on this J"
2020.findings-emnlp.121,P18-1049,0,0.620441,"proposal on two datasets. All the codes of our model and two baselines is released. 3 2 2.1 Related Work Temporal Relation Classification Most existing temporal relation classification approaches focus on extracting various features from the textual sentence in the local pair-wise setting. Inspired by the success of neural networks in various NLP tasks, Cheng and Miyao (2017); Meng et al. (2017); Vashishtha et al. (2019); Han et al. (2019b,a) propose a series of neural networks to achieve accuracy with less feature engineering. However, these neural models still drop in the pairwise setting. Meng and Rumshisky (2018) propose a global context layer (GCL) to store/read the solved TLINK history upon a pre-trained pair-wise classifier. However, they find slow converge when training the GCL and pair-wise classifier simultaneously. Minor improvement is observed compared to their pair-wise classifier. Our model is distinguished from their work in three focuses: 1) We constrains the model in a reasonable scope, i.e. 3 https://github.com/racerandom/ NeuralTime Figure 1: The overview of the proposed model. SECT chain. 2) We manages dynamic event representations, while their model stores/reads pair history 3) Our mo"
2020.findings-emnlp.121,D17-1092,0,0.279835,"ploits a multi-task learning framework with two common layers trained by a combined category-specific loss to overcome the data isolation among TLINK categories. The experimental results suggest the effectiveness of our proposal on two datasets. All the codes of our model and two baselines is released. 3 2 2.1 Related Work Temporal Relation Classification Most existing temporal relation classification approaches focus on extracting various features from the textual sentence in the local pair-wise setting. Inspired by the success of neural networks in various NLP tasks, Cheng and Miyao (2017); Meng et al. (2017); Vashishtha et al. (2019); Han et al. (2019b,a) propose a series of neural networks to achieve accuracy with less feature engineering. However, these neural models still drop in the pairwise setting. Meng and Rumshisky (2018) propose a global context layer (GCL) to store/read the solved TLINK history upon a pre-trained pair-wise classifier. However, they find slow converge when training the GCL and pair-wise classifier simultaneously. Minor improvement is observed compared to their pair-wise classifier. Our model is distinguished from their work in three focuses: 1) We constrains the model in"
2020.findings-emnlp.121,C16-1265,0,0.0242799,"ation micro F1 of all TLINKs against the training epochs of the above asynchronous training strategies. no freeze shows the evidence of our concern that the curve undulate after the initial 3 epochs. freeze performs a stable learning phase with the lowest initialization. freeze after k epochs achieves the balance of the stability and high F1. Therefore, we perform the third strategy for all the following experiments. The number k is selected from {3, 4, 5} based on the validation scores. 4.2 Main Timebank-Dense Results Table 2 shows the experimental results on the English TD corpus. ‘CATENA’ (Mirza and Tonelli, 2016) is the feature-based model combined with dense word embeddings. ‘SDP-RNN’ (Cheng and Miyao, 2017) is the dependency tree enhanced RNN model.‘GCL’ (Meng and Rumshisky, 2018) is the global context layer model introduced in § 2.1. ‘Fine-grained TRC’ Vashishtha et al. (2019) is the ELMO based fine-grained TRC model with only the E2E results reported. It’s not surprising that the proposed model substantially outperforms state-of-the-art systems, as the existing SOTA didn’t exploit BERT yet. Therefore, we offer the ablation test with ‘LocalBERT’(w/o multi-categories learning and global SEC RNN) and"
2020.findings-emnlp.121,N18-1202,0,0.0494105,"-wise classifier. Our model is distinguished from their work in three focuses: 1) We constrains the model in a reasonable scope, i.e. 3 https://github.com/racerandom/ NeuralTime Figure 1: The overview of the proposed model. SECT chain. 2) We manages dynamic event representations, while their model stores/reads pair history 3) Our model integrates category-specific classifiers by multi-task learning, while they use the categories as the features in one single classifier. 2.2 Multi-task Transfer Learning For the past three years, several successful transfer learning models (ELMO, GPT and BERT) (Peters et al., 2018; Radford et al.; Devlin et al., 2019) have been proposed, which significantly improved the state-of-the-art on a wide range of NLP tasks. (Liu et al., 2019) propose a single-task batch multitask learning approach over a common BERT to leverage a large mount of cross-task data in the fine-tuning stage. In this work, our model deals with various categories of TLINKs (E2E, E2T and E2D) in a batch of SECT chains to calculate the combined loss with the category-specific classifiers. 2.3 Non-English Temporal Corpora Less attention has been paid for non-English temporal corpora. Until 2014, Asahara"
2020.findings-emnlp.121,D18-2010,1,0.731125,"Missing"
2020.findings-emnlp.121,P19-1280,0,0.0435049,"Missing"
2020.lrec-1.24,K18-1030,0,0.0166441,"employed as computational models of human language processing and evaluated against human behavioral data such as self-paced reading (Roark et al., 2009; Frank et al., 2013) and eye-tracking (Frank and Bod, 2011; Fossum and Levy, 2012). In contrast, for the cognitive science → NLP direction, human behavioral data, especially eyetracking, have been used to train engineering models and improve performance in part-of-speech tagging (Barrett et al., 2016), sentiment analysis (Mishra et al., 2016), named entity recognition (Hollenstein and Zhang, 2019), and attention in artificial neural networks (Barrett et al., 2018). Moreover, given the historical relationship between biological and artificial neural networks (Amari, 1967; Fukushima, 1980), the advent of deep learning has resparked strong interests in the fusion of NLP and the neuroscience of language. For example, neuro-computational models of human language processing have been constructed based on symbolic automata and neural networks and evaluated against human neural data such as electroencephalography (EEG) (Frank et al., 2015; Brennan and Hale, 2019), functional resonance magnetic imaging (fMRI) (Brennan et al., 2016; Henderson et al., 2016), magn"
2020.lrec-1.24,N06-1038,0,0.0103589,"sists of the first chapter of the English story Alice’s Adventures in Wonderland read by Kristen McQuillan experimentally annotated with EEG data collected from 52 participants. This corpus was also annotated with fMRI data on the same chapter of the story collected from 29 participants (Brennan et al., 2016). Zurich Cognitive Language Processing Corpus (ZuCo): The Zurich Cognitive Language Processing Corpus (ZuCo) (Hollenstein et al., 2018) consists of about 1000 English independent sentences from the Stanford Sentiment Treebank (Socher et al., 2013) and Wikipedia relation extraction corpus (Culotta et al., 2006) experimentally annotated with simultaneously recorded EEG and eye-tracking data collected from 12 participants. 190 2.3. 3. BCCWJ BCCWJ: The Balanced Corpus of Contemporary Written Japanese (BCCWJ) (Maekawa et al., 2014) is the balanced corpus composed of 100 million Japanese words randomly sampled from various text genres including books, textbooks, magazines, newspapers, blogs, minutes, newsletters, laws, posts, etc. Importantly, BCCWJ is originally annotated with rich linguistic information including partof-speech, document structure, meta-information, and subsequently expanded with depend"
2020.lrec-1.24,W12-1706,0,0.0612962,"cience and NLP will also be discussed. Keywords: Balanced Corpus of Contemporary Written Japanese, Electroencephalography, Cognitive Modeling 1. Introduction The past decade has witnessed the happy marriage between natural language processing (NLP) and the cognitive science of language. For the NLP → cognitive science direction, engineering models originally proposed in NLP have been employed as computational models of human language processing and evaluated against human behavioral data such as self-paced reading (Roark et al., 2009; Frank et al., 2013) and eye-tracking (Frank and Bod, 2011; Fossum and Levy, 2012). In contrast, for the cognitive science → NLP direction, human behavioral data, especially eyetracking, have been used to train engineering models and improve performance in part-of-speech tagging (Barrett et al., 2016), sentiment analysis (Mishra et al., 2016), named entity recognition (Hollenstein and Zhang, 2019), and attention in artificial neural networks (Barrett et al., 2018). Moreover, given the historical relationship between biological and artificial neural networks (Amari, 1967; Fukushima, 1980), the advent of deep learning has resparked strong interests in the fusion of NLP and th"
2020.lrec-1.24,L18-1012,0,0.0196481,"age processing (Demberg and Keller, 2008; Mitchell et al., 2010; Frank and Bod, 2011; Fossum and Levy, 2012). Potsdam Sentence Corpus: The Potsdam Sentence Corpus (Kliegl et al., 2006) is another famous eye-tracking corpus composed of 144 German independent sentences manually edited to contain low-frequency syntactic constructions and experimentally annotated with eye-tracking data collected from 222 participants. This corpus was used to investigate human language processing with dependency parsing (Boston et al., 2008; Boston et al., 2011). Natural Stories Corpus: The Natural Stories Corpus (Futrell et al., 2018) is not the eye-tracking corpus per se but, like the Potsdam Sentence Corpus (Kliegl et al., 2006), comprised of 10 English stories manually edited to con1 tain low-frequency syntactic constructions and experimentally annotated with self-paced reading data collected from 19 participants. This corpus was also annotated with fMRI data collected from 78 participants (Shain et al., 2019). Ghent Eye-Tracking Corpus (GECO): The Ghent EyeTracking Corpus (GECO) (Cop et al., 2017) consists of the English novel The Mysterious Affair at Styles by Agatha Christie experimentally annotated with eye-tracking"
2020.lrec-1.24,N19-1001,0,0.0108514,"science direction, engineering models originally proposed in NLP have been employed as computational models of human language processing and evaluated against human behavioral data such as self-paced reading (Roark et al., 2009; Frank et al., 2013) and eye-tracking (Frank and Bod, 2011; Fossum and Levy, 2012). In contrast, for the cognitive science → NLP direction, human behavioral data, especially eyetracking, have been used to train engineering models and improve performance in part-of-speech tagging (Barrett et al., 2016), sentiment analysis (Mishra et al., 2016), named entity recognition (Hollenstein and Zhang, 2019), and attention in artificial neural networks (Barrett et al., 2018). Moreover, given the historical relationship between biological and artificial neural networks (Amari, 1967; Fukushima, 1980), the advent of deep learning has resparked strong interests in the fusion of NLP and the neuroscience of language. For example, neuro-computational models of human language processing have been constructed based on symbolic automata and neural networks and evaluated against human neural data such as electroencephalography (EEG) (Frank et al., 2015; Brennan and Hale, 2019), functional resonance magnetic"
2020.lrec-1.24,Y18-1029,1,0.792871,"WJ) (Maekawa et al., 2014) is the balanced corpus composed of 100 million Japanese words randomly sampled from various text genres including books, textbooks, magazines, newspapers, blogs, minutes, newsletters, laws, posts, etc. Importantly, BCCWJ is originally annotated with rich linguistic information including partof-speech, document structure, meta-information, and subsequently expanded with dependency tree structure (Asahara and Matsumoto, 2016), predicate argument structure (Takeuchi et al., 2015), temporal and event information (Asahara et al., 2013), syntactic and semantic categories (Kato et al., 2018), information structure (Miyauchi et al., 2018), clause classification (Matsumoto et al., 2018), universal dependencies (Omura and Asahara, 2018), etc. BCCWJ-EyeTrack: The BCCWJ-EyeTrack (Asahara et al., 2016) is the eye-tracking corpus, like the Dundee Corpus (Kennedy and Pynte, 2005), composed of 20 Japanese newspaper articles selected from BCCWJ (Maekawa et al., 2014) experimentally annotated with eye-tracking and selfpaced reading data collected from 24 participants. BCCWJ-EEG: The BCCWJ-EEG is the EEG corpus designed in this paper and composed of the same set of 20 Japanese newspaper arti"
2020.lrec-1.24,K16-1016,0,0.0146357,"ve science of language. For the NLP → cognitive science direction, engineering models originally proposed in NLP have been employed as computational models of human language processing and evaluated against human behavioral data such as self-paced reading (Roark et al., 2009; Frank et al., 2013) and eye-tracking (Frank and Bod, 2011; Fossum and Levy, 2012). In contrast, for the cognitive science → NLP direction, human behavioral data, especially eyetracking, have been used to train engineering models and improve performance in part-of-speech tagging (Barrett et al., 2016), sentiment analysis (Mishra et al., 2016), named entity recognition (Hollenstein and Zhang, 2019), and attention in artificial neural networks (Barrett et al., 2018). Moreover, given the historical relationship between biological and artificial neural networks (Amari, 1967; Fukushima, 1980), the advent of deep learning has resparked strong interests in the fusion of NLP and the neuroscience of language. For example, neuro-computational models of human language processing have been constructed based on symbolic automata and neural networks and evaluated against human neural data such as electroencephalography (EEG) (Frank et al., 2015"
2020.lrec-1.24,P10-1021,0,0.0184604,", the Balanced Corpus of Contemporary Written Japanese (BCCWJ) is introduced in combination with rich linguistic information already annotated on BCCWJ. Those language resources are summarized in Table 1. 2.1. Eye-tracking Dundee Corpus: The Dundee Corpus (Kennedy and Pynte, 2005) is the famous eye-tracking corpus composed of 20 English newspaper articles experimentally annotated with eye-tracking data collected from 10 English and 10 French participants. This corpus has been widely used in the literature to evaluate computational models of human language processing (Demberg and Keller, 2008; Mitchell et al., 2010; Frank and Bod, 2011; Fossum and Levy, 2012). Potsdam Sentence Corpus: The Potsdam Sentence Corpus (Kliegl et al., 2006) is another famous eye-tracking corpus composed of 144 German independent sentences manually edited to contain low-frequency syntactic constructions and experimentally annotated with eye-tracking data collected from 222 participants. This corpus was used to investigate human language processing with dependency parsing (Boston et al., 2008; Boston et al., 2011). Natural Stories Corpus: The Natural Stories Corpus (Futrell et al., 2018) is not the eye-tracking corpus per se but"
2020.lrec-1.24,W18-6014,1,0.832161,"corpus composed of 100 million Japanese words randomly sampled from various text genres including books, textbooks, magazines, newspapers, blogs, minutes, newsletters, laws, posts, etc. Importantly, BCCWJ is originally annotated with rich linguistic information including partof-speech, document structure, meta-information, and subsequently expanded with dependency tree structure (Asahara and Matsumoto, 2016), predicate argument structure (Takeuchi et al., 2015), temporal and event information (Asahara et al., 2013), syntactic and semantic categories (Kato et al., 2018), information structure (Miyauchi et al., 2018), clause classification (Matsumoto et al., 2018), universal dependencies (Omura and Asahara, 2018), etc. BCCWJ-EyeTrack: The BCCWJ-EyeTrack (Asahara et al., 2016) is the eye-tracking corpus, like the Dundee Corpus (Kennedy and Pynte, 2005), composed of 20 Japanese newspaper articles selected from BCCWJ (Maekawa et al., 2014) experimentally annotated with eye-tracking and selfpaced reading data collected from 24 participants. BCCWJ-EEG: The BCCWJ-EEG is the EEG corpus designed in this paper and composed of the same set of 20 Japanese newspaper articles experimentally annotated with EEG data col"
2020.lrec-1.24,D09-1034,0,0.0132605,"ompilation schedule. In addition, potential applications of BCCWJ-EEG to neuroscience and NLP will also be discussed. Keywords: Balanced Corpus of Contemporary Written Japanese, Electroencephalography, Cognitive Modeling 1. Introduction The past decade has witnessed the happy marriage between natural language processing (NLP) and the cognitive science of language. For the NLP → cognitive science direction, engineering models originally proposed in NLP have been employed as computational models of human language processing and evaluated against human behavioral data such as self-paced reading (Roark et al., 2009; Frank et al., 2013) and eye-tracking (Frank and Bod, 2011; Fossum and Levy, 2012). In contrast, for the cognitive science → NLP direction, human behavioral data, especially eyetracking, have been used to train engineering models and improve performance in part-of-speech tagging (Barrett et al., 2016), sentiment analysis (Mishra et al., 2016), named entity recognition (Hollenstein and Zhang, 2019), and attention in artificial neural networks (Barrett et al., 2018). Moreover, given the historical relationship between biological and artificial neural networks (Amari, 1967; Fukushima, 1980), the"
2020.lrec-1.24,D13-1170,0,0.00303849,"3). Alice Corpus: The Alice Corpus (Brennan and Hale, 2019) consists of the first chapter of the English story Alice’s Adventures in Wonderland read by Kristen McQuillan experimentally annotated with EEG data collected from 52 participants. This corpus was also annotated with fMRI data on the same chapter of the story collected from 29 participants (Brennan et al., 2016). Zurich Cognitive Language Processing Corpus (ZuCo): The Zurich Cognitive Language Processing Corpus (ZuCo) (Hollenstein et al., 2018) consists of about 1000 English independent sentences from the Stanford Sentiment Treebank (Socher et al., 2013) and Wikipedia relation extraction corpus (Culotta et al., 2006) experimentally annotated with simultaneously recorded EEG and eye-tracking data collected from 12 participants. 190 2.3. 3. BCCWJ BCCWJ: The Balanced Corpus of Contemporary Written Japanese (BCCWJ) (Maekawa et al., 2014) is the balanced corpus composed of 100 million Japanese words randomly sampled from various text genres including books, textbooks, magazines, newspapers, blogs, minutes, newsletters, laws, posts, etc. Importantly, BCCWJ is originally annotated with rich linguistic information including partof-speech, document st"
2020.paclic-1.15,S01-1001,0,0.215622,"a number of tasks, such as machine translation and text summarization. Word embeddings are usually generated using text corpora. It is possible to generate concept embeddings by the same method used to generate word embeddings if the word sequence (i.e., text corpus) is replaced with a concept sequence constructed from a concept-tagged corpus. However, it is difficult to obtain a sufficiently large concept-tagged corpus because the annotation of concept tags is time-consuming. There have been several studies that assigned word senses using the all-words word sense disambiguation (WSD) method (Edmonds and Cotton, 2001), (Snyder and Palmer, 2004), (Navigli et al., 2007), (Iacobacci et al., 2016), (Raganato et al., 2017a), (Raganato et al., 2017b), (Suzuki et al., 2018), (Shinnou et al., 2018). As a result, it is possible to create a concept-tagged corpus using the methods proposed in these studies. However, the results of all-words WSD systems are not always correct; therefore, an automatically tagged corpus created via all-words WSD may not be suitable for generating concept embeddings. In this paper, we generate concept embeddings of Word List by Semantic Principles (WLSP) (National Institute for Japanese"
2020.paclic-1.15,P16-1085,0,0.0226331,"eddings are usually generated using text corpora. It is possible to generate concept embeddings by the same method used to generate word embeddings if the word sequence (i.e., text corpus) is replaced with a concept sequence constructed from a concept-tagged corpus. However, it is difficult to obtain a sufficiently large concept-tagged corpus because the annotation of concept tags is time-consuming. There have been several studies that assigned word senses using the all-words word sense disambiguation (WSD) method (Edmonds and Cotton, 2001), (Snyder and Palmer, 2004), (Navigli et al., 2007), (Iacobacci et al., 2016), (Raganato et al., 2017a), (Raganato et al., 2017b), (Suzuki et al., 2018), (Shinnou et al., 2018). As a result, it is possible to create a concept-tagged corpus using the methods proposed in these studies. However, the results of all-words WSD systems are not always correct; therefore, an automatically tagged corpus created via all-words WSD may not be suitable for generating concept embeddings. In this paper, we generate concept embeddings of Word List by Semantic Principles (WLSP) (National Institute for Japanese Language and Linguistics, 1964), a Japanese thesaurus, from manually and auto"
2020.paclic-1.15,Y18-1029,1,0.877379,"Missing"
2020.paclic-1.15,N13-1090,0,0.00598347,", with the concept tag annotation via the all-words WSD system. The manual corpus is the part of the core data with manual annotation of the concept tags, which includes approximately 340,000 words. Examples of the text corpus and a generated concept sequence are presented in Table 2. In the table, an original Japanese text, its English translation and concept sequence are shown. The concepts of “な く” and “ない” are both 3.1200 because they are the same words after lemmatization. Table 3 presents the number of words, vocabulary, and concepts in each corpus. 3.3 Vectors In this study, word2vec2 (Mikolov et al., 2013a; Mikolov et al., 2013b; Mikolov et al., 2013c) was used to generate concept embeddings. Then, finetuning was performed. Fine-tuning is a method in which generated distributed representations are 2 https://code.google.com/archive/p/ word2vec/ given as initial values and retrained with a new corpus. The following four types of concept embeddings were created: • All-words WSD vector: concept embeddings were trained with the all-words WSD corpus. • All-words WSD-fine vector: concept embeddings were trained with the all-words WSD corpus and retrained with a manual corpus. • Manual vector: concept"
2020.paclic-1.15,D17-1120,0,0.0678417,"ted using text corpora. It is possible to generate concept embeddings by the same method used to generate word embeddings if the word sequence (i.e., text corpus) is replaced with a concept sequence constructed from a concept-tagged corpus. However, it is difficult to obtain a sufficiently large concept-tagged corpus because the annotation of concept tags is time-consuming. There have been several studies that assigned word senses using the all-words word sense disambiguation (WSD) method (Edmonds and Cotton, 2001), (Snyder and Palmer, 2004), (Navigli et al., 2007), (Iacobacci et al., 2016), (Raganato et al., 2017a), (Raganato et al., 2017b), (Suzuki et al., 2018), (Shinnou et al., 2018). As a result, it is possible to create a concept-tagged corpus using the methods proposed in these studies. However, the results of all-words WSD systems are not always correct; therefore, an automatically tagged corpus created via all-words WSD may not be suitable for generating concept embeddings. In this paper, we generate concept embeddings of Word List by Semantic Principles (WLSP) (National Institute for Japanese Language and Linguistics, 1964), a Japanese thesaurus, from manually and automatically tagged corpora"
2020.paclic-1.15,W04-0811,0,0.0762677,"achine translation and text summarization. Word embeddings are usually generated using text corpora. It is possible to generate concept embeddings by the same method used to generate word embeddings if the word sequence (i.e., text corpus) is replaced with a concept sequence constructed from a concept-tagged corpus. However, it is difficult to obtain a sufficiently large concept-tagged corpus because the annotation of concept tags is time-consuming. There have been several studies that assigned word senses using the all-words word sense disambiguation (WSD) method (Edmonds and Cotton, 2001), (Snyder and Palmer, 2004), (Navigli et al., 2007), (Iacobacci et al., 2016), (Raganato et al., 2017a), (Raganato et al., 2017b), (Suzuki et al., 2018), (Shinnou et al., 2018). As a result, it is possible to create a concept-tagged corpus using the methods proposed in these studies. However, the results of all-words WSD systems are not always correct; therefore, an automatically tagged corpus created via all-words WSD may not be suitable for generating concept embeddings. In this paper, we generate concept embeddings of Word List by Semantic Principles (WLSP) (National Institute for Japanese Language and Linguistics, 1"
2020.paclic-1.15,L18-1162,1,0.693266,"oncept embeddings by the same method used to generate word embeddings if the word sequence (i.e., text corpus) is replaced with a concept sequence constructed from a concept-tagged corpus. However, it is difficult to obtain a sufficiently large concept-tagged corpus because the annotation of concept tags is time-consuming. There have been several studies that assigned word senses using the all-words word sense disambiguation (WSD) method (Edmonds and Cotton, 2001), (Snyder and Palmer, 2004), (Navigli et al., 2007), (Iacobacci et al., 2016), (Raganato et al., 2017a), (Raganato et al., 2017b), (Suzuki et al., 2018), (Shinnou et al., 2018). As a result, it is possible to create a concept-tagged corpus using the methods proposed in these studies. However, the results of all-words WSD systems are not always correct; therefore, an automatically tagged corpus created via all-words WSD may not be suitable for generating concept embeddings. In this paper, we generate concept embeddings of Word List by Semantic Principles (WLSP) (National Institute for Japanese Language and Linguistics, 1964), a Japanese thesaurus, from manually and automatically tagged corpora. First, concept embeddings are generated from a co"
2020.paclic-1.46,P17-1042,0,0.0224069,"ctor space such that the word embeddings of the words whose meanings were similar to each other in two languages can be brought closer. The geometrical relations that hold between words are similar across languages; thus a vector space of a language can be transformed into that of another language using a linear projection. We adapted hereikn two methods of the BWE, namely, linear transformation matrix and VecMap. A linear projection matrix W was 4 https://github.com/artetxem/vecmap#publications learned when we used a linear transformation matrix. VecMap is an implementation of a framework of Artetxe et al. (2017) to learn cross-lingual word embedding mappings (Artetxe et al., 2018a)(Artetxe et al., 2018b). 3.1.1 Linear Transformation Matrix We conducted the following experiments when a linear transformation matrix was learned: 1. Generate short and long unit corpora and learn short or long unit embeddings for each corpus from them using word2vec (cf. Figure 1). 2. Learn a linear projection matrix W from the vector space of the short units to that of the long units using pairs of embeddings for common words generated in the last step. 3. Apply matrix W to the short unit embeddings and obtain the projec"
2020.paclic-1.46,P18-1073,0,0.0178917,"ere similar to each other in two languages can be brought closer. The geometrical relations that hold between words are similar across languages; thus a vector space of a language can be transformed into that of another language using a linear projection. We adapted hereikn two methods of the BWE, namely, linear transformation matrix and VecMap. A linear projection matrix W was 4 https://github.com/artetxem/vecmap#publications learned when we used a linear transformation matrix. VecMap is an implementation of a framework of Artetxe et al. (2017) to learn cross-lingual word embedding mappings (Artetxe et al., 2018a)(Artetxe et al., 2018b). 3.1.1 Linear Transformation Matrix We conducted the following experiments when a linear transformation matrix was learned: 1. Generate short and long unit corpora and learn short or long unit embeddings for each corpus from them using word2vec (cf. Figure 1). 2. Learn a linear projection matrix W from the vector space of the short units to that of the long units using pairs of embeddings for common words generated in the last step. 3. Apply matrix W to the short unit embeddings and obtain the projected long unit embeddings for them. 3.1.2 VecMap VecMap was used as an"
2020.paclic-1.46,P14-1006,0,0.0177335,"that appeared in the source language corpus into the target language using Wiktionary. They then ﬁltered out the noises of these pairs and trained the model with this corpus, in which the pairs were replaced with placeholders to ensure that the translations of the same word have the same vector representation. The third approach is cross-lingual training. This approach trains their embeddings on a parallel corpus and optimizes a cross-lingual constraint between the embeddings of different languages that encourages embeddings of similar words to be close to each other in a shared vector space. Hermann and Blunsom (2014) trained two models to output sentence embeddings for input sentences in two different languages. They retrained these models with sentence embeddings using a least squares method. The ﬁnal approach is joint optimization, which not only considers a cross-lingual constraint but also jointly optimizes monolingual and cross-lingual objectives. Klementiev et al. (2012) performed the ﬁrst research using joint optimization. Zou et al. (2013) used a matrix factorization approach to learn crosslingual word representations for English and Chinese and utilized the representations for a machine 3 https:/"
2020.paclic-1.46,C12-1089,0,0.0254638,"ch trains their embeddings on a parallel corpus and optimizes a cross-lingual constraint between the embeddings of different languages that encourages embeddings of similar words to be close to each other in a shared vector space. Hermann and Blunsom (2014) trained two models to output sentence embeddings for input sentences in two different languages. They retrained these models with sentence embeddings using a least squares method. The ﬁnal approach is joint optimization, which not only considers a cross-lingual constraint but also jointly optimizes monolingual and cross-lingual objectives. Klementiev et al. (2012) performed the ﬁrst research using joint optimization. Zou et al. (2013) used a matrix factorization approach to learn crosslingual word representations for English and Chinese and utilized the representations for a machine 3 https://ruder.io/cross-lingual-embeddings/ translation task. In this study, we used the ﬁrst approach, monolingual mapping. The nearest works to this research are those of Komiya et al. (2019) and Kouno and Komiya (2020). Komiya et al. (2019) composed word embeddings for long units from the two word embeddings of short units using a feed-forward neural network system. The"
2020.paclic-1.46,W14-1613,0,0.0211906,"rains monolingual word embeddings and learns a transformation matrix that maps representations in one language to those of the other language. Mikolov et al. (2013) showed that vector spaces can encode meaningful relations between words and that the geometric relations that hold between words are similar across languages. They did not assume the use of speciﬁc language; thus their method can be used to extend and reﬁne dictionaries for any language pairs. The second approach is pseudo-cross-lingual. This approach creates a pseudo-cross-lingual corpus by mixing contexts of different languages. Xiao and Guo (2014) proposed the ﬁrst pseudo-cross-lingual method that utilized translation pairs. They ﬁrst translated all words that appeared in the source language corpus into the target language using Wiktionary. They then ﬁltered out the noises of these pairs and trained the model with this corpus, in which the pairs were replaced with placeholders to ensure that the translations of the same word have the same vector representation. The third approach is cross-lingual training. This approach trains their embeddings on a parallel corpus and optimizes a cross-lingual constraint between the embeddings of diffe"
2020.paclic-1.46,D13-1141,0,0.0140009,"onstraint between the embeddings of different languages that encourages embeddings of similar words to be close to each other in a shared vector space. Hermann and Blunsom (2014) trained two models to output sentence embeddings for input sentences in two different languages. They retrained these models with sentence embeddings using a least squares method. The ﬁnal approach is joint optimization, which not only considers a cross-lingual constraint but also jointly optimizes monolingual and cross-lingual objectives. Klementiev et al. (2012) performed the ﬁrst research using joint optimization. Zou et al. (2013) used a matrix factorization approach to learn crosslingual word representations for English and Chinese and utilized the representations for a machine 3 https://ruder.io/cross-lingual-embeddings/ translation task. In this study, we used the ﬁrst approach, monolingual mapping. The nearest works to this research are those of Komiya et al. (2019) and Kouno and Komiya (2020). Komiya et al. (2019) composed word embeddings for long units from the two word embeddings of short units using a feed-forward neural network system. They classiﬁed the dependency relations of two short units into 13 groups a"
2020.repl4nlp-1.8,N19-1423,0,0.0539052,"ild. Thus, we can infer that a possible reason that the writer needs to be dressed by other people is that he or she may have a physical disability (Huang et al., 2019). Although a simple task for humans, it is still challenging for computers to understand and reason about commonsense. Commonsense inference in natural language processing (NLP) is generally evaluated via machine reading comprehension task, in the format of selecting plausible responses with respect to natural language queries. Recent approaches are based on the use of pre-trained Transformer-based language models such as BERT (Devlin et al., 2019). Some approaches rely solely on these models by adopting either a single or multi-stage fine-tuning approach (by fine-tuning using additional datasets in a stepwise manner) (Li and Xie, 2019; Sharma and Roychowdhury, 2019; Liu and Yu, 2019; Huang et al., Table 1: Example from the CosmosQA dataset (Huang et al., 2019). The task is to identify the correct answer option. The correct answer is in bold. 2019; Zhou et al., 2019), while others further enhance their word representations with knowledge bases such as ConceptNet (Jain and Singh, 2019; Da, 2019; Wang et al., 2020). However, due to the of"
2020.repl4nlp-1.8,D19-1243,0,0.0659429,"Missing"
2020.repl4nlp-1.8,2021.ccl-1.108,0,0.161232,"Missing"
2020.repl4nlp-1.8,D19-6008,0,0.0284281,"ained Transformer-based language models such as BERT (Devlin et al., 2019). Some approaches rely solely on these models by adopting either a single or multi-stage fine-tuning approach (by fine-tuning using additional datasets in a stepwise manner) (Li and Xie, 2019; Sharma and Roychowdhury, 2019; Liu and Yu, 2019; Huang et al., Table 1: Example from the CosmosQA dataset (Huang et al., 2019). The task is to identify the correct answer option. The correct answer is in bold. 2019; Zhou et al., 2019), while others further enhance their word representations with knowledge bases such as ConceptNet (Jain and Singh, 2019; Da, 2019; Wang et al., 2020). However, due to the often limited data from the downstream tasks and the extremely high complexity of the pre-trained model, aggressive fine-tuning can easily make the adapted model overfit the data of the target task, making it unable to generalize well on unseen data (Jiang et al., 2019). Moreover, some researchers have shown that such pre-trained models are vulnerable to adversarial attacks (Jin et al., 2020). Inspired by the recent success of adversarial training in NLP (Zhu et al., 2020; Jiang et al., 2019), our AdversariaL training algorithm for commonsens"
2020.repl4nlp-1.8,S19-1012,0,0.0190808,"he perturbation δ. This model recently obtained state-of-the-art results on a bunch of NLP tasks on the GLUE benchmark (Wang et al., 2018). We also compare ALICE with a baseline that uses only the label y for estimating the perturbation δ (called model ADV hereafter) (Madry et al., 2018). The summary of the datasets is in Table 2. For the MCTACO dataset, no training set is available. Following (Zhou et al., 2019), we use the dev set for fine-tuning the model. We perform 5-fold crossvalidation for fine-tuning the parameters. We evaluate CosmosQA and MCScript2.0 in terms of accuracy. Following (Ostermann et al., 2019a), we also report for the MCScript2.0 accuracy on the commonsense based questions and accuracy on the questions that are not commonsense based. For the MCTACO, we report the exact match (EM) and F1 scores, following (Zhou et al., 2019). EM measures how many questions a system correctly labeled all candidate answers, while F1 measures the average overlap between one’s predictions and the ground truth. Our implementation for pairwise text classification and relevance ranking tasks are based on the MT-DNN framework1 (Liu et al., 2019a, 2020). 3.4 3.2 Baselines Results The results are summarized"
2020.repl4nlp-1.8,D19-6007,0,0.0114632,"he perturbation δ. This model recently obtained state-of-the-art results on a bunch of NLP tasks on the GLUE benchmark (Wang et al., 2018). We also compare ALICE with a baseline that uses only the label y for estimating the perturbation δ (called model ADV hereafter) (Madry et al., 2018). The summary of the datasets is in Table 2. For the MCTACO dataset, no training set is available. Following (Zhou et al., 2019), we use the dev set for fine-tuning the model. We perform 5-fold crossvalidation for fine-tuning the parameters. We evaluate CosmosQA and MCScript2.0 in terms of accuracy. Following (Ostermann et al., 2019a), we also report for the MCScript2.0 accuracy on the commonsense based questions and accuracy on the questions that are not commonsense based. For the MCTACO, we report the exact match (EM) and F1 scores, following (Zhou et al., 2019). EM measures how many questions a system correctly labeled all candidate answers, while F1 measures the average overlap between one’s predictions and the ground truth. Our implementation for pairwise text classification and relevance ranking tasks are based on the MT-DNN framework1 (Liu et al., 2019a, 2020). 3.4 3.2 Baselines Results The results are summarized"
2020.repl4nlp-1.8,D19-6009,0,0.020467,"ill challenging for computers to understand and reason about commonsense. Commonsense inference in natural language processing (NLP) is generally evaluated via machine reading comprehension task, in the format of selecting plausible responses with respect to natural language queries. Recent approaches are based on the use of pre-trained Transformer-based language models such as BERT (Devlin et al., 2019). Some approaches rely solely on these models by adopting either a single or multi-stage fine-tuning approach (by fine-tuning using additional datasets in a stepwise manner) (Li and Xie, 2019; Sharma and Roychowdhury, 2019; Liu and Yu, 2019; Huang et al., Table 1: Example from the CosmosQA dataset (Huang et al., 2019). The task is to identify the correct answer option. The correct answer is in bold. 2019; Zhou et al., 2019), while others further enhance their word representations with knowledge bases such as ConceptNet (Jain and Singh, 2019; Da, 2019; Wang et al., 2020). However, due to the often limited data from the downstream tasks and the extremely high complexity of the pre-trained model, aggressive fine-tuning can easily make the adapted model overfit the data of the target task, making it unable to gener"
2020.repl4nlp-1.8,W18-5446,0,0.103196,"Missing"
2020.repl4nlp-1.8,D18-1009,0,0.024548,"e judged as plausible or not. The sentences are taken from different sources such as news, Wikipedia and textbooks. We compare ALICE to a list of state-of-the-art models, as shown in Table 3. BERT + unit normalization (Zhou et al., 2019) is the BERT base model. The authors further add unit normalization to temporal expressions in candidate answers and finetune on the MC-TACO dataset. RoBERTaLARGE is our re-implementation of the large RoBERTa model by (Liu et al., 2019b). PSH-SJTU (Li and Xie, 2019) is based on multi-stage fine-tuning XLNET (Yang et al., 2019) on RACE (Lai et al., 2017), SWAG (Zellers et al., 2018) and MC-Script2.0 datasets. K-ADAPTER (Wang et al., 2020) further enhances RoBERTa word representations with multiple knowledge sources, such as factual knowledge obtained through Wikipedia and Wikidata and linguistic knowledge obtained through dependency parsing web texts. SMART (Jiang et al., 2019) is an adversarial training model for fine-tuning pretrained language models through regularization. SMART uses the model prediction, f (x; θ), for estimating the perturbation δ. This model recently obtained state-of-the-art results on a bunch of NLP tasks on the GLUE benchmark (Wang et al., 2018)."
2020.repl4nlp-1.8,D19-1332,0,0.306941,"ecting plausible responses with respect to natural language queries. Recent approaches are based on the use of pre-trained Transformer-based language models such as BERT (Devlin et al., 2019). Some approaches rely solely on these models by adopting either a single or multi-stage fine-tuning approach (by fine-tuning using additional datasets in a stepwise manner) (Li and Xie, 2019; Sharma and Roychowdhury, 2019; Liu and Yu, 2019; Huang et al., Table 1: Example from the CosmosQA dataset (Huang et al., 2019). The task is to identify the correct answer option. The correct answer is in bold. 2019; Zhou et al., 2019), while others further enhance their word representations with knowledge bases such as ConceptNet (Jain and Singh, 2019; Da, 2019; Wang et al., 2020). However, due to the often limited data from the downstream tasks and the extremely high complexity of the pre-trained model, aggressive fine-tuning can easily make the adapted model overfit the data of the target task, making it unable to generalize well on unseen data (Jiang et al., 2019). Moreover, some researchers have shown that such pre-trained models are vulnerable to adversarial attacks (Jin et al., 2020). Inspired by the recent success o"
2020.repl4nlp-1.8,D17-1082,0,\N,Missing
2020.repl4nlp-1.8,P19-1441,1,\N,Missing
2020.repl4nlp-1.8,D19-6011,0,\N,Missing
2020.repl4nlp-1.8,2020.acl-demos.16,1,\N,Missing
2021.acl-long.405,P18-1254,0,0.0490997,"Missing"
2021.acl-long.405,W12-1706,0,0.376094,"uniform information density. Overall, our results suggest that a crosslingual evaluation will be necessary to construct human-like computational models. 1 Introduction It is well known that the probability of a word in context (i.e., surprisal) impacts its processing difficulty in incremental human language comprehension (Hale, 2001; Demberg and Keller, 2008; Levy, 2008; Smith and Levy, 2013). Building on this basis, researchers have compared a variety of language models (LMs) in terms of how well their surprisal correlates with human reading behavior (Roark et al., 2009; Frank and Bod, 2011; Fossum and Levy, 2012; Hale et al., 2018; Goodkind and Bicknell, 2018; Aurnhammer and Frank, 2019; Merkx and Frank, 2020; Wilcox et al., 2020). Such investigations could provide insights into the development of a general computational model of human language processing. For example, recent studies reported that LMs with better performance for next-word prediction could also better predict the human reading behavior (i.e. more humanlike) (Fossum and Levy, 2012; Goodkind and Bicknell, 2018; Wilcox et al., 2020). In this paper, we re-examine whether the recent findings on human-like computational models can be genera"
2021.acl-long.405,D09-1034,0,0.251632,"r explored from the perspective of (non-)uniform information density. Overall, our results suggest that a crosslingual evaluation will be necessary to construct human-like computational models. 1 Introduction It is well known that the probability of a word in context (i.e., surprisal) impacts its processing difficulty in incremental human language comprehension (Hale, 2001; Demberg and Keller, 2008; Levy, 2008; Smith and Levy, 2013). Building on this basis, researchers have compared a variety of language models (LMs) in terms of how well their surprisal correlates with human reading behavior (Roark et al., 2009; Frank and Bod, 2011; Fossum and Levy, 2012; Hale et al., 2018; Goodkind and Bicknell, 2018; Aurnhammer and Frank, 2019; Merkx and Frank, 2020; Wilcox et al., 2020). Such investigations could provide insights into the development of a general computational model of human language processing. For example, recent studies reported that LMs with better performance for next-word prediction could also better predict the human reading behavior (i.e. more humanlike) (Fossum and Levy, 2012; Goodkind and Bicknell, 2018; Wilcox et al., 2020). In this paper, we re-examine whether the recent findings on h"
2021.acl-long.405,P16-1162,0,0.00660288,"sahara et al., 2016) and was extensively annotated with various linguistic properties (Asahara and Kato, 2017; Asahara, 2017, 2018). 3 Methods This section describes the settings of LMs, eye movement data, and evaluation metrics. 3.1 Language models A variety of sentence-level, left-to-right sequential LMs was used. Training data of English LMs: We used the WikiText-103 dataset to train the English LMs. Based on the reports that subword-level English LMs exhibits superior psychometric predictive power (Wilcox et al., 2020), input texts were divided into subwords by a byte-pair encoding (BPE) (Sennrich et al., 2016).2 The training data consist of approximately 4M sentences (114M subwords units). Training data size: For each neural LM architecture (T RANS - LG, T RANS - SM, and LSTM), three variants were trained using different training data sizes: LG (full training data), MD (1/10 training data), and SM (1/100 training data). The N-gram LMs were trained on LG datasets. Number of updates: The parameters of each neural LM were saved at four different points during training: 100, 1K, 10K, and 100K parameter updates. To summarize, 39 LM training settings were attained for each language (3 architectures × 3 d"
asahara-etal-2002-use,ide-etal-2000-xces,0,\N,Missing
C00-1004,J95-4004,0,0.083928,"Missing"
C00-1004,A92-1018,0,0.113139,"Missing"
C04-1066,N03-1002,1,0.895604,"Missing"
C04-1066,A00-1031,0,0.0925994,"Missing"
C04-1066,P03-2039,1,0.880388,"Missing"
C04-1066,shinnou-ikeya-2000-extraction,0,0.0587615,"Missing"
C04-1066,N01-1025,1,0.686062,"Seven character types ar defined: Space, Digit, Lowercase alphabet, Uppercase alphabet, Hiragana, Katakana, Other (Kanji). The character type is directly or indirectly used in most of previous work and appears an important feature to characterize unknown words in Japanese texts. Table 1: Tags for positions in a word Tag S B E I Description one-character word first character in a multi-character word last character in a multi-character word intermediate character in a multi-character word (only for words longer than 2 chars) 2.3 Support Vector Machine-based Chunking We use the chunker YamCha (Kudo and Matsumoto, 2001), which is based on SVMs (Vapnik, 1998). Suppose we have a set of training data for a binary class problem: (x1 , y1 ), . . . , (xN , yN ), where xi ∈ Rn is a feature vector of the i th sample in the training data and yi ∈ {+1, −1} is the label of the sample. The goal is to find a decision function which accurately predicts y for an unseen x. An support vector machine classifier gives a decision function f (x) = sign(g(x)) for an input vector x where g(x) =  αi yi K(x, zi ) + b. zi ∈SV K(x, z) is a kernel function which maps vectors into a higher dimensional space. We use a polynomial kernel"
C04-1066,C96-2202,0,0.414243,"Missing"
C04-1066,P99-1036,0,0.150218,"Missing"
C04-1066,W95-0107,0,0.0365165,"* unknown word tag B I I Figure 1: An example of features for chunking for the extension, the “One vs. Rest method” and the “Pairwise method”. In the “One vs. Rest methods”, we prepare n binary classifiers between one class and the remain classes. Whereas in the “Pairwise method”, we prepare n C2 binary classifiers between all pairs of classes. We use “Pairwise method” since it is efficient to train than the “One vs. Rest method”. Chunking is performed by deterministically annotating a tag on each character. Table 2 shows the unknown word tags for chunking, which are known as the IOB2 model (Ramshaw and Marcus, 1995). Table 2: Tags for unknown word chunking Tag Description B first character in an unknown word character in an unknown word (except B) I character in a known word O We perform chunking either from the beginning or from the end of the sentence. Figure 1 illustrates a snapshot of chunking procedure. Two character contexts on both sides are referred to. Information of two preceding unknown word tags is also used since the chunker has already determined them and they are available. In the example, the chunker uses the features appearing within the solid box to infer the unknown word tag (“I”) at t"
C04-1066,W02-1817,0,0.0343378,"Missing"
C04-1066,W01-0512,0,\N,Missing
C04-1066,C02-1049,0,\N,Missing
C04-1066,C02-2019,0,\N,Missing
C04-1066,P03-1061,0,\N,Missing
C04-1066,maekawa-etal-2000-spontaneous,0,\N,Missing
C08-1046,P06-1105,0,0.034975,"Missing"
C08-1046,C96-1058,0,0.0901231,"(a) “He is a man who doesn’t read books.” 彼は kare-wa (He) 本を hon-wo (books) 読まない。 yomanai. (doesn’t read .) (b) “He doesn’t read books.” Figure 1: Examples of Japanese sentences. Introduction The shared tasks of multi-lingual dependency parsing took place at CoNLL-2006 (Buchholz and Marsi, 2006) and CoNLL-2007 (Nivre et al., 2007). Many language-independent parsing algorithms were proposed there. The algorithms need to adapt to various dependency structure constraints according to target languages: projective vs. non-projective, head-initial vs. head-final, and single-rooted vs. multi-rooted. Eisner (1996) proposed a CKY-like O(n3 ) algorithm. Yamada and Matsumoto (2003) proposed a shift-reducelike O(n2 ) deterministic algorithm. Nivre et al. (2003; 2004) also proposed a shift-reduce-like c 2008.  Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. O(n) deterministic algorithm for projective languages. The model is enhanced for non-projective languages by Nivre and Nilsson (2005). McDonald et al. (2005) proposed a method based on search of maximum spanning trees employing the C"
C08-1046,W03-2604,1,0.757988,"ved the highest accuracy in the experiments with Kyoto Text Corpus Version 3.0 data 1 , since other deterministic methods do not consider relative preference among candidate heads but solely consider whether the focused-on pair of bunsetsu’s is in a dependency relation or not. We propose a model that takes a bunsetsu and two candidate heads into consideration and selects the better candidate head out of those two. This step is repeated in a step ladder tournament to get the best candidate head (hereafter we call this model as a “tournament model”). The tournament model was first introduced by Iida et al. (2003) for coreference resolution. We applied this model to selecting the most plausible candidate head for each bunsetsu except for the sentence final one. Section 2 describes the tournament model comparing with previous research. Section 3 describes 1 Note: Sassano’s SR algorithm is the highest by experiment with the smaller data Kyoto Text Corpus Version 2.0 Relative preference method and SR algorithm are not compared directly with the same data. The most likely candidate head 彼は kare-wa (He) Focused-on dependent 本を hon-wo (books) 読まない yomanai (doesn’t read) 人だ。 hito-da. (man .) Its candidate hea"
C08-1046,C04-1010,0,0.173635,"Missing"
C08-1046,W03-3017,0,0.0888379,"“yomanai” in (b) but not in (a). In dependency parsing of Japanese, deterministic algorithms outperform probabilistic CKY methods. Kudo and Matsumoto (2002) applied the 361 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 361–368 Manchester, August 2008 cascaded chunking algorithm (hereafter “CC algorithm”) to Japanese dependency parsing. Yamada’s method (Yamada and Matsumoto, 2003) employed a similar algorithm. Sassano (2004) proposed a linear-order shift-reduce-like algorithm (hereafter “SR algorithm”), which is similar to Nivre’s algorithm (Nivre, 2003). These deterministic algorithms are biased to select nearer candidate heads since they examine the candidates sequentially, and once they find a plausible one they never consider further candidates. We experimented the CLE algorithm with Japanese dependency parsing, and found that the CLE algorithm is comparable to or in some cases poorer than the deterministic algorithms in our experiments. Actually, the CLE algorithm is not suitable for some of the constraints in Japanese dependency structures: head-final and projective. First, head-final means that dependency relation always goes from left"
C08-1046,C04-1002,0,0.343353,"(a) is similar to sentence (b), the syntactic structures of these two are different, especially because “kare-wa” directly depends on “yomanai” in (b) but not in (a). In dependency parsing of Japanese, deterministic algorithms outperform probabilistic CKY methods. Kudo and Matsumoto (2002) applied the 361 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 361–368 Manchester, August 2008 cascaded chunking algorithm (hereafter “CC algorithm”) to Japanese dependency parsing. Yamada’s method (Yamada and Matsumoto, 2003) employed a similar algorithm. Sassano (2004) proposed a linear-order shift-reduce-like algorithm (hereafter “SR algorithm”), which is similar to Nivre’s algorithm (Nivre, 2003). These deterministic algorithms are biased to select nearer candidate heads since they examine the candidates sequentially, and once they find a plausible one they never consider further candidates. We experimented the CLE algorithm with Japanese dependency parsing, and found that the CLE algorithm is comparable to or in some cases poorer than the deterministic algorithms in our experiments. Actually, the CLE algorithm is not suitable for some of the constraints"
C08-1046,D07-1064,0,0.0462536,"Missing"
C08-1046,W08-2132,1,0.882103,"Missing"
C08-1046,W03-3023,1,0.956027,"(He) 本を hon-wo (books) 読まない。 yomanai. (doesn’t read .) (b) “He doesn’t read books.” Figure 1: Examples of Japanese sentences. Introduction The shared tasks of multi-lingual dependency parsing took place at CoNLL-2006 (Buchholz and Marsi, 2006) and CoNLL-2007 (Nivre et al., 2007). Many language-independent parsing algorithms were proposed there. The algorithms need to adapt to various dependency structure constraints according to target languages: projective vs. non-projective, head-initial vs. head-final, and single-rooted vs. multi-rooted. Eisner (1996) proposed a CKY-like O(n3 ) algorithm. Yamada and Matsumoto (2003) proposed a shift-reducelike O(n2 ) deterministic algorithm. Nivre et al. (2003; 2004) also proposed a shift-reduce-like c 2008.  Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. O(n) deterministic algorithm for projective languages. The model is enhanced for non-projective languages by Nivre and Nilsson (2005). McDonald et al. (2005) proposed a method based on search of maximum spanning trees employing the Chu-Liu-Edmonds algorithm (hereafter “CLE algorithm”) (Chu and Liu,"
C08-1046,W02-2016,1,0.947086,"e dependency structures have the following constraints: head-final, singlehead, single-rooted, connected, acyclic and projective. Figure 1 shows examples of Japanese sentences and their dependency structures. Each box represents a bunsetsu. A dependency relation is represented by an edge from a dependent to its head. Though sentence (a) is similar to sentence (b), the syntactic structures of these two are different, especially because “kare-wa” directly depends on “yomanai” in (b) but not in (a). In dependency parsing of Japanese, deterministic algorithms outperform probabilistic CKY methods. Kudo and Matsumoto (2002) applied the 361 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 361–368 Manchester, August 2008 cascaded chunking algorithm (hereafter “CC algorithm”) to Japanese dependency parsing. Yamada’s method (Yamada and Matsumoto, 2003) employed a similar algorithm. Sassano (2004) proposed a linear-order shift-reduce-like algorithm (hereafter “SR algorithm”), which is similar to Nivre’s algorithm (Nivre, 2003). These deterministic algorithms are biased to select nearer candidate heads since they examine the candidates sequentially, and once they find"
C08-1046,P05-1012,0,0.442665,"vs. non-projective, head-initial vs. head-final, and single-rooted vs. multi-rooted. Eisner (1996) proposed a CKY-like O(n3 ) algorithm. Yamada and Matsumoto (2003) proposed a shift-reducelike O(n2 ) deterministic algorithm. Nivre et al. (2003; 2004) also proposed a shift-reduce-like c 2008.  Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. O(n) deterministic algorithm for projective languages. The model is enhanced for non-projective languages by Nivre and Nilsson (2005). McDonald et al. (2005) proposed a method based on search of maximum spanning trees employing the Chu-Liu-Edmonds algorithm (hereafter “CLE algorithm”) (Chu and Liu, 1965; Edmonds, 1967). Most Japanese dependency parsers are based on bunsetsu units, which are similar concept to English base phrases. The constraints in Japanese dependency structure are stronger than those in other languages. Japanese dependency structures have the following constraints: head-final, singlehead, single-rooted, connected, acyclic and projective. Figure 1 shows examples of Japanese sentences and their dependency structures. Each box repr"
C08-1046,W06-2920,0,\N,Missing
C08-1046,P05-1013,0,\N,Missing
C08-1046,D07-1096,0,\N,Missing
C12-2134,D08-1073,0,0.106911,"logy, Japan katsumasay@gmail.com, masayu-a@ninjal.ac.jp, ryu-i@cl.cs.titech.ac.jp Abstract This paper presents a temporal relation identification method optimizing relations at sentence and document levels. Temporal relation identification is to identify temporal orders between events and time expressions. Various approaches of this task have been studied through the shared tasks TempEval (Verhagen et al., 2007, 2010). Not only identifying each temporal relation independently, some works also try to find multiple temporal relations jointly by logical constraints in Integer Linear Programming (Chambers and Jurafsky, 2008; Do et al., 2012) or Markov Logic Networks (Yoshikawa et al., 2009; Ling and Weld, 2010; Ha et al., 2010). Though previous joint approaches optimize temporal relations in an entire document, we first optimize our model at sentence level and then extend it to document level. We consider that different types of temporal relations require different types of optimizations. By evaluating our sentence and document optimized model on the TempEval-2 data, we show that our approaches can achieve competitive performance in comparison to other state-of-the-art systems. We find that the sentence and docu"
C12-2134,D12-1062,0,0.0480689,"com, masayu-a@ninjal.ac.jp, ryu-i@cl.cs.titech.ac.jp Abstract This paper presents a temporal relation identification method optimizing relations at sentence and document levels. Temporal relation identification is to identify temporal orders between events and time expressions. Various approaches of this task have been studied through the shared tasks TempEval (Verhagen et al., 2007, 2010). Not only identifying each temporal relation independently, some works also try to find multiple temporal relations jointly by logical constraints in Integer Linear Programming (Chambers and Jurafsky, 2008; Do et al., 2012) or Markov Logic Networks (Yoshikawa et al., 2009; Ling and Weld, 2010; Ha et al., 2010). Though previous joint approaches optimize temporal relations in an entire document, we first optimize our model at sentence level and then extend it to document level. We consider that different types of temporal relations require different types of optimizations. By evaluating our sentence and document optimized model on the TempEval-2 data, we show that our approaches can achieve competitive performance in comparison to other state-of-the-art systems. We find that the sentence and document optimized mod"
C12-2134,S10-1076,0,0.230641,"oral relation identification method optimizing relations at sentence and document levels. Temporal relation identification is to identify temporal orders between events and time expressions. Various approaches of this task have been studied through the shared tasks TempEval (Verhagen et al., 2007, 2010). Not only identifying each temporal relation independently, some works also try to find multiple temporal relations jointly by logical constraints in Integer Linear Programming (Chambers and Jurafsky, 2008; Do et al., 2012) or Markov Logic Networks (Yoshikawa et al., 2009; Ling and Weld, 2010; Ha et al., 2010). Though previous joint approaches optimize temporal relations in an entire document, we first optimize our model at sentence level and then extend it to document level. We consider that different types of temporal relations require different types of optimizations. By evaluating our sentence and document optimized model on the TempEval-2 data, we show that our approaches can achieve competitive performance in comparison to other state-of-the-art systems. We find that the sentence and document optimized model has strong tasks in TempEval-2, respectively. Keywords: temporal relation identificat"
C12-2134,S10-1063,0,0.334019,"n which contains all the local and global features. 2.1 Local Model Our local model utilizes only local features and solves each task independently as a local classification problem. In the Markov Logic framework, local features are represented as local formulae. We say that a formula is local if it only considers the hidden temporal relation of a single event-event, event-time or event-DCT pair. The formulae in the second class are global: they involve two or more temporal relations at the same time. The local features are based on features employed in previous work (UzZaman and Allen, 2010; Llorens et al., 2010) and are listed in Table 3. In order to illustrate how we implement each feature as a formula, we show a simple example. Consider the tense-feature for Task F. For this feature we introduce a predicate tense(e, te) that denotes the tense te for an event e. In Table 3, this feature corresponds to the second row “EVENT-tense”. For Task F, we employ the tense combinations of two events (e1 x e2). Then we add a formula such as tense(e1, +te1) ∧ tense(e2, +te2) ⇒ e2s(e1, e2, +R) (1) which represents the properties of combinations between tense and event-event relations. Note, “+” sign means that th"
C12-2134,P06-1095,0,0.03644,"pEval-2. The temporal relations (TLINKs) are annotated as shown in Table 1 and we have to estimate these TLINK labels such as BEFORE, OVERLAP, and AFTER. task relation Task C Task D Task D Task D Task E Task F Task F Table e53 (change) OVERLAP t10 (a couple of years) e50 (think) OVERLAP t0 (DCT) e52 (think) OVERLAP t0 (DCT) e53 (change) AFTER t0 (DCT) e50 (think) OVERLAP e57 (reposition) e50 (think) OVERLAP e51 (gloomy) e52 (think) BEFORE e53 (change) 1: Temporal Relations (TLINKs) in Figure 1 While the first studies handled this task as local classification problems (Boguraev and Ando, 2005; Mani et al., 2006), some recent works regard temporal relation identification as a global optimization problem in an entire document. Global optimization approaches take into account several relations and jointly identify all relations within a document. In order to ensure the consistencies among relations, previous work exploited global approaches with transitivity constraints in Integer Linear Programming (Chambers and Jurafsky, 2008; Do et al., 2012) or Markov Logic (Yoshikawa et al., 2009; Ling and Weld, 2010). In this paper, we propose a new approach to temporal relation identification by optimizing tempor"
C12-2134,N09-1018,0,0.0249243,". With event-argument relations (semantic roles), we construct some more global formulae. For e2d, we assume that the relations sharing the same time expression have the same relations. Such properties can be expressed as, srl(e1, t, AM-TMP) ∧ srl(e2, t, AM-TMP) ⇒ e2d(e1, R1) ∧ e2d(e2, R2) ∧ R1 = R2. (10) Likewise, for e2t, we assume that the relations sharing the same time expression affect each other: srl(e1, t, AM-TMP) ∧ srl(e2, t, AM-TMP) ∧ e2t(e1, t, +R1) ⇒ e2t(e2, t, +R2). (11) It is easy for the sentence-optimized model to implement much more features and constraints as in other tasks (Meza-Ruiz and Riedel, 2009; Yoshikawa et al., 2011). 2.3 Document-optimized Model The last model is the method which optimizes problems at document level. We add another hidden predicate e2e which handles Task E of TempEval-2. Note, in order to pursue computational efficiency, we should deal with e2t, e2d, and e2s as observed predicates and solve only e2e in this phase. However, we only add a few global formulae and can construct 2 Formula (5b) is instantiated by the relations in Figure 1 1376 a global model which jointly optimizes four tasks. We no longer change the formulae we constructed for the sentence-optimized m"
C12-2134,D08-1068,0,0.069323,"Missing"
C12-2134,S10-1062,0,0.0904227,"ed model is a full version which contains all the local and global features. 2.1 Local Model Our local model utilizes only local features and solves each task independently as a local classification problem. In the Markov Logic framework, local features are represented as local formulae. We say that a formula is local if it only considers the hidden temporal relation of a single event-event, event-time or event-DCT pair. The formulae in the second class are global: they involve two or more temporal relations at the same time. The local features are based on features employed in previous work (UzZaman and Allen, 2010; Llorens et al., 2010) and are listed in Table 3. In order to illustrate how we implement each feature as a formula, we show a simple example. Consider the tense-feature for Task F. For this feature we introduce a predicate tense(e, te) that denotes the tense te for an event e. In Table 3, this feature corresponds to the second row “EVENT-tense”. For Task F, we employ the tense combinations of two events (e1 x e2). Then we add a formula such as tense(e1, +te1) ∧ tense(e2, +te2) ⇒ e2s(e1, e2, +R) (1) which represents the properties of combinations between tense and event-event relations. Note,"
C12-2134,S07-1014,0,0.171442,"and Document Optimizations Katsumasa Y oshikawa1 M asayuki Asahara2 Ryu Iida3 (1) IBM Research, Tokyo, Japan (2) National Institute for Japanese Language and Linguistics, Japan (3) Tokyo Institute of Technology, Japan katsumasay@gmail.com, masayu-a@ninjal.ac.jp, ryu-i@cl.cs.titech.ac.jp Abstract This paper presents a temporal relation identification method optimizing relations at sentence and document levels. Temporal relation identification is to identify temporal orders between events and time expressions. Various approaches of this task have been studied through the shared tasks TempEval (Verhagen et al., 2007, 2010). Not only identifying each temporal relation independently, some works also try to find multiple temporal relations jointly by logical constraints in Integer Linear Programming (Chambers and Jurafsky, 2008; Do et al., 2012) or Markov Logic Networks (Yoshikawa et al., 2009; Ling and Weld, 2010; Ha et al., 2010). Though previous joint approaches optimize temporal relations in an entire document, we first optimize our model at sentence level and then extend it to document level. We consider that different types of temporal relations require different types of optimizations. By evaluating"
C12-2134,I11-1126,1,0.806752,"ons (semantic roles), we construct some more global formulae. For e2d, we assume that the relations sharing the same time expression have the same relations. Such properties can be expressed as, srl(e1, t, AM-TMP) ∧ srl(e2, t, AM-TMP) ⇒ e2d(e1, R1) ∧ e2d(e2, R2) ∧ R1 = R2. (10) Likewise, for e2t, we assume that the relations sharing the same time expression affect each other: srl(e1, t, AM-TMP) ∧ srl(e2, t, AM-TMP) ∧ e2t(e1, t, +R1) ⇒ e2t(e2, t, +R2). (11) It is easy for the sentence-optimized model to implement much more features and constraints as in other tasks (Meza-Ruiz and Riedel, 2009; Yoshikawa et al., 2011). 2.3 Document-optimized Model The last model is the method which optimizes problems at document level. We add another hidden predicate e2e which handles Task E of TempEval-2. Note, in order to pursue computational efficiency, we should deal with e2t, e2d, and e2s as observed predicates and solve only e2e in this phase. However, we only add a few global formulae and can construct 2 Formula (5b) is instantiated by the relations in Figure 1 1376 a global model which jointly optimizes four tasks. We no longer change the formulae we constructed for the sentence-optimized model. So, what we have to"
C12-2134,P09-1046,1,0.892116,"ech.ac.jp Abstract This paper presents a temporal relation identification method optimizing relations at sentence and document levels. Temporal relation identification is to identify temporal orders between events and time expressions. Various approaches of this task have been studied through the shared tasks TempEval (Verhagen et al., 2007, 2010). Not only identifying each temporal relation independently, some works also try to find multiple temporal relations jointly by logical constraints in Integer Linear Programming (Chambers and Jurafsky, 2008; Do et al., 2012) or Markov Logic Networks (Yoshikawa et al., 2009; Ling and Weld, 2010; Ha et al., 2010). Though previous joint approaches optimize temporal relations in an entire document, we first optimize our model at sentence level and then extend it to document level. We consider that different types of temporal relations require different types of optimizations. By evaluating our sentence and document optimized model on the TempEval-2 data, we show that our approaches can achieve competitive performance in comparison to other state-of-the-art systems. We find that the sentence and document optimized model has strong tasks in TempEval-2, respectively."
C12-2134,S10-1010,0,\N,Missing
C16-1066,N01-1021,0,0.901434,"Pynte, 2005), which contains reading times for English and French newspaper editorials from 10 native speakers for each language, recorded using eyetracking equipment. The English version of the Dundee Eyetracking Corpus is composed of 20 editorial articles with 51,501 words. The Dundee Eyetracking Corpus does not target a specific set of linguistic phenomena; instead, it provides naturally occurring texts for the testing of diverse hypotheses. For example, Demberg and Keller (2008) used the corpus to test Gibson’s Dependency Locality Theory (DLT), (Gibson, 2008), and Hale’s surprisal theory (Hale, 2001). The corpus also allows for replications to be conducted, as in Roland et al. (2012), who concluded that previous analyses (Demberg and Keller, 2007) had been distorted by the presense of a few outlier data points. Our goal is to produce a similar resource that can serve as a shared, available foundation for research in Japanese text processing. Once completed, the corpus will allow us to address two issues that are specific to Japanese. The first issue is related to two types of reading-time measurements commonly used, namely, eyetracking and self-paced reading. Although eyetracking provides"
C16-2006,C16-2011,1,0.806207,"(hereafter ‘NWJC’)(Asahara et al., 2014). This paper presents the web-based corpus concordance system ‘BonTen’ – Brahman1 for NWJC. The system designs are based on the string search mechanisms of the web-based search system ‘Shonagon’ 2 , which is used to search ‘the Balanced Corpus of Contemporary Written Japanese’ (hereafter ‘BCCWJ’)(Maekawa et al., 2014). Shonagon enables a short unit sequence search to be carried out on the web-based corpus concordance system ‘Chunagon’ for BCCWJ, and a dependency search to be performed on the corpus management system ‘ChaKi.NET’ (Matsumoto et al., 2005; Asahara et al., 2016). Because the system functions as a web application, the user only requires a web browser to access the corpus. The user interface design 3 is based on that of ‘ChaKi.NET’. The back-end search system is based on ‘Sedue for Bigdata’ and was developed by Retrieva Inc. 4 . The search system can effectively search the ten-billion-word scale corpora at practical speeds. 2 ‘NINJAL Web Japanese Corpus’ (NWJC) NWJC is a web corpus for Japanese linguistic research comprising ten billion words. Page collection is performed by employing remote harvesting using the Heritrix crawler. 5 Our web crawler proc"
C16-2011,C16-1066,1,0.824744,"ency parsed (Figure 6). We also plan to use this function with a historical Japanese corpus containing translations into contemporary Japanese. 50 Figure 4: Visualization of two word segmentation standards Figure 5: Visualization of Japanese-English parallel corpus 2.4 Visualization of Time ChaKi.NET can store the start time, end time, and duration of words or morphemes for speech transcription corpora. The demo for ‘Corpus of Spontaneous Japanese’ (CSJ) (Maekawa et al., 2000) can be accessed at https://youtu.be/Qod6J14X9mU. 2.5 Combination of Projection and Time The BCCWJ EyeTracking Corpus (Asahara et al., 2016) contains the reading time data of 24 experiment subjects, obtained from BCCWJ samples. We can define two word orders – the reading order of the subject and the word order in the original text. For the former order, we can define the start time, end time, and duration. For the latter order, reading time is aggregated into the following three duration types: first pass duration, regression path duration, and total duration. First pass duration is the time spent in a word region before moving on or looking back. Regression path duration is the time from Figure 6: Visualization of dialect and sta"
C16-2011,maekawa-etal-2000-spontaneous,0,0.150456,"t corpus is Bunsetsu-segmented with Katanaka transcription. The dialect is translated into standard Japanese, which is POS tagged and dependency parsed (Figure 6). We also plan to use this function with a historical Japanese corpus containing translations into contemporary Japanese. 50 Figure 4: Visualization of two word segmentation standards Figure 5: Visualization of Japanese-English parallel corpus 2.4 Visualization of Time ChaKi.NET can store the start time, end time, and duration of words or morphemes for speech transcription corpora. The demo for ‘Corpus of Spontaneous Japanese’ (CSJ) (Maekawa et al., 2000) can be accessed at https://youtu.be/Qod6J14X9mU. 2.5 Combination of Projection and Time The BCCWJ EyeTracking Corpus (Asahara et al., 2016) contains the reading time data of 24 experiment subjects, obtained from BCCWJ samples. We can define two word orders – the reading order of the subject and the word order in the original text. For the former order, we can define the start time, end time, and duration. For the latter order, reading time is aggregated into the following three duration types: first pass duration, regression path duration, and total duration. First pass duration is the time s"
D07-1068,E06-1002,0,0.0626311,"Missing"
D07-1068,N04-4028,0,0.0190297,"Networks. Since Bayesian Networks are directed graphical models, PRMs cannot model directly the cases where instantiated graph contains cycles. Taskar et al. proposed Relational Markov Networks (RMNs) 656 (2002). RMNs are the special case of Conditional Markov Networks (or Conditional Random Fields) in which graph structure and parameter tying are determined by SQL-like form. As for the marginal probability to use as a confidence measure shown in Figure 4, Peng et al. (2004) has applied linear-chain CRFs to Chinese word segmentation. It is calculated by constrained forwardbackward algorithm (Culotta and McCallum, 2004), and confident segments are added to the dictionary in order to improve segmentation accuracy. 6 Conclusion In this paper, we proposed a method for categorizing NEs in Wikipedia. We defined three types of cliques that are constitute dependent anchor texts in construct CRFs graph structure, and introduced potential functions for them to reflect classification. The experimental results show that the effectiveness of capturing dependencies, and proposed CRFs model can achieve significant improvements compare to baseline methods with SVMs. The results also show that the dependency information fro"
D07-1068,C04-1081,0,0.0107572,"ectly estimate most likely assignments. Getoor et al. proposed Probabilistic Relational Models (PRMs) (2001) which are built upon Bayesian Networks. Since Bayesian Networks are directed graphical models, PRMs cannot model directly the cases where instantiated graph contains cycles. Taskar et al. proposed Relational Markov Networks (RMNs) 656 (2002). RMNs are the special case of Conditional Markov Networks (or Conditional Random Fields) in which graph structure and parameter tying are determined by SQL-like form. As for the marginal probability to use as a confidence measure shown in Figure 4, Peng et al. (2004) has applied linear-chain CRFs to Chinese word segmentation. It is calculated by constrained forwardbackward algorithm (Culotta and McCallum, 2004), and confident segments are added to the dictionary in order to improve segmentation accuracy. 6 Conclusion In this paper, we proposed a method for categorizing NEs in Wikipedia. We defined three types of cliques that are constitute dependent anchor texts in construct CRFs graph structure, and introduced potential functions for them to reflect classification. The experimental results show that the effectiveness of capturing dependencies, and propos"
D07-1068,N06-1025,0,0.0262168,"Missing"
D07-1068,sekine-etal-2002-extended,0,0.16391,"v ,v )∈E (d) ∪E (d) ∪E (d) k i j S C R +   λk fk (yi , x(d) ) − logZ(x(d) )] vi ∈V (d) k  −  λ2   λ2 k k − 2 2σ 2 2σ  k (6) k where the last two terms are due to the Gaussian prior (Chen and Rosenfeld, 1999) used to reduce overfitting. Quasi-Newton methods, such as LBFGS (Liu and Nocedal, 1989) can be used for maximizing the function. 652 Dataset Our dataset is a random selection of 2300 articles from the Japanese version of Wikipedia as of October 2005. All anchor texts appearing under HTML <LI&gt; tags are hand-annotated with NE class label. We use the Extended Named Entity Hierarchy (Sekine et al., 2002) as the NE class labeling guideline, but reduce the number of classes to 13 from the original 200+ by ignoring fine-grained categories and nearby categories in order to avoid data sparseness. We eliminate examples that consist of less than two nodes in the SCR model. There are 16136 anchor texts with 14285 NEs. The number of Sibling, Cousin and Relative edges in the dataset are |ES |= 4925, |EC |= 13134 and |ER |= 746 respectively. 4.2 Experimental settings The aims of experiments are the two-fold. Firstly, we investigate the effect of each cliques. The several graphs are composed with the thr"
D07-1068,N06-2018,0,0.0356922,"Missing"
D11-1137,D07-1101,0,0.0228192,"ocal features. Our framework is for a dependency parser and the decoding in the reranking stage is done with an exact 1-best dynamic programming algorithm. Sangati et al. (2009) proposed a k-best generative reranking algorithm for dependency parsing. In this paper, we use a similar generative model, but combined with a variational model learned on the fly. Moreover, our framework is applicable to forests, not k-best lists. Koo and Collins (2010) presented third-order dependency parsing algorithm. Their model 1 is defined by an enclosing grandsibling for each sibling or grandchild part used in Carreras (2007). Our grandsibling model is similar to the model 1, but ours is defined by a generative model. The decoding in the reranking stage is also similar to the parsing algorithm of their model 1. In order to capture grandsibling factors, our decoding calculates inside probablities for not the current head node but each pair of the node and its outgoing edges. Titov and Henderson (2006) reported that the MBR approach could be applied to a projective dependency parser. In the field of SMT, for an approximation of MAP decoding, Li et al. (2009) proposed variational decoding and Kumar et al. (2009) pres"
D11-1137,P05-1022,0,0.903388,"baseline parser on the fly. The final prediction in the reranking stage is performed using linear interpolation of these models and discriminative model. In order to efficiently train the model from and decode on a hypergraph data structure representing a forest, we apply extended inside/outside and Viterbi algorithms. Experimental results show that our proposed forest reranking algorithm achieves significant improvement when compared with conventional approaches. 1 Introduction Recently, much of research on statistical parsing has been focused on k-best (or forest) reranking (Collins, 2000; Charniak and Johnson, 2005; Huang, 2008). Typically, reranking methods first generate a list of top-k candidates (or a forest) from a baseline system, then rerank the candidates with arbitrary features that are intractable within the baseline system. In the reranking framework, the baseline system is usually modeled with a generative model, and a discriminative model is used for reranking. Sangati et al. (2009) reversed the usual order of the two models for dependency parsing by employing a generative model to rescore the k-best candidates provided by a discriminative model. They use a variant of Eisner’s generative mo"
D11-1137,J07-2003,0,0.019011,"of each model in Table 3. Our reranking models are generative versions of Koo and Collins (2010)’s third-order factorization model. Non-locality of weight function makes it difficult to perform the search of Eq.8 with an usual exact Viterbi 1-best algorithm. One solution to resolve the intractability is an approximate k-best Viterbi search. For a constituent parser, Huang (2008) applied cube pruning techniques to forest reranking with non-local features. Cube pruning is originally proposed for the decoding of statistical machine translation (SMT) with an integrated n-gram lan1482 guage model (Chiang, 2007). It is an approximate k-best Viterbi search algorithm using beam search and lazy computation (Huang and Chiang, 2005). In the case of a dependency parser, Koo and Collins (2010) proposed dynamic-programmingbased third-order parsing algorithm, which enumerates all grandparents with an additional loop. Our hypergraph based search algorithm for Eq.8 share the same spirit to their third-order parsing algorithm since the grandsibling model is similar to their model 1 in that it is factored in grandsibling structure. Algorithm 1 shows the search algorithm. This is almost the same bottom-up 1-best V"
D11-1137,C96-1058,0,0.523394,", 2008). Typically, reranking methods first generate a list of top-k candidates (or a forest) from a baseline system, then rerank the candidates with arbitrary features that are intractable within the baseline system. In the reranking framework, the baseline system is usually modeled with a generative model, and a discriminative model is used for reranking. Sangati et al. (2009) reversed the usual order of the two models for dependency parsing by employing a generative model to rescore the k-best candidates provided by a discriminative model. They use a variant of Eisner’s generative model C (Eisner, 1996b; 1479 Eisner, 1996a) for reranking and extend it to capture higher-order information than Eisner’s second-order generative model. Their reranking model showed large improvements in dependency parsing accuracy. They reported that the discriminative model is very effective at filtering out bad candidates, while the generative model is able to further refine the selection among the few best candidates. In this paper, we propose a forest generative reranking algorithm, opposed to Sangati et al. (2009)’s approach which reranks only k-best candidates. Forests usually encode better candidates more"
D11-1137,N10-1115,0,0.0368683,"ecoding. The search algorithm in the reranking stage can be performed using dynamic programming algorithm. Our variational reranking is aimed at selecting a candidate from a forest, which is correct both in local and global. Our experimental results show more significant improvements than conventional approaches, such as k-best and forest generative reranking. In the future, we plan to investigate more appropriate generative models for reranking. PPAttachment is one of the most difficult problems for a natural language parser. We plan to examine to model such a complex structure (granduncle) (Goldberg and Elhadad, 2010) or higher-order structure than third-order for reranking which is computationally expensive for a baseline parser. As we mentioned in Section 5.4, we also plan to incorporate semi-supervised learning into our framework, which may potentially improve our reranking performance. Acknowledgments We would like to thank Graham Neubig and Masashi Shimbo for their helpful comments and to the anonymous reviewers for their effort of reviewing our paper and giving valuable comments. This work was supported in part by Grant-in-Aid for Japan Society for the Promotion of Science (JSPS) Research Fellowship"
D11-1137,W05-1506,0,0.441204,"er factorization model. Non-locality of weight function makes it difficult to perform the search of Eq.8 with an usual exact Viterbi 1-best algorithm. One solution to resolve the intractability is an approximate k-best Viterbi search. For a constituent parser, Huang (2008) applied cube pruning techniques to forest reranking with non-local features. Cube pruning is originally proposed for the decoding of statistical machine translation (SMT) with an integrated n-gram lan1482 guage model (Chiang, 2007). It is an approximate k-best Viterbi search algorithm using beam search and lazy computation (Huang and Chiang, 2005). In the case of a dependency parser, Koo and Collins (2010) proposed dynamic-programmingbased third-order parsing algorithm, which enumerates all grandparents with an additional loop. Our hypergraph based search algorithm for Eq.8 share the same spirit to their third-order parsing algorithm since the grandsibling model is similar to their model 1 in that it is factored in grandsibling structure. Algorithm 1 shows the search algorithm. This is almost the same bottom-up 1-best Viterbi algorithm except an additional loop in line 4. Line 4 references outgoing edge e′ of node h from a set of outgo"
D11-1137,P10-1110,0,0.158821,"Missing"
D11-1137,P08-1067,0,0.247023,"The final prediction in the reranking stage is performed using linear interpolation of these models and discriminative model. In order to efficiently train the model from and decode on a hypergraph data structure representing a forest, we apply extended inside/outside and Viterbi algorithms. Experimental results show that our proposed forest reranking algorithm achieves significant improvement when compared with conventional approaches. 1 Introduction Recently, much of research on statistical parsing has been focused on k-best (or forest) reranking (Collins, 2000; Charniak and Johnson, 2005; Huang, 2008). Typically, reranking methods first generate a list of top-k candidates (or a forest) from a baseline system, then rerank the candidates with arbitrary features that are intractable within the baseline system. In the reranking framework, the baseline system is usually modeled with a generative model, and a discriminative model is used for reranking. Sangati et al. (2009) reversed the usual order of the two models for dependency parsing by employing a generative model to rescore the k-best candidates provided by a discriminative model. They use a variant of Eisner’s generative model C (Eisner,"
D11-1137,P10-1001,0,0.173547,"2008). Moreover, our reranking uses not only a generative model obtained from training data, but also a sentence specific generative model learned from a forest. In the reranking stage, we use linearly combined model of these models. We call this variational reranking model. The model proposed in this paper is factored in the third-order structure, therefore, its non-locality makes it difficult to perform the reranking with an usual 1-best Viterbi search. To solve this problem, we also propose a new search algorithm, which is inspired by the third-order dynamic programming parsing algorithm (Koo and Collins, 2010). This algorithm enables us an exact 1-best reranking without any approximation. We summarize our contributions in this paper as follows. • To extend k-best to forest generative reranking. • We introduce variational reranking which is a combination approach of generative reranking and variational decoding (Li et al., 2009). • To obtain 1-best tree in the reranking stage, we Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1479–1488, c Edinburgh, Scotland, UK, July 27–31, 2011. 2011 Association for Computational Linguistics .top.0,8 propose an exact"
D11-1137,P08-1068,0,0.0309923,"hows the examples whose accuracy scores improved by the grandsibling model. For example, the dependency relationship from Verb to Noun phrase was corrected by our proposed model. On the other hand, many errors remain still in 1486 Table 10 shows the comparison of the performance of variational reranking (16-best forests) with that of other systems. Our method outperforms supervised parsers with second-order features, and achieves comparable results compared to a parser with thirdorder features (Koo and Collins, 2010). We can not directly compare our method with semi-supervised parsers such as Koo et al. (2008)’s semi-sup and Suzuki et al. (2009), because ours does not use additional unlabeled data for training. The model trained from unlabeled data can be easily incorporated into our reranking framework. We plan to investigate semi-supervised learning in future work. Table 9: Examples of outputs for input sentence No.148 and No.283 in section 23 from baseline and variational reranking parsers. The underlined portions show the effect of the grandsibling model. sent (No.148) A quick turnaround is crucial to Quantum because its cash requirements remain heavy . correct 3 3 4 0 4 5 6 4 11 11 12 8 12 4 b"
D11-1137,P09-1019,0,0.105002,"locally and globally appropriate candidate from a forest. Table 7 shows the parsing time (on 2.66GHz Quad-Core Xeon) of the baseline k-best, generative reranking and variational reranking parsers (java implemented). The variational reranking parser contains the following procedures. 1. 2. 3. 4. k-best forest creation (baseline) Estimation of variational model Forest pruning Search with the third-order model Our reranking parser incurred little overhead to the Table 5: The comparison of the decoding frameworks: MBR decoding seeks a candidate which has the highest accuracy scores over a forest (Kumar et al., 2009). Variational decoding is performed based on Eq.8. XX XXX Eval Unlabeled XXX Decoding XX baseline 91.9 MBR (8-best forest) 91.99 Variational (8-best forest) 92.17 Table 7: The parsing time (CPU second per sentence) and accuracy score of the baseline k-best, generative reranking and variational reranking parsers k baseline generative variational 2 0.09 (91.9) +0.03 (92.67) +0.05 (92.76) 4 0.1 (91.9) +0.05 (92.68) +0.09 (92.81) 8 0.13 (91.9) +0.06 (92.72) +0.11 (92.87) 16 0.18 (91.9) +0.07 (92.75) +0.12 (92.89) 32 0.29 (91.9) +0.07 (92.73) +0.13 (92.89) 64 0.54 (91.9) +0.08 (92.72) +0.15 (92.87)"
D11-1137,P09-1067,0,0.366974,"hird-order structure, therefore, its non-locality makes it difficult to perform the reranking with an usual 1-best Viterbi search. To solve this problem, we also propose a new search algorithm, which is inspired by the third-order dynamic programming parsing algorithm (Koo and Collins, 2010). This algorithm enables us an exact 1-best reranking without any approximation. We summarize our contributions in this paper as follows. • To extend k-best to forest generative reranking. • We introduce variational reranking which is a combination approach of generative reranking and variational decoding (Li et al., 2009). • To obtain 1-best tree in the reranking stage, we Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1479–1488, c Edinburgh, Scotland, UK, July 27–31, 2011. 2011 Association for Computational Linguistics .top.0,8 propose an exact 1-best search algorithm with the third-order model. In experiments on English Penn Treebank data, we show that our proposed methods bring significant improvement to dependency parsing. Moreover, our variational reranking framework achieves consistent improvement, compared to conventional approaches, such as simple k-best a"
D11-1137,P05-1010,0,0.0396665,"n rule to dependency parsing. For dependency parsing, we can choose to model q ∗ as the tri-sibling and grandsibling generative models in section 3. 2 In case of dependency parsing, Titov and Henderson (2006) proposed that a loss function is simply defined using a dependency attachment score. 3 In SMT, a marginalization of all derivations which yield a paticular translation needs to be carried out for each translation. This makes the MAP decoding NP-hard in SMT. This variational approximate framework can be applied to other tasks collapsing spurious ambiguity, such as latent-variable parsing (Matsuzaki et al., 2005). Algorithm 2 DP-ML Estimation(HG(x)) 100 1: run inside and outside algorithm on HG(x) 2: for v ∈ V do 3: for e ∈ IE(v) do 4: ctsib = pe · α(v)/β(top) 5: for u ∈ tails(e) do 6: ctsib = ctsib · β(u) 7: for e′ ∈ IE(u) do 8: cgsib = pe · pe′ · α(v)/β(top) 9: for u′ ∈ tails(e)  u do 10: cgsib = cgsib · β(u′ ) 11: for u′′ ∈ tails(e′ ) do 12: cgsib = cgsib · β(u′′ ) 13: for u′′ ∈ tails(e′ ) do 14: c2 (u′′ |C(u′′ ))+ = cgsib 15: c2 (C(u′′ ))+ = cgsib 16: for u ∈ tails(e) do 17: c1 (u|C(u))+ = ctsib 18: c1 (C(u))+ = ctsib 19: MLE estimate q1∗ , q2∗ using formula Eq.14 = Unlabeled Accuracy 98 k=100 97"
D11-1137,E06-1011,0,0.138728,"b .sib .v g.. .h .sib .v Figure 2: The left side denotes tri-sibling structure and the right side denotes grandsibling structure. Table 3: A summarization of the model factorization and order first-order second-order (sibling) third-order (tri-sibling) third-order (grandsibling) McDonald et al. (2005) Eisner (1996a) McDonald et al. (2005) tri-sibling model Model 2 (Koo and Collins, 2010) grandsibling model (Sangati et al., 2009) Model 1 (Koo and Collins, 2010) 3.2 Exact Search Algorithm Our baseline discriminative model uses first- and second-order features provided in (McDonald et al., 2005; McDonald and Pereira, 2006). Therefore, both our tri-sibling model and baseline discriminative model integrate local features that are factored in one hyperedge. On the other hand, the grandsibling model has non-local features because the grandparent is not factored in one hyperedge. We summarize the order of each model in Table 3. Our reranking models are generative versions of Koo and Collins (2010)’s third-order factorization model. Non-locality of weight function makes it difficult to perform the search of Eq.8 with an usual exact Viterbi 1-best algorithm. One solution to resolve the intractability is an approximate"
D11-1137,P05-1012,0,0.710609,"g 2-nd term wt(h),t(sib),d 3-rd term wt(v),t(h),t(sib),d wt(h),wt(sib),t(tsib),d t(h),t(sib),d t(v),t(h),t(sib),d wt(h),wt(sib),t(g),d t(h),t(sib),d t(v),t(h),t(sib),d t(h),wt(sib),t(tsib),d wt(h),t(sib),t(tsib),d t(h),t(sib),t(tsib),d — — — — — — t(h),wt(sib),t(g),d wt(h),t(sib),t(g),d t(h),t(sib),t(g),d — — .. h .tsib .sib .v g.. .h .sib .v Figure 2: The left side denotes tri-sibling structure and the right side denotes grandsibling structure. Table 3: A summarization of the model factorization and order first-order second-order (sibling) third-order (tri-sibling) third-order (grandsibling) McDonald et al. (2005) Eisner (1996a) McDonald et al. (2005) tri-sibling model Model 2 (Koo and Collins, 2010) grandsibling model (Sangati et al., 2009) Model 1 (Koo and Collins, 2010) 3.2 Exact Search Algorithm Our baseline discriminative model uses first- and second-order features provided in (McDonald et al., 2005; McDonald and Pereira, 2006). Therefore, both our tri-sibling model and baseline discriminative model integrate local features that are factored in one hyperedge. On the other hand, the grandsibling model has non-local features because the grandparent is not factored in one hyperedge. We summarize the"
D11-1137,D08-1022,0,0.0136474,"ctsib as the posterior weight for computing expected count c1 of events in the tri-sibling model q1∗ . Lines 16-18 compute c1 for all events occuring in a hyperedge e. The expected count c2 needed for the estimation of grandsibling model q2∗ is extracted in lines 7-15. c2 for a grandsibling model must be extracted over two hyperedges e and e′ because it needs grandparent information. Lines 8-12 show the algorithm to compute the posterior weight cgsib of e and e′ , which 1484 is similar to that to compute the posterior weight of rules of tree substitution grammars used in treebased MT systems (Mi and Huang, 2008). Lines 13-15 compute expected counts c2 of events occuring over two hyperedges e and e′ . Finally, line 19 estimates q1∗ and q2∗ using the form in Eq.14. Li et al. (2009) assumes n-gram locality of the forest to efficiently train the model, namely, the baseline n-gram model has larger n than that of variational n-gram model. In our case, grandsibling locality is not embedded in the forest generated from the baseline parser. Therefore, we need to reference incoming hyperedges of tail nodes in line 7. y ∗ of Eq.12 may be locally appropriate but globally inadequate because q ∗ only approximates"
D11-1137,P03-1021,0,0.0907227,"e show the reductions list for each term of two models in Table 2. The usage of reductions list is identical to Eisner (1996a) and readers may refer to it for further details. The final prediction is performed using a loglinear interpolated model. It interpolates the baseline discriminative model and two (tri-sibling and grandsibling) generative models. yˆ = argmax 2 ∑ log qn (top(y))θn y∈G(x) n=1 + log p(y|x)θbase (8) (5) where θ are parameters to adjust the weight of each = q1 (dist(v, h), wrd(v), tag(v)|h, sib, tsib, dir) term in prediction. These parameters are tuned using MERT algorithm (Och, 2003) on development data = q1 (tag(v)|h, sib, tsib, dir) using a criterion of accuracy maximization. The rea×q1 (wrd(v)|tag(v), h, sib, tsib, dir) son why we chose MERT is that it effectively tunes ×q1 (dist(v, h)|wrd(v), tag(v), h, sib, tsib, dir) dense parameters with a line search algorithm. 1481 q1 (v|h, sib, tsib, dir) Table 2: Reduction lists for tri-sibling and grandsibling models: wt(), w() and t() mean word and POS-tag, word, POS-tag for a node. d indicates the direction. The first reduction on the list keeps all or most of the original condition; later reductions throw away more and more"
D11-1137,W09-3839,0,0.304606,"achieves significant improvement when compared with conventional approaches. 1 Introduction Recently, much of research on statistical parsing has been focused on k-best (or forest) reranking (Collins, 2000; Charniak and Johnson, 2005; Huang, 2008). Typically, reranking methods first generate a list of top-k candidates (or a forest) from a baseline system, then rerank the candidates with arbitrary features that are intractable within the baseline system. In the reranking framework, the baseline system is usually modeled with a generative model, and a discriminative model is used for reranking. Sangati et al. (2009) reversed the usual order of the two models for dependency parsing by employing a generative model to rescore the k-best candidates provided by a discriminative model. They use a variant of Eisner’s generative model C (Eisner, 1996b; 1479 Eisner, 1996a) for reranking and extend it to capture higher-order information than Eisner’s second-order generative model. Their reranking model showed large improvements in dependency parsing accuracy. They reported that the discriminative model is very effective at filtering out bad candidates, while the generative model is able to further refine the selec"
D11-1137,D09-1058,0,0.0295312,"scores improved by the grandsibling model. For example, the dependency relationship from Verb to Noun phrase was corrected by our proposed model. On the other hand, many errors remain still in 1486 Table 10 shows the comparison of the performance of variational reranking (16-best forests) with that of other systems. Our method outperforms supervised parsers with second-order features, and achieves comparable results compared to a parser with thirdorder features (Koo and Collins, 2010). We can not directly compare our method with semi-supervised parsers such as Koo et al. (2008)’s semi-sup and Suzuki et al. (2009), because ours does not use additional unlabeled data for training. The model trained from unlabeled data can be easily incorporated into our reranking framework. We plan to investigate semi-supervised learning in future work. Table 9: Examples of outputs for input sentence No.148 and No.283 in section 23 from baseline and variational reranking parsers. The underlined portions show the effect of the grandsibling model. sent (No.148) A quick turnaround is crucial to Quantum because its cash requirements remain heavy . correct 3 3 4 0 4 5 6 4 11 11 12 8 12 4 baseline 3 3 4 0 4 5 6 4 11 11 8 8 12"
D11-1137,C10-1123,0,0.0187849,"using G(x), the conditional probability p(y|x) is typically derived as follows: p(y|x) = eγ·s(x,y) eγ·s(x,y) =∑ γ·s(x,y) Z(x) y∈G(x) e (2) where s(x, y) is the score function shown in Eq.1 and γ is a scaling factor to adjust the sharpness of the distribution and Z(x) is a normarization factor. 2.1 Hypergraph Representation We propose to encode many hypotheses in a compact representation called dependency forest. While there may be exponentially many dependency trees, the forest represents them in polynomial space. A dependency forest (or tree) can be defined as a hypergraph data strucure HG (Tu et al., 2010). Figure 1 shows an example of a hypergraph for a dependency tree. A shaded hyperedge e is defined as the following form: e : ⟨(I1,2 , girl3,5 , with5,8 ), saw1,8 ⟩. 1480 . .. .e . .saw1,8 . :V ... . . g. irl3,5 . :N .I1,2.:N . . . . . . . . . . . .a3,4.:D . . . . .with5,8 . :P . . . 6,8 :N . . .telescope . . .a .:D . . . . . 6,7 Figure 1: An example of dependency tree for a sentence “I saw a girl with a telescope”. The node saw1,8 is a head node of e. The nodes, I1,2 , girl3,5 and with5,8 , are tail nodes of e. The hyperedge e is an incoming edge for saw1,8 and outgoing edge for each of I1,2"
D11-1137,W03-3023,1,0.78739,"tion of variational decoding and generative reranking. We call this framework variational reranking. Table 4: The statistics of forests and 20-best lists on development data: this shows the average number of hyperedges and nodes per sentence and oracle scores. forest 20-best pruning threshold ρ = 10−3 — ave. num of hyperedges 180.67 255.04 ave. num of nodes 135.74 491.42 oracle scores 98.76 96.78 5 Experiments Experiments are performed on English Penn Treebank data. We split WSJ part of the Treebank into sections 02-21 for training, sections 22 for development, sections 23 for testing. We use Yamada and Matsumoto (2003)’s head rules to convert phrase structure to dependency structure. We obtain k-best lists and forests generated from the baseline discriminative model which has the same feature set as provided in (McDonald et al., 2005), using the secondorder Eisner algorithms. We use MIRA for training as it is one of the learning algorithms that achieves the best performance in dependency parsing. We set the scaling factor γ = 1.0. We also train a generative reranking model from the training data. To reduce the data sparseness problem, we use the back-off strategy proposed in (Eisner, 1996a). Parameters θ ar"
D19-5902,maekawa-etal-2000-spontaneous,0,0.0568003,"st by Semantic Principles’. 1 Introduction Compiling a lexicon is difficult work. In the lexicography field, there are two main types of methodology that are utilized to compile lexicons. One is a corpus-based methodology, which supports the objectivity of the language resources and results. This methodology requires large-scale, balanced corpora to function, which do exist in several languages; for instance, there are several corpus databases for the Japanese language, such as the ‘Balanced Corpus of Contemporary Written Japanese’ (Maekawa et al., 2014), the ‘Corpus of Spontaneous Japanese’ (Maekawa et al., 2000) and the ‘NINJAL Web Japanese Corpus’ (Asahara et al., 2014). In contrast to the corpusbased lexicography, the intuition-based method is more rooted in the subjective perspective of the lexicographer. Nowadays, however, we can perform large-scale experiments that gather enough crowdsourced subjective perspectives to constitute objective linguistic data on individual words. Generally, a lexicon covers several layers of linguistic features, such as pronunciation, morphological information, part-of-speech or word class, • We compiled a word familiarity rate database for thesaurus entries. • We us"
I05-1050,J90-1003,0,0.293839,"h these two sub-tasks simultaneously, using supervised machine learning. The third problem we tackle (§3.3) is estimation of the part of speech of MWEs. This problem is also solved using supervised machine learning. In this research we limit ourselves to MWEs containing only two words (i.e. bigrams). In the future, we plan to generalize the method so that it works with MWEs of arbitrary length. 2 Related Work Collocation extraction has been covered extensively in the literature. One of the earliest attempts to automatically extract collocations from a corpus was undertaken by Church and Hanks [1]. The statistical measure they used to identify collocations was based on mutual information. Smadja [2] developed a tool called Xtract for the extraction of collocations. His deﬁnition of a collocation diﬀered slightly from that of Church and Hanks because he claimed expressions such as doctors and nurses are not real collocations, just words related by virtue of their shared domain or semantics. Thanopoulos, Fakotakis and Kokkinakis in [3] reviewed the statistical measures most frequently used for collocation extraction, and evaluated them by comparing their performance with that of two new"
I05-1050,J93-1007,0,0.0755391,".3) is estimation of the part of speech of MWEs. This problem is also solved using supervised machine learning. In this research we limit ourselves to MWEs containing only two words (i.e. bigrams). In the future, we plan to generalize the method so that it works with MWEs of arbitrary length. 2 Related Work Collocation extraction has been covered extensively in the literature. One of the earliest attempts to automatically extract collocations from a corpus was undertaken by Church and Hanks [1]. The statistical measure they used to identify collocations was based on mutual information. Smadja [2] developed a tool called Xtract for the extraction of collocations. His deﬁnition of a collocation diﬀered slightly from that of Church and Hanks because he claimed expressions such as doctors and nurses are not real collocations, just words related by virtue of their shared domain or semantics. Thanopoulos, Fakotakis and Kokkinakis in [3] reviewed the statistical measures most frequently used for collocation extraction, and evaluated them by comparing their performance with that of two new measures of their own. Their ﬁrst novel measure, Mutual Dependency (MD) is pointwise mutual information"
I05-1050,thanopoulos-etal-2002-comparative,0,0.0603543,"covered extensively in the literature. One of the earliest attempts to automatically extract collocations from a corpus was undertaken by Church and Hanks [1]. The statistical measure they used to identify collocations was based on mutual information. Smadja [2] developed a tool called Xtract for the extraction of collocations. His deﬁnition of a collocation diﬀered slightly from that of Church and Hanks because he claimed expressions such as doctors and nurses are not real collocations, just words related by virtue of their shared domain or semantics. Thanopoulos, Fakotakis and Kokkinakis in [3] reviewed the statistical measures most frequently used for collocation extraction, and evaluated them by comparing their performance with that of two new measures of their own. Their ﬁrst novel measure, Mutual Dependency (MD) is pointwise mutual information minus self-information. The second measure attempts to introduce a slight frequency bias by combining the t-score with mutual dependency. Although frequency alone is not suﬃcient evidence of collocational status, they argue that candidate collocations that have a high frequency are more likely to be valid than those that are very rare. Whi"
I05-1050,W02-2001,0,0.016545,"eceived attention over a number of years, MWEs have only relatively recently emerged as a research topic within natural language processing. In consequence, there are relatively few articles speciﬁcally about MWEs. Sag et al. in [4] gave a linguistic categorisation of the diﬀerent types of MWE, and described ways of representing them eﬃciently within a computational framework2. Although MWEs as a whole have yet to receive widespread investigation, attention has been paid to speciﬁc types of MWE. For example, verb-particle constructions have been the subject of several studies (see for example [5] and [6]). 2 Head-driven Phrase Structure Grammar (HPSG). Automatic Extraction of Fixed Multiword Expressions 3 569 Method In order to extract information about ﬁxed MWEs from a corpus, we use a three stage process. In the ﬁrst stage we identify a list of candidate MWEs based on the statistical behaviour of the tokens in the corpus. Two words whose probability of appearing together is greater than that which would be expected based on their individual frequencies, are considered to constitute a potential MWE and are extracted for later processing. In other words, stage one is collocation extra"
I05-1050,W03-1808,0,0.0167121,"attention over a number of years, MWEs have only relatively recently emerged as a research topic within natural language processing. In consequence, there are relatively few articles speciﬁcally about MWEs. Sag et al. in [4] gave a linguistic categorisation of the diﬀerent types of MWE, and described ways of representing them eﬃciently within a computational framework2. Although MWEs as a whole have yet to receive widespread investigation, attention has been paid to speciﬁc types of MWE. For example, verb-particle constructions have been the subject of several studies (see for example [5] and [6]). 2 Head-driven Phrase Structure Grammar (HPSG). Automatic Extraction of Fixed Multiword Expressions 3 569 Method In order to extract information about ﬁxed MWEs from a corpus, we use a three stage process. In the ﬁrst stage we identify a list of candidate MWEs based on the statistical behaviour of the tokens in the corpus. Two words whose probability of appearing together is greater than that which would be expected based on their individual frequencies, are considered to constitute a potential MWE and are extracted for later processing. In other words, stage one is collocation extraction. I"
I05-1050,J93-1003,0,0.045184,"ting in a classiﬁer capable of distinguishing between, on the one hand, true MWEs, and on the other, non-MWEs and pseudo-MWEs. In the ﬁnal stage we use supervised machine learning to train a classiﬁer to perform MWE part of speech assignment. By examining the context surrounding an MWE, it is possible for the classiﬁer to determine the most likely part of speech for the MWE in that context. 3.1 Collocation Extraction Collocation extraction was performed using one of the statistical measures discussed in [3]. The measures we experimented with were: frequency, χ-square [7], log-likelihood ratio [8], t-score [7], mutual information (MI) [1], mutual dependency (MD – mutual information minus self-information) [3], and log-frequency biased mutual dependency (LFMD – a combination of the t-score and mutual dependency) [3]. The equations of these measures are shown in Fig. 2. We compared the resulting ranked lists of bigrams with a list of target MWEs extracted from the British National Corpus (BNC)3 . The target list was produced by starting with a list of all MWEs tagged as such in the BNC, and removing MWEs with a frequency of less than ﬁve, and MWEs with a part of speech of noun, or adject"
I05-1050,W03-3023,1,0.717499,"sed on bigrams. We hope to generalise our approach, so that MWEs of length greater than two can be extracted and assigned a part of speech. We plan to evaluate the performance of the BNC models described above on another corpus to determine their ﬂexibility. Speciﬁcally, we plan to use a corpus of North American English such as the Penn Treebank, in the hope of demonstrating the models’ ability to handle American as well as British English. We also plan to check the eﬀect on parsing accuracy of using the extracted multiword expressions in the input to a parser such as Collins’ [9] or Yamada’s [10]. 6 Conclusion In this research we aimed to identify a method for the automatic extraction and part of speech estimation of ﬁxed MWEs. Knowledge about ﬁxed MWEs has Automatic Extraction of Fixed Multiword Expressions 575 the potential to improve the accuracy of numerous natural language processing applications. Generating such a list therefore represents an important natural language processing task. Our method uses a collocation measure to produce a list of candidate bigrams. These candidates are then used to select training data for a classiﬁer. The trained classiﬁer was successfully able to"
I05-1059,C94-1048,0,0.120434,"Missing"
I05-1059,2001.mtsummit-papers.10,0,0.178013,"Missing"
I05-1059,Y04-1018,0,0.0617146,"Missing"
I05-3003,P01-1017,0,0.0346125,"Missing"
I05-3003,P04-1015,0,0.082201,"Missing"
I05-3003,C04-1040,0,0.050351,"Missing"
I05-3003,J91-4001,0,0.122637,"Missing"
I05-3003,C04-1010,0,0.192855,"Missing"
I05-3018,W04-1109,1,0.93577,"ods for Optimum Chinese Word Segmentation Masayuki Asahara Kenta Fukuoka Ai Azuma Chooi-Ling Goh Yotaro Watanabe Yuji Matsumoto Nara Institute of Science and Technology, Japan E-mail: cje@is.naist.jp Abstract Takashi Tsuzuki Matsushita Electric Industrial Co., Ltd. word classes and character classes in order to overcome the data sparse problem. The word classes are used as the hidden states in MEMM and CRF-based word segmenters. The character classes are used as the features in character-based tagging, character-based chunking and word segmentation. Model b is our previous method proposed in (Goh et al., 2004b): First, a MaxEnt classifier is used to perform character-based tagging to identify OOV words in the test data. In-vocabulary (IV) word list together with the extracted OOV word candidates is used in Maximum Matching algorithm. Overlapping ambiguity is denoted by the different outputs from Forward and Backward Maximum Matching algorithm. Finally, character-based tagging by MaxEnt classifier resolves the ambiguity. Section 2 describes Models a and c. Section 3 describes Model b. Section 4 discusses the differences among the three models. This article presents our recent work for participation"
I05-3018,Y04-1014,1,0.836321,"ods for Optimum Chinese Word Segmentation Masayuki Asahara Kenta Fukuoka Ai Azuma Chooi-Ling Goh Yotaro Watanabe Yuji Matsumoto Nara Institute of Science and Technology, Japan E-mail: cje@is.naist.jp Abstract Takashi Tsuzuki Matsushita Electric Industrial Co., Ltd. word classes and character classes in order to overcome the data sparse problem. The word classes are used as the hidden states in MEMM and CRF-based word segmenters. The character classes are used as the features in character-based tagging, character-based chunking and word segmentation. Model b is our previous method proposed in (Goh et al., 2004b): First, a MaxEnt classifier is used to perform character-based tagging to identify OOV words in the test data. In-vocabulary (IV) word list together with the extracted OOV word candidates is used in Maximum Matching algorithm. Overlapping ambiguity is denoted by the different outputs from Forward and Backward Maximum Matching algorithm. Finally, character-based tagging by MaxEnt classifier resolves the ambiguity. Section 2 describes Models a and c. Section 3 describes Model b. Section 4 discusses the differences among the three models. This article presents our recent work for participation"
I05-3018,N01-1025,1,0.86496,"Missing"
I05-3018,W04-3230,1,0.871441,"fferty et al., 2001). The chunker annotates BIO position tags: “B” stands for ’the first character of an OOV word’; “I” stands for ’other characters in an OOV word’; “O” stands for ’a character outside an OOV word’. The features used in the two chunkers are the characters, the character classes and the information of other characters in five-character window size. The word sequence output by the MEMM-based word segmenter is converted into character sequence with BIES position tags and the word classes. The position tags 135 Final word segmentation is carried out by a CRF-based word segmenter (Kudo and Matsumoto, 2004) (Peng and McCallum, 2004). The word trellis is composed by the similar method with MEMM-based word segmenter. Though state transition probabilities are estimated in the case of MaxEnt framework, the probabilities are normalized in the whole sentence in CRFbased method. CRF-based word segmenter is robust to length-bias problem (Kudo and Matsumoto, 2004) by the global normalization. We will discuss the lengthbias problem in section 4. 2.5 Note on MSR data Unfortunately, we could not complete Models a and c for the MSR data due to time constraints. Therefore, we submitted the following 2 fragmen"
I05-3018,C04-1067,0,0.0620608,"cause the precision of 136 OOV word extraction becomes higher. Other types of OOV word extraction methods should be introduced. For example, (Uchimoto et al., 2001) embeded OOV models in MEMM-based word segmenter (with POS tagging). Less than six-character substrings are extracted as the OOV word candidates in the word trellis. (Peng and McCallum, 2004) proposed OOV word extraction methods based on CRF-based word segmenter. Their CRF-based word segmenter can compute a confidence in each segment. The high confident segments that are not in the IV word list are regarded as OOV word candidates. (Nakagawa, 2004) proposed integration of word and OOV word position tag in a trellis. These three OOV extraction method are different from our methods – character-based tagging. Future work will include implementation of these different sorts of OOV word extraction modules. Length bias problem means the tendency that the locally normalized Markov Model family prefers longer words. Since choosing the longer words reduces the number of words in a sentence, the state-transitions are reduced. The less the state-transitions, the larger the likelihood of the whole sentence. Actually, the lengthbias reflects the rea"
I05-3018,C04-1081,0,0.515471,"hunker annotates BIO position tags: “B” stands for ’the first character of an OOV word’; “I” stands for ’other characters in an OOV word’; “O” stands for ’a character outside an OOV word’. The features used in the two chunkers are the characters, the character classes and the information of other characters in five-character window size. The word sequence output by the MEMM-based word segmenter is converted into character sequence with BIES position tags and the word classes. The position tags 135 Final word segmentation is carried out by a CRF-based word segmenter (Kudo and Matsumoto, 2004) (Peng and McCallum, 2004). The word trellis is composed by the similar method with MEMM-based word segmenter. Though state transition probabilities are estimated in the case of MaxEnt framework, the probabilities are normalized in the whole sentence in CRFbased method. CRF-based word segmenter is robust to length-bias problem (Kudo and Matsumoto, 2004) by the global normalization. We will discuss the lengthbias problem in section 4. 2.5 Note on MSR data Unfortunately, we could not complete Models a and c for the MSR data due to time constraints. Therefore, we submitted the following 2 fragmented models: Model a for MS"
I05-3018,W01-0512,0,0.018108,"but the precision is low. We tried to refine OOV extraction by voting and merging (Model a and c). However, the ROOV of Models a and c are not as good as that of Model b. Figure 1 shows type-precision and type-recall of each OOV extraction modules. While voting helps to make the precision higher, voting deteriorates the recall. Defining some hand written rules to prune false OOV words will help to improve the IV word segmentation (Goh et al., 2004b), because the precision of 136 OOV word extraction becomes higher. Other types of OOV word extraction methods should be introduced. For example, (Uchimoto et al., 2001) embeded OOV models in MEMM-based word segmenter (with POS tagging). Less than six-character substrings are extracted as the OOV word candidates in the word trellis. (Peng and McCallum, 2004) proposed OOV word extraction methods based on CRF-based word segmenter. Their CRF-based word segmenter can compute a confidence in each segment. The high confident segments that are not in the IV word list are regarded as OOV word candidates. (Nakagawa, 2004) proposed integration of word and OOV word position tag in a trellis. These three OOV extraction method are different from our methods – character-ba"
I05-3018,W02-1815,0,0.150494,"mplete Models a and c for the MSR data due to time constraints. Therefore, we submitted the following 2 fragmented models: Model a for MSR data is MEMM-based word segmenter with OOV word list by voting; Model c for MSR data is CRF-based word segmenter with no OOV word candidate. 3 Model b Model b uses a different approach. First, we extract the OOV words using a MaxEnt classifier with only the character as the features. We did not use the character classes as the features. Each character is assigned with BIES position tags. Word segmentation by characterbased tagging is firstly introduced by (Xue and Converse, 2002). In encoding, we extract characters within five-character window size for each character position in the training data as the features for the classifier. In decoding, the BIES position tag is deterministically annotated character by character in the test data. The words that appear only in the test data are treated as OOV word candidates. We can obtain quite high unknown word recall with this model but the precision is a bit low. However, the following segmentation model will try to eliminate some false unknown words. In the next step, we append OOV word candidates into the IV word list extr"
I08-1062,E06-1002,0,0.11292,"Missing"
I08-4005,W04-3205,0,0.106072,"Missing"
I08-4005,P04-1074,0,0.251641,"ation extraction are still limited. Temporal relation extraction includes the following issues: identifying events, anchoring events on the timeline, ordering events, and reasoning with contextually underspecified temporal expressions. To extract temporal relations, several knowledge resources are necessary, such as tense and aspect of verbs, temporal adverbs, and world knowledge (Mani, et al., 2006). In English, TimeBank (Pustejovsky, et al., 2006), a temporal information annotated corpus, is available to machine learning approaches for automatically extracting temporal relation. In Chinese, Li (2004) proposed a machine learning based method for temporal relation identification, but they considered the relation between adjacent verbs in a small scale corpus. There is no publicly available Chinese resource for temporal information processing. We proposed (Cheng, 2007) a dependency structure based method to annotate temporal relations manually on a limited set of event pairs and extend the relations using inference rules. In our previous research, the dependency structure helps to detect subordinate and coordinate structures in sentences. Our proposed criteria can reduce the manual effort fo"
I08-4005,S07-1014,0,\N,Missing
I08-4008,O03-4001,0,0.0541009,"Missing"
I08-4008,O97-4003,0,0.0604099,"Missing"
I08-4008,C00-1026,0,0.0442978,"Missing"
I08-4008,W02-1811,0,\N,Missing
I08-4008,Y06-1044,1,\N,Missing
I11-1126,I05-1005,0,0.0251042,"ata, it extracts more numbers of ga-case than the others. However, ga-case is often the most important for PA relation extraction and sometimes called indispensable case. Our method can extract such important information better than previous work. Although our model did not exploit large-scale corpora, our results are competitive to the results of Imamura et al. (2009). By global optimization in a sentence, our Global model overcame the lack of semantic features and successfully identiﬁed “����” as wo-case of “ ����”. This PA relation is in a relative clause and often hard to identify. Though Abekawa and Okumura (2005) resolved Japanese PA relations in relative clauses by exploiting large-scale corpora, our Markov Logic approach handles this problem by global optimization. Moreover, in global model, � � delete(1), delete(2), delete(7) are also output and “��” and “��” did not become argument candidates. As a result, “��������” was correctly selected as a ga-case of “��”. Error Analysis 6 Conclusion (this) (reason) (Gray Wolf) (revival in the US) �� �� � ���� ���� 1 2 3 4 (plan) (FWS) (in Canada) (capture) ��� �������� ���� ���� 7 6 8 5 (transport by air) (wild) (twelve wolves) ��� ���� �� � 9 10 11 (Form th"
I11-1126,Y01-1001,0,0.0283936,"arguments for the predicate, that is, a nominative case role (ga) is “� (He)” and a dative case role (ni) is “��� (library)”. 1 Introduction Predicate-argument (PA) relation extraction is one of the challenging problems in Natural Language Processing. The analysis extracts semantic information such as “who did what to whom”, which is often useful to various applications like information extraction, document summarization, and machine translation. Predicate-argument relation extraction is often called semantic role labeling. In English, it has been researched on large corpora such as FrameNet (Fillmore et al., 2001) and PropBank (Palmer et al., 2005). CoNLL Shared Task 2008 (Surdeanu et al., 2008) is a representative work of semantic role labeling based on these corpora. Japanese PA relation extraction is a kind of semantic role labeling but an argument is often called case. A typical example of Japanese PA reIn Japanese, Taira et al. (2008) and Imamura et al. (2009) tackled PA relation extraction on NAIST Text Corpus (Iida et al., 2007). They created three separated models corresponding to each of the case; ga (Nominative), wo (Accusative), and ni (Dative). Even though some English semantic role labeler"
I11-1126,P06-1079,1,0.773228,"not an argument. If a is an argument of p with the role r then neither p nor a is deleted. ga wo ni Dep. 13,086 5,192 3,645 Zero-Intra 4,556 376 231 Total 17,642 5,568 3,876 Table 5: Statistics in Evaluation Data isArg delete role Local R 71.4 90.4 72.5 F 75.1 88.4 78.8 P 94.6 94.3 85.5 Global R 84.2 97.9 77.7 F 89.1 96.1 81.4 Table 6: Local vs Global lations (Dep.) are much more common than intra-sentential zero-anaphoric PA relations (ZeroIntra). However, in Japanese, we often ﬁnd zero-anaphoric PA relations called case ellipsis. More detailed descriptions of PA relation types are shown in (Iida et al., 2006). Note that we target only PA relations which occur in a sentence (intra-sentential PA relations). The joint approach using Markov Logic is computationally hard even if it targets only intra-sentential PA relations. Therefore, extraction of inter-sentential PA relations which are crossing sentence boundaries is intractable. Moreover, our approach ﬁnds the most optimized PA assignments in a whole sentence. To keep consistency in a sentence, we delete the sentences which have inter-sentential PA relations. For extracting features, we exploit the annotation of Kyoto Text Corpus as the POS and the"
I11-1126,W07-1522,1,0.932493,"ine translation. Predicate-argument relation extraction is often called semantic role labeling. In English, it has been researched on large corpora such as FrameNet (Fillmore et al., 2001) and PropBank (Palmer et al., 2005). CoNLL Shared Task 2008 (Surdeanu et al., 2008) is a representative work of semantic role labeling based on these corpora. Japanese PA relation extraction is a kind of semantic role labeling but an argument is often called case. A typical example of Japanese PA reIn Japanese, Taira et al. (2008) and Imamura et al. (2009) tackled PA relation extraction on NAIST Text Corpus (Iida et al., 2007). They created three separated models corresponding to each of the case; ga (Nominative), wo (Accusative), and ni (Dative). Even though some English semantic role labeler apply global models, most of them solve problems on a per-predicate basis (Toutanova et al., 2008; Watanabe et al., 2010). In this work, we propose an approach to Japanese PA relation extraction on a per-sentence basis and utilize important dependencies between one PA relation and another in the same sentence. In order to use such dependencies as global constraints, we apply a Markov Logic approach to Japanese PA relation ext"
I11-1126,P09-2022,0,0.132113,"applications like information extraction, document summarization, and machine translation. Predicate-argument relation extraction is often called semantic role labeling. In English, it has been researched on large corpora such as FrameNet (Fillmore et al., 2001) and PropBank (Palmer et al., 2005). CoNLL Shared Task 2008 (Surdeanu et al., 2008) is a representative work of semantic role labeling based on these corpora. Japanese PA relation extraction is a kind of semantic role labeling but an argument is often called case. A typical example of Japanese PA reIn Japanese, Taira et al. (2008) and Imamura et al. (2009) tackled PA relation extraction on NAIST Text Corpus (Iida et al., 2007). They created three separated models corresponding to each of the case; ga (Nominative), wo (Accusative), and ni (Dative). Even though some English semantic role labeler apply global models, most of them solve problems on a per-predicate basis (Toutanova et al., 2008; Watanabe et al., 2010). In this work, we propose an approach to Japanese PA relation extraction on a per-sentence basis and utilize important dependencies between one PA relation and another in the same sentence. In order to use such dependencies as global c"
I11-1126,kawahara-etal-2002-construction,0,0.0129164,"selectional preference features obtained from large-scale unlabelled data. In qualitative analysis, we ﬁnd that our global model resolves some diﬃcult cases such as PA relations in relative clauses. The remainder of this paper is organized as follows: Section 2 describes related work; Section 3 introduces Markov Logic; Section 4 explains our proposed Markov Logic Network; Section 5 presents and discusses the experimental setting and the results; and in Section 6 we conclude and present ideas for future research. 2 Related Work In Japanese, PA annotated corpora such as Kyoto Text Corpus (KTC) (Kawahara et al., 2002) and NAIST Text Corpus (NTC) (Iida et al., 2007) have been developed and utilized. 1 CoNLL Shared Task 2009 (Hajiˇc et al., 2009) included Japanese PA relation extraction on the data from KTC. The data we used in this work is from NTC. NTC is based on the same text as KTC, which contains 38,384 sentences from 2,929 news articles. 2 The annotation in NTC has the three case roles: “ga (Nominative)”, “wo (Accusative)”, and “ni (Dative)”. The predicate-argument annotation in NTC is based on deep cases and is more diﬃcult to ana1 KTC is annotated with surface cases and NTC is annotated with deep ca"
I11-1126,N09-1018,0,0.396125,"ough some English semantic role labeler apply global models, most of them solve problems on a per-predicate basis (Toutanova et al., 2008; Watanabe et al., 2010). In this work, we propose an approach to Japanese PA relation extraction on a per-sentence basis and utilize important dependencies between one PA relation and another in the same sentence. In order to use such dependencies as global constraints, we apply a Markov Logic approach to Japanese PA relation extraction. In recent years, in English semantic role labeling, a Markov Logic model has achieved one of the state-of-theart results (Meza-Ruiz and Riedel, 2009a). With global constraints between multiple PA relations, a Markov Logic model can avoid inconsistencies between several PA relations and improve performance of extraction. In addition, we introduce new global constraints to eﬀectively delete inappropriate argument candidates which are unrelated to PA relations. We consider that extraction of PA relations and dele1125 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 1125–1133, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP Figure 2: Diﬀerence in Methods tion of the other phrases are two si"
I11-1126,W09-1213,0,0.196183,"ough some English semantic role labeler apply global models, most of them solve problems on a per-predicate basis (Toutanova et al., 2008; Watanabe et al., 2010). In this work, we propose an approach to Japanese PA relation extraction on a per-sentence basis and utilize important dependencies between one PA relation and another in the same sentence. In order to use such dependencies as global constraints, we apply a Markov Logic approach to Japanese PA relation extraction. In recent years, in English semantic role labeling, a Markov Logic model has achieved one of the state-of-theart results (Meza-Ruiz and Riedel, 2009a). With global constraints between multiple PA relations, a Markov Logic model can avoid inconsistencies between several PA relations and improve performance of extraction. In addition, we introduce new global constraints to eﬀectively delete inappropriate argument candidates which are unrelated to PA relations. We consider that extraction of PA relations and dele1125 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 1125–1133, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP Figure 2: Diﬀerence in Methods tion of the other phrases are two si"
I11-1126,J05-1004,0,0.0129451,"a nominative case role (ga) is “� (He)” and a dative case role (ni) is “��� (library)”. 1 Introduction Predicate-argument (PA) relation extraction is one of the challenging problems in Natural Language Processing. The analysis extracts semantic information such as “who did what to whom”, which is often useful to various applications like information extraction, document summarization, and machine translation. Predicate-argument relation extraction is often called semantic role labeling. In English, it has been researched on large corpora such as FrameNet (Fillmore et al., 2001) and PropBank (Palmer et al., 2005). CoNLL Shared Task 2008 (Surdeanu et al., 2008) is a representative work of semantic role labeling based on these corpora. Japanese PA relation extraction is a kind of semantic role labeling but an argument is often called case. A typical example of Japanese PA reIn Japanese, Taira et al. (2008) and Imamura et al. (2009) tackled PA relation extraction on NAIST Text Corpus (Iida et al., 2007). They created three separated models corresponding to each of the case; ga (Nominative), wo (Accusative), and ni (Dative). Even though some English semantic role labeler apply global models, most of them"
I11-1126,D08-1068,0,0.0477078,"arkov Logic (Richardson and Domingos, 2006), a combination of ﬁrstorder logic and Markov Networks. It can be understood as a formalism that extends ﬁrst-order logic to allow formulae that can be violated with some penalty. From an alternative point of view, it is an expressive template language that uses ﬁrst order logic formulae to instantiate Markov Networks of repetitive structure. In the ﬁeld of NLP, the Markov Logic approach has been applied to various tasks such as entity resolution (Singla and Domingos, 2006)�information extraction (Poon and Domingos, 2007), and coreference resolution (Poon and Domingos, 2008), among others. From a wide range of SRL languages we chose Markov Logic because it supports discriminative training (as opposed to generative SRL languages such as PRM (Koller, 1999)). Moreover, several Markov Logic software libraries exist and are freely available (as opposed to other discriminative frameworks such as Relational Markov Networks (Taskar et al., 2002)). A Markov Logic Network (MLN) M is a set of pairs (φ, w) where φ is a ﬁrst order formula and w is a real number (the formula’s weight). It deﬁnes a probability distribution over sets of ground atoms, or so-called possible worlds"
I11-1126,W08-2121,0,0.093796,"Missing"
I11-1126,D08-1055,0,0.402372,"often useful to various applications like information extraction, document summarization, and machine translation. Predicate-argument relation extraction is often called semantic role labeling. In English, it has been researched on large corpora such as FrameNet (Fillmore et al., 2001) and PropBank (Palmer et al., 2005). CoNLL Shared Task 2008 (Surdeanu et al., 2008) is a representative work of semantic role labeling based on these corpora. Japanese PA relation extraction is a kind of semantic role labeling but an argument is often called case. A typical example of Japanese PA reIn Japanese, Taira et al. (2008) and Imamura et al. (2009) tackled PA relation extraction on NAIST Text Corpus (Iida et al., 2007). They created three separated models corresponding to each of the case; ga (Nominative), wo (Accusative), and ni (Dative). Even though some English semantic role labeler apply global models, most of them solve problems on a per-predicate basis (Toutanova et al., 2008; Watanabe et al., 2010). In this work, we propose an approach to Japanese PA relation extraction on a per-sentence basis and utilize important dependencies between one PA relation and another in the same sentence. In order to use suc"
I11-1126,J08-2002,0,0.166651,", 2008) is a representative work of semantic role labeling based on these corpora. Japanese PA relation extraction is a kind of semantic role labeling but an argument is often called case. A typical example of Japanese PA reIn Japanese, Taira et al. (2008) and Imamura et al. (2009) tackled PA relation extraction on NAIST Text Corpus (Iida et al., 2007). They created three separated models corresponding to each of the case; ga (Nominative), wo (Accusative), and ni (Dative). Even though some English semantic role labeler apply global models, most of them solve problems on a per-predicate basis (Toutanova et al., 2008; Watanabe et al., 2010). In this work, we propose an approach to Japanese PA relation extraction on a per-sentence basis and utilize important dependencies between one PA relation and another in the same sentence. In order to use such dependencies as global constraints, we apply a Markov Logic approach to Japanese PA relation extraction. In recent years, in English semantic role labeling, a Markov Logic model has achieved one of the state-of-theart results (Meza-Ruiz and Riedel, 2009a). With global constraints between multiple PA relations, a Markov Logic model can avoid inconsistencies betwe"
I11-1126,P10-2018,1,0.920047,"ive work of semantic role labeling based on these corpora. Japanese PA relation extraction is a kind of semantic role labeling but an argument is often called case. A typical example of Japanese PA reIn Japanese, Taira et al. (2008) and Imamura et al. (2009) tackled PA relation extraction on NAIST Text Corpus (Iida et al., 2007). They created three separated models corresponding to each of the case; ga (Nominative), wo (Accusative), and ni (Dative). Even though some English semantic role labeler apply global models, most of them solve problems on a per-predicate basis (Toutanova et al., 2008; Watanabe et al., 2010). In this work, we propose an approach to Japanese PA relation extraction on a per-sentence basis and utilize important dependencies between one PA relation and another in the same sentence. In order to use such dependencies as global constraints, we apply a Markov Logic approach to Japanese PA relation extraction. In recent years, in English semantic role labeling, a Markov Logic model has achieved one of the state-of-theart results (Meza-Ruiz and Riedel, 2009a). With global constraints between multiple PA relations, a Markov Logic model can avoid inconsistencies between several PA relations"
I11-1126,W09-1201,0,\N,Missing
I17-1041,W13-2326,0,0.0302023,"t the same points in the segmented and unsegmented conditions to guarantee that the same number of non-space characters was shown under both conditions. The same procedure was adopted for the selfpaced reading presentation except that the chin rest was not used, and participants could move their heads freely while looking directly at the display. Doug Rohde’s Linger program Version 2.942 was used to record keyboard-press latencies while sentences were shown using a noncumulative self-paced moving-window presenta2015) presented a grammaticality detection model for machine-processed sentences. (Iida et al., 2013) presented an analysis of eye-tracking data for the annotation of predicate–argument relations. Our paper is slightly different from these preceding papers. We present a corpus-based psycholinguistic research on the relationship between reading time and syntactic/semantic categories. 3 Data and Method We used the overlaid data of BCCWJ-EyeTrack and syntactic/semantic categories, as given in Table 1. We present the data below in detail. 3.1 BCCWJ and its annotation We used BCCWJ (Maekawa et al., 2014) and its annotation data. BCCWJ is a balanced corpus of Japanese. We used newspaper articles fr"
I17-1041,W15-1814,0,0.0413024,"Missing"
I17-1041,Y17-1006,1,0.669177,"es. The results show that the bunsetsu with arguments tend to have shorter reading times than the ones without arguments. This fact supports the anti-locality (Konieczny and D¨oring, 2003) and Hale’s surprisal theory (Hale, 2001). Our current work comprises two analyses. The first one is a contrastive analysis between reading time and information structure annotation. We overlaid the annotation of information structures (Miyauchi et al., 2017) on the reading time data. The result showed that reading time can reveal the difference in whether the target nominal phrase is hearer-new or bridging (Asahara, 2017). The second one is contrastive analysis between reading time and the clause boundary category annotation. The result shows that the clause end segments tend to have shorter reading times. Furthermore, the reading time of clause boundaries vary according to the classification of the clauses. In our future work, we plan to introduce Bayesian linear mixed model (Sorensen et al., 2016) for the statistical modelling. We also hope to investigate the correlation between reading time and word familiarity rate. Word familiarity rate is the fundamental data to estimate Japanese language vocabulary eval"
I17-1041,W16-5406,1,0.908261,"eading time annotation on BCCWJ: BCCWJ-EyeTrack (Asahara et al., 2016) is available for the linguistic research community. The data in the BCCWJ enable us to perform exploratory data analysis in fair and reproducible environments. We measured the readability of humans. More concretely, we performed a contrast comparison between reading time and syntactic/semantic categories of words. We prepared the annotation 404 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 404–412, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP dency annotation(Asahara and Matsumoto, 2016) for the data to investigate the correlation between syntactic dependency attachments and reading time. Table 1: Data format of BCCWJ-EyeTrack name surface time logtime measure sample article metadata orig metadata length space type factor int num factor factor factor factor factor int factor subj setorder dependent sessionN articleN screenN lineN segmentN is first is last is second last WLSPLUWFALSE factor factor int int int int int int factor factor factor factor WLSPLUWA factor WLSPLUWB factor decription surface form reading time reading time (log) reading time type sample name article info"
I17-1041,C16-1066,1,0.89107,"Missing"
I17-1041,P16-2094,0,0.0280226,"t a specific set of linguistic phenomena but instead provides naturally occurring texts for testing diverse hypotheses. For example, (Demberg and Keller, 2008) used the corpus to test Gibson’s dependency locality theory (DLT) (Gibson, 2008) and Hale’s surprisal theory (Hale, 2001). The corpus also allows for replications to be conducted; for example, (Roland et al., 2012) concluded that previous analyses (Demberg and Keller, 2007) had been distorted by the presence of a few outlier data points. Second, we present language analyses or models with reading time or eye tracking gaze information. (Barrett et al., 2016) presented a POS tagging model with gaze patterns. (Klerke et al., Most of the studies on sentence processing by humans are based on confirmatory data analysis. The methodology involves developing a hypothesis, constructing sample sentences, including the target language phenomena, and performing a psycholinguistic experiment, such as recording reading time or event-related potentials. In recent times, the ‘Balanced Corpus of Contemporary Written Japanese’ (hereafter ‘BCCWJ’) (Maekawa et al., 2014) was compiled and published. The reading time annotation on BCCWJ: BCCWJ-EyeTrack (Asahara et al."
I17-1041,N01-1021,0,0.772932,"gazing time. 1 2 Related Work Introduction First, we present related work on eye tracking. The Dundee Eyetracking Corpus (Kennedy and Pynte, 2005) contains reading times for English and French newspaper editorials from 10 native speakers of each language that were recorded using eye-tracking equipment. The corpus does not target a specific set of linguistic phenomena but instead provides naturally occurring texts for testing diverse hypotheses. For example, (Demberg and Keller, 2008) used the corpus to test Gibson’s dependency locality theory (DLT) (Gibson, 2008) and Hale’s surprisal theory (Hale, 2001). The corpus also allows for replications to be conducted; for example, (Roland et al., 2012) concluded that previous analyses (Demberg and Keller, 2007) had been distorted by the presence of a few outlier data points. Second, we present language analyses or models with reading time or eye tracking gaze information. (Barrett et al., 2016) presented a POS tagging model with gaze patterns. (Klerke et al., Most of the studies on sentence processing by humans are based on confirmatory data analysis. The methodology involves developing a hypothesis, constructing sample sentences, including the targ"
L16-1261,W08-1301,0,0.258594,"Missing"
L16-1261,de-marneffe-etal-2014-universal,0,0.14179,"Missing"
L16-1261,den-etal-2008-proper,0,0.0441224,"Missing"
L16-1261,N06-1023,0,0.0301,"ersal part-of-speech (POS) tags (UPOS) (Petrov et al., 2012). In our research, we attempt to port the UD annotation scheme to the Japanese language. The traditional annotation schemes for the Japanese language have been uniquely developed and are markedly different from other schemes, such as Penn Treebank-style annotation. Japanese syntactic parsing trees are usually represented as unlabeled dependency structures between bunsetsu chunks (base phrase units), as found in the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the outputs of syntactic parsers (Kudo and Matsumoto, 2002; Kawahara and Kurohashi, 2006). Therefore, we must devise a method to construct word-based dependency structures that match the characteristics of the Japanese language (Uchimoto and Den, 2008; Mori et al., 2014; Tanaka and Nagata, 2015) and are able to derive the syntactic information required to assign relation types to dependencies. We describe the conversion from the Japanese POS tagset to the UPOS tagset, the adaptation of the UD annotation for Japanese syntax, and the attempt to build a UD corpus by converting the existing resources. We also address the remaining issues that may emerge when applying the UD scheme to"
L16-1261,W02-2016,1,0.600528,"al., 2014) and Google universal part-of-speech (POS) tags (UPOS) (Petrov et al., 2012). In our research, we attempt to port the UD annotation scheme to the Japanese language. The traditional annotation schemes for the Japanese language have been uniquely developed and are markedly different from other schemes, such as Penn Treebank-style annotation. Japanese syntactic parsing trees are usually represented as unlabeled dependency structures between bunsetsu chunks (base phrase units), as found in the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the outputs of syntactic parsers (Kudo and Matsumoto, 2002; Kawahara and Kurohashi, 2006). Therefore, we must devise a method to construct word-based dependency structures that match the characteristics of the Japanese language (Uchimoto and Den, 2008; Mori et al., 2014; Tanaka and Nagata, 2015) and are able to derive the syntactic information required to assign relation types to dependencies. We describe the conversion from the Japanese POS tagset to the UPOS tagset, the adaptation of the UD annotation for Japanese syntax, and the attempt to build a UD corpus by converting the existing resources. We also address the remaining issues that may emerge"
L16-1261,W04-3230,1,0.799406,"Missing"
L16-1261,maekawa-etal-2000-spontaneous,0,0.265949,"Missing"
L16-1261,mori-etal-2014-japanese,1,0.826748,"apanese language have been uniquely developed and are markedly different from other schemes, such as Penn Treebank-style annotation. Japanese syntactic parsing trees are usually represented as unlabeled dependency structures between bunsetsu chunks (base phrase units), as found in the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the outputs of syntactic parsers (Kudo and Matsumoto, 2002; Kawahara and Kurohashi, 2006). Therefore, we must devise a method to construct word-based dependency structures that match the characteristics of the Japanese language (Uchimoto and Den, 2008; Mori et al., 2014; Tanaka and Nagata, 2015) and are able to derive the syntactic information required to assign relation types to dependencies. We describe the conversion from the Japanese POS tagset to the UPOS tagset, the adaptation of the UD annotation for Japanese syntax, and the attempt to build a UD corpus by converting the existing resources. We also address the remaining issues that may emerge when applying the UD scheme to other languages. Word unit The definition of a word unit is indispensable in UD annotation, which is not a trivial question for Japanese, since a sentence is not segmented into word"
L16-1261,P11-2093,1,0.783083,"e adaptation of the UD annotation for Japanese syntax, and the attempt to build a UD corpus by converting the existing resources. We also address the remaining issues that may emerge when applying the UD scheme to other languages. Word unit The definition of a word unit is indispensable in UD annotation, which is not a trivial question for Japanese, since a sentence is not segmented into words or morphemes by white space in its orthography. Thus, we have several word unit standards that can be found in corpus annotation schemata or in the outputs of morphological analyzers (Kudo et al., 2004; Neubig et al., 2011). NINJAL1 proposed several word unit standards for Japanese corpus linguistics, such as the minimum word unit (Maekawa et al., 2000). Since 2002, the Institute has maintained a morphological information annotated lexicon, UniDic (Den et al., 2008), and has proposed three types of word unit standards: Short Unit Word (SUW): SUW is a minimal language unit that has a morphological function. SUW almost always corresponds to an entry in traditional Japanese dictionaries. Middle Unit Word (MUW): MUW is based on the rightbranching compound word construction and on phonological constructions, such as"
L16-1261,petrov-etal-2012-universal,0,0.0821258,". Keywords: typed dependencies, Short Unit Word, multiword expression, UniDic 1. Introduction 2. The Universal Dependencies (UD) project has been developing cross-linguistically consistent treebank annotation for various languages in recent years. The goal of the project is to facilitate multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective (Nivre, 2015). The annotation scheme is based on (universal) Stanford dependencies (de Marneffe and Manning, 2008; de Marneffe et al., 2014) and Google universal part-of-speech (POS) tags (UPOS) (Petrov et al., 2012). In our research, we attempt to port the UD annotation scheme to the Japanese language. The traditional annotation schemes for the Japanese language have been uniquely developed and are markedly different from other schemes, such as Penn Treebank-style annotation. Japanese syntactic parsing trees are usually represented as unlabeled dependency structures between bunsetsu chunks (base phrase units), as found in the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the outputs of syntactic parsers (Kudo and Matsumoto, 2002; Kawahara and Kurohashi, 2006). Therefore, we must devise a m"
L16-1261,W13-4913,1,0.86233,"(10) 太郎 . NOUN . Taro . cop は . ADP . -TOPIC . 学生 . . NOUN . student . だ . AUX . COPULA . ‘Taro is a student.’ 5. Corpus It is reasonable to obtain Japanese UD corpora by converting existent linguistic resources; however, a direct conversion from the major Japanese corpora such as the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) is not simple since they lack syntactic information (unlabeled) and the structure is not suitable to recover constituents (bunsetsu chunk-based dependency trees). Therefore, we first constructed conversion rules for use with Japanese constituent treebank (Tanaka and Nagata, 2013) 1655 for the Mainichi Shimbun Newspaper. The treebank was initially built by converting the Kyoto University Text Corpus and was manually annotated. The treebank has clause level annotations with syntactic function labels, e.g., syntactic role and clause type, and coordination construction, which are required for UD annotation. The treebank is composed of complete binary trees, and can be easily converted to dependency tree by adapting the head percolation rules and dependency type rules for each partial tree. The UD corpus is composed of 10,000 sentences, and it contains 267,631 tokens. The"
L16-1261,P15-2039,1,0.532985,"ve been uniquely developed and are markedly different from other schemes, such as Penn Treebank-style annotation. Japanese syntactic parsing trees are usually represented as unlabeled dependency structures between bunsetsu chunks (base phrase units), as found in the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the outputs of syntactic parsers (Kudo and Matsumoto, 2002; Kawahara and Kurohashi, 2006). Therefore, we must devise a method to construct word-based dependency structures that match the characteristics of the Japanese language (Uchimoto and Den, 2008; Mori et al., 2014; Tanaka and Nagata, 2015) and are able to derive the syntactic information required to assign relation types to dependencies. We describe the conversion from the Japanese POS tagset to the UPOS tagset, the adaptation of the UD annotation for Japanese syntax, and the attempt to build a UD corpus by converting the existing resources. We also address the remaining issues that may emerge when applying the UD scheme to other languages. Word unit The definition of a word unit is indispensable in UD annotation, which is not a trivial question for Japanese, since a sentence is not segmented into words or morphemes by white sp"
L16-1261,uchimoto-den-2008-word,0,0.0247262,"tation schemes for the Japanese language have been uniquely developed and are markedly different from other schemes, such as Penn Treebank-style annotation. Japanese syntactic parsing trees are usually represented as unlabeled dependency structures between bunsetsu chunks (base phrase units), as found in the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the outputs of syntactic parsers (Kudo and Matsumoto, 2002; Kawahara and Kurohashi, 2006). Therefore, we must devise a method to construct word-based dependency structures that match the characteristics of the Japanese language (Uchimoto and Den, 2008; Mori et al., 2014; Tanaka and Nagata, 2015) and are able to derive the syntactic information required to assign relation types to dependencies. We describe the conversion from the Japanese POS tagset to the UPOS tagset, the adaptation of the UD annotation for Japanese syntax, and the attempt to build a UD corpus by converting the existing resources. We also address the remaining issues that may emerge when applying the UD scheme to other languages. Word unit The definition of a word unit is indispensable in UD annotation, which is not a trivial question for Japanese, since a sentence is not"
L18-1162,Y15-1005,1,0.771566,". Generally, WSD using supervised learning can achieve high accuracy rates, but requires substantial manual effort due to the need for a sufficient amount of manually-annotated training data. On the other hand, unsupervised learning does not need such manual input, but it is difficult to obtain as high an accuracy rate as with the supervised learning. Many WSD methods have been proposed. WLSP article numbers or hypernyms of target words obtained from the WLSP are often used as supervised learning features. Vu and Parker (2016) proposed the idea of K-embeddings for learning concept embeddings. Komiya et al. (2015) proposed a surrounding word sense model for Japanese allwords WSD using unsupervised learning which assumes that the sense distribution of surrounding words changes depending on the sense in which a polysemous word is used. Shinnou et al. (2017b) proposed a WSD system capable of performing Japanese WSD easily using a supervised approach. 3. WSD Using Synonym Information from the WLSP We propose three WSD methods that use synonym information from the WLSP: 1) a method using only the word embeddings of synonyms, 2) a method using both the word and concept embeddings of synonyms, and 3) a method"
L18-1162,N13-1090,0,0.0942523,"r of iterations -cbow -size -window -negative -hs -sample -iter 1 200 8 25 0 1e-4 15 Table 3: Parameters Used to Generate NWJC2vec Note that we cannot know what is the most frequent sense using an unsupervised approach. We used NWJC2vec2 (Shinnou et al., 2017a) for the Japanese word embeddings. This is a set of word embeddings generated from the NWJC-2014-4Q dataset, which is an enormous Japanese corpus developed using the word2vec3 tool. Tables 2 and 3 present summary statistics for the NWJC-2014-4Q data and the parameters used to generate the word embeddings, respectively. We used word2vec (Mikolov et al., 2013c; Mikolov et al., 2013a; Mikolov et al., 2013b) to generate the concept embeddings, and the parameters used are summarized in Table 4. The window size for the surrounding word vectors was set to two, meaning four words in total. When the number of surrounding words was smaller than the window size, we used a zero vector. Therefore, the dimensionality of the surrounding word vectors was 800 when they were created using only the word embeddings, and 1,000 when both the word and concept embeddings were used. It was 200 when only the concept embeddings are used. We used KNeighborsClassifier from"
L18-1162,Y17-1052,1,0.930799,"d such manual input, but it is difficult to obtain as high an accuracy rate as with the supervised learning. Many WSD methods have been proposed. WLSP article numbers or hypernyms of target words obtained from the WLSP are often used as supervised learning features. Vu and Parker (2016) proposed the idea of K-embeddings for learning concept embeddings. Komiya et al. (2015) proposed a surrounding word sense model for Japanese allwords WSD using unsupervised learning which assumes that the sense distribution of surrounding words changes depending on the sense in which a polysemous word is used. Shinnou et al. (2017b) proposed a WSD system capable of performing Japanese WSD easily using a supervised approach. 3. WSD Using Synonym Information from the WLSP We propose three WSD methods that use synonym information from the WLSP: 1) a method using only the word embeddings of synonyms, 2) a method using both the word and concept embeddings of synonyms, and 3) a method using only the concept embeddings of synonyms. 3.1. WSD Using the Word Embeddings of Surrounding Words Since the senses of words are determined by context, such as the surrounding words, similar words are believed to 1006 have similar sets of s"
L18-1162,N16-1151,0,0.0197738,"thods can broadly be divided into two categories: supervised and unsupervised approaches. Generally, WSD using supervised learning can achieve high accuracy rates, but requires substantial manual effort due to the need for a sufficient amount of manually-annotated training data. On the other hand, unsupervised learning does not need such manual input, but it is difficult to obtain as high an accuracy rate as with the supervised learning. Many WSD methods have been proposed. WLSP article numbers or hypernyms of target words obtained from the WLSP are often used as supervised learning features. Vu and Parker (2016) proposed the idea of K-embeddings for learning concept embeddings. Komiya et al. (2015) proposed a surrounding word sense model for Japanese allwords WSD using unsupervised learning which assumes that the sense distribution of surrounding words changes depending on the sense in which a polysemous word is used. Shinnou et al. (2017b) proposed a WSD system capable of performing Japanese WSD easily using a supervised approach. 3. WSD Using Synonym Information from the WLSP We propose three WSD methods that use synonym information from the WLSP: 1) a method using only the word embeddings of synon"
L18-1287,W16-5406,1,0.730532,"D Japanese-GSD, UD JapanesePUD, and UD Japanese-Modern (Omura et al., 2017). Table 1 presents the current status of UD Japanese resources. Below, we describe these resources briefly. UD Japanese-BCCWJ is UD data based on the ‘Balanced Corpus of Contemporary Written Japanese’ (hereafter BCCWJ) (Maekawa et al., 2014). The BCCWJ defines 1 million word-scale core data samples in which the morphological information is manually annotated with three layers of word delimitations: Short Unit Word (SUW), Long Unit Word (LUW), and bunsetsu. The BCCWJ has several syntactic annotations. The BCCWJ-DepPara (Asahara and Matsumoto, 2016) is a bunsetsu-based syntactic dependency and coordinate structure annotation. The BCCWJ-PAS (Ueda et al., 2015) is a predicate-argument relation annotation with the NAIST Text Corpus annotation schema (Iida et al., 2007). We maintain conversion rules based on these annotations. UD Japanese-KTC (Tanaka et al., 2016) is based on the NTT Japanese Phrase Structure Treebank (Tanaka and Nagata, 2013) which contains the same original text as the Kyoto Text Corpus (KTC) (Kurohashi and Nagao, 2003). KTC is a bunsetsu, namely base phrase, based dependency treebank with its own word delimitation schema"
L18-1287,W07-1522,1,0.718422,"ced Corpus of Contemporary Written Japanese’ (hereafter BCCWJ) (Maekawa et al., 2014). The BCCWJ defines 1 million word-scale core data samples in which the morphological information is manually annotated with three layers of word delimitations: Short Unit Word (SUW), Long Unit Word (LUW), and bunsetsu. The BCCWJ has several syntactic annotations. The BCCWJ-DepPara (Asahara and Matsumoto, 2016) is a bunsetsu-based syntactic dependency and coordinate structure annotation. The BCCWJ-PAS (Ueda et al., 2015) is a predicate-argument relation annotation with the NAIST Text Corpus annotation schema (Iida et al., 2007). We maintain conversion rules based on these annotations. UD Japanese-KTC (Tanaka et al., 2016) is based on the NTT Japanese Phrase Structure Treebank (Tanaka and Nagata, 2013) which contains the same original text as the Kyoto Text Corpus (KTC) (Kurohashi and Nagao, 2003). KTC is a bunsetsu, namely base phrase, based dependency treebank with its own word delimitation schema and POS tagset. The NTT Japanese Phrase Structure Treebank is a phrase structure-based treebank. The word delimitation and POS are adapted to the UniDic SUW standard. The data is still in version 1.0 schema as of February"
L18-1287,C00-1060,1,0.238943,"version 1.0 schema as of February 2018. We are now modifying UD Japanese KTC from version 1.0 schema to version 2.0. UD Japanese-GSD (formerly known as UD Japanese) consists of sentences from Wikipedia. The version 2.0 of this annotated corpus was provided for the CoNLL 2017 Shared Task (Zeman et al., 2017). In the release of version 2.0, the sentences have been automatically split into words by IBM’s word segmenter. The segmentation errors were removed by adding lexicons specific to the data. In addition, the dependencies are automatically resolved using the bunsetsu-level dependency parser (Kanayama et al., 2000) with the attachment rules for functional words defined in UD Japanese (Tanaka et al., 2016). Complex sentences with parenthesis were removed to avoid parsing errors. In the version 2.1 released in November 2017, manual annotations were merged with the semi-automatic annotations to reduce remaining errors. UD Japanese-PUD was created in the same manner as UD Japanese-GSD, with the goal of maintaining consistency with UD Japanese-GSD. Since it is a parallel corpus with other languages, no sentences were removed from the corpus, including the ones containing parenthesis. UD Japanese-Modern (Omur"
L18-1287,P13-2017,0,0.1339,"Missing"
L18-1287,W13-4913,1,0.80844,"information is manually annotated with three layers of word delimitations: Short Unit Word (SUW), Long Unit Word (LUW), and bunsetsu. The BCCWJ has several syntactic annotations. The BCCWJ-DepPara (Asahara and Matsumoto, 2016) is a bunsetsu-based syntactic dependency and coordinate structure annotation. The BCCWJ-PAS (Ueda et al., 2015) is a predicate-argument relation annotation with the NAIST Text Corpus annotation schema (Iida et al., 2007). We maintain conversion rules based on these annotations. UD Japanese-KTC (Tanaka et al., 2016) is based on the NTT Japanese Phrase Structure Treebank (Tanaka and Nagata, 2013) which contains the same original text as the Kyoto Text Corpus (KTC) (Kurohashi and Nagao, 2003). KTC is a bunsetsu, namely base phrase, based dependency treebank with its own word delimitation schema and POS tagset. The NTT Japanese Phrase Structure Treebank is a phrase structure-based treebank. The word delimitation and POS are adapted to the UniDic SUW standard. The data is still in version 1.0 schema as of February 2018. We are now modifying UD Japanese KTC from version 1.0 schema to version 2.0. UD Japanese-GSD (formerly known as UD Japanese) consists of sentences from Wikipedia. The ver"
L18-1287,uchimoto-den-2008-word,0,0.0154352,"d on UniDic word boundary definition. The definition contains three layers: SUW, LUW, and bunsetsu. SUW can be produced by the morphological analyser MeCab.1 with UniDic2 LUW and bunsetsu can be produced by the pre-trained chunker Comainu.3 NINJAL4 defined five sorts of word unit definitions by operationalism. The most fine-grained unit is NINJAL Minimum Unit Word. SUW (Short Unit Word: 短単位) is constructively defined by the NINJAL Minimum Unit Word (最小単位). MUW (Middle Unit Word: 中単位) is a basic unit where a sound may change at the beginning or the ending of a word and/or an accent may change (Uchimoto and Den, 2008). The Middle Unit Word defines voiced compound (“rendaku”) (van de Weijer et al., 2005). 1825 1 taku910.github.io/mecab/ unidic.ninjal.ac.jp/ 3 osdn.net/projects/comainu/ 4 National Institute for Japanese Language and Linguistics. 2 Short Unit Word (SUW) advcl root iobj name punct iobj name 中国 . PROPN . China . . ・ . PUNCT . . . 北京 . PROPN . Beijing . . punct case 大 . NOUN . univ. . . obj aux に . ADP . -IOBJ . . 留学 . VERB . . . compound し . AUX . . study . abroad . 、 . PUNCT . . . 帰国 . VERB . return . to Japan . case 後 . NOUN . after . . case に . ADP . -IOBJ . . 双子 . NOUN . twins . . を. ADP ."
L18-1287,K17-3001,1,0.858266,"Missing"
matsumoto-etal-2006-annotated,J93-2004,0,\N,Missing
matsumoto-etal-2006-annotated,W02-2016,1,\N,Missing
matsumoto-etal-2006-annotated,P96-1025,0,\N,Missing
N03-1002,C02-1054,0,\N,Missing
N03-1002,P00-1042,0,\N,Missing
N03-1002,N01-1025,1,\N,Missing
N03-1002,W02-1036,0,\N,Missing
O05-4005,O97-1011,0,0.831118,"Missing"
O05-4005,C02-1049,0,0.178643,"Missing"
O05-4005,Y03-1009,0,0.0209175,"Missing"
O05-4005,N01-1025,1,0.865225,"Missing"
O05-4005,W03-1701,0,0.23614,"Missing"
O05-4005,C02-1055,0,0.264809,"Missing"
O05-4005,W03-1705,0,0.175471,"Missing"
O05-4005,E99-1023,0,0.099543,"Missing"
O05-4005,W03-1719,0,0.0912641,"Missing"
O05-4005,P00-1042,0,0.0566609,"Missing"
O05-4005,W02-1815,0,0.0917483,"Missing"
O05-4005,W03-1728,0,0.201181,"Missing"
O05-4005,W02-1817,0,0.218727,"Missing"
O05-4005,W03-1730,0,0.033193,"Missing"
O08-4003,O08-4003,1,0.0530913,"Missing"
O08-4003,W04-3205,0,0.164092,"Missing"
O08-4003,P04-1074,0,0.230621,"Missing"
O08-4003,P06-1095,0,0.39501,"Missing"
O08-4003,H05-1066,0,0.0712675,"Missing"
O08-4003,S07-1014,0,0.120093,"Missing"
O08-4003,I05-1061,0,0.292541,"Missing"
O14-4001,O08-4003,1,0.862921,"Missing"
O14-4001,den-etal-2008-proper,0,0.035424,"Missing"
O14-4001,C96-1079,0,0.558752,"Missing"
O14-4001,W09-3417,0,0.0419743,"Missing"
O14-4001,E14-4026,0,0.0497503,"Missing"
O14-4001,I08-7018,1,0.707483,"Missing"
O14-4001,P06-1095,0,0.102858,"Missing"
O14-4001,pustejovsky-etal-2010-iso,0,0.0822603,"Missing"
O14-4001,sekine-isahara-2000-irex,0,0.0992776,"Missing"
O14-4001,sekine-etal-2002-extended,0,0.112816,"Missing"
O14-4001,S13-2001,0,0.105086,"Missing"
O14-4001,S07-1014,0,0.109407,"Missing"
O14-4001,C10-2156,0,0.0668305,"Missing"
P03-2039,N01-1025,1,0.561182,"nization names in the corpus. For general unknown word, all words that occurred only once in the corpus were deleted from the dictionary, and were treated as unknown words. 12,730 unknown words were created under this condition. 4 Results Character types can also be used as features for chunking. However, the only information at our disposal is the possibility for a character to be a family name. The set of characters used for transliteration may also be useful for retrieving transliterated names. 2.3 Chunking with Support Vector Machine We use a Support Vector Machines-based chunker, YamCha (Kudo and Matsumoto, 2001), to extract We now present the results of our experiments in recall, precision and F-measure, as usual in such experiments. 4.1 Person Name Extraction Table 2 shows the results of person name extraction. The accuracy for retrieving person names was quite satisfiable. We could also extract names overlapping with the next known word. For example, for /v /f /v /v the sequence “ /Ng /Ag        Position i-2 i-1 i i+1 i+2 Char.     POS(best) n-S Ag-S Ng-S n-B n-E Family Name Y N N N Y Chunk B I I O O Figure 1: An illustration of chunking process ‘President Jiang Zemin’  /u   /n”"
P03-2039,W02-1817,0,0.171219,"Missing"
P03-2039,C02-1049,0,\N,Missing
P09-1046,D08-1073,0,0.602023,"Missing"
P09-1046,S07-1052,1,0.565953,"cal formulae for the Tasks A, B and C. We say that a formula is local if it only considers the hidden temporal relation of a single event-event, event-time or event-DCT pair. The formulae in the second class are global: they in4 Proposed Markov Logic Network volve two or more temporal relations at the same As stated before, our aim is to jointly tackle time, and consider Tasks A, B and C simultaneTasks A, B and C of the TempEval challenge. In ously. this section we introduce the Markov Logic NetThe local formulae are based on features emwork we designed for this goal. ployed in previous work (Cheng et al., 2007; We have three hidden predicates, corresponding Bethard and Martin, 2007) and are listed in Table 1. to Tasks A, B, and C: relE2T(e, t, r) represents the What follows is a simple example in order to illustemporal relation of class r between an event e trate how we implement each feature as a formula feature: here for every event e the decision “e happens be- (or set of formulae). fore DCT” becomes more likely with a higher weight for this feature. 7 http://alchemy.cs.washington.edu/ 8 http://code.google.com/p/thebeast/ Consider the tense-feature for Task C. For this feature we first introduce"
P09-1046,P06-1095,0,0.721207,"ions —and to the best results for the task when compared to those of other machine learning based systems. 1 Introduction Temporal relation identification (or temporal ordering) involves the prediction of temporal order between events and/or time expressions mentioned in text, as well as the relation between events in a document and the time at which the document was created. With the introduction of the TimeBank corpus (Pustejovsky et al., 2003), a set of documents annotated with temporal information, it became possible to apply machine learning to temporal ordering (Boguraev and Ando, 2005; Mani et al., 2006). These tasks have been regarded as essential for complete document understanding and are useful for a wide range of NLP applications such as question answering and machine translation. Most of these approaches follow a simple schema: they learn classifiers that predict the temporal order of a given event pair based on a set of the pair’s of features. This approach is local in the sense that only a single temporal relation is considered at a time. Learning to predict temporal relations in this isolated manner has at least two advantages over any approach that considers several temporal relatio"
P09-1046,D08-1068,0,0.140991,"Missing"
P09-1046,S07-1108,0,0.198726,"Missing"
P09-1046,S07-1014,0,0.757283,": we only need to define features (in terms of formulae) and provide input data in the correct format. 2 In particular, we do not need to manually construct ILPs for each document we encounter. Moreover, we can exploit and compare advanced methods of global inference and learning, as long as they are implemented in our Markov Logic interpreter of choice. Hence, in our future work we can focus entirely on temporal relations, as opposed to inference or learning techniques for machine learning. We evaluate our approach using the data of the “TempEval” challenge held at the SemEval 2007 Workshop (Verhagen et al., 2007). This challenge involved three tasks corresponding to three types of temporal relations: between events and time expressions in a sentence (Task A), between events of a document and the document creation time (Task B), and between events in two consecutive sentences (Task C). Our findings show that by incorporating global constraints that hold between temporal relations predicted in Tasks A, B and C, the accuracy for all three tasks can be improved significantly. In comparison to other participants of the “TempEval” challenge our approach is very competitive: for two out of the three tasks we"
P09-1046,S07-1025,0,\N,Missing
P10-2018,D09-1003,0,0.0547945,"Missing"
P10-2018,D09-1002,0,0.0294119,"Missing"
P10-2018,W08-2123,0,0.0388026,"Missing"
P10-2018,D07-1033,0,0.0290824,"pair of p and A. We deﬁne the score function for ∑ predicate-argument structures as s(p, A) = Fk ∈F Fk (x, p, A). F is a set of all the factors, Fk (x, p, A) corresponds to a particular factor in Figure 1, and gives a score to a predicate or argument label assignments. Since we use linear models, Fk (x, p, A) = w · Φk (x, p, A). 2.2 Inference The crucial point of the model is how to deal with the global factor FG , because enumerating possible assignments is too costly. A number of methods have been proposed for the use of global features for linear models such as (Daum´e III and Marcu, 2005; Kazama and Torisawa, 2007). In this work, we use the approach proposed in (Kazama and Torisawa, 2007). Although the approach is proposed for sequence labeling tasks, it 99 can be easily extended to our structured model. That is, for each possible predicate sense p of the predicate, we provide N-best argument role assignments using three local factors FP , FA and FP A , and then add scores of the global factor FG , ﬁnally select the argmax from them. In this case, the argmax is selected from |Pl |N candidates. lL+G is the loss function for the case of using both local and global features, corresponding to the constraint"
P10-2018,N09-1018,0,0.113401,"anguages without applying any feature engineering procedure. Table 3 shows the performances of predicate sense disambiguation and argument role labeling separately. In terms of sense disambiguation results, incorporating FP A and FG worked well. Although incorporating either of FP A and FG provided improvements of +0.13 and +0.18 on average, adding both factors provided improvements of +0.50. We compared the predicate sense disTable 3: Predicate sense disambiguation and argument role labeling results (average). used for FP A are inspired by formulae used in the MLN-based SRL systems, such as (Meza-Ruiz and Riedel, 2009b). We used the same feature templates for all languages. 3.2 Results Table 2 shows the results of the experiments, and also shows the results of the top 3 systems in the CoNLL-2009 Shared Task participants of the SRLonly system. By incorporating FP A , we achieved performance improvement for all languages. This results suggest that it is effective to capture local interdependencies between a predicate sense and one of its argument roles. Comparing the results with FP +FA and FP +FA +FG , incorporating FG also contributed performance improvements for all languages, especially the substantial F"
P10-2018,W09-1213,0,0.0544183,"anguages without applying any feature engineering procedure. Table 3 shows the performances of predicate sense disambiguation and argument role labeling separately. In terms of sense disambiguation results, incorporating FP A and FG worked well. Although incorporating either of FP A and FG provided improvements of +0.13 and +0.18 on average, adding both factors provided improvements of +0.50. We compared the predicate sense disTable 3: Predicate sense disambiguation and argument role labeling results (average). used for FP A are inspired by formulae used in the MLN-based SRL systems, such as (Meza-Ruiz and Riedel, 2009b). We used the same feature templates for all languages. 3.2 Results Table 2 shows the results of the experiments, and also shows the results of the top 3 systems in the CoNLL-2009 Shared Task participants of the SRLonly system. By incorporating FP A , we achieved performance improvement for all languages. This results suggest that it is effective to capture local interdependencies between a predicate sense and one of its argument roles. Comparing the results with FP +FA and FP +FA +FG , incorporating FG also contributed performance improvements for all languages, especially the substantial F"
P10-2018,W08-2125,0,0.0200125,"lysis. They used argument sequences tied with a predicate sense (e.g. AGENT-buy.01/ActivePATIENT) as a feature for the re-ranker of the system where predicate sense and argument role candidates are generated by their pipelined architecture. They reported that incorporating this type of features provides substantial gain of the system performance. The other factor is inter-dependencies between a predicate sense and argument roles, which relate to selectional preference, and motivated us to jointly identify a predicate sense and its argument roles. This type of dependencies has been explored by Riedel and Meza-Ruiz (2008; 2009b; 2009a), all of which use Markov Logic Networks (MLN). The work uses the global formulae that have atoms in terms of both a predicate sense and each of its argument roles, and the system identiﬁes predicate senses and argument roles simultaneously. Ideally, we want to capture both types of dependencies simultaneously. The former approaches can not explicitly include features that capture inter-dependencies between a predicate sense and its argument roles. Though these are implicitly incorporated by re-ranking where the most plausible assignment is selected from a small subset of predic"
P10-2018,W08-2121,0,0.130008,"Missing"
P10-2018,J08-2002,0,0.161717,"Missing"
P10-2018,W09-1206,0,0.0674744,"Missing"
P12-1069,W06-2922,0,0.42502,"Missing"
P12-1069,P04-1015,0,0.203063,"wn (beam 8, pred 5) and shift-reduce (beam 8) and MST(2nd) parsers in Table 1. 0.4 0.2 0 0 10 20 30 40 50 length of input sentence 60 70 Figure 5: Scatter plot of parsing time against sentence length, comparing with top-down, 2nd-MST and shiftreduce parsers (beam size: 8, pred size: 5) we used the information of words and fine-grained POS-tags for features. We also implemented and experimented Huang and Sagae (2010)’s arc-standard shift-reduce parser. For the 2nd-order Eisner-Satta algorithm, we used MSTParser (McDonald, 2012). We used an early update version of averaged perceptron algorithm (Collins and Roark, 2004) for training of shift-reduce and top-down parsers. A set of feature templates in (Huang and Sagae, 2010) were used for the stack-based model, and a set of feature templates in (McDonald and Pereira, 2006) were used for the 2nd-order prediction model. The weighted prediction and stack-based models of topdown parser were jointly trained. 8.1 Results for English Data During training, we fixed the prediction size and beam size to 5 and 16, respectively, judged by pre663 top-down (beam:8, pred:5) shift-reduce (beam:8) 2nd-MST oracle (sh+mst) oracle (top+sh) oracle (top+mst) oracle (top+sh+mst) acc"
P12-1069,P81-1022,0,0.771692,", 2004; Zhang and Clark, 2008), are widely used for dependency analysis because of the efficiency and comparatively good performance. However, these parsers have one major problem that they can handle only local information. Isozaki et al. (2004) pointed out that the drawbacks of shift-reduce parser could be resolved by incorporating top-down information such as root finding. This work presents an O(n2 ) top-down headdriven transition-based parsing algorithm which can parse complex structures that are not trivial for shiftreduce parsers. The deductive system is very similar to Earley parsing (Earley, 1970). The Earley prediction is tied to a particular grammar rule, but the proposed algorithm is data-driven, following the current trends of dependency parsing (Nivre, 2006; McDonald and Pereira, 2006; Koo et al., 2010). To do the prediction without any grammar rules, we introduce a weighted prediction that is to predict lower nodes from higher nodes with a statistical model. Definition 2.1 (Dependency Graph) Given an input sentence W = n0 . . . nn where n0 is a special root node $, a directed graph is defined as GW = (VW , AW ) where VW = {0, 1, . . . , n} is a set of (indices of) nodes and AW ⊆"
P12-1069,P99-1059,0,0.203438,"pushes them into hypo in line 9 of Algorithm 1. 6 Time Complexity Our proposed top-down algorithm has three kinds of actions which are scan, comp and predict. Each scan and comp actions occurs n times when parsing a sentence with the length n. Predict action also occurs n times in which a child node is selected from 662 n ∑ i= n(n + 1) . (11) 2 n2 As for prediction is the most dominant factor, the time complexity of the algorithm is O(n2 ) and that of the algorithm with beam search is O(n2 ∗ b). 7 Related Work Alshawi (1996) proposed head automaton which recognizes an input sentence top-down. Eisner and Satta (1999) showed that there is a cubic-time parsing algorithm on the formalism of the head automaton grammars, which are equivalently converted into split-head bilexical context-free grammars (SBCFGs) (McAllester, 1999; Johnson, 2007). Although our proposed algorithm does not employ the formalism of SBCFGs, it creates left children before right children, implying that it does not have spurious ambiguities as well as parsing algorithms on the SBCFGs. Head-corner parsing algorithm (Kay, 1989) creates dependency tree top-down, and in this our algorithm has similar spirit to it. Yamada and Matsumoto (2003)"
P12-1069,N10-1115,0,0.0762616,"Missing"
P12-1069,D11-1137,1,0.712619,"Missing"
P12-1069,P10-1110,0,0.439528,"rsing with Top-down Prediction Katsuhiko Hayashi† , Taro Watanabe‡ , Masayuki Asahara§ , Yuji Matsumoto† † Nara Institute of Science and Technology Ikoma, Nara, 630-0192, Japan ‡ National Institute of Information and Communications Technology Sorakugun, Kyoto, 619-0289, Japan § National Institute for Japanese Language and Linguistics Tachikawa, Tokyo, 190-8561, Japan katsuhiko-h@is.naist.jp, taro.watanabe@nict.go.jp masayu-a@ninjal.ac.jp, matsu@is.naist.jp Abstract To improve parsing flexibility in deterministic parsing, our top-down parser uses beam search algorithm with dynamic programming (Huang and Sagae, 2010). The complexity becomes O(n2 ∗ b) where b is the beam size. To reduce prediction errors, we propose a lookahead technique based on a FIRST function, inspired by the LL(1) parser (Aho and Ullman, 1972). Experimental results show that the proposed top-down parser achieves competitive results with other data-driven parsing algorithms. This paper presents a novel top-down headdriven parsing algorithm for data-driven projective dependency analysis. This algorithm handles global structures, such as clause and coordination, better than shift-reduce or other bottom-up algorithms. Experiments on the E"
P12-1069,C04-1040,0,0.0334442,"ttom-up algorithms. Experiments on the English Penn Treebank data and the Chinese CoNLL-06 data show that the proposed algorithm achieves comparable results with other data-driven dependency parsing algorithms. 2 Definition of Dependency Graph 1 Introduction A dependency graph is defined as follows. Transition-based parsing algorithms, such as shiftreduce algorithms (Nivre, 2004; Zhang and Clark, 2008), are widely used for dependency analysis because of the efficiency and comparatively good performance. However, these parsers have one major problem that they can handle only local information. Isozaki et al. (2004) pointed out that the drawbacks of shift-reduce parser could be resolved by incorporating top-down information such as root finding. This work presents an O(n2 ) top-down headdriven transition-based parsing algorithm which can parse complex structures that are not trivial for shiftreduce parsers. The deductive system is very similar to Earley parsing (Earley, 1970). The Earley prediction is tied to a particular grammar rule, but the proposed algorithm is data-driven, following the current trends of dependency parsing (Nivre, 2006; McDonald and Pereira, 2006; Koo et al., 2010). To do the predic"
P12-1069,W07-2416,0,0.0235581,"e results are almost 664 the same as those of the English results. 8.3 Analysis of Results Table 4 shows two interesting results, on which topdown parser is superior to either shift-reduce parser or 2nd-MST parser. The sentence No.717 contains an adverbial clause structure between the subject and the main verb. Top-down parser is able to handle the long-distance dependency while shift-reudce parser cannot correctly analyze it. The effectiveness on the clause structures implies that our head-driven parser may handle non-projective structures well, which are introduced by Johansonn’s head rule (Johansson and Nugues, 2007). The sentence No.127 contains a coordination structure, which it is difficult for bottom-up parsers to handle, but, top-down parser handles it well because its top-down prediction globally captures the coordination. 9 Conclusion This paper presents a novel head-driven parsing algorithm and empirically shows that it is as practical as other dependency parsing algorithms. Our head-driven parser has potential for handling nonprojective structures better than other non-projective dependency algorithms (McDonald et al., 2005; Attardi, 2006; Nivre, 2008b; Koo et al., 2010). We are in the process of"
P12-1069,P07-1022,0,0.0198248,"length n. Predict action also occurs n times in which a child node is selected from 662 n ∑ i= n(n + 1) . (11) 2 n2 As for prediction is the most dominant factor, the time complexity of the algorithm is O(n2 ) and that of the algorithm with beam search is O(n2 ∗ b). 7 Related Work Alshawi (1996) proposed head automaton which recognizes an input sentence top-down. Eisner and Satta (1999) showed that there is a cubic-time parsing algorithm on the formalism of the head automaton grammars, which are equivalently converted into split-head bilexical context-free grammars (SBCFGs) (McAllester, 1999; Johnson, 2007). Although our proposed algorithm does not employ the formalism of SBCFGs, it creates left children before right children, implying that it does not have spurious ambiguities as well as parsing algorithms on the SBCFGs. Head-corner parsing algorithm (Kay, 1989) creates dependency tree top-down, and in this our algorithm has similar spirit to it. Yamada and Matsumoto (2003) applied a shiftreduce algorithm to dependency analysis, which is known as arc-standard transition-based algorithm (Nivre, 2004). Nivre (2003) proposed another transition-based algorithm, known as arc-eager algorithm. The arc"
P12-1069,W89-0206,0,0.583899,". 7 Related Work Alshawi (1996) proposed head automaton which recognizes an input sentence top-down. Eisner and Satta (1999) showed that there is a cubic-time parsing algorithm on the formalism of the head automaton grammars, which are equivalently converted into split-head bilexical context-free grammars (SBCFGs) (McAllester, 1999; Johnson, 2007). Although our proposed algorithm does not employ the formalism of SBCFGs, it creates left children before right children, implying that it does not have spurious ambiguities as well as parsing algorithms on the SBCFGs. Head-corner parsing algorithm (Kay, 1989) creates dependency tree top-down, and in this our algorithm has similar spirit to it. Yamada and Matsumoto (2003) applied a shiftreduce algorithm to dependency analysis, which is known as arc-standard transition-based algorithm (Nivre, 2004). Nivre (2003) proposed another transition-based algorithm, known as arc-eager algorithm. The arc-eager algorithm processes rightdependent top-down, but this does not involve the prediction of lower nodes from higher nodes. Therefore, the arc-eager algorithm is a totally bottom-up algorithm. Zhang and Clark (2008) proposed a combination approach of the tra"
P12-1069,P10-2035,0,0.537808,"Missing"
P12-1069,P10-1001,0,0.138001,"Missing"
P12-1069,D10-1125,0,0.0267333,"information. Isozaki et al. (2004) pointed out that the drawbacks of shift-reduce parser could be resolved by incorporating top-down information such as root finding. This work presents an O(n2 ) top-down headdriven transition-based parsing algorithm which can parse complex structures that are not trivial for shiftreduce parsers. The deductive system is very similar to Earley parsing (Earley, 1970). The Earley prediction is tied to a particular grammar rule, but the proposed algorithm is data-driven, following the current trends of dependency parsing (Nivre, 2006; McDonald and Pereira, 2006; Koo et al., 2010). To do the prediction without any grammar rules, we introduce a weighted prediction that is to predict lower nodes from higher nodes with a statistical model. Definition 2.1 (Dependency Graph) Given an input sentence W = n0 . . . nn where n0 is a special root node $, a directed graph is defined as GW = (VW , AW ) where VW = {0, 1, . . . , n} is a set of (indices of) nodes and AW ⊆ VW × VW is a set of directed arcs. The set of arcs is a set of pairs (x, y) where x is a head and y is a dependent of x. x →∗ l denotes a path from x to l. A directed graph GW = (VW , AW ) is well-formed if and only"
P12-1069,E06-1011,0,0.214123,"t they can handle only local information. Isozaki et al. (2004) pointed out that the drawbacks of shift-reduce parser could be resolved by incorporating top-down information such as root finding. This work presents an O(n2 ) top-down headdriven transition-based parsing algorithm which can parse complex structures that are not trivial for shiftreduce parsers. The deductive system is very similar to Earley parsing (Earley, 1970). The Earley prediction is tied to a particular grammar rule, but the proposed algorithm is data-driven, following the current trends of dependency parsing (Nivre, 2006; McDonald and Pereira, 2006; Koo et al., 2010). To do the prediction without any grammar rules, we introduce a weighted prediction that is to predict lower nodes from higher nodes with a statistical model. Definition 2.1 (Dependency Graph) Given an input sentence W = n0 . . . nn where n0 is a special root node $, a directed graph is defined as GW = (VW , AW ) where VW = {0, 1, . . . , n} is a set of (indices of) nodes and AW ⊆ VW × VW is a set of directed arcs. The set of arcs is a set of pairs (x, y) where x is a head and y is a dependent of x. x →∗ l denotes a path from x to l. A directed graph GW = (VW , AW ) is well"
P12-1069,H05-1066,0,0.130502,"Missing"
P12-1069,J03-1006,0,0.035985,"-order one for weighted prediction. 661 Pred takes either predx or predy . Beam search is performed based on the following linear order for the two states p and p′ at the same step, which have (cfw , cin ) and (c′ fw , c′ in ) respectively: p ≻ p′ iff cfw < c′ fw or cfw = c′ fw ∧ cin < c′ . (9) a node sequence in the input queue. Thus, the algorithm takes the following times for prediction: n + (n − 1) + · · · + 1 = i in We prioritize the forward cost over the inside cost since forward cost pertains to longer action sequence and is better suited to evaluate hypothesis states than inside cost (Nederhof, 2003). 5.4 FIRST Function for Lookahead Top-down backtrack parser usually reduces backtracking by precomputing the set FIRST(·) (Aho and Ullman, 1972). We define the set FIRST(·) for our top-down dependency parser: FIRST(t’) = {ld.t|ld ∈ lmdescendant(Tree, t’) Tree ∈ Corpus} (10) where t’ is a POS-tag, Tree is a correct dependency tree which exists in Corpus, a function lmdescendant(Tree, t’) returns the set of the leftmost descendant node ld of each nodes in Tree whose POS-tag is t’, and ld.t denotes a POS-tag of ld. Though our parser does not backtrack, it looks ahead when selecting possible chil"
P12-1069,W03-3017,0,0.098252,"rted into split-head bilexical context-free grammars (SBCFGs) (McAllester, 1999; Johnson, 2007). Although our proposed algorithm does not employ the formalism of SBCFGs, it creates left children before right children, implying that it does not have spurious ambiguities as well as parsing algorithms on the SBCFGs. Head-corner parsing algorithm (Kay, 1989) creates dependency tree top-down, and in this our algorithm has similar spirit to it. Yamada and Matsumoto (2003) applied a shiftreduce algorithm to dependency analysis, which is known as arc-standard transition-based algorithm (Nivre, 2004). Nivre (2003) proposed another transition-based algorithm, known as arc-eager algorithm. The arc-eager algorithm processes rightdependent top-down, but this does not involve the prediction of lower nodes from higher nodes. Therefore, the arc-eager algorithm is a totally bottom-up algorithm. Zhang and Clark (2008) proposed a combination approach of the transition-based algorithm with graph-based algorithm (McDonald and Pereira, 2006), which is the same as our combination model of stack-based and prediction models. 8 Experiments Experiments were performed on the English Penn Treebank data and the Chinese CoN"
P12-1069,W04-0308,0,0.433655,"hms. This paper presents a novel top-down headdriven parsing algorithm for data-driven projective dependency analysis. This algorithm handles global structures, such as clause and coordination, better than shift-reduce or other bottom-up algorithms. Experiments on the English Penn Treebank data and the Chinese CoNLL-06 data show that the proposed algorithm achieves comparable results with other data-driven dependency parsing algorithms. 2 Definition of Dependency Graph 1 Introduction A dependency graph is defined as follows. Transition-based parsing algorithms, such as shiftreduce algorithms (Nivre, 2004; Zhang and Clark, 2008), are widely used for dependency analysis because of the efficiency and comparatively good performance. However, these parsers have one major problem that they can handle only local information. Isozaki et al. (2004) pointed out that the drawbacks of shift-reduce parser could be resolved by incorporating top-down information such as root finding. This work presents an O(n2 ) top-down headdriven transition-based parsing algorithm which can parse complex structures that are not trivial for shiftreduce parsers. The deductive system is very similar to Earley parsing (Earley"
P12-1069,J08-4003,0,0.154551,"”. We follow a convention and write the stack with its topmost element to the right, and the queue with its first element to the left. In this example, we set the window size d to 1, and write the descendants of trees on stack elements s0 and s1 within depth 1. parser constructs left and right children of a head node in a left-to-right direction by scanning the head node prior to its right children. Figure 2 shows an example for parsing a sentence “I saw a girl”. 4 Correctness To prove the correctness of the system in Figure 1 for the projective dependency graph, we use the proof strategy of (Nivre, 2008a). The correct deductive system is both sound and complete. Theorem 4.1 The deductive system in Figure 1 is correct for the class of dependency forest. Proof 4.1 To show soundness, we show that Gp0 = (VW , ∅), which is a directed graph defined by the axiom, is well-formed and projective, and that every transition preserves this property. • ROOT: The node 0 is a root in Gp0 , and the node 0 is on the top of stack of p0 . The two pred actions put a word onto the top of stack, and predict an arc from root or its descendant to the child. The comp actions add the predicted arcs which include no ar"
P12-1069,J95-2002,0,0.086641,"e cost of a top tree s0 in stack S. We define these costs using a combination of stack-based model and weighted prediction model. The forward and inside costs of the combination model are as follows: { fw fw c = cfw s + cp (5) in in in c = cs + cp in where cfw s and cs are a forward cost and an inside in cost for stack-based model, and cfw p and cp are a forward cost and an inside cost for weighted prediction model. We add the following tuple of costs to a state: in fw in (cfw s , cs , cp , cp ). For each action, we define how to efficiently calculate the forward and inside costs3 , following Stolcke (1995) and Huang and Sagae (2010)’s works. In either case of predx or predy , fw (cfw s , , cp , ) fw (cfw s + λ, 0, cp + cp (s0 .h, nk ), 0) where λ= m−1 ∑ θs · fs,predx (i, h, j, S) if predx θs · fs,predy (i, h, j, S) if predy (6) In the case of scan, cp (h, ly , ly+1 ) in fw in (cfw s , cs , cp , cp ) in fw in (cfw s + ξ, cs + ξ, cp , cp ) y=1 +cp (h, −, r1 ) + { cp (h, ry , ry+1 ). where y=1 This is different from McDonald and Pereira (2006) in that the cost factors for left children are calculated from left to right, while those in McDonald and Pereira (2006)’s definition are calculated from ri"
P12-1069,W03-3023,1,0.78688,"wn. Eisner and Satta (1999) showed that there is a cubic-time parsing algorithm on the formalism of the head automaton grammars, which are equivalently converted into split-head bilexical context-free grammars (SBCFGs) (McAllester, 1999; Johnson, 2007). Although our proposed algorithm does not employ the formalism of SBCFGs, it creates left children before right children, implying that it does not have spurious ambiguities as well as parsing algorithms on the SBCFGs. Head-corner parsing algorithm (Kay, 1989) creates dependency tree top-down, and in this our algorithm has similar spirit to it. Yamada and Matsumoto (2003) applied a shiftreduce algorithm to dependency analysis, which is known as arc-standard transition-based algorithm (Nivre, 2004). Nivre (2003) proposed another transition-based algorithm, known as arc-eager algorithm. The arc-eager algorithm processes rightdependent top-down, but this does not involve the prediction of lower nodes from higher nodes. Therefore, the arc-eager algorithm is a totally bottom-up algorithm. Zhang and Clark (2008) proposed a combination approach of the transition-based algorithm with graph-based algorithm (McDonald and Pereira, 2006), which is the same as our combinat"
P12-1069,D08-1059,0,0.367636,"er presents a novel top-down headdriven parsing algorithm for data-driven projective dependency analysis. This algorithm handles global structures, such as clause and coordination, better than shift-reduce or other bottom-up algorithms. Experiments on the English Penn Treebank data and the Chinese CoNLL-06 data show that the proposed algorithm achieves comparable results with other data-driven dependency parsing algorithms. 2 Definition of Dependency Graph 1 Introduction A dependency graph is defined as follows. Transition-based parsing algorithms, such as shiftreduce algorithms (Nivre, 2004; Zhang and Clark, 2008), are widely used for dependency analysis because of the efficiency and comparatively good performance. However, these parsers have one major problem that they can handle only local information. Isozaki et al. (2004) pointed out that the drawbacks of shift-reduce parser could be resolved by incorporating top-down information such as root finding. This work presents an O(n2 ) top-down headdriven transition-based parsing algorithm which can parse complex structures that are not trivial for shiftreduce parsers. The deductive system is very similar to Earley parsing (Earley, 1970). The Earley pred"
P12-1069,P11-2033,0,0.155303,"Missing"
S07-1052,J93-2004,0,\N,Missing
S07-1052,E06-1011,0,\N,Missing
S07-1052,S07-1014,0,\N,Missing
S07-1052,P06-1095,0,\N,Missing
S07-1052,P02-1034,0,\N,Missing
S07-1052,W04-3205,0,\N,Missing
W03-1720,N01-1025,1,0.898246,"m using the training material (See (Manning and Sch¨utze., 1999)). The learning process is based on the Baum-Welch algorithm and is the same as the well-known use of HMM for part-of-speech tagging problem, except that the number of states are arbitrarily determined and the initial probabilities are randomly assigned in our model. 1.2 Correction by Support Vector Machine-based Chunker While the HMM-based word segmenter achieves good accuracy for known words, it cannot identify compound words and out-of-vocabulary words. Therefore, we introduce a Support Vector Machine(below SVM)-based chunker (Kudo and Matsumoto, 2001) to cover the errors made by the segmenter. The SVM-based chunker re-assigns new word boundaries to the output of the segmenter. An SVM (Vapnik, 1998) is a binary classifier. Suppose we have a set of training data for a binary class problem: (x1 , y1 ), . . . , (xN , yN ), where xi ∈ Rn is a feature vector of the i th sample in the training data and yi ∈ {+1, −1} is the label of the sample. The goal is to find a decision function which accurately predicts y for an unseen x. An SVM classifier gives a decision function f (x) for an input vector x where X f (x) = sign( αi yi K(x, zi ) + b). zi ∈S"
W03-1720,W95-0107,0,0.0701678,"Missing"
W06-2927,I05-3003,1,0.876312,"Missing"
W06-2927,1995.iwpt-1.17,0,0.063867,"g of a preposition which includes few children is usually a verb; on the other hand, the real POS tag of a preposition is usually a preposition. If our parser considers the preposition which leads a short phrase, the parser will estimate the relation of the preposition as a verb. At the same time, if the boundary of prepositional phrase is analyzed incorrectly, other succeeding words will be wrongly analyzed, too. Error analysis of Japanese data (Kawata and Bartels, 2000) shows that CNJ (Conjunction) is a difficult POS tag. The parser does not have any module to detect coordinate structures. (Kurohashi, 1995) proposed a method in which coordinate structure with punctuation is detected by a coeffi195 Conclusion This paper reported on multi-lingual dependency parsing on combining SVMs and MaxEnt. The system uses SVMs for word dependency attachment analysis and MaxEnt for the label tagging when the new dependency attachment is generated. We discussed some preprocessing methods that are useful in our preceding work for Chinese dependency analysis, but these methods, except one, cannot be used in multi-lingual dependency parsing. Only using the SVM-based tagger to extract the neighbor relation could im"
W06-2927,W04-0308,0,0.293436,"we not only adopted the Nivre algorithm with SVMs, but also tried some preprocessing methods. We investigated several preprocessing methods on a Chinese Treebank. In this shared task (Buchholz et. al, 2006), we also investigate which preprocessing method is effective on other languages. We found that only the method that uses a tagger to extract the word dependency attachment between two neighboring words works effectively in most of the languages. Abstract In this paper, we present a framework for multi-lingual dependency parsing. Our bottom-up deterministic parser adopts Nivre’s algorithm (Nivre, 2004) with a preprocessor. Support Vector Machines (SVMs) are utilized to determine the word dependency attachments. Then, a maximum entropy method (MaxEnt) is used for determining the label of the dependency relation. To improve the performance of the parser, we construct a tagger based on SVMs to find neighboring attachment as a preprocessor. Experimental evaluation shows that the proposed extension improves the parsing accuracy of our base parser in 9 languages. (Hajič et al., 2004; Simov et al., 2005; Simov and Osenova, 2003; Chen et al., 2003; Böhmová et al., 2003; Kromann, 2003; van der Beek"
W06-2927,W03-2403,0,\N,Missing
W06-2927,W06-2920,0,\N,Missing
W06-2927,dzeroski-etal-2006-towards,0,\N,Missing
W06-2927,W03-2405,0,\N,Missing
W08-2132,W06-2920,0,0.119472,"Missing"
W08-2132,J02-3001,0,0.0502326,"nd that for noun predicates. Semantic frames are useful information for semantic role classiﬁcation. Generally, obligatory arguments not included in semantic frames do not appear in actual texts. For this reason, we use PropBank/NomBank semantic frames for semantic role pruning. Suppose semantic roles in the semantic frame are Fi = {A0, A1, A2, A3}. Since obligatory arguments are {A0...AA}, the remaining arguments {A4, A5, AA} are removed from label candidates. For verb predicates, the features used in our system are based on (Hacioglu, 2004). We also employed some other features proposed in (Gildea and Jurafsky, 2002; Pradhan et al., 2004b). For noun predicates, the features are primarily based on (Pradhan et al., 2004a). The features that we deﬁned for semantic role labeling are as follows: Word features: SPLIT LEMMA and PPOS of the predicate, dependent and dependent’s head, and its conjunctions. Dependency label: The dependency label between the argument candidate and the its head. Family: The position of the argument candidate with respect to the predicate position over the dependency tree (e.g., child, sibling). Position: The position of the head of the dependency relation with respect to the predicat"
W08-2132,C04-1186,0,0.0181747,"on, we created two models: argument classiﬁer for verb predicates and that for noun predicates. Semantic frames are useful information for semantic role classiﬁcation. Generally, obligatory arguments not included in semantic frames do not appear in actual texts. For this reason, we use PropBank/NomBank semantic frames for semantic role pruning. Suppose semantic roles in the semantic frame are Fi = {A0, A1, A2, A3}. Since obligatory arguments are {A0...AA}, the remaining arguments {A4, A5, AA} are removed from label candidates. For verb predicates, the features used in our system are based on (Hacioglu, 2004). We also employed some other features proposed in (Gildea and Jurafsky, 2002; Pradhan et al., 2004b). For noun predicates, the features are primarily based on (Pradhan et al., 2004a). The features that we deﬁned for semantic role labeling are as follows: Word features: SPLIT LEMMA and PPOS of the predicate, dependent and dependent’s head, and its conjunctions. Dependency label: The dependency label between the argument candidate and the its head. Family: The position of the argument candidate with respect to the predicate position over the dependency tree (e.g., child, sibling). Position: The"
W08-2132,W03-2604,1,0.810969,"uration, which achieved 80.89 F1 for the joint task, and 74.53 semantic dependencies F1. The result shows that the conﬁguration of pipeline is a crucial issue in the task. Figure 1: Overview of the System This paper presents the description of our system in CoNLL-2008 shared task. We split the shared task into ﬁve sub-problems – syntactic dependency parsing, syntactic dependency label classiﬁcation, predicate identiﬁcation, word sense disambiguation, and semantic role labeling. The overview of our system is illustrated in Figure 1. Our dependency parsing module is based on a tournament model (Iida et al., 2003), in which a dependency attachment is estimated in step-ladder tournament matches. The relative preference of the attachment is modeled by one-on-one match in the tournament. Iwatate et al. (Iwatate et al., 2008) initially proposed the method for Japanese dependency parsing, and we applied it to other languages by relaxing some constraints (Section 2.1). Dependency label classiﬁcation is performed by a linearchain sequential labeling on the dependency siblings like McDonald’s schemata (McDonald et al., 2006). We use an online passive-aggressive algorithm (Crammer et al., 2006) for linear-chain"
W08-2132,C08-1046,1,0.910766,"paper presents the description of our system in CoNLL-2008 shared task. We split the shared task into ﬁve sub-problems – syntactic dependency parsing, syntactic dependency label classiﬁcation, predicate identiﬁcation, word sense disambiguation, and semantic role labeling. The overview of our system is illustrated in Figure 1. Our dependency parsing module is based on a tournament model (Iida et al., 2003), in which a dependency attachment is estimated in step-ladder tournament matches. The relative preference of the attachment is modeled by one-on-one match in the tournament. Iwatate et al. (Iwatate et al., 2008) initially proposed the method for Japanese dependency parsing, and we applied it to other languages by relaxing some constraints (Section 2.1). Dependency label classiﬁcation is performed by a linearchain sequential labeling on the dependency siblings like McDonald’s schemata (McDonald et al., 2006). We use an online passive-aggressive algorithm (Crammer et al., 2006) for linear-chain sequential labeling (Section 2.2). We also use the other linear-chain sequential labeling method to annotate whether each word is a predicate or not (Section 2.3). If an identiﬁed predicate has more than one sen"
W08-2132,N04-4036,0,0.0182715,". Semantic frames are useful information for semantic role classiﬁcation. Generally, obligatory arguments not included in semantic frames do not appear in actual texts. For this reason, we use PropBank/NomBank semantic frames for semantic role pruning. Suppose semantic roles in the semantic frame are Fi = {A0, A1, A2, A3}. Since obligatory arguments are {A0...AA}, the remaining arguments {A4, A5, AA} are removed from label candidates. For verb predicates, the features used in our system are based on (Hacioglu, 2004). We also employed some other features proposed in (Gildea and Jurafsky, 2002; Pradhan et al., 2004b). For noun predicates, the features are primarily based on (Pradhan et al., 2004a). The features that we deﬁned for semantic role labeling are as follows: Word features: SPLIT LEMMA and PPOS of the predicate, dependent and dependent’s head, and its conjunctions. Dependency label: The dependency label between the argument candidate and the its head. Family: The position of the argument candidate with respect to the predicate position over the dependency tree (e.g., child, sibling). Position: The position of the head of the dependency relation with respect to the predicate position in the sent"
W08-2132,N04-1030,0,0.032753,". Semantic frames are useful information for semantic role classiﬁcation. Generally, obligatory arguments not included in semantic frames do not appear in actual texts. For this reason, we use PropBank/NomBank semantic frames for semantic role pruning. Suppose semantic roles in the semantic frame are Fi = {A0, A1, A2, A3}. Since obligatory arguments are {A0...AA}, the remaining arguments {A4, A5, AA} are removed from label candidates. For verb predicates, the features used in our system are based on (Hacioglu, 2004). We also employed some other features proposed in (Gildea and Jurafsky, 2002; Pradhan et al., 2004b). For noun predicates, the features are primarily based on (Pradhan et al., 2004a). The features that we deﬁned for semantic role labeling are as follows: Word features: SPLIT LEMMA and PPOS of the predicate, dependent and dependent’s head, and its conjunctions. Dependency label: The dependency label between the argument candidate and the its head. Family: The position of the argument candidate with respect to the predicate position over the dependency tree (e.g., child, sibling). Position: The position of the head of the dependency relation with respect to the predicate position in the sent"
W08-2132,W04-3212,0,0.0263834,"e reason of the result of semantic role labeling could be usages of PropBank/NomBank frames. We did not achieve the maximum use of the resources, hence the design of features and the choice of learning algorithm may not be optimal. Figure 4: Overview of the Modiﬁed System The other reason is the design of the pipeline. We changed the design of the pipeline after the test run. The overview of the modiﬁed system is illustrated in Figure 4. After the syntactic dependency parsing, we limited the predicate candidates as verbs and nouns by PPOSS, and ﬁltered the argument candidates by Xue’s method (Xue and Palmer, 2004). Next, the candidate pair of predicate-argument was classiﬁed by an online passive-aggressive algorithm as shown in Section 2.5. Finally, the word sense of the predicate is determined by the module in Section 2.4. The new result is scores with ∗ in Table 1. The result means that the ﬁrst design was not the best for the task. Acknowledgements We would like to thank the CoNLL-2008 shared task organizers and the data providers (Surdeanu et al., 2008). 231 Problem Complete Problem Semantic Dependency Semantic Role Labeling Predicate Identiﬁcation & Word Sense Disambiguation Syntactic Dependency ("
W08-2132,W06-2932,0,0.168294,"is illustrated in Figure 1. Our dependency parsing module is based on a tournament model (Iida et al., 2003), in which a dependency attachment is estimated in step-ladder tournament matches. The relative preference of the attachment is modeled by one-on-one match in the tournament. Iwatate et al. (Iwatate et al., 2008) initially proposed the method for Japanese dependency parsing, and we applied it to other languages by relaxing some constraints (Section 2.1). Dependency label classiﬁcation is performed by a linearchain sequential labeling on the dependency siblings like McDonald’s schemata (McDonald et al., 2006). We use an online passive-aggressive algorithm (Crammer et al., 2006) for linear-chain sequential labeling (Section 2.2). We also use the other linear-chain sequential labeling method to annotate whether each word is a predicate or not (Section 2.3). If an identiﬁed predicate has more than one sense, a nearest neighbour classiﬁer disambiguates the word sense candidates (Section 2.4). We use an online passive-aggressive algorithm again for the semantic role labeling (Section 2.5). The machine learning algorithms used in separated modules are diverse due to role sharing.1 c 2008.  Licensed und"
W08-2132,W08-2121,0,\N,Missing
W08-2132,D07-1096,0,\N,Missing
W09-1218,burchardt-etal-2006-salsa,0,0.0332761,"Missing"
W09-1218,D07-1101,0,0.173593,"ctic-semantic structure among all possible structures in that syntactic dependencies and semantic dependencies are correlated. However, solving this problem is too difﬁcult because the search space of the problem is extremely large. Therefore we focus on improving performance for each subproblem: dependency parsing and semantic role labeling. In the past few years, research investigating higher-order dependency parsing algorithms has found its superiority to ﬁrst-order parsing algorithms. To reap the beneﬁts of these advances, we 114 use a higher-order projective dependency parsing algorithm (Carreras, 2007) which is an extension of the span-based parsing algorithm (Eisner, 1996), for syntactic dependency parsing. In terms of semantic role labeling, we would like to capture global information about predicateargument structures in order to accurately predict the correct predicate-argument structure. Previous research dealt with such information using re-ranking (Toutanova et al., 2005; Johansson and Nugues, 2008). We explore a different approach to deal with such information using global features. Use of global features for structured prediction problem has been explored by several NLP application"
W09-1218,C96-1058,0,0.0582791,"Missing"
W09-1218,P05-1045,0,0.00368784,"pan-based parsing algorithm (Eisner, 1996), for syntactic dependency parsing. In terms of semantic role labeling, we would like to capture global information about predicateargument structures in order to accurately predict the correct predicate-argument structure. Previous research dealt with such information using re-ranking (Toutanova et al., 2005; Johansson and Nugues, 2008). We explore a different approach to deal with such information using global features. Use of global features for structured prediction problem has been explored by several NLP applications such as sequential labeling (Finkel et al., 2005; Krishnan and Manning, 2006; Kazama and Torisawa, 2007) and dependency parsing (Nakagawa, 2007) with a great deal of success. We attempt to use global features for argument classiﬁcation in which the most plausible semantic role assignment is selected using both local and global information. We present an approximate max-margin learning algorithm for argument classiﬁers with global features. 2 Dependency Parsing As in previous work, we use a linear model for dependency parsing. The score function used in our dependency parser is deﬁned as follows. s(y) = ∑ F (h, m, x) (1) (h,m)∈y where h and"
W09-1218,W08-2122,0,0.0258264,"Although our system is not a joint approach but a pipeline approach, the system is comparable to the top system for some of the 7 languages. A further research direction we are investigating is the application of various types of global features. We believe that there is still room for improvements since we used only two types of global features for the argument classiﬁer. Another research direction is investigating joint approaches. To the best of our knowledge, three types of joint approaches have been proposed: N-best based approach (Johansson and Nugues, 2008), synchronous joint approach (Henderson et al., 2008), and a joint approach where parsing and SRL are performed simultaneously (Llu´ıs and M`arquez, 2008). We attempted to perform Nbest based joint approach, however, the expensive computational cost of the 2nd-order projective parser discouraged it. We would like to investigate syntactic-semantic joint approaches with reasonable time complexities. Acknowledgments We would like to thank Richard Johansson for his advice on parser implementation, and the CoNLL2009 organizers (Hajiˇc et al., 2009; Taul´e et al., 2008; Palmer and Xue, 2009; Hajiˇc et al., 2006; Surdeanu et al., 2008; Burchardt et al."
W09-1218,W08-2123,0,0.114866,"Missing"
W09-1218,kawahara-etal-2002-construction,0,0.0181481,"Missing"
W09-1218,D07-1033,0,0.0793895,"yntactic dependency parsing. In terms of semantic role labeling, we would like to capture global information about predicateargument structures in order to accurately predict the correct predicate-argument structure. Previous research dealt with such information using re-ranking (Toutanova et al., 2005; Johansson and Nugues, 2008). We explore a different approach to deal with such information using global features. Use of global features for structured prediction problem has been explored by several NLP applications such as sequential labeling (Finkel et al., 2005; Krishnan and Manning, 2006; Kazama and Torisawa, 2007) and dependency parsing (Nakagawa, 2007) with a great deal of success. We attempt to use global features for argument classiﬁcation in which the most plausible semantic role assignment is selected using both local and global information. We present an approximate max-margin learning algorithm for argument classiﬁers with global features. 2 Dependency Parsing As in previous work, we use a linear model for dependency parsing. The score function used in our dependency parser is deﬁned as follows. s(y) = ∑ F (h, m, x) (1) (h,m)∈y where h and m denote the head and the dependent of the dependency ed"
W09-1218,P06-1141,0,0.0183095,"orithm (Eisner, 1996), for syntactic dependency parsing. In terms of semantic role labeling, we would like to capture global information about predicateargument structures in order to accurately predict the correct predicate-argument structure. Previous research dealt with such information using re-ranking (Toutanova et al., 2005; Johansson and Nugues, 2008). We explore a different approach to deal with such information using global features. Use of global features for structured prediction problem has been explored by several NLP applications such as sequential labeling (Finkel et al., 2005; Krishnan and Manning, 2006; Kazama and Torisawa, 2007) and dependency parsing (Nakagawa, 2007) with a great deal of success. We attempt to use global features for argument classiﬁcation in which the most plausible semantic role assignment is selected using both local and global information. We present an approximate max-margin learning algorithm for argument classiﬁers with global features. 2 Dependency Parsing As in previous work, we use a linear model for dependency parsing. The score function used in our dependency parser is deﬁned as follows. s(y) = ∑ F (h, m, x) (1) (h,m)∈y where h and m denote the head and the de"
W09-1218,W08-2124,0,0.0331244,"Missing"
W09-1218,D07-1100,0,0.0178301,"ole labeling, we would like to capture global information about predicateargument structures in order to accurately predict the correct predicate-argument structure. Previous research dealt with such information using re-ranking (Toutanova et al., 2005; Johansson and Nugues, 2008). We explore a different approach to deal with such information using global features. Use of global features for structured prediction problem has been explored by several NLP applications such as sequential labeling (Finkel et al., 2005; Krishnan and Manning, 2006; Kazama and Torisawa, 2007) and dependency parsing (Nakagawa, 2007) with a great deal of success. We attempt to use global features for argument classiﬁcation in which the most plausible semantic role assignment is selected using both local and global information. We present an approximate max-margin learning algorithm for argument classiﬁers with global features. 2 Dependency Parsing As in previous work, we use a linear model for dependency parsing. The score function used in our dependency parser is deﬁned as follows. s(y) = ∑ F (h, m, x) (1) (h,m)∈y where h and m denote the head and the dependent of the dependency edge in y, and F (h, m, x) is a Factor tha"
W09-1218,P05-1013,0,0.0400704,"Missing"
W09-1218,W08-2121,0,0.05671,"Missing"
W09-1218,taule-etal-2008-ancora,0,0.079745,"Missing"
W09-1218,P05-1073,0,0.0845518,"Missing"
W09-1218,W08-2132,1,0.745212,"relaxation as in (Kazama and Torisawa, 2007). At ﬁrst we generate n-best assignments using only the local factor, and then add the global factor score for each n-best assignment, ﬁnally select the best scoring assignment from them. In order to generate n-best assignments, we used a beam-search algorithm. 3.2.1 Learning the Model As in dependency parser and predicate classiﬁer, we train the model using the PA algorithm with parameter averaging. The learning algorithm is shown 116 3.2.2 Features for Argument Classiﬁcation The local features used in our system are the same as our previous work (Watanabe et al., 2008) except for language dependent features. The global features that used in our system are based on (Johansson and Nugues, 2008) that used for re-ranking. Local Features Word features: Predicted lemma and predicted POS of the predicate, predicate’s head, argument candidate, argument candidate’s head, leftmost/rightmost dependent and leftmost/rightmost sibling. Dependency label: The dependency label of predicate, argument candidate and argument candidate’s dependent. Family: The position of the argument candicate with respect to the predicate position in the dependency tree (e.g. child, sibling)."
W09-1218,W09-1201,0,\N,Missing
W11-3504,W09-3536,0,0.0627478,"Missing"
W11-3504,P97-1017,0,\N,Missing
W16-5406,uchimoto-etal-2006-dependency,0,0.0412276,"ndency treebanks have been word-based. However, treebanking based on bunsetsu (base phrase unit) has been adopted by the Japanese NLP community, due to the nature of the Japanese bunsetsu dependency structure, such as strictly being head-final and projective on the bunsetsu units. Several annotation schemas for the bunsetsu-based treebanks are accessible in selected Japanese cor KC pora. First is the Kyoto Text Corpus Schema(hereafter  )(Kurohashi and Nagao, 1998), which is used for newspaper articles. Second is the Corpus of Spontaneous Japanese (Maekawa, 2003) Schema  (hereafter CSJ )(Uchimoto et al., 2006). We propose a novel annotation schema for the Japanese bunsetsu dependency structure, in which we also annotate coordinate and apposition structure scopes as segments. In this standard, we define the detailed inter-clause attachment guideline based on (Minami, 1974) and also introduce some labels to resolve errors or discrepancies in the upper process of bunsetsu and sentence boundary annotation. We applied the annotation schema for the core data of ‘Balanced Corpus of Contemporary Written Japanese’ (Maekawa et al., 2014) which comprised data from newspaper(PN), books(PB),magazines(PM), white"
W18-2805,W17-0706,0,0.485148,"a Bayesian linear mixed model with manually annotated predicate-argument structure data. The findings from the refined corpus analysis confirmed the effects of information status of an NP as ‘givennew ordering’ in addition to the effects of ‘long-before-short’ as a tendency of the general Japanese word order. 1 Shin-Ichiro Sano Satoshi Nambu Introduction Because Japanese exhibits a flexible word order, potential factors that predict word orders of a given construction in Japanese have been recently delved into, particularly in the field of computational linguistics (Yamashita and Kondo, 2011; Orita, 2017). One of the major findings relevant to the current study is ‘long-before-short’, whereby a long noun phrase (NP) tends to be scrambled ahead of a short NP (Yamashita and Chang, 2001). This paper sheds light on those factors in double object constructions (DOC), where either (1) an indirect object (IOBJ) or (2) a direct object (DOBJ) can precede the other object: (1) Taro-ga Hanako-ni hon-o ageta. Taro-SBJ Hanako-IOBJ book-DOBJ gave ‘Taro gave Hanako a book.’ (3) (2) Taro-ga hon-o Hanako-ni ageta. Taro-SBJ book-DOBJ Hanako-IOBJ gave ‘Taro gave Hanako a book.’ Since both of the word orders are"
W18-2805,W16-5406,1,0.894773,"Missing"
W18-2805,P16-1211,0,0.0854759,"obj) and predicate (pred) from the overlaid data. Excluding 4-tuples with zero-pronoun, case alternation, or inter-clause dependencies from the target data, we obtained 584 samples of the 4-tuples. Figure 1 shows an example sentence from BCCWJ Yahoo! Answer sample (OC09 04653). The surface is segmented into base phrases, which is the unit to evaluate the distance between two constituents as in the following pairs of the 4-tuples: dobj subj-pred (distsubj pred ), dobj-pred (distpred ), iobj-pred Preceding Work Table 1 shows a comparison with the latest corpus studies on Japanese word ordering. Sasano and Okumura (2016) explored the canonical word order of Japanese double object constructions (either SUBJ-IOBJ-DOBJ-PRED or SUBJ-DOBJ-IOBJ-PRED) by a large-scale web corpus. The web corpus contains 10 billion sentences parsed by the Japanese morphological analyzer JUMAN and the syntactic analyzer KNP. In their analysis, the parse trees without syntactic ambiguity were extracted from the web corpus, and the word order was estimated by verb types with a linear regression and normalized pointwise mutual information. Their model did not include any inter-sentential factors such as coreference. Orita (2017) made a s"
W18-2805,W07-1522,0,0.0294488,"mber of coindexed items in a preceding text. 2 The current work BCCWJ-PAS and BCCWJ-DepPara Newspaper, Books, Magazines, Yahoo! Answes, Blog, Whitepaper SUBJ-IOBJ-DOBJ-PRED 1,980 57,225 584 tokens NP length, and given-new 3 3.1 Experiments Corpora: BCCWJ-PAS We used the ‘Balanced Corpus of Contemporary Written Japanese’ (BCCWJ) (Maekawa et al., 2014), which includes morphological information and sentence boundaries, as the target corpus. The corpus was extended with annotations of predicate-argument structures as BCCWJ-PAS (BCCWJ Predicate Argument Structures), based on the NAIST Text Corpus (Iida et al., 2007) compatible standard. We revised all annotations of the BCCWJ-PAS data, including subjects (with case marker -ga), direct objects (with case marker -o), and indirect objects (with case marker -ni), as well as coreferential information of NPs. After the revision process, syntactic dependencies of BCCWJDepPara (Asahara and Matsumoto, 2016) were overlaid on the predicate-argument structures. We extracted 4-tuples of subject (subj), direct object (dobj), indirect object (iobj) and predicate (pred) from the overlaid data. Excluding 4-tuples with zero-pronoun, case alternation, or inter-clause depen"
W18-6009,L18-1287,1,0.271859,"fundamental issues due to hypotactic attributes in terms of syntax in coordinate structures. This paper points out the issues in the treatment of coordinate structures with evidence of linguistic plausibility and the trainability of parsers, reports on the current status of the corpora in those languages, and proposes alternative representations. Section 2 describes the linguistic features of head-final languages, and Section 3 points out the problems in the left-headed coordinate structures in head-final languages. Section 4 summarizes the current status of UD Japanese (Tanaka et al., 2016; Asahara et al., 2018) and UD Korean (Chun et al., 2018) corpora released as version 2.2. Section 5 shows the experimental results on multiple corpora in Japanese and Korean to attest the difficulty in training with left-headed coordination. Section 6 proposes a revision to the UD guidelines more suited to head-final languages. This paper discusses the representation of coordinate structures in the Universal Dependencies framework for two head-final languages, Japanese and Korean. UD applies a strict principle that makes the head of coordination the left-most conjunct. However, the guideline may produce syntactic t"
W18-6009,W17-6508,0,0.118231,"Missing"
W18-6009,W11-3801,1,0.783345,"the complexities outlined in the previous section, the UD Japanese and UD Korean teams had to work within the bounds of the principles laid out by the Universal Dependencies version 2. Therefore, in the official version 2.2 release used for the CoNLL 2018 shared task (Zeman et al., 2018), UD Japanese and UD Korean adopted two separate strategies in order to ensure compliance, 79 the verb ‘run’ with the (nsubj) label. 4.2 UD Korean Unlike the Japanese UD, the Korean UD effort has made a conscious decision to use right-headedness for conjunction following the coordination guidelines proposed by Choi and Palmer (2011). Thus, the coordinate structures in all three of the Korean UD corpora (Chun et al., 2018) were developed with the rightmost conjunct as the head of the phrase, with each conjunct pointing to its right sibling as its head. For the latest available UD_Korean-GSD, however, the dependencies were converted to leftheaded structures post-development in an effort to fully comply with the UD guidelines despite the problems left-headed structures pose for the language as described in Section 3. The other two Korean UD corpora, namely the Kaist and the Korean Penn Treebank, reflect right-headed coordin"
W18-6009,L18-1347,1,0.849927,"attributes in terms of syntax in coordinate structures. This paper points out the issues in the treatment of coordinate structures with evidence of linguistic plausibility and the trainability of parsers, reports on the current status of the corpora in those languages, and proposes alternative representations. Section 2 describes the linguistic features of head-final languages, and Section 3 points out the problems in the left-headed coordinate structures in head-final languages. Section 4 summarizes the current status of UD Japanese (Tanaka et al., 2016; Asahara et al., 2018) and UD Korean (Chun et al., 2018) corpora released as version 2.2. Section 5 shows the experimental results on multiple corpora in Japanese and Korean to attest the difficulty in training with left-headed coordination. Section 6 proposes a revision to the UD guidelines more suited to head-final languages. This paper discusses the representation of coordinate structures in the Universal Dependencies framework for two head-final languages, Japanese and Korean. UD applies a strict principle that makes the head of coordination the left-most conjunct. However, the guideline may produce syntactic trees which are difficult to accept"
W18-6009,de-marneffe-etal-2014-universal,0,0.118166,"Missing"
W18-6009,W15-2113,0,0.550814,"Missing"
W18-6009,W14-4202,1,0.883365,"Missing"
W18-6009,C18-1324,0,0.0259098,"on scheme the conjunctive particle かわいい ⽝ と 猫 が ⾛る “와” (wa) is kept suffixized in the left nominal conkawaii inu -to neko -ga hashiru junct eojeol, thus the conjunction relation cc is not ADJ NOUN CCONJ NOUN ADP VERB overtly marked. ‘cute’ ‘dog’ ‘and’ ‘cat’ -NOM ‘run’ A common problem with adjectival modification in UD shown in Figures 4 and 5 is that there Figure 4: Left-headed representation of a nominal cois no way to distinguish between modification ordination in Japanese “⽝と猫” (‘dog and cat’), in a of the full coordination vs. of the first conjunct sentence “かわいい⽝と猫が⾛る” (‘A cute dog and (Przepiórkowski and Patejuk, 2018) . For examcat run’). root ple, there is no way to specify the scope of the adjective ‘cute’: the two readings (1) only a dog is nsubj cute and (2) both animals are cute. acl conj 3.2 Verbal coordination 예쁜 개와 고양이가 달린다 yeyppun kay+wa koyangi+ka tali+nta ADJ NOUN NOUN VERB ‘cute’ ‘dog+and’ ‘cat-NOM’ ‘run’ Further critical issues are attested in the verbal coordinate structures. Figure 6 shows the left-headed verbal coordination “⾷べて⾛る” (‘eat and run’) in a noun phrase “⾷べて⾛る⼈” (‘a person who eats and runs’), where verb “⾷べ” (‘eat’) is the child of “⼈” (‘person’). Despite this dependency relatio"
W18-6009,L16-1376,0,0.0419402,"Missing"
W18-6009,L16-1680,0,0.017083,"on strictly reduces the dependency distance in head-final languages. These results support the advantages of the rightheaded strategy in Japanese coordinate structures. nsubj 오바마 대통령이 말한다 obama taythonglyeng+i malha+nta PROPN NOUN VERB ‘Obama’ ‘president-NOM’ ‘say’ (a) Korean right-headed flat structure. root nsubj flat 오바마 대통령이 말한다 obama taythonglyeng+i malha+nta PROPN NOUN VERB ‘Obama’ ‘president-NOM’ ‘say’ (b) (a) converted to left-headed structure as reflected in the UD_Korean-GSD. Figure 12: The use of flat in Korean UD v2.2. guages? To answer this question, we trained and tested UDPipe (Straka et al., 2016) on multiple versions of UD Japanese and Korean corpora. 5.1 Japanese As described in Section 4.1, the current UD Japanese-GSD corpus does not use conj tags. The corpus was converted into another version with coordinations without changing the dependency structures (right-headed coordination), that is, some of nmod and advcl labels are converted into conj label when the original manual annotation used conj regarding them as nominal or verbal coordinations. Also CCONJ tag and cc label are assigned to the coordinative case markers. The corpus was further converted into left-headed coordination,"
W18-6009,L16-1261,1,0.697171,"structure poses some fundamental issues due to hypotactic attributes in terms of syntax in coordinate structures. This paper points out the issues in the treatment of coordinate structures with evidence of linguistic plausibility and the trainability of parsers, reports on the current status of the corpora in those languages, and proposes alternative representations. Section 2 describes the linguistic features of head-final languages, and Section 3 points out the problems in the left-headed coordinate structures in head-final languages. Section 4 summarizes the current status of UD Japanese (Tanaka et al., 2016; Asahara et al., 2018) and UD Korean (Chun et al., 2018) corpora released as version 2.2. Section 5 shows the experimental results on multiple corpora in Japanese and Korean to attest the difficulty in training with left-headed coordination. Section 6 proposes a revision to the UD guidelines more suited to head-final languages. This paper discusses the representation of coordinate structures in the Universal Dependencies framework for two head-final languages, Japanese and Korean. UD applies a strict principle that makes the head of coordination the left-most conjunct. However, the guideline"
W18-6014,L18-1287,1,0.87495,"for assigning UD relations. These conversions combine various rules like bunsetsu information, case information, and coordination relations between the head word and the dependent word. Our current rules, which are unable to identify clauses, thus cannot effectively handle clauserelated labels such as csubj, advcl, and acl; this is because clauses in Japanese are vaguer than in English, as described in Section 5.2. In the future, we will solve this problem by establishing 7 As described in (Kanayama et al., 2018), this property affects coordinate structures. 8 Please refer to Section 3.4 in (Asahara et al., 2018) for a discussion of case markers in Japanese. 121 UD rel AUX ADJ DET PRON AUX VERB PROPN ADV NOUN NOUN NOUN6 Table 5: Some of example of rules for assigning UD relations, which of the number is about sixty. It is more detailed in the actual implementation. Rule root of sentence and head word in bunsetsu. have UD POS NUM have UD POS ADV include case ’ga’ (nominative case) in bunsetsu include case ’o’ (accusative case) in bunsetsu have UD POS VERB and the dependency have UD POS VERB if the relation is above bunsetsu. have UD POS VERB and the dependency have UD POS VERB if the relation is not ab"
W18-6014,W16-5406,1,0.727147,"d. According to Table 1, UD Japanese-BCCWJ is the largest UD Japanese corpus. Furthermore, it is the second largest of all UD corpora and includes many documents across various domains as shown in Table 3. Existing Japanese-language corpora tagged with dependency structures include the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the Japanese Dependency Corpus (Mori et al., 2014). These corpora frequently use bunsetsu as the syntactic dependency annotation units for Japanese. Also, the BCCWJ, based on UD Japanese-BCCWJ, is annotated using a bunsetsu-level dependency structure (Asahara and Matsumoto, 2016), which we must thus convert from a bunsetsu-level dependency structure to a Universal Dependencies schema. Figure 1 shows an example of BCCWJ with the UD annotation schema. In this paper, we describe the conversion of the BCCWJ to the UD annotation schema. To accomplish the conversion, the following information must be combined: word-morphological information, bunsetsu-level dependency structure, coordination structure annotation, and predicate argument structure information. We also attempt to convert the BCCWJ to a UD schema, which allows us to respond to changes in the tree structures base"
W18-6014,W18-6009,1,0.901389,"cates a nominal subject nsubj, but also frequently appears as a topic marker. 8 Table 5 shows the rules for assigning UD relations. These conversions combine various rules like bunsetsu information, case information, and coordination relations between the head word and the dependent word. Our current rules, which are unable to identify clauses, thus cannot effectively handle clauserelated labels such as csubj, advcl, and acl; this is because clauses in Japanese are vaguer than in English, as described in Section 5.2. In the future, we will solve this problem by establishing 7 As described in (Kanayama et al., 2018), this property affects coordinate structures. 8 Please refer to Section 3.4 in (Asahara et al., 2018) for a discussion of case markers in Japanese. 121 UD rel AUX ADJ DET PRON AUX VERB PROPN ADV NOUN NOUN NOUN6 Table 5: Some of example of rules for assigning UD relations, which of the number is about sixty. It is more detailed in the actual implementation. Rule root of sentence and head word in bunsetsu. have UD POS NUM have UD POS ADV include case ’ga’ (nominative case) in bunsetsu include case ’o’ (accusative case) in bunsetsu have UD POS VERB and the dependency have UD POS VERB if the rela"
W18-6014,W04-3230,0,0.301997,"Missing"
W18-6014,K17-3009,0,0.0725472,"Missing"
W18-6014,L16-1261,1,0.854066,"88.58 87.16 87.06 85.72 84.32 83.23 81.43 88.07 86.79 89.28 85.51 88.17 87.00 85.33 89.30 87.14 88.90 87.65 root nsubj acl case しっぽ NOUN tail が ADP SUBJ 赤い ADJ red 猫 NOUN cat root acl 赤い ADJ red 猫 NOUN cat There is the cat with a red tail. Figure 6: Clause or Phrase. 6 Other UD Japanese resources In this section, we describe other UD Japanese resources at the time of writing. Table 2 shows a summary of these. As noted, there are five UD Japanese corpora as of March 2018, which in scale constitute the second largest of all UD corpora with the addition of the UD Japanese-BCCWJ. UD Japanese-KTC (Tanaka et al., 2016) is based on the NTT Japanese Phrase Structure Treebank (Tanaka and Nagata, 2013), which contains the same original text as the Kyoto Text Corpus (KTC) (Kurohashi and Nagao, 2003). KTC is a bunsetsu-level dependency structure like BCCWJ, but with its own word delimitation schema and POS tag set. We are now modifying the UD Japanese KTC from the version 1.0 schema to version 2.0. UD Japanese-GSD consists of sentences from Japanese Wikipedia that have been automatically split into words by IBM’s word seg5.2 Clause The UD dependency labels are designed to be split between the word/phrase and the"
W18-6014,W13-4913,0,0.0280708,"85.33 89.30 87.14 88.90 87.65 root nsubj acl case しっぽ NOUN tail が ADP SUBJ 赤い ADJ red 猫 NOUN cat root acl 赤い ADJ red 猫 NOUN cat There is the cat with a red tail. Figure 6: Clause or Phrase. 6 Other UD Japanese resources In this section, we describe other UD Japanese resources at the time of writing. Table 2 shows a summary of these. As noted, there are five UD Japanese corpora as of March 2018, which in scale constitute the second largest of all UD corpora with the addition of the UD Japanese-BCCWJ. UD Japanese-KTC (Tanaka et al., 2016) is based on the NTT Japanese Phrase Structure Treebank (Tanaka and Nagata, 2013), which contains the same original text as the Kyoto Text Corpus (KTC) (Kurohashi and Nagao, 2003). KTC is a bunsetsu-level dependency structure like BCCWJ, but with its own word delimitation schema and POS tag set. We are now modifying the UD Japanese KTC from the version 1.0 schema to version 2.0. UD Japanese-GSD consists of sentences from Japanese Wikipedia that have been automatically split into words by IBM’s word seg5.2 Clause The UD dependency labels are designed to be split between the word/phrase and the clause. The difference between clauses and words/phrases is vague in Japanese, be"
W18-6014,de-marneffe-etal-2014-universal,0,0.0609123,"Missing"
W18-6014,P13-2017,0,0.0858605,"Missing"
W18-6014,mori-etal-2014-japanese,0,0.0568283,"ed UD Japanese treebank derived from Wikipedia, UD Japanese-GSD, and a Japanese-PUD corpus, UD Japanese-PUD (Zeman et al., 2017), derived from parallel corpora, but all of these have had to be partially manually corrected. According to Table 1, UD Japanese-BCCWJ is the largest UD Japanese corpus. Furthermore, it is the second largest of all UD corpora and includes many documents across various domains as shown in Table 3. Existing Japanese-language corpora tagged with dependency structures include the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the Japanese Dependency Corpus (Mori et al., 2014). These corpora frequently use bunsetsu as the syntactic dependency annotation units for Japanese. Also, the BCCWJ, based on UD Japanese-BCCWJ, is annotated using a bunsetsu-level dependency structure (Asahara and Matsumoto, 2016), which we must thus convert from a bunsetsu-level dependency structure to a Universal Dependencies schema. Figure 1 shows an example of BCCWJ with the UD annotation schema. In this paper, we describe the conversion of the BCCWJ to the UD annotation schema. To accomplish the conversion, the following information must be combined: word-morphological information, bunset"
W18-6014,petrov-etal-2012-universal,0,0.0986808,"Missing"
Y04-1014,Y03-1009,0,\N,Missing
Y04-1014,C04-1067,0,\N,Missing
Y04-1014,W03-1730,0,\N,Missing
Y04-1014,W03-1705,0,\N,Missing
Y04-1014,W03-1719,0,\N,Missing
Y04-1014,W03-1726,0,\N,Missing
Y04-1014,C04-1081,0,\N,Missing
Y04-1014,W03-1720,1,\N,Missing
Y04-1014,W02-1815,0,\N,Missing
Y04-1014,W04-1109,1,\N,Missing
Y06-1044,W03-1719,0,0.0227289,"ictionary. To build a practical system, this number is too small. Therefore, we tried to enlarge the system dictionary using unknown word extraction methods. We intend to extract a large amount of unknown words from a huge raw text corpus. Based on our methods, we have successfully increased the system dictionary to 120,769 entries. Although this number is good enough for a practical system but we still hope to add more in the future. 2 New Segmentation Unit In Chinese language processing community, no single segmentation standard is agreeable across different instituitions. In SIGHAN bakeoff [1], we could see that different institutions have provided different segmentation standards. Most of the disagreements in the standards come from the segmentation of morphologically derived words [2] and named entities. For example, some would say that “孩子们/NN” (children) as one word and some would prefer to it as two words, “孩子/NN” and “们 /M”. For named entities such as Chinese person names, whether a string of a surname and a given name should be one word or two words, is also under argument. It would be nice if we can build a system that suits everyone’s needs but it sounds almost impossible."
Y06-1044,O03-4001,0,0.164599,"unknown words from a huge raw text corpus. Based on our methods, we have successfully increased the system dictionary to 120,769 entries. Although this number is good enough for a practical system but we still hope to add more in the future. 2 New Segmentation Unit In Chinese language processing community, no single segmentation standard is agreeable across different instituitions. In SIGHAN bakeoff [1], we could see that different institutions have provided different segmentation standards. Most of the disagreements in the standards come from the segmentation of morphologically derived words [2] and named entities. For example, some would say that “孩子们/NN” (children) as one word and some would prefer to it as two words, “孩子/NN” and “们 /M”. For named entities such as Chinese person names, whether a string of a surname and a given name should be one word or two words, is also under argument. It would be nice if we can build a system that suits everyone’s needs but it sounds almost impossible. Wu [2] tried to define tree structures to 1 http://www.cis.upenn.edu/~chinese/ 332 morphologically derived words but that will need a lot of human efforts as they are all based on rules defined. G"
Y06-1044,P04-1059,0,0.0146308,"entities. For example, some would say that “孩子们/NN” (children) as one word and some would prefer to it as two words, “孩子/NN” and “们 /M”. For named entities such as Chinese person names, whether a string of a surname and a given name should be one word or two words, is also under argument. It would be nice if we can build a system that suits everyone’s needs but it sounds almost impossible. Wu [2] tried to define tree structures to 1 http://www.cis.upenn.edu/~chinese/ 332 morphologically derived words but that will need a lot of human efforts as they are all based on rules defined. Gao et al. [3] have tried to modify their current system to adapt for all segmentation standards in SIGHAN bakeoff using the transformation-based learning methods [4]. Since we would like to build a system for CTB, we try to define our segmentation units as close as to the CTB standard, or at least to be able to modify back to the CTB standard easily. There are a few changes that we have made on the CTB corpus to suit our purpose and to ease our processing. We refer to this new segmentation units as minimal segmentation units. The changes are made on proper names, foreign words and numeral type words only."
Y06-1044,Y04-1014,1,0.880443,"Missing"
Y06-1044,P03-2039,1,0.887726,"Missing"
Y06-1044,W02-1817,0,0.0322692,"Missing"
Y06-1044,N01-1025,1,0.748391,"5 81.1 84.6 89.8 84.8 87.2 91.4 88.8 90.1 POS Tagging Rec. Prec. F 82.1 75.8 78.8 83.3 78.7 80.9 84.7 82.2 83.5 90.1 90.7 90.4 91.1 91.8 91.5 80.2 73.6 76.7 81.4 76.8 79.1 83.0 80.6 81.8 4.2 CTB Unit Analysis -YamCha The second layer takes the output from the first layer and joins the words by chunking. In order to obtain the original segmentation and POS tags, our task is to join up family names and given names, numbers, numeral type time nouns, and foreign words. The only difference with the original POS tags is that we cannot get back the original POS tags for foreign words. We used YamCha [10] for chunking as it is proved to be efficient for this task. This system is based on Support Vector Machines. The feature sets used are two words and POS tags at both left and right sides of the current word, plus the previous two output labels. The output labels are NR-PER-B, NR-PER-I, CD-B, CD-I, OD-B, OD-I, NT-B, NT-I, FW-B, FW-I and O. Bottom part of Table 3 shows the results of the second layer analysis. While the results of first layer are based on minimal units, the results of second layer are based on CTB units. Since the results are based on different segmentation units, we cannot do"
Y06-1044,W03-1730,0,0.0608622,"Missing"
Y06-1044,W03-1726,0,\N,Missing
Y13-1019,den-etal-2008-proper,0,0.0135002,"sia Conference on Language, Information, and Computation pages 206－214 PACLIC-27 several research institutes (e.g. for syntactic dependency structures, by NAIST and NINJAL; predicate-argument relations, by NAIST, named entities by TITECH , modality, by Tohoku and Yamanashi Universities; Japanese framenet , by Keio University, and so on). The CORE samples are split into annotation priority sets from A to E to allow the annotations to overlie as much as possible. Table 1 shows the basic statistics and priority sets of BCCWJ CORE. The word unit is based on the ’Short Unit Word’, UniDic standard (Den et al., 2008); UniDic is a lexicon for Japanese morphological analysis. 4/WG 2 defined ISO-TimeML as Semantic Annotation Framework(SemAF)-Time (ISO-246171:2012) within the context of TC 37/SC 4. TimeML and ISO-TimeML define four types of entities — ⟨TIMEX3⟩, ⟨EVENT⟩, ⟨MAKEINSTANCE⟩, and ⟨SIGNAL⟩. The ⟨TIMEX3⟩ tag specifies various attributes of time expressions, such as tid, type, quant, freq, mod, and value. The time expressions are categorised into four types: DATE, TIME, DURATION, and SET. The attribute @value includes the normalised values of the time expressions in a machine-readable format. The ⟨EVEN"
Y13-1019,I08-7018,1,0.834627,"10), a task for the SemEval-2010, and TempEval-3 (UzZaman et al., 2013), a task for the SemEval-2013, have been proposed as shared temporal-relation reasoning tasks. In these shared tasks, datasets for English, Italian, Spanish, Chinese, and Korean are provided. However, there is no such resource for the Japanese language. In this paper, we present a means of porting ISO-TimeML into the Japanese language and also describe the basic specifications of ’BCCWJ-TimeBank’ which is a realisation of the temporal information annotation of the Balanced Corpus of Contemporary Written Japanese, or BCCWJ (Maekawa, 2008). 2 Related Research This section explains two related research areas. One is ISO-TimeML, which is an ISO standard for temporal information mark-up languages. The other is BCCWJ, on which we annotate temporal information tags. 2.1 ISO-TimeML The ISO Technical Committee (TC 37) proposes several standards for language resources, under the collective category ’Terminology and other language and content resources’. Four structures of the committee (SC) are established: TC 37/SC 4 1 is charged with looking at annotation standards for all areas of natural language resources. TC 37/SC 4 includes six"
Y13-1019,pustejovsky-etal-2010-iso,0,0.0790886,"Missing"
Y13-1019,S13-2001,0,0.0450549,"sing have been developed, such as an annotation specification TimeML (Pustejovsky et al., 2003) and annotated corpora TimeBank (Pustejovsky et al., 2010) and Aquaint TimeML Corpus. The English annotation specification has been extended as an ISO standard of a temporal information mark-up language – ISO TimeML (ISO, 2008), which covers Italian, Spanish, Chinese and other languages. Temporal information-annotated corpora in various languages have been developed and shared by natural language processing researchers. TempEval-2 (Verhagen et al., 2010), a task for the SemEval-2010, and TempEval-3 (UzZaman et al., 2013), a task for the SemEval-2013, have been proposed as shared temporal-relation reasoning tasks. In these shared tasks, datasets for English, Italian, Spanish, Chinese, and Korean are provided. However, there is no such resource for the Japanese language. In this paper, we present a means of porting ISO-TimeML into the Japanese language and also describe the basic specifications of ’BCCWJ-TimeBank’ which is a realisation of the temporal information annotation of the Balanced Corpus of Contemporary Written Japanese, or BCCWJ (Maekawa, 2008). 2 Related Research This section explains two related re"
Y13-1019,sekine-etal-2002-extended,0,\N,Missing
Y13-1019,C10-2156,0,\N,Missing
Y13-1019,S07-1014,0,\N,Missing
Y13-1019,W09-3417,0,\N,Missing
Y13-1019,P06-1095,0,\N,Missing
Y13-1019,S10-1010,0,\N,Missing
Y13-1019,E14-4026,0,\N,Missing
Y13-1019,sekine-isahara-2000-irex,0,\N,Missing
Y13-1019,C96-1079,0,\N,Missing
Y17-1006,W16-5406,1,0.267648,"Missing"
Y17-1006,C16-1066,1,0.570195,"Missing"
Y17-1006,P16-2094,0,0.0934623,", we present related work on information structure annotation. G¨otze et al. (G¨otze et al., 2007) devised criteria for annotating the information status (given/accessible/new), topic (aboutness/frame setting), and focus (new-information focus/contrastive focus) independently of languages and linguistic theories. Prasad et al. (Prasad et al., 2015) discussed the bridging annotation standard of the Penn Discourse Treebank (Miltsakaki et al., 2004) and PropBank (Palmer et al., 2005). Third, we present language analyses or models with reading time or eye tracking gaze information. Barret et al. (Barrett et al., 2016) presented a POS tagging model with gaze patterns. Klerke et al. (Klerke et al., 2015) presented a grammaticality detection model for machine processed sentences. Iida et al. (Iida et al., 2013) presented an analysis of eye-tracking data for the annotation of predicate– argument relations. Our paper is slightly different from these preced16 Table 1: Data format Column Name surface time logtime measure sample article metadata orig metadata length space subj setorder rspan voc dependent sessionN articleN screenN lineN segmentN is first is last is second last infostatus definiteness specificity a"
Y17-1006,N01-1021,0,0.0404391,"cture. 2 Related Work First, we present related work on eye tracking. The Dundee Eyetracking Corpus (Kennedy and Pynte, 2005) contains reading times for English and French newspaper editorials from 10 native speakers of each language that were recorded by using eye-tracking equipment. The corpus does not target a specific set of linguistic phenomena but instead provides naturally occurring texts for testing diverse hypotheses. For example, Demberg and Keller (Demberg and Keller, 2008) used the corpus to test Gibson’s dependency locality theory (DLT) (Gibson, 2008) and Hale’s surprisal theory (Hale, 2001). The corpus also allows for replications to be conducted; for example, Roland et al. (Roland et al., 2012) concluded that previous analyses (Demberg and Keller, 2007) had been distorted by the presence of a few outlier data points. Second, we present related work on information structure annotation. G¨otze et al. (G¨otze et al., 2007) devised criteria for annotating the information status (given/accessible/new), topic (aboutness/frame setting), and focus (new-information focus/contrastive focus) independently of languages and linguistic theories. Prasad et al. (Prasad et al., 2015) discussed"
Y17-1006,N13-1111,0,0.0710954,"Missing"
Y17-1006,W13-2326,0,0.175718,"ame setting), and focus (new-information focus/contrastive focus) independently of languages and linguistic theories. Prasad et al. (Prasad et al., 2015) discussed the bridging annotation standard of the Penn Discourse Treebank (Miltsakaki et al., 2004) and PropBank (Palmer et al., 2005). Third, we present language analyses or models with reading time or eye tracking gaze information. Barret et al. (Barrett et al., 2016) presented a POS tagging model with gaze patterns. Klerke et al. (Klerke et al., 2015) presented a grammaticality detection model for machine processed sentences. Iida et al. (Iida et al., 2013) presented an analysis of eye-tracking data for the annotation of predicate– argument relations. Our paper is slightly different from these preced16 Table 1: Data format Column Name surface time logtime measure sample article metadata orig metadata length space subj setorder rspan voc dependent sessionN articleN screenN lineN segmentN is first is last is second last infostatus definiteness specificity animacy sentience agentivity commonness Type factor int num factor factor factor factor factor int factor factor factor num num int int int int int int factor factor factor factor factor factor f"
Y17-1006,W15-1814,0,0.131436,"al., 2007) devised criteria for annotating the information status (given/accessible/new), topic (aboutness/frame setting), and focus (new-information focus/contrastive focus) independently of languages and linguistic theories. Prasad et al. (Prasad et al., 2015) discussed the bridging annotation standard of the Penn Discourse Treebank (Miltsakaki et al., 2004) and PropBank (Palmer et al., 2005). Third, we present language analyses or models with reading time or eye tracking gaze information. Barret et al. (Barrett et al., 2016) presented a POS tagging model with gaze patterns. Klerke et al. (Klerke et al., 2015) presented a grammaticality detection model for machine processed sentences. Iida et al. (Iida et al., 2013) presented an analysis of eye-tracking data for the annotation of predicate– argument relations. Our paper is slightly different from these preced16 Table 1: Data format Column Name surface time logtime measure sample article metadata orig metadata length space subj setorder rspan voc dependent sessionN articleN screenN lineN segmentN is first is last is second last infostatus definiteness specificity animacy sentience agentivity commonness Type factor int num factor factor factor factor"
Y17-1006,miltsakaki-etal-2004-penn,0,0.0193575,"ample, Roland et al. (Roland et al., 2012) concluded that previous analyses (Demberg and Keller, 2007) had been distorted by the presence of a few outlier data points. Second, we present related work on information structure annotation. G¨otze et al. (G¨otze et al., 2007) devised criteria for annotating the information status (given/accessible/new), topic (aboutness/frame setting), and focus (new-information focus/contrastive focus) independently of languages and linguistic theories. Prasad et al. (Prasad et al., 2015) discussed the bridging annotation standard of the Penn Discourse Treebank (Miltsakaki et al., 2004) and PropBank (Palmer et al., 2005). Third, we present language analyses or models with reading time or eye tracking gaze information. Barret et al. (Barrett et al., 2016) presented a POS tagging model with gaze patterns. Klerke et al. (Klerke et al., 2015) presented a grammaticality detection model for machine processed sentences. Iida et al. (Iida et al., 2013) presented an analysis of eye-tracking data for the annotation of predicate– argument relations. Our paper is slightly different from these preced16 Table 1: Data format Column Name surface time logtime measure sample article metadata"
Y17-1006,J05-1004,0,0.0132155,"12) concluded that previous analyses (Demberg and Keller, 2007) had been distorted by the presence of a few outlier data points. Second, we present related work on information structure annotation. G¨otze et al. (G¨otze et al., 2007) devised criteria for annotating the information status (given/accessible/new), topic (aboutness/frame setting), and focus (new-information focus/contrastive focus) independently of languages and linguistic theories. Prasad et al. (Prasad et al., 2015) discussed the bridging annotation standard of the Penn Discourse Treebank (Miltsakaki et al., 2004) and PropBank (Palmer et al., 2005). Third, we present language analyses or models with reading time or eye tracking gaze information. Barret et al. (Barrett et al., 2016) presented a POS tagging model with gaze patterns. Klerke et al. (Klerke et al., 2015) presented a grammaticality detection model for machine processed sentences. Iida et al. (Iida et al., 2013) presented an analysis of eye-tracking data for the annotation of predicate– argument relations. Our paper is slightly different from these preced16 Table 1: Data format Column Name surface time logtime measure sample article metadata orig metadata length space subj set"
Y17-1006,W15-2707,0,0.0148947,"s surprisal theory (Hale, 2001). The corpus also allows for replications to be conducted; for example, Roland et al. (Roland et al., 2012) concluded that previous analyses (Demberg and Keller, 2007) had been distorted by the presence of a few outlier data points. Second, we present related work on information structure annotation. G¨otze et al. (G¨otze et al., 2007) devised criteria for annotating the information status (given/accessible/new), topic (aboutness/frame setting), and focus (new-information focus/contrastive focus) independently of languages and linguistic theories. Prasad et al. (Prasad et al., 2015) discussed the bridging annotation standard of the Penn Discourse Treebank (Miltsakaki et al., 2004) and PropBank (Palmer et al., 2005). Third, we present language analyses or models with reading time or eye tracking gaze information. Barret et al. (Barrett et al., 2016) presented a POS tagging model with gaze patterns. Klerke et al. (Klerke et al., 2015) presented a grammaticality detection model for machine processed sentences. Iida et al. (Iida et al., 2013) presented an analysis of eye-tracking data for the annotation of predicate– argument relations. Our paper is slightly different from t"
Y18-1003,Y18-1000,0,0.212312,"Missing"
Y18-1003,W16-5406,1,0.926489,"am Sentence Corpus (Kliegl et al., 2006), the Potsdam-Allahabad Hindi Eyetracking corpus (Husain et al., 2015) and the Beijing Sentence Corpus of Mandarin Chinese (Yan et al., 2010). The corpus does not target a specific set of linguistic phenomena, but instead provides naturally occurring texts to test diverse hypotheses. BCCWJEyeTrack (Asahara et al., 2016) published reading time data for a subset of the core data of the BCCWJ (Maekawa et al., 2014), which consisted of newspaper article (PN: published newspaper) samples. The original BCCWJ-EyeTrack includes syntactic dependency information (Asahara and Matsumoto, 2016). Third, the eye-tracking corpus-based psycholinguistic research is conducted using contrastive statistical analysis with annotations. (Asahara and Kato, 2017) overlaid the annotation of categories in a thesaurus ‘Word List by Semantic Principles’ on BCCWJ-EyeTrack, and explained the relation between reading time and syntactic/semantic categories. (Asahara, 2017) overlaid the annotation of information structure (Miyauchi et al., 2017) and explained the relation between reading time and information structure in discourse. Fourth, there are several preceding work to evaluate wrap-up effect other"
Y18-1003,C16-1066,1,0.861858,"Missing"
Y18-1003,Y17-1006,1,0.823534,"time data for a subset of the core data of the BCCWJ (Maekawa et al., 2014), which consisted of newspaper article (PN: published newspaper) samples. The original BCCWJ-EyeTrack includes syntactic dependency information (Asahara and Matsumoto, 2016). Third, the eye-tracking corpus-based psycholinguistic research is conducted using contrastive statistical analysis with annotations. (Asahara and Kato, 2017) overlaid the annotation of categories in a thesaurus ‘Word List by Semantic Principles’ on BCCWJ-EyeTrack, and explained the relation between reading time and syntactic/semantic categories. (Asahara, 2017) overlaid the annotation of information structure (Miyauchi et al., 2017) and explained the relation between reading time and information structure in discourse. Fourth, there are several preceding work to evaluate wrap-up effect other than the aforementioned ones. (Hill and Murray, 2000) evaluated the reading speed around punctuations including prepositional phrases. (Hirotani et al., 2006) also evaluated clause and sentence wrap-up with punctuation and intonation. (Warren et al., 2009) evaluated intra- and interclause integration by eye-tracking. However, these evaluations are only for Engli"
Y18-1003,P16-2094,0,0.0286688,"rases require a shorter reading time than the apposition clause end phrases; the noun clause end phrases have a shorter reading time than the quotation clause end phrases; and there are reading time differences between causal clause end and attendant circumstance clause end. Section 2 presents related work. Section 3 describes the data. Section 4 shows statistical analysis method. Section 5 presents results with discussions. Finally, Section 6 presents our concluding remarks. 2 Related Work First, we present models of language analysis involving reading time or eye-tracking gaze information. (Barrett et al., 2016) presented a POS tagging model with gaze patterns. (Klerke et al., 2015) presented a grammaticality detection model for machine-processed sentences. Second, we present related work on eye-tracking corpora. The Dundee Eyetracking Corpus (Kennedy and Pynte, 2005) contains reading times for English and French newspaper editorials collected from 10 native speakers of each language, measured using 19 32nd Pacific Asia Conference on Language, Information and Computation Hong Kong, 1-3 December 2018 Copyright 2018 by the authors PACLIC 32 eye-tracking equipment. (Frank et al., 2013) developed UCL cor"
Y18-1003,L18-1012,0,0.0118542,"l., 2015) presented a grammaticality detection model for machine-processed sentences. Second, we present related work on eye-tracking corpora. The Dundee Eyetracking Corpus (Kennedy and Pynte, 2005) contains reading times for English and French newspaper editorials collected from 10 native speakers of each language, measured using 19 32nd Pacific Asia Conference on Language, Information and Computation Hong Kong, 1-3 December 2018 Copyright 2018 by the authors PACLIC 32 eye-tracking equipment. (Frank et al., 2013) developed UCL corpus which includes isolated sentences with eye-tracking data. (Futrell et al., 2018) developed Natural Stories Corpus which comprises selfpaced reading data. Eye-tracking corpora for other languages are also available, including the Potsdam Sentence Corpus (Kliegl et al., 2006), the Potsdam-Allahabad Hindi Eyetracking corpus (Husain et al., 2015) and the Beijing Sentence Corpus of Mandarin Chinese (Yan et al., 2010). The corpus does not target a specific set of linguistic phenomena, but instead provides naturally occurring texts to test diverse hypotheses. BCCWJEyeTrack (Asahara et al., 2016) published reading time data for a subset of the core data of the BCCWJ (Maekawa et a"
Y18-1003,W15-1814,0,0.021636,"es; the noun clause end phrases have a shorter reading time than the quotation clause end phrases; and there are reading time differences between causal clause end and attendant circumstance clause end. Section 2 presents related work. Section 3 describes the data. Section 4 shows statistical analysis method. Section 5 presents results with discussions. Finally, Section 6 presents our concluding remarks. 2 Related Work First, we present models of language analysis involving reading time or eye-tracking gaze information. (Barrett et al., 2016) presented a POS tagging model with gaze patterns. (Klerke et al., 2015) presented a grammaticality detection model for machine-processed sentences. Second, we present related work on eye-tracking corpora. The Dundee Eyetracking Corpus (Kennedy and Pynte, 2005) contains reading times for English and French newspaper editorials collected from 10 native speakers of each language, measured using 19 32nd Pacific Asia Conference on Language, Information and Computation Hong Kong, 1-3 December 2018 Copyright 2018 by the authors PACLIC 32 eye-tracking equipment. (Frank et al., 2013) developed UCL corpus which includes isolated sentences with eye-tracking data. (Futrell e"
