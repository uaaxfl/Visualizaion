2020.coling-demos.1,2020.iwclul-1.4,1,0.839407,"Missing"
2020.coling-demos.1,N19-4022,0,0.0158904,"is capable of automatically generating morphological inflections, and these inflectional forms can be edited together with the continuation lexicon information. In other words, this can be used to fix any issues that are present in the FSTs. However, at the moment, this is a manual endeavor. Whenever the inflectional forms are edited, the person in charge of writing the FSTs can see the edits in the administration view of Ve0 rdd and adjust the FSTs accordingly. A future solution would be to make it possible to inspect and edit FSTs directly in the system, similarly to the system proposed by (Lepp et al., 2019). As a longer term goal for the system is a closer integration with the GiellaLT infrastructure and Akusanat MediaWiki dictionary. Ve0 rdd currently uses the tools and lexicographic information coming from these systems, but any edits made in Ve0 rdd do not get reflected back to the other systems. As the focus is currently in finalizing the printed Skolt Sami dictionary, this bi-directionality has been left for the future. The development of Ve0 rdd continues in close collaboration with the Skolt Sami language community. The immediate next step is to come into an agreement on the layout of the"
2020.coling-demos.1,D19-5519,1,0.798257,"Missing"
2020.coling-demos.1,W17-0601,1,0.895282,"Missing"
2020.coling-demos.1,2020.sltu-1.35,1,0.85974,"Missing"
2020.iwclul-1.4,N19-4021,0,0.0289552,"which is heavily guided by the needs of one individual language. Our infrastrucSkolt word for stream 26 Proceedings of the 6th International Workshop on Computational Linguistics of Uralic Languages, pages 26–30 c 2020 Association for Computational Linguistics Wien, Austria, January 10 — 11, 2020. https://doi.org/10.18653/v1/FIXME Figure 1: A UML diagram illustrating use-cases of the infrastructure ture diﬀers from these projects in that its driving design principle is multilinguality and support for a multitude of diﬀerent Uralic languages. A recent dictionary for St. Lawrence Island Yupik (Hunt et al., 2019) combines Foma-based morphological analyzers with an HTML based search interface. Unlike Akusanat, which does the morphological analysis and generation in the cloud, their solution runs the transducers on the client side with Foma’s Javascript integration. The Livonian dictionary consists of three databases, one – lexical, the second – morphological, and the third – a text corpus. While lemmas and their data are stored in the lexical database, and morphological forms are documented in the morphological database, all words indexed in the corpus refer to lemmas in the lexical database. Thus, all"
2020.nlposs-1.13,W18-7101,0,0.0126717,"iellaLT (Moshagen et al., 2014). GiellaLT provides our transducers with a list of quality attributes. Their infrastructure consists of work done for multiple endangered languages in such a way that the morphological resources can be used in a multitude of different contexts such as disambiguation (Trosterud, 2004; Ens et al., 2019), dependency parsing (Antonsen et al., 2010), online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Wiechetek et al., 2019), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019) and language learning tools (Antonsen and Argese, 2018). In order to gain the added benefit from the GiellaLT infrastructure, we have to design our transducers so that they are compatible with HFST and that they follow a certain morphological tagset and that they take the input and output in a certain format. These requirements define the API our transducers need to implement. An example of this can be seen in Table 1. Apertium (Forcada et al., 2011) is another opensource system that uses FST transducers for rulebased machine translation. They use their own transducer format, but fortunately also support analyzer вирев generator вирев+A+Sg+Nom+Ind"
2020.nlposs-1.13,antonsen-etal-2010-reusing,0,0.040988,"any different systems. Popular tools include XFST (Karttunen et al., 1997), Foma (Hulden, 2009) and OpenFST (Allauzen et al., 2007). However, we use HFST (Helsinki-Finite State Technology) (Lindén et al., 2009) because it is the system used in GiellaLT (Moshagen et al., 2014). GiellaLT provides our transducers with a list of quality attributes. Their infrastructure consists of work done for multiple endangered languages in such a way that the morphological resources can be used in a multitude of different contexts such as disambiguation (Trosterud, 2004; Ens et al., 2019), dependency parsing (Antonsen et al., 2010), online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Wiechetek et al., 2019), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019) and language learning tools (Antonsen and Argese, 2018). In order to gain the added benefit from the GiellaLT infrastructure, we have to design our transducers so that they are compatible with HFST and that they follow a certain morphological tagset and that they take the input and output in a certain format. These requirements define the API our transducers need to implement. An example of this can be"
2020.nlposs-1.13,W19-6139,1,0.705533,"ased morphology can be implemented in many different systems. Popular tools include XFST (Karttunen et al., 1997), Foma (Hulden, 2009) and OpenFST (Allauzen et al., 2007). However, we use HFST (Helsinki-Finite State Technology) (Lindén et al., 2009) because it is the system used in GiellaLT (Moshagen et al., 2014). GiellaLT provides our transducers with a list of quality attributes. Their infrastructure consists of work done for multiple endangered languages in such a way that the morphological resources can be used in a multitude of different contexts such as disambiguation (Trosterud, 2004; Ens et al., 2019), dependency parsing (Antonsen et al., 2010), online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Wiechetek et al., 2019), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019) and language learning tools (Antonsen and Argese, 2018). In order to gain the added benefit from the GiellaLT infrastructure, we have to design our transducers so that they are compatible with HFST and that they follow a certain morphological tagset and that they take the input and output in a certain format. These requirements define the API our transducers n"
2020.nlposs-1.13,E09-2008,0,0.0544611,"ts that are seemingly different, still face the very same technical problems (Mäkelä et al., 2020). In arguably, any work conducted with endangered languages to document them and better serve the small community of speakers has a lot of value. However, the fact that the wheel gets reinvented over and over again leads to fragmentation in the resources available for smaller languages and makes their use more difficult as each individual tool exposes an API of their own. Rule-based morphology can be implemented in many different systems. Popular tools include XFST (Karttunen et al., 1997), Foma (Hulden, 2009) and OpenFST (Allauzen et al., 2007). However, we use HFST (Helsinki-Finite State Technology) (Lindén et al., 2009) because it is the system used in GiellaLT (Moshagen et al., 2014). GiellaLT provides our transducers with a list of quality attributes. Their infrastructure consists of work done for multiple endangered languages in such a way that the morphological resources can be used in a multitude of different contexts such as disambiguation (Trosterud, 2004; Ens et al., 2019), dependency parsing (Antonsen et al., 2010), online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Wiec"
2020.nlposs-1.13,N19-4021,0,0.0213228,"tps://github.com/mikahama/uralicNLP 2 94 Proceedings of Second Workshop for NLP Open Source Software (NLP-OSS), pages 94–100 c Virtual Conference, November 19, 2020. 2020 Association for Computational Linguistics 2 input Designing for a Reusable API It is not uncommon that similar tools and methods are developed by different research groups in different parts of the world for language documentation purposes. To name a few, there are projects developing similar language documentation systems for African languages (Jones and Muftic, 2020), Indonesian languages (Nasution et al., 2018) and Yupik (Hunt et al., 2019), while at the same time, it has been shown that digital humanities projects that are seemingly different, still face the very same technical problems (Mäkelä et al., 2020). In arguably, any work conducted with endangered languages to document them and better serve the small community of speakers has a lot of value. However, the fact that the wheel gets reinvented over and over again leads to fragmentation in the resources available for smaller languages and makes their use more difficult as each individual tool exposes an API of their own. Rule-based morphology can be implemented in many diff"
2020.nlposs-1.13,L18-1536,0,0.0312131,"/github.com/giellalt/lang-mdf 3 https://github.com/mikahama/uralicNLP 2 94 Proceedings of Second Workshop for NLP Open Source Software (NLP-OSS), pages 94–100 c Virtual Conference, November 19, 2020. 2020 Association for Computational Linguistics 2 input Designing for a Reusable API It is not uncommon that similar tools and methods are developed by different research groups in different parts of the world for language documentation purposes. To name a few, there are projects developing similar language documentation systems for African languages (Jones and Muftic, 2020), Indonesian languages (Nasution et al., 2018) and Yupik (Hunt et al., 2019), while at the same time, it has been shown that digital humanities projects that are seemingly different, still face the very same technical problems (Mäkelä et al., 2020). In arguably, any work conducted with endangered languages to document them and better serve the small community of speakers has a lot of value. However, the fact that the wheel gets reinvented over and over again leads to fragmentation in the resources available for smaller languages and makes their use more difficult as each individual tool exposes an API of their own. Rule-based morphology c"
2020.nlposs-1.13,2020.rail-1.1,0,0.0380595,"1 https://github.com/giellalt/lang-myv https://github.com/giellalt/lang-mdf 3 https://github.com/mikahama/uralicNLP 2 94 Proceedings of Second Workshop for NLP Open Source Software (NLP-OSS), pages 94–100 c Virtual Conference, November 19, 2020. 2020 Association for Computational Linguistics 2 input Designing for a Reusable API It is not uncommon that similar tools and methods are developed by different research groups in different parts of the world for language documentation purposes. To name a few, there are projects developing similar language documentation systems for African languages (Jones and Muftic, 2020), Indonesian languages (Nasution et al., 2018) and Yupik (Hunt et al., 2019), while at the same time, it has been shown that digital humanities projects that are seemingly different, still face the very same technical problems (Mäkelä et al., 2020). In arguably, any work conducted with endangered languages to document them and better serve the small community of speakers has a lot of value. However, the fact that the wheel gets reinvented over and over again leads to fragmentation in the resources available for smaller languages and makes their use more difficult as each individual tool expose"
2020.nlposs-1.13,2020.iwclul-1.3,1,0.698546,"´z NA -sami´z Obj+Pl1 -sami´z -sami´z -sami´z -sami´z Table 4: Erzya default first person object (see Table 4). Moksha, however, makes a further semantic split with regard to the category of person in the subject, namely, the form -sama´st’ is used to indicate a second person subject, and -sama´z is used to indcate a third or indefinite person subject (see Table 5). The differences outlined here are not the same, but comparable, to those found in a recent study that evaluated the morphological differences between Komi-Zyrian and Komi-Permyak within the context of FST and treebank development (Rueter et al., 2020). With closely related languages any kind of resource reuse or transfer is rarely trivial, but through careful evaluation of linguistic features and differences we show that these goals are certainly possible and realistic. 4 Current State and Ensuring Maintainability At the time of writing the transducers lemmas, stems and glosses were acquired through several channels. Statistics on the coverage of the Erzya FST can be seen on Table 6. The same statistics for Subj+Sg2 Subj+Pl2 Subj+Sg3 Subj+Pl3 Obj+Sg1 NA -sama´st’ NA -sama´z Obj+Pl1 -sama´st’ -sama´st’ -sama´z -sama´z Table 5: Moksha defaul"
2020.nlposs-1.13,L18-1294,0,0.0171791,", over the past decade there has been an increasing number of publications on Erzya, relating to its morphology (Rueter, 2010), its OCR tools (Silfverberg and Rueter, 2015) and universal dependencies (Rueter and Tyers, 2018). Introduction There are over 5000 languages spoken world wide, and a vast majority of them are endangered (see Moseley 2010). The Mordvinic languages Erzya and Moksha are no exception. One of the first NLP solutions that are typically developed along with lexical resources for any low-resourced language is a morphological analyzer (cf Zueva et al. 2020; Tyers et al. 2019; Lovick et al. 2018). In this paper, we describe the development of an open-source FST (finite-state transducer) based morphological analyzer, lemmatizer and generator for Erzya and Moksha. We highlight the importance of certain design decisions to ensure the compatibility of our transducers with existing systems. In addition, we will describe how the transducers can be edited in a system that creates an abstraction layer behind a graphical user interface for FST development. The unity and diversity of the Mordvin literary languages of today, Erzya and Moksha, has been a subject of research for over two hundred y"
2020.nlposs-1.13,W19-6010,0,0.0284921,"ordvin. Fortunately, over the past decade there has been an increasing number of publications on Erzya, relating to its morphology (Rueter, 2010), its OCR tools (Silfverberg and Rueter, 2015) and universal dependencies (Rueter and Tyers, 2018). Introduction There are over 5000 languages spoken world wide, and a vast majority of them are endangered (see Moseley 2010). The Mordvinic languages Erzya and Moksha are no exception. One of the first NLP solutions that are typically developed along with lexical resources for any low-resourced language is a morphological analyzer (cf Zueva et al. 2020; Tyers et al. 2019; Lovick et al. 2018). In this paper, we describe the development of an open-source FST (finite-state transducer) based morphological analyzer, lemmatizer and generator for Erzya and Moksha. We highlight the importance of certain design decisions to ensure the compatibility of our transducers with existing systems. In addition, we will describe how the transducers can be edited in a system that creates an abstraction layer behind a graphical user interface for FST development. The unity and diversity of the Mordvin literary languages of today, Erzya and Moksha, has been a subject of research f"
2020.nlposs-1.13,W18-0213,0,0.0276698,"line user interfaces Ve’rdd (Alnajjar et al., 2020) and Akusanat (Hämäläinen and Rueter, 2018) that make it possible to edit XML based dictionaries for anyone without any technical background. This is important since direct edits to an XML might be daunting for a language community member who has no programming background. These two different levels of abstraction ultimately produce XMLs in the GiellaLT format that can be directly used to enhance the transducers. To provide further comparison, a very similar mechanism to store lexicon externally from the FST has also been used successfully by Wilbur (2018) with Pite Saami. Also in this case same lexicon is used in FST, in a published dictionary (Wilbur, 2016), and in an online dictionary4 . This shows that approach described here is practical, Table 6: Statistics for Erzya transducers word class common nouns proper nouns adjectives verbs lemma:stem pairs total 12851 50070 12043 13449 92716 glossed 9056 267 4083 11577 26572 inflections 426 (426) (426) 337 derivations 6 6 1 10 23 Table 7: Statistics for Moksha transducers Moksha are shown in Table 7. Although the largest bilingual dictionaries for Erzya and Moksha provide declension information,"
2020.nlposs-1.13,2020.lrec-1.314,0,0.0146772,"be done for Erzya Mordvin. Fortunately, over the past decade there has been an increasing number of publications on Erzya, relating to its morphology (Rueter, 2010), its OCR tools (Silfverberg and Rueter, 2015) and universal dependencies (Rueter and Tyers, 2018). Introduction There are over 5000 languages spoken world wide, and a vast majority of them are endangered (see Moseley 2010). The Mordvinic languages Erzya and Moksha are no exception. One of the first NLP solutions that are typically developed along with lexical resources for any low-resourced language is a morphological analyzer (cf Zueva et al. 2020; Tyers et al. 2019; Lovick et al. 2018). In this paper, we describe the development of an open-source FST (finite-state transducer) based morphological analyzer, lemmatizer and generator for Erzya and Moksha. We highlight the importance of certain design decisions to ensure the compatibility of our transducers with existing systems. In addition, we will describe how the transducers can be edited in a system that creates an abstraction layer behind a graphical user interface for FST development. The unity and diversity of the Mordvin literary languages of today, Erzya and Moksha, has been a su"
2020.paclic-1.60,L18-1530,0,0.366244,"cy when there is more training data. They also present a comparison of models trained on different amounts of training data using Na and Chatino data, which also inspired our own comparative experiments. We have also seen very recently large improvements in such systems on related Uralic languages, for example Zyrian Komi (Hjortnaes et al., 2020b; Hjortnaes et al., 2020a). We have also seen experiments where ASR is being integrated to the language documentation workflows, for example, in Papuan context (Zahrer et al., 2020). Most widely applied speech recognition systems have been Persephone (Adams et al., 2018), Elpis (Foley et al., 2018) and DeepSpeech (Hannun et al., 2014). In this paper, we present and discuss several experiments we have done using Persephone system. 3 Languages and Data Nganasan is an endangered Samoyedic language spoken by Nganasans, a small ethnic group in Taimyr Peninsula, Northern Siberia (Janhunen and Gruzdeva, 2020). According to official statistics there are 470 Nganasans, from who approximately 125 speak the Nganasan language (WagnerNagy, 2018, 3,17). Despite languages endangerment, plenty of documentation work has been conducted (Leisio, 2006; Wagner-Nagy, 2014; Kaheine"
2020.paclic-1.60,2020.sltu-1.51,0,0.314891,"Missing"
2020.paclic-1.60,R19-1051,1,0.825725,"ds lie. These experiments are described in Table 3. While discussing the results we have also compared our error rates to those reported in other studies, in order to understand better how the variation we see connects to earlier studies with different languages. 5 Results In this section, we present the results of the different models. These results are reported as a LER (label error rate) score. In practice, this is a measurement similar to CER (character error rate) that is widely used in studies focusing on text normalization and OCR correction (see (Tang et al., 2018; Veliz et al., 2019; Hämäläinen and Hengchen, 2019)). 5.1 Nganasan Results In Nganasan experiment we selected utterances from three most prominent speakers. Table 1 shows the amount of data that we used and the accuracy reached. We can easily conclude that the results were not successful in all experiments. In the cases where we had less than an hour of transcriptions, the quality was extremely low. When the label error rate is Compared to the Nganasan experiment, the Kamas results are very different. Indeed, the results we achieve are very high, and on par with the best scores reported elsewhere for Persephone. We argue that the primary reaso"
2020.paclic-1.60,2020.sltu-1.47,1,0.892442,"ed language context has seen significant improvements, especially in scenarios where there is only one single speaker. Adams et. al. (2018) report a reasonable accuracy under these circumstances already with just a few hours of transcribed data, with rapid increase in accuracy when there is more training data. They also present a comparison of models trained on different amounts of training data using Na and Chatino data, which also inspired our own comparative experiments. We have also seen very recently large improvements in such systems on related Uralic languages, for example Zyrian Komi (Hjortnaes et al., 2020b; Hjortnaes et al., 2020a). We have also seen experiments where ASR is being integrated to the language documentation workflows, for example, in Papuan context (Zahrer et al., 2020). Most widely applied speech recognition systems have been Persephone (Adams et al., 2018), Elpis (Foley et al., 2018) and DeepSpeech (Hannun et al., 2014). In this paper, we present and discuss several experiments we have done using Persephone system. 3 Languages and Data Nganasan is an endangered Samoyedic language spoken by Nganasans, a small ethnic group in Taimyr Peninsula, Northern Siberia (Janhunen and Gruzd"
2020.paclic-1.60,2020.iwclul-1.5,1,0.745755,"ed language context has seen significant improvements, especially in scenarios where there is only one single speaker. Adams et. al. (2018) report a reasonable accuracy under these circumstances already with just a few hours of transcribed data, with rapid increase in accuracy when there is more training data. They also present a comparison of models trained on different amounts of training data using Na and Chatino data, which also inspired our own comparative experiments. We have also seen very recently large improvements in such systems on related Uralic languages, for example Zyrian Komi (Hjortnaes et al., 2020b; Hjortnaes et al., 2020a). We have also seen experiments where ASR is being integrated to the language documentation workflows, for example, in Papuan context (Zahrer et al., 2020). Most widely applied speech recognition systems have been Persephone (Adams et al., 2018), Elpis (Foley et al., 2018) and DeepSpeech (Hannun et al., 2014). In this paper, we present and discuss several experiments we have done using Persephone system. 3 Languages and Data Nganasan is an endangered Samoyedic language spoken by Nganasans, a small ethnic group in Taimyr Peninsula, Northern Siberia (Janhunen and Gruzd"
2020.paclic-1.60,W19-0307,1,0.782632,"also through our published new datasets. There is a rule based morphological analyser for Nganasan (Endrédy et al., 2010), which, however, appears to be available only through a web interface, and is not open access. What it comes to other Samoyedic languages, a rule based Tundra Nenets morphological analyser exists in the GiellaLT infrastructure (Moshagen et al., 2014)8 with availability through UralicNLP (Hämäläinen, 2019). There are also early Selkup9 and Nganasan10 analysers in the same infrastructure. Also OCR models have been developed to target early writing systems on these languages (Partanen and Rießler, 2019b), with associated data pack7 https://zenodo.org/record/4029494 https://github.com/giellalt/lang-yrk 9 https://github.com/giellalt/lang-sel 10 https://github.com/giellalt/lang-nio 8 age (Partanen and Rießler, 2018). This responds well to OCR challenges identified earlier for these languages by Partanen (2017). The vast majority of these languages have virtually no language technology at the moment, but as there are increasingly larger and larger corpora, the possibilities for future work are many. One challenge in working with these endangered languages is that very few researchers are able t"
2020.paclic-1.60,2020.lrec-1.324,0,0.0319159,"ifferences between the original transcription and IPA representation. These are primarily about the how the long vowels are presented, as the original transcript was primarily split to characters, whereas the converted IPA has more phonemic units as individual labels. This process gave us two more transcriptions versions: Plain IPA text, and an IPA version where only those word boundaries were retained which occurred within natural pauses. This work was highly experimental, and we did not correct the segmentations manually. Same Kamas data will be included in manually corrected DoReCo corpus (Paschen et al., 2020), which will allow better inspection of these Experiment 1 2 3 Utterances 1152 512 704 Minutes 108 57 43 LER 0.334 0.930 0.892 Table 1: Nganasan experiments with three different speakers. Exp. 4 5 6 7 Description Original transcript, no spaces Original transcript, with spaces IPA transcript, no spaces IPA transcript, real pauses LER 0.226 0.195 0.149 0.243 Table 2: Kamas experiments with 4224 training samples, 266 minutes. features. Our primary goal in this experiment was simply to investigate whether essentially very minor changes in transcriptions impact the result, and to see if different r"
2020.paclic-1.60,W17-0601,1,0.780526,"Missing"
2020.paclic-1.60,C18-1112,0,0.027766,"show where the most important thresholds lie. These experiments are described in Table 3. While discussing the results we have also compared our error rates to those reported in other studies, in order to understand better how the variation we see connects to earlier studies with different languages. 5 Results In this section, we present the results of the different models. These results are reported as a LER (label error rate) score. In practice, this is a measurement similar to CER (character error rate) that is widely used in studies focusing on text normalization and OCR correction (see (Tang et al., 2018; Veliz et al., 2019; Hämäläinen and Hengchen, 2019)). 5.1 Nganasan Results In Nganasan experiment we selected utterances from three most prominent speakers. Table 1 shows the amount of data that we used and the accuracy reached. We can easily conclude that the results were not successful in all experiments. In the cases where we had less than an hour of transcriptions, the quality was extremely low. When the label error rate is Compared to the Nganasan experiment, the Kamas results are very different. Indeed, the results we achieve are very high, and on par with the best scores reported elsew"
2020.paclic-1.60,D19-5536,0,0.0607409,"Missing"
2020.paclic-1.60,2020.sltu-1.43,0,0.265312,"9). We used Klavdiya Plotnikova’s part of the corpus in our Kamas experiments, as she contributes the vast majority of all Kamas materials that exists. In the Nganasan experiments, we used the data from three prominent speakers in the Nganasan Spoken Language Corpus, who are also mentioned in the Nganasan grammar based largely to the same materials (Wagner-Nagy, 2018, 30). One of the most important preprocessing steps was to exclude from training all sentences that are longer than 10 seconds. This is a condition set by Persephone system, and a convention followed also in other investigations (Wisniewski et al., 2020, 30). Similarly, Hjortnaes et al (2020b) filtered Zyrian Komi corpus by this limit. This choice leaves open an obvious possibility to improve the current results. As the filtered portion of the corpus is relatively large, either finding a way to include longest segments into the training process, or splitting those into smaller units, would easily increase the amount of training data. Preprocessing conventions were very similar with both corpora, although independent inspection of particularities of individual datasets was done. It is customary that we work with speech corpora includes an int"
2020.paclic-1.60,2020.lrec-1.353,0,0.119411,"cumstances already with just a few hours of transcribed data, with rapid increase in accuracy when there is more training data. They also present a comparison of models trained on different amounts of training data using Na and Chatino data, which also inspired our own comparative experiments. We have also seen very recently large improvements in such systems on related Uralic languages, for example Zyrian Komi (Hjortnaes et al., 2020b; Hjortnaes et al., 2020a). We have also seen experiments where ASR is being integrated to the language documentation workflows, for example, in Papuan context (Zahrer et al., 2020). Most widely applied speech recognition systems have been Persephone (Adams et al., 2018), Elpis (Foley et al., 2018) and DeepSpeech (Hannun et al., 2014). In this paper, we present and discuss several experiments we have done using Persephone system. 3 Languages and Data Nganasan is an endangered Samoyedic language spoken by Nganasans, a small ethnic group in Taimyr Peninsula, Northern Siberia (Janhunen and Gruzdeva, 2020). According to official statistics there are 470 Nganasans, from who approximately 125 speak the Nganasan language (WagnerNagy, 2018, 3,17). Despite languages endangerment,"
2020.sltu-1.35,2020.iwclul-1.4,1,0.301179,"orms in a given conjugation paradigm. Nonfinite derivation, participles in addition to deverbal nouns and verbs, adds feeders to nominal and verbal derivation alike. A large percentage of this regular inflection is in place and available in the UralicNLP, a python library for Uralic minority languages (Hämäläinen, 2019). The lexical database for Skolt Sami is also undergoing rigorous scrutiny and development in the editing of the forth-coming Moshnikoff Skolt Sami dictionary in Ve0 rdd9 , an open-source dictionary environment for minority language community editor and developer collaboration (Alnajjar et al., 2020). Ve0 rdd ‘stream, flow’ also provides an interface for feedback into the dictionary system. 5. Discussion and Future Work The FSTs are released in GiellaLT infrastructure as a constantly updating bleeding edge release. Efforts have been made to bring the writing of the FST lexc materials into an easier MediaWiki based framework (Rueter and Hämäläinen, 2017). All edits to the FSTs made in the MediaWiki platform are automatically synchronized with those uploaded to GiellaLT. According to statistics at GiellaLT for online dictionary usage, the Skolt Sami–Finnish dictionary enjoys a great popular"
2020.sltu-1.35,W17-0215,0,0.0292219,"e (Moshagen et al., 2013) and (Moshagen et al., 2014), and previous work also exists for Skolt Sami3 (Sammallahti and Mosnikoff, 1991; Sammallahti, 2015; Feist, 2015). There are online and click-in-text dictionaries (Rueter, 2017), 4 spell checkers (Morottaja et al., 2018), 5 , these are implemented in OpenOffice, but some of the more prominent languages are supported in MS Word, as well as rule-based language learning (Antonsen et al., 2013; Uibo et al., 2015). For languages with extensive description and documentation, there are syntax checkers (Wiechetek et al., 2019), machine translation (Antonsen et al., 2017) and speech synthesis and recognition (Hjortnaes et al., 2020), just to mention the tip of the iceberg (Rueter, 2014). From a language learner and research point of departure, the development and application of these tools points to well-organized morphosyntactic and lexical descriptions of the language in focus. By well-organized descriptions, we mean approaching tasks at hand with applied reusability. Reusability is illustrated in the construction of a morphological analyzer for linguists, which, due to the fact that it is able to recognize and analyze regular morphological forms, can also s"
2020.sltu-1.35,E17-1032,0,0.0310602,"sive suffix: +N+Pl+Com+PxSg3. Essentially all nouns in the selected vocabulary available for this reading are inadvertently presented to the learner. 2. Related Work In the past, multiple methods have been proposed for automatically learning morphology for a given language. One of these is Morfessor (Creutz and Lagus, 2007), which is a set of tools designed to learn morphology from raw textual data. It has been developed with Finnish in mind, and this means that it is intended to perform well with extensive regular morphology, i.e. morphologically rich languages, too. Bergmanis and Goldwater (Bergmanis and Goldwater, 2017) present another statistical approach that can also take spelling variation into account. Their approach is based on the notion of a morphological chain consisting of childparent pairs. When analyzing the morphology of a language, the approach takes several features into account such as presence of the parent in the training data, semantic similarity, likely affixes and so on. Such statistical approaches, however, are data-hungry. This is a problem for various reasons in the case of Skolt Sami. 6 http://oanpa.no/davvi/morfas/ The scarce quantity of textual data is one limitation, but it is eve"
2020.sltu-1.35,W19-6139,1,0.747422,"thongs will be analogous to that of quantity. Especially front and fronted diphthongs still offer unresolved variation in the paradigms of a number of nouns. FSTs provide a good starting point for development of higher level NLP tools that embrace the new neural network methods. For instance, FSTs can be used to generate parallel sentences out of lexica and abstract syntax descriptions to be used for neural machine translation in scenarios without any real parallel data (Hämäläinen and Alnajjar, 2019). Neural models for morphological tagging can as well benefit from readings provided by FSTs (Ens et al., 2019). 6. Conclusions We have presented the current state of our on-going project of modeling Skolt Sami morphology. The transducers are 9 https://akusanat.com/verdd/ made available in a continuously updated fashion in multiple different channels, to promote their use in any tasks that contributes to the revitalization of the language The highly phonological Skolt Sami orthography has strengthened the notion that one description might be utilized in multiple tools, i.e. text-to-speech, orthographic, pedagogical, etc. This has lead to the addition of two extra characters in the alphabet and the addi"
2020.sltu-1.35,2020.iwclul-1.5,0,0.0207948,"evious work also exists for Skolt Sami3 (Sammallahti and Mosnikoff, 1991; Sammallahti, 2015; Feist, 2015). There are online and click-in-text dictionaries (Rueter, 2017), 4 spell checkers (Morottaja et al., 2018), 5 , these are implemented in OpenOffice, but some of the more prominent languages are supported in MS Word, as well as rule-based language learning (Antonsen et al., 2013; Uibo et al., 2015). For languages with extensive description and documentation, there are syntax checkers (Wiechetek et al., 2019), machine translation (Antonsen et al., 2017) and speech synthesis and recognition (Hjortnaes et al., 2020), just to mention the tip of the iceberg (Rueter, 2014). From a language learner and research point of departure, the development and application of these tools points to well-organized morphosyntactic and lexical descriptions of the language in focus. By well-organized descriptions, we mean approaching tasks at hand with applied reusability. Reusability is illustrated in the construction of a morphological analyzer for linguists, which, due to the fact that it is able to recognize and analyze regular morphological forms, can also serve as a morphological spell checker. In fact, this same anal"
2020.sltu-1.35,W13-5631,0,0.0713536,"Missing"
2020.sltu-1.35,W17-0601,1,0.560572,"Sami is also undergoing rigorous scrutiny and development in the editing of the forth-coming Moshnikoff Skolt Sami dictionary in Ve0 rdd9 , an open-source dictionary environment for minority language community editor and developer collaboration (Alnajjar et al., 2020). Ve0 rdd ‘stream, flow’ also provides an interface for feedback into the dictionary system. 5. Discussion and Future Work The FSTs are released in GiellaLT infrastructure as a constantly updating bleeding edge release. Efforts have been made to bring the writing of the FST lexc materials into an easier MediaWiki based framework (Rueter and Hämäläinen, 2017). All edits to the FSTs made in the MediaWiki platform are automatically synchronized with those uploaded to GiellaLT. According to statistics at GiellaLT for online dictionary usage, the Skolt Sami–Finnish dictionary enjoys a great popularity among the language community. It is only second to North Sami–Norwegian (Trosterud, p.c. 2019–06–04). Statistics provide pointers for where elaboration is needed in definitions as well as the shortcomings of the transducer (analysis of misspelled words). In order to make the FSTs more accessible for other resarchers conducting NLP tasks focused on Skolt"
2020.sltu-1.35,W17-0602,1,0.824706,".no/korp/ members access to language materials directly. The trick is to find new uses and reuses for data sets and technologies as well as to bring development closer to the language community. If development follows the North Sámi lead, any project can reap from the work already done. Extensive work has already been done on data and tool development in the GiellaLT infrastructure (Moshagen et al., 2013) and (Moshagen et al., 2014), and previous work also exists for Skolt Sami3 (Sammallahti and Mosnikoff, 1991; Sammallahti, 2015; Feist, 2015). There are online and click-in-text dictionaries (Rueter, 2017), 4 spell checkers (Morottaja et al., 2018), 5 , these are implemented in OpenOffice, but some of the more prominent languages are supported in MS Word, as well as rule-based language learning (Antonsen et al., 2013; Uibo et al., 2015). For languages with extensive description and documentation, there are syntax checkers (Wiechetek et al., 2019), machine translation (Antonsen et al., 2017) and speech synthesis and recognition (Hjortnaes et al., 2020), just to mention the tip of the iceberg (Rueter, 2014). From a language learner and research point of departure, the development and application"
2020.sltu-1.35,W15-1906,1,0.81955,"mi lead, any project can reap from the work already done. Extensive work has already been done on data and tool development in the GiellaLT infrastructure (Moshagen et al., 2013) and (Moshagen et al., 2014), and previous work also exists for Skolt Sami3 (Sammallahti and Mosnikoff, 1991; Sammallahti, 2015; Feist, 2015). There are online and click-in-text dictionaries (Rueter, 2017), 4 spell checkers (Morottaja et al., 2018), 5 , these are implemented in OpenOffice, but some of the more prominent languages are supported in MS Word, as well as rule-based language learning (Antonsen et al., 2013; Uibo et al., 2015). For languages with extensive description and documentation, there are syntax checkers (Wiechetek et al., 2019), machine translation (Antonsen et al., 2017) and speech synthesis and recognition (Hjortnaes et al., 2020), just to mention the tip of the iceberg (Rueter, 2014). From a language learner and research point of departure, the development and application of these tools points to well-organized morphosyntactic and lexical descriptions of the language in focus. By well-organized descriptions, we mean approaching tasks at hand with applied reusability. Reusability is illustrated in the co"
2020.sltu-1.35,W19-0312,0,0.012587,"tool development in the GiellaLT infrastructure (Moshagen et al., 2013) and (Moshagen et al., 2014), and previous work also exists for Skolt Sami3 (Sammallahti and Mosnikoff, 1991; Sammallahti, 2015; Feist, 2015). There are online and click-in-text dictionaries (Rueter, 2017), 4 spell checkers (Morottaja et al., 2018), 5 , these are implemented in OpenOffice, but some of the more prominent languages are supported in MS Word, as well as rule-based language learning (Antonsen et al., 2013; Uibo et al., 2015). For languages with extensive description and documentation, there are syntax checkers (Wiechetek et al., 2019), machine translation (Antonsen et al., 2017) and speech synthesis and recognition (Hjortnaes et al., 2020), just to mention the tip of the iceberg (Rueter, 2014). From a language learner and research point of departure, the development and application of these tools points to well-organized morphosyntactic and lexical descriptions of the language in focus. By well-organized descriptions, we mean approaching tasks at hand with applied reusability. Reusability is illustrated in the construction of a morphological analyzer for linguists, which, due to the fact that it is able to recognize and an"
2020.sltu-1.5,P17-1095,0,0.0410675,"Missing"
2020.sltu-1.5,antonsen-etal-2010-reusing,1,0.828183,"Missing"
2020.sltu-1.5,P16-1184,0,0.0313598,"ith neural networks to solve the problem of disambiguation (Ens et al., 2019). 2. Uralic languages call for a more full blown morphological disambiguation than a mere POS tagging in order to make higher-level NLP tools usable for these languages. Moreover, our approach cannot count on the existence of high-quality bilingual dictionaries between morphologically similar languages nor aligned word embeddings, as such resources are not easily available for endangered languages. Related Work Parallel texts have been used to deal with morphological tagging in the context of low-resourced languages (Buys and Botha, 2016). They use aligned parallel sentences to train their their Wsabie-based model to tag the low-resource language based on the morphological tags of a more resourced language sentences in the training data. A limitation of this approach is that the morphological relatedness of the high-resource and low-resource languages has to be high. Andrews et al. (Andrews et al., 2017) have proposed a method for POS (part of speech) tagging of low-resource languages. They use a bilingual dictionary between a lowresource and high-resource language. In addition, their system requires monolingual data for build"
2020.sltu-1.5,W19-6139,1,0.798504,"Missing"
2020.sltu-1.5,C90-3030,0,0.360927,"f 500 speakers, is categorized as severely endangered by UNESCO (Moseley, 2010) and is spoken in Norway and Sweden. The language is spoken in Norway and Sweden and its bilingual users frequently face bigger challenges regarding literacy in the lesser used language than in the majority language due to reduced access to language arenas (Outakoski, 2013; Lindgren et al., 2016). The central tools used for disambiguation of S´ami languages are finite state transducers and Constraint Grammars. Constraint Grammar is a rule-based formalism for writing disambiguation and syntactic annotation grammars (Karlsson, 1990; Karlsson et al., 1995). Constraint Grammar relies on a bottom-up analysis of running text. Possible but unlikely analyses are discarded step by step with the help of morpho-syntactic context. The vislcg3 implementation1 is used in particular. South S´ami has several Constraint Grammars including a morpho-syntactic disambiguator, a shallow syntactic analyzer, and a dependency analyzer (Antonsen et al., 2010; Antonsen and Trosterud, 2011). Antonsen and Trosterud (2011) use a fairly small Constraint Grammar (115 rules) for South S´ami part of speech (POS) and lemma disambiguation, resulting in"
2020.sltu-1.5,P17-4012,0,0.0171994,"gs, we converted the tags automatically into UD format, since the neural network is trained to output UD tags. The evaluation results are shown in Table 4. The first column shows the percentage of sentences that have been fully disambiguated correctly, the second columns shows this on a word level i.e. how many words were fully correctly disambiguated and finally the last column shows the accuracy in POS tagging. The results indicate that adding the small synthetically generated data to the training boosted the results significantly. We train a sequence-to-sequence Bi-RNN model using OpenNMT (Klein et al., 2017) with the default settings except for the encoder where we use a BRNN (bi-directional recurrent neural network) instead of the default RNN (recurrent neural network) as BRNN has been shown to provide a performance gain in a variety of tasks. We use the default of two layers for both the encoder and the decoder and the default attention model, which is the general global attention presented by Luong et al. (Luong et al., 2015). We experiment with two models, one that is trained with the North S´ami Treebank only, and another one that is trained with South S´ami text generated by templates and t"
2020.sltu-1.5,L18-1352,0,0.126092,"n of this approach is that the morphological relatedness of the high-resource and low-resource languages has to be high. Andrews et al. (Andrews et al., 2017) have proposed a method for POS (part of speech) tagging of low-resource languages. They use a bilingual dictionary between a lowresource and high-resource language. In addition, their system requires monolingual data for building cross-lingual word embeddings. The resulting POS tagger is trained on an LSTM neural network, and their approach performs consistently better than the other approaches on the benchmarks they report. Lim et al. (Lim et al., 2018) present an approach for syntactic parsing of Komi-Zyrian and North S´ami data using multilingual word embeddings. They use pre-trained wordembeddings of two high-resource languages; Finnish and Russian. Then they train monolingual word-embeddings for the low-resource languages from small corpora. They project these individual word embeddings into a single space by using bilingual dictionaries for alignment. The parser was implemented as an LSTM based model, and its performance is higher for POS tagging than for syntactic parsing. The most important finding for our purposes is that including a"
2020.sltu-1.5,D15-1166,0,0.0534109,"Missing"
2020.sltu-1.5,D18-1061,0,0.064848,"Missing"
2020.sltu-1.5,W19-6012,0,0.0527049,"Missing"
2020.sltu-1.5,P16-1009,0,0.0225087,"ture is how far one could get in disambiguation with our proposed method if one was only to train the model by using templates. As even a small number of templates was enough to improve the results noticeably, an entirely template based approach does not seem to be entirely out of the question. Especially if the templates were constructed with more generative freedom such as by following a formalism deriving from CFG (context-free grammar). The use of synthetically generated source data is known to improve NMT (neural machine translation) models when the target data is of a high quality (see (Sennrich et al., 2016)). Also, some promising work has been conducted in fully synthetically generated parallel data in NMT (H¨am¨al¨ainen and Alnajjar, 2019). This year has been particularly good for Uralic languages with small UD Treebanks recently published for Skolt S´ami, Karelian, Livvi, Komi-Permyak and Moksha. This means that in the future we can try different variations of our method with these languages as well with minimal modifications to the current approach as all of these languages have rule-based FSTs available in the GiellaLT infrastructure. Table 5: Errors based on the number of erroneous morpholo"
2020.sltu-1.5,W19-0301,0,0.0251869,"Missing"
2020.sltu-1.5,W17-0607,0,0.028522,"of low-resource languages. Their core idea is to use a biLSTM model to project POS tags from one language to another with the help of lexical information and word embeddings. Their experiments in a low-resource setting reveal that including word embeddings can boost the model, but lexical information can also help to a smaller degree. The scope of a great part of the related work is limited to POS tagging. Nevertheless, the morphologically rich 3. Data and Tools The training data for South S´ami disambiguation comes from the Universal Dependencies Treebank of the related North S´ami language (Sheyanova and Tyers, 2017). Out of all the S´ami languages, North S´ami has by and large the biggest amount of NLP resources available and therefore its use as a starting point for related languages makes perfect sense. The treebank consists of 26K tokens and comes pre-divided into a training and testing datasets. In addition to the treebank, we use FSTs for both North S´ami and South S´ami with UralicNLP (H¨am¨al¨ainen, 2019). These transducers are integrated in the open GiellaLT infrastructure (Moshagen et al., 2014) for Uralic languages. The FSTs take in a word in an inflectional form and produce all the possible mo"
2021.americasnlp-1.4,L18-1293,0,0.028562,"rphology is encountered in the expression of possession. While the possessor of a noun may be indicated morphologically on the possessum, it is not obligatory. A preceding personal pronoun, for example, also serves as a marker of possession, to which the morphology of the possessum reacts and shows indication of being possessed. Hence, there are four basic categories that can be expressed on the possessum: The Feature of CASE, for example, permeates many of the individual language projects, and some attempts are made to align case documentation with principles adapted in the Unimorph project (Kirov et al., 2018). In the instance of Apurinã, parallel case categories have been adapted with names familiar to those used in work with languages of the Uralic language family. This was done princi29 person, number and gender of the possessor, on the one hand, and indication of whether the entity is a possessum or not, on the other. These categories are expressed as feature and value pairs in the UD project: body part person other Possessed kywy sytu-re kuta-re2 Not Possessed kyw˜ı-txi sytu kuta-ry2 translation ’head’ ’woman’ ’basket’ Table 1: Marking of possessed feature • Gender[psor]=Masc|Fem 2.3 • Number["
2021.americasnlp-1.4,W19-6139,1,0.717342,"ka Hämäläinen1 and Niko Partanen1 1 University of Helsinki 2 Universidade Federal do Pará 1 firstname.lastname@helsinki.fi 2 {mfpf,sidi}@ufpa.br Abstract resource that helps to maintain consistency in the treebanks of this complex linguistic regions. The advantage of UD treebanks is that they can be used directly in many neural NLP applications such as parsers (Qi et al., 2020) and part-of-speech taggers (Kim et al., 2017). Although the endangered languages have a very different starting point in comparison with large languages (Hämäläinen, 2021), there has been recent work (Lim et al., 2018; Ens et al., 2019; Hämäläinen and Wiechetek, 2020; Alnajjar, 2021) showcasing good results on a variety of tasks even for the few endangered languages that have a UD treebank. The fact that UD treebanks can be used with neural models to build higher level NLP tools is one of the key motivations for us to build this resource for Apurinã. In addition to NLP research, UD treebanks have been used in many purely linguistically motivated research papers (Croft et al., 2017; Levshina, 2017, 2019; Sinnemäki and Haakana, 2020). We believe such developments will only grow stronger, and believe that easily available tree"
2021.americasnlp-1.4,L18-1352,1,0.82673,"lva Facundes2 , Mika Hämäläinen1 and Niko Partanen1 1 University of Helsinki 2 Universidade Federal do Pará 1 firstname.lastname@helsinki.fi 2 {mfpf,sidi}@ufpa.br Abstract resource that helps to maintain consistency in the treebanks of this complex linguistic regions. The advantage of UD treebanks is that they can be used directly in many neural NLP applications such as parsers (Qi et al., 2020) and part-of-speech taggers (Kim et al., 2017). Although the endangered languages have a very different starting point in comparison with large languages (Hämäläinen, 2021), there has been recent work (Lim et al., 2018; Ens et al., 2019; Hämäläinen and Wiechetek, 2020; Alnajjar, 2021) showcasing good results on a variety of tasks even for the few endangered languages that have a UD treebank. The fact that UD treebanks can be used with neural models to build higher level NLP tools is one of the key motivations for us to build this resource for Apurinã. In addition to NLP research, UD treebanks have been used in many purely linguistically motivated research papers (Croft et al., 2017; Levshina, 2017, 2019; Sinnemäki and Haakana, 2020). We believe such developments will only grow stronger, and believe that eas"
2021.americasnlp-1.4,2020.sltu-1.5,1,0.845273,"Niko Partanen1 1 University of Helsinki 2 Universidade Federal do Pará 1 firstname.lastname@helsinki.fi 2 {mfpf,sidi}@ufpa.br Abstract resource that helps to maintain consistency in the treebanks of this complex linguistic regions. The advantage of UD treebanks is that they can be used directly in many neural NLP applications such as parsers (Qi et al., 2020) and part-of-speech taggers (Kim et al., 2017). Although the endangered languages have a very different starting point in comparison with large languages (Hämäläinen, 2021), there has been recent work (Lim et al., 2018; Ens et al., 2019; Hämäläinen and Wiechetek, 2020; Alnajjar, 2021) showcasing good results on a variety of tasks even for the few endangered languages that have a UD treebank. The fact that UD treebanks can be used with neural models to build higher level NLP tools is one of the key motivations for us to build this resource for Apurinã. In addition to NLP research, UD treebanks have been used in many purely linguistically motivated research papers (Croft et al., 2017; Levshina, 2017, 2019; Sinnemäki and Haakana, 2020). We believe such developments will only grow stronger, and believe that easily available treebanks in the UD project, coverin"
2021.americasnlp-1.4,2020.acl-demos.14,0,0.0500764,"Missing"
2021.americasnlp-1.4,D17-1302,0,0.0256255,"Missing"
2021.americasnlp-1.4,W19-8009,1,0.850311,"ndangered according to the UNESCO classification (Moseley, 2010). This paper is dedicated to describing the first ever Universal Dependencies (UD) treebank for Apurinã1 . We describe how the treebank was created, and what exact decisions were made in different parts of the process. The UD project (Zeman et al., 2020) has the goal of collecting syntactically annotated corpora containing information about lemmas, parts-of-speech, morphology and dependencies in such a fashion that the annotation conventions are shared across languages, although there may be inconsistencies between languages (see Rueter and Partanen 2019). As the number of South American languages represented in the Universal Dependencies project has grown rapidly in the last years (see i.e. Vasquez et al., 2018; Thomas, 2019), the descriptions of individual treebanks are thereby also a very valuable 2 Modelling the Apurinã Language in UD The Apurinã language has a rich morphology with regular correlation between numerous formatives and semantic categories. One challenge in the conversion from fieldwork/typology style annotation to that used in the UD project is to choose what 1 https://github.com/UniversalDependencies/UD_ApurinaUFPA 28 Procee"
2021.americasnlp-1.4,W18-0210,1,0.837608,"from the morphologically challenging Uralic and other languages of the Circum-Polar region. Solutions for dealing with the categories of case, number, person and gender are available in the GiellaLT infrastructure. Extensions, however, have been required for Apurinã in the categories of number, person and gender. Unlike some IndoEuropean and Uralic languages, the category of gender must also be applied to the subjects and objects of verbs; subject and object marking for number (see Facundes et al. 2021) and person categories could have been adapted directly from description work in the Erzya (Rueter and Tyers, 2018) and Moksha (Rueter, 2018) UD treebanks. pally because the team involved in the annotation was most familiar with this language family: at the same time the Uralic UD annotations, especially for the minority languages, are already closely adapted to the UD project at large. Whether such generalizations work is also one test for the cross-linguistic suitability of the current annotation model. The concept of case in Apurinã is most salient in oblique marking. While the subject, object and adposition complements show no special marking, there are at least six oblique marker to deal with (Facunde"
2021.americasnlp-1.4,2020.udw-1.18,0,0.0381876,"oint in comparison with large languages (Hämäläinen, 2021), there has been recent work (Lim et al., 2018; Ens et al., 2019; Hämäläinen and Wiechetek, 2020; Alnajjar, 2021) showcasing good results on a variety of tasks even for the few endangered languages that have a UD treebank. The fact that UD treebanks can be used with neural models to build higher level NLP tools is one of the key motivations for us to build this resource for Apurinã. In addition to NLP research, UD treebanks have been used in many purely linguistically motivated research papers (Croft et al., 2017; Levshina, 2017, 2019; Sinnemäki and Haakana, 2020). We believe such developments will only grow stronger, and believe that easily available treebanks in the UD project, covering continuously better the world’s linguistic diversity, will continue widening their role as suitable and valuable tools for both descriptive linguistic research and computational linguistics. This goal will be achievable only by creating an open discussion about the conventions and choices done in different treebanks, which can be adjusted and refined at the later stage. This study aims to provide such description about Apurinã treebank. An example of a UD annotated se"
2021.americasnlp-1.4,2020.udw-1.22,0,0.0138581,"em Gender=Masc Gender[obj]=Masc Gender[psor]=Fem Gender[psor]=Masc Gender[subj]=Masc Number=Plur Number=Sing № 1 3 39 6 1 № 10 5 22 5 3 3 48 2 24 2 deprel mark nmod nsubj nummod obj obl root xcomp acl:relcl advcl:tcl № 3 18 83 9 63 15 76 1 5 2 deprel advmod:lmod advmod:neg advmod:tmod nmod:poss nsubj:cop obj:agent obl:lmod obl:tmod № 1 13 13 2 2 1 19 4 Table 4: Dependency relations 4 Future work Due to the size and orientation of the dataset some features of the Apurinã language have been neglected. It will also be a challenge to apply recent studies in noun incorporation annotation for UD in Tyers and Mishchenkova, 2020 to what Facundes and Freitas, 2015 describe for Apurinã noun and classifier incorporation. Another obvious goal for further work is to make Apurinã treebank so large that it can be split into train, test and dev portions. The goal to expand the treebank is connected to the availability of resources. Currently the sentences used in the treebank come mainly from the grammatical descriptions. As a language documentation corpus exists2 , an important consideration is whether the treebank sentences could be more closely connected to audio and video recordings as well, and, of course, the main corp"
2021.emnlp-main.692,2021.wanlp-1.34,0,0.044289,". Many for individual dialects which features are the most foreign accents have clear cues through phonemes stable and will remain as local regional markers, that are not part of the Finnish phonotactic system, and which seem to be in retention (Räsänen and where as with dialects, all phonemes are part of Palander, 2015, 25). In this study we conduct just Finnish. individual experiments and report their results, but There have been several recent approaches for in the further research we hope the results could Arabic to detect dialect from text (Balaji et al., 8778 2020; Talafha et al., 2020; Alrifai et al., 2021). Textual dialect detection has been done also for German (Jauhiainen et al., 2018), Romanian (Zaharia et al., 2021) and Low Saxon (Siewert et al., 2020). The methods used range from traditional machine learning with features such as n-grams to neural models with pretrained embeddings, as it is typically the case in NLP research. None of these approaches use audio, as they rely on text only. At the same time, North Sami dialects have been identified from audio by training several models, kNNs, SVMs, RFs, CRFs, and LSTM, based on extracted features (Kakouros et al., 2020). Kethireddy et al. (20"
2021.emnlp-main.692,2020.lrec-1.520,0,0.0848656,"Missing"
2021.emnlp-main.692,2020.wanlp-1.25,0,0.0995369,"Missing"
2021.emnlp-main.692,N19-1423,0,0.0314673,"Missing"
2021.emnlp-main.692,2021.jeptalnrecital-taln.18,1,0.722652,"8 1171 1026 857 1913 733 3885 859 4292 1801 2371 2344 Table 1: Dialects and the number of sentences in each dialect in the corpus 2 Related work The current approaches to Finnish dialect have focused on the textual modality only. Previously, bidirectional LSTM (long short-term memory) based models have been used to normalize Finnish dialects to standard Finnish (Partanen et al., 2019) and to adapt standard Finnish text into different dialectal forms (Hämäläinen et al., 2020). Similar approach has also been used to normalize historical In Finnish linguistics the dialect identification Finnish (Hämäläinen et al., 2021; Partanen et al., has primarily been studied in the context of folk 2021). linguistics. In this line of research the perceptions The closest research to our paper conducted for of native speakers are investigated (Niedzielski and Finnish has been detection of foreign accents from Preston, 2000). This type of studies have been audio. Behravan et al. (2013) have detected fordone for Finnish, for example, by Mielikäinen and eign accents from audio only by using i-vectors. Palander (2014), Räsänen and Palander (2015) and However, foreign accent detection is a very differPalander (2011). It has be"
2021.emnlp-main.692,P17-4012,0,0.0216395,"Missing"
2021.emnlp-main.692,D15-1166,0,0.0464911,"classification model using a bidirectional long short-term memory (LSTM) based model (Hochreiter and Schmidhuber, 1997) by using OpenNMT-py (Klein et al., 2017) with the default settings except for the encoder where we use a BRNN (bi-directional recurrent neural network) (Schuster and Paliwal, 1997) instead of the default RNN (recurrent neural network), since BRNN based models have been shown to provide better results in a variety of tasks. We use the default of two layers for both the encoder and the decoder and the default attention model, which is the general global attention presented by Luong et al. (2015). The models are trained for the default of 100,000 steps. The model receives dialectal text6 as input and predicts a dialect name as an output. 4.2 Text and audio model Our multi-modal model makes use of the dialectal text and audio. The model combines BERT (Devlin et al., 2019) and XLSR-Wav2Vec2 (Baevski et al., 2020) neural models trained on Finnish data. We utilize the uncased Finnish BERT model7 (Virtanen et al., 2019). The multilingual XLSRWav2Vec2 model released by Facebook does not 6 We also experimented with a character-level model using the same neural network structure, but the accu"
2021.emnlp-main.692,W18-3929,0,0.0260115,"clear cues through phonemes stable and will remain as local regional markers, that are not part of the Finnish phonotactic system, and which seem to be in retention (Räsänen and where as with dialects, all phonemes are part of Palander, 2015, 25). In this study we conduct just Finnish. individual experiments and report their results, but There have been several recent approaches for in the further research we hope the results could Arabic to detect dialect from text (Balaji et al., 8778 2020; Talafha et al., 2020; Alrifai et al., 2021). Textual dialect detection has been done also for German (Jauhiainen et al., 2018), Romanian (Zaharia et al., 2021) and Low Saxon (Siewert et al., 2020). The methods used range from traditional machine learning with features such as n-grams to neural models with pretrained embeddings, as it is typically the case in NLP research. None of these approaches use audio, as they rely on text only. At the same time, North Sami dialects have been identified from audio by training several models, kNNs, SVMs, RFs, CRFs, and LSTM, based on extracted features (Kakouros et al., 2020). Kethireddy et al. (2020) use Mel-weighted SFF spectrogram to detect spoken Arabic dialects. Mel spectogr"
2021.emnlp-main.692,2021.lchange-1.4,1,0.827332,"Missing"
2021.emnlp-main.692,D19-5519,1,0.840414,"also been manually normalized. Dataset used is described in more detail in Section 3 Data. Short EH EK EP ES ESa EKS IS KH K KK KP LS LU LP LKS P PKS PVS PH PK PP PS PSa Sentences 1860 813 2684 848 1744 2168 4035 8026 3995 1640 900 1288 1171 1026 857 1913 733 3885 859 4292 1801 2371 2344 Table 1: Dialects and the number of sentences in each dialect in the corpus 2 Related work The current approaches to Finnish dialect have focused on the textual modality only. Previously, bidirectional LSTM (long short-term memory) based models have been used to normalize Finnish dialects to standard Finnish (Partanen et al., 2019) and to adapt standard Finnish text into different dialectal forms (Hämäläinen et al., 2020). Similar approach has also been used to normalize historical In Finnish linguistics the dialect identification Finnish (Hämäläinen et al., 2021; Partanen et al., has primarily been studied in the context of folk 2021). linguistics. In this line of research the perceptions The closest research to our paper conducted for of native speakers are investigated (Niedzielski and Finnish has been detection of foreign accents from Preston, 2000). This type of studies have been audio. Behravan et al. (2013) have"
2021.emnlp-main.692,2020.vardial-1.3,0,0.0215749,"ers, that are not part of the Finnish phonotactic system, and which seem to be in retention (Räsänen and where as with dialects, all phonemes are part of Palander, 2015, 25). In this study we conduct just Finnish. individual experiments and report their results, but There have been several recent approaches for in the further research we hope the results could Arabic to detect dialect from text (Balaji et al., 8778 2020; Talafha et al., 2020; Alrifai et al., 2021). Textual dialect detection has been done also for German (Jauhiainen et al., 2018), Romanian (Zaharia et al., 2021) and Low Saxon (Siewert et al., 2020). The methods used range from traditional machine learning with features such as n-grams to neural models with pretrained embeddings, as it is typically the case in NLP research. None of these approaches use audio, as they rely on text only. At the same time, North Sami dialects have been identified from audio by training several models, kNNs, SVMs, RFs, CRFs, and LSTM, based on extracted features (Kakouros et al., 2020). Kethireddy et al. (2020) use Mel-weighted SFF spectrogram to detect spoken Arabic dialects. Mel spectograms are also used by Draghici et al. (2020). All these approaches are"
2021.emnlp-main.692,2020.wanlp-1.10,0,0.0804835,"Missing"
2021.emnlp-main.692,2021.vardial-1.13,0,0.0288327,"nd will remain as local regional markers, that are not part of the Finnish phonotactic system, and which seem to be in retention (Räsänen and where as with dialects, all phonemes are part of Palander, 2015, 25). In this study we conduct just Finnish. individual experiments and report their results, but There have been several recent approaches for in the further research we hope the results could Arabic to detect dialect from text (Balaji et al., 8778 2020; Talafha et al., 2020; Alrifai et al., 2021). Textual dialect detection has been done also for German (Jauhiainen et al., 2018), Romanian (Zaharia et al., 2021) and Low Saxon (Siewert et al., 2020). The methods used range from traditional machine learning with features such as n-grams to neural models with pretrained embeddings, as it is typically the case in NLP research. None of these approaches use audio, as they rely on text only. At the same time, North Sami dialects have been identified from audio by training several models, kNNs, SVMs, RFs, CRFs, and LSTM, based on extracted features (Kakouros et al., 2020). Kethireddy et al. (2020) use Mel-weighted SFF spectrogram to detect spoken Arabic dialects. Mel spectograms are also used by Draghici et"
2021.gem-1.9,2020.inlg-1.41,0,0.0495737,"ual environment Question generation from images Multi-sentence image description generation content, fluency, and style Not discussed 5 point scale and yes/no/partially/can’t decide for factuality 5 point scale relatedness, funniness Not discussed 4 point scale Not discussed user study based on quantitative values Not discussed 5 point scale Not discussed slider Question answering relevance, errors Not discussed style, meaning, familiarity Not discussed Turing test Not discussed 15. Lee 2020 16. Mendes and Oliveira 2020a 17. Langner 2020 18. Scialom et al. 2020 19. Ilinykh and Dobnik 2020 20. Akermi et al. 2020 21. Nikolov et al. 2020 evaluation 1 Nikolov et al. 2020 evaluation 2 Nikolov et al. 2020 evaluation 3 22. Wang et al. 2020 23. Hedayatnia et al. 2020 Rap lyric generation comprehension based on identification time, error rate and repetition counts readability, caption relevance and image relevance word choice, object salience, sentence structure and paragraph coherence Turing test Paper review generation constructivenness and validity Response generation appropriateness in a dialog system Not discussed Not discussed relevance (correct/not correct), error type checkboxes, open ended comment f"
2021.gem-1.9,W18-6534,1,0.891268,"Missing"
2021.gem-1.9,2020.inlg-1.4,0,0.071031,"Missing"
2021.gem-1.9,2021.gem-1.10,0,0.0729749,"Missing"
2021.gem-1.9,2020.inlg-1.23,0,0.0962226,"Missing"
2021.gem-1.9,W17-3903,0,0.0592732,"Missing"
2021.gem-1.9,2020.inlg-1.40,0,0.23909,"ression generation in a virtual environment Question generation from images Multi-sentence image description generation content, fluency, and style Not discussed 5 point scale and yes/no/partially/can’t decide for factuality 5 point scale relatedness, funniness Not discussed 4 point scale Not discussed user study based on quantitative values Not discussed 5 point scale Not discussed slider Question answering relevance, errors Not discussed style, meaning, familiarity Not discussed Turing test Not discussed 15. Lee 2020 16. Mendes and Oliveira 2020a 17. Langner 2020 18. Scialom et al. 2020 19. Ilinykh and Dobnik 2020 20. Akermi et al. 2020 21. Nikolov et al. 2020 evaluation 1 Nikolov et al. 2020 evaluation 2 Nikolov et al. 2020 evaluation 3 22. Wang et al. 2020 23. Hedayatnia et al. 2020 Rap lyric generation comprehension based on identification time, error rate and repetition counts readability, caption relevance and image relevance word choice, object salience, sentence structure and paragraph coherence Turing test Paper review generation constructivenness and validity Response generation appropriateness in a dialog system Not discussed Not discussed relevance (correct/not correct), error type checkboxe"
2021.gem-1.9,2020.inlg-1.17,0,0.033516,"y, fluency annotator’s perception, coherence, rhythm, rhyme, quality, enjoyment, relation between the hip hop and metal dataset, and relationship between input and output familiarity, novelty, grammaticality, semantics, singability, overall appreciation and topicality typicality, understandability, quality of language, evoked imagery, evoked emotions, annotator’s liking content preservation, transfer strength and fluency 10. Savery et al. 2020 Real time humanmachine rap battles 11. Oliveira 2020 Song lyric transformation 12. Shihadeh and Ackerman 2020 Emily Dickinson style poem generation 13. Gong et al. 2020 Text style transfer 14. Obeid and Hoque 2020 Text generation from charts informativeness, conciseness, coherence, fluency, factuality Not discussed Style transform Enhancing headlines with creative expressions Referring expression generation in a virtual environment Question generation from images Multi-sentence image description generation content, fluency, and style Not discussed 5 point scale and yes/no/partially/can’t decide for factuality 5 point scale relatedness, funniness Not discussed 4 point scale Not discussed user study based on quantitative values Not discussed 5 point scale Not"
2021.gem-1.9,W19-8637,1,0.899549,"Missing"
2021.gem-1.9,2021.humeval-1.8,1,0.851039,"Missing"
2021.gem-1.9,2020.inlg-1.36,0,0.0634381,"s with creative expressions Referring expression generation in a virtual environment Question generation from images Multi-sentence image description generation content, fluency, and style Not discussed 5 point scale and yes/no/partially/can’t decide for factuality 5 point scale relatedness, funniness Not discussed 4 point scale Not discussed user study based on quantitative values Not discussed 5 point scale Not discussed slider Question answering relevance, errors Not discussed style, meaning, familiarity Not discussed Turing test Not discussed 15. Lee 2020 16. Mendes and Oliveira 2020a 17. Langner 2020 18. Scialom et al. 2020 19. Ilinykh and Dobnik 2020 20. Akermi et al. 2020 21. Nikolov et al. 2020 evaluation 1 Nikolov et al. 2020 evaluation 2 Nikolov et al. 2020 evaluation 3 22. Wang et al. 2020 23. Hedayatnia et al. 2020 Rap lyric generation comprehension based on identification time, error rate and repetition counts readability, caption relevance and image relevance word choice, object salience, sentence structure and paragraph coherence Turing test Paper review generation constructivenness and validity Response generation appropriateness in a dialog system Not discussed Not discussed r"
2021.gem-1.9,2020.inlg-1.46,0,0.0692825,"and yes/no/partially/can’t decide for factuality 5 point scale relatedness, funniness Not discussed 4 point scale Not discussed user study based on quantitative values Not discussed 5 point scale Not discussed slider Question answering relevance, errors Not discussed style, meaning, familiarity Not discussed Turing test Not discussed 15. Lee 2020 16. Mendes and Oliveira 2020a 17. Langner 2020 18. Scialom et al. 2020 19. Ilinykh and Dobnik 2020 20. Akermi et al. 2020 21. Nikolov et al. 2020 evaluation 1 Nikolov et al. 2020 evaluation 2 Nikolov et al. 2020 evaluation 3 22. Wang et al. 2020 23. Hedayatnia et al. 2020 Rap lyric generation comprehension based on identification time, error rate and repetition counts readability, caption relevance and image relevance word choice, object salience, sentence structure and paragraph coherence Turing test Paper review generation constructivenness and validity Response generation appropriateness in a dialog system Not discussed Not discussed relevance (correct/not correct), error type checkboxes, open ended comment field 5 point scale picking which out of 2 is written by a human human written (yes/no) not stated Previous research picking the best Table 1: Evaluated"
2021.gem-1.9,2020.inlg-1.25,0,0.11406,"iscussed Style transform Enhancing headlines with creative expressions Referring expression generation in a virtual environment Question generation from images Multi-sentence image description generation content, fluency, and style Not discussed 5 point scale and yes/no/partially/can’t decide for factuality 5 point scale relatedness, funniness Not discussed 4 point scale Not discussed user study based on quantitative values Not discussed 5 point scale Not discussed slider Question answering relevance, errors Not discussed style, meaning, familiarity Not discussed Turing test Not discussed 15. Lee 2020 16. Mendes and Oliveira 2020a 17. Langner 2020 18. Scialom et al. 2020 19. Ilinykh and Dobnik 2020 20. Akermi et al. 2020 21. Nikolov et al. 2020 evaluation 1 Nikolov et al. 2020 evaluation 2 Nikolov et al. 2020 evaluation 3 22. Wang et al. 2020 23. Hedayatnia et al. 2020 Rap lyric generation comprehension based on identification time, error rate and repetition counts readability, caption relevance and image relevance word choice, object salience, sentence structure and paragraph coherence Turing test Paper review generation constructivenness and validity Response generation appropriateness i"
2021.gem-1.9,2020.inlg-1.42,0,0.0964092,"n generation from images Multi-sentence image description generation content, fluency, and style Not discussed 5 point scale and yes/no/partially/can’t decide for factuality 5 point scale relatedness, funniness Not discussed 4 point scale Not discussed user study based on quantitative values Not discussed 5 point scale Not discussed slider Question answering relevance, errors Not discussed style, meaning, familiarity Not discussed Turing test Not discussed 15. Lee 2020 16. Mendes and Oliveira 2020a 17. Langner 2020 18. Scialom et al. 2020 19. Ilinykh and Dobnik 2020 20. Akermi et al. 2020 21. Nikolov et al. 2020 evaluation 1 Nikolov et al. 2020 evaluation 2 Nikolov et al. 2020 evaluation 3 22. Wang et al. 2020 23. Hedayatnia et al. 2020 Rap lyric generation comprehension based on identification time, error rate and repetition counts readability, caption relevance and image relevance word choice, object salience, sentence structure and paragraph coherence Turing test Paper review generation constructivenness and validity Response generation appropriateness in a dialog system Not discussed Not discussed relevance (correct/not correct), error type checkboxes, open ended comment field 5 point scale picki"
2021.gem-1.9,D16-1127,0,0.0208843,"stions established in the paper. Paper 13 formulated the evaluated parameters so that they would measure the same things as their automated evaluation. Paper 9 and 12 used evaluation questions originally established by Toivanen et al. (2012). While basing evaluation on existing research makes the evaluation questions sound more well motivated, the original paper where these evaluation questions were first established did not present any reasoning as to why these should be the evaluation questions to be used with generated poetry. Also paper 23 stated they used ”a similar setup” as proposed by Li et al. (2016). In practice this meant that whereas the original paper proposed 3 different evaluation setups, paper 23 only presented one of them. The reasoning for this evaluation was not discussed in the original paper. 2.3 How is the evaluation conducted? Most of the papers present only one human evaluation method. The exceptions are paper 9 that presents two distinct evaluation setups and paper 21 that presents 3 distinct evaluation setups. The most common way of conducting a human evaluation is to use a questionnaire that is rated on a numerical scale. Papers 4, 7, 9 (evaluation 1) 11, 12, 14, 15, 18"
2021.gem-1.9,2020.inlg-1.20,0,0.0342658,"nce, rhythm, rhyme, quality, enjoyment, relation between the hip hop and metal dataset, and relationship between input and output familiarity, novelty, grammaticality, semantics, singability, overall appreciation and topicality typicality, understandability, quality of language, evoked imagery, evoked emotions, annotator’s liking content preservation, transfer strength and fluency 10. Savery et al. 2020 Real time humanmachine rap battles 11. Oliveira 2020 Song lyric transformation 12. Shihadeh and Ackerman 2020 Emily Dickinson style poem generation 13. Gong et al. 2020 Text style transfer 14. Obeid and Hoque 2020 Text generation from charts informativeness, conciseness, coherence, fluency, factuality Not discussed Style transform Enhancing headlines with creative expressions Referring expression generation in a virtual environment Question generation from images Multi-sentence image description generation content, fluency, and style Not discussed 5 point scale and yes/no/partially/can’t decide for factuality 5 point scale relatedness, funniness Not discussed 4 point scale Not discussed user study based on quantitative values Not discussed 5 point scale Not discussed slider Question answering relevance"
2021.gem-1.9,C67-1002,0,0.246102,"Missing"
2021.gem-1.9,2020.inlg-1.32,0,0.549938,"ration, Evaluation, and Metrics (GEM 2021), pages 84–95 August 5–6, 2021. ©2021 Association for Computational Linguistics Paper NLG task Evaluated parameters 1. Mathewson et al. 2020 Collaborative dialogue engagement 2. Cheatley et al. 2020 Song writing tool Support of self-expression, therapeutic value and receptiveness to the tool and songs created Not discussed User study (qualitative) Based on critics’ previews and reviews No questions public performance coherence, impactfulness Not discussed 5 point scale 3. Mirowski et al. 2020 4. Spendlove and Ventura 2020 5. Ammanabrolu et al. 2020 6. Mendes and Oliveira 2020b Auxiliary tool for improv theater Generating six word stories Quest generation in text adventure games Headline-proverb pair generation Questions motivated Evaluation type Engagement measured the Ranking models notions of revealing and concealing. coherence, originality (novelty), sense of By Boden’s theory on creativity acomplishment (value), unpredictability (surprise) 7 point scale relatedness, funniness Not discussed 4 point scale 5 point scale Not discussed 3 point scale Previous research 5 point scale Not discussed Association By research questions open ended questions + automatic anal"
2021.gem-1.9,2020.inlg-1.39,0,0.0562974,"xpressions Referring expression generation in a virtual environment Question generation from images Multi-sentence image description generation content, fluency, and style Not discussed 5 point scale and yes/no/partially/can’t decide for factuality 5 point scale relatedness, funniness Not discussed 4 point scale Not discussed user study based on quantitative values Not discussed 5 point scale Not discussed slider Question answering relevance, errors Not discussed style, meaning, familiarity Not discussed Turing test Not discussed 15. Lee 2020 16. Mendes and Oliveira 2020a 17. Langner 2020 18. Scialom et al. 2020 19. Ilinykh and Dobnik 2020 20. Akermi et al. 2020 21. Nikolov et al. 2020 evaluation 1 Nikolov et al. 2020 evaluation 2 Nikolov et al. 2020 evaluation 3 22. Wang et al. 2020 23. Hedayatnia et al. 2020 Rap lyric generation comprehension based on identification time, error rate and repetition counts readability, caption relevance and image relevance word choice, object salience, sentence structure and paragraph coherence Turing test Paper review generation constructivenness and validity Response generation appropriateness in a dialog system Not discussed Not discussed relevance (correct/not co"
2021.gem-1.9,W18-6312,0,0.016856,"step closer to scientific rigor as automated evaluation metrics were commonly used together with human evaluation, and sometimes as the only evaluation metric (such as Bie´n et al. 2020), whereas ICCC had several papers presenting work on creative NLG without any evaluation at all (such as Agafonova et al. 2020; Petac et al. 2020; Wright and Purver 2020). The use of experts in evaluation is something that should be taken under rigorous inspection in the future. Currently, there are contradicting studies on the topic indicating that consulting expert does have an effect in machine translation (Toral et al., 2018) but not in poem generation (Lamb et al., 2017). However, this is a question that is very likely to depend on the output that is to be evaluated and also on how the evaluation is conducted. Human computer interaction research has some more established methodologies for conducting human studies (see Jacko 2012; Lazar et al. 2017 such as cognitive walk-through (see Mahatody et al. 2010), human performance evaluation support system (Ha et al., 2007) and user studies (see MacKenzie 2015). These established methodologies could be taken into account when conducting evaluation of such an NLG system t"
2021.gem-1.9,2020.inlg-1.44,0,0.157889,"scussed 5 point scale and yes/no/partially/can’t decide for factuality 5 point scale relatedness, funniness Not discussed 4 point scale Not discussed user study based on quantitative values Not discussed 5 point scale Not discussed slider Question answering relevance, errors Not discussed style, meaning, familiarity Not discussed Turing test Not discussed 15. Lee 2020 16. Mendes and Oliveira 2020a 17. Langner 2020 18. Scialom et al. 2020 19. Ilinykh and Dobnik 2020 20. Akermi et al. 2020 21. Nikolov et al. 2020 evaluation 1 Nikolov et al. 2020 evaluation 2 Nikolov et al. 2020 evaluation 3 22. Wang et al. 2020 23. Hedayatnia et al. 2020 Rap lyric generation comprehension based on identification time, error rate and repetition counts readability, caption relevance and image relevance word choice, object salience, sentence structure and paragraph coherence Turing test Paper review generation constructivenness and validity Response generation appropriateness in a dialog system Not discussed Not discussed relevance (correct/not correct), error type checkboxes, open ended comment field 5 point scale picking which out of 2 is written by a human human written (yes/no) not stated Previous research picking"
2021.humeval-1.8,2020.acl-main.34,0,0.0296282,"Missing"
2021.humeval-1.8,W17-3903,0,0.197473,"Missing"
2021.humeval-1.8,D19-1617,1,0.898485,"Missing"
2021.humeval-1.8,W19-8637,1,0.750529,"Missing"
2021.humeval-1.8,2020.inlg-1.23,0,0.377362,"Missing"
2021.humeval-1.8,W18-6534,1,0.772281,"Missing"
2021.humeval-1.8,W19-8643,0,0.0554199,"Missing"
2021.humeval-1.8,2020.acl-main.387,0,0.0168413,"between the problem definition and the evaluation, but also the proposed solution, let it be rule-based, algorithmic or a machine learning model. We can often see that the solution itself has very little to do with the human evaluation methods used. In this paper, we study the Great Misalignment Problem (alignment of a problem definition, method and human evaluation) by surveying papers published in ACL 2020 that use human evaluation. We focus on ACL since it is supposed to be the most prestigious conference in the field. For courtesy reasons, we anonymize the papers surveyed, except Paper 3 (Mohankumar et al., 2020) which was the only paper that did not exhibit the Great Misalignment Problem. We do not want single anyone out with our critique as that is not the goal of our paper. 69 Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval), pages 69–74 Online, April 19, 2021. ©2021 Association for Computational Linguistics Definition Paper 1 Paper 2 Paper 3 Paper 4 Paper 5 Paper 6 Paper 7 Paper 8 Paper 9 Paper 10 Theoretical Absent ML Absent Absent Absent Math Theoretical Absent Absent Method in line with the definition No No Yes No No No Yes Yes No No Evaluation in line with the definitio"
2021.humeval-1.8,D17-1238,0,0.0212071,"portant. The situation changes, however, when your main evaluation method is a subjective human evaluation. The reason for this is simple: only when you have defined the problem clearly, can you derive the questions and methods for a human evaluation (c.f. Alnajjar and H¨am¨al¨ainen 2018; Jordanous 2012). When one does not have a clear understanding of the problem one seeks to solve, the evaluation is usually not representative of the problem, thus they are misaligned. Introduction There has been a lot of academic discussion recently about different evaluation methods used and their validity (Novikova et al., 2017; Reiter, 2018; Howcroft et al., 2020; van der Lee et al., 2019). Reproducibility is an important problem in our field of science and it is not currently archived in human evaluation, as some researches have found that trying to reproduce a human evaluation gives different results (H¨am¨al¨ainen et al., 2020; Mieskes et al., 2019). However important reproducibility is, we have identified an even more severe problem in human evaluation. We call this problem the Great Misalignment Problem that is a mismatch between a problem statement, a proposed model and a proposed evaluation method. It is typ"
2021.humeval-1.8,P02-1040,0,0.116284,"Missing"
2021.humeval-1.8,J18-3002,0,0.0135909,"changes, however, when your main evaluation method is a subjective human evaluation. The reason for this is simple: only when you have defined the problem clearly, can you derive the questions and methods for a human evaluation (c.f. Alnajjar and H¨am¨al¨ainen 2018; Jordanous 2012). When one does not have a clear understanding of the problem one seeks to solve, the evaluation is usually not representative of the problem, thus they are misaligned. Introduction There has been a lot of academic discussion recently about different evaluation methods used and their validity (Novikova et al., 2017; Reiter, 2018; Howcroft et al., 2020; van der Lee et al., 2019). Reproducibility is an important problem in our field of science and it is not currently archived in human evaluation, as some researches have found that trying to reproduce a human evaluation gives different results (H¨am¨al¨ainen et al., 2020; Mieskes et al., 2019). However important reproducibility is, we have identified an even more severe problem in human evaluation. We call this problem the Great Misalignment Problem that is a mismatch between a problem statement, a proposed model and a proposed evaluation method. It is typical in the fi"
2021.humeval-1.8,2020.wmt-1.29,0,0.0114581,"n our field of science and it is not currently archived in human evaluation, as some researches have found that trying to reproduce a human evaluation gives different results (H¨am¨al¨ainen et al., 2020; Mieskes et al., 2019). However important reproducibility is, we have identified an even more severe problem in human evaluation. We call this problem the Great Misalignment Problem that is a mismatch between a problem statement, a proposed model and a proposed evaluation method. It is typical in the field of NLP to work with ill-defined problems. For instance, many machine translation papers (Roest et al., 2020; Chen et al., 2020; Talman et al., 2019) do not extensively define what they mean by translation, a topic that has The Great Misalignment Problem is not just about the misalignment between the problem definition and the evaluation, but also the proposed solution, let it be rule-based, algorithmic or a machine learning model. We can often see that the solution itself has very little to do with the human evaluation methods used. In this paper, we study the Great Misalignment Problem (alignment of a problem definition, method and human evaluation) by surveying papers published in ACL 2020 that u"
2021.humeval-1.8,W19-5347,0,0.0433269,"Missing"
2021.iwclul-1.4,2020.iwclul-1.3,1,0.916009,"n Komi, and their progressing digitization gives us access to an increasing number of materials hitherto unavailable in digital format. When this process advances and we inevitably encounter more dialectal texts, we must also consider wider dialectal features of Komi when we develop the transducer. Additionally, as there are two main Komi varieties with written standards and their dialects, Zyrian and Permyak, we must acknowledge that infrastructures for these languages cannot be developed in isolation, but rather that both language variants must be taken into consideration in different ways (Rueter et al., 2020c). At the same time, the respective written standards have needs for their own tools and resources that are still independent, so the whole question of how to best handle pluricentric language varieties such as Komi still needs additional planning. The study is structured so that we first describe the work that has been done for modeling the morphosyntax of the Komi-Zyrian language. Then we discuss individual features and their role in the description, and aim to illustrate the types of challenges they present. As we believe that computational modeling of the language is directly connected to"
2021.iwclul-1.8,Q17-1010,0,0.0234611,"ration and learners’ error correction are domains with some research with potential for new discoveries in the future. Machine translation gets frequently attention from different researchers. There are several more NLG tasks (see Gatt and Krahmer 2018) that have not been researched at all in Finnish, which means that there is a lot of room for more research on this topic. 2.3 Semantics Vector representations of meaning have become common place in NLP and Finnish is no exception with the availability of pretrained word2vec  (Laippala and Ginter, 2014; Kutuzov et al., 2017) and fastText (Bojanowski et al., 2017) models. BERT models have also become available as part of the multilingual BERT model (Devlin et al., 2019) or trained separately for Finnish  (Kutuzov et al., 2017; Virtanen et al., 2019). Even Elmo models have been made available for Finnish (Ulčar and Robnik-Šikonja, 2020). In addition to the standard vector-based representations of meaning, there is another statistical model called SemFi (Hämäläinen, 2018a). The model is a relational database that captures semantic relations of words based on their syntactic cooccurencies. Before the era of machine learning, there were two promi"
2021.iwclul-1.8,L18-1218,0,0.0182769,"ämäläinen, 2018b), Poeticus (Toivanen et al., 2012) and others (Hämäläinen and Alnajjar, 2019a,b). There is also an interactive poem generator tool called Runokone (Poem Machine) (Hämäläinen, 2018c). Recently there have been several approaches to enhancing existing news headlines (Alnajjar et al., 2019; Rämö and Leppänen, 2021). And some approaches to generating entire news articles automatically (Kanerva et al., 2019; Haapanen and Leppänen, 2020). Paraphrase generation (Sjöblom et al., 2020) has also become a researched topic with the availability of monolingually aligned parallel corpora (Creutz, 2018). There is also an approach to converting standard Finnish text into different dialects (Hämäläinen et al., 2020). Finnish is a typical language for machine translation tasks and it is not uncommon to see it featured in several papers that deal with multiple languages. However, there are several papers that fohttps://github.com/giellalt/lang-fin/tree/main/src/cg3 https://github.com/mpsilfve/FinnPos See Pirinen, 2019b for some comparison between rules and neural networks https://turkunlp.org/Finnish-dep-parser/ http://turkunlp.org/Turku-neural-parser-pipeline/ https://github.com/mikahama/"
2021.iwclul-1.8,W19-6303,0,0.0283063,"sing https://turkunlp.org/fin-ner.html https://stanfordnlp.github.io/stanza/ https://github.com/mikahama/syntaxmaker https://spacy.io/ https://github.com/mikahama/murre https://github.com/mikahama/keinoleino https://github.com/Traubert/FiNerhttp://runokone.cs.helsinki.fi/ cus on Finnish in particular (Hurskainen and Tiedemann, 2017; Hämäläinen and Alnajjar, 2019c; Pirinen, 2019a; Tiedemann et al., 2020). There is also a recent approach to dialog generation in Finnish (Leino et al., 2020). Also non-native language learner’s errors have been corrected successfully automatically (Creutz and Sjöblom, 2019). To summarize the approaches, there are several generators for poetry and news that benefit from the available surface realizers. Paraphrasing, dialect adaptation, dialog generation and learners’ error correction are domains with some research with potential for new discoveries in the future. Machine translation gets frequently attention from different researchers. There are several more NLG tasks (see Gatt and Krahmer 2018) that have not been researched at all in Finnish, which means that there is a lot of room for more research on this topic. 2.3 Semantics Vector representations of meaning"
2021.iwclul-1.8,N19-1423,0,0.192313,"st (Jauhiainen, 2001) and recently (Partanen et al., 2019). The latter leading to a Python library called Murre for automatic normalization of dialectal Finnish. Non-standard data has been an issue in digital humanities (DH) projects (Mäkelä et al., 2020), and lately there have been efforts in automatically correcting OCR errors in existing historical datasets (Kettunen, 2015; Drobac and Lindén, 2020; Drobac, 2020; Duong et al., 2020). Named entity recognition has also been under study with FiNER and its recently released data (Ruokolainen et al., 2019). There is also another recent BERT (Devlin et al., 2019) based approach to the topic (Luoma et al., 2020). There have been several approaches to language detection including detection of Finnish from web corpora (see Jauhiainen et al., 2021). Similarly, native Finnish has been automatically identified from learner’s Finnish (Malmasi and Dras, 2014). In summary, parsing has been researched on different levels of language such as syntax, morphology, POS and NER tagging, and lemmatization. It has been mainly focusing on standard well-formed Finnish, although there are methods for coping with dialectal Finnish and OCR errors as well. 2.2 Generation T"
2021.iwclul-1.8,K18-2013,0,0.0156322,") and it works together with constraint grammar (CG) based disambiguators and syntactic parsers available in the Giellatekno (Moshagen et al., 2014) repositories. FinnPos (Silfverberg et al., 2016) is another morphological tagger and lemmatizer tool based on CRF (conditional random field). There have been recently more data driven approaches focusing on Finnish (Silfverberg and Hulden, 2018). While rule-based tradition has been strong in the past, there are several machine learning driven dependency parsers for Finnish, such as the statistical one (Haverinen et al., 2014) and neural one (Kanerva et al., 2018) by TurkuNLP. Out of the aforementioned tools Omorfi (and the CG disambigator) and the machine learning based parsers are available to use through a Python package named UralicNLP  (Hämäläinen, 2019). As Finnish data is available in several multilingual datasets, there are many multilingual approaches for parsing (Qi et al., 2020) (Honnibal et al., 2020) and morphology (Aharoni and Goldberg, 2017; Nicolai and Yarowsky, 2019; Silfverberg and Tyers, 2019; Grönroos et al., 2020). The fact that spoken Finnish is very different to standard Finnish has drawn some attention in the past (Jauhiai"
2021.iwclul-1.8,2020.lrec-1.567,0,0.0332277,"2019). The latter leading to a Python library called Murre for automatic normalization of dialectal Finnish. Non-standard data has been an issue in digital humanities (DH) projects (Mäkelä et al., 2020), and lately there have been efforts in automatically correcting OCR errors in existing historical datasets (Kettunen, 2015; Drobac and Lindén, 2020; Drobac, 2020; Duong et al., 2020). Named entity recognition has also been under study with FiNER and its recently released data (Ruokolainen et al., 2019). There is also another recent BERT (Devlin et al., 2019) based approach to the topic (Luoma et al., 2020). There have been several approaches to language detection including detection of Finnish from web corpora (see Jauhiainen et al., 2021). Similarly, native Finnish has been automatically identified from learner’s Finnish (Malmasi and Dras, 2014). In summary, parsing has been researched on different levels of language such as syntax, morphology, POS and NER tagging, and lemmatization. It has been mainly focusing on standard well-formed Finnish, although there are methods for coping with dialectal Finnish and OCR errors as well. 2.2 Generation The lowest level of natural language generation is s"
2021.iwclul-1.8,U14-1020,0,0.0169922,"in automatically correcting OCR errors in existing historical datasets (Kettunen, 2015; Drobac and Lindén, 2020; Drobac, 2020; Duong et al., 2020). Named entity recognition has also been under study with FiNER and its recently released data (Ruokolainen et al., 2019). There is also another recent BERT (Devlin et al., 2019) based approach to the topic (Luoma et al., 2020). There have been several approaches to language detection including detection of Finnish from web corpora (see Jauhiainen et al., 2021). Similarly, native Finnish has been automatically identified from learner’s Finnish (Malmasi and Dras, 2014). In summary, parsing has been researched on different levels of language such as syntax, morphology, POS and NER tagging, and lemmatization. It has been mainly focusing on standard well-formed Finnish, although there are methods for coping with dialectal Finnish and OCR errors as well. 2.2 Generation The lowest level of natural language generation is surface realization (see Reiter, 1994), and for that there are tools such as Omorfi and Syntax Maker (Hämäläinen and Rueter, 2018). The latter uses Omorfi for morphological inflection while it takes care of higher level morphosyntax such as cas"
2021.iwclul-1.8,P19-1172,0,0.0193825,"been strong in the past, there are several machine learning driven dependency parsers for Finnish, such as the statistical one (Haverinen et al., 2014) and neural one (Kanerva et al., 2018) by TurkuNLP. Out of the aforementioned tools Omorfi (and the CG disambigator) and the machine learning based parsers are available to use through a Python package named UralicNLP  (Hämäläinen, 2019). As Finnish data is available in several multilingual datasets, there are many multilingual approaches for parsing (Qi et al., 2020) (Honnibal et al., 2020) and morphology (Aharoni and Goldberg, 2017; Nicolai and Yarowsky, 2019; Silfverberg and Tyers, 2019; Grönroos et al., 2020). The fact that spoken Finnish is very different to standard Finnish has drawn some attention in the past (Jauhiainen, 2001) and recently (Partanen et al., 2019). The latter leading to a Python library called Murre for automatic normalization of dialectal Finnish. Non-standard data has been an issue in digital humanities (DH) projects (Mäkelä et al., 2020), and lately there have been efforts in automatically correcting OCR errors in existing historical datasets (Kettunen, 2015; Drobac and Lindén, 2020; Drobac, 2020; Duong et al., 2020). Na"
2021.iwclul-1.8,W18-0202,0,0.0254635,"t al., 2019). With the similar ideology to the hand crafted resources, there have been several different linked http://vectors.nlpl.eu/repository/ https://bionlp.utu.fi/finnish-internet-parsebank.html https://fasttext.cc/docs/en/pretrained-vectors.html https://github.com/google-research/bert http://vectors.nlpl.eu/repository/ https://github.com/TurkuNLP/FinBERT https://www.clarin.si/repository/xmlui/handle/11356/1277 https://github.com/mikahama/uralicNLP/wiki/Semantics(SemFi,-SemUr) data projects in Finland representing semantics in structured ontologies (Hyvönen et al., 2006; Nyrkkö, 2018; Thomas et al., 2018; Koho et al., 2019). Many of the linked data projects are available on the Linked Data Finland website. There is a Python library called FinMeter (Hämäläinen and Alnajjar, 2019b) that has some higher level semantic tools for Finnish such as metaphor interpretation, word concreteness analysis and sentiment analysis. Sentiment analysis for Finnish has also been studied later on (Öhman et al., 2020; Vankka et al., 2019; Lindén et al., 2020). There is also research on topic modeling methods (Ginter et al., 2009; Hengchen et al., 2018; Loukasmäki and Makkonen, 2019). Fin"
2021.iwclul-1.8,2020.coling-main.575,0,0.0233777,"dle/11356/1277 https://github.com/mikahama/uralicNLP/wiki/Semantics(SemFi,-SemUr) data projects in Finland representing semantics in structured ontologies (Hyvönen et al., 2006; Nyrkkö, 2018; Thomas et al., 2018; Koho et al., 2019). Many of the linked data projects are available on the Linked Data Finland website. There is a Python library called FinMeter (Hämäläinen and Alnajjar, 2019b) that has some higher level semantic tools for Finnish such as metaphor interpretation, word concreteness analysis and sentiment analysis. Sentiment analysis for Finnish has also been studied later on (Öhman et al., 2020; Vankka et al., 2019; Lindén et al., 2020). There is also research on topic modeling methods (Ginter et al., 2009; Hengchen et al., 2018; Loukasmäki and Makkonen, 2019). Finnish is well supported by traditional representations of semantics and latest vector based models. There is a vast amount of linked data resources in a variety of domains. Higher-level semantics such as metaphor interpretation and sentiment analysis also have received their share of research interest, although there are many more questions related to pragmatics and figurative language that have not been researched, such as"
2021.iwclul-1.8,D19-5519,1,0.833464,"aforementioned tools Omorfi (and the CG disambigator) and the machine learning based parsers are available to use through a Python package named UralicNLP  (Hämäläinen, 2019). As Finnish data is available in several multilingual datasets, there are many multilingual approaches for parsing (Qi et al., 2020) (Honnibal et al., 2020) and morphology (Aharoni and Goldberg, 2017; Nicolai and Yarowsky, 2019; Silfverberg and Tyers, 2019; Grönroos et al., 2020). The fact that spoken Finnish is very different to standard Finnish has drawn some attention in the past (Jauhiainen, 2001) and recently (Partanen et al., 2019). The latter leading to a Python library called Murre for automatic normalization of dialectal Finnish. Non-standard data has been an issue in digital humanities (DH) projects (Mäkelä et al., 2020), and lately there have been efforts in automatically correcting OCR errors in existing historical datasets (Kettunen, 2015; Drobac and Lindén, 2020; Drobac, 2020; Duong et al., 2020). Named entity recognition has also been under study with FiNER and its recently released data (Ruokolainen et al., 2019). There is also another recent BERT (Devlin et al., 2019) based approach to the topic (Luoma"
2021.iwclul-1.8,W19-5336,0,0.0171732,"9; Haapanen and Leppänen, 2020). Paraphrase generation (Sjöblom et al., 2020) has also become a researched topic with the availability of monolingually aligned parallel corpora (Creutz, 2018). There is also an approach to converting standard Finnish text into different dialects (Hämäläinen et al., 2020). Finnish is a typical language for machine translation tasks and it is not uncommon to see it featured in several papers that deal with multiple languages. However, there are several papers that fohttps://github.com/giellalt/lang-fin/tree/main/src/cg3 https://github.com/mpsilfve/FinnPos See Pirinen, 2019b for some comparison between rules and neural networks https://turkunlp.org/Finnish-dep-parser/ http://turkunlp.org/Turku-neural-parser-pipeline/ https://github.com/mikahama/uralicNLP https://github.com/mikahama/uralicNLP/wiki/Dependencyrules/blob/master/finer-readme.md parsing https://turkunlp.org/fin-ner.html https://stanfordnlp.github.io/stanza/ https://github.com/mikahama/syntaxmaker https://spacy.io/ https://github.com/mikahama/murre https://github.com/mikahama/keinoleino https://github.com/Traubert/FiNerhttp://runokone.cs.helsinki.fi/ cus on Finnish in particular (Hu"
2021.iwclul-1.8,W19-0309,0,0.0128704,"9; Haapanen and Leppänen, 2020). Paraphrase generation (Sjöblom et al., 2020) has also become a researched topic with the availability of monolingually aligned parallel corpora (Creutz, 2018). There is also an approach to converting standard Finnish text into different dialects (Hämäläinen et al., 2020). Finnish is a typical language for machine translation tasks and it is not uncommon to see it featured in several papers that deal with multiple languages. However, there are several papers that fohttps://github.com/giellalt/lang-fin/tree/main/src/cg3 https://github.com/mpsilfve/FinnPos See Pirinen, 2019b for some comparison between rules and neural networks https://turkunlp.org/Finnish-dep-parser/ http://turkunlp.org/Turku-neural-parser-pipeline/ https://github.com/mikahama/uralicNLP https://github.com/mikahama/uralicNLP/wiki/Dependencyrules/blob/master/finer-readme.md parsing https://turkunlp.org/fin-ner.html https://stanfordnlp.github.io/stanza/ https://github.com/mikahama/syntaxmaker https://spacy.io/ https://github.com/mikahama/murre https://github.com/mikahama/keinoleino https://github.com/Traubert/FiNerhttp://runokone.cs.helsinki.fi/ cus on Finnish in particular (Hu"
2021.iwclul-1.8,2020.acl-demos.14,0,0.0146349,"oaches focusing on Finnish (Silfverberg and Hulden, 2018). While rule-based tradition has been strong in the past, there are several machine learning driven dependency parsers for Finnish, such as the statistical one (Haverinen et al., 2014) and neural one (Kanerva et al., 2018) by TurkuNLP. Out of the aforementioned tools Omorfi (and the CG disambigator) and the machine learning based parsers are available to use through a Python package named UralicNLP  (Hämäläinen, 2019). As Finnish data is available in several multilingual datasets, there are many multilingual approaches for parsing (Qi et al., 2020) (Honnibal et al., 2020) and morphology (Aharoni and Goldberg, 2017; Nicolai and Yarowsky, 2019; Silfverberg and Tyers, 2019; Grönroos et al., 2020). The fact that spoken Finnish is very different to standard Finnish has drawn some attention in the past (Jauhiainen, 2001) and recently (Partanen et al., 2019). The latter leading to a Python library called Murre for automatic normalization of dialectal Finnish. Non-standard data has been an issue in digital humanities (DH) projects (Mäkelä et al., 2020), and lately there have been efforts in automatically correcting OCR errors in existing"
2021.iwclul-1.8,2021.hackashop-1.9,0,0.016969,"e latter uses Omorfi for morphological inflection while it takes care of higher level morphosyntax such as case government and agreement. There is a strong computational creativity focus in Helsinki and it also shows in Finnish NLG, as there are several poem generators such as Keinoleino (Hämäläinen, 2018b), Poeticus (Toivanen et al., 2012) and others (Hämäläinen and Alnajjar, 2019a,b). There is also an interactive poem generator tool called Runokone (Poem Machine) (Hämäläinen, 2018c). Recently there have been several approaches to enhancing existing news headlines (Alnajjar et al., 2019; Rämö and Leppänen, 2021). And some approaches to generating entire news articles automatically (Kanerva et al., 2019; Haapanen and Leppänen, 2020). Paraphrase generation (Sjöblom et al., 2020) has also become a researched topic with the availability of monolingually aligned parallel corpora (Creutz, 2018). There is also an approach to converting standard Finnish text into different dialects (Hämäläinen et al., 2020). Finnish is a typical language for machine translation tasks and it is not uncommon to see it featured in several papers that deal with multiple languages. However, there are several papers that fohttps:"
2021.iwclul-1.8,W94-0319,0,0.192724,"l approaches to language detection including detection of Finnish from web corpora (see Jauhiainen et al., 2021). Similarly, native Finnish has been automatically identified from learner’s Finnish (Malmasi and Dras, 2014). In summary, parsing has been researched on different levels of language such as syntax, morphology, POS and NER tagging, and lemmatization. It has been mainly focusing on standard well-formed Finnish, although there are methods for coping with dialectal Finnish and OCR errors as well. 2.2 Generation The lowest level of natural language generation is surface realization (see Reiter, 1994), and for that there are tools such as Omorfi and Syntax Maker (Hämäläinen and Rueter, 2018). The latter uses Omorfi for morphological inflection while it takes care of higher level morphosyntax such as case government and agreement. There is a strong computational creativity focus in Helsinki and it also shows in Finnish NLG, as there are several poem generators such as Keinoleino (Hämäläinen, 2018b), Poeticus (Toivanen et al., 2012) and others (Hämäläinen and Alnajjar, 2019a,b). There is also an interactive poem generator tool called Runokone (Poem Machine) (Hämäläinen, 2018c). Recentl"
2021.iwclul-1.8,W18-0209,0,0.0440973,"sis (inhttps://voikko.puimula.org/ https://github.com/flammie/omorfi cluding lemmatization) and generation. It is an FST (finite-state transducer) based tool developed on HFST (Helsinki finite-state technology) (Lindén et al., 2013) and it works together with constraint grammar (CG) based disambiguators and syntactic parsers available in the Giellatekno (Moshagen et al., 2014) repositories. FinnPos (Silfverberg et al., 2016) is another morphological tagger and lemmatizer tool based on CRF (conditional random field). There have been recently more data driven approaches focusing on Finnish (Silfverberg and Hulden, 2018). While rule-based tradition has been strong in the past, there are several machine learning driven dependency parsers for Finnish, such as the statistical one (Haverinen et al., 2014) and neural one (Kanerva et al., 2018) by TurkuNLP. Out of the aforementioned tools Omorfi (and the CG disambigator) and the machine learning based parsers are available to use through a Python package named UralicNLP  (Hämäläinen, 2019). As Finnish data is available in several multilingual datasets, there are many multilingual approaches for parsing (Qi et al., 2020) (Honnibal et al., 2020) and morpholo"
2021.iwclul-1.8,W19-0301,0,0.0199981,"here are several machine learning driven dependency parsers for Finnish, such as the statistical one (Haverinen et al., 2014) and neural one (Kanerva et al., 2018) by TurkuNLP. Out of the aforementioned tools Omorfi (and the CG disambigator) and the machine learning based parsers are available to use through a Python package named UralicNLP  (Hämäläinen, 2019). As Finnish data is available in several multilingual datasets, there are many multilingual approaches for parsing (Qi et al., 2020) (Honnibal et al., 2020) and morphology (Aharoni and Goldberg, 2017; Nicolai and Yarowsky, 2019; Silfverberg and Tyers, 2019; Grönroos et al., 2020). The fact that spoken Finnish is very different to standard Finnish has drawn some attention in the past (Jauhiainen, 2001) and recently (Partanen et al., 2019). The latter leading to a Python library called Murre for automatic normalization of dialectal Finnish. Non-standard data has been an issue in digital humanities (DH) projects (Mäkelä et al., 2020), and lately there have been efforts in automatically correcting OCR errors in existing historical datasets (Kettunen, 2015; Drobac and Lindén, 2020; Drobac, 2020; Duong et al., 2020). Named entity recognition has al"
2021.iwclul-1.8,2020.lrec-1.224,0,0.0303091,"Missing"
2021.iwclul-1.8,2020.lrec-1.470,0,0.0183593,"Finnish-dep-parser/ http://turkunlp.org/Turku-neural-parser-pipeline/ https://github.com/mikahama/uralicNLP https://github.com/mikahama/uralicNLP/wiki/Dependencyrules/blob/master/finer-readme.md parsing https://turkunlp.org/fin-ner.html https://stanfordnlp.github.io/stanza/ https://github.com/mikahama/syntaxmaker https://spacy.io/ https://github.com/mikahama/murre https://github.com/mikahama/keinoleino https://github.com/Traubert/FiNerhttp://runokone.cs.helsinki.fi/ cus on Finnish in particular (Hurskainen and Tiedemann, 2017; Hämäläinen and Alnajjar, 2019c; Pirinen, 2019a; Tiedemann et al., 2020). There is also a recent approach to dialog generation in Finnish (Leino et al., 2020). Also non-native language learner’s errors have been corrected successfully automatically (Creutz and Sjöblom, 2019). To summarize the approaches, there are several generators for poetry and news that benefit from the available surface realizers. Paraphrasing, dialect adaptation, dialog generation and learners’ error correction are domains with some research with potential for new discoveries in the future. Machine translation gets frequently attention from different researchers. There are several more NLG t"
2021.iwclul-1.8,2020.lrec-1.582,0,0.0127867,"rched at all in Finnish, which means that there is a lot of room for more research on this topic. 2.3 Semantics Vector representations of meaning have become common place in NLP and Finnish is no exception with the availability of pretrained word2vec  (Laippala and Ginter, 2014; Kutuzov et al., 2017) and fastText (Bojanowski et al., 2017) models. BERT models have also become available as part of the multilingual BERT model (Devlin et al., 2019) or trained separately for Finnish  (Kutuzov et al., 2017; Virtanen et al., 2019). Even Elmo models have been made available for Finnish (Ulčar and Robnik-Šikonja, 2020). In addition to the standard vector-based representations of meaning, there is another statistical model called SemFi (Hämäläinen, 2018a). The model is a relational database that captures semantic relations of words based on their syntactic cooccurencies. Before the era of machine learning, there were two prominent projects for modeling meaning computationally which have been translated into Finnish WordNet (Lindén and Carlson, 2010) and FrameNet (Lindén et al., 2019). With the similar ideology to the hand crafted resources, there have been several different linked http://vectors.nlpl.eu/"
2021.jeptalnrecital-taln.18,W19-8637,1,0.892195,"Missing"
2021.jeptalnrecital-taln.18,W18-4510,1,0.831946,"Missing"
2021.jeptalnrecital-taln.18,W19-2509,1,0.899376,"Missing"
2021.jeptalnrecital-taln.18,W18-6107,0,0.0643021,"Missing"
2021.jeptalnrecital-taln.18,W17-4412,0,0.0352657,"Missing"
2021.jeptalnrecital-taln.18,W17-4404,0,0.0624957,"Missing"
2021.lchange-1.4,L16-1152,0,0.0444631,"Missing"
2021.lchange-1.4,P19-1044,0,0.0226818,"the proposed approach works, and the errors are connected to accumulating changes and innovations, which also results in a continuous decrease in the accuracy of the model. The described error types also guide further work in improving these models, and document the currently observed issues. We also have trained word embeddings for four centuries of lemmatized Old Literary Finnish, which are available on Zenodo. 1 2 Related work Natural language processing for Old Literary Finnish is still in a very early stage, while extensive work already exists for historical variants of other languages (Dubossarsky et al., 2019; Perrone et al., 2019; Hill and Hengchen, 2019; DegaetanoOrtlieb et al., 2021). Most work has been done with historical newspapers, which represent only later periods of this language variety, starting from 1771. Many studies are connected to improving OCR accuracy, which remains as an important task for old printed materials. Recognizing named entities is another line of research that has been developed relatively far, especially by Kettunen and Ruokolainen (2017), Kettunen et al. (2016a) and Kettunen and L¨ofberg (2017). This connects to other work in NER of other Finnish varieties (Porjazo"
2021.lchange-1.4,2021.nodalida-main.17,1,0.757292,"Missing"
2021.lchange-1.4,D19-5519,1,0.397211,"Missing"
2021.lchange-1.4,W19-4707,0,0.0187628,"ks, and the errors are connected to accumulating changes and innovations, which also results in a continuous decrease in the accuracy of the model. The described error types also guide further work in improving these models, and document the currently observed issues. We also have trained word embeddings for four centuries of lemmatized Old Literary Finnish, which are available on Zenodo. 1 2 Related work Natural language processing for Old Literary Finnish is still in a very early stage, while extensive work already exists for historical variants of other languages (Dubossarsky et al., 2019; Perrone et al., 2019; Hill and Hengchen, 2019; DegaetanoOrtlieb et al., 2021). Most work has been done with historical newspapers, which represent only later periods of this language variety, starting from 1771. Many studies are connected to improving OCR accuracy, which remains as an important task for old printed materials. Recognizing named entities is another line of research that has been developed relatively far, especially by Kettunen and Ruokolainen (2017), Kettunen et al. (2016a) and Kettunen and L¨ofberg (2017). This connects to other work in NER of other Finnish varieties (Porjazovski et al., 2020; Ush"
2021.lchange-1.4,W17-0204,0,0.0381875,"Missing"
2021.lchange-1.4,2021.eacl-demos.7,0,0.015886,"019; Hill and Hengchen, 2019; DegaetanoOrtlieb et al., 2021). Most work has been done with historical newspapers, which represent only later periods of this language variety, starting from 1771. Many studies are connected to improving OCR accuracy, which remains as an important task for old printed materials. Recognizing named entities is another line of research that has been developed relatively far, especially by Kettunen and Ruokolainen (2017), Kettunen et al. (2016a) and Kettunen and L¨ofberg (2017). This connects to other work in NER of other Finnish varieties (Porjazovski et al., 2020; Ushio and Camacho-Collados, 2021). Also evaluation and post processing approaches are closely connected to our study. Kettunen and P¨aa¨ kk¨onen (2016) and Kettunen et al. (2016b) used a morphological analyser adapted for historical Finnish to evaluate OCR accuracy in these newspapers. Later on, OCR accuracy has been improved through unsupervised post-correction in Finnish newspapers (Duong et al., 2020). Koskenniemi and Kuutti (2017) studied alignment and analysis of Old Literary Finnish, using a Helsinki Finite-State Transducer (Lind´en et al., 2013). Lexical change through neologisms has been studied in historical data by"
2021.maiworkshop-1.9,2020.coling-main.20,0,0.0418524,"the context of sarcasm, the meaning difference can either be the Related work In this section, we will present some of the recent related work on sarcasm detection. There has been some work also on sarcasm generation (Chakrabarty et al., 2020) and interpretation (Peled and Reichart, 2017), but they are rather different as tasks and we will not discuss them in detail. Badlani et al. (2019) show an approach for sarcasm detection in online reivews. They train a CNN (convolutional neural network) based model on separate feature embeddings for sarcasm, humor, sentiment and hate speech. Similarly, Babanejad et al. (2020) also detect sarcasm in text. They combine an LSTM (long short-term memory) model with BERT. Dubey et al. (2019) also work on text only by detecting sarcastic numbers in tweets. They experiment with rules, SVMs (support vector machines) and CNNs. Cai et al. (2019) use an LSTM model to detect sarcasm in tweets. Their approach is multimodal in the sense that it takes text and images into account, but it does not deal with audio and video like our 1 Open access version of the data (contains text only) https://zenodo.org/record/4701383 2 Access by request version of the data (videos and text) http"
2021.maiworkshop-1.9,W18-0905,0,0.0333307,"Missing"
2021.maiworkshop-1.9,D19-5544,0,0.0521747,"Missing"
2021.maiworkshop-1.9,P19-1239,0,0.0202542,"and Reichart, 2017), but they are rather different as tasks and we will not discuss them in detail. Badlani et al. (2019) show an approach for sarcasm detection in online reivews. They train a CNN (convolutional neural network) based model on separate feature embeddings for sarcasm, humor, sentiment and hate speech. Similarly, Babanejad et al. (2020) also detect sarcasm in text. They combine an LSTM (long short-term memory) model with BERT. Dubey et al. (2019) also work on text only by detecting sarcastic numbers in tweets. They experiment with rules, SVMs (support vector machines) and CNNs. Cai et al. (2019) use an LSTM model to detect sarcasm in tweets. Their approach is multimodal in the sense that it takes text and images into account, but it does not deal with audio and video like our 1 Open access version of the data (contains text only) https://zenodo.org/record/4701383 2 Access by request version of the data (videos and text) https://zenodo.org/record/4707913 63 Proceedings of the Third Workshop on Multimodal Artificial Intelligence, pages 63–68 June 6, 2021. ©2021 Association for Computational Linguistics Speaker Archer Stan Lana Utterance No, Lana, para nada Lo siento chicos, mi papá dic"
2021.maiworkshop-1.9,W19-8637,1,0.860225,"Missing"
2021.maiworkshop-1.9,P19-1455,0,0.24488,"(videos and text) https://zenodo.org/record/4707913 63 Proceedings of the Third Workshop on Multimodal Artificial Intelligence, pages 63–68 June 6, 2021. ©2021 Association for Computational Linguistics Speaker Archer Stan Lana Utterance No, Lana, para nada Lo siento chicos, mi papá dice que está muy ocupado con los Broncos, no tiene tiempo Decías algo acerca de un plan Translation No, Lana, not at all I am sorry guys, my dad says he is very busy with the Broncos, he doesn’t have time You said something about a plan Sarcasm true false true Table 1: Example sentences from the dataset. approach. Castro et al. (2019) present a multimodal sarcasm dataset in English. The dataset consists of annotated videos from TV sitcoms such as Friends and the Big Bang Theory, apart from being in English instead of Spanish, the main difference is that our dataset consists of animated cartoons instead of TV shows played by real people. Another big difference is in the data collection as they opted for querying sarcastic video clips, where as the data we work with represents full episodes. Chauhan et al. (2020) use this data and present a multimodal sarcasm detection framework based on a Bi-GRU model. Many of the related w"
2021.maiworkshop-1.9,2020.acl-main.711,0,0.0229818,"t view to sarcasm in the literature, for example, according to Kumon-Nakamura et al. (1995) sarcasm requires an allusion to a failed expectation and pragmatic insincerity (see Grice 1975) to be present in the same time. However, Utsumi (1996) highlights that these two preconditions are not enough, as sarcasm needs an ironic context to take place. Haverkate (1990) argues that, in the context of sarcasm, the meaning difference can either be the Related work In this section, we will present some of the recent related work on sarcasm detection. There has been some work also on sarcasm generation (Chakrabarty et al., 2020) and interpretation (Peled and Reichart, 2017), but they are rather different as tasks and we will not discuss them in detail. Badlani et al. (2019) show an approach for sarcasm detection in online reivews. They train a CNN (convolutional neural network) based model on separate feature embeddings for sarcasm, humor, sentiment and hate speech. Similarly, Babanejad et al. (2020) also detect sarcasm in text. They combine an LSTM (long short-term memory) model with BERT. Dubey et al. (2019) also work on text only by detecting sarcastic numbers in tweets. They experiment with rules, SVMs (support v"
2021.maiworkshop-1.9,2020.acl-main.401,0,0.0282385,"ime You said something about a plan Sarcasm true false true Table 1: Example sentences from the dataset. approach. Castro et al. (2019) present a multimodal sarcasm dataset in English. The dataset consists of annotated videos from TV sitcoms such as Friends and the Big Bang Theory, apart from being in English instead of Spanish, the main difference is that our dataset consists of animated cartoons instead of TV shows played by real people. Another big difference is in the data collection as they opted for querying sarcastic video clips, where as the data we work with represents full episodes. Chauhan et al. (2020) use this data and present a multimodal sarcasm detection framework based on a Bi-GRU model. Many of the related work has been focusing on text only. Research on multimodal approaches has been carried out only for English data, not unlike the textual approaches. 3 which is speaker intent, and rather they consider sarcasm purely based on subjective intuition. In order to produce a multimodal dataset out of the existing one, we locate the corresponding videos for the annotations and manually align them with the video. We use our own in-house tool JustAnnotate for this task4 . This was a time con"
2021.maiworkshop-1.9,K18-2005,0,0.0191395,"000), due to its efficiency when dealing with a high dimensional space and ability to train a model with small data. We use the SVM implementation provided in Scikit-learn (Pedregosa et al., 2011). Following the work of Castro et al. (2019), we use an RBF kernel and a scaled gamma. The regularization parameter C is set for 1000. This setup is followed in all of our SVM models. Regarding the textual features of the SVM, we make use of GloVe (Pennington et al., 2014) embeddings5 trained on the Spanish Billion Words Corpus (Cardellino, 2019) and ELMo (Peters et al., 2018) embeddings provided by (Che et al., 2018). Each textual instance is tokenized using TokTok6 , and then a sentence-level vector is constructed by computing the centroid (i.e., average vector) of all tokens, for each word embeddings type. In the case of ELMo, the vector of each token is the average of the last three layers of the neural network. The input to the SVM model is the concatenation of the two types of sentence embeddings. Figure 2: Cartman uttering a sarcastic sentence that can be resolved only by visual cues. In Figure 2 Cartman comments on the neckpiece of Stan by saying Esas corbatas están de moda, tiene suerte de tenerla"
2021.maiworkshop-1.9,P17-4012,0,0.0235777,"Missing"
2021.maiworkshop-1.9,C96-2162,0,0.163682,"ive language, where the meaning of an utterance has little to do with the surface meaning (see Kreuz and Glucksberg 1989). Understanding sarcasm is difficult even for us humans as it requires certain mental capacities such as a theory of mind (see Zhu and Wang 2020) and it is very dependent on the context and speaker who is being sarcastic. There are also very different view to sarcasm in the literature, for example, according to Kumon-Nakamura et al. (1995) sarcasm requires an allusion to a failed expectation and pragmatic insincerity (see Grice 1975) to be present in the same time. However, Utsumi (1996) highlights that these two preconditions are not enough, as sarcasm needs an ironic context to take place. Haverkate (1990) argues that, in the context of sarcasm, the meaning difference can either be the Related work In this section, we will present some of the recent related work on sarcasm detection. There has been some work also on sarcasm generation (Chakrabarty et al., 2020) and interpretation (Peled and Reichart, 2017), but they are rather different as tasks and we will not discuss them in detail. Badlani et al. (2019) show an approach for sarcasm detection in online reivews. They train"
2021.maiworkshop-1.9,D15-1166,0,0.0219968,"against the common sense Figure 1 shows an example of a scene in the corpus. In this particular scene, Archer asks sarcastically ¿Dónde se compra la leche materna? (Where 3 Available on https://www.kaggle.com/mikahama/the-bestsarcasm-annotated-dataset-in-spanish 4 64 https://mikakalevi.com/downloads/JustAnnotate.exe does one buy breast milk?). This is an example of sarcasm in the corpus where sarcasm violates common sense. Depending on the speaker, the utterance might be sarcastic or the speaker might lack knowledge on the topic. tion model, which is the general global attention presented by Luong et al. (2015). The model is trained for the default 100,000 steps. The second model is a Support Vector Machine (SVM) (Schölkopf et al., 2000), due to its efficiency when dealing with a high dimensional space and ability to train a model with small data. We use the SVM implementation provided in Scikit-learn (Pedregosa et al., 2011). Following the work of Castro et al. (2019), we use an RBF kernel and a scaled gamma. The regularization parameter C is set for 1000. This setup is followed in all of our SVM models. Regarding the textual features of the SVM, we make use of GloVe (Pennington et al., 2014) embed"
2021.maiworkshop-1.9,P17-1155,0,0.0198795,"le, according to Kumon-Nakamura et al. (1995) sarcasm requires an allusion to a failed expectation and pragmatic insincerity (see Grice 1975) to be present in the same time. However, Utsumi (1996) highlights that these two preconditions are not enough, as sarcasm needs an ironic context to take place. Haverkate (1990) argues that, in the context of sarcasm, the meaning difference can either be the Related work In this section, we will present some of the recent related work on sarcasm detection. There has been some work also on sarcasm generation (Chakrabarty et al., 2020) and interpretation (Peled and Reichart, 2017), but they are rather different as tasks and we will not discuss them in detail. Badlani et al. (2019) show an approach for sarcasm detection in online reivews. They train a CNN (convolutional neural network) based model on separate feature embeddings for sarcasm, humor, sentiment and hate speech. Similarly, Babanejad et al. (2020) also detect sarcasm in text. They combine an LSTM (long short-term memory) model with BERT. Dubey et al. (2019) also work on text only by detecting sarcastic numbers in tweets. They experiment with rules, SVMs (support vector machines) and CNNs. Cai et al. (2019) us"
2021.maiworkshop-1.9,D14-1162,0,0.0854267,"esented by Luong et al. (2015). The model is trained for the default 100,000 steps. The second model is a Support Vector Machine (SVM) (Schölkopf et al., 2000), due to its efficiency when dealing with a high dimensional space and ability to train a model with small data. We use the SVM implementation provided in Scikit-learn (Pedregosa et al., 2011). Following the work of Castro et al. (2019), we use an RBF kernel and a scaled gamma. The regularization parameter C is set for 1000. This setup is followed in all of our SVM models. Regarding the textual features of the SVM, we make use of GloVe (Pennington et al., 2014) embeddings5 trained on the Spanish Billion Words Corpus (Cardellino, 2019) and ELMo (Peters et al., 2018) embeddings provided by (Che et al., 2018). Each textual instance is tokenized using TokTok6 , and then a sentence-level vector is constructed by computing the centroid (i.e., average vector) of all tokens, for each word embeddings type. In the case of ELMo, the vector of each token is the average of the last three layers of the neural network. The input to the SVM model is the concatenation of the two types of sentence embeddings. Figure 2: Cartman uttering a sarcastic sentence that can b"
2021.maiworkshop-1.9,N18-1202,0,0.019895,"ort Vector Machine (SVM) (Schölkopf et al., 2000), due to its efficiency when dealing with a high dimensional space and ability to train a model with small data. We use the SVM implementation provided in Scikit-learn (Pedregosa et al., 2011). Following the work of Castro et al. (2019), we use an RBF kernel and a scaled gamma. The regularization parameter C is set for 1000. This setup is followed in all of our SVM models. Regarding the textual features of the SVM, we make use of GloVe (Pennington et al., 2014) embeddings5 trained on the Spanish Billion Words Corpus (Cardellino, 2019) and ELMo (Peters et al., 2018) embeddings provided by (Che et al., 2018). Each textual instance is tokenized using TokTok6 , and then a sentence-level vector is constructed by computing the centroid (i.e., average vector) of all tokens, for each word embeddings type. In the case of ELMo, the vector of each token is the average of the last three layers of the neural network. The input to the SVM model is the concatenation of the two types of sentence embeddings. Figure 2: Cartman uttering a sarcastic sentence that can be resolved only by visual cues. In Figure 2 Cartman comments on the neckpiece of Stan by saying Esas corba"
2021.nlp4if-1.6,P19-1498,0,0.017681,"eedings of the 4th NLP4IF Workshop on NLP for Internet Freedom, pages 39–44 June 6, 2021. ©2021 Association for Computational Linguistics language, that has also sparked research interest in detection (Li et al., 2020) and generation (Alnajjar and Hämäläinen, 2018) on its own, was useful in detecting fake news. They proposed an SVM (support vector machines) approach capturing five features: Absurdity, Humor, Grammar, Negative Affect and Punctuation. The idea of satire in fake news detection was also studied later on by Levi et al. (2019). Tree LSTMs have been used recently in rumor detection (Kumar and Carley, 2019). They train the models on social media text which contains interactions as people reply to statements either providing supporting or contradicting statements. Their model is capable of taking these replies into account when doing predictions. Sujana et al. (2020) detect rumors by using multiloss hierarchical BiLSTM models. The authors claim the hierarchical structure makes it possible to extract deep information form text. Their results show that their model outperforms a regular BiLSTM model. Previous work on Finnish news materials include a study by (Ruokolainen et al., 2019), where the art"
2021.nlp4if-1.6,N19-1423,0,0.0775724,"Missing"
2021.nlp4if-1.6,W17-0237,0,0.0154057,"f the default RNN (recurrent neural network). We use the default of two layers for both the encoder and the decoder and the default attention model, which is the general global attention presented by Luong et al. (2015). The model is trained for the default 100,000 steps. The model is trained with tokenized headlines as its source and the rumor/factual label as its target. We train an additional LSTM model with the same configuration and same random seed (3435) with the only difference being that we use pretrained word2vec embeddings for the encoder. We use the Finnish embeddings provided by (Kutuzov et al., 2017)4 . The vector size is 100 and the model has been trained with a window size 10 using skipgrams on the Finnish CoNLL17 corpus. In addition, we train two different BERT based sequence classification models based on the Finnish BERT model FinBERT (Virtanen et al., Data We collect data from a Finnish news aggregation website2 , in particular, we crawl the news headlines in the rumor category to form samples of rumor data. In addition, we crawl the headlines in the category news from Finland to compile a list of headlines that do not contain rumors but actual fact-based news stories. This way we h"
2021.nlp4if-1.6,D19-5004,0,0.0174665,"available for download on Zenodo https://zenodo.org/record/4697529 39 Proceedings of the 4th NLP4IF Workshop on NLP for Internet Freedom, pages 39–44 June 6, 2021. ©2021 Association for Computational Linguistics language, that has also sparked research interest in detection (Li et al., 2020) and generation (Alnajjar and Hämäläinen, 2018) on its own, was useful in detecting fake news. They proposed an SVM (support vector machines) approach capturing five features: Absurdity, Humor, Grammar, Negative Affect and Punctuation. The idea of satire in fake news detection was also studied later on by Levi et al. (2019). Tree LSTMs have been used recently in rumor detection (Kumar and Carley, 2019). They train the models on social media text which contains interactions as people reply to statements either providing supporting or contradicting statements. Their model is capable of taking these replies into account when doing predictions. Sujana et al. (2020) detect rumors by using multiloss hierarchical BiLSTM models. The authors claim the hierarchical structure makes it possible to extract deep information form text. Their results show that their model outperforms a regular BiLSTM model. Previous work on Fin"
2021.nlp4if-1.6,2020.lrec-1.775,0,0.0357052,"h interest in this topic, and 2 Related Work Rumor detection has in recent years become an active topic of investigation, especially due to the complex influence it has on modern societies through social media. There has been other work on rumor detection for languages other than English as well. Alzanin and Azmi (2019) studied rumor detection in Arabic tweets and Chernyaev et al. (2020) in Russian tweets. Recently, Ke et al. (2020) has also presented a method for rumor detection in Cantonese. A closely related topic, stance detection, has been studied in a comparable corpus of French Tweets (Evrard et al., 2020). In this section, we describe some of the related work in more detail. Rubin et al. (2016) harnessed satire in the task of fake news detection, in their study, this figure of 1 Our dataset is freely available for download on Zenodo https://zenodo.org/record/4697529 39 Proceedings of the 4th NLP4IF Workshop on NLP for Internet Freedom, pages 39–44 June 6, 2021. ©2021 Association for Computational Linguistics language, that has also sparked research interest in detection (Li et al., 2020) and generation (Alnajjar and Hämäläinen, 2018) on its own, was useful in detecting fake news. They proposed"
2021.nlp4if-1.6,2020.nlp4if-1.4,0,0.0327432,"e. A closely related topic, stance detection, has been studied in a comparable corpus of French Tweets (Evrard et al., 2020). In this section, we describe some of the related work in more detail. Rubin et al. (2016) harnessed satire in the task of fake news detection, in their study, this figure of 1 Our dataset is freely available for download on Zenodo https://zenodo.org/record/4697529 39 Proceedings of the 4th NLP4IF Workshop on NLP for Internet Freedom, pages 39–44 June 6, 2021. ©2021 Association for Computational Linguistics language, that has also sparked research interest in detection (Li et al., 2020) and generation (Alnajjar and Hämäläinen, 2018) on its own, was useful in detecting fake news. They proposed an SVM (support vector machines) approach capturing five features: Absurdity, Humor, Grammar, Negative Affect and Punctuation. The idea of satire in fake news detection was also studied later on by Levi et al. (2019). Tree LSTMs have been used recently in rumor detection (Kumar and Carley, 2019). They train the models on social media text which contains interactions as people reply to statements either providing supporting or contradicting statements. Their model is capable of taking th"
2021.nlp4if-1.6,W18-0205,1,0.808601,"Missing"
2021.nlp4if-1.6,W02-0109,0,0.0739305,"Missing"
2021.nlp4if-1.6,D15-1166,0,0.012756,"etection. We compare LSTM based models with transfer learning on two different BERT models. We train our first model using a bi-directional long short-term memory (LSTM) based model (Hochreiter and Schmidhuber, 1997) using OpenNMT (Klein et al., 2017) with the default settings except for the encoder where we use a BRNN (bidirectional recurrent neural network) (Schuster and Paliwal, 1997) instead of the default RNN (recurrent neural network). We use the default of two layers for both the encoder and the decoder and the default attention model, which is the general global attention presented by Luong et al. (2015). The model is trained for the default 100,000 steps. The model is trained with tokenized headlines as its source and the rumor/factual label as its target. We train an additional LSTM model with the same configuration and same random seed (3435) with the only difference being that we use pretrained word2vec embeddings for the encoder. We use the Finnish embeddings provided by (Kutuzov et al., 2017)4 . The vector size is 100 and the model has been trained with a window size 10 using skipgrams on the Finnish CoNLL17 corpus. In addition, we train two different BERT based sequence classification"
2021.nlp4if-1.6,2020.emnlp-demos.6,0,0.0828558,"Missing"
2021.nlp4if-1.6,Y18-1061,0,0.0651208,"Missing"
2021.nlp4if-1.6,N18-2084,0,0.0388749,"Missing"
2021.nlp4if-1.6,W16-0802,0,0.0470742,"ctive topic of investigation, especially due to the complex influence it has on modern societies through social media. There has been other work on rumor detection for languages other than English as well. Alzanin and Azmi (2019) studied rumor detection in Arabic tweets and Chernyaev et al. (2020) in Russian tweets. Recently, Ke et al. (2020) has also presented a method for rumor detection in Cantonese. A closely related topic, stance detection, has been studied in a comparable corpus of French Tweets (Evrard et al., 2020). In this section, we describe some of the related work in more detail. Rubin et al. (2016) harnessed satire in the task of fake news detection, in their study, this figure of 1 Our dataset is freely available for download on Zenodo https://zenodo.org/record/4697529 39 Proceedings of the 4th NLP4IF Workshop on NLP for Internet Freedom, pages 39–44 June 6, 2021. ©2021 Association for Computational Linguistics language, that has also sparked research interest in detection (Li et al., 2020) and generation (Alnajjar and Hämäläinen, 2018) on its own, was useful in detecting fake news. They proposed an SVM (support vector machines) approach capturing five features: Absurdity, Humor, Gramm"
2021.nlp4if-1.6,2020.aacl-main.3,0,0.0278543,"n its own, was useful in detecting fake news. They proposed an SVM (support vector machines) approach capturing five features: Absurdity, Humor, Grammar, Negative Affect and Punctuation. The idea of satire in fake news detection was also studied later on by Levi et al. (2019). Tree LSTMs have been used recently in rumor detection (Kumar and Carley, 2019). They train the models on social media text which contains interactions as people reply to statements either providing supporting or contradicting statements. Their model is capable of taking these replies into account when doing predictions. Sujana et al. (2020) detect rumors by using multiloss hierarchical BiLSTM models. The authors claim the hierarchical structure makes it possible to extract deep information form text. Their results show that their model outperforms a regular BiLSTM model. Previous work on Finnish news materials include a study by (Ruokolainen et al., 2019), where the articles were annotated for named entities. In addition, other researchers have targeted Finnish news materials, especially historical newspapers that are openly available. Furthermore, (Mela et al., 2019) has studied NER (named entity recognition) in the context of"
2021.nodalida-main.17,W18-7101,0,0.0247087,"terud, 2004) and neural disambiguation (Ens et al., 2019), dependency parsing (Antonsen et al., 2010) and 1 https://github.com/mikahama/uralicNLP/wiki/Neuralmorphology 2 http://doi.org/10.5281/zenodo.3926769 3 http://doi.org/10.5281/zenodo.3928628 machine translation (Pirinen et al., 2017). The transducers are also in constant use in several real world applications such as online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Trosterud and Moshagen, 2021), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019), language learning tools (Antonsen and Argese, 2018) and documentation of endangered languages (Gerstenberger et al., 2017; Wilbur, 2018). As an additional important application we can mention the wide use of FSTs in the creation of Universal Dependencies treebanks for low-resource languages, at least with Erzya (Rueter and Tyers, 2018), Northern Saami (Tyers and Sheyanova, 2017) Karelian (Pirinen, 2019a) and Komi-Zyrian (Partanen et al., 2018). Especially in the context of endangered languages, accuracy is a virtue. Rule-based methods not only serve as NLP tools but also as a way of documenting languages in a machinereadable fashion. Members o"
2021.nodalida-main.17,antonsen-etal-2010-reusing,0,0.0203232,"cerning endangered languages, morphology is one of the first NLP problems people address. The GiellaLT infrastructure (Moshagen et al., 2014) has HFST-based (Lindén et al., 2013) finitestate transducers (FSTs) for several morphologically rich (and mostly Uralic) languages. These FSTs are capable of lemmatization, morphological analysis and morphological generation of different words. These transducers are at the core of this infrastructure, and they are in use in many higher level NLP tasks, such as rule-based (Trosterud, 2004) and neural disambiguation (Ens et al., 2019), dependency parsing (Antonsen et al., 2010) and 1 https://github.com/mikahama/uralicNLP/wiki/Neuralmorphology 2 http://doi.org/10.5281/zenodo.3926769 3 http://doi.org/10.5281/zenodo.3928628 machine translation (Pirinen et al., 2017). The transducers are also in constant use in several real world applications such as online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Trosterud and Moshagen, 2021), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019), language learning tools (Antonsen and Argese, 2018) and documentation of endangered languages (Gerstenberger et al., 2017; Wil"
2021.nodalida-main.17,W15-1807,0,0.0416183,"Missing"
2021.nodalida-main.17,W19-6139,1,0.790489,"es for NLP systems, and in the work concerning endangered languages, morphology is one of the first NLP problems people address. The GiellaLT infrastructure (Moshagen et al., 2014) has HFST-based (Lindén et al., 2013) finitestate transducers (FSTs) for several morphologically rich (and mostly Uralic) languages. These FSTs are capable of lemmatization, morphological analysis and morphological generation of different words. These transducers are at the core of this infrastructure, and they are in use in many higher level NLP tasks, such as rule-based (Trosterud, 2004) and neural disambiguation (Ens et al., 2019), dependency parsing (Antonsen et al., 2010) and 1 https://github.com/mikahama/uralicNLP/wiki/Neuralmorphology 2 http://doi.org/10.5281/zenodo.3926769 3 http://doi.org/10.5281/zenodo.3928628 machine translation (Pirinen et al., 2017). The transducers are also in constant use in several real world applications such as online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Trosterud and Moshagen, 2021), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019), language learning tools (Antonsen and Argese, 2018) and documentation of endangere"
2021.nodalida-main.17,W17-0109,1,0.82732,"parsing (Antonsen et al., 2010) and 1 https://github.com/mikahama/uralicNLP/wiki/Neuralmorphology 2 http://doi.org/10.5281/zenodo.3926769 3 http://doi.org/10.5281/zenodo.3928628 machine translation (Pirinen et al., 2017). The transducers are also in constant use in several real world applications such as online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Trosterud and Moshagen, 2021), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019), language learning tools (Antonsen and Argese, 2018) and documentation of endangered languages (Gerstenberger et al., 2017; Wilbur, 2018). As an additional important application we can mention the wide use of FSTs in the creation of Universal Dependencies treebanks for low-resource languages, at least with Erzya (Rueter and Tyers, 2018), Northern Saami (Tyers and Sheyanova, 2017) Karelian (Pirinen, 2019a) and Komi-Zyrian (Partanen et al., 2018). Especially in the context of endangered languages, accuracy is a virtue. Rule-based methods not only serve as NLP tools but also as a way of documenting languages in a machinereadable fashion. Members of language communities do not benefit, for example, from a neural spel"
2021.nodalida-main.17,W18-6525,1,0.752924,"is infrastructure, and they are in use in many higher level NLP tasks, such as rule-based (Trosterud, 2004) and neural disambiguation (Ens et al., 2019), dependency parsing (Antonsen et al., 2010) and 1 https://github.com/mikahama/uralicNLP/wiki/Neuralmorphology 2 http://doi.org/10.5281/zenodo.3926769 3 http://doi.org/10.5281/zenodo.3928628 machine translation (Pirinen et al., 2017). The transducers are also in constant use in several real world applications such as online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Trosterud and Moshagen, 2021), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019), language learning tools (Antonsen and Argese, 2018) and documentation of endangered languages (Gerstenberger et al., 2017; Wilbur, 2018). As an additional important application we can mention the wide use of FSTs in the creation of Universal Dependencies treebanks for low-resource languages, at least with Erzya (Rueter and Tyers, 2018), Northern Saami (Tyers and Sheyanova, 2017) Karelian (Pirinen, 2019a) and Komi-Zyrian (Partanen et al., 2018). Especially in the context of endangered languages, accuracy is a virtue. Rule-based methods not on"
2021.nodalida-main.17,2020.lrec-1.439,0,0.0430747,"for analysis, generation and lemmatization. It is important to note that we approach the lemmatization and analysis from the same point of view as the FSTs. This means that it is a strictly morphological process, and the question of disambiguation is left for another part of the GiellaLT NLP pipeline, namely constraint grammar rules (Bick and Didriksen, 2015). There is a plethora of work dealing with in-context lemmatization (Manjavacas et al., 2019; Malaviya et al., 2019), morphological analysis (Lim et al., 2018; Zalmout and Habash, 2020) and part-of-speech tagging (Perl et al., 2020; Hoya Quecedo et al., 2020), but that is not what we are aiming for. We are aiming for neural models that can be used to complement the already existing systems relying on the GiellaLT infrastructure. For all three tasks, we train a character based bidirectional LSTM model (Hochreiter and Schmidhuber, 1997) by using OpenNMT-py (Klein et al., 2017) with the default settings except for the encoder where we use a BRNN (bi-directional recurrent neural network) (Schuster and Paliwal, 1997) instead of the default RNN (recurrent neural network) as BRNN has been shown to provide a performance gain in a variety of tasks. We use"
2021.nodalida-main.17,P17-4012,0,0.0376459,"ammar rules (Bick and Didriksen, 2015). There is a plethora of work dealing with in-context lemmatization (Manjavacas et al., 2019; Malaviya et al., 2019), morphological analysis (Lim et al., 2018; Zalmout and Habash, 2020) and part-of-speech tagging (Perl et al., 2020; Hoya Quecedo et al., 2020), but that is not what we are aiming for. We are aiming for neural models that can be used to complement the already existing systems relying on the GiellaLT infrastructure. For all three tasks, we train a character based bidirectional LSTM model (Hochreiter and Schmidhuber, 1997) by using OpenNMT-py (Klein et al., 2017) with the default settings except for the encoder where we use a BRNN (bi-directional recurrent neural network) (Schuster and Paliwal, 1997) instead of the default RNN (recurrent neural network) as BRNN has been shown to provide a performance gain in a variety of tasks. We use the default of two layers for both the encoder and the decoder and the default attention model, which is the general global attention presented by Luong et al. (Luong et al., 2015). Table 4 shows an example of the input and output of the training data in each of the three different tasks. Words are split into characters"
2021.nodalida-main.17,W19-4203,0,0.0236945,"s where the FSTs fail in their coverage. 3 Experiments and Results In this section, we cover the neural architecture for the three separate morphological tasks: lemmatization, analysis and generation. We also show the results of the models in these tasks for each language, and present an error analysis on the Finnish and Komi-Zyrian by taking a closer look at the results. 3.1 The Neural Model Over recent years, there has been a growing body of work on different neural approaches for low resourced languages in morphological analysis (Moeller et al., 2019; Schwartz et al., 2019), lemmatization (Kondratyuk, 2019; Silfverberg and Tyers, 2019) and generation (Oseki et al., 2019; Yu et al., 2020). Most notably the use of bi-directional LSTM architecture seems to be supported by most of the recent related work for analysis, generation and lemmatization. It is important to note that we approach the lemmatization and analysis from the same point of view as the FSTs. This means that it is a strictly morphological process, and the question of disambiguation is left for another part of the GiellaLT NLP pipeline, namely constraint grammar rules (Bick and Didriksen, 2015). There is a plethora of work dealing wi"
2021.nodalida-main.17,L18-1352,1,0.78617,"use of bi-directional LSTM architecture seems to be supported by most of the recent related work for analysis, generation and lemmatization. It is important to note that we approach the lemmatization and analysis from the same point of view as the FSTs. This means that it is a strictly morphological process, and the question of disambiguation is left for another part of the GiellaLT NLP pipeline, namely constraint grammar rules (Bick and Didriksen, 2015). There is a plethora of work dealing with in-context lemmatization (Manjavacas et al., 2019; Malaviya et al., 2019), morphological analysis (Lim et al., 2018; Zalmout and Habash, 2020) and part-of-speech tagging (Perl et al., 2020; Hoya Quecedo et al., 2020), but that is not what we are aiming for. We are aiming for neural models that can be used to complement the already existing systems relying on the GiellaLT infrastructure. For all three tasks, we train a character based bidirectional LSTM model (Hochreiter and Schmidhuber, 1997) by using OpenNMT-py (Klein et al., 2017) with the default settings except for the encoder where we use a BRNN (bi-directional recurrent neural network) (Schuster and Paliwal, 1997) instead of the default RNN (recurren"
2021.nodalida-main.17,D15-1166,0,0.0589999,"rastructure. For all three tasks, we train a character based bidirectional LSTM model (Hochreiter and Schmidhuber, 1997) by using OpenNMT-py (Klein et al., 2017) with the default settings except for the encoder where we use a BRNN (bi-directional recurrent neural network) (Schuster and Paliwal, 1997) instead of the default RNN (recurrent neural network) as BRNN has been shown to provide a performance gain in a variety of tasks. We use the default of two layers for both the encoder and the decoder and the default attention model, which is the general global attention presented by Luong et al. (Luong et al., 2015). Table 4 shows an example of the input and output of the training data in each of the three different tasks. Words are split into characters on both the input and output side of the data. Different morphological tags are treated as separate tokens, this means that FST morphologies consisting of multiple tags such as N+Msc+Sg+Dat are simply split by the plus sign. We train a separate model for each task, meaning that we train three different models for each language: one for lemmatization, analysis and generation. All models have shared the same random seed (3435), therefore training the model"
2021.nodalida-main.17,N19-1155,0,0.0199289,"t al., 2019; Yu et al., 2020). Most notably the use of bi-directional LSTM architecture seems to be supported by most of the recent related work for analysis, generation and lemmatization. It is important to note that we approach the lemmatization and analysis from the same point of view as the FSTs. This means that it is a strictly morphological process, and the question of disambiguation is left for another part of the GiellaLT NLP pipeline, namely constraint grammar rules (Bick and Didriksen, 2015). There is a plethora of work dealing with in-context lemmatization (Manjavacas et al., 2019; Malaviya et al., 2019), morphological analysis (Lim et al., 2018; Zalmout and Habash, 2020) and part-of-speech tagging (Perl et al., 2020; Hoya Quecedo et al., 2020), but that is not what we are aiming for. We are aiming for neural models that can be used to complement the already existing systems relying on the GiellaLT infrastructure. For all three tasks, we train a character based bidirectional LSTM model (Hochreiter and Schmidhuber, 1997) by using OpenNMT-py (Klein et al., 2017) with the default settings except for the encoder where we use a BRNN (bi-directional recurrent neural network) (Schuster and Paliwal,"
2021.nodalida-main.17,N19-1153,0,0.0253488,") and generation (Oseki et al., 2019; Yu et al., 2020). Most notably the use of bi-directional LSTM architecture seems to be supported by most of the recent related work for analysis, generation and lemmatization. It is important to note that we approach the lemmatization and analysis from the same point of view as the FSTs. This means that it is a strictly morphological process, and the question of disambiguation is left for another part of the GiellaLT NLP pipeline, namely constraint grammar rules (Bick and Didriksen, 2015). There is a plethora of work dealing with in-context lemmatization (Manjavacas et al., 2019; Malaviya et al., 2019), morphological analysis (Lim et al., 2018; Zalmout and Habash, 2020) and part-of-speech tagging (Perl et al., 2020; Hoya Quecedo et al., 2020), but that is not what we are aiming for. We are aiming for neural models that can be used to complement the already existing systems relying on the GiellaLT infrastructure. For all three tasks, we train a character based bidirectional LSTM model (Hochreiter and Schmidhuber, 1997) by using OpenNMT-py (Klein et al., 2017) with the default settings except for the encoder where we use a BRNN (bi-directional recurrent neural network)"
2021.nodalida-main.17,2020.lrec-1.483,0,0.0457872,"Missing"
2021.nodalida-main.17,W19-6011,0,0.0205936,"s more close to the one they are trained for, namely, in cases where the FSTs fail in their coverage. 3 Experiments and Results In this section, we cover the neural architecture for the three separate morphological tasks: lemmatization, analysis and generation. We also show the results of the models in these tasks for each language, and present an error analysis on the Finnish and Komi-Zyrian by taking a closer look at the results. 3.1 The Neural Model Over recent years, there has been a growing body of work on different neural approaches for low resourced languages in morphological analysis (Moeller et al., 2019; Schwartz et al., 2019), lemmatization (Kondratyuk, 2019; Silfverberg and Tyers, 2019) and generation (Oseki et al., 2019; Yu et al., 2020). Most notably the use of bi-directional LSTM architecture seems to be supported by most of the recent related work for analysis, generation and lemmatization. It is important to note that we approach the lemmatization and analysis from the same point of view as the FSTs. This means that it is a strictly morphological process, and the question of disambiguation is left for another part of the GiellaLT NLP pipeline, namely constraint grammar rules (Bick and"
2021.nodalida-main.17,W18-0210,1,0.805507,"). The transducers are also in constant use in several real world applications such as online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Trosterud and Moshagen, 2021), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019), language learning tools (Antonsen and Argese, 2018) and documentation of endangered languages (Gerstenberger et al., 2017; Wilbur, 2018). As an additional important application we can mention the wide use of FSTs in the creation of Universal Dependencies treebanks for low-resource languages, at least with Erzya (Rueter and Tyers, 2018), Northern Saami (Tyers and Sheyanova, 2017) Karelian (Pirinen, 2019a) and Komi-Zyrian (Partanen et al., 2018). Especially in the context of endangered languages, accuracy is a virtue. Rule-based methods not only serve as NLP tools but also as a way of documenting languages in a machinereadable fashion. Members of language communities do not benefit, for example, from a neural spell checker that works to a degree in a closed test set, but fails miserably in real world usage. On the contrary, a rule based description of morphology can only go so far. New words appear and disappear all the time"
2021.nodalida-main.17,W19-6012,0,0.0169437,"e they are trained for, namely, in cases where the FSTs fail in their coverage. 3 Experiments and Results In this section, we cover the neural architecture for the three separate morphological tasks: lemmatization, analysis and generation. We also show the results of the models in these tasks for each language, and present an error analysis on the Finnish and Komi-Zyrian by taking a closer look at the results. 3.1 The Neural Model Over recent years, there has been a growing body of work on different neural approaches for low resourced languages in morphological analysis (Moeller et al., 2019; Schwartz et al., 2019), lemmatization (Kondratyuk, 2019; Silfverberg and Tyers, 2019) and generation (Oseki et al., 2019; Yu et al., 2020). Most notably the use of bi-directional LSTM architecture seems to be supported by most of the recent related work for analysis, generation and lemmatization. It is important to note that we approach the lemmatization and analysis from the same point of view as the FSTs. This means that it is a strictly morphological process, and the question of disambiguation is left for another part of the GiellaLT NLP pipeline, namely constraint grammar rules (Bick and Didriksen, 2015). There"
2021.nodalida-main.17,W19-4220,0,0.0218591,"lts In this section, we cover the neural architecture for the three separate morphological tasks: lemmatization, analysis and generation. We also show the results of the models in these tasks for each language, and present an error analysis on the Finnish and Komi-Zyrian by taking a closer look at the results. 3.1 The Neural Model Over recent years, there has been a growing body of work on different neural approaches for low resourced languages in morphological analysis (Moeller et al., 2019; Schwartz et al., 2019), lemmatization (Kondratyuk, 2019; Silfverberg and Tyers, 2019) and generation (Oseki et al., 2019; Yu et al., 2020). Most notably the use of bi-directional LSTM architecture seems to be supported by most of the recent related work for analysis, generation and lemmatization. It is important to note that we approach the lemmatization and analysis from the same point of view as the FSTs. This means that it is a strictly morphological process, and the question of disambiguation is left for another part of the GiellaLT NLP pipeline, namely constraint grammar rules (Bick and Didriksen, 2015). There is a plethora of work dealing with in-context lemmatization (Manjavacas et al., 2019; Malaviya et"
2021.nodalida-main.17,W18-6015,1,0.851167,"ter and Hämäläinen, 2019), spell checkers (Trosterud and Moshagen, 2021), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019), language learning tools (Antonsen and Argese, 2018) and documentation of endangered languages (Gerstenberger et al., 2017; Wilbur, 2018). As an additional important application we can mention the wide use of FSTs in the creation of Universal Dependencies treebanks for low-resource languages, at least with Erzya (Rueter and Tyers, 2018), Northern Saami (Tyers and Sheyanova, 2017) Karelian (Pirinen, 2019a) and Komi-Zyrian (Partanen et al., 2018). Especially in the context of endangered languages, accuracy is a virtue. Rule-based methods not only serve as NLP tools but also as a way of documenting languages in a machinereadable fashion. Members of language communities do not benefit, for example, from a neural spell checker that works to a degree in a closed test set, but fails miserably in real world usage. On the contrary, a rule based description of morphology can only go so far. New words appear and disappear all the time in a language, and keeping up with that pace is a never ending job. This is where neural models come in as the"
2021.nodalida-main.17,2020.acl-main.239,0,0.0774166,"Missing"
2021.nodalida-main.17,W19-8016,0,0.011685,"such as online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Trosterud and Moshagen, 2021), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019), language learning tools (Antonsen and Argese, 2018) and documentation of endangered languages (Gerstenberger et al., 2017; Wilbur, 2018). As an additional important application we can mention the wide use of FSTs in the creation of Universal Dependencies treebanks for low-resource languages, at least with Erzya (Rueter and Tyers, 2018), Northern Saami (Tyers and Sheyanova, 2017) Karelian (Pirinen, 2019a) and Komi-Zyrian (Partanen et al., 2018). Especially in the context of endangered languages, accuracy is a virtue. Rule-based methods not only serve as NLP tools but also as a way of documenting languages in a machinereadable fashion. Members of language communities do not benefit, for example, from a neural spell checker that works to a degree in a closed test set, but fails miserably in real world usage. On the contrary, a rule based description of morphology can only go so far. New words appear and disappear all the time in a language, and keeping up with that pace is a never ending job."
2021.nodalida-main.17,W19-0309,0,0.0236503,"such as online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Trosterud and Moshagen, 2021), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019), language learning tools (Antonsen and Argese, 2018) and documentation of endangered languages (Gerstenberger et al., 2017; Wilbur, 2018). As an additional important application we can mention the wide use of FSTs in the creation of Universal Dependencies treebanks for low-resource languages, at least with Erzya (Rueter and Tyers, 2018), Northern Saami (Tyers and Sheyanova, 2017) Karelian (Pirinen, 2019a) and Komi-Zyrian (Partanen et al., 2018). Especially in the context of endangered languages, accuracy is a virtue. Rule-based methods not only serve as NLP tools but also as a way of documenting languages in a machinereadable fashion. Members of language communities do not benefit, for example, from a neural spell checker that works to a degree in a closed test set, but fails miserably in real world usage. On the contrary, a rule based description of morphology can only go so far. New words appear and disappear all the time in a language, and keeping up with that pace is a never ending job."
2021.nodalida-main.17,W17-0214,0,0.0143737,"transducers (FSTs) for several morphologically rich (and mostly Uralic) languages. These FSTs are capable of lemmatization, morphological analysis and morphological generation of different words. These transducers are at the core of this infrastructure, and they are in use in many higher level NLP tasks, such as rule-based (Trosterud, 2004) and neural disambiguation (Ens et al., 2019), dependency parsing (Antonsen et al., 2010) and 1 https://github.com/mikahama/uralicNLP/wiki/Neuralmorphology 2 http://doi.org/10.5281/zenodo.3926769 3 http://doi.org/10.5281/zenodo.3928628 machine translation (Pirinen et al., 2017). The transducers are also in constant use in several real world applications such as online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Trosterud and Moshagen, 2021), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019), language learning tools (Antonsen and Argese, 2018) and documentation of endangered languages (Gerstenberger et al., 2017; Wilbur, 2018). As an additional important application we can mention the wide use of FSTs in the creation of Universal Dependencies treebanks for low-resource languages, at least with Erzya (R"
2021.nodalida-main.17,2020.lrec-1.858,0,0.0998538,"Missing"
2021.nodalida-main.17,Q18-1030,0,0.027652,"Missing"
2021.nodalida-main.17,W19-0301,0,0.0116411,"ail in their coverage. 3 Experiments and Results In this section, we cover the neural architecture for the three separate morphological tasks: lemmatization, analysis and generation. We also show the results of the models in these tasks for each language, and present an error analysis on the Finnish and Komi-Zyrian by taking a closer look at the results. 3.1 The Neural Model Over recent years, there has been a growing body of work on different neural approaches for low resourced languages in morphological analysis (Moeller et al., 2019; Schwartz et al., 2019), lemmatization (Kondratyuk, 2019; Silfverberg and Tyers, 2019) and generation (Oseki et al., 2019; Yu et al., 2020). Most notably the use of bi-directional LSTM architecture seems to be supported by most of the recent related work for analysis, generation and lemmatization. It is important to note that we approach the lemmatization and analysis from the same point of view as the FSTs. This means that it is a strictly morphological process, and the question of disambiguation is left for another part of the GiellaLT NLP pipeline, namely constraint grammar rules (Bick and Didriksen, 2015). There is a plethora of work dealing with in-context lemmatization (M"
2021.nodalida-main.17,W17-0607,0,0.0119904,"se in several real world applications such as online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Trosterud and Moshagen, 2021), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019), language learning tools (Antonsen and Argese, 2018) and documentation of endangered languages (Gerstenberger et al., 2017; Wilbur, 2018). As an additional important application we can mention the wide use of FSTs in the creation of Universal Dependencies treebanks for low-resource languages, at least with Erzya (Rueter and Tyers, 2018), Northern Saami (Tyers and Sheyanova, 2017) Karelian (Pirinen, 2019a) and Komi-Zyrian (Partanen et al., 2018). Especially in the context of endangered languages, accuracy is a virtue. Rule-based methods not only serve as NLP tools but also as a way of documenting languages in a machinereadable fashion. Members of language communities do not benefit, for example, from a neural spell checker that works to a degree in a closed test set, but fails miserably in real world usage. On the contrary, a rule based description of morphology can only go so far. New words appear and disappear all the time in a language, and keeping up with that pace"
2021.nodalida-main.17,W18-0213,0,0.0227916,"10) and 1 https://github.com/mikahama/uralicNLP/wiki/Neuralmorphology 2 http://doi.org/10.5281/zenodo.3926769 3 http://doi.org/10.5281/zenodo.3928628 machine translation (Pirinen et al., 2017). The transducers are also in constant use in several real world applications such as online dictionaries (Rueter and Hämäläinen, 2019), spell checkers (Trosterud and Moshagen, 2021), online creative writing tools (Hämäläinen, 2018), automated news generation (Alnajjar et al., 2019), language learning tools (Antonsen and Argese, 2018) and documentation of endangered languages (Gerstenberger et al., 2017; Wilbur, 2018). As an additional important application we can mention the wide use of FSTs in the creation of Universal Dependencies treebanks for low-resource languages, at least with Erzya (Rueter and Tyers, 2018), Northern Saami (Tyers and Sheyanova, 2017) Karelian (Pirinen, 2019a) and Komi-Zyrian (Partanen et al., 2018). Especially in the context of endangered languages, accuracy is a virtue. Rule-based methods not only serve as NLP tools but also as a way of documenting languages in a machinereadable fashion. Members of language communities do not benefit, for example, from a neural spell checker that"
2021.nodalida-main.17,2020.sigmorphon-1.5,0,0.0199535,"we cover the neural architecture for the three separate morphological tasks: lemmatization, analysis and generation. We also show the results of the models in these tasks for each language, and present an error analysis on the Finnish and Komi-Zyrian by taking a closer look at the results. 3.1 The Neural Model Over recent years, there has been a growing body of work on different neural approaches for low resourced languages in morphological analysis (Moeller et al., 2019; Schwartz et al., 2019), lemmatization (Kondratyuk, 2019; Silfverberg and Tyers, 2019) and generation (Oseki et al., 2019; Yu et al., 2020). Most notably the use of bi-directional LSTM architecture seems to be supported by most of the recent related work for analysis, generation and lemmatization. It is important to note that we approach the lemmatization and analysis from the same point of view as the FSTs. This means that it is a strictly morphological process, and the question of disambiguation is left for another part of the GiellaLT NLP pipeline, namely constraint grammar rules (Bick and Didriksen, 2015). There is a plethora of work dealing with in-context lemmatization (Manjavacas et al., 2019; Malaviya et al., 2019), morph"
2021.nodalida-main.17,2020.acl-main.736,0,0.0231918,"nal LSTM architecture seems to be supported by most of the recent related work for analysis, generation and lemmatization. It is important to note that we approach the lemmatization and analysis from the same point of view as the FSTs. This means that it is a strictly morphological process, and the question of disambiguation is left for another part of the GiellaLT NLP pipeline, namely constraint grammar rules (Bick and Didriksen, 2015). There is a plethora of work dealing with in-context lemmatization (Manjavacas et al., 2019; Malaviya et al., 2019), morphological analysis (Lim et al., 2018; Zalmout and Habash, 2020) and part-of-speech tagging (Perl et al., 2020; Hoya Quecedo et al., 2020), but that is not what we are aiming for. We are aiming for neural models that can be used to complement the already existing systems relying on the GiellaLT infrastructure. For all three tasks, we train a character based bidirectional LSTM model (Hochreiter and Schmidhuber, 1997) by using OpenNMT-py (Klein et al., 2017) with the default settings except for the encoder where we use a BRNN (bi-directional recurrent neural network) (Schuster and Paliwal, 1997) instead of the default RNN (recurrent neural network) as BRNN h"
2021.nodalida-main.24,P18-1220,0,0.0199513,"r Finnish, Drobac et al. (2017) correct the OCR of newspapers using weighted finite-state methods, accordance with, Silfverberg and Rueter (2015) do the same for Finnish (and Erzya). Most recent approaches rely on the machine translation (MT) of “dirty” text 3 Eighteenth Century Collections Online, https://www.gale.com/primary-sources/ eighteenth-century-collections-online 4 http://www.impact-project.eu into “clean” texts. These MT approaches are quickly moving from statistical MT (SMT) – as previously used for historical text normalisation, e.g. the work by Pettersson et al. (2013) – to NMT: Dong and Smith (2018) use a word-level seq2seq NMT approach for OCR post-correction, while Hämäläinen and Hengchen (2019), on which we base our work, mobilised character-level NMT. Very recently, Nguyen et al. (2020) use BERT embeddings to improve an NMT-based OCR postcorrection system on English. 3 Experiment In this section, we describe our methods for automatically generating parallel data that can be used in a character-level NMT model to conduct OCR post-correction. In short, our method requires only a corpus with OCRed text that we want to automatically correct, a word list, a morphological analyzer and any"
2021.nodalida-main.24,W17-0209,0,0.0272886,"eports such as the one put forward by Smith and Cordell (2019) rise OCR initiatives, while the Library-of-Congress-commissioned report by Cordell (2020) underlines the importance of OCR for culturage heritage collections. These reports echo earlier work by, among others, Tanner et al. (2009) who tackle the digitisation of British newspapers, the EU-wide IMPACT project4 that gathers 26 national libraries, or Adesam et al. (2019) who set out to analyse the quality of OCR made available by the Swedish language bank. OCR post-correction has been tackled in previous work. Specifically for Finnish, Drobac et al. (2017) correct the OCR of newspapers using weighted finite-state methods, accordance with, Silfverberg and Rueter (2015) do the same for Finnish (and Erzya). Most recent approaches rely on the machine translation (MT) of “dirty” text 3 Eighteenth Century Collections Online, https://www.gale.com/primary-sources/ eighteenth-century-collections-online 4 http://www.impact-project.eu into “clean” texts. These MT approaches are quickly moving from statistical MT (SMT) – as previously used for historical text normalisation, e.g. the work by Pettersson et al. (2013) – to NMT: Dong and Smith (2018) use a wor"
2021.nodalida-main.24,R19-1051,1,0.870616,"roblem especially for endangered languages (Partanen, 2017), although OCR quality for such languages can be improved by limiting the domain in which the OCR models are trained and used (Partanen and Rießler, 2019). Automated OCR post-correction is usually modelled as a supervised machine learning problem where a model is trained with parallel data consisting of OCR erroneous text and manually corrected text. However, we want to develop a method that can be used even in contexts where no manually annotated data is available. The most viable recent method for such a task is the one presented by Hämäläinen and Hengchen (2019). However, their model works only on correcting individual words without considering the context in sentences, and as it focuses on English, it completely ignores the issues rising from a rich morphology. Extending their approach, we introduce a self-supervised model to automatically generate parallel data which is learned from the real OCRed text. Later, we train sequence-to-sequence (seq2seq) NMT models on character level with context information to correct OCR errors. The NMT models are based on the Transformer algorithm (Vaswani et al., 2017), whose detailed comparison is demonstrated in t"
2021.nodalida-main.24,L16-1152,0,0.0222648,"Missing"
2021.nodalida-main.24,P17-4012,0,0.0165156,"rm of that given word. As a result, for each given correct word, we have a set of similar correct words including the given one and a set of error words. From the two extracted groups, we do pairwise mapping to have one error word as training input and one correct word as the target output. Finally, the parallel data is converted into a character level format before feeding it to the NMT model for training. For example: j o l e e n → j o k e e n (“into a river"") pair has the first word is incorrect and the second one is the right form. We follow Hämäläinen and Hengchen (2019) and use OpenNMT (Klein et al., 2017) with default settings, i.e. bi-directional LSTM with global attention (Luong et al., 2015). We train for 10,000 steps and keep the last checkpoint as a baseline, which will be referred to as “NATAS"" in the remainder of this paper. 3.2 Methods In the following subsections we introduce a different method to create a parallel dataset and apply a new sequence to the sequence model to train the data. The baseline approach presented above might introduce noise when we are unable to confidently know that the error word is mapped cor5 https://fi.wiktionary.org/wiki/Wikisanakirja:Etusivu rectly to the"
2021.nodalida-main.24,L18-1352,0,0.025385,"ng parallel data that can be used in a character-level NMT model to conduct OCR post-correction. In short, our method requires only a corpus with OCRed text that we want to automatically correct, a word list, a morphological analyzer and any corpus of error free text. Since we focus on Finnish only, it is important to note that such resources exist for many endangered Uralic languages as well as they have extensive XML dictionaries and FSTs available (see (Hämäläinen and Rueter, 2018)) together with a growing number of Universal Dependencies (Nivre et al., 2016) treebanks such as Komi-Zyrian (Lim et al., 2018), Erzya (Rueter and Tyers, 2018), Komi-Permyak (Rueter et al., 2020) and North Sami (Sheyanova and Tyers, 2017). 3.1 Baseline We design the first experiment based on the previous work (Hämäläinen and Hengchen, 2019), who train a character-level NMT system. Their research indicates that there is a strong semantic relationship between the correct word to its erroneous forms and we can generate OCR error candidates using semantic similarity. To be able to train the NMT model, we need to extract the parallel data of correct words and their OCR errors. Accordingly, we trained the Word2Vec model (Mi"
2021.nodalida-main.24,D15-1166,0,0.0529055,"orrect words including the given one and a set of error words. From the two extracted groups, we do pairwise mapping to have one error word as training input and one correct word as the target output. Finally, the parallel data is converted into a character level format before feeding it to the NMT model for training. For example: j o l e e n → j o k e e n (“into a river"") pair has the first word is incorrect and the second one is the right form. We follow Hämäläinen and Hengchen (2019) and use OpenNMT (Klein et al., 2017) with default settings, i.e. bi-directional LSTM with global attention (Luong et al., 2015). We train for 10,000 steps and keep the last checkpoint as a baseline, which will be referred to as “NATAS"" in the remainder of this paper. 3.2 Methods In the following subsections we introduce a different method to create a parallel dataset and apply a new sequence to the sequence model to train the data. The baseline approach presented above might introduce noise when we are unable to confidently know that the error word is mapped cor5 https://fi.wiktionary.org/wiki/Wikisanakirja:Etusivu rectly to the given correct word, especially in the case of semantically similar words that have similar"
2021.nodalida-main.24,W19-0307,0,0.013016,"not unique to Finnish. There are several other languages in the world with rich morphologies and relatively poor support for both historical and modern NLP. Such is the case with most of the languages that are related to Finnish like Erzya, Sami and Komi, these Uralic languages are severely endangered but have valuable historical resources in books that are not yet available in a digital format. OCR remains a problem especially for endangered languages (Partanen, 2017), although OCR quality for such languages can be improved by limiting the domain in which the OCR models are trained and used (Partanen and Rießler, 2019). Automated OCR post-correction is usually modelled as a supervised machine learning problem where a model is trained with parallel data consisting of OCR erroneous text and manually corrected text. However, we want to develop a method that can be used even in contexts where no manually annotated data is available. The most viable recent method for such a task is the one presented by Hämäläinen and Hengchen (2019). However, their model works only on correcting individual words without considering the context in sentences, and as it focuses on English, it completely ignores the issues rising fr"
2021.nodalida-main.24,2020.iwclul-1.3,0,0.0146127,"to conduct OCR post-correction. In short, our method requires only a corpus with OCRed text that we want to automatically correct, a word list, a morphological analyzer and any corpus of error free text. Since we focus on Finnish only, it is important to note that such resources exist for many endangered Uralic languages as well as they have extensive XML dictionaries and FSTs available (see (Hämäläinen and Rueter, 2018)) together with a growing number of Universal Dependencies (Nivre et al., 2016) treebanks such as Komi-Zyrian (Lim et al., 2018), Erzya (Rueter and Tyers, 2018), Komi-Permyak (Rueter et al., 2020) and North Sami (Sheyanova and Tyers, 2017). 3.1 Baseline We design the first experiment based on the previous work (Hämäläinen and Hengchen, 2019), who train a character-level NMT system. Their research indicates that there is a strong semantic relationship between the correct word to its erroneous forms and we can generate OCR error candidates using semantic similarity. To be able to train the NMT model, we need to extract the parallel data of correct words and their OCR errors. Accordingly, we trained the Word2Vec model (Mikolov et al., 2013) on the Historical Newspaper of Finland from 1771"
2021.nodalida-main.24,W18-0210,0,0.0199642,"be used in a character-level NMT model to conduct OCR post-correction. In short, our method requires only a corpus with OCRed text that we want to automatically correct, a word list, a morphological analyzer and any corpus of error free text. Since we focus on Finnish only, it is important to note that such resources exist for many endangered Uralic languages as well as they have extensive XML dictionaries and FSTs available (see (Hämäläinen and Rueter, 2018)) together with a growing number of Universal Dependencies (Nivre et al., 2016) treebanks such as Komi-Zyrian (Lim et al., 2018), Erzya (Rueter and Tyers, 2018), Komi-Permyak (Rueter et al., 2020) and North Sami (Sheyanova and Tyers, 2017). 3.1 Baseline We design the first experiment based on the previous work (Hämäläinen and Hengchen, 2019), who train a character-level NMT system. Their research indicates that there is a strong semantic relationship between the correct word to its erroneous forms and we can generate OCR error candidates using semantic similarity. To be able to train the NMT model, we need to extract the parallel data of correct words and their OCR errors. Accordingly, we trained the Word2Vec model (Mikolov et al., 2013) on the Histo"
2021.nodalida-main.24,W17-0607,0,0.0272514,"ort, our method requires only a corpus with OCRed text that we want to automatically correct, a word list, a morphological analyzer and any corpus of error free text. Since we focus on Finnish only, it is important to note that such resources exist for many endangered Uralic languages as well as they have extensive XML dictionaries and FSTs available (see (Hämäläinen and Rueter, 2018)) together with a growing number of Universal Dependencies (Nivre et al., 2016) treebanks such as Komi-Zyrian (Lim et al., 2018), Erzya (Rueter and Tyers, 2018), Komi-Permyak (Rueter et al., 2020) and North Sami (Sheyanova and Tyers, 2017). 3.1 Baseline We design the first experiment based on the previous work (Hämäläinen and Hengchen, 2019), who train a character-level NMT system. Their research indicates that there is a strong semantic relationship between the correct word to its erroneous forms and we can generate OCR error candidates using semantic similarity. To be able to train the NMT model, we need to extract the parallel data of correct words and their OCR errors. Accordingly, we trained the Word2Vec model (Mikolov et al., 2013) on the Historical Newspaper of Finland from 1771 to 1929 using the ˇ uˇrek and Sojka, 2010)"
2021.wnut-1.3,W17-5802,0,0.0605016,"Missing"
2021.wnut-1.3,W18-0609,0,0.0232838,"Missing"
2021.wnut-1.3,N19-1423,0,0.188423,"e her every day at the bus stop in the morning. False เขามีเพียงรอยยิมประดับเลกนอยบนแกม He only has a slightly embellished smile on his cheeks. False Table 1: Example sentences from the dataset and their translations in English depressed nondepressed train 12837 valid 1712 test 2567 12240 1632 2448 4 Detecting depression In this section, we describe the four different models we use to automatically detect depression in our dataset. Following Hämäläinen et al. (2021), two of the models are based on LSTM (long short-term memory) models and two on transfer learning on pretrained BERT models (Devlin et al., 2019). We train our first model using a bidirectional LSTM based model (Hochreiter and Schmidhuber, 1997) using OpenNMT (Klein et al., 2017) with the default settings except for the encoder where we use a BRNN (bidirectional recurrent neural network) (Schuster and Paliwal, 1997) instead of the default RNN (recurrent neural network). We use the default of two layers for both the encoder and the decoder and the default attention model, which is the general global attention presented by Luong et al. (2015). The model is trained for the default 100,000 steps. The model is trained with tokenized sentenc"
2021.wnut-1.3,P17-4012,0,0.017395,"his cheeks. False Table 1: Example sentences from the dataset and their translations in English depressed nondepressed train 12837 valid 1712 test 2567 12240 1632 2448 4 Detecting depression In this section, we describe the four different models we use to automatically detect depression in our dataset. Following Hämäläinen et al. (2021), two of the models are based on LSTM (long short-term memory) models and two on transfer learning on pretrained BERT models (Devlin et al., 2019). We train our first model using a bidirectional LSTM based model (Hochreiter and Schmidhuber, 1997) using OpenNMT (Klein et al., 2017) with the default settings except for the encoder where we use a BRNN (bidirectional recurrent neural network) (Schuster and Paliwal, 1997) instead of the default RNN (recurrent neural network). We use the default of two layers for both the encoder and the decoder and the default attention model, which is the general global attention presented by Luong et al. (2015). The model is trained for the default 100,000 steps. The model is trained with tokenized sentences as its source and the depression label as its target. We train an additional LSTM model with the same configuration and the same ran"
2021.wnut-1.3,W18-0608,0,0.0659843,"Missing"
2021.wnut-1.3,Y18-1070,0,0.0742839,"Missing"
2021.wnut-1.3,D15-1166,0,0.108378,"Missing"
2021.wnut-1.3,W18-5903,0,0.0506008,"Missing"
D19-1617,P11-1020,0,0.0183863,"ems in the field of computational creativity, instead of trying to come up with an evaluation metric of our own, we opt for the evaluation method used to evaluate a previous Finnish poem generator. In practice, this means conducting a quantitative evaluation with human judges with the evaluation questions defined by Toivanen et al. (2012). An additional reasoning for using human evaluators instead of automated evaluation metrics is the poor correlation observed in a previous study (H¨am¨al¨ainen and Alnajjar, 2019) of automatic evaluation metrics such as BLEU (Papineni et al., 2002) and PINC (Chen and Dolan, 2011) scores with human judgments when evaluating creativity of a system. We run the genetic algorithm to produce a final population for 20 different initial poems for four different themes luonto (nature), perhe (family), lemmikki (pet) and ihminen (human). From each of the 20 final populations, we pick one poem at random. We shuffle the order of poems to reduce the priming effect of poems appearing always in a given order. We divide the 20 poems into two batches of 10 poems to reduce the effort of an individual evaluator. Each batch of 10 is then evaluated by 10 different human evaluators recruit"
D19-1617,D10-1051,0,0.0358384,"on its fitness function. An important aspect for creativity is that the system should be able to assess its own creations, a notion called appreciation (Colton, 2008) or aesthetic function (Colton et al., 2011) in the literature. The fitness Related work In the past, poetry generation has been studied both from the point of view of computational creativity and natural language generation. Poem generation has been tackled with a variety of different methods such as case-based reasoning (Gerv´as, 2001), templates (Colton et al., 2012), translation with WFSTs (weighted finitestate transducers) (Greene et al., 2010), text transformation via word embeddings (Bay et al., 2017) and conditional variational autoencoders (Li et al., 2018). As the field of poem generation has been broadly discussed by Oliveira (2017), we dedicate the rest of this section to describing the existing poetry generation work conducted for Finnish within the computational creativity paradigm. We also discuss some previous approaches using genetic algorithms. One of the first takes on Finnish poem generation is the P. O. Eticus system (Toivanen et al., 2012). P. O. Eticus uses a corpus of human authored poems. These poems are used as"
D19-1617,W18-6525,1,0.890724,"Missing"
D19-1617,W17-3502,0,0.0312952,"., 2011) in the literature. The fitness Related work In the past, poetry generation has been studied both from the point of view of computational creativity and natural language generation. Poem generation has been tackled with a variety of different methods such as case-based reasoning (Gerv´as, 2001), templates (Colton et al., 2012), translation with WFSTs (weighted finitestate transducers) (Greene et al., 2010), text transformation via word embeddings (Bay et al., 2017) and conditional variational autoencoders (Li et al., 2018). As the field of poem generation has been broadly discussed by Oliveira (2017), we dedicate the rest of this section to describing the existing poetry generation work conducted for Finnish within the computational creativity paradigm. We also discuss some previous approaches using genetic algorithms. One of the first takes on Finnish poem generation is the P. O. Eticus system (Toivanen et al., 2012). P. O. Eticus uses a corpus of human authored poems. These poems are used as templates for generating new poetry. In practice, the system takes a random poem from the corpus, conducts a morphological analysis on it and replaces some of the words in the existing poem. The rep"
D19-1617,W18-0205,1,0.893354,"Missing"
D19-1617,P02-1040,0,0.113005,"s one of the most difficult problems in the field of computational creativity, instead of trying to come up with an evaluation metric of our own, we opt for the evaluation method used to evaluate a previous Finnish poem generator. In practice, this means conducting a quantitative evaluation with human judges with the evaluation questions defined by Toivanen et al. (2012). An additional reasoning for using human evaluators instead of automated evaluation metrics is the poor correlation observed in a previous study (H¨am¨al¨ainen and Alnajjar, 2019) of automatic evaluation metrics such as BLEU (Papineni et al., 2002) and PINC (Chen and Dolan, 2011) scores with human judgments when evaluating creativity of a system. We run the genetic algorithm to produce a final population for 20 different initial poems for four different themes luonto (nature), perhe (family), lemmikki (pet) and ihminen (human). From each of the 20 final populations, we pick one poem at random. We shuffle the order of poems to reduce the priming effect of poems appearing always in a given order. We divide the 20 poems into two batches of 10 poems to reduce the effort of an individual evaluator. Each batch of 10 is then evaluated by 10 di"
D19-1617,D18-1423,0,0.0200474,"a notion called appreciation (Colton, 2008) or aesthetic function (Colton et al., 2011) in the literature. The fitness Related work In the past, poetry generation has been studied both from the point of view of computational creativity and natural language generation. Poem generation has been tackled with a variety of different methods such as case-based reasoning (Gerv´as, 2001), templates (Colton et al., 2012), translation with WFSTs (weighted finitestate transducers) (Greene et al., 2010), text transformation via word embeddings (Bay et al., 2017) and conditional variational autoencoders (Li et al., 2018). As the field of poem generation has been broadly discussed by Oliveira (2017), we dedicate the rest of this section to describing the existing poetry generation work conducted for Finnish within the computational creativity paradigm. We also discuss some previous approaches using genetic algorithms. One of the first takes on Finnish poem generation is the P. O. Eticus system (Toivanen et al., 2012). P. O. Eticus uses a corpus of human authored poems. These poems are used as templates for generating new poetry. In practice, the system takes a random poem from the corpus, conducts a morphologi"
D19-5519,W13-2711,0,0.0313767,"a from 23 distinct Finnish dialect varieties. The best functioning BRNN approach lowers the initial word error rate of the corpus from 52.89 to 5.73. 1 2 Related work Automated normalization has been tackled in the past many times especially in the case of historical text normalization. A recent meta-analysis on the topic (Bollmann, 2019) divides the contemporary approaches into five categories: substitution lists like VARD (Rayson et al., 2005) and Norma (Bollmann, 2012), rule-based methods (Baron and Rayson, 2008; Porta et al., 2013), edit distance based approaches (Hauser and Schulz, 2007; Amoia and Martinez, 2013), statistical methods and most recently neural methods. For statistical methods, the most prominent recent ones have been different statistical machine translation (SMT) based methods. These methods often assimilate the normalization process with a regular translation process by training an SMT model on a character level. Such methods have been used for historical text (Pettersson et al., 2013; H¨am¨al¨ainen et al., 2018) and contemporary dialect normalization (Samardzic et al., 2015). Recently, many normalization methods utilized neural machine translation (NMT) analogously to the previous SM"
D19-5519,N19-1389,0,0.0195388,"nnish. As dialect is the common way of communication for people online in Finnish, such a normalization is a necessary step to improve the accuracy of the existing Finnish NLP tools that are tailored for normative Finnish text. We work on a corpus consisting of dialectal data from 23 distinct Finnish dialect varieties. The best functioning BRNN approach lowers the initial word error rate of the corpus from 52.89 to 5.73. 1 2 Related work Automated normalization has been tackled in the past many times especially in the case of historical text normalization. A recent meta-analysis on the topic (Bollmann, 2019) divides the contemporary approaches into five categories: substitution lists like VARD (Rayson et al., 2005) and Norma (Bollmann, 2012), rule-based methods (Baron and Rayson, 2008; Porta et al., 2013), edit distance based approaches (Hauser and Schulz, 2007; Amoia and Martinez, 2013), statistical methods and most recently neural methods. For statistical methods, the most prominent recent ones have been different statistical machine translation (SMT) based methods. These methods often assimilate the normalization process with a regular translation process by training an SMT model on a characte"
D19-5519,C16-1013,0,0.0211937,"ent recent ones have been different statistical machine translation (SMT) based methods. These methods often assimilate the normalization process with a regular translation process by training an SMT model on a character level. Such methods have been used for historical text (Pettersson et al., 2013; H¨am¨al¨ainen et al., 2018) and contemporary dialect normalization (Samardzic et al., 2015). Recently, many normalization methods utilized neural machine translation (NMT) analogously to the previous SMT based approaches on a character level due to its considerable ability in addressing the task. Bollmann and Søgaard (2016) have used a bidirectional long short-term memory (bi-LSTM) deep neural network to normalize historical German on a character level. The authors have also tested the efficiency of the model Introduction Normalization is one of the possible preprocessing steps that can be applied to various text types in order to increase their compatibility with tools designed for the standard language. This approach can be taken in an essentially similar manner with dialectal texts, historical texts or colloquial written genres, and can be beneficial also as one processing step with many types of spoken langu"
D19-5519,W17-4404,0,0.0690667,"Missing"
D19-5519,R19-1051,1,0.828041,"Missing"
D19-5519,W18-4510,1,0.811202,"Missing"
D19-5519,W19-2509,1,0.873997,"Missing"
D19-5519,W17-4412,0,0.0613142,"Missing"
D19-5519,P17-4012,0,0.0198466,"ngs in the same municipalities that were the targets of earlier recording activity. 4 Dialect normalization Our approach consists of a character level NMT model that learns to translate the dialectal Finnish to normative spelling. We experiment with two different model types, one being an LSTM based BRNN (bi-directional recurrent neural network) approach as taken by many in the past, and the 1 142 http://urn.fi/urn:nbn:fi:lb-201407141 other is a transformer model as it has been reported to outperform LSTMs in many other sequence-tosequence tasks. For the BRNN model, we use mainly the OpenNMT (Klein et al., 2017) defaults. This means that there are two layers both in the encoder and the decoder and the attention model is the general global attention presented by Luong et al. (2015). The transformer model is that of Vaswani et al. (2017). Both models are trained for the default 100,000 training steps. We experiment with three different ways of training the models. We train a set of models on a word level normalization, which means that the source and target consist of single words split into characters by white spaces. In order to make the models more aware of the context, we also train a set of models"
D19-5519,D15-1166,0,0.057397,"to translate the dialectal Finnish to normative spelling. We experiment with two different model types, one being an LSTM based BRNN (bi-directional recurrent neural network) approach as taken by many in the past, and the 1 142 http://urn.fi/urn:nbn:fi:lb-201407141 other is a transformer model as it has been reported to outperform LSTMs in many other sequence-tosequence tasks. For the BRNN model, we use mainly the OpenNMT (Klein et al., 2017) defaults. This means that there are two layers both in the encoder and the decoder and the attention model is the general global attention presented by Luong et al. (2015). The transformer model is that of Vaswani et al. (2017). Both models are trained for the default 100,000 training steps. We experiment with three different ways of training the models. We train a set of models on a word level normalization, which means that the source and target consist of single words split into characters by white spaces. In order to make the models more aware of the context, we also train a set of models on chunked data. This means that we train the models by feeding in 3 words at a time; the words are split into characters and the word boundaries are indicated with an und"
D19-5519,W18-6107,0,0.0605429,"Missing"
L18-1138,W09-4604,0,0.0361138,"Missing"
L18-1138,P10-1023,0,0.0334565,"resources and see if reducing the term data can be compensated by more exact structure and content. Hovy’s approach (Hovy, 1998) is focused on describing the use and results of semi-automated cross-ontology concept. The goal is to create ontologies which are based in largescale machine translations. The focus is in combining the ontologies in order to create a practical large-scale ontology for free use in the web. The primary stress lies in combining and standardizing these ontologies. The main use for these ontologies is in machine translation but they can be used in other purposes as well. Navigli and Ponzetto (2010) are presenting a multilingual semantic network, BabelNet, with the aim to produce a lexical resource with high accuracy. By the automatic mapping between BabelNet’s two resources, the English Wikipedia and WordNet, they have provided an automatic construction in order to create a large multilingual lexicon. Their aim is to present a new methodology for the automatic construction of a multilingual lexical knowledge resource of this art. The project is based on combining the lexicographic and encyclopedic knowledge. Navigli and Ponzetto have unified the word senses as concepts and semantic poin"
L18-1138,W17-0601,1,0.830855,"Uralic languages in the Giellatekno infrastructure1 for the past decade in the form of dictionaries, morphological analyzers, constraint grammars and rule-based machine translation tools among others. This paper builds upon the manually crafted bilingual dictionaries in the Giellatekno infrastructure and proposes an automatized way of combining semantic and translation knowledge from these dictionaries. This method will expand the existing language resources by providing completely new translations and language pairs. Later on, this work will be incorporated in the Sanat2 MediaWiki platform (Rueter & Hämäläinen, 2017), which is used to crowdsource the future development of the Giellatekno language resources. 2. Related Work Standardizing bilingual or multilingual dictionaries through combining entries from different corpora and sources, such as WordNet (Miller, 1995), in order to build well-structured dictionaries for machine translation and other uses has become a central source of interest over the past decades. A great many past studies, however have focused on majority languages. The aim of (Klavans & Tzoukermann, 1990) is to focus on the methods that combine structured but incomplete or only partially"
L18-1138,W09-0415,0,0.0254142,"fied the word senses as concepts and semantic pointers between synsets as relations from the WordNet with all the encyclopedic entries, such as individual pages, as concepts from Wikipedia. The semantically unspecified relations in Wikipedia are collected from hyperlinked texts. These two resources give lexical knowledge of different type, from which one is concentrated on the named entities and the other on concepts. Linking the two knowledge resources and the use of two different resources has displayed that it will provide large-scale lexical resources which work as the basis for BabelNet. Wehrli et al. (2009) present the MulTra (Multilingual Translation) project. The aim of the MulTra project is to develop an efficient grammar based translation model which is able to cover several different languages. The project is also based on object-oriented software design. The basis for this grammatically oriented approach is abstract and generic linguistic, which is based for example on Noam Chomsky’s generic grammar. The aim of the research is to grow the amount of language pairs and develop them but also to reduce the development costs. First, the project is concentrated to five large European languages ("
R19-1051,P17-4012,0,0.0426037,". In addition, we use the frequencies from the British National Corpus (The BNC Consortium, 2007) to produce one more dataset of words occurring in the BNC over 1000 times to test whether the results can be improved with frequencies obtained from a non-noisy corpus. This BNC dataset is also used to produce multiple datasets based on the length of the word. The sizes of these automatically extracted parallel datasets are shown in Table 1. 3.2 The NMT Model We use the automatically extracted parallel datasets to train a character level NMT model for each dataset. For this task, we use OpenNMT8 (Klein et al., 2017) with the default parameters except for the encoder where we use a BRNN (bi-directional recurrent neural network) instead of the default RNN (recurrent neural network) as BRNN has been shown to provide a performance gain in character-level text normalization (Hämäläinen et al., 2019). We use the default of two layers for both the encoder and the decoder and the default attention model, which is the general global attention presented by Luong et al. (2015). The models are trained for the default number of 100,000 training steps with the We use the extraction algorithm to extract the parallel da"
R19-1051,W17-0504,0,0.0187089,"roblem of text normalization, which means converting text written in a non-standard form of a language to the standard form in order to facilitate its processing with existing NLP tools. SMT (statistical machine translation) has been used previously, for instance, to normalize historical text (Pettersson et al., 2013) to modern language and to normalize modern Swiss German dialects (Samardzic et al., 2015) into a unified language form. More recently with the rise of the NMT, research has emerged in using NMT to normalize non-standard text, for example work on normalization of medieval German (Korchagina, 2017) and on historical English (Hämäläinen et al., 2018). All of the normalization work cited above on using machine translation for normalization has been based on character-level machine translation. This means that words are split into characters and the translation model will learn to translate from character to character instead of word to word. 3 parallel data from our corpus containing OCR errors, then we will present the model designed to carry out the actual error correction. 3.1 To extract a parallel corpus of OCR errors and their correctly spelled counterparts out of our corpus, we use"
R19-1051,P18-1220,0,0.120813,"is a keyed subset of ECCO, compiled with the support of 35 libraries and made up of 2,231 documents”. (Hill and Hengchen, 2019) 3 Our code https://github.com/mikahama/natas 431 Proceedings of Recent Advances in Natural Language Processing, pages 431–436, Varna, Bulgaria, Sep 2–4, 2019. https://doi.org/10.26615/978-954-452-056-4_051 pean Commission-funded IMPACT project4 gathers 26 national libraries and commercial providers to “take away the barriers that stand in the way of the mass digitization of the European cultural heritage” by improving OCR technology and advocating for best practices. Dong and Smith (2018) present an unsupervised method for OCR post-correction. As opposed to our character-level approach, they use a word-level sequence-to-sequence approach. As such a model requires training data, they gather the data automatically by using repeated texts. This means aligning the OCRed text automatically with matched variants of the same text from other corpora or within the OCRed text itself. In contrast, our unsupervised approach does not require any repetition of text, but rather repetition of individual words. Different machine translation approaches have been used in the past to solve the si"
R19-1051,D15-1166,0,0.106678,"We use the automatically extracted parallel datasets to train a character level NMT model for each dataset. For this task, we use OpenNMT8 (Klein et al., 2017) with the default parameters except for the encoder where we use a BRNN (bi-directional recurrent neural network) instead of the default RNN (recurrent neural network) as BRNN has been shown to provide a performance gain in character-level text normalization (Hämäläinen et al., 2019). We use the default of two layers for both the encoder and the decoder and the default attention model, which is the general global attention presented by Luong et al. (2015). The models are trained for the default number of 100,000 training steps with the We use the extraction algorithm to extract the parallel data by using several different word lists. First, we list all the words in the vocabulary of the 7 &gt;=2 28910 Table 1: Sizes of the extracted parallel datasets Algorithm 1: Extraction of parallel data Draw words w from the input word list; for w do Draw synonyms sw in the word embedding model for synonym sw do if sw is correctly spelled then Add sw to correct forms f ormsc end else Add sw to error forms f ormse end end for error e in f ormse do group e with"
R19-1051,W17-0209,0,0.139685,"ersion, ECCOTCP,2 to compare the output of different common DH methods such as authorship attribution, countbased vector space models, and topic modelling, 2 Related Work OCR quality for historical texts has recently received a lot of attention from funding bodies and data providers. Indeed, Smith and Cordell (2019) present a (USA-focused) technical report on OCR quality, and aim to spearhead the efforts on setting a research agenda for tackling OCR problems. Other initiatives such as Adesam et al. (2019) set out to analyse the quality of OCR produced by the Swedish language bank Språkbanken, Drobac et al. (2017) correct the OCR of Finnish newspapers using weighted finite-state methods, Tanner et al. (2009) measure mass digitisation in the context of British newspaper archives, while the Euro1 Eighteenth Century Collections Online (ECCO) is a dataset which “contains over 180,000 titles (200,000 volumes) and more than 32 million pages”, according to its copyright holder Gale: https://www.gale.com/primary-sources/ eighteenth-century-collections-online. 2 ECCO-TCP (Text Creation Partnership) “is a keyed subset of ECCO, compiled with the support of 35 libraries and made up of 2,231 documents”. (Hill and H"
R19-1051,L18-1113,0,0.120726,"ven in scenarios with less NLP resources than what English has. Although not a requirement, having the additional information about word frequencies from another OCR error-free corpus can boost the results. A limitation of our approach is that it cannot do word segmentation in the case where multiple words have been merged together as a result of the OCR process. However, this problem is complex enough on its own right to deserve an entire publication of its own and is thus not in the scope of our paper. Indeed, previous research has been conducted focusing solely on the segmentation problem (Nastase and Hitschler, 2018; Soni et al., 2019) of historical text and in the future such methods can be incorporated as a preprocessing step for our proposed method. It is in the interest of the authors to extend the approach presented in this paper on historical data written in Finnish and in Swedish in the immediate near future. The source code and the best working NMT model discussed in this paper has be made freely available on GitHub as a part of the natas Python library9 . Evaluation For evaluation, we prepare by hand a gold standard containing 200 words with OCR errors from the ECCO and their correct spelling. T"
R19-1051,W18-4510,1,0.836338,"verting text written in a non-standard form of a language to the standard form in order to facilitate its processing with existing NLP tools. SMT (statistical machine translation) has been used previously, for instance, to normalize historical text (Pettersson et al., 2013) to modern language and to normalize modern Swiss German dialects (Samardzic et al., 2015) into a unified language form. More recently with the rise of the NMT, research has emerged in using NMT to normalize non-standard text, for example work on normalization of medieval German (Korchagina, 2017) and on historical English (Hämäläinen et al., 2018). All of the normalization work cited above on using machine translation for normalization has been based on character-level machine translation. This means that words are split into characters and the translation model will learn to translate from character to character instead of word to word. 3 parallel data from our corpus containing OCR errors, then we will present the model designed to carry out the actual error correction. 3.1 To extract a parallel corpus of OCR errors and their correctly spelled counterparts out of our corpus, we use a simple procedure consisting of measuring the simil"
R19-1051,W19-2509,1,0.825617,"aset is also used to produce multiple datasets based on the length of the word. The sizes of these automatically extracted parallel datasets are shown in Table 1. 3.2 The NMT Model We use the automatically extracted parallel datasets to train a character level NMT model for each dataset. For this task, we use OpenNMT8 (Klein et al., 2017) with the default parameters except for the encoder where we use a BRNN (bi-directional recurrent neural network) instead of the default RNN (recurrent neural network) as BRNN has been shown to provide a performance gain in character-level text normalization (Hämäläinen et al., 2019). We use the default of two layers for both the encoder and the decoder and the default attention model, which is the general global attention presented by Luong et al. (2015). The models are trained for the default number of 100,000 training steps with the We use the extraction algorithm to extract the parallel data by using several different word lists. First, we list all the words in the vocabulary of the 7 &gt;=2 28910 Table 1: Sizes of the extracted parallel datasets Algorithm 1: Extraction of parallel data Draw words w from the input word list; for w do Draw synonyms sw in the word embeddin"
R19-1051,W19-2513,0,0.130905,"P resources than what English has. Although not a requirement, having the additional information about word frequencies from another OCR error-free corpus can boost the results. A limitation of our approach is that it cannot do word segmentation in the case where multiple words have been merged together as a result of the OCR process. However, this problem is complex enough on its own right to deserve an entire publication of its own and is thus not in the scope of our paper. Indeed, previous research has been conducted focusing solely on the segmentation problem (Nastase and Hitschler, 2018; Soni et al., 2019) of historical text and in the future such methods can be incorporated as a preprocessing step for our proposed method. It is in the interest of the authors to extend the approach presented in this paper on historical data written in Finnish and in Swedish in the immediate near future. The source code and the best working NMT model discussed in this paper has be made freely available on GitHub as a part of the natas Python library9 . Evaluation For evaluation, we prepare by hand a gold standard containing 200 words with OCR errors from the ECCO and their correct spelling. The performance of ou"
W18-0205,W94-0319,0,0.668132,"titutes. Another take on generating Finnish poetry in a human-computer co-creativity setting (Kantosalo et al., 2015) was to use sentences extracted from the Project Gutenberg’s children’s literature in Finnish. These sentences were treated as ”poetry fragments” and they were used to generate poems by combining them together in a randomized fashion. This method indeed gives syntactically better results than the one described in (Toivanen et al., 2012), as it puts human-written sentences together, but it doesn’t allow any variation in the poem apart from the order of the sentences in the poem. Reiter (1994) identifies four different steps in an NLG pipeline. Those are content determination, sentence planning, surface generation, and morphology and formatting. In the content determination step, an input is given to the NLG system, e.g. in the form of a query to obtain desired information from the system. Based on this query, a semantic representation is produced addressing the results to the query. In other words, this step decides what information is to be conveyed to the user in the final output sentence, but also how it will be communicated in the rhetorical planning of the sentence. The sente"
W18-4510,W13-2711,0,0.222638,"work and MorphAdorner does not provide enough coverage for our data. This work is licensed under a Creative Commons Attribution 4.0 International Licence. http://creativecommons.org/licenses/by/4.0/. Licence details: 87 Proceedings of Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature, pages 87–96 Santa Fe, New Mexico, USA, August 25, 2018. Using a string similarity metric such as edit distance has been used in the past for normalization. An example of such is the automatically produced diachronic dictionary of spelling variants for German (Amoia and Martinez, 2013). In building the dictionary, the authors used Levenshtein edit distance to cluster similar words together with their modern counterparts. This was facilitated by the fact that they were dealing with recipes, which thanks to their limited vocabulary, are easy to cluster. In addition, words can be clustered based on their semantics by looking at the shared contexts of the words. Statistical machine translation models have also been used in solving the task by training a character based translation model using known historical spellings and their modern variants as training data. In (Samardzic e"
W18-4510,C16-1013,0,0.130993,"In addition, words can be clustered based on their semantics by looking at the shared contexts of the words. Statistical machine translation models have also been used in solving the task by training a character based translation model using known historical spellings and their modern variants as training data. In (Samardzic et al., 2015) such a model was trained for normalizing Swiss German dialects to a standard variant. A similar SMT based approach has also been used in the context of historical text in (Pettersson et al., 2013). Normalization has also been done by using deep learning. In (Bollmann and Søgaard, 2016), normalization is presented as a character-based sequence labeling task for bi-directional LSTMs. In their method a historical character does not need to be aligned with a single modern spelling character but can be aligned with a compound of characters in the training data. 3 The Corpus and Data Sources The primary corpus we use is the CEEC (Nevalainen et al., 1998 2006). Compiled for the purposes of historical sociolinguistics, it is a corpus of personal correspondence in English representing a time span from the 15th to the 19th century. The letters have been selected from published origin"
W18-4510,P13-2121,0,0.0182096,"er to make the SMT tool, Moses (Koehn et al., 2007), treat individual characters of a word as though they were words of a sentence. The parallel non-normalized to normalized word lists are aligned with GIZA++ (Och and Ney, 2003) as part of the machine translation process. An SMT based system also requires a language model. Without it, the system would be more likely to produce non-words as output. As a language model, we use the list of words extracted from the BNC. Again, these words are split into characters by whitespaces. We build a 10-gram language model based on the BNC data with KenLM (Heafield et al., 2013) and use this model with Moses3 . For tuning the model, we take a random sample of 2000 non-normalized and normalized word pairs from our parallel data set and run the tuning on that. We also tune century specific models with 2000 words from the era for the 15th and the 18th century to compare whether tuning for a given century yields better results for that century than a more generally tuned model. 4.4 Neural Machine Translation (NMT) Neural machine translation can be used for normalization in a similar fashion to the SMT approach. We use OpenNMT (Klein et al., 2017) to train against a chara"
W18-4510,P17-4012,0,0.0454911,"BNC data with KenLM (Heafield et al., 2013) and use this model with Moses3 . For tuning the model, we take a random sample of 2000 non-normalized and normalized word pairs from our parallel data set and run the tuning on that. We also tune century specific models with 2000 words from the era for the 15th and the 18th century to compare whether tuning for a given century yields better results for that century than a more generally tuned model. 4.4 Neural Machine Translation (NMT) Neural machine translation can be used for normalization in a similar fashion to the SMT approach. We use OpenNMT (Klein et al., 2017) to train against a character based machine translation model by using the parallel data extracted earlier. For validation of the model, we use the same 2000 word parallel list as we did for the general SMT model. For NMT, we train two different models for 13 epochs. The first model gets the same input as SMT, i.e. a parallel list of word forms. The second model has a specific input for the centuries in which certain non-normalized forms were used together with the actual word forms. This is done simply by appending the year of the century before each historical form in the data set. For some"
W18-4510,P07-2045,0,0.00747958,"orthography and pronunciation are not always clearly connected, we use Soundex2 with the size of 6 to produce an estimated pronunciation. 4.3 Statistical Machine Translation (SMT) Previous research has shown that SMT is a viable form of solving the problem of normalization. This is why we have decided to include an SMT based approach as a module in our system. We train a character based SMT model using the parallel data extracted earlier from the OED, MED and known normalizations in the CEEC. All the words are split into letters separated by a whitespace in order to make the SMT tool, Moses (Koehn et al., 2007), treat individual characters of a word as though they were words of a sentence. The parallel non-normalized to normalized word lists are aligned with GIZA++ (Och and Ney, 2003) as part of the machine translation process. An SMT based system also requires a language model. Without it, the system would be more likely to produce non-words as output. As a language model, we use the list of words extracted from the BNC. Again, these words are split into characters by whitespaces. We build a 10-gram language model based on the BNC data with KenLM (Heafield et al., 2013) and use this model with Mose"
W18-4510,J03-1002,0,0.024092,"T) Previous research has shown that SMT is a viable form of solving the problem of normalization. This is why we have decided to include an SMT based approach as a module in our system. We train a character based SMT model using the parallel data extracted earlier from the OED, MED and known normalizations in the CEEC. All the words are split into letters separated by a whitespace in order to make the SMT tool, Moses (Koehn et al., 2007), treat individual characters of a word as though they were words of a sentence. The parallel non-normalized to normalized word lists are aligned with GIZA++ (Och and Ney, 2003) as part of the machine translation process. An SMT based system also requires a language model. Without it, the system would be more likely to produce non-words as output. As a language model, we use the list of words extracted from the BNC. Again, these words are split into characters by whitespaces. We build a 10-gram language model based on the BNC data with KenLM (Heafield et al., 2013) and use this model with Moses3 . For tuning the model, we take a random sample of 2000 non-normalized and normalized word pairs from our parallel data set and run the tuning on that. We also tune century s"
W18-6525,W18-0205,1,0.610008,"Missing"
W18-6534,W17-3542,0,0.0608666,"Missing"
W18-6534,P17-4012,0,0.0382474,"Missing"
W18-6534,W16-3511,0,0.0645503,"Missing"
W18-6534,P13-2044,0,0.0257201,"t for appreciation is an automated assessment of the humorousness of the output. Two key components have been identified for humorousness in jokes: surprise and coherence (Brownell et al., 1983). When the brain makes sense of the stimuli it tem suggests funny replacement words for familiar expressions such as proverbs. The replacements are found by applying a phonetic similarity metric together with a Latent semantic analysis (LSA) based semantic similarity metric, which not only gives semantically related words but also semantically opposed ones. A fully automated pun generator, presented in Valitutti et al. (2013), takes an English sentence as its input and changes one word in it based on three criteria: sound or spelling similarity, the replacement word has to be a taboo and that the word has to go well together with its immediate predecessor in the sentence. The system operates with a predefined set of taboo words and an n-gram model to assess how well the new words fit in the sentence. A more recent take on the pun generation is that of Shah et al. (2016), which presents a template based approach on humor generation. The templates are filled by using WordNet relations for the input compound word. Th"
W19-2509,W18-4510,1,0.565181,"Missing"
W19-2509,P17-4012,0,0.0455607,"rent gold standards. At first, we change one parameter at a time and compare the results to the default settings. We try two different encoder types, bi-directional recurrent neural networks (BRNNs) and mean, which is an encoder applying mean pooling. BRNN uses two independent encoders to encode the sequence reversed and without reversal. The default RNN, in contrast, only encodes the sequence normally without reversing it. In addition to the default attention model, we also try out the MLP (multi-layer perceptron) model proposed by Bahdanau et al. (2014). We The NMT Approach We use OpenNMT1 (Klein et al., 2017) to train the NMT models discussed in this paper. The models are trained on a character level. This means that the model is supplied with parallel lists of historical spellings and their modern counterparts, where the words have been split into individual characters separated by white spaces. The training is done for pairs of words, i.e. the normalization is to be conducted without a context. The NMT model would then treat individual characters as though they were words in a sentence and ”translate” them into the corresponding modernized spelling. 1 The Parallel Data Version 0.2.1 of opennmt-p"
W19-2509,W17-0504,0,0.103387,"alignment of the parallel data on both word and character level. SMT has also been used in normalization of contemporary dialectal language to the standardized normative form (Samardzic et al., 2015). They test normalization with word-by-word trans71 Proc. of the 3rd Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature, pp. 71–75 c Minneapolis, MN, USA, June 7, 2019. 2019 Association for Computational Linguistics 4.1 lation and character level SMT. The character level SMT improves the normalization of unseen and ambiguous words. Korchagina (2017) proposes an NMT based normalization for medieval German. It is supposedly one of the first attempts to use NMT for historical normalization. The study reports NMT outperforming the existing rule-based and SMT methods. A recent study by Tang et al. (2018) compared different NMT models for historical text normalization in five different languages. They report that NMT outperforms SMT in four of the five languages. In terms of performance, vanilla RNNs are comparable to LSTMs and GRUs, and also the difference between attention and no attention is small. 3 We use different sources of historical-m"
W19-2509,C18-1112,0,0.0229732,"oc. of the 3rd Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature, pp. 71–75 c Minneapolis, MN, USA, June 7, 2019. 2019 Association for Computational Linguistics 4.1 lation and character level SMT. The character level SMT improves the normalization of unseen and ambiguous words. Korchagina (2017) proposes an NMT based normalization for medieval German. It is supposedly one of the first attempts to use NMT for historical normalization. The study reports NMT outperforming the existing rule-based and SMT methods. A recent study by Tang et al. (2018) compared different NMT models for historical text normalization in five different languages. They report that NMT outperforms SMT in four of the five languages. In terms of performance, vanilla RNNs are comparable to LSTMs and GRUs, and also the difference between attention and no attention is small. 3 We use different sources of historical-modern English parallel data. These include the normalized words from the CEEC, the historical forms provided in the OED and the historical lemmas in the Middle English Dictionary (MED, n.d.) that have been linked to the OED lemmas with modern spelling. Th"
W19-4105,W18-6534,1,0.883906,"Missing"
W19-6006,P14-2017,0,0.286325,"he single most accurate method in normalization by a recent study with historical English (Hämäläinen et al., 2018). In this paper, we use NMT in a similar character level fashion for finding cognates. Furthermore, due to the limited availability of training data, we present an SMT (statistical machine translation) method for generating more data to boost the performance of the NMT model. 2 Related Work Automatic identification of cognates has received a fair share of interest in the past from different methodological stand points. In this section, we will go through some of these approaches. Ciobanu and Dinu (2014) propose a method based on orthographic alignment. This means a character level alignment of cognate pairs. After the alignment, the mismatches around the aligned pairs are used as features for the machine learning algorithm. Another take on cognate detection is that of Rama (2016). This approach employs Siamese convolutional networks to learn phoneme level representation and language relatedness of words. They based the study on Swadesh lists and used hand-written phonetic features and 1-hot encoding for the phonetic representation. Cognate detection has also been done by looking at features"
W19-6006,W18-4510,1,0.7264,"odel can learn the cognate features between North Sami and Skolt Sami more specifically. We assimilate this problem with that of normalization of historical spelling variants. On a higher level, historical variation within one language can be seen as discovering cognates of different temporal forms of the language. Therefore, we want to take the work done in that vein for the first time in the context of cognate detection. Using NMT (neural machine translation) on a character level has been shown to be the single most accurate method in normalization by a recent study with historical English (Hämäläinen et al., 2018). In this paper, we use NMT in a similar character level fashion for finding cognates. Furthermore, due to the limited availability of training data, we present an SMT (statistical machine translation) method for generating more data to boost the performance of the NMT model. 2 Related Work Automatic identification of cognates has received a fair share of interest in the past from different methodological stand points. In this section, we will go through some of these approaches. Ciobanu and Dinu (2014) propose a method based on orthographic alignment. This means a character level alignment of"
W19-6006,P13-2121,0,0.0247322,"del to the opposite direction of the NMT model with the same parallel data. This means translating from North Sami to Skolt Sami. We use the same parallel data as for the NMT model, meaning that on the source side, we have North Sami and on the target side we have all the possible cognates in other languages. The parallel data is aligned with GIZA++ (Och and Ney, 2003). Since we are training an SMT model, there are two ways we can make the noisy target of all the other languages resemble more Skolt Sami. One is by using a language model. For this, we build a 10-gram language model with KenLM (Heafield et al., 2013) from Skolt Sami words recorded in the Giellatekno dictionaries. The other way of making the model more aware of Skolt Sami in particular is to tune the SMT model after the initial training. For the tuning, we use the Skolt Sami-North Sami parallel data exclusively so that the SMT model will go more towards Skolt Sami when producing cognates. We use the SMT model to translate all of the words extracted from the North Sami dictionary into Skolt Sami. This results in a parallel dataset of real, existing North Sami words and words that resemble Skolt Sami. We then use this data to continue the tr"
W19-6006,P17-4012,0,0.0426407,"base. This produces a parallel dataset of North Sami words and their cognates in other languages. The North Sami to other languages parallel dataset consists of 32905 parallel words, of which 2633 items represent the correlations between North Sami and Skolt Sami. We find cognates for nouns, adjectives, verbs and adverbs recorded in the Giellatekno dictionaries (Moshagen et al., 2013) for North Sami and Skolt Sami. These dictionaries serve as an input for the trained NMT model and for filtering the output produced by the model. 3.2 The NMT Model For the purpose of our research we use OpenNMT (Klein et al., 2017) to train a character based NMT model that will take a Skolt Sami word as its input and produce a potential North Sami cognate as its output. We use the default settings for OpenNMT1 . We train a sequence to sequence model with the list of known cognates in other languages as the source data and their North Sami counterparts as the target data. In this way, the system learns a good representation of the target language, North Sami, and can learn what kind of changes are possible between cognates in general. Thus, the model can learn additional information about cognates that would not be prese"
W19-6006,W13-5631,0,0.0190059,"Our training data consists of Álgu (Kotus, 2006), which is an etymological database of the Sami languages. From this database, we use all the cognate relations recorded for North Sami to all the other Finno-Ugric languages in the database. This produces a parallel dataset of North Sami words and their cognates in other languages. The North Sami to other languages parallel dataset consists of 32905 parallel words, of which 2633 items represent the correlations between North Sami and Skolt Sami. We find cognates for nouns, adjectives, verbs and adverbs recorded in the Giellatekno dictionaries (Moshagen et al., 2013) for North Sami and Skolt Sami. These dictionaries serve as an input for the trained NMT model and for filtering the output produced by the model. 3.2 The NMT Model For the purpose of our research we use OpenNMT (Klein et al., 2017) to train a character based NMT model that will take a Skolt Sami word as its input and produce a potential North Sami cognate as its output. We use the default settings for OpenNMT1 . We train a sequence to sequence model with the list of known cognates in other languages as the source data and their North Sami counterparts as the target data. In this way, the syst"
W19-6006,J03-1002,0,0.02225,"of NMT to train a model that will produce plausible but slightly irregular Skolt Sami cognates for the word list of North Sami words obtained from the Giellatekno dictionaries. We use Moses (Koehn et al., 2007) baseline2 to train a translation model to the opposite direction of the NMT model with the same parallel data. This means translating from North Sami to Skolt Sami. We use the same parallel data as for the NMT model, meaning that on the source side, we have North Sami and on the target side we have all the possible cognates in other languages. The parallel data is aligned with GIZA++ (Och and Ney, 2003). Since we are training an SMT model, there are two ways we can make the noisy target of all the other languages resemble more Skolt Sami. One is by using a language model. For this, we build a 10-gram language model with KenLM (Heafield et al., 2013) from Skolt Sami words recorded in the Giellatekno dictionaries. The other way of making the model more aware of Skolt Sami in particular is to tune the SMT model after the initial training. For the tuning, we use the Skolt Sami-North Sami parallel data exclusively so that the SMT model will go more towards Skolt Sami when producing cognates. We u"
W19-6006,N10-1135,0,0.0145162,"de insight for second syllable vowel quality, as not all SamicMordvin vocabulary is attested in Balto-Finnic (cf. Korhonen, 1981). The Sami languages themselves (there are seven written languages) also exhibit regular sound correspondence, even though cognates, at times, may be opaque to the layman. One token of cognate relation studies is the Álgu database (Kotus, 2006), which contains a set of inter-Sami cognates. Cognates have applicability in NLP research for low-resource languages as they can, for instance, be used to induce the predicate-argument structures from bilingual vector spaces (Peirsman and Padó, 2010). Jack Rueter Department of Digital Humanities University of Helsinki jack.rueter@helsinki.fi The main motivation for this work is to extend the known cognate information available in the Online Dictionary of Uralic Languages (Hämäläinen and Rueter, 2018). This dictionary, at its current stage, only has cognate relations recorded in the Álgu database. Dealing with true cognates in a non-attested hypothetical proto-language presupposes adherence to a set of sound correlations posited by a given school of thought. Since Proto-Samic is one such language, we have taken liberties to interpret the t"
W19-6006,C16-1097,0,0.219291,"l machine translation) method for generating more data to boost the performance of the NMT model. 2 Related Work Automatic identification of cognates has received a fair share of interest in the past from different methodological stand points. In this section, we will go through some of these approaches. Ciobanu and Dinu (2014) propose a method based on orthographic alignment. This means a character level alignment of cognate pairs. After the alignment, the mismatches around the aligned pairs are used as features for the machine learning algorithm. Another take on cognate detection is that of Rama (2016). This approach employs Siamese convolutional networks to learn phoneme level representation and language relatedness of words. They based the study on Swadesh lists and used hand-written phonetic features and 1-hot encoding for the phonetic representation. Cognate detection has also been done by looking at features such as semantics, phonetics and regular sound correspondences (St. Arnaud et al., 2017). Their approach implements a general model and language specific models using support vector machine (SVM). Rama et al. (2017) present an unsupervised method for cognate identification. The met"
W19-6006,P16-1009,0,0.115666,"Missing"
W19-6006,D17-1267,0,0.217499,"Missing"
W19-6139,W18-6015,0,0.0697469,"in a sentence and apply their rules to remove the non-possible readings. In some cases, a CG disambiguator might produce a fully disambiguated sentence, however these models are often unable to resolve all morphological ambiguity. In this paper, we use the UD Treebanks for our languages of interest. For Finnish, we use Turku Dependency Treebank (Haverinen et al., 2014) with 202K tokens (14K sentences). The Northern Sami Treebank (Sheyanova and Tyers, 2017) is the largest one for the endangered languages with 26K tokens (3K sentences). For Komi-Zyrian, we use the Komi-Zyrian Lattice Treebank (Partanen et al., 2018) of 2K tokens (189 sentences) representing the standard written Komi. The Erzya Treebank (Rueter and Tyers, 2018) is the second largest endangered language one we use in our research with 15k tokens (1,500 sentences). 5 Sentence Representation We represent each word as a non-empty set of morphological tags. This representation does not contain the word form itself nor its lemma, as we aim for a more abstract level morphological representation. This representation is meant to capture the possible morphologies following each other in a sentence to learn morphosyntactic inter-dependencies such as"
W19-6139,L18-1138,1,0.856149,"Missing"
W19-6139,L18-1352,0,0.114068,"urce language based on the morphological tags of the high-resource language sentences in the training data. A limitation of this approach is the morphological relatedness of the high-resource and low-resource languages. A method for POS tagging of low-resource languages has been proposed by Andrews et al. (2017). They use a bi-lingual dictionary between a low and high-resource language together with monolingual data to build cross-lingual word embeddings. The POS tagger is trained on an LSTM neural network, and their approach performs consistently better than the other benchmarks they report. Lim et al. (2018) present work conducted on syntactically parsing Komi-Zyrian and Northern Sami using multilingual word-embeddings. They use pretrained word-embeddings for Finnish and Russian, and train word-embeddings for the lowresource languages from small corpora. These individual word-embeddings are then projected into a single space by using bilingual dictionaries. The parser was implemented as an LSTM model and it performed better in a POS tagging task than in predicting syntactic relations. The key finding for our purposes is that including a related high-resource language (Finnish in this case) improv"
W19-6139,W17-0607,0,0.112703,"thout any weights to indicate which reading is the most probable one. The existing CG disambiguators get the morphological readings produced by the FST for each word in a sentence and apply their rules to remove the non-possible readings. In some cases, a CG disambiguator might produce a fully disambiguated sentence, however these models are often unable to resolve all morphological ambiguity. In this paper, we use the UD Treebanks for our languages of interest. For Finnish, we use Turku Dependency Treebank (Haverinen et al., 2014) with 202K tokens (14K sentences). The Northern Sami Treebank (Sheyanova and Tyers, 2017) is the largest one for the endangered languages with 26K tokens (3K sentences). For Komi-Zyrian, we use the Komi-Zyrian Lattice Treebank (Partanen et al., 2018) of 2K tokens (189 sentences) representing the standard written Komi. The Erzya Treebank (Rueter and Tyers, 2018) is the second largest endangered language one we use in our research with 15k tokens (1,500 sentences). 5 Sentence Representation We represent each word as a non-empty set of morphological tags. This representation does not contain the word form itself nor its lemma, as we aim for a more abstract level morphological represe"
W19-8637,N19-1040,0,0.0176044,"sed online dictionary4 in such a way that we consider the three topmost translations that are verbs, nouns or adjectives for each English word. To deal with polysemy, if multiple English words translate into one Finnish word, we take the average of the concreteness values of the English words for the Finnish word. If the concreteness value is greater or equal to 3, the word is considered concrete. The aesthetic function gives a ratio of concrete words over concrete and abstract words in the poem. For sentiment, due to the lack of resources for Finnish, we use a recent state of the art method (Feng and Wan, 2019) that can learn sentiment prediction for English with annotated data and use the model for other languages by bilingual word embeddings. We train the model with sentiment annotated data for English from the OpeNER project (Agerri et al., 2013). We use their method to map the pretrained Finnish and English fasttext models from Grave et al. (2018) into a common space. This aesthetic measure will score sentiments on verse level and output their variance on the poem level. Dividing words into semantic fields can be used as an auxiliary tool in poem analysis in literature studies as it can reveal t"
W19-8637,L18-1550,0,0.0148521,"eater or equal to 3, the word is considered concrete. The aesthetic function gives a ratio of concrete words over concrete and abstract words in the poem. For sentiment, due to the lack of resources for Finnish, we use a recent state of the art method (Feng and Wan, 2019) that can learn sentiment prediction for English with annotated data and use the model for other languages by bilingual word embeddings. We train the model with sentiment annotated data for English from the OpeNER project (Agerri et al., 2013). We use their method to map the pretrained Finnish and English fasttext models from Grave et al. (2018) into a common space. This aesthetic measure will score sentiments on verse level and output their variance on the poem level. Dividing words into semantic fields can be used as an auxiliary tool in poem analysis in literature studies as it can reveal tensions inside of a poem (c.f Lotman, 1974). By following this notion, we cluster the open class part of speech words based on their cosine similarity within a poem. For this clustering, we use affinity propagation (Frey and Dueck, 2007), which takes a similarity matrix as input and clusters the words based on the matrix. The number of clusters"
W19-8637,W18-6534,1,0.506974,"Missing"
W19-8637,W18-0205,1,0.892839,"Missing"
W19-8637,D15-1166,0,0.034041,"of the master. In this section we evaluate the apprentices by evaluating their output by masters’ liking. This is done only in an automatic fashion by having all 3 of the apprentices create output for 100 randomly picked poems from the poem corpus. Apprentice Apprentice is a sequence-to-sequence model that learns to produce creatively altered verses out of verses in existing poetry. To achieve this, we use a BRNN model with a copy attention mechanism by using OpenNMT (Klein et al., 2018). We use the default settings which are two layers for encoding and decoding and general global attention (Luong et al., 2015). One apprentice is trained from the output of each master, and an additional one from the output of both of the masters. We train the apprentices for 90000 steps to produce poems one verse at a time, from the original poem to the master generated ones. The master for the 19th century produced 11903 poems and the 20th century one 11900 poems out of randomly picked initial poems from the entire corpus. These constitute the training data for the apprentices. The random seed used in training is the same for all apprentices to make intercomparison possible. apprentice 1800 apprentice 1900 apprenti"
W19-8637,W17-3502,0,0.0305593,"the genetic algorithm, such as sonic features, semantic coherence, imagery and metaphor. Furthermore, we justify the creativity of our method based on the FACE theory on computational creativity and take additional care in evaluating our system by automatic metrics for concepts together with human evaluation for aesthetics, framing and expressions. 1 2 Introduction Related Work While poetry generation has been tackled a number of times before by multiple authors (Gerv´as, 2001; Toivanen et al., 2012; Misztal and Indurkhya, 2014; Oliveira et al., 2017), and an excellent overview is provided by Oliveira (2017) on the recent state of the research, we dedicate this section in describing the most recent work conducted in the field after the aforementioned overview paper. TwitSong (Lamb and Brown, 2019) mines a corpus for verses to be used in poetry based on how well they rhyme together. They score the verses in poems by four metrics (meter, emotion, topicality and imagery) and use a genetic algorithm to edit the worst scoring verse in the poem. However, they only assess poems on a verse level and their algorithm lacks poem level metrics (i.e. each verse is considered individually and not as a part of"
W19-8637,W12-2502,0,0.013032,"nish spelling is almost one to one mapping with phonology, we can do this on a character level without the need to approximate the pronunciation. Meter is captured by two aesthetic functions: the number of syllables and the distribution of long and short syllables within a verse. These two functions are again solved by simple rules. The master rates higher the meter it has learned from its training corpus. A previous attempt to capture imagery in the literature is by comparing the number of abstract and non-abstract words with the hypothesis that nonabstract words provoke more mental imagery (Kao and Jurafsky, 2012). However, this notion can be used only as a proxy to the quantity of imagery in poetry, but it tells nothing about the nature of the provoked imagery. For this reason, we have also decided to use sentiment as an indicator of the mood of the mental image painted by the poem. For abstractness of words we use an existing 293 dataset for English that maps 40,000 common English words to an average concreteness score as annotated by humans on a 5-point Likert scale (Brysbaert et al., 2014). We translate this data in Finnish with a Wiktionary based online dictionary4 in such a way that we consider t"
W19-8637,W18-1817,0,0.0136338,"t is fixed and can only adjust its appreciation, but the apprentice is an entirely new concept that is created from the output of the master. In this section we evaluate the apprentices by evaluating their output by masters’ liking. This is done only in an automatic fashion by having all 3 of the apprentices create output for 100 randomly picked poems from the poem corpus. Apprentice Apprentice is a sequence-to-sequence model that learns to produce creatively altered verses out of verses in existing poetry. To achieve this, we use a BRNN model with a copy attention mechanism by using OpenNMT (Klein et al., 2018). We use the default settings which are two layers for encoding and decoding and general global attention (Luong et al., 2015). One apprentice is trained from the output of each master, and an additional one from the output of both of the masters. We train the apprentices for 90000 steps to produce poems one verse at a time, from the original poem to the master generated ones. The master for the 19th century produced 11903 poems and the 20th century one 11900 poems out of randomly picked initial poems from the entire corpus. These constitute the training data for the apprentices. The random se"
W19-8637,D18-1423,0,0.031688,"the ground level. And on the process level it refers to how such a program was generated. Finally, the ground level expression is the creative output, or artefact, generated by the system, whereas the process level of expression describes the method for generating output for a given input. is potentially problematic as broad questions open more room for subjective interpretation. Last year, a myriad of work on generation of Chinese poetry with machine learning methods was conducted. Research ranging from mutual reinforcement learning (Yi et al., 2018) and conditional variational autoencoders (Li et al., 2018) to sequence-to-sequence Bi-LSTMs (Yang et al., 2018) was presented. However, none of these methods has been motivated from the point of view of computational creativity, but rather serve for a purely generative purpose. The work conducted by Colton et al. (2012), although not recent, deserves special attention, as they had used the same FACE model as a basis in their poem generation. They take a template based approach to generating poems from current news articles. Unfortunately they do not provide an evaluation of the generated poetry, which makes meaningful comparison difficult. The work p"
W19-8637,D18-1430,0,0.0303358,"s to how such a program was generated. Finally, the ground level expression is the creative output, or artefact, generated by the system, whereas the process level of expression describes the method for generating output for a given input. is potentially problematic as broad questions open more room for subjective interpretation. Last year, a myriad of work on generation of Chinese poetry with machine learning methods was conducted. Research ranging from mutual reinforcement learning (Yi et al., 2018) and conditional variational autoencoders (Li et al., 2018) to sequence-to-sequence Bi-LSTMs (Yang et al., 2018) was presented. However, none of these methods has been motivated from the point of view of computational creativity, but rather serve for a purely generative purpose. The work conducted by Colton et al. (2012), although not recent, deserves special attention, as they had used the same FACE model as a basis in their poem generation. They take a template based approach to generating poems from current news articles. Unfortunately they do not provide an evaluation of the generated poetry, which makes meaningful comparison difficult. The work presented by us in this paper has to deal with the ric"
W19-8637,D18-1353,0,0.0316302,"refer to the program that generates creative artefacts on the ground level. And on the process level it refers to how such a program was generated. Finally, the ground level expression is the creative output, or artefact, generated by the system, whereas the process level of expression describes the method for generating output for a given input. is potentially problematic as broad questions open more room for subjective interpretation. Last year, a myriad of work on generation of Chinese poetry with machine learning methods was conducted. Research ranging from mutual reinforcement learning (Yi et al., 2018) and conditional variational autoencoders (Li et al., 2018) to sequence-to-sequence Bi-LSTMs (Yang et al., 2018) was presented. However, none of these methods has been motivated from the point of view of computational creativity, but rather serve for a purely generative purpose. The work conducted by Colton et al. (2012), although not recent, deserves special attention, as they had used the same FACE model as a basis in their poem generation. They take a template based approach to generating poems from current news articles. Unfortunately they do not provide an evaluation of the generated poet"
