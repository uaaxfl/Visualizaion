2021.humeval-1.11,On User Interfaces for Large-Scale Document-Level Human Evaluation of Machine Translation Outputs,2021,-1,-1,3,0,6016,roman grundkiewicz,Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval),0,"Recent studies emphasize the need of document context in human evaluation of machine translations, but little research has been done on the impact of user interfaces on annotator productivity and the reliability of assessments. In this work, we compare human assessment data from the last two WMT evaluation campaigns collected via two different methods for document-level evaluation. Our analysis shows that a document-centric approach to evaluation where the annotator is presented with the entire document context on a screen leads to higher quality segment and document level assessments. It improves the correlation between segment and document scores and increases inter-annotator agreement for document scores but is considerably more time consuming for annotators."
2020.wmt-1.1,Findings of the 2020 Conference on Machine Translation ({WMT}20),2020,-1,-1,5,0,8740,loic barrault,Proceedings of the Fifth Conference on Machine Translation,0,"This paper presents the results of the news translation task and the similar language translation task, both organised alongside the Conference on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages."
2020.nlpcovid19-2.5,{TICO}-19: the Translation Initiative for {CO}vid-19,2020,-1,-1,5,0,832,antonios anastasopoulos,Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020,0,"The COVID-19 pandemic is the worst pandemic to strike the world in over a century. Crucial to stemming the tide of the SARS-CoV-2 virus is communicating to vulnerable populations the means by which they can protect themselves. To this end, the collaborators forming the Translation Initiative for COvid-19 (TICO-19) have made test and development data available to AI and MT researchers in 35 different languages in order to foster the development of tools and resources for improving access to information about COVID-19 in these languages. In addition to 9 high-resourced, {''}pivot{''} languages, the team is targeting 26 lesser resourced languages, in particular languages of Africa, South Asia and South-East Asia, whose populations may be the most vulnerable to the spread of the virus. The same data is translated into all of the languages represented, meaning that testing or development can be done for any pairing of languages in the set. Further, the team is converting the test and development data into translation memories (TMXs) that can be used by localizers from and to any of the languages."
2020.iwslt-1.1,{FINDINGS} {OF} {THE} {IWSLT} 2020 {EVALUATION} {CAMPAIGN},2020,-1,-1,9,0,11026,ebrahim ansari,Proceedings of the 17th International Conference on Spoken Language Translation,0,"The evaluation campaign of the International Conference on Spoken Language Translation (IWSLT 2020) featured this year six challenge tracks: (i) Simultaneous speech translation, (ii) Video speech translation, (iii) Offline speech translation, (iv) Conversational speech translation, (v) Open domain translation, and (vi) Non-native speech translation. A total of teams participated in at least one of the tracks. This paper introduces each track{'}s goal, data and evaluation metrics, and reports the results of the received submissions."
2020.findings-emnlp.375,Assessing Human-Parity in Machine Translation on the Segment Level,2020,-1,-1,2,0,9403,yvette graham,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"Recent machine translation shared tasks have shown top-performing systems to tie or in some cases even outperform human translation. Such conclusions about system and human performance are, however, based on estimates aggregated from scores collected over large test sets of translations and unfortunately leave some remaining questions unanswered. For instance, simply because a system significantly outperforms the human translator on average may not necessarily mean that it has done so for every translation in the test set. Firstly, are there remaining source segments present in evaluation test sets that cause significant challenges for top-performing systems and can such challenging segments go unnoticed due to the opacity of current human evaluation procedures? To provide insight into these issues we carefully inspect the outputs of top-performing systems in the most recent WMT-19 news translation shared task for all language pairs in which a system either tied or outperformed human translation. Our analysis provides a new method of identifying the remaining segments for which either machine or human perform poorly. For example, in our close inspection of WMT-19 English to German and German to English we discover the segments that disjointly proved a challenge for human and machine. For English to Russian, there were no segments included in our sample of translations that caused a significant challenge for the human translator, while we again identify the set of segments that caused issues for the top-performing system."
W19-5401,Findings of the {WMT} 2019 Shared Tasks on Quality Estimation,2019,0,7,5,0,13913,erick fonseca,"Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",0,"We report the results of the WMT19 shared task on Quality Estimation, i.e. the task of predicting the quality of the output of machine translation systems given just the source text and the hypothesis translations. The task includes estimation at three granularity levels: word, sentence and document. A novel addition is evaluating sentence-level QE against human judgments: in other words, designing MT metrics that do not need a reference translation. This year we include three language pairs, produced solely by neural machine translation systems. Participating teams from eleven institutions submitted a variety of systems to different task variants and language pairs."
W19-5402,Findings of the {WMT} 2019 Shared Task on Automatic Post-Editing,2019,0,0,2,0.27658,13898,rajen chatterjee,"Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",0,"We present the results from the 5th round of the WMT task on MT Automatic Post-Editing. The task consists in automatically correcting the output of a {``}black-box{''} machine translation system by learning from human corrections. Keeping the same general evaluation setting of the previous four rounds, this year we focused on two language pairs (English-German and English-Russian) and on domain-specific data (In-formation Technology). For both the language directions, MT outputs were produced by neural systems unknown to par-ticipants. Seven teams participated in the English-German task, with a total of 18 submitted runs. The evaluation, which was performed on the same test set used for the 2018 round, shows a slight progress in APE technology: 4 teams achieved better results than last year{'}s winning system, with improvements up to -0.78 TER and +1.23 BLEU points over the baseline. Two teams participated in theEnglish-Russian task submitting 2 runs each. On this new language direction, characterized by a higher quality of the original translations, the task proved to be particularly challenging. None of the submitted runs improved the very high results of the strong system used to produce the initial translations(16.16 TER, 76.20 BLEU)."
W19-5301,Findings of the 2019 Conference on Machine Translation ({WMT}19),2019,0,50,4,0,8740,loic barrault,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"This paper presents the results of the premier shared task organized alongside the Conference on Machine Translation (WMT) 2019. Participants were asked to build machine translation systems for any of 18 language pairs, to be evaluated on a test set of news stories. The main metric for this task is human judgment of translation quality. The task was also opened up to additional test suites to probe specific aspects of translation."
D19-5503,Multilingual Whispers: Generating Paraphrases with Translation,2019,0,3,1,1,6017,christian federmann,Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019),0,"Naturally occurring paraphrase data, such as multiple news stories about the same event, is a useful but rare resource. This paper compares translation-based paraphrase gathering using human, automatic, or hybrid techniques to monolingual paraphrasing by experts and non-experts. We gather translations, paraphrases, and empirical human quality assessments of these approaches. Neural machine translation techniques, especially when pivoting through related languages, provide a relatively robust source of paraphrases with diversity comparable to expert human paraphrases. Surprisingly, human translators do not reliably outperform neural systems. The resulting data release will not only be a useful test set, but will also allow additional explorations in translation and paraphrase quality assessments and relationships."
W18-6401,Findings of the 2018 Conference on Machine Translation ({WMT}18),2018,0,84,2,0,292,ondvrej bojar,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"This paper presents the results of the premier shared task organized alongside the Conference on Machine Translation (WMT) 2018. Participants were asked to build machine translation systems for any of 7 language pairs in both directions, to be evaluated on a test set of news stories. The main metric for this task is human judgment of translation quality. This year, we also opened up the task to additional test sets to probe specific aspects of translation."
C18-2019,Appraise Evaluation Framework for Machine Translation,2018,0,0,1,1,6017,christian federmann,Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations,0,"We present Appraise, an open-source framework for crowd-based annotation tasks, notably for evaluation of machine translation output. This is the software used to run the yearly evaluation campaigns for shared tasks at the WMT Conference on Machine Translation. It has also been used at IWSLT 2017 and, recently, to measure human parity for machine translation for Chinese to English news text. The demo will present the full end-to-end lifecycle of an Appraise evaluation campaign, from task creation to annotation and interpretation of results."
W17-4717,Findings of the 2017 Conference on Machine Translation ({WMT}17),2017,0,109,3,0,292,ondvrej bojar,Proceedings of the Second Conference on Machine Translation,0,"This paper presents the results of the WMT17 shared tasks, which includedn three machine translation (MT) tasks (news, biomedical, and multimodal), two evaluation tasks (metrics and run-time estimation of MT quality), an automatic post-editing task, a neural MT training task, and a bandit learning task."
W16-2301,Findings of the 2016 Conference on Machine Translation,2016,113,137,3,0,292,ondvrej bojar,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper presents the results of the WMT16 shared tasks, which included five machine translation (MT) tasks (standard news, IT-domain, biomedical, multimodal, pronoun), three evaluation tasks (metrics, tuning, run-time estimation of MT quality), and an automatic post-editing task and bilingual document alignment task. This year, 102 MT systems from 24 institutions (plus 36 anonymized online systems) were submitted to the 12 translation directions in the news translation task. The IT-domain task received 31 submissions from 12 institutions in 7 directions and the Biomedical task received 15 submissions systems from 5 institutions. Evaluation was both automatic and manual (relative ranking and 100-point scale assessments). The quality estimation task had three subtasks, with a total of 14 teams, submitting 39 entries. The automatic post-editing task had a total of 6 teams, submitting 11 entries."
W15-3001,Findings of the 2015 Workshop on Statistical Machine Translation,2015,78,107,3,0.07424,292,ondvrej bojar,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"This paper presents the results of the WMT15 shared tasks, which included a standard news translation task, a metrics task, a tuning task, a task for run-time estimation of machine translation quality, and an automatic post-editing task. This year, 68 machine translation systems from 24 institutions were submitted to the ten translation directions in the standard translation task. An additional 7 anonymized systems were included, and were then evaluated both automatically and manually. The quality estimation task had three subtasks, with a total of 10 teams, submitting 34 entries. The pilot automatic postediting task had a total of 4 teams, submitting 7 entries."
2015.iwslt-papers.2,Applying cross-entropy difference for selecting parallel training data from publicly available sources for conversational machine translation,2015,0,4,2,0,36762,william lewis,Proceedings of the 12th International Workshop on Spoken Language Translation: Papers,0,None
W14-3302,Findings of the 2014 Workshop on Statistical Machine Translation,2014,75,148,3,0.0864455,292,ondvrej bojar,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper presents the results of the WMT14 shared tasks, which included a standard news translation task, a separate medical translation task, a task for run-time estimation of machine translation quality, and a metrics task. This year, 143 machine translation systems from 23 institutions were submitted to the ten translation directions in the standard translation task. An additional 6 anonymized systems were included, and were then evaluated both automatically and manually. The quality estimation task had four subtasks, with a total of 10 teams, submitting 57 entries"
W13-2201,Findings of the 2013 {W}orkshop on {S}tatistical {M}achine {T}ranslation,2013,86,192,4,0.0864455,292,ondvrej bojar,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"We present the results of the WMT13 shared tasks, which included a translation task, a task for run-time estimation of machine translation quality, and an unofficial metrics task. This year, 143 machine translation systems were submitted to the ten translation tasks from 23 institutions. An additional 6 anonymized systems were included, and were then evaluated both automatically and manually, in our largest manual evaluation to date. The quality estimation task had four subtasks, with a total of 14 teams, submitting 55 entries."
W12-5708,"System Combination Using Joint, Binarised Feature Vectors",2012,16,1,1,1,6017,christian federmann,Proceedings of the Second Workshop on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid {MT},0,"We describe a method for system combination based on joint, binarised feature vectors. Our method can be used to combine several black-box source systems. We first define a total order on given translation output which can be used to partition an n-best list of translations into a set of pairwise system comparisons. Using this data, we explain how an SVM-based classification model can be trained and how this classifier can be applied to combine translation output on the sentence level. We describe our experiments for the ML4HMT-12 shared task and conclude by giving a summary of our findings and by discussing future extensions and experiments using the proposed approach."
W12-5709,Results from the {ML}4{HMT}-12 Shared Task on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid Machine Translation,2012,11,0,1,1,6017,christian federmann,Proceedings of the Second Workshop on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid {MT},0,We describe the second edition of the ML4HMT shared task which challenges participants to create hybrid translations from the translation output of several individual MT systems. We provide an overview of the shared task and the data made available to participants before briefly describing the individual systems. We report on the results using automatic evaluation metrics and conclude with a summary of ML4HMT-12 and an outlook to future work.
W12-4210,Using Domain-specific and Collaborative Resources for Term Translation,2012,23,2,2,0,6275,mihael arcan,"Proceedings of the Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"In this article we investigate the translation of terms from English into German and vice versa in the isolation of an ontology vocabulary. For this study we built new domain-specific resources from the translation search engine Linguee and from the online encyclopedia Wikipedia. We learned that a domain-specific resource produces better results than a bigger, but more general one. The first finding of our research is that the vocabulary and the structure of the parallel corpus are important. By integrating the multilingual knowledge base Wikipedia, we further improved the translation wrt. the domain-specific resources, whereby some translation evaluation metrics outperformed the results of Google Translate. This finding leads us to the conclusion that a hybrid translation system, a combination of bilingual terminological resources and statistical machine translation can help to improve translation of domain-specific terms."
W12-3138,Machine Learning for Hybrid Machine Translation,2012,20,14,3,0,36181,sabine hunsicker,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"We describe a substitution-based system for hybrid machine translation (MT) that has been extended with machine learning components controlling its phrase selection. The approach is based on a rule-based MT (RBMT) system which creates template translations. Based on the rule-based generation parse tree and target-to-target alignments, we identify the set of interesting translation candidates from one or more translation engines which could be substituted into our translation templates. The substitution process is either controlled by the output from a binary classifier trained on feature vectors from the different MT engines, or it is depending on weights for the decision factors, which have been tuned using MERT. We are able to observe improvements in terms of BLEU scores over a baseline version of the hybrid system."
W12-0115,Can Machine Learning Algorithms Improve Phrase Selection in Hybrid Machine Translation?,2012,14,3,1,1,6017,christian federmann,Proceedings of the Joint Workshop on Exploiting Synergies between Information Retrieval and Machine Translation ({ESIRMT}) and Hybrid Approaches to Machine Translation ({H}y{T}ra),0,"We describe a substitution-based, hybrid machine translation (MT) system that has been extended with a machine learning component controlling its phrase selection. Our approach is based on a rule-based MT (RBMT) system which creates template translations. Based on the generation parse tree of the RBMT system and standard word alignment computation, we identify potential translation snippets from one or more translation engines which could be substituted into our translation templates. The substitution process is controlled by a binary classifier trained on feature vectors from the different MT engines. Using a set of manually annotated training data, we are able to observe improvements in terms of BLEU scores over a baseline version of the hybrid system."
avramidis-etal-2012-involving,Involving Language Professionals in the Evaluation of Machine Translation,2012,17,12,3,0,5140,eleftherios avramidis,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Significant breakthroughs in machine translation only seem possible if human translators are taken into the loop. While automatic evaluation and scoring mechanisms such as BLEU have enabled the fast development of systems, it is not clear how systems can meet real-world (quality) requirements in industrial translation scenarios today. The taraX{\""U} project paves the way for wide usage of hybrid machine translation outputs through various feedback loops in system development. In a consortium of research and industry partners, the project integrates human translators into the development process for rating and post-editing of machine translation outputs thus collecting feedback for possible improvements."
avramidis-etal-2012-richly,"A Richly Annotated, Multilingual Parallel Corpus for Hybrid Machine Translation",2012,12,3,3,0,5140,eleftherios avramidis,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In recent years, machine translation (MT) research has focused on investigating how hybrid machine translation as well as system combination approaches can be designed so that the resulting hybrid translations show an improvement over the individual ÂcomponentÂ translations. As a first step towards achieving this objective we have developed a parallel corpus with source text and the corresponding translation output from a number of machine translation engines, annotated with metadata information, capturing aspects of the translation process performed by the different MT systems. This corpus aims to serve as a basic resource for further research on whether hybrid machine translation algorithms and system combination techniques can benefit from additional (linguistically motivated, decoding, and runtime) information provided by the different systems involved. In this paper, we describe the annotated corpus we have created. We provide an overview on the component MT systems and the XLIFF-based annotation format we have developed. We also report on first experiments with the ML4HMT corpus data."
federmann-etal-2012-meta,{META}-{SHARE} v2: An Open Network of Repositories for Language Resources including Data and Tools,2012,2,12,1,1,6017,christian federmann,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We describe META-SHARE which aims at providing an open, distributed, secure, and interoperable infrastructure for the exchange of language resources, including both data and tools. The application has been designed and is developed as part of the T4ME Network of Excellence. We explain the underlying motivation for such a distributed repository for metadata storage and give a detailed overview on the META-SHARE application and its various components. This includes a discussion of the technical architecture of the system as well as a description of the component-based metadata schema format which has been developed in parallel. Development of the META-SHARE infrastructure adopts state-of-the-art technology and follows an open-source approach, allowing the general community to participate in the development process. The META-SHARE software package including full source code has been released to the public in March 2012. We look forward to present an up-to-date version of the META-SHARE software at the conference."
federmann-etal-2012-ml4hmt,The {ML}4{HMT} Workshop on Optimising the Division of Labour in Hybrid Machine Translation,2012,22,3,1,1,6017,christian federmann,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We describe the ÂShared Task on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid Machine TranslationÂ (ML4HMT) which aims to foster research on improved system combination approaches for machine translation (MT). Participants of the challenge are requested to build hybrid translations by combining the output of several MT systems of different types. We first describe the ML4HMT corpus used in the shared task, then explain the XLIFF-based annotation format we have designed for it, and briefly summarize the participating systems. Using both automated metrics scores and extensive manual evaluation, we discuss the individual performance of the various systems. An interesting result from the shared task is the fact that we were able to observe different systems winning according to the automated metrics scores when compared to the results from the manual evaluation. We conclude by summarising the first edition of the challenge and by giving an outlook to future work."
C12-1005,Experiments with Term Translation,2012,24,4,2,0,6275,mihael arcan,Proceedings of {COLING} 2012,0,"In this article we investigate the translation of financial terms from English into German in the isolation of an ontology vocabulary. For this study we automatically built new domain-specific resources from the translation search engine Linguee and from the online encyclopaedia Wikipedia. Due to the fact that we performed the translation approach on a monolingual ontology, we ran several sub-experiments to find the most appropriate model to translate the financial vocabulary. The findings from these experiments lead to the conclusion that a hybrid translation system, a combination of bilingual terminological resources and statistical machine translation, can help to improve translation of domain-specific terms. Finally we undertook a manual cross-lingual evaluation on the monolingual ontology to get a better understanding on this specific short text translation task."
2012.amta-papers.23,"Hybrid Machine Translation Using Joint, Binarised Feature Vectors",2012,-1,-1,1,1,6017,christian federmann,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"We present an approach for Hybrid Machine Translation, based on a Machine-Learning framework. Our method combines output from several source systems. We first define an extensible, total order on translations and use it to estimate a ranking on the sentence level for a given set of systems. We introduce and define the notion of joint, binarised feature vectors. We train an SVM-based classifier and show how its classification results can be used to create hybrid translations. We describe a series of oracle experiments on data sets from the WMT11 translation task in order to find an upper bound regarding the achievable level of translation quality. We also present results from first experiments with an implemented version of our system. Evaluation using NIST and BLEU metrics indicates that the proposed method can outperform its individual source systems. An interesting finding is that our approach allows to leverage good translations from otherwise bad systems as the translation quality estimation is based on sentence-level phenomena rather than corpus-level metrics. We conclude by summarising our findings and by giving an outlook to future work."
W11-2141,Stochastic Parse Tree Selection for an Existing {RBMT} System,2011,6,15,1,1,6017,christian federmann,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"In this paper we describe our hybrid machine translation system with which we participated in the WMT11 shared translation task for the Englishxe2x86x92German language pair. Our system was able to outperform its RBMT baseline and turned out to be the best-scored participating system in the manual evaluation. To achieve this, we extended an existing, rule-based MT system with a module for stochastic selection of analysis parse trees that allowed to better cope with parsing errors during the system's analysis phase. Due to the integration into the analysis phase of the RBMT engine, we are able to preserve the benefits of a rule-based translation system such as proper generation of target language text. Additionally, we used a statistical tool for terminology extraction to improve the lexicon of the RBMT system. We report results from both automated metrics and human evaluation efforts, including examples which show how the proposed approach can improve machine translation quality."
2011.eamt-1.31,From Statistical Term Extraction to Hybrid Machine Translation,2011,6,8,3,0,41883,petra wolf,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,This study presents a new hybrid approach for translation equivalent selection within a transfer-based machine translation system using an intertwined net of traditional linguistic methods together with statistical techniques. Detailed evaluation reveals that the translation quality can be improved substantially in this way.
W10-1708,Further Experiments with Shallow Hybrid {MT} Systems,2010,3,18,1,1,6017,christian federmann,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"We describe our hybrid machine translation system which has been developed for and used in the WMT10 shared task. We compute translations from a rule-based MT system and combine the resulting translation templates with partial phrases from a state-of-the-art phrase-based, statistical MT engine. Phrase substitution is guided by several decision factors, a continuation of previous work within our group. For the shared task, we have computed translations for six language pairs including English, German, French and Spanish. Our experiments have shown that our shallow substitution approach can effectively improve the translation result from the RBMT system; however it has also become clear that a deeper integration is needed to further improve translation quality."
federmann-2010-appraise,{A}ppraise: An Open-Source Toolkit for Manual Phrase-Based Evaluation of Translations,2010,12,18,1,1,6017,christian federmann,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We describe a focused effort to investigate the performance of phrase-based, human evaluation of machine translation output achieving a high annotator agreement. We define phrase-based evaluation and describe the implementation of Appraise, a toolkit that supports the manual evaluation of machine translation results. Phrase ranking can be done using either a fine-grained six-way scoring scheme that allows to differentiate between ''``much better'''' and ''``slightly better'''', or a reduced subset of ranking choices. Afterwards we discuss kappa values for both scoring models from several experiments conducted with human annotators. Our results show that phrase-based evaluation can be used for fast evaluation obtaining significant agreement among annotators. The granularity of ranking choices should, however, not be too fine-grained as this seems to confuse annotators and thus reduces the overall agreement. The work reported in this paper confirms previous work in the field and illustrates that the usage of human evaluation in machine translation should be reconsidered. The Appraise toolkit is available as open-source and can be downloaded from the author's website."
federmann-declerck-2010-extraction,"Extraction, Merging, and Monitoring of Company Data from Heterogeneous Sources",2010,5,1,1,1,6017,christian federmann,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We describe the implementation of an enterprise monitoring system that builds on an ontology-based information extraction (OBIE) component applied to heterogeneous data sources. The OBIE component consists of several IE modules - each extracting on a regular temporal basis a specific fraction of company data from a given data source - and a merging tool, which is used to aggregate all the extracted information about a company. The full set of information about companies, which is to be extracted and merged by the OBIE component, is given in the schema of a domain ontology, which is guiding the information extraction process. The monitoring system, in case it detects changes in the extracted and merged information on a company with respect to the actual state of the knowledge base of the underlying ontology, ensures the update of the population of the ontology. As we are using an ontology extended with temporal information, the system is able to assign time intervals to any of the object instances. Additionally, detected changes can be communicated to end-users, who can validate and possibly correct the resulting updates in the knowledge base."
W09-0405,Combining Multi-Engine Translations with {M}oses,2009,14,19,7,0.833333,3161,yu chen,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,"We present a simple method for generating translations with the Moses toolkit (Koehn et al., 2007) from existing hypotheses produced by other translation engines. As the structures underlying these translation engines are not known, an evaluation-based strategy is applied to select systems for combination. The experiments show promising improvements in terms of BLEU."
W09-0411,Translation Combination using Factored Word Substitution,2009,8,6,1,1,6017,christian federmann,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,"We present a word substitution approach to combine the output of different machine translation systems. Using part of speech information, candidate words are determined among possible translation options, which in turn are estimated through a pre-computed word alignment. Automatic substitution is guided by several decision factors, including part of speech, local context, and language model probabilities. The combination of these factors is defined after careful manual analysis of their respective impact. The approach is tested for the language pair German-English, however the general technique itself is language independent."
W08-0328,Using {M}oses to Integrate Multiple Rule-Based Machine Translation Engines into a Hybrid System,2008,8,43,2,0,13817,andreas eisele,Proceedings of the Third Workshop on Statistical Machine Translation,0,"Based on an architecture that allows to combine statistical machine translation (SMT) with rule-based machine translation (RBMT) in a multi-engine setup, we present new results that show that this type of system combination can actually increase the lexical coverage of the resulting hybrid system, at least as far as this can be measured via BLEU score."
schafer-etal-2008-extracting,Extracting and Querying Relations in Scientific Papers on Language Technology,2008,10,3,3,0,42237,ulrich schafer,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We describe methods for extracting interesting factual relations from scientific texts in computational linguistics and language technology taken from the ACL Anthology. We use a hybrid NLP architecture with shallow preprocessing for increased robustness and domain-specific, ontology-based named entity recognition, followed by a deep HPSG parser running the English Resource Grammar (ERG). The extracted relations in the MRS (minimal recursion semantics) format are simplified and generalized using WordNet. The resulting ÂquriplesÂ are stored in a database from where they can be retrieved (again using abstraction methods) by relation-based search. The query interface is embedded in a web browser-based application we call the ScientistÂs Workbench. It supports researchers in editing and online-searching scientific papers."
2008.eamt-1.6,Hybrid machine translation architectures within and beyond the {E}uro{M}atrix project,2008,-1,-1,2,0,13817,andreas eisele,Proceedings of the 12th Annual conference of the European Association for Machine Translation,0,None
W07-0726,Multi-Engine Machine Translation with an Open-Source {SMT} Decoder,2007,16,13,3,0,3161,yu chen,Proceedings of the Second Workshop on Statistical Machine Translation,0,We describe an architecture that allows to combine statistical machine translation (SMT) with rule-based machine translation (RBMT) in a multi-engine setup. We use a variant of standard SMT technology to align translations from one or more RBMT systems with the source text. We incorporate phrases extracted from these alignments into the phrase table of the SMT system and use the open-source decoder Moses to find good combinations of phrases from SMT training data with the phrases derived from RBMT. First experiments based on this hybrid architecture achieve promising results.
